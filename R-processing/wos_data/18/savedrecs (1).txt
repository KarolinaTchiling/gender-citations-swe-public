FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Mansri, I
   Kouadria, N
   Doghmane, N
   Harize, S
   Bekhouch, A
AF Mansri, Islem
   Kouadria, Nasreddine
   Doghmane, Noureddine
   Harize, Saliha
   Bekhouch, Amara
TI Reference picture selection with decreased temporal dependency for HEVC
   error resilience
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error-resilience; Error-resilience; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Low-delay; Low-delay; Low-delay; Low-delay;
   Low-delay; Low-delay; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Video transmission; Video
   transmission; Video transmission; Low-delay; Low-delay; Low-delay;
   Low-delay; Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation;
   Error-propagation; Error-propagation; Error-propagation; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment; Error
   concealment; Error concealment; Error concealment; Error concealment;
   Error concealment; Error concealment; Error concealment
ID QUALITY
AB The high level of compression efficiency achieved by the High-Efficiency Video Coding standard (HEVC) decreases the robustness of the encoded bitstreams. This increased susceptibility to network errors leads to end video quality degradation. Moreover, due to the high computational complexity of HEVC, high-resolution video transmission with time constraints over hostile channels such as wireless networks becomes more challenging. This paper proposes a reference picture selection-based error-resilient method to reduce the temporal error propagation due to high-trip delay and frame-copy concealment error. First, the encoder selects the reference pictures based on the error status received from the feedback channel, taking into consideration the Rate-Distortion-Optimization (RDO). Second, the temporal information mismatch prediction resulting from the error concealment is reduced by decreasing the temporal dependency between adjacent frames based on new motion -estimation tools. Results show a PSNR gain of about 6.13 dB, 5.20 dB and 4.72 dB for 1080p, 720p and 480p resolutions respectively.
C1 [Mansri, Islem; Kouadria, Nasreddine; Doghmane, Noureddine; Harize, Saliha] Badji Mokhtar Annaba Univ, Fac Technol, Dept Elect, Sidi Amar 23000, Annaba, Algeria.
   [Bekhouch, Amara] Souk Ahras Univ, Comp Sci Dept, Souk Ahras 41000, Algeria.
C3 Universite Badji Mokhtar - Annaba; Universite de Souk Ahras Mohammed
   Cherif Messaadia
RP Mansri, I (corresponding author), Badji Mokhtar Annaba Univ, Fac Technol, Dept Elect, Sidi Amar 23000, Annaba, Algeria.
EM islem.mansri@gmail.com
RI Bekhouch, Amara/KCK-6721-2024
OI Mansri, Islem/0000-0002-4093-353X
CR Alfaqheri TT, 2020, J REAL-TIME IMAGE PR, V17, P2047, DOI 10.1007/s11554-019-00923-5
   [Anonymous], 2022, ELECARD STREAMEYE ST
   [Anonymous], 2010, N11113 ISOIEC MPEG
   Bandyopadhyay SK, 2006, IEEE SARNOFF SYMPOS, P97
   Bo Li., 2011, VEHICULAR TECHNOLOGY, P1, DOI DOI 10.1109/ISGT.2011.5759178
   Bossen F., 2013, JCTVCL1100
   Carreira J, 2014, IEEE IMAGE PROC, P2457, DOI 10.1109/ICIP.2014.7025497
   Carreira J, 2014, EUR SIGNAL PR CONF, P281
   CISCO, 2018, CISCO VISUAL NETWORK, P1
   Fukunaga S, 1996, IEEE GLOBECOM 1996 - CONFERENCE RECORD, VOLS 1-3, P1503, DOI 10.1109/GLOCOM.1996.591892
   Guanghui Ren, 2010, Information Technology Journal, V9, P1390, DOI 10.3923/itj.2010.1390.1396
   Hong D., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P146, DOI 10.1109/PCS.2010.5702445
   ITU-T, 2008, ITU T P910 SUBJECTIV
   Maung HM, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030310
   Maung HM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P286, DOI 10.1109/ICDSP.2016.7868563
   Maung HM, 2015, 2015 15TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P241, DOI 10.1109/ISCIT.2015.7458352
   McCann K., 2022, DOCUMENT JCTVC S1002
   Nightingale J, 2014, IEEE T CONSUM ELECTR, V60, P242, DOI 10.1109/TCE.2014.6852000
   Oztas B, 2012, IEEE I C ELECT CIRC, P785, DOI 10.1109/ICECS.2012.6463542
   Piñol P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103495
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Sjöberg R, 2012, IEEE T CIRC SYST VID, V22, P1858, DOI 10.1109/TCSVT.2012.2223052
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang TY, 2018, IEEE ACCESS, V6, P71279, DOI 10.1109/ACCESS.2018.2879867
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wenger S, 2012, JCTVCH0072
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
NR 28
TC 0
Z9 0
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103724
DI 10.1016/j.jvcir.2022.103724
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7T5BS
UT WOS:000911461200001
DA 2024-07-18
ER

PT J
AU Menasri, W
   Djabri, M
   Chennoufi, S
   Skoudarli, A
   Bouhedda, M
   Benzineb, O
AF Menasri, Wahiba
   Djabri, Manel
   Chennoufi, Sarah
   Skoudarli, Abdellah
   Bouhedda, Mounir
   Benzineb, Omar
TI Hardware implementation of HEVC CABAC binarization/de-binarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binarization; CABAC; De-binarization; FPGA; HEVC; Matlab; VHDL
AB High efficiency video coding (HEVC) video codec applies different techniques in order to achieve high compression ratios and video quality that supports real-time applications. One of the critical techniques in HEVC is the Context adaptive Binary Arithmetic Coding (CABAC) which is type of entropy coding. CABAC comes at the cost of increased computational complexity, especially for parallelization and pipeline of these blocks: binar-ization, context modeling and binary arithmetic encoding. The Binarization (BZ) and de-Binarization (DBZ) methods are considered as important techniques in HEVC CABAC encoder and decoder respectively. Indeed, an important goal is to get high throughput in hardware architectures of CABAC BZ and DBZ in order to achieve high resolution applications. This work is the only one found on recent literature which focuses on design and implementation of full BZ and full DBZ compatible with H.265 and H.264. Consequently, a hardware archi-tectures of BZ and DBZ are designed and implemented by using VHDL language, targeted an FPGA virtex4 xc4vsx25-12ff668 board and emulated with ModelSim. As a result, the implementation of BZ and DBZ can process 2 bins/cycle for each syntax element when operated at 697.83 MHz and 789.26 MHz, respectively. The proposed designs exhibits an improved high-throughput of 1395.66 Mbins/s for BZ and 1578.52 Mbins/s for the DBZ. The obtained Area Efficiencies in our proposed BZ and DBZ are about 0.544 Mbins/s/slices and 0.606 Mbins/s/slices, respectively, and it is better than many recent works.
C1 [Menasri, Wahiba; Skoudarli, Abdellah] Univ Houari Boumediene Sci & Technol USTHB, Fac Elect & Comp Sci, Lab Image Proc & Radiat, BP 32 El Alia, Algiers, Algeria.
   [Menasri, Wahiba; Djabri, Manel; Chennoufi, Sarah] Univ Medea Nouveau Pole Urbain, Fac Technol, Medea, Algeria.
   [Bouhedda, Mounir] Univ Medea, Lab Adv Elect Syst LSEA, Medea 26000, Algeria.
   [Benzineb, Omar] Univ Blida 1, BP 270, Blida, Algeria.
C3 Universite Yahia Fares Medea
RP Menasri, W (corresponding author), Univ Houari Boumediene Sci & Technol USTHB, Fac Elect & Comp Sci, Lab Image Proc & Radiat, BP 32 El Alia, Algiers, Algeria.
EM omenasri@usthb.dz
CR Alonso CD, 2017, 2017 30TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN (SBCCI 2017): CHOP ON SANDS, P30, DOI 10.1145/3109984.3109988
   [Anonymous], 2014, DESIGN SUITE VERSION
   Banitalebi-Dehkordi M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2020.103011
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chen YH, 2015, IEEE T CIRC SYST VID, V25, P856, DOI 10.1109/TCSVT.2014.2363748
   del Mestre Martins Andre Luis, 2010, Proceedings of the 2010 17th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2010), P392, DOI 10.1109/ICECS.2010.5724535
   Tran DL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040684
   Hmida A. B., 2014, 2014 INT C ELECT SCI, P1
   Jarray N., 2013, PROC ENG TECHNOL, V3, P216
   Kim Doohwan, 2016, [Journal of IKEEE, 전기전자학회논문지], V20, P326
   Kim D, 2015, INT SOC DESIGN CONF, P183, DOI 10.1109/ISOCC.2015.7401779
   Liu Y., 2011, 2011 INT C ELECT INF, P2237, DOI 10.1109/ICEICE.2011.5777972
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Menasri W, 2019, IET IMAGE PROCESS, V13, P954, DOI 10.1049/iet-ipr.2018.6336
   ModelSim S., 2004, USERS MANUAL V6 0A
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Osorio RR, 2006, IEEE T CIRC SYST VID, V16, P1376, DOI 10.1109/TCSVT.2006.883508
   Pham Duyen Hai, 2014, [Journal of IKEEE, 전기전자학회논문지], V18, P356, DOI 10.7471/ikeee.2014.18.3.356
   Shirvaikar M., 2009, REAL TIME IMAGE VIDE, V7244
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sze V, 2013, IEEE WORKSHOP SIG, P165, DOI 10.1109/SiPS.2013.6674499
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   T. standardization sector of ITU, 2016, SER H AUD MULT SYST
   Yang YC, 2009, IEEE T CIRC SYST VID, V19, P1395, DOI 10.1109/TCSVT.2009.2020340
   Zhou DJ, 2015, IEEE T CIRC SYST VID, V25, P497, DOI 10.1109/TCSVT.2014.2337572
NR 25
TC 0
Z9 0
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103673
DI 10.1016/j.jvcir.2022.103673
EA OCT 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500007
DA 2024-07-18
ER

PT J
AU Shang, C
   Wu, F
   Wang, ML
   Gao, Q
AF Shang, Cheng
   Wu, Feng
   Wang, MeiLi
   Gao, Qiang
TI Cattle behavior recognition based on feature fusion under a dual
   attention mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dual attention mechanism; Feature fusion; Behavior recognition; Smart
   animal husbandry
AB In recent years, artificial intelligence has been widely used in such fields as agricultural informatization, precision agriculture and precision animal husbandry. Due to limited research on deep learning in real-time agricultural and pastoral situations, deep learning and computer vision have become very important topics in the agricultural field. Recent studies have shown that the fusion of features under different attention mechanisms will help advance the utilization of such features, and will thus influence the accuracy and generalization ability of the models used. In this paper, we propose a lightweight network structure based on feature fusion under a dual attention mechanism with the same activation and joint loss functions. More specifically, we propose an innovative method to improve the network structure of two different attention mechanisms, and achieve feature fusion by combining the two. At the same time, we keep the activation functions consistent with those of the original network structure, and we develop a joint loss function to expand the use of various features. We also take the novel approach of applying the trajectory behavior analysis method to walking and standing. Experiments using both a publicly available data set and a data set obtained from a farm show that our algorithm achieves state-of-the-art performance in terms of accuracy and generalization ability, as compared to other methods.
C1 [Shang, Cheng; Wu, Feng; Wang, MeiLi] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Peoples R China.
   [Wang, MeiLi] Minist Agr, Key Lab Agr Internet Things, Yangling 712100, Peoples R China.
   [Wang, MeiLi] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Peoples R China.
   [Gao, Qiang] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs; Northwest A&F University - China
RP Wang, ML (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Peoples R China.; Gao, Q (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
EM anshidiandu@foxmail.com; wufeng20180901@nwafu.edu.cn; wml@nwsuaf.edu.cn;
   hillfinder@nwafu.edu.cn
RI Wu, Feng/KCY-3017-2024
FU Shaanxi Province Key RD Program [2022QFY11-03]; Shaanxi Agricultural
   Science and Technology Innovation Drive Project [NYKJ-2021-YL (XN) 48];
   Key Laboratory of the Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, Yangling, Shaanxi, China [2018AIOT-09]
FX Acknowledgements This work was partially funded by the Shaanxi Province
   Key R & D Program (2022QFY11-03) , Shaanxi Agricultural Science and
   Technology Innovation Drive Project (NYKJ-2021-YL (XN) 48) , and the Key
   Laboratory of the Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, Yangling, Shaanxi 712100, China
   (2018AIOT-09) .
CR [Anonymous], 2010, BRIT MACH VIS C
   [Anonymous], 2018, WHAT HAVE WE LEARNED
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Gao R., 2017, IM2FLOW MOTION HALLU
   [何东健 He Dongjian], 2020, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P250
   Howard A. G., 2017, arXiv
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang HE, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102925
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Jiang M, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102846
   Ketprom U., 2011, 2011 Annual SRII Global Conference (SRII), P517, DOI 10.1109/SRII.2011.107
   Li W., 2019, arXiv
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ng ML, 2005, IEEE 2005 International Symposium on Microwave, Antenna, Propagation and EMC Technologies for Wireless Communications Proceedings, Vols 1 and 2, P67
   Qiao YL, 2020, IEEE INT CON AUTO SC, P967, DOI [10.1109/case48305.2020.9217026, 10.1109/CASE48305.2020.9217026]
   Qiao YL, 2019, IFAC PAPERSONLINE, V52, P318, DOI 10.1016/j.ifacol.2019.12.558
   Qin X., 2019, J. Hangzhou Dianzi Univ., V39, P12
   Roy AG, 2019, IEEE T MED IMAGING, V38, P540, DOI 10.1109/TMI.2018.2867261
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tang JL, 2019, NEUROCOMPUTING, V332, P270, DOI 10.1016/j.neucom.2018.12.052
   Taylor M, 2000, IN PRACTICE, V22, P604, DOI 10.1136/inpract.22.10.604
   Thi Thi Zin, 2020, 2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech), P65, DOI 10.1109/LifeTech48969.2020.1570625232
   Thi Thi Zin, 2018, International MultiConference of Engineers and Computer Scientists 2018. Proceedings, P320
   Tian S, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102576
   Volk T., 2012, SMART SYSTECH 2012, P1
   Wang D, 2018, COMPUT ELECTRON AGR, V154, P443, DOI 10.1016/j.compag.2018.09.030
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Z., 2010, P 2010 I E INT C COM, V2, pV2
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Zhang HY, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102942
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhong X, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103138
NR 35
TC 8
Z9 9
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103524
DI 10.1016/j.jvcir.2022.103524
EA APR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P5AF
UT WOS:000802020500003
DA 2024-07-18
ER

PT J
AU Kim, W
   Song, M
AF Kim, Wonjun
   Song, Minsoo
TI Decomposition and replacement: Spatial knowledge distillation for
   monocular depth estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular depth estimation; Knowledge distillation; Laplacian pyramid;
   ReplaceBlock
ID SINGLE-IMAGE
AB Knowledge distillation has become a key technique for making smart and light-weight networks through model compression and transfer learning. Unlike previous methods that applied knowledge distillation to the classification task, we propose to exploit the decomposition-and-replacement based distillation scheme for depth estimation from a single RGB color image. To do this, Laplacian pyramid-based knowledge distillation is firstly presented in this paper. The key idea of the proposed method is to transfer the rich knowledge of the scene depth, which is well encoded through the teacher network, to the student network in a structured way by decomposing it into the global context and local details. This is fairly desirable for the student network to restore the depth layout more accurately with limited resources. Moreover, we also propose a new guidance concept for knowledge distillation, so-called ReplaceBlock, which replaces blocks randomly selected in the decoded feature of the student network with those of the teacher network. Our ReplaceBlock gives a smoothing effect in learning the feature distribution of the teacher network by considering the spatial contiguity in the feature space. This process is also helpful to clearly restore the depth layout without the significant computational cost. Based on various experimental results on benchmark datasets, the effectiveness of our distillation scheme for monocular depth estimation is demonstrated in details. The code and model are publicly available at : https://github.com/tjqansthd/Lap_Rep_KD_Depth.
C1 [Kim, Wonjun; Song, Minsoo] Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University
RP Song, M (corresponding author), Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
EM wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
OI SONG, MINSOO/0000-0003-3823-4913
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2020R1F1A1068080]
FX Acknowledgments This work was supported by the National Research
   Foundation of Korea (NRF) grant funded by the Korea government (MSIT)
   (No. 2020R1F1A1068080) .
CR BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cao YZH, 2020, IEEE T CIRC SYST VID, V30, P2674, DOI 10.1109/TCSVT.2019.2929202
   Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321
   Chen Guobin, 2017, NEURIPS
   Dahyun Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P575, DOI 10.1007/978-3-030-58610-2_34
   Denton E.L., 2015, CoRR, P1486
   Dong X., 2019, ADV NEUR IN, P760
   Eigen D, 2014, ADV NEUR IN, V27
   Fei P., 2021, IEEE T INSTRUM MEAS, V70, P1
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Ghiasi G, 2018, ADV NEUR IN, V31
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Guo XY, 2018, LECT NOTES COMPUT SC, V11215, P506, DOI 10.1007/978-3-030-01252-6_30
   Hambarde P, 2020, IEEE IMAGE PROC, P1441, DOI 10.1109/ICIP40778.2020.9190985
   Hambarde P, 2020, IEEE T COMPUT IMAG, V6, P806, DOI 10.1109/TCI.2020.2981761
   Hambarde P, 2019, IEEE IMAGE PROC, P989, DOI [10.1109/icip.2019.8803027, 10.1109/ICIP.2019.8803027]
   He K., 2016, P IEEE C COMP VIS PA, P770, DOI DOI 10.48550/ARXIV.1512.03385
   Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648
   Hinton G., 2015, COMPUT SCI, V2
   Ignatov A, 2021, IEEE COMPUT SOC CONF, P2545, DOI 10.1109/CVPRW53098.2021.00288
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Komodakis N, 2017, P ICLR
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lee J, 2019, IEEE ACCESS, V7, P167260, DOI 10.1109/ACCESS.2019.2953542
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Liu Y, 2021, PATTERN ANAL APPL, V24, P611, DOI 10.1007/s10044-020-00932-2
   Loshkarev IY, 2019, J PHYS CONF SER, V1333, DOI 10.1088/1742-6596/1333/4/042019
   Mohaghegh H, 2019, IEEE T CIRC SYST VID, V29, P683, DOI 10.1109/TCSVT.2018.2808682
   Paris S, 2015, COMMUN ACM, V58, P81, DOI 10.1145/2723694
   Paszke A., 2017, PROC 31 INT C NEURAL
   Pilzer A, 2019, PROC CVPR IEEE, P9760, DOI 10.1109/CVPR.2019.01000
   Poggi M, 2020, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR42600.2020.00329
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song M, 2021, IEEE T CIRC SYST VID, V31, P4381, DOI 10.1109/TCSVT.2021.3049869
   Song M, 2019, IEEE ACCESS, V7, P142595, DOI 10.1109/ACCESS.2019.2944937
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Srinivas S., 2015, P BRIT MACH VIS C 20, DOI DOI 10.5244/C.29.31
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian FZ, 2022, IEEE T CIRC SYST VID, V32, P1751, DOI 10.1109/TCSVT.2021.3080928
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   Wang T, 2019, PROC CVPR IEEE, P4928, DOI 10.1109/CVPR.2019.00507
   Wolk D, 2019, IEEE INT CONF ROBOT, P6101, DOI [10.1109/icra.2019.8794182, 10.1109/ICRA.2019.8794182]
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xie J., 2018, PROC BRIT MACH VIS C
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Yukang Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P346, DOI 10.1007/978-3-030-58571-6_21
   Zhang K, 2021, IEEE T CIRC SYST VID
   Zhang ZW, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3237
NR 56
TC 2
Z9 2
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
DI 10.1016/j.jvcir.2022.103523
EA APR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P5AF
UT WOS:000802020500004
DA 2024-07-18
ER

PT J
AU Chai, XL
   Shao, F
AF Chai, Xiongli
   Shao, Feng
TI M2OVQA: Multi-space signal characterization and multi-channel
   information aggregation for quality assessment of compressed
   omnidirectional videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Omnidirectional video quality assessment; Image quality assessment;
   Compression distortion; Signal characterization; Information aggregation
ID IMAGE; SIMILARITY; PERCEPTION
AB Considering the high requirements for omnidirectional video compression, we propose an objective quality evaluation method to assess quality loss in encoding omnidirectional videos. According to characteristics of 360 degrees videos, we consider multi-space signal characterization (MSSC) to fully characterize the distortions of video signals from spatial/image domains to frequency domains and from image content to motion information, and further consider multi-channel information aggregation (MCIA) to fuse scores from multiple projection planes and temporal divided groups. The main innovation of our method is to establish a universal framework in bridging the connection between typical quality assessment and 360 degrees quality assessment to measure 360 degrees video quality effectively and efficiently. Experimental results show that our method outperforms state-of-the-art 2D quality metrics and quality metrics for omnidirectional images.
C1 [Chai, Xiongli; Shao, Feng] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
EM shaofeng@nbu.edu.cn
FU Natural Science Foundation of China [62071261, 61622109]; Zhejiang
   Natural Science Foun-dation of China [R18F010008]; K.C. Wong Magna Fund
   in Ningbo University
FX Acknowledgments This work was supported by the Natural Science
   Foundation of China (grant 62071261, 61622109) , and the Zhejiang
   Natural Science Foun-dation of China (grant R18F010008) . It was also
   sponsored by K.C. Wong Magna Fund in Ningbo University.
CR Aabed MA, 2017, IEEE INT CON MULTI, P1476, DOI 10.1109/ICME.2017.8019333
   [Anonymous], 2016, ITU-T Recommendation G.652
   Athar S, 2019, IEEE ACCESS, V7, P140030, DOI 10.1109/ACCESS.2019.2943319
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   BRADY N, 1995, VISION RES, V35, P739, DOI 10.1016/0042-6989(94)00172-I
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen SJ, 2018, IEEE INT CON MULTI
   Duan H., 2017, P IEEE INT C SYST SI, P1
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Egiazarian K., 2006, proceedings of the second international workshop on video processing and quality metrics, P4
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   He Y., 2018, JVET AHG REPORT 360
   Henriksson L, 2009, J NEUROSCI, V29, P14342, DOI 10.1523/JNEUROSCI.3136-09.2009
   Hosseini MS, 2019, IEEE T IMAGE PROCESS, V28, P4510, DOI 10.1109/TIP.2019.2906582
   Hosseini MS, 2017, IEEE T IMAGE PROCESS, V26, P4596, DOI 10.1109/TIP.2017.2713950
   Huang MK, 2018, IEEE T IMAGE PROCESS, V27, P6039, DOI 10.1109/TIP.2018.2865089
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jiang QP, 2020, IEEE T INSTRUM MEAS, V69, P9784, DOI 10.1109/TIM.2020.3005111
   Jiang QP, 2020, IEEE T INSTRUM MEAS, V69, P7398, DOI 10.1109/TIM.2020.2984928
   Jiang QP, 2019, IEEE T IMAGE PROCESS, V28, P1866, DOI 10.1109/TIP.2018.2881828
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Kelley C. T., 1999, FRONT APP M, V18
   Kim HG, 2020, IEEE T CIRC SYST VID, V30, P917, DOI 10.1109/TCSVT.2019.2898732
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li C, 2019, PROC CVPR IEEE, P7864, DOI 10.1109/CVPR.2019.00806
   Li C, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P932, DOI 10.1145/3240508.3240581
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Li YM, 2019, IEEE T CIRC SYST VID, V29, P1767, DOI 10.1109/TCSVT.2018.2846042
   Lim HT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6737, DOI 10.1109/ICASSP.2018.8461317
   Lin JY, 2014, ASIAPAC SIGN INFO PR
   Ling SY, 2019, IEEE J EM SEL TOP C, V9, P204, DOI 10.1109/JETCAS.2019.2893484
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Pan Gao, 2022, IEEE Transactions on Multimedia, V24, P1, DOI 10.1109/TMM.2020.3044458
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Stankowski J., 2020, JTC1SC29WG11 ISO IEC
   Sun W., 2018, 2018 IEEE International Conference on Communications (ICC), P1, DOI 10.1109/MMSP.2018.8547102
   Sun W, 2020, IEEE J-STSP, V14, P64, DOI 10.1109/JSTSP.2019.2955024
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Upenik E, 2017, INT WORK QUAL MULTIM
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2019, IEEE T MULTIMEDIA, V21, P2738, DOI 10.1109/TMM.2019.2908377
   Xia C, 2016, IEEE T NEUR NET LEAR, V27, P1227, DOI 10.1109/TNNLS.2015.2512898
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1109/TCSVT.2018.2886277, 10.1080/17445302.2018.1558727]
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XF, 2019, IEEE T IMAGE PROCESS, V28, P1163, DOI 10.1109/TIP.2018.2874283
   Zhang YX, 2018, IEEE T BROADCAST, V64, P461, DOI 10.1109/TBC.2018.2811627
NR 61
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103419
DI 10.1016/j.jvcir.2021.103419
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PA
UT WOS:000783924200001
DA 2024-07-18
ER

PT J
AU Pan, JS
   Liu, T
   Yang, HM
   Yan, B
   Chu, SC
   Zhu, TT
AF Pan, Jeng-Shyang
   Liu, Tao
   Yang, Hong-Mei
   Yan, Bin
   Chu, Shu-Chuan
   Zhu, Tongtong
TI Visual cryptography scheme for secret color images with color QR codes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography scheme; Color QR code; Color XOR
ID ERROR DIFFUSION; ENCRYPTION
AB Visual cryptography scheme can divide the secret image into several shares. It can be used to enhance the secure transmission of the secret image on the Internet. Most schemes cannot fully restore the secret color image and generate meaningful shares. This paper proposes two new schemes by using color XOR to solve these problems. The first proposed scheme generates meaningless shares. The second proposed scheme can generate n - 1 meaningful shares and a meaningless share. Based on the first proposed scheme, n - 1 shares are modified to color QR codes in the second proposed scheme. These color QR codes can be decoded by the general decoder instead of the standard decoder. All shares are performed the color XOR to restore the secret color image completely. This paper uses some experiments to test two proposed schemes. Experimental results show that the two proposed schemes are feasible.
C1 [Pan, Jeng-Shyang; Liu, Tao; Yang, Hong-Mei; Chu, Shu-Chuan] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Yan, Bin; Zhu, Tongtong] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Chu, SC (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM jengshyangpan@gmail.com; taoliu0201@163.com; yhm1998@163.com;
   yanbinhit@hotmail.com; scchu0803@gmail.com; Tongtongzhu97@163.com
RI Pan, Jeng-Shyang/AEO-3450-2022; Zhu, Tongtong/J-2081-2016; Chu,
   Shu-Chuan/AFQ-6798-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025; Chu, Shu-Chuan/0000-0003-2117-0618
CR Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Agar AU, 2005, IEEE T IMAGE PROCESS, V14, P1945, DOI 10.1109/TIP.2005.859380
   [Anonymous], 2021, ZXING LIB
   [Anonymous], 1929, T OPT SOC, DOI DOI 10.1088/1475-4878/30/4/301
   Bakshi A, 2019, J INF SECUR APPL, V46, P281, DOI 10.1016/j.jisa.2019.03.004
   Bellare M, 2003, LECT NOTES COMPUT SC, V2612, P1
   Chen B, 2018, J VIS COMMUN IMAGE R, V57, P272, DOI 10.1016/j.jvcir.2018.11.017
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Ding SY, 2016, NAT REV MATER, V1, DOI [10.1038/natrevmats.2016.71, 10.1038/natrevmats.2016.21]
   Evans BL, 2003, PROC SPIE, V5008, P371, DOI 10.1117/12.481450
   Fairman HS, 1997, COLOR RES APPL, V22, P11, DOI 10.1002/(SICI)1520-6378(199702)22:1<11::AID-COL4>3.0.CO;2-7
   Fang WP, 2009, INT J COMPUT SCI NET, V9, P204
   Feng H., 2002, INF MANAGE COMPUT SE
   FLOYD R, 1975, SID INT S, P36
   FLOYD RW, 1976, P SID, V17, P75
   Guild J, 1932, PHILOS T R SOC LOND, V230, P149, DOI 10.1098/rsta.1932.0005
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Huang PC, 2019, MULTIMED TOOLS APPL, V78, P26023, DOI 10.1007/s11042-019-07795-8
   Information technology, 2006, QR COD 2005 BAR COD, V8004
   Li LD, 2010, INFORM SCIENCES, V180, P2875, DOI 10.1016/j.ins.2010.04.009
   Lin SJ, 2008, ISI 2008: 2008 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P271, DOI 10.1109/ISI.2008.4565080
   Liu T, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214670
   Lou DC, 2011, DISPLAYS, V32, P118, DOI 10.1016/j.displa.2011.02.001
   Luo H, 2014, MEASUREMENT, V51, P81, DOI 10.1016/j.measurement.2014.01.033
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Shaowei Weng, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P241
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Thomas Sandhya Anne, 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1091, DOI 10.1109/ICOEI.2018.8553863
   Tian AQ, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12030767
   Ulichney R., 1987, DIGITAL HALFTONING
   Wan S, 2020, MULTIMED TOOLS APPL, V79, P2789, DOI 10.1007/s11042-019-08246-0
   Wang L, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010065
   Wang XY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103123
   Weng SW, 2021, INFORM SCIENCES, V549, P13, DOI 10.1016/j.ins.2020.10.063
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wu TY, 2019, J CHIN INST ENG, V42, P20, DOI 10.1080/02533839.2018.1537807
   Wu XT, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107657
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
   Yang CN, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102660
NR 44
TC 12
Z9 12
U1 4
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103405
DI 10.1016/j.jvcir.2021.103405
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0V1MU
UT WOS:000788110200002
DA 2024-07-18
ER

PT J
AU Shen, XP
   Ding, YR
AF Shen, Xiangpei
   Ding, Yanrui
TI Human skeleton representation for 3D action recognition based on complex
   network coding and LSTM
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skeleton-based action recognition; Complex network coding; LSTM; Feature
   extraction
AB 3D skeleton sequences contain more effective and discriminative information than RGB video and are more suitable for human action recognition. Accurate extraction of human skeleton information is the key to the high accuracy of action recognition. Considering the correlation between joint points, in this work, we first propose a skeleton feature extraction method based on complex network. The relationship between human skeleton points in each frame is coded as a network. The changes of action over time are described by a time series network composed of skeleton points. Network topology attributes are used as feature vectors, complex network coding and LSTM are combined to recognize human actions. The method was verified on the NTU RGB + D60, MSR Action3D and UTKinect-Action3D dataset, and have achieved good performance, respectively. It shows that the method of extracting skeleton features based on complex network can properly identify different actions. This method that considers the temporal information and the relationship between skeletons at the same time plays an important role in the accurate recognition of human actions.
C1 [Shen, Xiangpei; Ding, Yanrui] Jiangnan Univ, Sch Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Shen, Xiangpei] Jiangnan Univ, Lab Media Design & Software Technol, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Ding, YR (corresponding author), Jiangnan Univ, Sch Sci, Wuxi 214122, Jiangsu, Peoples R China.
EM yr_ding@jiangnan.edu.cn
OI /0000-0001-8383-6900
CR [Anonymous], 2014, ASIAN C COMPUT VIS
   [Anonymous], 2016, END TO END SPATIO TE
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Ding W., 2015, STFC SPATIO TEMPORAL, V26, P329
   Ding W., 2017, LEARNING LINEAR DYNA
   Ding WW, 2018, PATTERN RECOGN, V77, P75, DOI 10.1016/j.patcog.2017.12.004
   Ellis C., 2013, EXPLORING TRADEOFF A, V101, P420
   Eweiwi A, 2015, LECT NOTES COMPUT SC, V9007, P428, DOI 10.1007/978-3-319-16814-2_28
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Lev G, 2016, LECT NOTES COMPUT SC, V9910, P833, DOI 10.1007/978-3-319-46466-4_50
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li L, 2018, ARXIVHTTPARXIVORGABS, V1, P3
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lo Presti, 2016, 3D SKELETON BASED HU
   Lo Presti L., 2015, HANKELETBASED DYNAMI, V44, P29
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Si C., 2020, SKELETON BASED ACTIO, V107
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Slama R., 2015, ACCURATE 3D ACTION R, V48, P556
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yan S., 2018, J ARXIV PREPRINT ARX
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhu W., 2016, X J ARXIV PREPRINT A
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 36
TC 12
Z9 13
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103386
DI 10.1016/j.jvcir.2021.103386
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z2GF
UT WOS:000790895000004
DA 2024-07-18
ER

PT J
AU Baffour, AA
   Qin, Z
   Wang, Y
   Qin, ZG
   Choo, KKR
AF Baffour, Adu Asare
   Qin, Zhen
   Wang, Yong
   Qin, Zhiguang
   Choo, Kim-Kwang Raymond
TI Spatial self-attention network with self-attention distillation for
   fine-grained image recognitionx2729;
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained recognition; Spatial self-attention; Knowledge
   distillation; Convolutional neural network
AB The underlining task for fine-grained image recognition captures both the inter-class and intra-class discriminate features. Existing methods generally use auxiliary data to guide the network or a complex network comprising multiple sub-networks. They have two significant drawbacks: (1) Using auxiliary data like bounding boxes requires expert knowledge and expensive data annotation. (2) Using multiple sub-networks make network architecture complex and requires complicated training or multiple training steps. We propose an end-to-end Spatial Self-Attention Network (SSANet) comprising a spatial self-attention module (SSA) and a self-attention distillation (Self-AD) technique. The SSA encodes contextual information into local features, improving intra-class representation. Then, the Self-AD distills knowledge from the SSA to a primary feature map, obtaining inter-class representation. By accumulating classification losses from these two modules enables the network to learn both inter-class and intra-class features in one training step. The experiment findings demonstrate that SSANet is effective and achieves competitive performance.
C1 [Baffour, Adu Asare; Qin, Zhen; Qin, Zhiguang] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
   [Qin, Zhen; Qin, Zhiguang] Network & Data Secur Key Lab Sichuan Prov, Chengdu 610054, Peoples R China.
   [Wang, Yong] Zhengzhou Aiwen Comp Technol Co Ltd, Zhengzhou 450000, Henan, Peoples R China.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.
C3 University of Electronic Science & Technology of China; University of
   Texas System; University of Texas at San Antonio (UTSA)
RP Qin, Z (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.; Qin, Z (corresponding author), Network & Data Secur Key Lab Sichuan Prov, Chengdu 610054, Peoples R China.
EM baffour@std.uestc.edu.cn; qinzhen@uestc.edu.cn; wangyong@ipplus360.com;
   qinzhen@uestc.edu.cn; raymond.choo@fulbrightmail.org
RI Baffour, Adu Asare/ABH-3045-2021
OI Baffour, Adu Asare/0000-0002-3349-8154; Choo, Kim-Kwang
   Raymond/0000-0001-9208-5336; Wang, Yong/0000-0002-8699-8355
FU National Natural Science Foundation of China [62076054, 62072074,
   62027827]; Frontier Science and Technology Innovation Projects of
   National Key RD Program [2019QY1405]; Sichuan Science-Technology Support
   Plan Program [2020YFSY0010, 2019YJ0636]; Sichuan Science and Technology
   Innovation Platform and Talent Plan [2020JDJQ0020]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 62076054, No. 62072074, No. 62027827), the
   Frontier Science and Technology Innovation Projects of National Key R&D
   Program (No. 2019QY1405), the Sichuan Science-Technology Support Plan
   Program (No. 2020YFSY0010, No. 2019YJ0636), the Sichuan Science and
   Technology Innovation Platform and Talent Plan (No. 2020JDJQ0020), and
   Kim-Kwang Raymond Choo was supported only by the Cloud Technology
   Endowed.
CR Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Dubey Abhimanyu, 2017, ABS170508016 CORR
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   Haase Daniel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14588, DOI 10.1109/CVPR42600.2020.01461
   He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775
   Hua X.-S., 2013, Proceedings of the 21st ACM International Conference on Multimedia, Oct. 21-25, ACM, P243
   Imran Ashiq, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P53, DOI 10.1007/978-3-030-64559-5_5
   Jetley S., 2018, P INT C LEARN REPR
   Ji R., 2019, ABS190911378 CORR
   Jiao QH, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102584
   Jing LL, 2018, J VIS COMMUN IMAGE R, V52, P58, DOI 10.1016/j.jvcir.2018.01.016
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Linsley Drew, 2018, ABS180508819 CORR
   Liu Xiao., 2016, CoRR abs/1603.06765
   Luo W, 2020, IEEE SIGNAL PROC LET, V27, P1545, DOI 10.1109/LSP.2020.3020227
   Mnih V, 2014, ADV NEUR IN, V27
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Qin Z, 2019, IEEE ACCESS, V7, P152891, DOI 10.1109/ACCESS.2019.2948260
   Qin Z, 2020, INFORM FUSION, V53, P80, DOI 10.1016/j.inffus.2019.06.014
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shen W., 2018, ABS181110770 CORR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Sun X, 2021, IEEE T IND ELECTRON, V68, P3588, DOI 10.1109/TIE.2020.2977553
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhou W, 2019, J VIS COMMUN IMAGE R, V61, P112, DOI 10.1016/j.jvcir.2019.03.003
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 48
TC 17
Z9 17
U1 3
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103368
DI 10.1016/j.jvcir.2021.103368
EA NOV 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD4BM
UT WOS:000722656700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Baisa, NL
AF Baisa, Nathanael L.
TI Occlusion-robust online multi-object visual tracking using a GM-PHD
   filter with CNN-based re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Online visual tracking; GM-PHD filter; Prediction; CNN features;
   Augmented likelihood; Re-identification
ID MULTITARGET TRACKING; MULTIPLE-TARGET
AB We propose a novel online multi-object visual tracker using a Gaussian mixture Probability Hypothesis Density (GM-PHD) filter and deep appearance learning. The GM-PHD filter has a linear complexity with the number of objects and observations while estimating the states and cardinality of time-varying number of objects, however, it is susceptible to miss-detections and does not include the identity of objects. We use visual-spatiotemporal information obtained from object bounding boxes and deeply learned appearance representations to perform estimates-to-tracks data association for target labeling as well as formulate an augmented likelihood and then integrate into the update step of the GM-PHD filter. We also employ additional unassigned tracks prediction after the data association step to overcome the susceptibility of the GM-PHD filter towards miss detections caused by occlusion. Extensive evaluations on MOT16, MOT17 and HiEve benchmark data sets show that our tracker significantly outperforms several state-of-the-art trackers in terms of tracking accuracy and identification.
C1 [Baisa, Nathanael L.] De Montfort Univ, Sch Comp Sci & Informat, Leicester LE1 9BH, Leics, England.
   [Baisa, Nathanael L.] Univ Lincoln, Sch Comp Sci, Lincoln LN6 7TS, England.
C3 De Montfort University; University of Lincoln
RP Baisa, NL (corresponding author), De Montfort Univ, Sch Comp Sci & Informat, Leicester LE1 9BH, Leics, England.
EM nathanael.baisa@dmu.ac.uk
OI Baisa, Nathanael L/0000-0003-2564-4681
CR [Anonymous], 2017, 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)
   [Anonymous], 2006, Proc. Siggraph Course
   [Anonymous], 2014, ARXIV14097618
   Vo BN, 2017, IEEE T SIGNAL PROCES, V65, P1975, DOI 10.1109/TSP.2016.2641392
   Vo BN, 2014, IEEE T SIGNAL PROCES, V62, P6554, DOI 10.1109/TSP.2014.2364014
   Baisa N.L, 2018, THESIS HERIOT WATT U
   Baisa N. L, 2019, ARXIV190803945
   Baisa NL, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019), DOI 10.23919/fusion43075.2019.9011441
   Baisa NL, 2019, DIGIT SIGNAL PROCESS, V89, P49, DOI 10.1016/j.dsp.2019.03.005
   Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026
   Baisa NL, 2018, J VIS COMMUN IMAGE R, V55, P464, DOI 10.1016/j.jvcir.2018.06.027
   Ban YT, 2016, LECT NOTES COMPUT SC, V9914, P52, DOI 10.1007/978-3-319-48881-3_5
   Bar-Shalom Y., 2011, Tracking and Data Fusion: A Handbook of Algorithms
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Borah A., 2017, Poly-lactic-co-glycolic acid Nanoformulation of Small Molecule Antagonist GANT61 for Cancer Annihilation, P1, DOI DOI 10.1109/AVSS.2017.8078481
   BOURGEOIS F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Emami, 2018, ARXIV PREPRINT ARXIV
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu ZY, 2019, IEEE T MULTIMEDIA, V21, P2277, DOI 10.1109/TMM.2019.2902480
   Fu ZY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4299, DOI 10.1109/ICASSP.2018.8461946
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kim DY, 2017, INT CONF CONTR AUTO, P181, DOI 10.1109/ICCAIS.2017.8217572
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leal-Taix L., 2015, MOTCHALLENGE 2015 BE
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Lee S, 2019, IEEE ACCESS, V7, P8181, DOI 10.1109/ACCESS.2018.2889442
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICCV.2009.5459432
   Lin W., 2021, ARXIV200504490
   Liu QK, 2019, IEEE ACCESS, V7, P76489, DOI 10.1109/ACCESS.2019.2921975
   Mahler R., 2014, ADV STAT MULTISOURCE
   Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119
   Maksai A, 2019, PROC CVPR IEEE, P4634, DOI 10.1109/CVPR.2019.00477
   Milan A., 2016, ARXIV160300831
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/502007
   Panta K, 2009, IEEE T AERO ELEC SYS, V45, P1003, DOI 10.1109/TAES.2009.5259179
   Paszke A, 2019, ADV NEUR IN, V32
   Peng J., 2018, 2018 AS COMM PHOT C 2018 AS COMM PHOT C, P1
   Peng JL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4615, DOI 10.1145/3394171.3416283
   Peng JL, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107480
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Ren S., 2015, IEEE T PATTERN ANAL, DOI [DOI 10.1109/TPAMI.2016.2577031, 10.1109/TPAMI.2016.2577031]
   Rezatofighi SH, 2015, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2015.349
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Ristic B, 2012, IEEE T AERO ELEC SYS, V48, P1656, DOI 10.1109/TAES.2012.6178085
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Song Guanglu, 2017, ARXIV171108766
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Song YM, 2019, IEEE ACCESS, V7, P165103, DOI 10.1109/ACCESS.2019.2953276
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Vo B.-N., 2015, Wiley encyclopedia of electrical and electronics engineering
   Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190
   Vo BN, 2005, IEEE T AERO ELEC SYS, V41, P1224, DOI 10.1109/TAES.2005.1561884
   Wang T, 2023, IEEE T NEUR NET LEAR, V34, P1777, DOI 10.1109/TNNLS.2020.2997006
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu AC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4620, DOI 10.1145/3394171.3416282
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yoon Y.-C, 2019, ARXIV190700831
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zhou K., 2019, ARXIV191010093
NR 76
TC 18
Z9 19
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103279
DI 10.1016/j.jvcir.2021.103279
EA AUG 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, CX
   Liu, Y
   Sun, JL
   Guo, JC
   Lu, W
AF Jiang, Chunxu
   Liu, Yu
   Sun, Jinglin
   Guo, Jichang
   Lu, Wei
TI Illumination-based adaptive saliency detection network through fusion of
   multi-source features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-source; Illumination discrimination; Salient object detection;
   Deep learning
AB Salient object detection (SOD) tasks aim to outline the most concerned part of human vision, which is widely used in computer vision fields. Due to possibility of the insufficient illumination in the application environment (such as night or dim indoor environment), RGB images from visible channels usually lose most of their performance, while thermal images can improve the detection performance. Therefore, it is in urgent need of a robust saliency detection method, which can handle complex illumination conditions and take use of features from multiple sources intelligently. Accordingly, we propose our 'illumination based multi-source fused salient object detection network' (IAN-MF-SOD network). Taking the illumination condition as a quantitative reference, we guide features from two sources to fuse adaptively and intelligently, so that our method can enhance both of their advantages. For different illumination conditions, we distribute different fusion weights for each RGB-thermal image pair. Well fused images are generated as inputs to a trained SOD network to obtain saliency maps. Due to the analysis of our proposed IAN-score, our method performs favorably against traditional RGB-based SOD networks.
C1 [Jiang, Chunxu; Guo, Jichang; Lu, Wei] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Liu, Yu; Sun, Jinglin] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Lu, W (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM jiangchunxu@tju.edu.cn; liuyu@tju.edu.cn; luwei@tju.edu.cn
RI Guo, Jichang/GQY-5798-2022
OI Guo, Jichang/0000-0003-3130-1685; Liu, Yu/0000-0002-5949-6587; jiang,
   chun xu/0000-0002-4791-2213
FU Tianjin Key Research Program, China [18ZXRHSY00190]; Yunnan Key Research
   Project [2018IB007]; National Natural Science Foundation of China
   [61771338]
FX This work is supported by the Tianjin Key Research Program, China
   (18ZXRHSY00190), Yunnan Key Research Project (2018IB007) and the
   National Natural Science Foundation of China (61771338).
CR Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo D, 2017, J IMAGING SCI TECHN, V61, DOI 10.2352/J.ImagingSci.Technol.2017.61.6.060403
   Hold-Geoffroy Y, 2017, PROC CVPR IEEE, P2373, DOI 10.1109/CVPR.2017.255
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li C, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P359
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Pang Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102676
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Tu ZZ, 2020, IEEE T MULTIMEDIA, V22, P160, DOI 10.1109/TMM.2019.2924578
   Wang G, 2017, J VIS COMMUN IMAGE R, V48, P432, DOI 10.1016/j.jvcir.2017.02.004
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xiao J, 2012, CVPR PROV RI, DOI DOI 10.1109/CVPR.2012.6247991
   Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451
   Zhang LJ, 2017, LECT NOTES COMPUT SC, V10636, P583, DOI 10.1007/978-3-319-70090-8_59
   Zhang Q, 2019, J VIS COMMUN IMAGE R, V59, P415, DOI 10.1016/j.jvcir.2019.01.034
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 28
TC 4
Z9 4
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103192
DI 10.1016/j.jvcir.2021.103192
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100003
DA 2024-07-18
ER

PT J
AU Subramaniam, RR
   Vasudevan, V
AF Subramaniam, R. Raja
   Vasudevan, V.
TI A deep genetic algorithm for human activity recognition leveraging fog
   computing frameworks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep genetic algorithm; Human activity recognition; Fog computing;
   Ambulatory healthcare
ID FEATURES
AB With modern e-healthcare developments, ambulatory healthcare has become a prominent requirement for physical or mental ailed, elderly, childhood people. One of the major challenges in such applications is timing and precision. A potential solution to this problem is the fog-assisted cloud computing architecture. The activity recognition task is performed with the hybrid advantages of deep learning and genetic algorithms. The video frames captured from vision cameras are subjected to the genetic change detection algorithm, which detects changes in activities of subsequent frames. Consequently, the deep learning algorithm recognizes the activity of the changed frame. This hybrid algorithm is run on top of fog-assisted cloud framework, fogbus and the performance measures including latency, execution time, arbitration time and jitter are observed. Empirical evaluations of the proposed model against three activity data sets shows that the proposed deep genetic algorithm exhibits higher accuracy in inferring human activities as compared to the state-of-the-art algorithms.
C1 [Subramaniam, R. Raja; Vasudevan, V.] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Virudunagar 626126, India.
   [Vasudevan, V.] Kalasalingam Acad Res & Educ, Virudunagar, India.
C3 Kalasalingam Academy of Research & Education; Kalasalingam Academy of
   Research & Education
RP Subramaniam, RR (corresponding author), Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Virudunagar 626126, India.
EM rajasubramanian.r@klu.ac.in
RI Subramanian, R. Raja/ABC-4439-2021
OI Subramanian, R. Raja/0000-0002-9065-5056
CR AlDahoul N, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/1639561
   [Anonymous], AAAI
   [Anonymous], 2010, UCF-ARG dataset
   [Anonymous], 2012, INT J INFORM TECHNOL
   [Anonymous], 2017, FOG ASSISTED WIOT SM
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chen N, 2016, 2016 FIRST IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC 2016), P95, DOI 10.1109/SEC.2016.25
   Dijk, 2014, ELECTROOPTICAL INFRA, VXI, P924
   Diro AA, 2018, FUTURE GENER COMP SY, V82, P761, DOI 10.1016/j.future.2017.08.043
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hammami M., 2019, PATTERN RECOGN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang Z., 2016, DEEP LEARNING LIE GR
   Islam N, 2019, FUTURE GENER COMP SY, V100, P569, DOI 10.1016/j.future.2019.05.059
   Jain M., 2016, FRONT ICT
   Jen-Pin Hsiao, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P4364
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon E, 2018, I C INF COMM TECH CO, P1500, DOI 10.1109/ICTC.2018.8539531
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Li LZ, 2018, IEEE T IND INFORM, V14, P4665, DOI 10.1109/TII.2018.2842821
   Li Y, 2016, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2016.215
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Mikolajczyk K, 2011, COMPUT VIS IMAGE UND, V115, P426, DOI 10.1016/j.cviu.2010.11.002
   Minaeian S, 2018, IEEE T INTELL TRANSP, V19, P497, DOI 10.1109/TITS.2017.2782790
   Mu CH, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105727
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Redmon J., 2018, COMPUTER VISION PATT
   Roshtkhari MJ, 2013, IMAGE VISION COMPUT, V31, P864, DOI 10.1016/j.imavis.2013.08.005
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Shen H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P542, DOI 10.1109/ICICISYS.2009.5357609
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Simonyan K, 2014, ADV NEUR IN, V27
   Stojanovic DH, 2019, 2019 14TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES, SYSTEMS AND SERVICES IN TELECOMMUNICATIONS (TELSIKS 2019), P66, DOI [10.1109/TELSIKS46999.2019.9002302, 10.1109/telsiks46999.2019.9002302]
   Teerapittayanon S, 2017, INT CON DISTR COMP S, P328, DOI 10.1109/ICDCS.2017.226
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Thi TH, 2012, COMPUT VIS IMAGE UND, V116, P378, DOI 10.1016/j.cviu.2011.09.007
   Tuli S, 2019, J SYST SOFTWARE, V154, P22, DOI 10.1016/j.jss.2019.04.050
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   YAN C, 2015, P IEEE 81 VEH TECHN, P1, DOI DOI 10.1109/VTC-SPRING.2015.7146043
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51
NR 67
TC 16
Z9 16
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103132
DI 10.1016/j.jvcir.2021.103132
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200004
DA 2024-07-18
ER

PT J
AU Wang, XJ
   Chai, XL
   Shao, F
AF Wang, Xuejin
   Chai, Xiongli
   Shao, Feng
TI Quality assessment for color correction-based stitched images via
   bi-directional matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Stitched image; Bi-directional matching; Color
   correction; Color aberration
AB With the deepening of social information, the panoramic image has drawn a significant interest of viewers and researchers as it can provide a very wide field of view (FoV). Since panoramic images are usually obtained by capturing images with the overlapping regions and then stitching them together, image stitching plays an important role in generating panoramic images. In order to effectively evaluate the quality of stitched images, a novel quality assessment method based on bi-directional matching is proposed for stitched images. Specifically, dense correspondences between the testing and benchmark stitched images are first established by bi-directional SIFT-flow matching. Then, color-aware, geometric-aware and structure-aware features are respectively extracted and fused via support vector regression (SVR) to obtain the final quality score. Experiments on our newly constructed database and ISIQA database demonstrate that the proposed method can achieve comparable performance compared with the conventional blind quality metrics and the quality metrics specially designed for stitched images.
C1 [Wang, Xuejin; Chai, Xiongli; Shao, Feng] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
EM shaofeng@nbu.edu.cn
FU Natural Science Foundation of China [R18F010008]; K. C. Wong Magna Fund
   in Ningbo University
FX This work was supported by the Natural Science Foundation of China
   (grant 62071261) , and Natural Science Foundation of China (grant
   R18F010008) . It was also sponsored by K. C. Wong Magna Fund in Ningbo
   University.
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bellavia F, 2018, IEEE T IMAGE PROCESS, V27, P735, DOI 10.1109/TIP.2017.2757262
   Chang CH, 2014, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2014.422
   Dudek R, 2019, SIGNAL PROCESS-IMAGE, V74, P231, DOI 10.1016/j.image.2019.02.013
   Fecker U, 2008, IEEE T CIRC SYST VID, V18, P1258, DOI 10.1109/TCSVT.2008.926997
   [富振奇 Fu Zhenqi], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P490
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He L, 2015, SIGNAL IMAGE VIDEO P, V9, P1965, DOI 10.1007/s11760-014-0691-y
   Hou JW, 2020, IEEE IMAGE PROC, P3463, DOI 10.1109/ICIP40778.2020.9191241
   Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732
   Li J, 2020, IEEE J-STSP, V14, P209, DOI 10.1109/JSTSP.2019.2953950
   Li J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2360, DOI 10.1145/3343031.3350973
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Lu Q., 2019, ACM INT C P SERIES, P200
   Madhusudana PC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2921858
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Qureshi HS, 2012, IET IMAGE PROCESS, V6, P1348, DOI 10.1049/iet-ipr.2011.0641
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu C., 2004, J COMPUTER APPL, V24, P135
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
   Yan WQ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107541
   Yang LY, 2017, IEEE INT CONF COMP V, P2487, DOI 10.1109/ICCVW.2017.293
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Ying-jing, 2012, Acta Photonica Sinica, V41, P602, DOI 10.3788/gzxb20124105.0602
   Zhou M, 2018, IEEE T BIO-MED ENG, V65, P521, DOI 10.1109/TBME.2017.2700627
NR 33
TC 9
Z9 9
U1 3
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103051
DI 10.1016/j.jvcir.2021.103051
EA FEB 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600002
DA 2024-07-18
ER

PT J
AU Shao, H
   Yu, M
   Jiang, GY
   Pan, ZY
   Peng, ZJ
   Chen, F
AF Shao, Hua
   Yu, Mei
   Jiang, Gangyi
   Pan, Zhiyong
   Peng, Zongju
   Chen, Fen
TI Strong ghost removal in multi-exposure image fusion using hole-filling
   with exposure congruency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-exposure image fusion; Weak ghost; Strong ghost; Ghost removal;
   Exposure congruency; Hole-filling
ID QUALITY ASSESSMENT; DENSE SIFT; TONE
AB It is the most crucial problem to remove ghost in the multi-exposure image fusion of dynamic scene. The traditional fusion methods have good effects to remove weak ghosts. However, they cannot effectively remove strong ghosts. This paper proposes a new strong ghost removal method in multi-exposure image fusion using hole-filling with exposure congruency. First, analyzing the characteristics of strong ghosts, a detection scheme for strong ghost regions is designed by combining histogram matching and exposure difference detection. Subsequently, to effectively extract image local features, a multi-scale fusion network for non-strong ghost regions is designed to obtain a pre-fused image. Further, based on the distribution characteristics of strong ghosts, a hole filling model with exposure congruency is designed to remove the strong ghosts. Experimental results show that compared with the state-of-the-art methods, the proposed method can obtain better performance in both of subjective and objective evaluation, particularly in terms of effectively removing strong ghosts.
C1 [Shao, Hua; Yu, Mei; Jiang, Gangyi; Pan, Zhiyong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Shao, Hua] Ningbo City Coll Vocat Technol, Ningbo 315100, Peoples R China.
   [Peng, Zongju; Chen, Fen] Chongqing Univ Technol, Sch Elect & Elect Engn, Chongqing 400054, Peoples R China.
C3 Ningbo University; Ningbo City College of Vocational Technology;
   Chongqing University of Technology
RP Yu, M; Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM shaohua_nb@126.com; yumei2@126.com; jianggangyi@126.com;
   zhiyong_pan@126.com; pengzongju@163.com; chenfen@cqut.edu.cn
RI Chen, Fen/ABG-7013-2021; jiang, gang/KII-8233-2024
FU Natural Science Foundation of China [61671258, 61871247, 62071266,
   61931022, 61671412, 61620106012]; Natural Science Foudation of Zhejiang
   Province [LY21F010003]; Natural Science Foundation of Ningbo
   [202003N4088]; K.C. Wong Magna Fund of Ningbo University
FX This work was supported by the Natural Science Foundation of China
   (Grant nos. 61671258, 61871247, 62071266, 61931022, 61671412 and
   61620106012) , Natural Science Foudation of Zhejiang Province (Grant no.
   LY21F010003) , Natural Science Foundation of Ningbo (Grant no.
   202003N4088) . It was also sponsored by the K.C. Wong Magna Fund of
   Ningbo University.
CR Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Fang YM, 2020, IEEE T IMAGE PROCESS, V29, P1127, DOI 10.1109/TIP.2019.2940678
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119
   Ha HG, 2016, J IMAGING SCI TECHN, V60, DOI 10.2352/J.ImagingSci.Technol.2016.60.4.040501
   Hayat N, 2019, J VIS COMMUN IMAGE R, V62, P295, DOI 10.1016/j.jvcir.2019.06.002
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Khan EA, 2006, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2006.312892
   Kou F, 2018, J VIS COMMUN IMAGE R, V53, P235, DOI 10.1016/j.jvcir.2018.03.020
   Lahiri Avisek, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13693, DOI 10.1109/CVPR42600.2020.01371
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P5805, DOI 10.1109/TIP.2020.2987133
   Li H, 2018, COMPUT VIS IMAGE UND, V168, P37, DOI 10.1016/j.cviu.2017.11.001
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Liang ZT, 2018, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2018.00500
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Luo K, 2009, J ZHEJIANG UNIV-SC A, V10, P1738, DOI 10.1631/jzus.A0820806
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Martorell O, 2019, SIGNAL PROCESS-IMAGE, V78, P409, DOI 10.1016/j.image.2019.07.020
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Nafchi HZ, 2015, IEEE SIGNAL PROC LET, V22, P1026, DOI 10.1109/LSP.2014.2381458
   Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Pece F., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P1, DOI 10.1109/CVMP.2010.8
   Prabhakar K. R., 2019, 2019 IEEE INT C COMP, P1
   Prabhakar KR, 2016, INT CONF ACOUST SPEE, P1766, DOI 10.1109/ICASSP.2016.7471980
   Qin XM, 2015, IEEE T CYBERNETICS, V45, P1549, DOI 10.1109/TCYB.2014.2355140
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosh KSG, 2019, IEEE IMAGE PROC, P4714, DOI [10.1109/ICIP.2019.8803582, 10.1109/icip.2019.8803582]
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Shibata T, 2016, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2016.300
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1007/978-3-030-01216-8_1, 10.1109/APCAP.2017.8420330]
   Tan M., 2019, ARXIV190709595
   Tursun OT, 2016, COMPUT GRAPH FORUM, V35, P139, DOI 10.1111/cgf.12818
   Vonikakis V., 2011, P IASTED SIPA, P135
   Wang CM, 2018, MULTIMED TOOLS APPL, V77, P31911, DOI 10.1007/s11042-018-6261-5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yi Z., 2020, CVPR, P7508
   Zhang W, 2017, INFORM SCIENCES, V415, P19, DOI 10.1016/j.ins.2017.05.019
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
NR 51
TC 2
Z9 2
U1 0
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103017
DI 10.1016/j.jvcir.2020.103017
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT0EK
UT WOS:000626265400001
DA 2024-07-18
ER

PT J
AU Tinnathi, S
   Sudhavani, G
AF Tinnathi, Sreenivasu
   Sudhavani, G.
TI An efficient copy move forgery detection using adaptive watershed
   segmentation with AGSO and hybrid feature extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move forgery detection; Segments; Adaptive Galactic Swarm
   Optimization; RANSAC; Adaptive thresholding
ID DIGITAL IMAGES; WAVELET
AB Copy-move forgery detection (CMFD) is the process of determining the presence of copied areas in an image. CMFD approaches are mainly classified into two groups: keypoint-based and block-based techniques. In this paper, a new CMFD approach is proposed on the basis of both block and keypoint based approaches. Initially, the forged image is partitioned into non overlapped segments utilizing adaptive watershed segmentation, wherein adaptive H-minima transform is used for extracting the markers. Also, an Adaptive Galactic Swarm Optimization (AGSO) algorithm is used to select optimal gap parameter while selecting the markers for reducing the undesired regional minima, which can increase the segmentation performance. After that, the features from every segment are extracted as segment features (SF) using Hybrid Wavelet Hadamard Transform (HWHT). Then, feature matching is performed using adaptive thresholding. The false matches or outliers can be removed with the help of Random Sample Consensus (RANSAC) algorithm. Finally, the Forgery Region Extraction Algorithm (FREA) is utilized for detecting the copied portion from the host image. Experimental results indicate that the proposed scheme find out image forgery region with Precision = 92.45%; Recall = 93.67% and F1 = 92.75% on MICC-F600 dataset and Precision = 94.52%; Recall = 95.32% and F1 = 93.56% on Bench mark dataset at pixel level. Also, it outperforms the existing approaches when the image undergone certain geometrical transformation and image degradation.
C1 [Tinnathi, Sreenivasu] Acharya Nagarjuna Univ, Dept ECE, Guntur, Andhra Pradesh, India.
   [Sudhavani, G.] RVR & JC Coll Engn, Dept ECE, Guntur, Andhra Pradesh, India.
C3 Acharya Nagarjuna University; RVR & JC College of Engineering
RP Tinnathi, S (corresponding author), Acharya Nagarjuna Univ, Dept ECE, Guntur, Andhra Pradesh, India.
RI SUDHAVANI, GHANTA/ABI-4458-2020; Tinnathi, Sreenivasu/ITT-0257-2023
OI Tinnathi, Sreenivasu/0009-0003-9284-8761; Ghanta,
   Sudhavani/0000-0002-9260-6098
CR Agarwal S, 2018, ADV INTELL SYST, V518, P117, DOI 10.1007/978-981-10-3373-5_10
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bagchi Chhandak, 2019, Information Systems Design and Intelligent Applications. Proceedings of Fifth International Conference INDIA 2018. Advances in Intelligent Systems and Computing (AISC 862), P123, DOI 10.1007/978-981-13-3329-3_12
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bernal Emer, 2018, METAHEURISTICS, P1
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Cheng JR, 2009, IEEE T BIO-MED ENG, V56, P741, DOI 10.1109/TBME.2008.2008635
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   Dixit R, 2019, MULTIMED TOOLS APPL, V78, P13819, DOI 10.1007/s11042-018-6666-1
   Farid A. P., 2004, TECHNICAL REPORT
   Fridrich A., 2003, P DIG FOR FOR WORKSH
   Huang Z, 2016, BIOMED SIGNAL PROCES, V25, P53, DOI 10.1016/j.bspc.2015.11.002
   Jafari-Khouzani K, 2005, IEEE T IMAGE PROCESS, V14, P783, DOI 10.1109/TIP.2005.847302
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Kumar A, 2019, ADV INTELL SYST, V670, P17, DOI 10.1007/978-981-10-8971-8_2
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li JW, 2017, MULTIMED TOOLS APPL, V76, P20483, DOI 10.1007/s11042-016-3967-0
   Lin CG, 2019, MYCOKEYS, P1, DOI 10.3897/mycokeys.51.32272
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Mokhtari Ardakan Mostafa, 2019, Fundamental Research in Electrical Engineering. The Selected Papers of The First International Conference on Fundamental Research in Electrical Engineering. Lecture Notes in Electrical Engineering (LNEE 480), P115, DOI 10.1007/978-981-10-8672-4_9
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Parveen A., 2019, INT J, P1
   Pesteie M, 2015, INT J COMPUT ASS RAD, V10, P901, DOI 10.1007/s11548-015-1202-5
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Shan WY, 2019, IEEE ACCESS, V7, P17174, DOI 10.1109/ACCESS.2019.2894981
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Thirunavukkarasu V, 2018, WIRELESS PERS COMMUN, V98, P3039, DOI 10.1007/s11277-016-3941-1
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
NR 42
TC 24
Z9 24
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102966
DI 10.1016/j.jvcir.2020.102966
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OJ
UT WOS:000613150700004
DA 2024-07-18
ER

PT J
AU Wang, C
   Fan, WS
   Wu, YT
   Su, ZX
AF Wang, Cong
   Fan, Wanshu
   Wu, Yutong
   Su, Zhixun
TI Weakly supervised single image dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Weakly supervised; Convolutional neural network (CNN);
   Multi-level multi-scale block
ID NETWORK; COLOR
AB Single image dehazing is a critical image pre-processing step for many practical vision systems. Most existing dehazing methods solve this problem utilizing various of hand-crafted priors or by supervised training on the synthetic hazy image information (such as haze-free image, transmission map and atmospheric light). However, the assumptions on the hand-crafted priors are easily violated and collecting realistic transmission map and atmospheric light are unpractical. In this paper, we propose a novel weakly supervised network based on the multi-level multi-scale block. The proposed network reduces the constraint on the training data and automatically estimates the transmission map and the atmospheric light as well as the intermediate haze-free image without using any realistic transmission map and atmospheric light as supervision. Moreover, the estimated intermediate haze-free image helps to generate accurate transmission map and atmospheric light by embedding the physical-model, which presents reliable restoration of the final haze-free image. In particular, our network also can be trained on the real-world dataset to fine-tune the model and the fine-tuning operation improves the dehazing performance on the real-world dataset. Quantitative and qualitative experimental results demonstrate the proposed method performs on par with the supervised methods.
C1 [Wang, Cong; Fan, Wanshu; Wu, Yutong; Su, Zhixun] Dalian Univ Technol, Sch Math Sci, 2 Linggong Rd, Dalian 116000, Peoples R China.
   [Fan, Wanshu] Dalian Univ, Sch Software Engn, Econ & Technol Dev Area, 10 Univ Ave, Dalian 116622, Peoples R China.
C3 Dalian University of Technology; Dalian University
RP Fan, WS (corresponding author), Dalian Univ Technol, Sch Math Sci, 2 Linggong Rd, Dalian 116000, Peoples R China.; Fan, WS (corresponding author), Dalian Univ, Sch Software Engn, Econ & Technol Dev Area, 10 Univ Ave, Dalian 116622, Peoples R China.
EM fan921amber@163.com
RI Li, Chun/KBC-9591-2024
OI Fan, Wanshu/0000-0001-6299-2795
FU Natural Science Foundation of China [61976041]; National Science and
   Technology Major Project [2018ZX04041001]; National Key R&D Program of
   China [2018AAA0100300]
FX This work was supported by the Natural Science Foundation of China
   [grant numbers 61976041]; National Science and Technology Major Project
   [grant number 2018ZX04041001]; National Key R&D Program of China [grant
   number 2018AAA0100300].
CR Berman D, 2017, IEEE INT CONF COMPUT, P115
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen WT, 2019, PROC CVPR IEEE, P11673, DOI 10.1109/CVPR.2019.01195
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dudhane A, 2019, IEEE WINT CONF APPL, P1147, DOI 10.1109/WACV.2019.00127
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Huang LY, 2019, IEEE IMAGE PROC, P2741, DOI [10.1109/ICIP.2019.8803316, 10.1109/icip.2019.8803316]
   Kingma D. P., 2014, arXiv
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long QX, 2020, NAT MED, V26, P845, DOI 10.1038/s41591-020-0897-1
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Su CC, 2013, IEEE T IMAGE PROCESS, V22, P2259, DOI 10.1109/TIP.2013.2249075
   Sulami M, 2014, IEEE INT CONF COMPUT
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 38
TC 12
Z9 13
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102897
DI 10.1016/j.jvcir.2020.102897
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400013
DA 2024-07-18
ER

PT J
AU Zhou, JJ
   He, ZN
   Liu, XD
   Wang, YH
   Wang, SS
   Liu, QG
AF Zhou, Jinjie
   He, Zhuonan
   Liu, Xiaodong
   Wang, Yuhao
   Wang, Shanshan
   Liu, Qiegen
TI Transformed denoising autoencoder prior for image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Denoising autoencoder; Pixel domain; Wavelet domain
ID LOW-RANK; RECONSTRUCTION; ALGORITHM
AB Image restoration problem is generally ill-posed, which can be alleviated by learning image prior. Inspired by the considerable performance of utilizing priors in pixel domain and wavelet domain jointly, we propose a novel transformed denoising autoencoder as prior (TDAEP). The core idea behind TDAEP is to enhance the classical denoising autoencoder (DAE) via transform domain, which captures complementary information from multiple views. Specifically, 1-level nonorthogonal wavelet coefficients are used to form 4-channel feature images. Moreover, a 5-channel tensor is obtained by stacking the original image under the pixel domain and 4-channel feature images under the wavelet domain. Then we train the transformed DAE (TDAE) with the 5-channel tensor as the network input. The optimized image prior is obtained based on the trained autoencoder, and it is incorporated into an iterative restoration procedure with the aid of the auxiliary variable technique. The resulting model is affiliationed by proximal gradient descent technique. Numerous experiments demonstrated that the TDAEP outperforms a set of image restoration benchmark algorithms.
C1 [Zhou, Jinjie; He, Zhuonan; Wang, Yuhao; Liu, Qiegen] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Liu, Xiaodong] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
   [Wang, Shanshan] Chinese Acad Sci, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
C3 Nanchang University; Wuhan University; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS
RP Liu, QG (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM liuqiegen@ncu.edu.cn
RI Liu, Xiaodong/KIB-4660-2024; Li, Yuanyuan/J-3539-2014; Wang,
   Shanshan/T-6972-2017
OI Li, Yuanyuan/0000-0001-6151-9306; Wang, Shanshan/0000-0002-0575-6523;
   Liu, Xiaodong/0000-0003-4112-9604
FU National Natural Science Foundation of China [61871206, 61661031];
   Natural Science Foundation of Jiangxi Province [20181BAB202003,
   YC2019-5052, CX2019075]
FX This work was supported in part by the National Natural Science
   Foundation of China under 61871206, 61661031, the Natural Science
   Foundation of Jiangxi Province under 20181BAB202003 and project of
   innovative special funds for graduate students (YC2019-5052, CX2019075).
CR [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Bigdeli SA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P33, DOI 10.5220/0006532100330044
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chen HG, 2018, IEEE COMPUT SOC CONF, P824, DOI 10.1109/CVPRW.2018.00114
   Chen Y., 2017, Advances in neural information processing systems, P4467
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Du W., 2020, P IEEE INT C COMP VI, P14483
   Eksioglu EM, 2016, J MATH IMAGING VIS, V56, P430, DOI 10.1007/s10851-016-0647-7
   ENGL HW, 1989, INVERSE PROBL, V5, P523, DOI 10.1088/0266-5611/5/4/007
   Favaro P., 2017, INT C NEURAL INF PRO, P763
   Fujiwara H., 2006, SICE ICASE INT JOINT, P3293
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang XJ, 2018, PATTERN RECOGN, V81, P388, DOI 10.1016/j.patcog.2018.03.014
   Jiao JB, 2020, IEEE T IMAGE PROCESS, V29, P6302, DOI 10.1109/TIP.2020.2990603
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li SQ, 2020, IEEE T IMAGE PROCESS, V29, P142, DOI 10.1109/TIP.2019.2931240
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu QG, 2020, MAGN RESON MED, V83, P322, DOI 10.1002/mrm.27921
   Liu RS, 2019, IEEE T IMAGE PROCESS, V28, P1528, DOI 10.1109/TIP.2018.2875568
   Liu XM, 2016, IEEE T IMAGE PROCESS, V25, P1649, DOI 10.1109/TIP.2016.2526910
   Mastan ID, 2019, IEEE COMPUT SOC CONF, P1728, DOI 10.1109/CVPRW.2019.00223
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007
   Ren DW, 2021, IEEE T PATTERN ANAL, V43, P284, DOI 10.1109/TPAMI.2019.2926357
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vigneshwaran B, 2020, SOFT COMPUT, V24, P10645, DOI 10.1007/s00500-019-04570-7
   Vigneshwaran B, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P300
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang L, 2019, NEURAL NETWORKS, V117, P201, DOI 10.1016/j.neunet.2019.05.007
   Wei Y., 2020, ARXIV200108388
   Wei YY, 2019, IEEE DATA MINING, P628, DOI 10.1109/ICDM.2019.00073
   Wei Yanyan, 2019, ARXIV PREPRINT ARXIV
   Xiong BA, 2018, IEEE T MULTIMEDIA, V20, P2316, DOI 10.1109/TMM.2018.2806225
   Yang Y, 2016, ADV NEUR IN, V29
   Yao HT, 2019, NEUROCOMPUTING, V359, P483, DOI 10.1016/j.neucom.2019.05.006
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YX, 2018, PROC CVPR IEEE, P8447, DOI 10.1109/CVPR.2018.00881
   Zhang Z, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2762
   Zhang Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1569, DOI 10.1145/3343031.3351023
   Zhang ZH, 2019, PATTERN RECOGN LETT, V125, P157, DOI 10.1016/j.patrec.2019.04.021
   Zhou J, 2009, IEEE T NUCL SCI, V56, P116, DOI 10.1109/TNS.2008.2009445
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 54
TC 2
Z9 2
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102927
DI 10.1016/j.jvcir.2020.102927
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400023
DA 2024-07-18
ER

PT J
AU Wang, LL
   Rajan, D
AF Wang, Liangliang
   Rajan, Deepu
TI An image similarity descriptor for classification tasks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image similarity; Similarity representation; Deep features selection;
   Correlational descriptor
ID SPARSE REPRESENTATION; COMPRESSION
AB We develop an image similarity descriptor for an image pair, based on deep features. The development consists of two parts - selecting the deep layer whose features are to be included in the descriptor, and a representation of the similarity between the images in the pair. The selection of the deep layer follows a sparse representation of the feature maps followed by multi-output support vector regression. The similarity representation is based on a novel correlation between the histograms of the feature maps of the two images. Experiments to demonstrate the effectiveness of the proposed descriptor are carried out on four applications that can be cast as classification tasks. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wang, Liangliang; Rajan, Deepu] Nanyang Technol Univ, Sch Comp Sci & Engn, Media & Interact Comp Lab, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Rajan, D (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Media & Interact Comp Lab, Singapore 639798, Singapore.
EM asdrajan@ntu.edu.sg
RI Rajan, Deepu/A-3666-2011
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2011, P 33 ANN C COGN SCI
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Borchani H, 2015, WIRES DATA MIN KNOWL, V5, P216, DOI 10.1002/widm.1157
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eguchi S, 2006, J MULTIVARIATE ANAL, V97, P2034, DOI 10.1016/j.jmva.2006.03.007
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Girod B., 1991, P 7 WORKSH MULT SIGN, P2
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guha T, 2014, IEEE T MULTIMEDIA, V16, P980, DOI 10.1109/TMM.2014.2306175
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Koch G., 2015, ICML DEEP LEARNING W, V37
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632
   Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Pandit RK, 2019, INT J ENERGY ENVIR E, V10, P181, DOI 10.1007/s40095-018-0287-3
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren Y., 2014, COMPUTER SCI
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Russakoff DB, 2004, LECT NOTES COMPUT SC, V3023, P596
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Scott D., 1979, OPTIMAL DATA BASED H
   Sermanet P., 2014, INT C LEARN REPR
   Simonyan K., 2014, CORR
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vandewalle J, 2002, LEAST SQUARES SUPPOR, DOI DOI 10.1142/5089
   Wei Zhang, 2012, Proceedings of the 2012 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA), P130, DOI 10.1109/CIMSA.2012.6269600
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Yang L., 2006, Distance metric learning: A comprehensive survey
   Yang X, 2017, PATTERN RECOGN, V65, P108, DOI 10.1016/j.patcog.2016.12.006
   Zhang X, 2018, IEEE T IMAGE PROCESS, V27, P3753, DOI 10.1109/TIP.2018.2823546
   Zhang X, 2017, IEEE T IMAGE PROCESS, V26, P633, DOI 10.1109/TIP.2016.2629447
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zheng L., 2016, ARXIV160400133
NR 58
TC 8
Z9 8
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102847
DI 10.1016/j.jvcir.2020.102847
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400018
DA 2024-07-18
ER

PT J
AU Wu, ZB
   Zhao, CX
   Liu, B
AF Wu, Zhaobin
   Zhao, Chunxia
   Liu, Bin
TI Polygonal approximation based on coarse-grained parallel genetic
   algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Polygonal approximation; Coarse-grained parallel genetic algorithms;
   Ensemble learning
ID DOMINANT POINTS; SEQUENTIAL METHOD; OBJECT DETECTION; ANGLE DETECTION;
   NUMBER; MIN
AB This paper proposes to apply coarse-grained parallel genetic algorithm (CGPGA) to solve polygonal approximation problem. Chromosomes are used to represent digital curves and genes correspond to points of curves. This method divides the whole population into several subpopulations, each of which performs evolutionary process independently. After every migration interval number of generations, these subpopulations exchange their information with each other. Inspired by the designing theory of ensemble learning in machine learning, this paper further improves the basic CGPGA through adopting different but effective genetic algorithms, respectively, in different subpopulations. Both the diversity among different subpopulations and the accuracy in each individual subpopulation are ensured. Experimental results, based on four benchmark curves and four real image curves extracted from the lake maps, show that the basic CGPGA outperforms the used genetic algorithm, and further the improved CGPGA (ICGPGA) is more effective than the basic CGPGA, in terms of the quality of best solutions, the average solutions, and the variance of best solutions. Especially for those larger approximation problems, the ICGPGA is more remarkably superior to some representative genetic algorithms. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Wu, Zhaobin; Zhao, Chunxia] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Liu, Bin] Hebei Univ Sci & Technol, Sch Econ & Management, Shijiazhuang 050018, Hebei, Peoples R China.
   [Liu, Bin] Hebei Univ Sci & Technol, Res Ctr Big Data & Social Comp, Shijiazhuang 050018, Hebei, Peoples R China.
C3 Nanjing University of Science & Technology; Hebei University of Science
   & Technology; Hebei University of Science & Technology
RP Wu, ZB (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM 13701355621@163.com
FU Hebei Science and technology support program [17210104D]; Science and
   technology research project of Hebei higher education institutions
   [ZD2015099]; High-level Talents Subsidy Project in Hebei Province
   [A2016002015]
FX This work is supported by Hebei Science and technology support program
   (17210104D), Science and technology research project of Hebei higher
   education institutions (ZD2015099), and High-level Talents Subsidy
   Project in Hebei Province (A2016002015).
CR Alba E, 2000, APPL INTELL, V12, P163, DOI 10.1023/A:1008358805991
   ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C
   ARCELLI C, 1993, PATTERN RECOGN, V26, P1563, DOI 10.1016/0031-3203(93)90161-O
   Atiqullah M.M., 2002, P INT S PAR DISTR PR, P204
   Bellman R., 1961, COMMUN ACM, V4
   Cantu-Paz E., 2000, EFFICIENT ACCURATE P, P162
   Cornic P, 1997, PATTERN RECOGN LETT, V18, P13, DOI 10.1016/S0167-8655(96)00116-X
   Crainic T.G., 1997, PARALLEL METAHEURIST, P53
   Cung V., 2001, STRATEGIES PARALLEL, P33
   Dietterich TG, 1997, AI MAG, V18, P97
   Duda R., 1973, Pattern Classification and Scene Analysis
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Falahiazar L., 2012, Proceedings of the 2012 International Conference on Recent Advances in Computing and Software Systems (RACSS), P37, DOI 10.1109/RACSS.2012.6212694
   FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756
   FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825
   Georges-Schleuter M.:., 1990, Schwefel and Maenner, P150
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Grajdeanu A., 2003, PARALLEL MODELS EVOL, P38
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Ho SY, 2001, PATTERN RECOGN, V34, P2305, DOI 10.1016/S0031-3203(00)00159-X
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   Inesta JM, 1998, PATTERN RECOGN, V31, P685, DOI 10.1016/S0031-3203(97)00081-2
   Kolesnikov A, 2005, IEEE IMAGE PROC, P1553
   KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9
   LEU JG, 1988, PATTERN RECOGN LETT, V7, P231, DOI 10.1016/0167-8655(88)90107-9
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   Masood A, 2007, J VIS COMMUN IMAGE R, V18, P264, DOI 10.1016/j.jvcir.2006.12.002
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Nowostawski M., 1999, P 3 INT C KNOWL BAS
   PAVLIDIS T, 1977, IEEE T COMPUT, V26, P800, DOI 10.1109/TC.1977.1674918
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PHILLIPS TY, 1988, PATTERN RECOGN LETT, V7, P291, DOI 10.1016/0167-8655(88)90069-4
   PIKAZ A, 1995, PATTERN RECOGN LETT, V16, P557, DOI 10.1016/0167-8655(95)80001-A
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D
   RAY BK, 1995, PATTERN RECOGN LETT, V16, P161, DOI 10.1016/0167-8655(94)00081-D
   RAY BK, 1993, PATTERN RECOGN, V26, P505, DOI 10.1016/0031-3203(93)90106-7
   RAY BK, 1994, PATTERN RECOGN LETT, V15, P161, DOI 10.1016/0167-8655(94)90045-0
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   SARKAR B, 2004, INT J IMAGE GRAPHICS, V4, P223
   SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X
   Sun YN, 2000, INT J PATTERN RECOGN, V14, P297, DOI 10.1142/S0218001400000209
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Toro F.D., 2002, P 10 EUR MICR PAR DI
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   Wang B, 2009, J VIS COMMUN IMAGE R, V20, P45, DOI 10.1016/j.jvcir.2008.10.001
   WU JS, 1993, PATTERN RECOGN, V26, P471, DOI 10.1016/0031-3203(93)90103-4
   WU WY, 1993, CVGIP-GRAPH MODEL IM, V55, P79, DOI 10.1006/cgip.1993.1006
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Yin PY, 1998, PATTERN RECOGN LETT, V19, P1017, DOI 10.1016/S0167-8655(98)00082-8
   Yin PY, 2004, J VIS COMMUN IMAGE R, V15, P241, DOI 10.1016/j.jvcir.2003.12.001
   Yin PY, 2003, PATTERN RECOGN, V36, P1783, DOI 10.1016/S0031-3203(02)00321-7
   Yin PY, 1998, PATTERN RECOGN LETT, V19, P31, DOI 10.1016/S0167-8655(97)00154-2
NR 62
TC 5
Z9 5
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102717
DI 10.1016/j.jvcir.2019.102717
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900032
DA 2024-07-18
ER

PT J
AU Zhang, ZX
   Pan, XH
   Jiang, SH
   Zhao, PJ
AF Zhang, Zhixin
   Pan, Xuhua
   Jiang, Shuhao
   Zhao, Peijun
TI High-quality face image generation based on generative adversarial
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face image generation; GAN; High-quality images
ID OBJECT DETECTION; SCENE; VIDEO; TEXT
AB Conventional face image generation using generative adversarial networks (GAN) is limited by the quality of generated images since generator and discriminator use the same backpropagation network. In this paper, we discuss algorithms that can improve the quality of generated images, that is, high-quality face image generation. In order to achieve stability of network, we replace MLP with convolutional neural network (CNN) and remove pooling layers. We conduct comprehensive experiments on LFW, CelebA data sets and experimental results show the effectiveness of our proposed method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Zhang, Zhixin; Pan, Xuhua; Jiang, Shuhao] Tianjin Univ Commerce, Informat Engn Dept, Tianjin 300134, Peoples R China.
   [Zhao, Peijun] Tianjin Inst Phys Educ, Sch Phys Educ & Educ Sci, Tianjin, Peoples R China.
C3 Tianjin University of Commerce
RP Pan, XH (corresponding author), Tianjin Univ Commerce, Informat Engn Dept, Tianjin 300134, Peoples R China.
EM Xuhua_Pan@tom.com
FU Research on Tianjin Scientific Research of Teaching Commit-tee Plan
   Project [20130146]
FX This work was supported by Research on Tianjin Scientific Research of
   Teaching Commit-tee Plan Project (NO. 20130146).
CR [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Denton Emily, 2015, Advances in Neural Information Processing Systems
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Gauthier J., 2014, Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, P2
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mescheder L, 2017, PMLR, P2391
   Miyato T, 2018, INT C LEARN REPR
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Radford A., 2015, ARXIV
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Sriman B, 2019, J VIS COMMUN IMAGE R, V62, P23, DOI 10.1016/j.jvcir.2019.04.007
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
NR 32
TC 10
Z9 10
U1 4
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102719
DI 10.1016/j.jvcir.2019.102719
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900022
DA 2024-07-18
ER

PT J
AU Pang, Y
   Yu, XS
   Wang, Y
   Wu, CD
AF Pang, Yu
   Yu, Xiaosheng
   Wang, Ying
   Wu, Chengdong
TI Salient object detection based on novel graph model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Background prior; Novel graph model; Saliency
   propagation; Optimization method
ID RANKING
AB In this paper, we present a salient object detection method based on novel graph structure. Given image is segmented into small image regions as basic units, we firstly construct an effective background-based map, each image region's saliency value is determined by its feature contrast with the image boundary. Then, saliency propagation mechanism is used to update all regions' saliency values by introducing a novel graph structure to better exploit the relationship between adjacent image regions. Finally, we propose an optimization method to further highlight salient objects and suppress background noises. Experimental results demonstrate adequately the superiority of proposed approach. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Pang, Yu; Yu, Xiaosheng; Wu, Chengdong] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Liaoning, Peoples R China.
   [Wang, Ying] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Yu, XS; Wu, CD (corresponding author), Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Liaoning, Peoples R China.
EM wuchengdongneu@163.com
RI Wu, Chengdong/IST-5302-2023
FU National Natural Science Foundation of China [61701101, 61973093,
   U1713216, 61901098, 61971118]; National Key Robot Project
   [2017YFB1301103]; Fundamental Research Fund for the Central Universities
   of China [N172603001, N181602014, N172604004, N172604003, N172604002]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant nos. 61701101, 61973093, U1713216,
   61901098, 61971118, the National Key Robot Project under Grant nos.
   2017YFB1301103, and the Fundamental Research Fund for the Central
   Universities of China N172603001, N181602014, N172604004, N172604003,
   and N172604002.
CR Achanta R., 2010, TECHNICAL REPORT, P2
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Chen SH, 2016, PATTERN RECOGN, V60, P2, DOI 10.1016/j.patcog.2016.05.016
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Hwang I, 2017, MULTIMED TOOLS APPL, V76, P2111, DOI 10.1007/s11042-015-3171-7
   Kong YQ, 2016, LECT NOTES COMPUT SC, V9910, P583, DOI 10.1007/978-3-319-46466-4_35
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Meng FM, 2013, IEEE T CYBERNETICS, V43, P725, DOI 10.1109/TSMCB.2012.2215316
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qin Y, 2018, INT J COMPUT VISION, V126, P751, DOI 10.1007/s11263-017-1062-2
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zeng Y, 2018, IEEE T IMAGE PROCESS, V27, P4545, DOI 10.1109/TIP.2018.2838761
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang M, 2018, J VIS COMMUN IMAGE R, V52, P131, DOI 10.1016/j.jvcir.2018.01.004
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 34
TC 11
Z9 11
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102676
DI 10.1016/j.jvcir.2019.102676
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700019
DA 2024-07-18
ER

PT J
AU Di Mauro, D
   Furnari, A
   Patanè, G
   Battiato, S
   Farinella, GM
AF Di Mauro, D.
   Furnari, A.
   Patane, G.
   Battiato, S.
   Farinella, G. M.
TI Estimating the occupancy status of parking areas by counting cars and
   non-empty stalls
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene understanding; Deep learning; Smart cities; Counting; Vehicle
   detection; Semantic segmentation
ID RANGE
AB This work presents and compares different vision-based approaches to estimate the occupancy status of parking areas by counting cars and non-empty parking stalls. Our investigation considers both the scenario in which parking stalls are marked on the ground and the more challenging one in which no assumption on the presence or position of stalls is assumed. We carry out an experimental analysis on a real-world dataset of videos collected in different parking areas. Specifically, this work compares solutions based on image classification, vehicle detection and semantic segmentation. Our analysis highlights that: (1) methods based on image classification can be effectively leveraged when the position of parking stalls is known in advance, (2) methods based on image segmentation should be preferred over methods based on object detection when the geometry of the scene is not known, (3) temporal smoothing can be effectively used to improve predictions over time. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Di Mauro, D.; Furnari, A.; Battiato, S.; Farinella, G. M.] Univ Catania, Dept Math & Comp Sci, Catania, Italy.
   [Di Mauro, D.; Patane, G.] Pk Smart Srl, Catania, Italy.
C3 University of Catania
RP Farinella, GM (corresponding author), Univ Catania, Dept Math & Comp Sci, Catania, Italy.
EM dimauro@dmi.unict.it; furnari@dmi.unict.it;
   giuseppe.patane@parksmart.it; battiato@dmi.unict.it;
   gfarinella@dmi.unict.it
RI Battiato, Sebastiano/ABI-1584-2020; Battiato, Sebastiano/O-7799-2019;
   FARINELLA, Giovanni Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432; Patane, Giuseppe/0000-0001-5845-9680; Di
   Mauro, Daniele/0000-0002-4286-2050
CR Amato G, 2017, EXPERT SYST APPL, V72, P327, DOI 10.1016/j.eswa.2016.10.055
   Amato G, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P1212, DOI 10.1109/ISCC.2016.7543901
   [Anonymous], 2018, CVPR
   [Anonymous], INT WORKSH TRAFF STR
   [Anonymous], EUR C COMP VIS
   [Anonymous], ABS50602640 CORR
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2004, P IEEE INT C AC SPEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2008, WORLD URB PROSP 2007
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Battiato S, 2015, EXPERT SYST APPL, V42, P7263, DOI 10.1016/j.eswa.2015.05.055
   Chan A. B., 2008, C COMPUTER VISION PA, P1
   Chen S, 2015, PROC CVPR IEEE, P1364, DOI 10.1109/CVPR.2015.7298742
   de Almeida PRL, 2015, EXPERT SYST APPL, V42, P4937, DOI 10.1016/j.eswa.2015.02.009
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Di Mauro D, 2016, LECT NOTES COMPUT SC, V10016, P410, DOI 10.1007/978-3-319-48680-2_36
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ferrari A, 2017, PATTERN RECOGN, V61, P629, DOI 10.1016/j.patcog.2016.07.016
   Fiaschi L, 2012, INT C PATT RECOG, P2685
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li M., 2008, 2008 19 INT C PATTER, P1, DOI DOI 10.1109/ICPR.2008.4761705
   Lin NL, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CIRCUITS AND SYSTEMS (ICCAS), P137, DOI 10.1109/ICCircuitsAndSystems.2012.6408305
   Mármol E, 2016, MULTIMED TOOLS APPL, V75, P17711, DOI 10.1007/s11042-016-3773-8
   Raymond J.-F., 2001, Designing Privacy Enhancing Technologies. International Workshop on Design Issues in Anonymity and Unobservability. Proceedings (Lecture Notes in Computer Science Vol.2009), P10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Valipour S, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P655, DOI 10.1109/WF-IoT.2016.7845408
   Wu Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P659
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang W, 2018, NEUROCOMPUTING, V275, P781, DOI 10.1016/j.neucom.2017.09.012
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 39
TC 7
Z9 7
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 234
EP 244
DI 10.1016/j.jvcir.2019.05.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600022
DA 2024-07-18
ER

PT J
AU Wang, XH
   Peng, MZ
   Pan, LJ
   Hu, M
   Jin, CH
   Ren, FJ
AF Wang Xiaohua
   Peng Muzi
   Pan Lijuan
   Hu Min
   Jin Chunhua
   Ren Fuji
TI Two-level attention with two-stage multi-task learning for facial
   emotion recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial emotion recognition; Attention mechanism; Multi-task learning;
   Valence-arousal dimension
ID EXPRESSION RECOGNITION; FACE
AB Compared with facial emotion estimation on categorical model, dimensional emotion estimation can describe numerous emotions more accurately. Most prior works of dimensional emotion estimation only considered laboratory data and used video, speech or other multi-modal features. Compared with other modal data, static images has superiorities of accessibility, which is more conducive to the emotion estimation in real world. In this paper, a two-level attention with two-stage multi-task learning (2Att-2Mt) framework is proposed for facial emotion estimation on only static images. Firstly, the features of corresponding region (position level features) are extracted and enhanced automatically by first-level attention mechanism. Then, we utilize Bi-directional Recurrent Neural Network (Bi-RNN) with self-attention (second-level attention) to make full use of the relationship features of different layers (layer-level features) adaptively. And then, we propose a two-stage multi-task learning structure, which exploits categorical representations to ameliorate the dimensional representations and estimate valence and arousal simultaneously in view of the inherent complexity of dimensional representations and correlation of the two targets. The quantitative results conducted on AffectNet dataset show significant advancement on Concordance Correlation Coefficient(CCC) and Root Mean Square Error (RMSE), illustrating the superiority of the proposed framework. Besides, extensive comparative experiments have also fully demonstrated the effectiveness of different components (2Att and 2Mt) in our framework. (C) 2019 Published by Elsevier Inc.
C1 [Wang Xiaohua; Peng Muzi; Pan Lijuan; Hu Min; Ren Fuji] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Anhui, Peoples R China.
   [Wang Xiaohua; Jin Chunhua] Huaiyin Inst Technol, Lab Internet Things & Mobile Internet Technol Jia, Huaian, Peoples R China.
   [Ren Fuji] Univ Tokushima, Fac Engn, Tokushima, Japan.
C3 Hefei University of Technology; Huaiyin Institute of Technology;
   Tokushima University
RP Hu, M (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Anhui, Peoples R China.
EM jsjxhumin@hfut.edu.cn
FU National Natural Science Foundation of China [61672202, 61432004];
   NSFCShenzhen Joint Foundation (Key Project) [U1613217]; Open Foundation
   of the Laboratory for Internet of Things and Mobile Internet Technology
   of Jiangsu Province, Huaiyin Institute of Technology [JSWLW-2017-017]
FX This research has been partially supported by National Natural Science
   Foundation of China under Grant No. 61672202, No. 61432004 and
   NSFCShenzhen Joint Foundation (Key Project) (Grant No. U1613217), and
   Open Foundation of the Laboratory for Internet of Things and Mobile
   Internet Technology of Jiangsu Province, Huaiyin Institute of Technology
   (JSWLW-2017-017).
CR [Anonymous], 1897, EXPRESS EMOT MAN
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2018, ARXIV180206664
   [Anonymous], 2017, ARXIV170803985
   [Anonymous], ARXIV180501024
   [Anonymous], ARXIV180402810
   [Anonymous], 2018, CORR ABS180501452
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2018, ARXIV181104544
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Brady K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P97, DOI 10.1145/2988257.2988264
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Chang J, 2017, INT CONF ACOUST SPEE, P2746, DOI 10.1109/ICASSP.2017.7952656
   Chen S., 2017, P 7 ANN WORKSH AUD V, P19
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo Y, 2016, INT J AEROSPACE ENG, V2016, DOI 10.1155/2016/2942686
   Hu J., 2017, CoRR
   Huang B, 2019, IEEE ACCESS, V7, P45146, DOI 10.1109/ACCESS.2019.2908877
   Jang YJ, 2016, 2016 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P47, DOI 10.1109/APCCAS.2016.7803892
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kervadec C., 2018, ARXIV180711215
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liu WF, 2012, INT C PATT RECOG, P1839
   Liu XF, 2017, IEEE COMPUT SOC CONF, P522, DOI 10.1109/CVPRW.2017.79
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Mehrabian A., 2008, Communication theory, V6, P193, DOI [10.4324/9781315080918, DOI 10.4324/9781315080918]
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Mnih V., 2014, Neural Information Processing Systems, P2204
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xia R, 2017, IEEE T AFFECT COMPUT, V8, P3, DOI 10.1109/TAFFC.2015.2512598
   Yan HB, 2018, PATTERN RECOGN, V75, P33, DOI 10.1016/j.patcog.2017.02.031
   Yao AB, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P472, DOI 10.1145/2993148.2997639
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 50
TC 42
Z9 43
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 217
EP 225
DI 10.1016/j.jvcir.2019.05.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA IL0CB
UT WOS:000476962600020
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ye, YS
   Zhang, XM
   Lin, YB
   Wang, HX
AF Ye, Yingsheng
   Zhang, Xingming
   Lin, Yubei
   Wang, Haoxiang
TI Facial expression recognition via region-based convolutional fusion
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Emotion recognition; Convolution neural
   network
ID SYSTEM; FACE
AB One of the key challenge issues of deep-learning-based facial expression recognition (FER) is learning effective and robust features from variant samples. In this paper, Region-based Convolutional Fusion Network (RCFN) is proposed to solve this issue via three aspects. Firstly, a muscle movement model is built to segment out crucial regions of frontal face, providing well-unified patches with benefits of removing unrepresentative regions and greatly reducing interference caused by facial organs with varied sizes and positions among individuals. Secondly, a fast and practical network is constructed to extract robust triple-level features from low level to semantic level in each crucial region and fuse them for FER. Thirdly, constrained punitive loss is introduced to leverage the network training for boosting up FER performance. The experiment results show that RCFN is effective in commonly used datasets like KDEF, CK+, and Oulu-CASIA, and can achieve comparable performance with other state-of-the-art FER methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ye, Yingsheng; Zhang, Xingming; Wang, Haoxiang] South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp Sci & Engn, B3 Bldg, Guangzhou 510006, Guangdong, Peoples R China.
   [Lin, Yubei] South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Software Engn, B7 Bldg, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Lin, YB (corresponding author), South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Software Engn, B7 Bldg, Guangzhou 510006, Guangdong, Peoples R China.
EM yecfly@outlook.com; cszxm@scut.edu.cn; yupilin@scut.edu.cn;
   hxwang@scut.edu.cn
OI Lin, Yubei/0000-0002-1438-3044
CR Alphonse AS, 2017, J VIS COMMUN IMAGE R, V49, P459, DOI 10.1016/j.jvcir.2017.10.008
   Amminger GP, 2012, SCHIZOPHRENIA BULL, V38, P1030, DOI 10.1093/schbul/sbr015
   [Anonymous], 1998, STOCKH DEP NEUROSCI, DOI DOI 10.1017/S0048577299971664
   [Anonymous], 2015, P IEEE INT C AUT FAC, DOI DOI 10.1109/FG.2015.7163082
   [Anonymous], ABS150607310 CORR
   [Anonymous], 2015, ABS150301532 CORR
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P IEEE WINT C APPL C
   Cao NT., 2016, INT J COMPUT VIS ROB, V6, P223, DOI DOI 10.1504/IJCVR.2016.077353
   Chen WC, 2017, IEEE/SICE I S SYS IN, P435, DOI 10.1109/SII.2017.8279251
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Ekman P., 1978, Facial action coding system
   Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006
   Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DB, 2015, ACS SYM SER, V1214, P1
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Moeini A, 2017, J VIS COMMUN IMAGE R, V45, P20, DOI 10.1016/j.jvcir.2017.02.007
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Rodriguez-Giustiniani P, 2019, INT J SPORT NUTR EXE, V29, P397, DOI 10.1123/ijsnem.2018-0214
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Sikka K, 2016, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2016.602
   Simonyan K., 2015, P ICLR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Sun YX, 2017, NEUROCOMPUTING, V230, P397, DOI 10.1016/j.neucom.2016.12.043
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Wang QT, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P314, DOI 10.1109/IIH-MSP.2015.54
   Xie ZZ, 2018, CHIN CONTR CONF, P9540, DOI 10.23919/ChiCC.2018.8483159
   Xu Linlin, 2017, Journal of Computer Applications, V37, P3509, DOI 10.11772/j.issn.1001-9081.2017.12.3509
   Yan HB, 2018, PATTERN RECOGN, V75, P33, DOI 10.1016/j.patcog.2017.02.031
   Yuan S, 2018, NEUROCOMPUTING, V275, P711, DOI 10.1016/j.neucom.2017.08.067
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
NR 52
TC 29
Z9 29
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 1
EP 11
DI 10.1016/j.jvcir.2019.04.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600001
DA 2024-07-18
ER

PT J
AU Ai, ZX
AF Ai Zexiu
TI Quantitative CT study of martial arts sports injuries based on image
   quality
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality; Wushu; Joint damage; Quantitative CT
ID OBJECT DETECTION; COMPUTATION; PROFILE; DEEP
AB Wushu is an outstanding cultural heritage of the Chinese nation and one of the most extensive mass sports in China. As a traditional sports event in China, martial arts are undergoing rapid changes. However, martial arts are a systemic sport with high requirements for speed, explosiveness and coordination. In recent years, with the rapid development of martial arts, competitive competitions have become increasingly fierce. It is easy for athletes to suffer physical damage during the practice of difficult movements. This not only affects the normal exercise and physical health of martial arts enthusiasts, but also affects the improvement of sports level and teaching quality. Therefore, it studies the common parts of martial arts sports injuries. Distribution, looking for its causes, proposing preventive measures, rapid development of image processing technology, digital image has become an indispensable part of multimedia information technology. Digital image is an important carrier for people to obtain information and communicate. Under this background, the research of image quality evaluation has become a hot spot in the field of image processing. The purpose of this paper is to analyze the anatomical characteristics of knee joints of martial arts athletes, the mechanics of injury, the pathophysiological changes after injury, and establish a mathematical model by computer algorithm to accurately perceive the image quality of martial arts sports damage, and finally achieve the use of computer instead of human vision. The system goes to view and recognize images. In this paper, the application value of quantitative CT parameters of martial arts exercise in the evaluation of martial arts injury joints is based on image quality, in order to provide valuable reference for the treatment of martial arts injury selection and prognosis evaluation. (C) 2019 Published by Elsevier Inc.
C1 [Ai Zexiu] Chengdu Sports Univ, Martial Arts Coll, Chengdu, Sichuan, Peoples R China.
C3 Chengdu Sport University
RP Ai, ZX (corresponding author), Chengdu Sports Univ, Martial Arts Coll, Chengdu, Sichuan, Peoples R China.
EM guozhenhua@jsu.edu.cn
FU Key Project of Philosophy and Social Science Foundation of Hunan
   Province [17ZDB024]
FX This work was supported by Key Project of Philosophy and Social Science
   Foundation of Hunan Province (No. 17ZDB024).
CR [Anonymous], 2018, J DIABETES RES, DOI DOI 10.1016/j.patrec.2018.02.001
   Bai ZB, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/129640
   Boguszewski D., 2015, POLISH J SPORT TOURI, V22
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cui YJ, 2013, APPL MATH-CZECH, V58, P689, DOI 10.1007/s10492-013-0035-1
   Drury BT, 2017, HAND CLIN, V33, P97, DOI 10.1016/j.hcl.2016.08.004
   Fu HL, 2018, COMPLEXITY, DOI 10.1155/2018/1876861
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Holman BF, 2015, PHYS MED BIOL, V60, P7387, DOI 10.1088/0031-9155/60/18/7387
   Jang S. W., 2017, P SOC PHOTO-OPT INS, V5, P110
   Jee YS, 2018, J EXERC REHABIL, V14, P64, DOI 10.12965/jer.1835208.604
   Jensen AR, 2017, SPORTS HEALTH, V9, P64, DOI 10.1177/1941738116664860
   Kurz C, 2015, MED PHYS, V42, P3979, DOI 10.1118/1.4921995
   Leng S., 2015, P SPIE INT SOC OPT E, V9412, P193
   Li C, 2015, MED PHYS, V42, P4553, DOI 10.1118/1.4923753
   Li G, 2013, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2013-265
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Liu YX, 2014, IEEE T BIO-MED ENG, V61, P2057, DOI 10.1109/TBME.2014.2313564
   Lystad RP, 2014, CLIN J SPORT MED, V24, P519, DOI 10.1097/JSM.0000000000000120
   Lystad RP, 2014, ORTHOP J SPORTS MED, V2, DOI 10.1177/2325967113518492
   Ma L, 2017, J BIOMED INFORM, V66, P148, DOI 10.1016/j.jbi.2017.01.002
   McClain R, 2014, CLIN J SPORT MED, V24, P497, DOI 10.1097/JSM.0000000000000078
   Neville C., 2017, BRIT J SPORT MED, V51
   Noferini L, 2016, PHYS MEDICA, V32, P1717, DOI 10.1016/j.ejmp.2016.11.002
   Sharma P, 2015, ABDOM IMAGING, V40, P299, DOI 10.1007/s00261-014-0219-5
   Sidky E. Y., 2017, IEEE J TRANSLATIONAL, V2, P1
   Sidky EY, 2014, IEEE J TRANSL ENG HE, V2, DOI 10.1109/JTEHM.2014.2300862
   Smilg JS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145340
   Sun Y L., 2014, COMPUTER KNOWLEDGE T, V43, P183
   Sun YG, 2017, COMPLEXITY, DOI 10.1155/2017/5876371
   Swierczynski P., 2017, COMPUTERIZED MED IMA, V65, P58
   Thomas R. E., 2018, PHYSICIAN SPORTSMED, V2018
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Xin BG, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/876298
   Yan H, 2014, MED PHYS, V41, DOI 10.1118/1.4881326
   Yang L, 2019, NEURAL COMPUT APPL, V31, P4463, DOI 10.1007/s00521-018-3525-y
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang YL, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/621264
   Zhu JG, 2019, ADV DIFFER EQU-NY, DOI 10.1186/s13662-018-1908-0
   Zou YM, 2013, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2013-233
NR 49
TC 6
Z9 6
U1 8
U2 58
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 417
EP 425
DI 10.1016/j.jvcir.2019.03.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000045
DA 2024-07-18
ER

PT J
AU Dong, QC
   Feng, JQ
AF Dong, Qicong
   Feng, Jieqing
TI Outlier detection and disparity refinement in stereo matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Outlier detection; Stereo matching; Match fixed point jumps;
   Normal-based plane fitting
ID OCCLUSION; VISION; COST
AB Disparity estimation in ill-posed regions, such as occlusions, repetitive patterns and textureless regions, is a challenging problem in stereo matching. The initial disparities obtained in these regions tend to be regarded as outliers that must be detected and addressed. In this paper, two outlier detection methods are proposed, i.e., the efficient approach and the accurate approach. The efficient approach detects outliers by exploring the disparity map for the left image only and reduces runtime and memory costs. First, the match fixed point jumps (MFPJ) algorithm is proposed as an initial solution to detect outliers. Then, a high-probability outlier detection algorithm is proposed to accomplish denser outlier detection with less noise. The accurate approach first classifies outliers as occlusions or mismatches. Then, 3D label assignment is performed for occlusion outliers and normal-based plane fitting is conducted for mismatch outliers to refine the disparities of the outliers and to achieve an accurate stereo matching result. Evaluations of the Middlebury datasets demonstrate that the proposed methods effectively improve the stereo matching performance. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Dong, Qicong; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jqfeng@cad.zju.edu.cn
FU National Natural Science Foundation of China [61732015, 61472349]; Key
   Research and Development Program of Zhejiang Province [2018C01090]
FX The authors would like to thank Qing Ran for her instructive commentary
   regarding of this paper. This work was supported by the National Natural
   Science Foundation of China under Grants No. 61732015 and No. 61472349,
   and Key Research and Development Program of Zhejiang Province under
   Grants No. 2018C01090.
CR ANDERSON BL, 1994, PSYCHOL REV, V101, P414, DOI 10.1037/0033-295X.101.3.414
   Bae K. R., 2016, MULTIMED TOOLS APPL, V76, P1
   Baker H. H., 1982, TECH REP
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Chang C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P722, DOI 10.1109/CVPR.1991.139799
   Drouyer S, 2017, LECT NOTES COMPUT SC, V10225, P172, DOI 10.1007/978-3-319-57240-6_14
   Egnal G, 2004, IMAGE VISION COMPUT, V22, P943, DOI 10.1016/j.imavis.2004.03.018
   Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808
   Hadfield S, 2017, COMPUT VIS IMAGE UND, V157, P206, DOI 10.1016/j.cviu.2016.08.001
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Intille S. S., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P179, DOI 10.1007/BFb0028349
   Jiao JB, 2014, IEEE MULTIMEDIA, V21, P16, DOI 10.1109/MMUL.2014.51
   Juyang Weng, 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P64, DOI 10.1109/CCV.1988.589972
   Kim KR, 2016, IEEE IMAGE PROC, P3429, DOI 10.1109/ICIP.2016.7532996
   Kong D., 2004, BRIT MACHINE VISION, V1, P2
   Li A, 2016, PROC CVPR IEEE, P4022, DOI 10.1109/CVPR.2016.436
   Li LC, 2018, IEEE T CIRC SYST VID, V28, P679, DOI 10.1109/TCSVT.2016.2628782
   Li LC, 2017, APPL OPTICS, V56, P3411, DOI 10.1364/AO.56.003411
   LITTLE JJ, 1990, IMAGE VISION COMPUT, V8, P328, DOI 10.1016/0262-8856(90)80009-I
   Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242
   MATTHIES L, 1992, INT J COMPUT VISION, V8, P71, DOI 10.1007/BF00126401
   Mattoccia S, 2007, LECT NOTES COMPUT SC, V4844, P517
   Mei X, 2011, PROC CVPR IEEE, P1257
   Merrell P, 2007, IEEE I CONF COMP VIS, P3012, DOI 10.1109/iccv.2007.4408984
   Mozerov M., 2009, IEEE INT C IM PROC, P2065
   Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355
   Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sinha SN, 2014, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2014.205
   Spoerri A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P209
   Taniai T, 2018, IEEE T PATTERN ANAL, V40, P2725, DOI 10.1109/TPAMI.2017.2766072
   Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Yoon KJ, 2008, COMPUT VIS IMAGE UND, V112, P173, DOI 10.1016/j.cviu.2008.02.003
   Yuille A. L., 1984, TECH REP
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhan YL, 2016, IEEE T CIRC SYST VID, V26, P1632, DOI 10.1109/TCSVT.2015.2473375
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
NR 44
TC 6
Z9 6
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 380
EP 390
DI 10.1016/j.jvcir.2019.03.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000041
DA 2024-07-18
ER

PT J
AU Liu, X
   Zhou, YJ
   Wang, ZR
AF Liu, Xin
   Zhou, Yanju
   Wang, Zongrun
TI Recognition and extraction of named entities in online medical diagnosis
   data based on a deep neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Continuous bags of word clusters; Deep neural network; Online medical
   diagnosis data; Named entities
ID CLINICAL INFORMATION; OBJECT DETECTION; IMAGE; REPRESENTATIONS; MODELS
AB How to correctly recognize and extract named entities, such as disease names, medical measurements and therapies, from online medical diagnosis data remains challenging. For the one hand, conventional natural language processing methods cannot be directly applied in the field of online medical diagnosis (OMD). Although existing supervised or unsupervised learning algorithms have offered strategies for OMD on open websites, such methods might extensively rely on specific knowledge sources or manually designed features. For the other hand, due to the large size of the data and the sophistication of the data structure, it is difficult to establish a robust NLP model for recognition and extraction of clinical named entities in paragraphs. Therefore, in the paper, we try to establish a new deep neural network (DNN), combine the bi-directional long short-term memory (Bi-LSTM) and the conditional random field (CRF), and utilize online medical diagnosis data for recognition and extraction of clinical named entities. Different from existing artificial neural networks (ANN), the proposed neural network well functions even without manual rules or features. The word representations input into the DNN is connected by character-based representations and continuous bags of word clusters (CBOWC) in an embedding way. We test the new DNN on different online medical diagnosis datasets obtained from a scalable web crawler, and compare it with the long short-term memory (LSTM) neural network linguistic model, the convolutional neural network (CNN) model and the most advanced Bi-LSTM-CRF. The fundamentals for the method selection is that they have been suggested to generate acceptable results. According to the comparison analyses, the DNN is proved to be a reliable tool and improves every benchmark performance of OMD. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Xin; Zhou, Yanju; Wang, Zongrun] Cent South Univ, Sch Business, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Zhou, YJ (corresponding author), Cent South Univ, Sch Business, Changsha 410083, Hunan, Peoples R China.
EM zyj4258@sina.com
RI liu, xinyi/GWZ-8739-2022
FU National Natural Science Foundation of China [71471178, 71871232,
   71371194, 71171201]; State Key Program of National Natural Science
   Foundation of China [71431006, 71631008]; Major Project for National
   Natural Science Foundation of China [71790615]; Projects of
   International Cooperation and Exchanges NSFC [71210003]; Fundamental
   Research Funds for the Central Universities [2011RWSK003]; Program for
   New Century Excellent Talents in University [NCET-13-0604]
FX The research described in this paper was substantially supported by
   Grants from the National Natural Science Foundation of China (nos.
   71471178, 71871232, 71371194, and 71171201) and the State Key Program of
   National Natural Science Foundation of China (nos. 71431006, 71631008)
   and Major Project for National Natural Science Foundation of China
   (71790615) and Projects of International Cooperation and Exchanges NSFC
   (no. 71210003) and the Fundamental Research Funds for the Central
   Universities (No. 2011RWSK003) and the Program for New Century Excellent
   Talents in University (No. NCET-13-0604).
CR [Anonymous], IEEE INT C SYST
   [Anonymous], COMPUT ENG APPL
   [Anonymous], 2017, IEEE INT C E HLTH NE
   [Anonymous], J SOFTW
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bruintjes TM, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086720
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Das S, 2018, PATTERN RECOGN, V81, P674, DOI 10.1016/j.patcog.2018.03.008
   De Boom C, 2016, PATTERN RECOGN LETT, V80, P150, DOI 10.1016/j.patrec.2016.06.012
   de Bruijn B, 2011, J AM MED INFORM ASSN, V18, P557, DOI 10.1136/amiajnl-2011-000150
   Dehghan A, 2015, J BIOMED INFORM, V58, pS53, DOI 10.1016/j.jbi.2015.06.029
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Du M, 2016, IEEE T PATTERN ANAL, V38, P1762, DOI 10.1109/TPAMI.2015.2497689
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Goyal A, 2018, COMPUT SCI REV, V29, P21, DOI 10.1016/j.cosrev.2018.06.001
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Dam HK, 2021, IEEE T SOFTWARE ENG, V47, P67, DOI 10.1109/TSE.2018.2881961
   Ireland R, 2018, CIRP J MANUF SCI TEC, V23, P128, DOI 10.1016/j.cirpj.2018.06.003
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jonnalagadda S, 2012, J BIOMED INFORM, V45, P129, DOI 10.1016/j.jbi.2011.10.007
   Kim HK, 2017, NEUROCOMPUTING, V266, P336, DOI 10.1016/j.neucom.2017.05.046
   Kim Y, 2016, AAAI CONF ARTIF INTE, P2741
   Kreimeyer K, 2017, J BIOMED INFORM, V73, P14, DOI 10.1016/j.jbi.2017.07.012
   Leaman R, 2016, BIOINFORMATICS, V32, P2839, DOI 10.1093/bioinformatics/btw343
   Luo L, 2018, BIOINFORMATICS, V34, P1381, DOI 10.1093/bioinformatics/btx761
   Marujo L, 2016, KNOWL-BASED SYST, V94, P33, DOI 10.1016/j.knosys.2015.11.005
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Sahu SK, 2018, J BIOMED INFORM, V86, P15, DOI 10.1016/j.jbi.2018.08.005
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Stamova IM, 2014, EUR J CONTROL, V20, P199, DOI 10.1016/j.ejcon.2014.05.001
   Su Ya, 2016, Acta Scientiarum Naturalium Universitatis Pekinensis, V52, P1, DOI 10.13209/j.0479-8023.2016.020
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   Wu J, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06799-6
   [杨锦锋 Yang Jinfeng], 2014, [自动化学报, Acta Automatica Sinica], V40, P1537
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang Q, 2011, COMPUT BIOL MED, V41, P190, DOI 10.1016/j.compbiomed.2011.02.005
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 53
TC 17
Z9 20
U1 1
U2 52
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 1
EP 15
DI 10.1016/j.jvcir.2019.02.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HS7ZO
UT WOS:000464088000001
DA 2024-07-18
ER

PT J
AU Xue, F
   Sun, J
   Liu, XL
   Liu, TP
   Lu, Q
AF Xue, Feng
   Sun, Jian
   Liu, Xueliang
   Liu, Tianpeng
   Lu, Qiang
TI Social multi-modal event analysis via knowledge-based weighted topic
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Social media; Multi-modal; Topic mining; Knowledge-based
AB Along with the development of mobile Internet and social network, people's lifestyles are also changing, and many social websites (e.g. Facebook, YouTube, and WeChat) have sprung up, which leads to the emergence of a large number of multimedia data (e.g. text, image, and video) of various events. The goal of this paper is to mine event topics efficiently from massive and unordered social media data, which is beneficial to search, browse and monitor significant social events for users or governments. In order to achieve this goal, this paper proposes a novel Knowledge-Based Multi-Modal Weighted Topic Model (KBMMWTM) for social event analysis. The proposed KBMMWTM has following advantages: (1) The proposed KBMMWTM can effectively take advantage of the multi-modality of social events jointly. (2) The proposed KBMMWTM exploits word correlation in dataset as prior knowledge to improve the performance of event topic mining. We evaluate our KBMMWTM model on a real dataset and full experiments show that our model outperforms state-of-the-art models. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xue, Feng; Sun, Jian; Liu, Xueliang; Liu, Tianpeng; Lu, Qiang] Hefei Univ Technol, Lab Multimedia & Recommendat Syst, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Xue, F (corresponding author), Hefei Univ Technol, Lab Multimedia & Recommendat Syst, Hefei, Anhui, Peoples R China.
EM feng.xue@hfut.edu.cn
RI Lu, Qiang/AAU-9248-2020
OI Xue, Feng/0000-0003-4962-9734
FU National Key Research and Development Program of China [2017YFB0803301];
   National Natural Science Foundation of China [61772170, 61472115];
   Fundamental Research Funds for the Central Universities [JZ2017YYPY0234]
FX This work is supported by the National Key Research and Development
   Program of China (No. 2017YFB0803301), the National Natural Science
   Foundation of China (No. 61772170, 61472115) and the Fundamental
   Research Funds for the Central Universities (No. JZ2017YYPY0234).
CR Allan J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P37, DOI 10.1145/290941.290954
   Andrzejewski D., 2011, Proceedings of the 22nd international joint conference on artificial intelligence
   Andrzejewski D., 2009, P NAACL HLT 2009 WOR, P43, DOI DOI 10.3115/1621829.1621835
   Andrzejewski David, 2009, Proc Int Conf Mach Learn, V382, P25
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   [Anonymous], 2011, Advances in neural information processing systems
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Bao Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P239, DOI 10.1145/2505515.2505556
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Chang  J., 2009, ADV NEURAL INFORM PR, P288, DOI DOI 10.5555/2984093.2984126
   Chen ZY, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P209, DOI 10.1145/2505515.2505519
   Das R, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P795
   Diakopoulos N., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922
   Doshi-Velez F, 2015, AAAI CONF ARTIF INTE, P2575
   Heinrich G, 2009, LECT NOTES ARTIF INT, V5781, P517, DOI 10.1007/978-3-642-04180-8_51
   Hoffman M., 2010, ADV NEURAL INFORM PR, V23, P856
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Hu Yuheng., 2012, AAAI, V12, P59
   Ifrim G., 2014, 2 WORKSH SOC NEWS WE
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Kim T. Y., 2010, SCIS ISIS, V2010, P189
   Krestel R., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P61, DOI [DOI 10.1145/1639714.1639726, 10.1145/1639714.1639726]
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Nguyen D. Q., 2015, Transactions of the Association for Computational Linguistics, V3, P299, DOI DOI 10.1162/TACL_A_00140
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nugroho R., 2015, INT C PAC ASS COMP L, V593, P177, DOI [10.1007/978-981-10-0515-2_13, DOI 10.1007/978-981-10-0515-2_13]
   Patel D., 2008, P 2008 ACM SIGMOD IN, P393, DOI DOI 10.1145/1376616.1376658
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Yang Y., 2002, P 8 ACM SIGKDD INT C, P688, DOI DOI 10.1145/775047.775150
   Yao L, 2015, LECT NOTES ARTIF INT, V9078, P586, DOI 10.1007/978-3-319-18032-8_46
   Zhang TZ, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2602633
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
   Zhuang Y., 2012, P 20 ACM INT C MULT, P957
NR 41
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 1
EP 8
DI 10.1016/j.jvcir.2018.12.033
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600001
DA 2024-07-18
ER

PT J
AU Wu, KW
   Gao, Y
   Ma, HL
   Sun, YX
   Yao, TT
   Xie, Z
AF Wu, Kewei
   Gao, Yang
   Ma, Hailong
   Sun, Yongxuan
   Yao, Tingting
   Xie, Zhao
TI A deep generative directed network for scene depth ordering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep generative directed-network; Depth ordering; Hidden Markov field;
   DenseNet
ID LOW-RANK; FRAMEWORK
AB In this paper, we present a Deep Generative Directed-Network (DGDN), which estimates the occlusion relationship of boundaries. Specially, we use a low-level segmentater to partition the image into regions, then estimate their occlusion relationship by two perceptual depth cues. We decompose our DGDN model into three sub-modules to extract regional appearance cue, edgel orientation cue and to further infer global occlusion relationship with these cues, respectively. Firstly, we predict regional scene depth by a upsampling deep dense network (DenseNet). Secondly, we simultaneously estimate edgel occlusion with logistic regression. However, the occlusion relationship always suffers from unexpected conflicts due to noisy regional and edgel cues. Therefore, we finally infer occlusion relationship in a Hidden Markov Field (HMF), which tackles conflicts with bi-direction inference and the HMF parameters are exploited by iterative EM-like procedure. Ablation experiments on NYUv2 and Make3D database prove that our DGDN model outperforms state-of-the-art methods. (C) 2018 Published by Elsevier Inc.
C1 [Wu, Kewei; Gao, Yang; Ma, Hailong; Sun, Yongxuan; Xie, Zhao] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Wu, Kewei] Hefei Univ Technol, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
   [Yao, Tingting] Dalian Maritime Univ, Coll Informat Sci & Technol, Collaborat Innovat Res Inst Autonomous Ship, Dalian 116026, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology; Dalian
   Maritime University
RP Wu, KW (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.; Wu, KW (corresponding author), Hefei Univ Technol, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
EM wu_kewei1984@163.com
RI Gao, Yang/HJY-8120-2023
FU National Key Research and Development Program of China [2017YFB1002203];
   National Nature Science Foundation of China [61273237, 61503111,
   61501467]; Anhui Natural Science Foundation [1808085MF168]; Anhui
   Province Key Laboratory of Industry Safety and Emergency Technology
FX This research was supported by National Key Research and Development
   Program of China (2017YFB1002203), National Nature Science Foundation of
   China (61273237, 61503111, 61501467), Anhui Natural Science Foundation
   (1808085MF168), and Anhui Province Key Laboratory of Industry Safety and
   Emergency Technology.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amer M.R., 2010, IEEE International Conference on Image Processing (ICIP), P3437
   Amer MR, 2015, INT J COMPUT VISION, V112, P23, DOI 10.1007/s11263-014-0752-2
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], ARXIV170708063
   [Anonymous], 2017, P INT C COMP VIS
   [Anonymous], EUR C COMP VIS
   Calderero F, 2013, INT J COMPUT VISION, V104, P38, DOI 10.1007/s11263-013-0613-4
   Cao YZH, 2017, IEEE T IMAGE PROCESS, V26, P836, DOI 10.1109/TIP.2016.2621673
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen W, 2016, ADV NEUR IN, V29
   Cheng YH, 2015, COMPUT VIS IMAGE UND, V139, P149, DOI 10.1016/j.cviu.2015.05.007
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fowlkes CC, 2007, J VISION, V7, DOI 10.1167/7.8.2
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4
   Jia ZY, 2012, PROC CVPR IEEE, P294, DOI 10.1109/CVPR.2012.6247688
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Leichter I, 2009, IEEE I CONF COMP VIS, P9, DOI 10.1109/ICCV.2009.5459208
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Ming AL, 2016, IEEE INTELL SYST, V31, P54, DOI 10.1109/MIS.2015.94
   Ming AL, 2015, IEEE IMAGE PROC, P2525, DOI 10.1109/ICIP.2015.7351257
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Palou G, 2013, IEEE T IMAGE PROCESS, V22, P1926, DOI 10.1109/TIP.2013.2240002
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Yu CC, 2014, GRAPH MODELS, V76, P507, DOI 10.1016/j.gmod.2014.03.015
   Zhang ZY, 2015, IEEE I CONF COMP VIS, P2614, DOI 10.1109/ICCV.2015.300
   Zheng KC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1381, DOI 10.1145/3240508.3240628
NR 34
TC 0
Z9 0
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 554
EP 564
DI 10.1016/j.jvcir.2018.12.034
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100054
DA 2024-07-18
ER

PT J
AU Huang, Y
   Yan, Y
   Chen, S
   Wang, HZ
AF Huang, Ying
   Yan, Yan
   Chen, Si
   Wang, Hanzi
TI Expression-targeted feature learning for effective facial expression
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Multi-task learning; Feature learning;
   Convolutional neural network
ID MACHINE; FACE
AB In this paper, we propose a novel expression-targeted feature learning (ETFL) method for effective facial expression recognition, which takes advantage of multi-task learning for discriminative feature learning. Specifically, the common features are firstly extracted from the lower layers of CNN. Then, based on the common features, the expression-specific features (ESF) are respectively learned for each facial expression via multi-task learning. In order to enhance the discriminability of ESF, we develop a joint loss (the combination of the center loss and a novel inter-class loss) to explicitly reduce intra-class variations while enlarging inter-class differences. Furthermore, we introduce the sample-sensitive weights and the soft-expression weights to balance the joint loss for better performance. Finally, all ESFs are combined for final classification. ETFL effectively exploits the relationship among all facial expressions, which leads to superiority feature discriminability. Experiments on public facial expression databases demonstrate the effectiveness of ETFL compared with several state-of-the-art methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Huang, Ying; Yan, Yan; Wang, Hanzi] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Fujian, Peoples R China.
   [Chen, Si] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen, Fujian, Peoples R China.
C3 Xiamen University; Xiamen University of Technology
RP Yan, Y (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Fujian, Peoples R China.
EM yanyan@xmu.edu.cn
RI Wang, Han/GPW-9809-2022; wang, handong/HLH-5739-2023; wang,
   hao/HSE-7975-2023
FU National Key R&D Program of China [2017YFB1302400]; National Natural
   Science Foundation of China [61571379, 61503315, U1605252, 61472334];
   Natural Science Foundation of Fujian Province of China [2017J01127,
   2018J01576]; Fundamental Research Funds for the Central Universities
   [20720170045]; State Key Laboratory of Advanced Optical Communication
   Systems Networks, China
FX This work was supported by the National Key R&D Program of China under
   Grant 2017YFB1302400, by the National Natural Science Foundation of
   China under Grants 61571379, 61503315, U1605252, and 61472334, by the
   Natural Science Foundation of Fujian Province of China under Grant
   2017J01127 and 2018J01576, by the Fundamental Research Funds for the
   Central Universities under Grant 20720170045, and by State Key
   Laboratory of Advanced Optical Communication Systems Networks, China.
CR [Anonymous], IEEE WINT C APPL COM
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], PROC CVPR IEEE
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Devries T, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P98, DOI 10.1109/CRV.2014.21
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Ekman P., 2002, FACIAL ACTION CODING
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Hu YF, 2009, ACTA OTO-LARYNGOL, V129, P161, DOI 10.1080/00016480802126553
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kim BK, 2016, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2016.187
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Liang XZ, 2017, LECT NOTES COMPUT SC, V10635, P413, DOI 10.1007/978-3-319-70096-0_43
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu P, 2014, LECT NOTES COMPUT SC, V8692, P151, DOI 10.1007/978-3-319-10593-2_11
   Lorincz A, 2013, IEEE COMPUT SOC CONF, P889, DOI 10.1109/CVPRW.2013.131
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Moeini A, 2016, J VIS COMMUN IMAGE R, V35, P1, DOI 10.1016/j.jvcir.2015.11.006
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Ptucha R., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2136, DOI 10.1109/ICCVW.2011.6130512
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Su CP, 2017, IEEE IMAGE PROC, P3800, DOI 10.1109/ICIP.2017.8296993
   Tian YL, 2000, PROC CVPR IEEE, P294, DOI 10.1109/CVPR.2000.855832
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Walecki Robert, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163137
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   WEN YD, 2016, PROC CVPR IEEE, P4893, DOI DOI 10.1109/CVPR.2016.529
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan Y, 2016, PATTERN RECOGN, V56, P40, DOI 10.1016/j.patcog.2016.02.010
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zhang ZZ, 2013, IEEE IMAGE PROC, P1192, DOI 10.1109/ICIP.2013.6738246
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
   Zhuang N, 2018, PATTERN RECOGN, V80, P225, DOI 10.1016/j.patcog.2018.03.018
NR 60
TC 8
Z9 9
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 677
EP 687
DI 10.1016/j.jvcir.2018.08.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100058
DA 2024-07-18
ER

PT J
AU Ribal, C
   Lermé, N
   Le Hégarat-Mascle, S
AF Ribal, Christophe
   Lerme, Nicolas
   Le Hegarat-Mascle, Sylvie
TI Efficient graph cut optimization for shape from focus
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape from focus; Depth map estimation; Graph cuts; Multi-labels
ID ENERGY MINIMIZATION; FLOW ALGORITHMS; IMAGE
AB Shape From Focus refers to the inverse problem of recovering the depth in every point of a scene from a set of differently focused 2D images. Recently, some authors stated it in the variational framework and solved it by minimizing a non-convex functional. However, the global optimality on the solution is not guaranteed and evaluations are often application-specific. To overcome these limits, we propose to globally and efficiently minimize a convex functional by decomposing it into a sequence of binary problems using graph cuts. To illustrate the genericity of such a decomposition-based approach, data-driven strategies are considered, allowing us to optimize (in terms of reconstruction error) the choice of the depth values for a given number of possible depths. We provide qualitative and quantitative evaluation on Middlebury datasets and we show that, according to classic statistics on error values, the proposed approach exhibits high performance and robustness against corrupted data.
C1 [Ribal, Christophe; Lerme, Nicolas; Le Hegarat-Mascle, Sylvie] Univ Paris Sud, Lab SATIE, UMR CNRS 8029, Rue Noetzlin, F-91190 Gif Sur Yvette, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite; Universite Paris Saclay
RP Ribal, C (corresponding author), Univ Paris Sud, Lab SATIE, UMR CNRS 8029, Rue Noetzlin, F-91190 Gif Sur Yvette, France.
EM christophe.ribal@u-psud.fr
RI Lermé, Nicolas/AAB-9793-2022; sylvie, le hégarat-mascle/AAB-9960-2022;
   Ribal, Christophe/AAC-1128-2022
OI sylvie, le hégarat-mascle/0000-0001-8494-2289; 
CR [Anonymous], 2007, PROC IEEE C COMPUT V
   [Anonymous], 2009, 19 INT C COMPUTER GR
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0
   Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003
   Goldfarb D, 2009, SIAM J SCI COMPUT, V31, P3712, DOI 10.1137/070706318
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Hazirbas C., ARXIV170401085
   Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kumar C. V. S., 2014, P ICVGIP, P1, DOI DOI 10.1145/2683483.2683563
   Kumar GP, 2017, IEEE INT CONF COMP V, P563, DOI 10.1109/ICCVW.2017.73
   Mahmood M.T., 2013, 11 IEEE IVMSP WORKSH, P1
   Malik AS, 2009, IEEE T SYST MAN CY C, V39, P246, DOI 10.1109/TSMCC.2008.2001714
   Moeller M, 2015, IEEE T IMAGE PROCESS, V24, P5369, DOI 10.1109/TIP.2015.2479469
   Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   Surya G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P61, DOI 10.1109/CVPR.1993.340978
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
NR 26
TC 8
Z9 12
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 529
EP 539
DI 10.1016/j.jvcir.2018.06.029
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100046
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, XY
   Jin, Z
   Zhou, JB
   Ma, XD
AF Wu, Xiyin
   Jin, Zhong
   Zhou, Jingbo
   Ma, Xiaodi
TI Saliency propagation with perceptual cues and background-excluded seeds
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Perceptual cue; Graph-based framework; Label
   propagation; Seed; Background probability
ID REGION DETECTION; OBJECT DETECTION; VISUAL SALIENCY; RANKING
AB Graph-based methods have shown their potentialities for saliency detection. In this paper, a graph-based framework is proposed for saliency detection, which incorporates perceptual cues into the framework and uses the background-excluded seeds to propagate saliency. Firstly, a graph is constructed by two perceptual cues, including proximity and similarity. Secondly, probable background nodes are generated by a novel background probability measure and used to pick out reliable seeds. Then a label propagation model is developed to diffuse saliency based on these reliable seeds. Lastly, another perceptual cue called rareness is integrated into a cost function to optimize the propagation result. Results on four datasets demonstrate that the proposed method achieves superior performance against fifteen state-of-the-art methods in terms of different evaluation metrics.
C1 [Wu, Xiyin; Jin, Zhong; Ma, Xiaodi] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Wu, Xiyin; Jin, Zhong; Ma, Xiaodi] Nanjing Univ Sci & Technol, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Jiangsu, Peoples R China.
   [Zhou, Jingbo] Nanjing Inst Technol, Sch Comp Engn, Nanjing 211100, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology; Nanjing Institute of Technology
RP Jin, Z (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM zhongjin@njust.edu.cn
RI Wu, Xiyin/AAQ-6518-2020
FU National Natural Science Foundation of China [61602244, 61702262,
   61602444, 91420201, 61472187]; National Basic Research Program of China
   [2014CB349303]; Pre-Research Area Foundation of China [6140312010101]
FX This work was supported by National Natural Science Foundation of China
   under Grant Nos. 61602244, 61702262, 61602444, 91420201, 61472187, and
   by the National Basic Research Program of China under Grant No.
   2014CB349303, and by the Pre-Research Area Foundation of China under
   Grant No. 6140312010101.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hati A, 2017, J VIS COMMUN IMAGE R, V43, P212, DOI 10.1016/j.jvcir.2017.01.007
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hu P, 2016, IEEE T IMAGE PROCESS, V25, P4653, DOI 10.1109/TIP.2016.2594489
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kimchi R, 2008, PSYCHOL SCI, V19, P660, DOI 10.1111/j.1467-9280.2008.02140.x
   Koffka Kurt, 2013, PRINCIPLES GESTALT P
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   WANG Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI DOI 10.1109/TNNLS.2015.2477537
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang JX, 2014, IEEE IMAGE PROC, P1175, DOI 10.1109/ICIP.2014.7025234
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhou T, 2015, PATTERN RECOGN, V48, P2459, DOI 10.1016/j.patcog.2015.03.008
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 46
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 51
EP 62
DI 10.1016/j.jvcir.2018.04.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800006
DA 2024-07-18
ER

PT J
AU Zhu, DD
   Luo, Y
   Dai, L
   Shao, X
   Zhou, QQ
   Itti, L
   Lu, JW
AF Zhu, Dandan
   Luo, Ye
   Dai, Lei
   Shao, Xuan
   Zhou, Qiangqiang
   Itti, Laurent
   Lu, Jianwei
TI Salient object detection via a local and global method based on deep
   residual network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Deep residual network; Local and global
   features
AB Salient object detection is a fundamental problem in both pattern recognition and image processing tasks. Previous salient object detection algorithms usually involve various features based on priors/assumptions about the properties of the objects. Inspired by the effectiveness of recently developed deep feature learning, we propose a novel Salient Object Detection via a Local and Global method based on Deep Residual Network model (SOD-LGDRN) for saliency computation. In particular, we train a deep residual network (ResNet-G) to measure the prominence of the salient object globally and extract multiple level local features via another deep residual network (ResNet-L) to capture the local property of the salient object. The final saliency map is obtained by combining the local-level and global-level saliency via Bayesian fusion. Quantitative and qualitative experiments on six benchmark datasets demonstrate that our SOD-LGDRN method outperforms eight state-of-the-art methods in the salient object detection.
C1 [Zhu, Dandan; Luo, Ye; Shao, Xuan; Lu, Jianwei] Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
   [Dai, Lei] Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang, Peoples R China.
   [Zhou, Qiangqiang] Tongji Univ, Sch Elect & Informat, Shanghai, Peoples R China.
   [Itti, Laurent] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA USA.
   [Itti, Laurent] Univ Southern Calif, Neurosci Program, Los Angeles, CA USA.
   [Lu, Jianwei] Tongji Univ, Inst Translat Med, Shanghai, Peoples R China.
C3 Tongji University; Jiangsu University; Tongji University; University of
   Southern California; University of Southern California; Tongji
   University
RP Luo, Y (corresponding author), Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.; Lu, JW (corresponding author), Tongji Univ, Inst Translat Med, Shanghai, Peoples R China.
EM yeluo@tongji.edu.cn; jwlu33@tongji.edu.cn
RI zhu, dd885/GRO-1645-2022; luo, ye/KQU-4093-2024; Zhou,
   Qiangqiang/AAF-9803-2019
FU National Natural Science Foundation of China (NSFC) [61572362,
   81571347]; Fundamental Research Funds for the Central Universities
   [22120180012]
FX This work was supported by the General Program of National Natural
   Science Foundation of China (NSFC) under Grant No. 61572362. This
   research was also partially supported by the General Program of National
   Natural Science Foundation of China (NSFC) under Grant No. 81571347, and
   the Fundamental Research Funds for the Central Universities under Grant
   No. 22120180012.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], J SIGNAL PROCESSING
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Da C, 2015, PROCEEDINGS OF THE 18TH ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS, VOL 1, P653, DOI 10.1007/978-3-319-13359-1_50
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fareed M.M.S., 2015, SALIENT REGION DETEC
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Itti L, 1999, P SOC PHOTO-OPT INS, V3644, P473, DOI 10.1117/12.348467
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Marat S., 2015, P 15 EUR SIGN C, P1784
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Sung Y.H., 2013, SIGNIFICANCE PRESERV
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wu L., 2016, ARXIV160107255
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhou CB, 2016, COMPUT ELECTR ENG, V54, P220, DOI 10.1016/j.compeleceng.2015.09.013
NR 43
TC 16
Z9 17
U1 1
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 1
EP 9
DI 10.1016/j.jvcir.2018.03.017
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800001
DA 2024-07-18
ER

PT J
AU Mahmood, T
   Mehmood, Z
   Shah, M
   Saba, T
AF Mahmood, Toqeer
   Mehmood, Zahid
   Shah, Mohsin
   Saba, Tanzila
TI A robust technique for copy-move forgery detection and localization in
   digital images via stationary wavelet and discrete cosine transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move forgery; Tampered images; Forgery detection; Authenticity;
   Passive authentication
ID REGION-DUPLICATION FORGERY; EFFICIENT
AB In this era, due to the widespread availability of digital devices, various open source and commercially available image editing tools have made authenticity of image contents questionable. Copy-move forgery (CMF) is a common technique to produce tampered images by concealing undesirable objects or replicating desirable objects in the same image. Therefore, means are required to authenticate image contents and identify the tampered areas. In this paper, a robust technique for CMF detection and localization in digital images is proposed. The technique extracts stationary wavelet transform (SWT) based features for exposing the forgeries in digital images. SWT is adopted because of its impressive localization properties, in both spectral and spatial domains. More specifically approximation subband of the stationary wavelet transform is utilized as this subband holds most of the information that is best suited for forgery detection. The dimension of the feature vectors is reduced by applying discrete cosine transform (DCT). To evaluate the proposed technique, we use two standard datasets namely, the CoMoFoD and the UCID for experimentations. The experimental results reveal that the proposed technique outperforms the existing techniques in terms of true and false detection rate. Consequently, the proposed forgery detection technique can be applied to detect the tampered areas and the benefits can be obtained in image forensic applications.
C1 [Mahmood, Toqeer] Univ Engn & Technol, Dept Comp Sci, Taxila 47050, Pakistan.
   [Mehmood, Zahid] Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
   [Shah, Mohsin] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila; Chinese Academy of Sciences; University of Science
   & Technology of China, CAS; Prince Sultan University
RP Mahmood, T (corresponding author), Univ Engn & Technol, Dept Comp Sci, Taxila 47050, Pakistan.
EM toqeer.mahmood@uettaxila.edu.pk; zahid.mehmood@uettaxila.edu.pk;
   mohsin@mail.ustc.edu.cn; tsaba@psu.edu.sa
RI Saba, Tanzila/D-4593-2018; Mehmood, Dr. Zahid/S-1709-2018; Mahmood,
   Toqeer/O-1681-2013
OI Saba, Tanzila/0000-0003-3138-3801; Mehmood, Dr.
   Zahid/0000-0003-4888-2594; Mahmood, Toqeer/0000-0003-3125-2430; Shah,
   Mohsin/0000-0003-2227-9797
FU Machine Learning Research Group; Prince Sultan University Riyadh; Saudi
   Arabia [RG-CCIS-2017-06-02]
FX This work was partially supported by the Machine Learning Research
   Group; Prince Sultan University Riyadh; Saudi Arabia
   [RG-CCIS-2017-06-02]. The authors are grateful for this financial
   support.
CR Al-Qershi OM, 2017, LECT NOTES ELECTR EN, V398, P209, DOI 10.1007/978-981-10-1721-6_23
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Almohammad A, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P544, DOI 10.1109/ARES.2008.72
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 1995, Translation-invariant denoising
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], INT C CHEM ENG ADV C
   [Anonymous], 2016, 2016 IEEE INT WORKSH, DOI DOI 10.1109/WIFS.2016.7823911
   [Anonymous], WORKSH INF HID DIG W
   [Anonymous], 2004, ELECT IMAGING
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Christlein V., 2012, IEEE T INF FOREN SEC, V7, P1841, DOI DOI 10.1109/TIFS.2012.2218597
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   Fridrich J., 2003, P DIG FOR RES WORKSH, P133
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Islam M, 2015, INT CONF FRONT INFO, P1, DOI 10.1109/FIT.2015.12
   Kessler G.C., 2014, An Overview of Steganography for
   Khan S, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P270, DOI 10.1109/INTECH.2016.7845022
   Khan Z, 2016, INT ARAB J INF TECHN, V13, P380
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Mahmood T., 2016, Int. J. Comput. Sci. Inf. Secur, V14, P156
   Mahmood T, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES (ICET)
   Mahmood T, 2018, APPL INTELL, V48, P1791, DOI 10.1007/s10489-017-1038-5
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Mahmood T, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P578, DOI 10.1109/INTECH.2016.7845040
   Mahmood T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8713202
   Mahmoud K, 2016, INT ARAB J INF TECHN, V13, P930
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rao C. S, 2016, Lecture Notes in Electrical Engineering, V372, P529
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Starck JL, 2007, IEEE T IMAGE PROCESS, V16, P297, DOI 10.1109/TIP.2006.887733
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Ul Islam A, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P265, DOI 10.1109/INTECH.2016.7845020
   Uliyan DM, 2016, EXPERT SYST APPL, V64, P1, DOI 10.1016/j.eswa.2016.07.026
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
   Zandi M, 2014, IEEE INT WORKS INFOR, P119, DOI 10.1109/WIFS.2014.7084314
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhou JH, 2017, LECT NOTES COMPUT SC, V10431, P65, DOI 10.1007/978-3-319-64185-0_6
   Zimba M., 2011, International Journal of Digital Content Technology and its Applications, V5, P251
NR 51
TC 75
Z9 76
U1 4
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 202
EP 214
DI 10.1016/j.jvcir.2018.03.015
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800019
DA 2024-07-18
ER

PT J
AU Wang, CT
   Xiao, DQ
   Peng, HX
   Zhang, RY
AF Wang, Chuntao
   Xiao, Deqing
   Peng, Hongxing
   Zhang, Rongyue
TI A lossy compression scheme for encrypted images exploiting Cauchy
   distribution and weighted rate distortion optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compression of encrypted signals; Statistical model; Rate-distortion
   optimization; Lifting wavelet
AB How to improve the compression efficiency of encrypted signals remains a challenging problem. To alleviate this problem, this paper develops a new compression scheme on encrypted gray images by exploiting the Cauchy distribution and the weighted rate-distortion optimization (wRDO). In the scheme, the low-frequency and wavelet subbands generated through lifting wavelet transform are encrypted by stream and permutation ciphers, respectively. They are then compressed in lossless and lossy ways, respectively. Inverse operations are finally conducted at the receiver to reconstruct the original image. The lossy compression is formulated as a problem of wRDO and further solved by incorporating the Cauchy distribution that is demonstrated via extensive simulations to well characterize statistical distributions of wavelet subbands. Experimental results show that the proposed scheme is significantly better than other permutation-based prior arts and achieves comparable or even better performance in comparison to the conventional JPEG algorithm with original unencrypted images as input.
C1 [Wang, Chuntao; Xiao, Deqing; Peng, Hongxing] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
   [Wang, Chuntao] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Zhang, Rongyue] Guangdong Univ Tech, Coll Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China Agricultural University; Shenzhen University; Guangdong
   University of Technology
RP Wang, CT (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
EM wangct@scau.edu.cn
RI lu, kai/KBB-4008-2024
OI Wang, Chuntao/0000-0002-5482-1766
FU National Natural Science Foundation of China [61672242, 61672170,
   61202467]; China Spark Program [2015GA780002]; National Key Research and
   Development Program of China [2017YFD0701601]; Natural Science
   Foundation of Guangdong Province [2015A030313413, 2015A030310258];
   Guangdong Science and Technology Plan [2016B010125001, 2015B090923004,
   2015A020209149]; NSFC-Guangdong Joint Funds [U1401251]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61672242, Grant 61672170, and Grant 61202467, in part
   by China Spark Program under Grant 2015GA780002, in part by The National
   Key Research and Development Program of China under Grant
   2017YFD0701601, in part by Natural Science Foundation of Guangdong
   Province under Grant 2015A030313413 and Grant 2015A030310258, in part by
   the Guangdong Science and Technology Plan under Grant 2016B010125001,
   Grant 2015B090923004, and Grant 2015A020209149, and in part by the
   NSFC-Guangdong Joint Funds under Grant U1401251.
CR [Anonymous], 2009, PROC TENCON 2009 IEE
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Erkin Z., 2007, EURASIP J INFORM SEC, V17, P2007
   Fu Z., 2016, IEEE T INFORM FORENS
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kamaci N, 2005, IEEE T CIRC SYST VID, V15, P994, DOI 10.1109/TCSVT.2005.852400
   Kang W., 2014, IEEE T INF THEORY
   Kang W., 2012, P 50 ANN ALL C COMM
   Kang XG, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-32
   Kumar AA, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P764
   Kumar M., 2016, SOCPROS 2015 SPRINGE, P729
   Kumar M, 2017, DIGIT SIGNAL PROCESS, V60, P81, DOI 10.1016/j.dsp.2016.08.011
   Lazzeretti R., 2008, P 16 EUR SIGN PROC C, P1
   Liu SH, 2015, J SUPERCOMPUT, V71, P3353, DOI 10.1007/s11227-015-1413-0
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Marcellin MW, 2002, SIGNAL PROCESS-IMAGE, V17, P73, DOI 10.1016/S0923-5965(01)00027-3
   Ning Xu, 2011, 2011 International Conference on Multimedia Technology, P3681
   Ran Hu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7387, DOI 10.1109/ICASSP.2014.6855035
   Schoder D., 2005, P 43 ANN ALL C, P1
   Schonberg D, 2006, IEEE IMAGE PROC, P269, DOI 10.1109/ICIP.2006.313177
   Schonberg D, 2008, IEEE T INF FOREN SEC, V3, P749, DOI 10.1109/TIFS.2008.2007244
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Song CH, 2013, IEEE GLOB COMM CONF, P653, DOI 10.1109/GLOCOM.2013.6831146
   Vaish A, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P228, DOI 10.1145/2818567.2818611
   Wang C., P 11 INT C INT INF H
   Wang CT, 2015, SIGNAL PROCESS-IMAGE, V39, P141, DOI 10.1016/j.image.2015.09.009
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xie X. X, 2013, THESIS
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Zhang X., 2013, MULTIMED TOOLS APPL, V78, P1
   Zhang XP, 2014, IEEE T MULTIMEDIA, V16, P1327, DOI 10.1109/TMM.2014.2315974
   Zhang XP, 2012, IEEE T IMAGE PROCESS, V21, P3108, DOI 10.1109/TIP.2012.2187671
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
   Zhang YS, 2015, SIGNAL PROCESS-IMAGE, V39, P202, DOI 10.1016/j.image.2015.09.001
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 37
TC 7
Z9 10
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 122
EP 130
DI 10.1016/j.jvcir.2018.01.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500012
DA 2024-07-18
ER

PT J
AU Nair, D
   Sankaran, P
AF Nair, Deepa
   Sankaran, Praveen
TI Color image dehazing using surround filter and dark channel prior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Atmospheric light; Color space; Dark channel prior; Dehazing; No
   reference quality assessment; Transmission map
ID RETINEX; VISION
AB Outdoor images are often degraded by haze, resulting in a distinctive gray or bluish hue which diminishes visibility. Of the existing haze removal methods, the ones that are effective are computationally complex and memory intensive. In this paper, we propose a simple haze removal technique, whose computational complexity is that of a simple convolution. To this purpose, a center surround filter is employed to improve speed and memory requirements of the transmission estimation in image dehazing. This can be useful for real time applications such as driver assistance, runway hazard detection and surveillance. The proposed technique relies on deriving an alternative transmission estimate by filtering the input image in three different color spaces, namely RGB, Lab and HSV. The effectiveness of the proposed method is compared with that of other state of the art methods using a subjective quality assessment method and a number of objective quality assessment methods.
C1 [Nair, Deepa; Sankaran, Praveen] Natl Inst Technol Calicut, Elect & Commun Engn Dept, Kozhikode 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Nair, D (corresponding author), Natl Inst Technol Calicut, Elect & Commun Engn Dept, Kozhikode 673601, Kerala, India.
EM psankaran@nitc.ac.in
RI Nair, Deepa/X-1001-2019
OI Nair, Deepa/0000-0002-1973-6312
CR Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 2005, 1 INT WORKSHOP VIDEO
   [Anonymous], RECENT ADV INTELLIGE
   [Anonymous], 2 INT C IM SIGN PROC
   [Anonymous], COMM SIGN PROC P IEE
   [Anonymous], P SPIE
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Koschmieder H., 1925, Theorie der horizontalen Sichtweite: Kontrast und Sichtweite
   LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163
   Lee HG, 2015, ASIAPAC SIGN INFO PR, P884, DOI 10.1109/APSIPA.2015.7415397
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P132
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Peng Ye, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3089, DOI 10.1109/ICIP.2011.6116318
   Qi M, 2015, OPTIK, V126, P3400, DOI 10.1016/j.ijleo.2015.07.114
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tan R, 2008, IEEE C COMPUTER VISI, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yu T, 2015, IET IMAGE PROCESS, V9, P725, DOI 10.1049/iet-ipr.2015.0087
NR 30
TC 29
Z9 30
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 9
EP 15
DI 10.1016/j.jvcir.2017.11.005
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700002
DA 2024-07-18
ER

PT J
AU Sreenivas, K
   Kamakshiprasad, V
AF Sreenivas, K.
   Kamakshiprasad, V.
TI Improved image tamper localisation using chaotic maps and self-recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Chaotic maps; Fragile watermarking; Image authentication; Self recovery;
   Tamper localisation
ID EMBEDDING FRAGILE WATERMARKING; RESTORATION CAPABILITY; SCHEME;
   AUTHENTICATION; MECHANISM
AB In this paper an image tamper localisation scheme is proposed in which authentication bits of a 2 x 2 image block are generated using the chaotic maps. Further the scheme is improved by including a self-recovery method to recover the tampered regions. To improve the quality of the recovered image, two different sets of restoration bits of a block are generated and each one is embedded into randomly selected distinct blocks. The proposed tamper detection scheme performs better than some of the recent schemes proposed by the researchers. The experimental results demonstrate the accuracy and fragility of the tamper detection scheme, and the efficacy of the recovery method. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Sreenivas, K.; Kamakshiprasad, V.] JNTUH, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
C3 Jawaharlal Nehru Technological University - Hyderabad
RP Sreenivas, K (corresponding author), JNTUH, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM ksreenivas2@gmail.com; kamakshiprasad@yahoo.com
CR Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Chen Fan, 2012, MULTIMED TOOLS APPL
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   Lee CW, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.5.057006
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Xiao D, 2012, OPT COMMUN, V285, P2596, DOI 10.1016/j.optcom.2012.02.002
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
NR 22
TC 24
Z9 24
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 164
EP 176
DI 10.1016/j.jvcir.2017.09.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800014
DA 2024-07-18
ER

PT J
AU Yajai, A
   Rasmequan, S
AF Yajai, Apichet
   Rasmequan, Suwanna
TI Adaptive directional bounding box from RGB-D information for improving
   fall detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fall detection; Comprehensive bounding box; Center of gravity; Aspect
   ratio; Kinect; Elderly care; Dynamic tracking; Stream data; Arbitrary
   movement
ID INTELLIGENT; SYSTEM
AB Fall detection for aging people is still a mainstream research focus for the current aging society. Tools that are simple and inexpensive but have high accuracy rates are needed. RGB-D information retrieved from a home entertainment system was used to detect falls using typical bounding boxes techniques. These techniques have limitations. This research introduced the Adaptive Directional Bounding Box that made use of a comprehensive bounding box and a dynamic state machine in a new way to detect falls. The proposed approach offered a way to track and analyze continuous data streams of the visual images to automatically predict a fall event prior to the fall state in a single-phase instead of the typical two-phases. This can significantly affect the survival or severe injury of the elderly. The proposed method can improve accuracy by 25.5% and the response time by 21.31% on average as compared to existing approaches. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Yajai, Apichet; Rasmequan, Suwanna] Burapha Univ, 169 Long Had Bangsaen, Saen Suk 20131, Thailand.
RP Rasmequan, S (corresponding author), Burapha Univ, 169 Long Had Bangsaen, Saen Suk 20131, Thailand.
EM rasmequa@go.buu.ac.th
FU National Research Council of Thailand
FX This research was supported by the National Research Council of Thailand
   grant to Burapha University in year 2013 and 2014.
CR Alhimale L, 2014, APPL SOFT COMPUT, V18, P59, DOI 10.1016/j.asoc.2014.01.024
   [Anonymous], 1996, GLOBAL BURDEN DIS
   [Anonymous], 2009 IEEE REG 10 C T
   Bevilacqua V, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P319, DOI 10.1109/INISTA.2014.6873638
   Chapman A., 2008, HUM KINETICS
   Doukas C, 2007, INT FED INFO PROC, P147
   DRILLIS R, 1964, Artif Limbs, V8, P44
   Edgcomb A, 2012, IEEE ENG MED BIO, P252, DOI 10.1109/EMBC.2012.6345917
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Kangas M, 2009, GAIT POSTURE, V29, P571, DOI 10.1016/j.gaitpost.2008.12.008
   Kawatsu C., 2013, ROBOT INTELLIGENCE T, P623, DOI [10.1007/978-3-642-37374-9_59, DOI 10.1007/978-3-642-37374-9_59]
   Laessoe U, 2007, J NEGAT RESULTS BIOM, V6, DOI 10.1186/1477-5751-6-2
   Lai CF, 2011, IEEE SENS J, V11, P763, DOI 10.1109/JSEN.2010.2062501
   Lee Y, 2007, P ANN INT IEEE EMBS, P2315, DOI 10.1109/IEMBS.2007.4352789
   Liu CL, 2010, EXPERT SYST APPL, V37, P7174, DOI 10.1016/j.eswa.2010.04.014
   Londei ST, 2009, J TELEMED TELECARE, V15, P383, DOI 10.1258/jtt.2009.090107
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Miaou SG, 2006, 1ST TRANSDISCIPLINARY CONFERENCE ON DISTRIBUTED DIAGNOSIS AND HOME HEALTHCARE, CONFERENCE PROCEEDINGS, P39, DOI 10.1109/DDHH.2006.1624792
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Mundher Zaid A., 2014, International Journal of Materials, Mechanics and Manufacturing, V2, P133, DOI 10.7763/IJMMM.2014.V2.115
   Nyan MN, 2006, MED ENG PHYS, V28, P842, DOI 10.1016/j.medengphy.2005.11.008
   Ong PS, 2014, IEEE REGION 10 SYMP, P397, DOI 10.1109/TENCONSpring.2014.6863065
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Siriboon S., 2008, POPULATION STAT THAI
   Sumiya T, 2015, PROCEDIA COMPUT SCI, V60, P870, DOI 10.1016/j.procs.2015.08.250
   Tao J., 2005, Proc. Fifth International Conference on Information, P1590, DOI DOI 10.1109/ICICS.2005.1689327
   Tran TTH, 2014, 2014 IEEE FIFTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P484, DOI 10.1109/CCE.2014.6916752
   Töreyin BU, 2005, LECT NOTES COMPUT SC, V3766, P211, DOI 10.1007/11573425_21
   Yajai A, 2015, INT JOINT CONF COMP, P52, DOI 10.1109/JCSSE.2015.7219769
   Zigel Y, 2009, IEEE T BIO-MED ENG, V56, P2858, DOI 10.1109/TBME.2009.2030171
NR 31
TC 10
Z9 10
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 257
EP 273
DI 10.1016/j.jvcir.2017.08.008
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800021
DA 2024-07-18
ER

PT J
AU Jin, LH
AF Jin, Lianghai
TI Complex impulse noise removal from color images based on super pixel
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image; Blob noise; Super pixel segmentation; Quaternion
ID SPARSE; FILTER; OPTIMIZATION; RESTORATION; ENHANCEMENT; MODEL
AB Impulse noise sometimes appears as blob or granular shapes in images, which are irregularly shaped with typically several pixels wide in different directions. Most existing methods are developed to remove only single-point impulse noise and usually perform poor when applied to blob noise removal. This paper presents a new method to suppress such complex blob noise with varying sizes and irregular shapes in color images. First, a noisy image is segmented into super pixels by mean shift filtering followed by a clustering operation based on quaternion color distance. Then, by analyzing the characteristics of super pixels, image pixels are classified into noise-free, blob-noisy, and single-point impulse ones. Finally, a selected recursive vector median filter with adaptive window sizes is employed on the noisy pixels detected. The experimental results exhibit the validity of the proposed solution by showing excellent denoising effect and performance, compared to other color image denoising methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Jin, Lianghai] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Jin, LH (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM Lianghaijin@hust.edu.cn
FU National Natural Science Foundation of China [61370181, 61370179]
FX This work is supported by the National Natural Science Foundation of
   China (61370181 and 61370179). The author would like to thank Dr.
   Ruixuan Wang, CVIP, University of Dundee, for providing the code of SPLR
   algorithm [3].
CR Ananthi VP, 2016, SIGNAL PROCESS, V121, P81, DOI 10.1016/j.sigpro.2015.10.030
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Brook A, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013034
   Camarena JG, 2013, IEEE T FUZZY SYST, V21, P971, DOI 10.1109/TFUZZ.2012.2234754
   Celebi ME, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2991415
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Evans CJ, 2000, IEEE IMAGE PROC, P541, DOI 10.1109/ICIP.2000.901015
   Gai S, 2015, MULTIDIM SYST SIGN P, V26, P307, DOI 10.1007/s11045-013-0268-x
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Jin LH, 2016, SIGNAL PROCESS, V128, P171, DOI 10.1016/j.sigpro.2016.03.025
   Karakos DG, 1997, IEEE T IMAGE PROCESS, V6, P1038, DOI 10.1109/83.597278
   Kim S, 2006, IEEE T IMAGE PROCESS, V15, P1163, DOI 10.1109/TIP.2005.864184
   Li CM, 2016, LECT NOTES ELECTR EN, V345, P347, DOI 10.1007/978-3-319-17314-6_46
   Li W, 2014, LECT NOTES COMPUT SC, V8692, P61, DOI 10.1007/978-3-319-10593-2_5
   Likforman-Sulem L, 2011, IMAGE VISION COMPUT, V29, P351, DOI 10.1016/j.imavis.2011.01.001
   Lin TC, 2012, NEURAL COMPUT APPL, V21, P695, DOI 10.1007/s00521-011-0648-9
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Lukac R, 2006, ADV IMAG ELECT PHYS, V140, P187, DOI 10.1016/S1076-5670(05)40004-X
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Mélange T, 2011, IEEE T IMAGE PROCESS, V20, P959, DOI 10.1109/TIP.2010.2077305
   Morillas S, 2008, COMPUT VIS IMAGE UND, V110, P102, DOI 10.1016/j.cviu.2007.05.001
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Plataniotis KN, 1998, IEEE T CIRCUITS-II, V45, P1414, DOI 10.1109/82.728854
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rosales-Silva AJ, 2012, J VIS COMMUN IMAGE R, V23, P143, DOI 10.1016/j.jvcir.2011.09.007
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Sangwine SJ, 2000, IEE P-VIS IMAGE SIGN, V147, P89, DOI 10.1049/ip-vis:20000211
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Shen YZ, 2006, IEEE T SIGNAL PROCES, V54, P2497, DOI 10.1109/TSP.2006.874028
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Sun T, 2014, IEEE IMAGE PROC, P3857, DOI 10.1109/ICIP.2014.7025783
   Tomaselli V., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P306, DOI 10.1109/ICCE-Berlin.2012.6336463
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
   Turkmen I, 2016, J VIS COMMUN IMAGE R, V34, P28, DOI 10.1016/j.jvcir.2015.10.011
   Wang RX, 2015, IEEE T IMAGE PROCESS, V24, P1485, DOI 10.1109/TIP.2015.2400225
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 46
TC 10
Z9 10
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 54
EP 65
DI 10.1016/j.jvcir.2017.05.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700005
DA 2024-07-18
ER

PT J
AU Chu, WT
   Zheng, XY
   Ding, DS
AF Chu, Wei-Ta
   Zheng, Xiang-You
   Ding, Ding-Shiuan
TI Camera as weather sensor: Estimating weather information from single
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-platform data association; Weather property estimation; Weather
   modeling; Random forests; Landmark classification
AB We estimate weather information from single images, as an important clue to unveil real-world characteristics available in the cyberspace, and as a complementary feature to facilitate computer vision applications. Based on an image collection with geotags, we crawl the associated weather and elevation properties from the web. With this large-scale and rich image dataset, various correlations between weather properties and metadata are observed, and are used to construct computational models based on random forests to estimate weather information for any given image. We describe interesting statistics linking weather properties with human behaviors, and show that image's weather information can potentially benefit computer vision tasks such as landmark classification. Overall, this work proposes a large-scale image dataset with rich weather properties, and provides comprehensive studies on using cameras as weather sensors. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Chu, Wei-Ta; Zheng, Xiang-You; Ding, Ding-Shiuan] Natl Chung Cheng Univ, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Chiayi, Taiwan.
EM wtchu@ccu.edu.tw
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
CR [Anonymous], 2008, 2008 IEEE C COMPUTER
   Avrithis Y., 2010, P ACM INT C MULT
   Bing-Fei Wu, 2008, 2008 IEEE International Symposium on Industrial Electronics (ISIE 2008), P1255, DOI 10.1109/ISIE.2008.4677194
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZC, 2012, IEEE IMAGE PROC, P1853, DOI 10.1109/ICIP.2012.6467244
   Crouxa C., 2007, COMPUT STAT DATA ANA, V52
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Fu H., 2012, P EUR C COMP VIS
   Glasner D, 2015, IEEE I CONF COMP VIS, P3997, DOI 10.1109/ICCV.2015.455
   Greengard S, 2014, COMMUN ACM, V57, P12, DOI 10.1145/2641225
   Hao Q, 2012, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2012.6248104
   Hauff C, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1037
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   IPTC, 2016, EMB MET IN
   Islam M., 2013, P IEEE CVPR WORKSH G
   Jacobs Nathan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P39, DOI 10.1109/CVPR.2009.5204185
   Jacobs N, 2007, PROC CVPR IEEE, P2210
   Katsura H, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2974
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101
   Lalonde JF, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618477
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li QY, 2012, IEEE GEOSCI REMOTE S, V9, P417, DOI 10.1109/LGRS.2011.2170953
   Lu CW, 2014, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2014.475
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mihail RP, 2016, IEEE WINT CONF APPL
   Narasimhan SG, 2002, LECT NOTES COMPUT SC, V2352, P148
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Razavian A., 2014, P CVPR WORKSH DEEPV
   Roser M, 2008, IEEE INT VEH SYM, P480
   Serrano N, 2002, INT C PATT RECOG, P146, DOI 10.1109/ICPR.2002.1047420
   Shen L, 2009, PROC CVPR IEEE, P1850, DOI 10.1109/CVPRW.2009.5206732
   Thomee B., 2010, P INT C MULTIMEDIA M, P1473
   Tseng T.-E., 2016, P IEEE C AC SPEECH S
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Volokitin A., 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P63
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Weng TL, 2010, EXPERT SYST APPL, V37, P1666, DOI 10.1016/j.eswa.2009.06.092
   Wu HM, 2010, COMPUT STAT DATA AN, V54, P767, DOI 10.1016/j.csda.2008.09.029
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yan XS, 2009, LECT NOTES COMPUT SC, V5553, P390
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Zhang Z, 2016, NEUROCOMPUTING, V207, P365, DOI 10.1016/j.neucom.2016.05.015
   Zhang Z, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/9825820
NR 52
TC 34
Z9 35
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 233
EP 249
DI 10.1016/j.jvcir.2017.04.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500021
DA 2024-07-18
ER

PT J
AU Lakehal, E
   Ziou, D
   Benmohammed, M
AF Lakehal, Elkhamssa
   Ziou, Djemel
   Benmohammed, Mohamed
TI Multiple illuminant estimation from the covariance of colors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Color constancy; White balancing; Multiple illuminant
   estimation; Dichromatic reflection model; Color space; Principal
   component analysis
ID 3D SCENE GEOMETRY; NEURAL-NETWORK; CONSTANCY; CHROMATICITY; REFLECTION;
   MODEL; HIGHLIGHTS; ALGORITHM; IMAGE
AB In this paper we present a single and a multiple illuminant estimation physics-based algorithm. Both algorithms are based on the mean projections maximization assumption and un-centered component analysis. The proposed assumption is validated for a large collection of images and later used to estimate the illuminant color. The multiple illuminant estimator assumes that the spectral power distribution of the light source is not the same for the whole scene, which is the case for a wide range of images. In such cases, our new multiple illuminant estimator recovers an accurate illuminants estimates map for each input image while maintaining speed. The evaluation of the proposed algorithms on different real image datasets is realized. The experimental results are satisfying; our algorithms maximize the trade-off between accuracy (illuminant estimation error) and computational complexity. Crown Copyright (C) 2017 Published by Elsevier Inc. All rights reserved.
C1 [Lakehal, Elkhamssa] Univ Batna 2, LAMIE Lab, Fac Math & Informat, Fesdis Batna 05110, Algeria.
   [Ziou, Djemel] Univ Sherbrooke, DI, Sherbrooke, PQ, Canada.
   [Benmohammed, Mohamed] LIRE Lab, BP 325,Route Ain El Bey, Constantine, Algeria.
C3 University of Batna 2; University of Sherbrooke
RP Lakehal, E (corresponding author), Univ Batna 2, LAMIE Lab, Fac Math & Informat, Fesdis Batna 05110, Algeria.
EM lakehal_elkhamssa@yahoo.fr
RI mohamed, benmohammed/AAE-1606-2019
CR Agarwal V, 2009, J PATTERN RECOGNIT R, V4, P92, DOI 10.13176/11.99
   [Anonymous], 2007, COLOR CONSTANCY
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587765
   Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049
   Barnard K, 2000, LECT NOTES COMPUT SC, V1842, P390
   Beigpour S, 2014, IEEE T IMAGE PROCESS, V23, P83, DOI 10.1109/TIP.2013.2286327
   Bianco Simone, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P81, DOI 10.1109/CVPRW.2015.7301275
   Bianco S, 2010, PATTERN RECOGN, V43, P695, DOI 10.1016/j.patcog.2009.08.007
   Bianco S, 2014, IEEE T PATTERN ANAL, V36, P1505, DOI 10.1109/TPAMI.2013.2297710
   Bodrogi P., 2012, Illumination, Color and Imaging: Evaluation and Optimization of Visual Displays
   Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cadima J, 2009, PAK J STAT, V25, P473
   Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P311
   Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374
   Celik T, 2012, COMPUT VIS IMAGE UND, V116, P561, DOI 10.1016/j.cviu.2011.12.004
   Chakrabarti A., 2008, 2008 IEEE C COMPUTER, P1
   Chen CL, 2011, EXPERT SYST APPL, V38, P7718, DOI 10.1016/j.eswa.2010.12.137
   Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160
   Drew MS, 2014, COMPUT VIS IMAGE UND, V127, P1, DOI 10.1016/j.cviu.2014.07.002
   Elfiky N, 2014, IEEE T IMAGE PROCESS, V23, P3855, DOI 10.1109/TIP.2014.2336545
   Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Funt B, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P47
   Gijsenij A., 2007, IEEE Conference on Computer Vision and Pattern Recognition(CVPR), P1
   Gijsenij A, 2012, IEEE T PATTERN ANAL, V34, P918, DOI 10.1109/TPAMI.2011.197
   Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   Gijsenij A, 2009, PROC CVPR IEEE, P581, DOI 10.1109/CVPRW.2009.5206497
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243
   HEALEY G, 1991, IMAGE VISION COMPUT, V9, P333, DOI 10.1016/0262-8856(91)90038-Q
   Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226
   Jenssen R, 2013, IEEE T NEUR NET LEAR, V24, P1553, DOI 10.1109/TNNLS.2013.2262774
   Joze HRV, 2012, COLOR IMAG CONF, P41
   Joze HRV, 2014, IEEE T PATTERN ANAL, V36, P860, DOI 10.1109/TPAMI.2013.169
   Lakehal E, 2016, LECT NOTES COMPUT SC, V9680, P148, DOI 10.1007/978-3-319-33618-3_16
   Land EH., 1977, The retinex theory of color vision
   LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694
   LEE HC, 1990, IEEE T PATTERN ANAL, V12, P402, DOI 10.1109/34.50626
   Lu R, 2009, IEEE I CONF COMP VIS, P1749, DOI 10.1109/ICCV.2009.5459391
   Lu R, 2009, IEEE IMAGE PROC, P685, DOI 10.1109/ICIP.2009.5414083
   Natrella M., 2010, NIST SEMATECH HDB ST
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Pillai SU, 2005, IEEE SIGNAL PROC MAG, V22, P62, DOI 10.1109/MSP.2005.1406483
   Rosenberg C., 2003, ADV NEURAL INFORM PR
   Schaefer G, 2005, PROC CVPR IEEE, P148
   Schaefer G, 2004, LECT NOTES COMPUT SC, V3212, P257
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   Shi Lilong., 2008, Conference on Colour in Graphics, Imaging, and Vision, V1, P259
   Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321
   TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576
   Toro J, 2007, IEEE T IMAGE PROCESS, V16, P92, DOI 10.1109/TIP.2006.884953
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Virgen-Navarro L, 2016, EXPERT SYST APPL, V54, P162, DOI 10.1016/j.eswa.2016.01.027
NR 58
TC 4
Z9 4
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 107
EP 118
DI 10.1016/j.jvcir.2017.03.013
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500010
DA 2024-07-18
ER

PT J
AU Moeini, A
   Faez, K
   Moeini, H
   Safai, AM
AF Moeini, Ali
   Faez, Karim
   Moeini, Hossein
   Safai, Armon Matthew
TI Facial expression recognition using dual dictionary learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial Expression Recognition; Dual dictionary learning; Sparse
   representation; Regression classification
ID SPARSE REPRESENTATION; FACE RECOGNITION; DISCRIMINATIVE DICTIONARY;
   K-SVD; SYSTEM; CLASSIFICATION
AB In this paper, a novel method is proposed for Facial Expression Recognition (FER) using dictionary learning to learn both identity and expression dictionaries simultaneously. Accordingly, an automatic and comprehensive feature extraction method is proposed. The proposed method accommodates real-valued scores to a probability of what percent of the given Facial Expression (FE) is present in the input image. To this end, a dual dictionary learning method is proposed to learn both regression and feature dictionaries for FER. Then, two regression classification methods are proposed using a regression model formulated based on dictionary learning and two known classification methods including Sparse Representation Classification (SRC) and Collaborative Representation Classification (CRC). Convincing results are acquired for FER on the CK+, CK, MMI and JAFFE image databases compared to several state-of-the-arts. Also, promising results are obtained from evaluating the proposed method for generalization on other databases. The proposed method not only demonstrates excellent performance by obtaining high accuracy on all four databases but also outperforms other state-of-the-art approaches. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Moeini, Ali; Faez, Karim] Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
   [Moeini, Hossein] Semnan Univ, Elect Engn Dept, Semnan, Iran.
   [Safai, Armon Matthew] Univ Calif San Diego, Comp Sci & Engn Dept, San Diego, CA 92103 USA.
C3 Amirkabir University of Technology; Semnan University; University of
   California System; University of California San Diego
RP Moeini, A (corresponding author), Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
EM ali.moeini1989@gmail.com
RI faez, karim/K-5117-2019
OI faez, karim/0000-0002-1159-4866
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], ICCV
   [Anonymous], FG
   [Anonymous], CVPR
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], 2013, CVPR
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006
   Gbèhounou S, 2016, J VIS COMMUN IMAGE R, V38, P276, DOI 10.1016/j.jvcir.2016.03.009
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kanade T., 2000, 4 IEEE INT C AUT FAC
   Liu S, 2012, IMAGE VISION COMPUT, V30, P535, DOI 10.1016/j.imavis.2012.05.004
   Liu WY, 2015, PATTERN RECOGN, V48, P3076, DOI 10.1016/j.patcog.2015.04.014
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Moeini A., 2014, ICPR
   Moeini A, 2017, IMAGE VISION COMPUT, V57, P1, DOI 10.1016/j.imavis.2016.11.002
   Moeini A, 2017, PATTERN RECOGN, V62, P99, DOI 10.1016/j.patcog.2016.08.031
   Moeini A, 2016, J VIS COMMUN IMAGE R, V35, P1, DOI 10.1016/j.jvcir.2015.11.006
   Moeini A, 2015, PATTERN RECOGN LETT, V68, P83, DOI 10.1016/j.patrec.2015.08.012
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Moeini A, 2015, IMAGE VISION COMPUT, V36, P9, DOI 10.1016/j.imavis.2015.01.007
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pai NS, 2011, COMPUT MATH APPL, V61, P2101, DOI 10.1016/j.camwa.2010.08.082
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Ptucha R, 2013, IMAGE VISION COMPUT, V31, P365, DOI 10.1016/j.imavis.2013.03.003
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rudovic Ognjen., 2012, CVPR
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Taheri S, 2013, IEEE T AFFECT COMPUT, V4, P360, DOI 10.1109/T-AFFC.2013.28
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Wang Z, 2016, NEUROCOMPUTING, V174, P756, DOI 10.1016/j.neucom.2015.09.083
   Woodward A, 2012, J VIS COMMUN IMAGE R, V23, P1113, DOI 10.1016/j.jvcir.2012.07.005
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu LL, 2016, J VIS COMMUN IMAGE R, V38, P561, DOI 10.1016/j.jvcir.2016.04.003
   Yan OY, 2015, NEUROCOMPUTING, V149, P71, DOI 10.1016/j.neucom.2014.03.073
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Zhang LG, 2014, NEUROCOMPUTING, V145, P451, DOI 10.1016/j.neucom.2014.05.008
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
NR 51
TC 23
Z9 24
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 20
EP 33
DI 10.1016/j.jvcir.2017.02.007
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100003
DA 2024-07-18
ER

PT J
AU Mekhalfi, ML
   Melgani, F
   Bazi, Y
   Alajlan, N
AF Mekhalfi, Mohamed L.
   Melgani, Farid
   Bazi, Yakoub
   Alajlan, Naif
TI Fast indoor scene description for blind people with multiresolution
   random projections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Assistive technologies; Coarse scene description; Multiobject
   recognition; Multiresolution processing; Random projection; Visually
   impaired people
ID PARALLEL FRAMEWORK; CLASSIFICATION; RECOGNITION; GUIDANCE
AB Object recognition forms a substantial need for blind and visually impaired individuals. This paper proposes a new multiobject recognition framework. It consists of coarsely checking the presence of multiple objects in a portable camera-grabbed image at a considered indoor site. The outcome is a list of objects that likely appear in the indoor scene. Such description is meant to uplift the conscience of the blind person in order to better sense his/her surroundings. The method consists of a library containing (i) a bunch of images represented by means of the Random Projections (RP) technique and (ii) their respective list of objects, both prepared offline. Thus, given an online shot image, its RP representation is generated and matched to the RP patterns of library images. It thus inherits the objects of the closest image from the library. Extensive experiments returned promising recognition accuracies and a processing lapse of real-time standard.(C) 2017 Elsevier Inc. All rights reserved.
C1 [Mekhalfi, Mohamed L.; Melgani, Farid] Univ Trento, Dept Informat Engn & Comp Sci, Via Sommarive 9, I-38123 Trento, Italy.
   [Bazi, Yakoub; Alajlan, Naif] King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
C3 University of Trento; King Saud University
RP Mekhalfi, ML (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, Via Sommarive 9, I-38123 Trento, Italy.
EM mohamed.mekhalfi@disi.unitn.it; melgani@disi.unitn.it; ybazi@ksu.edu.sa;
   najlan@ksu.edu.sa
RI Mekhalfi, Mohamed Lamine/AAA-4596-2019; Alajlan, Naif/A-3904-2008; Bazi,
   Yakoub/K-8864-2012
OI Alajlan, Naif/0000-0003-1846-1131; Mekhalfi, Mohamed
   Lamine/0000-0002-4295-0974
FU Deanship of Scientific Research at King Saud University through the
   Local Research Group Program [RG-1435-055]
FX This work was supported by the Deanship of Scientific Research at King
   Saud University through the Local Research Group Program under Project
   RG-1435-055.
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   [Anonymous], 2012, AUST ROBOT AUTOM ASS, DOI DOI 10.1007/978-3-319-16199-0_32
   [Anonymous], 2015, P 23 ACM INT C MULT
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bingham E., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P245, DOI 10.1145/502512.502546
   Bousbia-Salah M, 2011, J INTELL ROBOT SYST, V64, P387, DOI 10.1007/s10846-011-9555-7
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Cardoso A, 2012, PATTERN RECOGN LETT, V33, P1749, DOI 10.1016/j.patrec.2012.06.007
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Florindo JB, 2013, EXPERT SYST APPL, V40, P4022, DOI 10.1016/j.eswa.2013.01.007
   Hasanuzzaman FM, 2012, IEEE T SYST MAN CY C, V42, P1021, DOI 10.1109/TSMCC.2011.2178120
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SW, 2008, INT J PATTERN RECOGN, V22, P1171, DOI 10.1142/S0218001408006727
   Li P., 2006, P 12 ACM SIGKDD INT, P287, DOI DOI 10.1145/1150402.1150436
   Li W, 2013, IEEE T GEOSCI REMOTE, V51, P833, DOI 10.1109/TGRS.2012.2204759
   Liao L, 2014, J VIS COMMUN IMAGE R, V25, P1187, DOI 10.1016/j.jvcir.2014.03.007
   López-de-Ipiña D, 2011, LECT NOTES COMPUT SC, V6719, P266, DOI 10.1007/978-3-642-21535-3_39
   Lu F, 2013, INT CONF CLOUD COMP, P25, DOI 10.1109/CloudCom.2013.10
   Luz E.J.S., 2015, COMPUT METH PROG BIO, P2608
   Mekhalfi ML, 2015, EXPERT SYST APPL, V42, P2907, DOI 10.1016/j.eswa.2014.11.017
   Mekhalfi ML, 2015, IEEE T CIRC SYST VID, V25, P1246, DOI 10.1109/TCSVT.2014.2372371
   Phung SL, 2007, IEEE T NEURAL NETWOR, V18, P329, DOI 10.1109/TNN.2006.884677
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Scalise L, 2012, IEEE T INSTRUM MEAS, V61, P3047, DOI 10.1109/TIM.2012.2202169
   Shoval S, 1998, IEEE T SYST MAN CY C, V28, P459, DOI 10.1109/5326.704589
   Shu X, 2012, PATTERN RECOGN, V45, P1892, DOI 10.1016/j.patcog.2011.11.012
   Ulrich I, 2001, IEEE T SYST MAN CY A, V31, P131, DOI 10.1109/3468.911370
   Wang J., 2012, Geometric structure of high-dimensional data and dimensionality reduction
   Wang SH, 2012, LECT NOTES COMPUT SC, V7383, P17, DOI 10.1007/978-3-642-31534-3_3
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang X., 2010, 2010 IEEE COMPUTER S, P57, DOI 10.1109/ CVPRW.2010.5543830.
   Zhou L, 2013, NEUROCOMPUTING, V122, P284, DOI 10.1016/j.neucom.2013.06.023
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
NR 38
TC 14
Z9 14
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 95
EP 105
DI 10.1016/j.jvcir.2017.01.025
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600009
DA 2024-07-18
ER

PT J
AU Nie, YM
   Yue, T
   Zhu, H
   Du, SD
   Cao, X
AF Nie, Yongming
   Yue, Tao
   Zhu, Hao
   Du, Sidan
   Cao, Xun
TI Robust multi-view stereo synthesized by various parameters model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view stereo; Variational method; Matrix splitting; Low-rank
   matrix; Accelerated proximal gradient
ID OPTIMIZATION; SILHOUETTE; FUSION
AB In this paper, we have developed a novel and robust framework of combining a matrix splitting with multi-view stereo reconstructions to separate reconstruction inaccuracies from a various parameters model for high-accuracy multi-view stereo reconstruction. Instead of performing the fixed parameters reconstruction procedure, we apply the variational based 3D reconstruction algorithm multi-times with various parameters to derive a set of hypothetic 3D models, and then synthesized the final result by formulating the problem as a low-rank matrix splitting problem. Benefited from the matrix splitting formulation, the outliers and bad matches, which are treated as the noise in the synthesized model, are effectively removed and thus lead to a 3D reconstruction with higher accuracy than the existing fixed parameters reconstructions. Constrained convex optimization is introduced for matrix splitting with an accelerated proximal gradient (APG) algorithm integrated for fast convergence. Both the experiments on the Middlebury and real-world data sets have demonstrated the effectiveness of the proposed method. (C) 2016 Published by Elsevier Inc.
C1 [Nie, Yongming; Yue, Tao; Zhu, Hao; Du, Sidan; Cao, Xun] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Yue, T; Du, SD (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
EM nju323nym@gmail.com; yuetao@nju.edu.cn; zhuhao@gmail.com;
   coff128@nju.edu.cn; caoxun@nju.edu.cn
RI Du, Sidan/JVN-2413-2024; 岳, 涛/IST-6884-2023
OI Du, Sidan/0000-0002-7079-0066; 
FU National Science Foundation of China [61300157, 61201425, 61371166,
   61422107]
FX This work was partially supported by Grant Nos. 61300157, 61201425,
   61371166, 61422107 from National Science Foundation of China. We thank
   S. Seitz, B. Curless, J. Diebel, D. Scharstein and R. Szeliski for the
   Temple and Dino data sets and evaluations.
CR [Anonymous], 2007, P IEEE C COMP VIS PA
   BANK RE, 1988, NUMER MATH, V52, P427, DOI 10.1007/BF01462238
   Bradley D., 2008, CVPR, P1
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Cremers D, 2011, IEEE T PATTERN ANAL, V33, P1161, DOI 10.1109/TPAMI.2010.174
   Deng Y, 2012, IEEE J-STSP, V6, P566, DOI 10.1109/JSTSP.2012.2195472
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Furukawa Y., 2006, URBANA, V12, P1825
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gargallo P, 2005, PROC CVPR IEEE, P885
   Goesele M., 2006, COMP VIS PATT REC 20, P2402, DOI DOI 10.1109/CVPR.2006.199
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kolev K, 2012, IEEE T PATTERN ANAL, V34, P493, DOI 10.1109/TPAMI.2011.150
   Kolev K, 2009, PROC CVPR IEEE, P1858, DOI 10.1109/CVPRW.2009.5206608
   Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Lin Z., 2009, The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]
   Merrell P, 2007, IEEE I CONF COMP VIS, P3012, DOI 10.1109/iccv.2007.4408984
   Oswald Martin Ralf, 2014, Computer Vision - ECCV 2014. 13th European Conference. Proceedings: LNCS 8692, P32, DOI 10.1007/978-3-319-10593-2_3
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Slesareva N, 2007, LECT NOTES COMPUT SC, V4522, P173
   Tran S, 2006, LECT NOTES COMPUT SC, V3952, P219
   Tseng P., 2016, SIAM J OPTIMIZ UNPUB
   Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712
   Wright J., ADV NEURAL INFORM PR, V22
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
NR 35
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 183
EP 191
DI 10.1016/j.jvcir.2016.11.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200015
OA Bronze
DA 2024-07-18
ER

PT J
AU Singh, C
   Kaur, KP
AF Singh, Chandan
   Kaur, Kanwal Preet
TI A fast and efficient image retrieval system based on color and texture
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Color histogram; Texture feature; BDIP; BVLC
ID PERFORMANCE EVALUATION; ROTATION-INVARIANT; SCALE; SIFT; REPRESENTATION;
   CLASSIFICATION; HISTOGRAMS
AB We propose a fast and efficient image retrieval system based on color and texture features. The color features are represented by color histograms and texture features are represented by block difference of inverse probabilities (BDIP) and block variation of local correlation coefficients (BVLC). It is observed that color features in combination with the texture features derived on the brightness component provides approximately similar results when color features are combined with the texture features using all three components of color, but with much less processing time. An analysis of various distance measures reveals that the square-chord distance measure outperforms the other prominent distance measures for the proposed method. Detailed experimental analysis is carried out using precision and recall on four datasets: Corel-5K, Corel-10K, UKbench and Holidays. The time analysis is also performed to compare processing speeds of the proposed method with the existing similar best methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Singh, Chandan; Kaur, Kanwal Preet] Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
C3 Punjabi University
RP Singh, C (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
EM chandan.csp@gmail.com; kanwalpreetkaur87@gmail.com
OI Singh, Chandan/0000-0002-8059-1263
FU University Grant Commission (UGC), Govt. of India; Ministry of Minority
   Affairs (MOMA), Govt. of India [F1-17.1/2013-14/MANF-2013-14-SIK-PUN-2
   2020]
FX The authors are thankful to the anonymous reviewers for their useful
   comments and suggestions to raise the standard of the paper. One of the
   authors (Kanwal Preet Kaur) is thankful to University Grant Commission
   (UGC) and the Ministry of Minority Affairs (MOMA), Govt. of India, for
   providing Maulana Azad National Fellowship
   (F1-17.1/2013-14/MANF-2013-14-SIK-PUN-2 2020) for carrying out the
   research work.
CR [Anonymous], 2000 ACM WORKSH MULT
   [Anonymous], 2014, PROC IEEE C COMPUT V
   [Anonymous], IEEE T SYST MAN CYBE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 159383FDIS ISOIEC
   [Anonymous], 39 JISC
   [Anonymous], 1999, Handbook of multimedia computing
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Burger W., 2009, Principles of Digital Image Processing
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Chen X., 2010, IEEE INT S BROADBAND, P1
   Chun YD, 2003, IEEE T CIRC SYST VID, V13, P951, DOI 10.1109/TCSVT.2003.816507
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Li B, 2011, PROC CVPR IEEE, P1737
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nister David, 2006, CVPR
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Wong KM, 2007, IEEE IMAGE PROC, P3161
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 58
TC 37
Z9 38
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 225
EP 238
DI 10.1016/j.jvcir.2016.10.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000020
DA 2024-07-18
ER

PT J
AU Zhan, YZ
   Liu, JQ
   Gou, JP
   Wang, MC
AF Zhan, Yongzhao
   Liu, Junqi
   Gou, Jianping
   Wang, Minchao
TI A video semantic detection method based. on locality-sensitive
   discriminant sparse representation and weighted KNN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Discrimination; Weighted KNN; Video semantic
   concept detection
ID K-SVD; CLASSIFICATION; DICTIONARIES; ALGORITHM
AB Video semantic detection has been one research hotspot in the field of human-computer interaction. In video features-oriented sparse representation, the features from the same category video could not achieve similar coding results. To address this, the Locality-Sensitive Discriminant Sparse Representation (LSDSR) is developed, in order that the video samples belonging to the same video category are encoded as similar sparse codes which make them have better category discrimination. In the LSDSR, a discriminative loss function based on sparse coefficients is imposed on the locality-sensitive sparse representation, which makes the optimized dictionary for sparse representation be discriminative. The LSDSR for video features enhances the power of semantic discrimination to optimize the dictionary and build the better discriminant sparse model. More so, to further improve the accuracy of video semantic detection after sparse representation, a weighted K-Nearest Neighbor (KNN) classification method with the loss function that integrates reconstruction error and discrimination for the sparse representation is adopted to detect video semantic concepts. The proposed methods are evaluated on the related video databases in comparison with existing sparse representation methods. The experimental results show that the proposed methods significantly enhance the power of discrimination of video features, and consequently improve the accuracy of video semantic concept detection. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhan, Yongzhao; Liu, Junqi; Gou, Jianping; Wang, Minchao] Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Zhan, YZ (corresponding author), Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM yzzhan@ujs.edu.cn
RI Gou, Jianping/JQX-2453-2023
OI Gou, Jianping/0000-0003-1413-0693
FU National Natural Science Foundation of China [61672268, 61502208];
   Primary Research & Developement Plan of Jiangsu Province of China
   [BE2015137]; Natural Science Foundation of the Jiangsu Higher Education
   Institutions of China [14KJB520007, 14KJB520008]; China Postdoctoral
   Science Foundation [2015M570411]; Natural Science Foundation of Jiangsu
   Province of China [BK20150522]; Research Foundation for Talented
   Scholars of Jiangsu University [14JDG037, 13JDG126]
FX This work was supported by National Natural Science Foundation of China
   (Grant Nos. 61672268, 61502208), Primary Research & Developement Plan of
   Jiangsu Province of China (Grant No. BE2015137), the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China (Grant
   Nos. 14KJB520007, 14KJB520008), China Postdoctoral Science Foundation
   (Grant No. 2015M570411), Natural Science Foundation of Jiangsu Province
   of China (Grant No. BK20150522) and Research Foundation for Talented
   Scholars of Jiangsu University (Grant Nos. 14JDG037, 13JDG126).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], J JIANGSU U
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fu J., 2012, INFORM TECHNOL J, V11, P1381
   Gou JP, 2014, KNOWL-BASED SYST, V70, P361, DOI 10.1016/j.knosys.2014.07.020
   Guha Tanaya, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P143, DOI 10.1109/FG.2011.5771388
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Liang Z., 2010, P INT C INF SCI ENG, P3404
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mukundan R., 2005, P IEEE REG 10 ANN IN
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P287, DOI 10.1016/j.image.2010.02.001
   Yuan Y., 2015, IMAGE VIS COMPUT
   Zhan YZ, 2015, COMPUT J, V58, P1360, DOI 10.1093/comjnl/bxu121
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
NR 24
TC 17
Z9 18
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 65
EP 73
DI 10.1016/j.jvcir.2016.09.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000007
DA 2024-07-18
ER

PT J
AU Yazdian-Dehkordi, M
   Azimifar, Z
AF Yazdian-Dehkordi, Mandi
   Azimifar, Zohreh
TI Adaptive visual target detection and tracking using weakly supervised
   incremental appearance learning and RGM-PHD tracker
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Background subtraction; Appearance modeling;
   Appearance-based detection; Incremental appearance learning; Weak
   supervision; Keypoint descriptors; RGM-PHD tracker
ID HYPOTHESIS DENSITY FILTER; ENTROPY DISTRIBUTION; MULTITARGET
AB Multiple visual target tracking is a challenging problem due to various uncertainties including occlusion, miss-detection and noisy measurement. Most tracking approaches utilize an object-specific detector, pre-trained on many labeled images, to provide suitable measurements for their tracking system. In this paper, we use a simple background subtraction detector which only needs the background image to localize targets independent of their shape or type. In order to cope with the uncertainties resulted by the detector, we propose an adaptive appearance model and develop an incremental appearance learning algorithm to learn the target appearances in time. The proposed method employs the background information and our defined keypoints' miss-matched history to adapt the target appearances within different frames. Furthermore, we combine Refined Gaussian Mixture Probability Hypothesis Density (RGM-PHD) tracker with the detectors to keep target trajectories and handle uncertainties. The experiments conducted on several video datasets show the effectiveness of our proposed method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yazdian-Dehkordi, Mandi; Azimifar, Zohreh] Shiraz Univ, Sch Elect & Comp Engn, Comp Vis & Pattern Recognit Lab, Shiraz, Iran.
C3 Shiraz University
RP Azimifar, Z (corresponding author), Shiraz Univ, Sch Elect & Comp Engn, Comp Vis & Pattern Recognit Lab, Shiraz, Iran.
EM yazdian@cse.shirazu.ac.ir; azimifar@cse.shirazu.ac.ir
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], SPIE C SERIES
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen J., 2014, IET RADAR SON NAV
   Cosar S, 2014, J VIS COMMUN IMAGE R, V25, P864, DOI 10.1016/j.jvcir.2014.02.004
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Guldogan MB, 2014, DIGIT SIGNAL PROCESS, V27, P1, DOI 10.1016/j.dsp.2014.01.009
   Hajimolahoseini H, 2014, IET COMPUT VIS, V8, P535, DOI 10.1049/iet-cvi.2013.0267
   Harris C., 1988, ALVEY VISION C, P147151
   Jan P, 2014, IEEE RAD CONF, P1084, DOI 10.1109/RADAR.2014.6875756
   Leach MJV, 2014, PATTERN RECOGN LETT, V44, P71, DOI 10.1016/j.patrec.2013.11.018
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li R., 2013, J INFORM COMPUTATION, V10, P2159, DOI [10.12733/jics20101694, DOI 10.12733/JICS20101694]
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Maggio E, 2008, IEEE T CIRC SYST VID, V18, P1016, DOI 10.1109/TCSVT.2008.928221
   Mahler R., 2001, DATA FUSION HDB, P14
   Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119
   Maresca ME, 2013, LECT NOTES COMPUT SC, V8157, P419, DOI 10.1007/978-3-642-41184-7_43
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Min Niu, 2013, Intelligent Computing Theories and Technology. 9th International Conference, ICIC 2013. Proceedings. LNCS 7996, P649, DOI 10.1007/978-3-642-39482-9_75
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Tian B, 2014, IEEE T INTELL TRANSP, V15, P597, DOI 10.1109/TITS.2013.2283302
   Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190
   Walha A, 2014, MULTIMED TOOLS APPL, P1
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang L, 2014, IEEE T INTELL TRANSP, V15, P1886, DOI 10.1109/TITS.2014.2303196
   Wang L, 2012, IEEE T INTELL TRANSP, V13, P691, DOI 10.1109/TITS.2011.2179536
   Wang Xiao, 2012, Control and Decision, V27, P1864
   Wang YD, 2008, IEEE T CIRC SYST VID, V18, P1085, DOI 10.1109/TCSVT.2008.927105
   Yazdian-Dehkordi M, 2012, IET RADAR SONAR NAV, V6, P251, DOI 10.1049/iet-rsn.2011.0038
   Yazdian-Dehkordi M, 2012, SIGNAL PROCESS, V92, P1230, DOI 10.1016/j.sigpro.2011.11.016
   Yazdian-Dehkordi M, 2015, SIGNAL PROCESS, V116, P112, DOI 10.1016/j.sigpro.2015.04.008
   Zhang JM, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P379, DOI 10.1109/AVSS.2012.51
   Zhang L, IEEE T MULTIMEDIA, V16
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhou XL, 2014, IEEE T IND INFORM, V10, P1064, DOI 10.1109/TII.2013.2294156
   Zhou XL, 2014, SIGNAL PROCESS, V94, P650, DOI 10.1016/j.sigpro.2013.08.002
NR 44
TC 2
Z9 2
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 14
EP 24
DI 10.1016/j.jvcir.2015.06.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700003
DA 2024-07-18
ER

PT J
AU Guastella, D
   Valenti, C
AF Guastella, Davide
   Valenti, Cesare
TI Cartoon filter via adaptive abstraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiresolution abstraction; Cartoon filter; Redundant wavelets;
   Circular median filter; Fast multi-scale median; Mathematical
   morphology; Euclidean distance transform; Edge preserving smoothing
ID DISCRETE WAVELET TRANSFORM; IMAGE; ALGORITHM; METHODOLOGY; EDGE
AB The Abstraction in computer graphics defines a procedure that discriminates the essential information that is worth keeping. Usually details, that correspond to higher frequency components, allow to distinguish otherwise similar images. Vice versa, low frequencies are related to the main information, which are larger structures. Contours themselves may also be identified by high frequencies and separate each pictured component. The underlying idea of the proposed algorithm consists in identifying these edges, by a redundant wavelet transform, and in blurring the inner areas of the components, by an adaptive circular median filter. In spite of its implementation simplicity, our unsupervised methodology provides results similar to those obtained by more complex techniques already described in the literature. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Guastella, Davide; Valenti, Cesare] Univ Palermo, Dipartimento Matemat & Informat, I-90133 Palermo, Italy.
C3 University of Palermo
RP Valenti, C (corresponding author), Dipartimento Matemat & Informat, Via Archirafi 34, I-90133 Palermo, Italy.
EM cesare.valenti@unipa.it
RI Guastella, Davide Andrea/AAB-9512-2022; Valenti, Cesare/V-2021-2019
OI Guastella, Davide Andrea/0000-0002-6865-1833; VALENTI, Cesare
   Fabio/0000-0002-4961-2054
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   Ballarò B, 2008, MED IMAGE ANAL, V12, P703, DOI 10.1016/j.media.2008.04.001
   Bellavia F, 2011, IET COMPUT VIS, V5, P87, DOI 10.1049/iet-cvi.2009.0127
   Bellavia F, 2014, COMPUT METH PROG BIO, V114, P240, DOI 10.1016/j.cmpb.2014.02.009
   Bellavia F, 2009, 2009 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2009), P18, DOI 10.1109/PDCAT.2009.45
   Bradski G., 2000, DR DOBBS J SOFTWARE, V25
   Chaudhury KN, 2013, IEEE T IMAGE PROCESS, V22, P1291, DOI 10.1109/TIP.2012.2222903
   Dokládal P, 2011, J VIS COMMUN IMAGE R, V22, P411, DOI 10.1016/j.jvcir.2011.03.005
   Fabbri R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322434
   González-Audícana M, 2005, INT J REMOTE SENS, V26, P595, DOI 10.1080/01431160512331314056
   Jain R., 1995, MACHINE VISION
   Jianbing Shen, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P475, DOI 10.1109/PSIVT.2010.86
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Kyprianidis J. E., 2008, P EG UK THEOR PRACT, P51
   Kyprianidis J.E., 2011, Proc. NPAR '11, P55, DOI [10.1145/2024676.2024686, DOI 10.1145/2024676.2024686]
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Lake C., 2000, Proceedings of the first international symposium on Non-photorealistic animation and rendering-NPAR'00, P13, DOI 10.1145/340916.3409185[27]M.S.
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   Mould D., 2013, COMPUTATIONAL IMAGIN, V42, P125
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Perreault S, 2007, IEEE T IMAGE PROCESS, V16, P2389, DOI 10.1109/TIP.2007.902329
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tian XL, 2015, J VIS COMMUN IMAGE R, V26, P146, DOI 10.1016/j.jvcir.2014.11.005
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Topal C, 2012, J VIS COMMUN IMAGE R, V23, P862, DOI 10.1016/j.jvcir.2012.05.004
   Turkowski K, 1990, GRAPHICS GEMS, P147, DOI DOI 10.1016/B978-0-08-050753-8.50042-5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
NR 35
TC 13
Z9 13
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 149
EP 158
DI 10.1016/j.jvcir.2016.01.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhu, HY
   Meng, FM
   Cai, JF
   Lu, SJ
AF Zhu, Hongyuan
   Meng, Fanman
   Cai, Jianfei
   Lu, Shijian
TI Beyond pixels: A comprehensive survey from bottom-up to semantic image
   segmentation and cosegmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Superpixel; Interactive image segmentation; Object
   proposal; Semantic image parsing; Image cosegmentation; Unsupervised
   image segmentation; Weakly-supervised image segmentation
ID APPROXIMATION; ALGORITHM; TEXTURE; MUMFORD; LAYOUT
AB Image segmentation refers to the process to divide an image into meaningful non-overlapping regions according to human perception, which has become a classic topic since the early ages of computer vision. A lot of research has been conducted and has resulted in many applications. While many segmentation algorithms exist, there are only a few sparse and outdated summarizations available. Thus, in this paper, we aim to provide a comprehensive review of the recent progress in the field. Covering 190 publications, we give an overview of broad segmentation topics including not only the classic unsupervised methods, but also the recent weakly-/semi-supervised methods and the fully-supervised methods. In addition, we review the existing influential datasets and evaluation metrics. We also suggest some design choices and research directions for future research in image segmentation. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhu, Hongyuan; Lu, Shijian] ASTAR, Inst Infocomm Res, Singapore, Singapore.
   [Meng, Fanman] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Peoples R China.
   [Cai, Jianfei] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); University of Electronic Science &
   Technology of China; Nanyang Technological University
RP Cai, JF (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM zhuh@i2r.a-star.edu.sg; fmmeng@uestc.edu.cn; asjfcai@ntu.edu.sg;
   slu@i2r.a-star.edu.sg
RI Lu, Shijian/AAU-4831-2021; Cai, Jianfei/A-3691-2011
OI Lu, Shijian/0000-0002-6766-2506; Cai, Jianfei/0000-0002-9444-3763
FU MoE AcRF Tier-1 Grant [RG30/11]
FX We thank anonymous reviewers' constructive comments for improving the
   manuscript. This research is partially supported by MoE AcRF Tier-1
   Grant RG30/11.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805
   [Anonymous], 2014, BMVC
   [Anonymous], 2012, CVPR
   [Anonymous], 2011, ICCV WORKSH
   [Anonymous], 2005, CVPR
   [Anonymous], 2014, WACV
   [Anonymous], 2014, ACCV
   [Anonymous], 2010, CVPR
   [Anonymous], 2008, ECCV
   [Anonymous], 2012, CVPR
   [Anonymous], 1997, CVPR
   [Anonymous], 2008, IEEE C COMPUTER VISI
   [Anonymous], 2014, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], 2014, CVPR
   [Anonymous], 2010, ECCV
   [Anonymous], 2013, ICCV
   [Anonymous], 2010, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   [Anonymous], 2014, ECCV
   [Anonymous], 2012, ECCV
   [Anonymous], 2014, ECCV
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arbelaez Pablo., 2009, CVPR
   Bai X, 2007, IEEE I CONF COMP VIS, P809
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Beare R, 2006, IEEE T PATTERN ANAL, V28, P1063, DOI 10.1109/TPAMI.2006.132
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Borji A., 14115878 CORR ABS
   Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Braides A, 1997, CALC VAR PARTIAL DIF, V5, P293, DOI 10.1007/s005260050068
   Braides A., 1998, LECT NOTES MATH, V1694
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1
   Brostow G.J., 2008, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-540-88682-2_5
   C Rubio J., 2012, CVPR
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chai Yuning., 2012, ECCV
   Chai Yuning., 2011, ICCV
   CHAMBOLLE A, 1995, SIAM J APPL MATH, V55, P827, DOI 10.1137/S0036139993257132
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   chen Chiu W., 2013, CVPR
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Collins MaxwellD., 2012, CVPR
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Couprie C., 2014, JMLR
   Criminisi A, 2008, ECCV
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Dai JF, 2013, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2013.165
   den Bergh M.V., 2012, ECCV
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Erhan D., 13122249 CORR ABS
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164
   Faliu Yi, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1936, DOI 10.1109/ICSAI.2012.6223428
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Farhadi A., 2010, CVPR
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Floros G., 2011, BMVC
   Freeman W.T., 2011, SODA
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Galleguillos Carolina., 2008, CVPR
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Gould S, 2009, ICCV, DOI [DOI 10.1109/ICCV.2009.5459211, 10.1109/ICCV.2009.5459211]
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Guo R., 2012, ECCV
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Gupta Abhinav., 2008, ECCV
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   He Jia., 2013, INTERACTIVE SEGMENTA
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He XM, 2004, PROC CVPR IEEE, P695
   He XueFeng He XueFeng, 2014, China Rural Survey, P4
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Jain A.K., 2004, ICPR
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Joulin Armand, 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539868
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kappes JorgH., 2013, CVPR
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kim E., 2012, CVPR
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kohli P, 2013, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2013.257
   Kohli P, 2009, IEEE T PATTERN ANAL, V31, P1645, DOI 10.1109/TPAMI.2008.217
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Larlus D., 2008, CVPR
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li H., 2013, ICME
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu MY, 2014, IEEE T PATTERN ANAL, V36, P99, DOI 10.1109/TPAMI.2013.107
   Liu YG, 2012, IEEE T VIS COMPUT GR, V18, P202, DOI 10.1109/TVCG.2011.77
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu J., 2012, CVPR
   Lu J., 2013, P CVPR
   Ma T., 2013, CVPR
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin D. R., 2003, THESIS
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Meila M, 2003, LECT NOTES ARTIF INT, V2777, P173, DOI 10.1007/978-3-540-45167-9_14
   Meng F., 2012, ISCAS
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Mori G., 2005, ICCV
   Mortensen E., 1992, Proceedings of Computer in Cardiology 1992 (Cat. No.92CH3259-9), P635, DOI 10.1109/CIC.1992.269378
   Mortensen E. N., 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Mukherjee Lopamudra., 2011, CVPR
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nguyen T. N. A., IEEE T IMAGE PROCESS, V21
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pfeiffer D, 2010, IEEE INT VEH SYM, P217, DOI 10.1109/IVS.2010.5548114
   Pock T., 2009, CVPR
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Rao S.R., 2009, ACCV
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Rubio J., 2012, ACCV
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Sturgess P., 2009, British Machine Vision Conference, P1, DOI [10.5244/C.23.62, DOI 10.5244/C.23.62]
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tighe J., 2011, ICCV
   Tighe J, 2014, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2014.479
   Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386
   Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z
   Toshev A., 13124659 CORR ABS
   Tsai D., 2010, BMVC, P1, DOI [DOI 10.5244/C.24.56, 10.5244/C.24.56]
   Tu Z.W., 2008, CVPR
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   van de Sande Koen E. A., 2011, IEEE I CONF COMP VIS
   Veksler Olga, 2010, Computer Vision-ECCV 2010, P211, DOI [10.1007/978-3-642-15555-0_16, DOI 10.1007/978-3-642-15555-0_16]
   Vese L.A., INT J COMPUT VISION, V50
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Vicente S, 2008, PROC CVPR IEEE, P767
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Vineet V., 2012, ECCV
   Vineet V, 2014, INT J COMPUT VISION, V110, P290, DOI 10.1007/s11263-014-0708-6
   Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6
   Werlberger M., 2009, SSVM
   Wertheimer M., 1929, PSYCOLOGISCHE FORSCH, P301
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611
   Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739
   Yuan J., 2010, ECCV
   Zhang Y., 2011, ICCV
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zheng S, 2014, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2014.411
   Zhu H., 2015, BMVC
   Zhu H., 2014, ICIP
   Zhu H., 2013, ISCAS
   Zhu HY, 2013, IEEE T IMAGE PROCESS, V22, P4019, DOI 10.1109/TIP.2013.2268973
NR 188
TC 165
Z9 179
U1 2
U2 78
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 12
EP 27
DI 10.1016/j.jvcir.2015.10.012
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Carlos, GD
   Pedrini, H
   Schwartz, WR
AF Carlos, Gerson de Paulo
   Pedrini, Helio
   Schwartz, William Robson
TI Classification schemes based on Partial Least Squares for face
   identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face identification; Partial Least Squares; One-against-none;
   One-against-all; One-against-some; Scalable face recognition;
   Classification schemes; Gallery enrollment
ID CORRELATION FILTER; RECOGNITION; SELECTION; PATTERNS
AB Approaches based on the construction of highly discriminative models, such as one-against-all classification schemes, have been employed successfully in face identification. However, their main drawback is the reduction in the scalability once the models for each individual depend on the remaining subjects. Therefore, when new subjects are enrolled, it is necessary to rebuild all models to take into account the new individuals. This work addresses different classification schemes based on Partial Least Squares employed to face identification. First, the one-against-all and the one-against-some classification schemes are described and, based on their drawbacks, a classification scheme referred to as one-against-none is proposed. This novel approach considers face samples that do not belong to subjects in the gallery. Experimental results show that it achieves similar results to the one-against-all and one-against-some even though it does not depend on the remaining subjects in the gallery to build the models. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Carlos, Gerson de Paulo; Pedrini, Helio] Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
   [Schwartz, William Robson] Univ Fed Minas Gerais, Dept Comp Sci, BR-31270010 Belo Horizonte, MG, Brazil.
C3 Universidade Estadual de Campinas; Universidade Federal de Minas Gerais
RP Schwartz, WR (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, BR-31270010 Belo Horizonte, MG, Brazil.
EM william@dcc.ufmg.br
RI Pedrini, Helio/A-7556-2012; Schwartz, William Robson/E-6612-2011; SILVA,
   EDUARDO/IQS-1403-2023
OI Schwartz, William/0000-0003-1449-8834
FU CAPES; FAPESP; FAPEMIG; CNPq
FX The authors are grateful to CAPES, FAPESP, FAPEMIG and CNPq for the
   financial support.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C
   [Anonymous], IEEE INT C BIOM THEO
   [Anonymous], INT JOINT C BIOM
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Gao YS, 2005, PATTERN RECOGN, V38, P1009, DOI 10.1016/j.patcog.2004.12.006
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jonghyun Choi, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P121, DOI 10.1109/WACV.2012.6163014
   Krzysko M, 2009, EUR J OPER RES, V199, P512, DOI 10.1016/j.ejor.2008.11.009
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Li AN, 2011, PATTERN RECOGN LETT, V32, P1948, DOI 10.1016/j.patrec.2011.07.020
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park SH, 2007, LECT NOTES ARTIF INT, V4701, P658
   Perez CA, 2011, PATTERN RECOGN, V44, P951, DOI 10.1016/j.patcog.2010.10.017
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rifkin R, 2004, J MACH LEARN RES, V5, P101
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Schwartz WR, 2012, IEEE T IMAGE PROCESS, V21, P2245, DOI 10.1109/TIP.2011.2176951
   Schwartz WR, 2010, LECT NOTES COMPUT SC, V6316, P476, DOI 10.1007/978-3-642-15567-3_35
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shih P., 2005, CVPR WORKSHOP, P156
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vasilescu MAO, 2002, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2002.1048350
   Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang SJ, 2011, IEEE T IMAGE PROCESS, V20, P2490, DOI 10.1109/TIP.2011.2121084
   Wold H, 1985, ENCY STAT SCI, P581, DOI DOI 10.1002/0471667196.ESS1914.PUB2
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yan Y, 2014, PATTERN RECOGN, V47, P3487, DOI 10.1016/j.patcog.2014.05.004
   Yan Y, 2013, NEUROCOMPUTING, V119, P201, DOI 10.1016/j.neucom.2013.03.039
   Yao B., 2008, IEEE INT C AUTOMATIC, P1
   Yuan Quan., 2005, CVPR WORKSHOP, P152
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang YongJie Zhang YongJie, 2012, Mycology - An International Journal on Fungal Biology, V3, P2
   Zhou HY, 2011, IEEE T SYST MAN CY C, V41, P577, DOI 10.1109/TSMCC.2010.2051328
NR 52
TC 6
Z9 6
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 170
EP 179
DI 10.1016/j.jvcir.2015.08.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300014
DA 2024-07-18
ER

PT J
AU Du, HS
   Hu, QP
   Jiang, MM
   Zhang, F
AF Du, Haishun
   Hu, Qingpu
   Jiang, Manman
   Zhang, Fan
TI Two-dimensional principal component analysis based on Schatten
   <i>p</i>-norm for image feature extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Schatten p-norm; Frebenius-norm; Two-dimensional principal component
   analysis (2DPCA); Dimensionality reduction; Feature extraction; Subspace
   learning; Image classification; Convex optimization
ID DISCRIMINANT-ANALYSIS; FACE RECOGNITION; ILLUMINATION; EIGENFACES
AB In this paper, we propose a novel Schatten p-norm-based two-dimensional principal component analysis (2DPCA) method, which is named after 2DPCA-Sp, for image feature extraction. Different from the conventional 2DPCA that is based on Frobenius-norm, 2DPCA-Sp learns an optimal projection matrix by maximizing the total scatter criterion based on Schatten p-norm in the low-dimensional feature space. Since p can take different values, 2DPCA-Sp is regarded as a general framework of 2DPCA. We also propose an iterative algorithm to solve the optimization problem of 2DPCA-Sp with 0 < p < 1, which is simple, effective, and easy to implement. Experimental results on several popular image databases show that 2DPCA-Sp with 0 < p < 1 is robust to impact factors (e.g. illuminations, view directions, and expressions) of images. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Du, Haishun; Hu, Qingpu; Jiang, Manman; Zhang, Fan] Henan Univ, Inst Image Proc & Pattern Recognit, Kaifeng 475004, Peoples R China.
C3 Henan University
RP Du, HS (corresponding author), Henan Univ, Inst Image Proc & Pattern Recognit, Kaifeng 475004, Peoples R China.
EM jddhs@henu.edu.cn
OI Du, Haishun/0000-0003-0883-8118
FU National Natural Science Foundation of China [61374134, 61304132]; key
   Scientific Research Project of Universities in Henan Province, China
   [15A413009]
FX We would like to thank all reviewers and editors for their detailed
   reviews, constructive suggestions and valuable comments. This work is
   supported in part by the National Natural Science Foundation of China
   (Nos. 61374134 and 61304132) and the key Scientific Research Project of
   Universities in Henan Province, China (No. 15A413009).
CR [Anonymous], MODERN MACHINE LEARN
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Chen SB, 2007, NEUROCOMPUTING, V70, P912, DOI 10.1016/j.neucom.2006.10.032
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Feiping Nie, 2015, Knowledge and Information Systems, V42, P525, DOI 10.1007/s10115-013-0713-z
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gu ZH, 2012, INT C PATT RECOG, P1213
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Ke QF, 2005, PROC CVPR IEEE, P739
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Kwak N, 2014, IEEE T CYBERNETICS, V44, P594, DOI 10.1109/TCYB.2013.2262936
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li X, 2010, NEUROCOMPUTING, V73, P2571, DOI 10.1016/j.neucom.2010.05.016
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lu CY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380155
   Luo L, 2014, COMM COM INF SC, V483, P140
   Nie F., 2011, P INT JOINT C ART IN
   Nie F., 2012, AAAI, P655
   Nie FP, 2012, IEEE DATA MINING, P566, DOI 10.1109/ICDM.2012.160
   Pang YW, 2008, IEEE T SYST MAN CY B, V38, P1176, DOI 10.1109/TSMCB.2008.923151
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Wang JG, 2008, NEUROCOMPUTING, V72, P352, DOI 10.1016/j.neucom.2008.01.004
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   XU L, 1995, IEEE T NEURAL NETWOR, V6, P131, DOI 10.1109/72.363442
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yu J, 2014, PATTERN RECOGN, V47, P3512, DOI 10.1016/j.patcog.2014.05.002
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang FL, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P74, DOI 10.1109/ACPR.2013.10
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 40
TC 8
Z9 8
U1 1
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 55
EP 62
DI 10.1016/j.jvcir.2015.07.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300004
DA 2024-07-18
ER

PT J
AU Kim, W
   Park, GS
   Song, H
AF Kim, Wan
   Park, Gi Seok
   Song, Hwangjun
TI An effective cross-layer designed packet scheduling, call admission
   control, and handover system for video streaming services over LTE
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video streaming service; Quality-of-Experience; LTE network; Packet
   scheduling; Call admission control; Handover; Cross-layer designed
   system; Cell availability
ID WIRELESS; PERFORMANCE; ALLOCATION; ISSUES
AB This paper presents an effective cross-layer designed packet scheduling, call admission control, and handover system to provide a seamless video streaming services over LTE network. The proposed packet scheduling algorithm allocates wireless network resources to admitted UEs while considering QoE states and wireless link states of UEs simultaneously. The proposed call admission control algorithm estimates the cell availability at the next call arriving time based on the current QoE states of UEs to determine the admission of a new UE. The proposed handover algorithm determines the appropriate handover trigger timing to keep a balance of the QoE states among immediately adjacent cells based on both the cell availability and wireless link states. Finally, simulations are conducted to evaluate the performance of the proposed system. Results indicate that the proposed cross-layer designed system improves the QoE states of all admitted UEs and overall network utilization better than other existing methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kim, Wan] Samsung Elect Co Ltd, Software R&D Ctr, Cloud Technol Lab, Suwon, South Korea.
   [Park, Gi Seok] POSTECH Pohang Univ Sci & Technol, Dept IT Convergence Engn, Pohang 790784, South Korea.
   [Song, Hwangjun] POSTECH Pohang Univ Sci & Technol, Comp Sci & Engn, Pohang 790784, South Korea.
C3 Samsung; Samsung Electronics; Pohang University of Science & Technology
   (POSTECH); Pohang University of Science & Technology (POSTECH)
RP Song, H (corresponding author), POSTECH Pohang Univ Sci & Technol, Comp Sci & Engn, Pohang 790784, South Korea.
EM wan318.kim@samsung.com; kiseok@postech.ac.kr; hwangjun@postech.ac.kr
FU ICT R&D program of MSIP/IITP [13-911-04-005]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Education [NRF-2013R1A1A2006732]
FX This work was partly supported by the ICT R&D program of MSIP/IITP
   [13-911-04-005, Research and Development of 5G Mobile Communications
   Technologies using CCN-based Multi-dimensional Scalability] and Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education (NRF-2013R1A1A2006732).
CR *3GPP, 25814 3GPP TS
   [Anonymous], 2012, CISCO VISUAL NETWORK
   Aziz D., 2009, P VEH TECHN C
   Aziz D, 2010, BELL LABS TECH J, V15, P63, DOI 10.1002/bltj.20457
   Baldo N., 2011, P 14 ACM INT C MOD A
   Basukala R., 2009, AH ICI 2009, P1, DOI DOI 10.1109/AHICI.2009.5340336
   Capozzi F, 2013, IEEE COMMUN SURV TUT, V15, P678, DOI 10.1109/SURV.2012.060912.00100
   Cha M, 2008, IMC'08: PROCEEDINGS OF THE 2008 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P71
   Chowdhury MZ, 2013, J COMMUN NETW-S KOR, V15, P15
   Fang YG, 2002, IEEE T VEH TECHNOL, V51, P371, DOI 10.1109/25.994812
   Ge Y., 2006, P IEEE VEH TECHN C
   Hansen P, 2010, ANN OPER RES, V175, P367, DOI 10.1007/s10479-009-0657-6
   Haupt R.L., 2004, PRACTICAL GENETIC AL, DOI [10.1002/0471671746, DOI 10.1002/0471671746]
   Inlet Media Corporation, FLVTOOL2 FLASH VID M
   Jansen T, 2010, IEEE VTS VEH TECHNOL
   Jeon WS, 2006, IEEE T VEH TECHNOL, V55, P1582, DOI 10.1109/TVT.2006.878562
   Jeong S. S., 2005, P IEEE VEH TECHN C
   Kang CG, 2008, IEEE COMMUN LETT, V12, P241, DOI 10.1109/LCOMM.2008.071984
   Karachontzitis S, 2011, IEEE INT CON MULTI
   Khanjaril S. A., 2011, INT J COMMUN SYST, V26, P811
   Kim H., 2004, P VEH TECHN C
   Kim J, 2012, IEEE GLOB COMM CONF, P4816, DOI 10.1109/GLOCOM.2012.6503881
   Kitagawa K., 2011, P PERS IND MOB RAD C
   Kwan R, 2009, IEEE SIGNAL PROC LET, V16, P461, DOI 10.1109/LSP.2009.2016449
   Lai WK, 2013, COMPUT NETW, V57, P1689, DOI 10.1016/j.comnet.2013.02.017
   Lee J., 2010, P GLOB TEL C
   Lee JY, 2008, IEEE WCNC, P2003
   Legg P, 2010, IEEE VTS VEH TECHNOL
   Li W, 2002, IEEE T WIREL COMMUN, V1, P682, DOI 10.1109/TWC.2002.804191
   Liu B, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P364, DOI 10.1109/CCNC.2013.6488471
   Lobinger A, 2011, P VEH TECHN C
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Muñoz P, 2013, IEEE T VEH TECHNOL, V62, P1895, DOI 10.1109/TVT.2013.2247778
   Navarro-Ortiz J, 2013, IEEE COMMUN LETT, V17, P677, DOI 10.1109/LCOMM.2013.021913.122716
   Niyato D, 2005, IEEE NETWORK, V19, P5, DOI 10.1109/MNET.2005.1509946
   Niyato D., 2007, IEEE T WIRELESS COMM, V6
   Niyato D., 2005, P IEEE GLOB TEL C
   Osti P, 2014, IEEE T VEH TECHNOL, V63, P4357, DOI 10.1109/TVT.2014.2314532
   Piro G, 2011, IEEE T VEH TECHNOL, V60, P498, DOI 10.1109/TVT.2010.2091660
   Porter T, 2011, IEEE COMMUN LETT, V15, P76, DOI 10.1109/LCOMM.2010.110310.101642
   Qian M., 2009, P IEEE GLOB TEL C
   Ramli HAM, 2009, 2009 IEEE 9TH MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P815, DOI 10.1109/MICC.2009.5431383
   Rardin R. L., 1998, Optimization in Operations Research
   Raychaudhuri D, 2012, P IEEE, V100, P824, DOI 10.1109/JPROC.2011.2182095
   Sohn K. H., 2006, P INFOCOM 2006 APR, P1
   Sripanidkulchai K, 2004, P 4 ACM SIGCOMM C IN
   Tso FP, 2012, IEEE T PARALL DISTR, V23, P1895, DOI 10.1109/TPDS.2011.289
   Tyagi RR, 2017, IEEE SYST J, V11, P2383, DOI 10.1109/JSYST.2014.2387371
   Yi Li, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), P196, DOI 10.1109/ICSESS.2012.6269439
   Zhou N, 2010, IEEE T WIREL COMMUN, V9, P1912, DOI 10.1109/TWC.2010.06.081595
NR 50
TC 6
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 335
EP 346
DI 10.1016/j.jvcir.2015.07.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600030
DA 2024-07-18
ER

PT J
AU Ding, RX
   Du, DK
   Huang, ZH
   Li, ZM
   Shang, K
AF Ding, Ru-Xi
   Du, Daniel K.
   Huang, Zheng-Hai
   Li, Zhi-Ming
   Shang, Kun
TI Variational Feature Representation-based Classification for face
   recognition with single sample per person
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Single sample per person; Generic learning;
   Variational Feature Representation; Face image; Normal feature; Linear
   regression; Non-ideal conditions
ID LINEAR-REGRESSION; TRAINING SAMPLE; IMAGE; ILLUMINATION; EIGENFACES;
   ALGORITHMS; FLDA
AB The single sample per person (SSPP) problem is of great importance for real-world face recognition systems. In SSPP scenario, there is always a large gap between a normal sample enrolled in the gallery set and the non-ideal probe sample. It is a crucial step for face recognition with SSPP to bridge the gap between the ideal and non-ideal samples. For this purpose, we propose a Variational Feature Representation-based Classification (VFRC) method, which employs the linear regression model to fit the variational information of a non-ideal probe sample with respect to an ideal gallery sample. Thus, a corresponding normal feature, which reserve the identity information of the probe sample, is obtained. A combination of the normal feature and the probe sample is used, which makes VFRC method more robust and effective for SSPP scenario. The experimental results show that VFRC method possesses higher recognition rate than other related face recognition methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ding, Ru-Xi; Du, Daniel K.; Huang, Zheng-Hai; Li, Zhi-Ming; Shang, Kun] Tianjin Univ, Ctr Appl Math, Tianjin 300072, Peoples R China.
   [Ding, Ru-Xi; Huang, Zheng-Hai; Li, Zhi-Ming] Tianjin Univ, Sch Sci, Dept Math, Tianjin 300072, Peoples R China.
   [Du, Daniel K.] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University; Tianjin University; Tianjin University
RP Li, ZM (corresponding author), Tianjin Univ, Sch Sci, Dept Math, Tianjin 300072, Peoples R China.
EM dingruxi@tju.edu.cn; daniel@tju.edu.cn; huangzhenghai@tju.edu.cn;
   lizm@tju.edu.cn; skun@tju.edu
RI Huang, Zheng-Hai/F-8646-2012
FU National Natural Science Foundations of China [11171252, 11431002]
FX This work was partially supported by the National Natural Science
   Foundations of China (Grants 11171252 and 11431002).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2004, DISCRIMINANT ANAL ST
   [Anonymous], 1998, AR FACE DATABASE
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Chen SB, 2014, J VIS COMMUN IMAGE R, V25, P1800, DOI 10.1016/j.jvcir.2014.07.007
   Chen YM, 2010, NEUROCOMPUTING, V73, P3089, DOI 10.1016/j.neucom.2010.06.007
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang ZH, 2015, INFORM FUSION, V22, P95, DOI 10.1016/j.inffus.2014.06.001
   Hui-ning Qiu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1023, DOI 10.1109/ICPR.2010.256
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lu C., 2006, P 25 CHIN CONTR C HA, P2215
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lu JW, 2013, IEEE T CIRC SYST VID, V23, P1070, DOI 10.1109/TCSVT.2013.2241353
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Qiu HN, 2011, INT J INNOV COMPUT I, V7, P5645
   Shahamat H, 2014, J VIS COMMUN IMAGE R, V25, P970, DOI 10.1016/j.jvcir.2014.02.007
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang B, 2013, NEUROCOMPUTING, V115, P186, DOI 10.1016/j.neucom.2013.02.004
   Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan HB, 2014, NEUROCOMPUTING, V143, P134, DOI 10.1016/j.neucom.2014.06.012
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 39
TC 26
Z9 26
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 35
EP 45
DI 10.1016/j.jvcir.2015.03.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900004
DA 2024-07-18
ER

PT J
AU Ma, XX
   Pan, ZB
   Hu, S
   Wang, LF
AF Ma, Xiaoxiao
   Pan, Zhibin
   Hu, Sen
   Wang, Lingfei
TI New high-performance reversible data hiding method for VQ indices based
   on improved locally adaptive coding scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Reversible data hiding; Vector quantization (VQ); Locally
   adaptive coding scheme; Improved locally adaptive coding scheme (ILAS);
   Codebook sorting; Index correlation; Region complexity
AB In this paper, a new high-performance reversible data hiding method for vector quantization (VQ) indices is proposed. The codebook is firstly sorted using the unidirectional static distance-order technique to improve the correlation among the neighboring indices. The two-dimensional structure of image and the high correlation among the neighboring blocks are used to update the self-organized list L in the improved locally adaptive coding scheme (ILAS). Then a new embedding rule according to the complexity of the region at which the current block locates and the position of current block index in the list L is proposed to obtain a better embedding capacity. The experimental results demonstrate that our proposed method has a better performance in terms of compression rate, embedding capacity and embedding rate compared with the related data hiding methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ma, Xiaoxiao; Pan, Zhibin; Hu, Sen; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of the National Laboratory of Pattern
   Recognition [201407370]; Open Project Program of the State Key Lab of
   SKL, Nanjing University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30), Open Project Program of the National Laboratory
   of Pattern Recognition (Grant No. 201407370) and Open Project Program of
   the State Key Lab of SKL (Grant No. KFKT2013B05), Nanjing University.
CR [Anonymous], ASSP MAG
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   [高风娟 Gao Fengjuan], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1967
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Wu HC, 2009, J SYST SOFTWARE, V82, P1966, DOI 10.1016/j.jss.2009.06.056
   Yang CH, 2011, J SYST SOFTWARE, V84, P388, DOI 10.1016/j.jss.2010.11.924
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
NR 23
TC 4
Z9 4
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 191
EP 200
DI 10.1016/j.jvcir.2015.04.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900017
DA 2024-07-18
ER

PT J
AU Korfiatis, VC
   Asvestas, PA
   Matsopoulos, GK
AF Korfiatis, Vasileios Ch
   Asvestas, Pantelis A.
   Matsopoulos, George K.
TI Automatic local parameterization of the Chan Vese active contour model's
   force coefficients using edge information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geometric active contours; Chan Vese algorithm; Automatic coefficient
   determination; Edge information; Automatic local ratio; Gaussian
   regularization; Fast edge integration algorithms; Edge transformation
   map
ID IMAGE SEGMENTATION; REGION; FORMULATION; EVOLUTION; MUMFORD
AB Image segmentation is an important field of computer vision that includes algorithms that segment images into foreground and background. Active Contours (AC) is a family of segmentation techniques that has gained high popularity in recent years due to the advantages it provides, including contour deformation, detail preservation and multiple objects identification. One of the most popular AC algorithms is the Chan-Vese (CV) algorithm, which uses region information. This paper presents a novel algorithmic scheme named Automatic Local Ratio (ALR) that extends the original CV algorithm in order to automatically determine its force coefficient's values, using edge information. Moreover, due to the use of edge information, this scheme provides an alternative to typical edge stopping functions. The proposed scheme is tested on real images, providing superior performance both in terms of qualitative and quantitative results compared to the CV using Gaussian regularization, the SBGFRLS and Fast Edge Integration algorithms. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Korfiatis, Vasileios Ch; Matsopoulos, George K.] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-10682 Athens, Greece.
   [Asvestas, Pantelis A.] Technol Educ Inst Athens, Fac Technol Applicat, Dept Biomed Engn, Athens, Greece.
C3 National Technical University of Athens; University of West Attica
RP Matsopoulos, GK (corresponding author), 9 Iroon Polytech Str, Athens 15780, Greece.
EM gmatso@esd.ece.ntua.gr
RI Asvestas, Pantelis/U-8912-2019
OI Asvestas, Pantelis/0000-0002-0570-0909
CR Allili MS, 2007, PATTERN RECOGN LETT, V28, P1946, DOI 10.1016/j.patrec.2007.05.002
   [Anonymous], 2002, SURFACES
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   Bogovic JA, 2013, COMPUT VIS IMAGE UND, V117, P145, DOI 10.1016/j.cviu.2012.10.006
   Brown ES, 2012, INT J COMPUT VISION, V98, P103, DOI 10.1007/s11263-011-0499-y
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Derraz F., 2012, THEORY TOOLS APPL
   Derraz F, 2009, IEEE IMAGE PROC, P3005, DOI 10.1109/ICIP.2009.5413423
   Kaibin Wang, 2011, 2011 International Conference on Multimedia Technology, P2649
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   Li DY, 2013, J VIS COMMUN IMAGE R, V24, P522, DOI 10.1016/j.jvcir.2013.03.007
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   Shi Y., 2005, COMPUTER VISION
   Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181
   Sundaramoorthi G, 2007, INT J COMPUT VISION, V73, P345, DOI 10.1007/s11263-006-0635-2
   Sundaramoorthi G, 2009, INT J COMPUT VISION, V84, P113, DOI 10.1007/s11263-008-0133-9
   Szeliski R., 2011, COMPUTER VISION ALGO
   Tian Y, 2013, MACH VISION APPL, V24, P47, DOI 10.1007/s00138-011-0363-7
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zhang KH, 2010, IEEE IMAGE PROC, P4105, DOI 10.1109/ICIP.2010.5651554
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 35
TC 7
Z9 7
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 71
EP 78
DI 10.1016/j.jvcir.2015.02.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100007
DA 2024-07-18
ER

PT J
AU Tommasi, F
   De Luca, V
   Melle, C
AF Tommasi, Franco
   De Luca, Valerio
   Melle, Catiuscia
TI Packet losses and objective video quality metrics in H.264 video
   streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video quality metric; Video over IP; Video streaming; Video encoding;
   Quality of experience; Packet loss; Video quality optimization; Video
   quality impairments
ID LOSS VISIBILITY; FRAME RATE; EXPERIENCE; IPTV; TRANSMISSION; PSNR
AB Video quality is a key factor in modern video streaming systems. Video compression artifacts affect it but also delay, jitter and packet loss may compromise it. Objective metrics have been proposed to emulate the human visual system: several experimental works have evaluated their adherence to opinions expressed by real users. Instead of dealing with subjective tests, we focused on the effects of network packet losses on objective metrics: since quality metrics are generally computationally intensive, a convenient approach could consist in inferring information about transmission quality from network impairment statistics. We did experimental tests on two computer-animated videos, whose high color contrasts allow a fair comparison between content dependent and content independent metrics. We studied the encoding parameters that minimize/maximize the values of some metrics (PSNR, BI-PSNR, SSIM, 3SSIM, MSSSIM, VQM) for several packet loss percentages. We analyzed also the Empirical Cumulative Density Function of the degradations of quality metrics. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Tommasi, Franco; De Luca, Valerio; Melle, Catiuscia] Univ Salento, Dept Engn Innovat, I-73100 Lecce, Italy.
C3 University of Salento
RP Tommasi, F (corresponding author), Univ Salento, Dept Engn Innovat, I-73100 Lecce, Italy.
EM franco.tommasi@unisalento.it; valerio.deluca@unisalento.it;
   catiuscia.melle@unisalento.it
RI De Luca, Valerio/JBJ-2116-2023; De Luca, Valerio/HGJ-6239-2022; Tommasi,
   Franco/N-9334-2015
OI De Luca, Valerio/0000-0003-3018-7251; Tommasi,
   Franco/0000-0003-2419-7381
FU Programma Operativo Nazionale (PON) Ricerca e Competitivita
FX This work has been partially supported by a grant from Programma
   Operativo Nazionale (PON) Ricerca e Competitivita 2007-2013. PON
   254/Ric. Potenziamento del CENTRO RICERCHE PER LA SALUTE DELL'UOMO E
   DELL'AMBIENTE Cod. PONa3_00334. CUP: F81D11000210007.
CR Abdeljaouad I., 2011, Proc. IEEE Global Telecommunications Conference, P1
   Abdeljaouad I, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P190, DOI 10.1109/CCNC.2013.6488445
   Ali I, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P118, DOI 10.1109/ICCE.2012.6161768
   Almesberger Werner, 1999, LINUX NETWORK TRAFFI
   [Anonymous], Categorical image quality (CSIQ) database
   [Anonymous], 2005, SUBJECTIVE QUALITY A
   [Anonymous], 2011, P 20 IEEE INT C COMP
   [Anonymous], CHILD CARE HLTH DEV
   [Anonymous], TENCON 2006 2006 IEE
   [Anonymous], P 9 IEEE INT C COMP
   [Anonymous], MICT image quality evaluation database
   ARIF A, 2010, 2 INT C ED TECHN COM, V5
   BAILEY C, 2012, IEEE INT C MULT EXP, P818
   Begen A., 2009, RTP PAYLOAD FORMAT N
   Begen AC, 2008, CONSUM COMM NETWORK, P632, DOI 10.1109/ccnc08.2007.146
   Born RT, 2005, ANNU REV NEUROSCI, V28, P157, DOI 10.1146/annurev.neuro.26.041002.131052
   Boulos F, 2009, 4 INT WORKSH VID PRO
   Brunnstrom Kjell, 2009, IEEE Signal Processing Magazine, V26, P96, DOI 10.1109/MSP.2009.932162
   BUSTAMANTE MJ, 2010, COMPARISON ALGORITHM
   Cermak GW, 2009, INT WORK QUAL MULTIM, P41, DOI 10.1109/QOMEX.2009.5246980
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   da Silva APC, 2008, IEEE ICC, P22, DOI 10.1109/ICC.2008.13
   DAI Q, 2011, 11 INT C TEL CONT P, P495
   Degrande N, 2008, BELL LABS TECH J, V13, P35, DOI 10.1002/bltj.20281
   FEGHALI R, 2005, IEEE INT C IM PROC 2, V3
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Garcia M. N., 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P349, DOI 10.1109/ISSPA.2010.5605528
   GONCALVES T, 2010, INT WORKSH QUAL EXP
   Gross J, 2004, COMPUT COMMUN, V27, P1044, DOI 10.1016/j.comcom.2004.01.010
   HOHLFELD O, 2009, KOMMUNIKATION VERTEI, P320
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   International Telecommunication Union (ITU), 1996, ITU-T Recommendation P.830
   *ITU R, 50012 ITUR BT
   Jae Cheol Kwon, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P224, DOI 10.1109/QOMEX.2010.5516127
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kanumuri S, 2006, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2006.312809
   Kei CH, 2008, J INF SCI ENG, V24, P425
   KHORSANDROO S, 2012, 4 INT C UB FUT NETW, P352
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Kohler E., 2006, DATAGRAM CONGESTION
   KREJCI J, 2009, 16 INT C SYST SIGN I, P1
   Li CF, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267087
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   LIAO N, 2005, 6 INT C PAR DISTR CO, P1039
   Lie A, 2008, MULTIMEDIA SYST, V14, P33, DOI 10.1007/s00530-007-0110-0
   Liu T, 2007, IEEE CONF WIREL MOB
   MOCCAGATTA I, 2002, ARBITRARY SLICE ORDE
   Mohamed S, 2002, IEEE T CIRC SYST VID, V12, P1071, DOI 10.1109/TCSVT.2002.806808
   Moorthy AK, 2010, PROC SPIE, V7527, DOI 10.1117/12.844198
   Ninassi A, 2006, PROC SPIE, V6057, DOI 10.1117/12.650780
   Ou YF, 2008, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2008.4711848
   PASTRANAVIDAL R, 2004, TEMPORAL MASKING EFF
   PASTRANAVIDAL R, 2004, SPORADIC FRAME DROPP
   Paxson V, 1997, PROCEEDINGS OF THE 1997 WINTER SIMULATION CONFERENCE, P1037, DOI 10.1145/268437.268737
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Ponomarenko N., 2008, Tampere image database
   PONOMARENKO N, 2009, 4 INT WORKSH QUAL ME
   Reibman A. R, 2007, PACKET VIDEO, P308
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   SALSANO S, 2012, 31 U ROM TOR VERG
   Seeling P, 2012, IEEE COMMUN SURV TUT, V14, P1142, DOI 10.1109/SURV.2011.082911.00067
   Serral-Gracià R, 2010, LECT NOTES COMPUT SC, V6074, P252
   SESHADRINATHAN K, 2009, HUMAN VISION ELECT I, V7240
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh H. R., IMAGE VIDEO QUALITY
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   STILLER B, 2006, TR126 DSL FOR
   Stocker AA, 2006, NAT NEUROSCI, V9, P578, DOI 10.1038/nn1669
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   SYED Y, 2002, JVTD121
   Tasaka S., 2008, Proceedings of ACM international conference on Multimedia, MULTIMEDIA'08, P259
   Tommasi F, 2013, INT CONF UBIQ FUTUR, P418, DOI 10.1109/ICUFN.2013.6614853
   UCAR I, 2012, IEEE INT S BROADB MU, P1
   Venkata M.G., 2009, IPDPS 2009. IEEE International Symposium on Parallel Distributed Processing, P1
   VERA DD, 2007, P 7 IEEE INT C IP OP, P131
   Wang L., 2012, 2012 URSI Benelux Conference on Telecommuication and Microwaves, P1
   Wang Z, 2005, INT CONF ACOUST SPEE, P573
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Wang Z, 2006, IEEE IMAGE PROC, P2945, DOI 10.1109/ICIP.2006.313136
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   WENGER S, 2002, JVTC089
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler S, 2009, 7 INT C INF COMM SIG, P1
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xiao F., DCT BASED VIDEO QUAL
   Zecic J., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P573
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   [No title captured]
NR 94
TC 16
Z9 16
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2015
VL 27
BP 7
EP 27
DI 10.1016/j.jvcir.2014.12.003
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CA5SI
UT WOS:000348967700002
DA 2024-07-18
ER

PT J
AU Yuan, Y
   Lu, WM
   Wu, F
   Zhuang, YT
AF Yuan, Ying
   Lu, Weiming
   Wu, Fei
   Zhuang, Yueting
TI Multiple kernel learning with NOn-conVex group spArsity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple kernel learning; Non-convex group sparsity; Consistent;
   Canonical correlation analysis; Image annotation; Feature selection;
   Image understanding; Oracle model
ID NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; IMAGE ANNOTATION;
   REGRESSION; LASSO
AB As the high-dimensional heterogeneous visual features extracted from images are intrinsically embedded in a non-linear space, some kernel methods such as SVM have been proposed to solve this problem. Since different kinds of heterogeneous features in images have different intrinsic discriminative powers for image understanding, how to enforce grouping sparsity penalty to effectively select out discriminative heterogeneous visual features is critical for image understanding. Most existing approaches are using a convex penalty for feature selection, which easily leads to inconsistent selection. To guarantee a consistent selection for heterogeneous features embedded in a non-linear space, this paper proposes a new approach called MKL-NOVA (Multiple Kernel Learning with NOn-conVex group spArsity). Because MKL-NOVA conducts a non-convex penalty for the selection of groups of features, it achieves the consistent selection. Furthermore, considering the contextual correlation between multi labels, sparse canonical correlation analysis is conducted to boost the image annotation performance by MKL-NOVA. We have demonstrated the superior performance of MKL-NOVA via two experiments in the paper. First, we showed that MKL-NOVA converges to the true underlying model by using a ground-truth-available generative-model simulation. Second, we compare the proposed MKL-NOVA and the state-of-the-art approaches which showed that MKL-NOVA achieved the best performance. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yuan, Ying] Zhejiang Police Coll, Comp & Informat Technol Dept, Hangzhou, Zhejiang, Peoples R China.
   [Lu, Weiming; Wu, Fei; Zhuang, Yueting] Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Police College; Zhejiang University
RP Lu, WM (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
EM yuanying8011@gmail.com; luwm@zju.edu.cn; wufei@cs.zju.edu.cn;
   yzhuang@cs.zju.edu.cn
FU National Basic Research Program of China [2012CB316400]; NSFC [61103099,
   61105074]; Fundamental Research Funds for the Central Universities;
   Chinese Knowledge Center of Engineering Science and Technology (CKCEST);
   Program for New Century Excellent Talents in University; Zhejiang
   Provincial Natural Science Foundation [LQ14F010004, LY14F020027]
FX This work is supported in part by National Basic Research Program of
   China (2012CB316400), NSFC (61103099, 61105074), the Fundamental
   Research Funds for the Central Universities and Chinese Knowledge Center
   of Engineering Science and Technology (CKCEST) and Program for New
   Century Excellent Talents in University, Zhejiang Provincial Natural
   Science Foundation (LQ14F010004, LY14F020027).
CR [Anonymous], ARXIV10010736
   [Anonymous], P 20 ACM INT C MULT
   [Anonymous], 2004, P 21 INT C MACH LEAR
   Bach FR, 2008, J MACH LEARN RES, V9, P1179
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Friedman J., TECHNICAL REPORT
   Gao C., 2011, P AAAI C ARTIFICIAL, V25, P356
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Jacob L., 2009, P 26 ANN INT C MACH, P433, DOI DOI 10.1145/1553374.1553431
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Li H, 2009, INT CONF DAT MIN WOR, P164, DOI 10.1109/ICDMW.2009.46
   Liu H., 2009, Journal of Machine Learning Research, P376
   Loui Alexander., 2007, MIR 07, P245
   Shen HF, 2010, IEEE INT CON MULTI, P980, DOI 10.1109/ICME.2010.5583900
   Shen J, 2013, IEEE INT CON MULTI
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wei FR, 2010, BERNOULLI, V16, P1369, DOI 10.3150/10-BEJ252
   Wu F, 2012, INT J MULTIMED INF R, V1, P3, DOI 10.1007/s13735-012-0001-9
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Yuan Y, 2013, J VIS COMMUN IMAGE R, V24, P95, DOI 10.1016/j.jvcir.2012.02.007
   Yuzhu Zhou, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P404, DOI 10.1109/ICNIDC.2010.5657800
   Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729
   Zhang DS, 2013, J VIS COMMUN IMAGE R, V24, P1087, DOI 10.1016/j.jvcir.2013.07.004
   Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802
   Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735
NR 29
TC 0
Z9 0
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1616
EP 1624
DI 10.1016/j.jvcir.2014.08.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100012
DA 2024-07-18
ER

PT J
AU Guo, JM
   Prasetyo, H
AF Guo, Jing-Ming
   Prasetyo, Heri
TI False-positive-free SVD-based image watermarking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE False positive problem; Image watermarking; Singular Value Decomposition
   (SVD); Shuffled SVD (SSVD); Data hiding; Authentication; Image security;
   Spread spectrum
ID SINGULAR-VALUE DECOMPOSITION; DISCRETE WAVELET TRANSFORM; SCHEME
AB The need of copyright protection and rightful ownership become very urgent in the fast growing Internet environment. The watermarking offers a convenient way to hide specific information via an imaging system for the consumer electronic devices such as digital camera, scanner, and printer. Numerous efforts have been devoted in the Singular Value Decomposition (SVD)-based image watermarking schemes which embed the visual watermark image into the host image before publishing for public usage. However, the main drawback of the SVD-based image watermarking is its false positive problem of which an attacker can easily claim and obtain the correct watermark from an unauthorized image. In this paper, we proposed a new SVD-based image watermarking by embedding the principal component of a watermark into the host image of block based manner using spread spectrum concept. The experimental results demonstrate that the proposed method overcomes the false positive problem, achieves a high payload, and outperforms the former reliable SVD-based watermarking. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Guo, Jing-Ming; Prasetyo, Heri] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jmguo@seed.net.tw; heri_inf_its_02@yahoo.co.id
RI Prasetyo, Heri/AAD-2388-2022
OI Prasetyo, Heri/0000-0002-1257-4832
CR Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Ali M., 2013, ENG APPL ARTIF INTEL
   Ali M., 2013, OPT INT J LIGHT ELEC
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   Bhatnagar G, 2013, MATH COMPUT MODEL, V58, P204, DOI 10.1016/j.mcm.2012.06.002
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Bhatnagar G, 2012, AEU-INT J ELECTRON C, V66, P275, DOI 10.1016/j.aeue.2011.08.005
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Cox I.J., 1997, IEEE TRANS IMAGE PRO, V6
   Dogan S, 2011, ADV ENG SOFTW, V42, P336, DOI 10.1016/j.advengsoft.2011.02.012
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Guo JM, 2007, IEEE T MULTIMEDIA, V9, P687, DOI 10.1109/TMM.2007.895678
   Guo JM, 2013, I SYMP CONSUM ELECTR, P217
   Guo JM, 2010, IEEE T IMAGE PROCESS, V19, P2056, DOI 10.1109/TIP.2010.2045709
   Guo JM, 2010, IEEE MULTIMEDIA, V17, P34
   Guo JM, 2009, SIGNAL PROCESS, V89, P1864, DOI 10.1016/j.sigpro.2009.03.013
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Jain C, 2008, RELIABLE SVD BASED W
   Lagzian S., 2011, 2011 International Symposium on Artificial Intelligence and Signal Processing (AISP), P48, DOI 10.1109/AISP.2011.5960985
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Ouhsain M, 2009, EXPERT SYST APPL, V36, P2123, DOI 10.1016/j.eswa.2007.12.046
   Ranade A, 2007, IMAGE VISION COMPUT, V25, P771, DOI 10.1016/j.imavis.2006.07.004
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Sadek RA, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2, P140, DOI 10.1109/CIMCA.2008.53
   Sheikh H.R., Live Image Quality Assessment Database
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Xiong CZ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P2596, DOI 10.1109/ICMA.2009.5246754
   Xiong CZ, 2008, IEEE IMAGE PROC, P437, DOI 10.1109/ICIP.2008.4711785
   Yen E, 2010, EXPERT SYST APPL, V37, P4033, DOI 10.1016/j.eswa.2009.09.032
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 39
TC 98
Z9 104
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1149
EP 1163
DI 10.1016/j.jvcir.2014.03.012
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200041
DA 2024-07-18
ER

PT J
AU Carballeira, P
   Cabrera, J
   Jaureguizar, F
   García, N
AF Carballeira, Pablo
   Cabrera, Julian
   Jaureguizar, Fernando
   Garcia, Narciso
TI Systematic analysis of the decoding delay in multiview video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three-dimensional video; Multiview video coding; Video conference; Low
   latency; Decoding delay; Parallel processing; Graph theory; Process
   scheduling
ID ARCHITECTURE; FRAMEWORK
AB We present a framework for the analysis of the decoding delay in multiview video coding (MVC). We show that in real-time applications, an accurate estimation of the decoding delay is essential to achieve a minimum communication latency. As opposed to single-view codecs, the complexity of the multiview prediction structure and the parallel decoding of several views requires a systematic analysis of this decoding delay, which we solve using graph theory and a model of the decoder hardware architecture. Our framework assumes a decoder implementation in general purpose multi-core processors with multi-threading capabilities. For this hardware model, we show that frame processing times depend on the computational load of the decoder and we provide an iterative algorithm to compute jointly frame processing times and decoding delay. Finally, we show that decoding delay analysis can be applied to design decoders with the objective of minimizing the communication latency of the MVC system. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Carballeira, Pablo; Cabrera, Julian; Jaureguizar, Fernando; Garcia, Narciso] Univ Politecn Madrid, ETSI Telecomun, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Carballeira, P (corresponding author), Univ Politecn Madrid, ETSI Telecomun, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
EM pcl@gti.ssr.upm.es
RI García, Narciso/E-8603-2011; Carballeira, Pablo/I-5983-2019; Jaureguizar
   Nuñez, Fernando/ITV-1191-2023; Jaureguizar, Fernando/T-7959-2018;
   QUESADA, JULIAN CABRERA/Y-7544-2019
OI García, Narciso/0000-0002-0397-894X; Carballeira,
   Pablo/0000-0002-7199-698X; Jaureguizar, Fernando/0000-0001-6449-5151;
   QUESADA, JULIAN CABRERA/0000-0002-7154-2451
FU Ministerio de Economia y Competitividad of the Spanish Government
   [TEC2010-20412]; Comunidad de Madrid
FX This work has been partially supported by the Ministerio de Economia y
   Competitividad of the Spanish Government under project TEC2010-20412
   (Enhanced 3DTV). Also, P. Carballeira wishes to thank the Comunidad de
   Madrid for a personal research grant.
CR [Anonymous], 2007, NETW MOD EV MULT TRA
   [Anonymous], 2005, 1449610 ISOIEC
   Carballeira P., 2009, P IS T SPIE VISUAL C, V7257
   Carballeira P, 2012, IEEE J-STSP, V6, P583, DOI 10.1109/JSTSP.2012.2193378
   Ho Y., 2008, MULTIVIEW VIDEO TEST
   Joint Video Team, 2011, JMVC REF SOFTW 8 5
   Kang SB, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P13, DOI 10.1109/ICIP.2000.899212
   Karlsson G, 1996, IEEE COMMUN MAG, V34, P118, DOI 10.1109/35.533930
   Liu YW, 2010, J VIS COMMUN IMAGE R, V21, P523, DOI 10.1016/j.jvcir.2010.02.004
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Morvan Y, 2008, IEEE T CONSUM ELECTR, V54, P925, DOI 10.1109/TCE.2008.4560180
   Pang Y, 2009, IEEE T CIRC SYST VID, V19, P1658, DOI 10.1109/TCSVT.2009.2031463
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Tanimoto M., 2009, MPEG CONTRIBUTION
   Thulasiraman K., 1992, Graphs: theory and algorithms
   VETRO A, 2008, JVTAB204
   Vetro A., 2005, MULTIVIEW TEST SEQUE
   Vetro A., 2008, JOINT MULTIVIEW VIDE
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Yang Y, 2006, IEEE IMAGE PROC, P521, DOI 10.1109/ICIP.2006.312391
NR 20
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 689
EP 697
DI 10.1016/j.jvcir.2013.04.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chen, Y
   Hannuksela, MM
   Suzuki, T
   Hattori, S
AF Chen, Ying
   Hannuksela, Miska M.
   Suzuki, Teruhiko
   Hattori, Shinobu
TI Overview of the MVC + D 3D video coding standard
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview video coding; MVC; MVC plus D; H.264; Multiview Video plus
   Depth; Multiview video coding plus depth; 3D video coding; 3D video
   coding standards
AB 3D video services are emerging in various application domains including cinema, TV broadcasting, Blu-ray discs, streaming and smartphones. A majority of the 3D video content in market is still based on stereo video, which is typically coded with the multiview video coding (MVC) extension of the Advanced Video Coding (H.264/AVC) standard or as frame-compatible stereoscopic video. However, the 3D video technologies face challenges as well as opportunities to support more demanding application scenarios, such as immersive 3D telepresence with numerous views and 3D perception adaptation for heterogeneous 3D devices and/or user preferences. The Multiview Video plus Depth (MVD) format enables depth-image-based rendering (DIBR) of additional viewpoints in the decoding side and hence helps in such advanced application scenarios. This paper reviews the MVC + D standard, which specifies an MVC-compatible MVD coding format. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Ying] Qualcomm Inc, San Diego, CA 92121 USA.
   [Hannuksela, Miska M.] Nokia Res Ctr, Tampere 33720, Finland.
   [Suzuki, Teruhiko; Hattori, Shinobu] Sony, Shinagawa Ku, Tokyo 1418610, Japan.
C3 Qualcomm; Nokia Corporation; Siemens AG; Nokia Siemens Networks; Nokia
   Finland
RP Chen, Y (corresponding author), Qualcomm Inc, 5775 Morehouse Dr, San Diego, CA 92121 USA.
EM cheny@qti.qualcomm.com
OI Suzuki, Teruhiko/0009-0002-2908-1222
CR Advanced Video Coding for Generic Audiovisual Services, 2012, 1449610MPEG4AVC ISOI
   Aflaki P., 2012, JCT3VB0147, P13
   [Anonymous], 2007, N8768 ISOIEC JTC MPE
   [Anonymous], 2005, JTC1SC29WG11 MPEG IS
   [Anonymous], 2011, JTC1SC29WG11 MPEG IS
   [Anonymous], P PCS 2006 PICT COD
   Bross B., 2012, JCTVC J1003 JOINT CO, P11
   Chen Y., 2012, JTC1SC29WG11 MPEG IS
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Hannuksela M., 2012, JCT3VB1002, P13
   Hannuksela M.M., 2012, JCT3VA0002
   Hannuksela M.M., 2012, JCT3VB1003
   Hattori S., 2012, JCT3VA0074
   Hattori S., 2011, JTC1SC29WG11 MPEG IS
   Kauff P., 2007, SIGNAL PROCESSING IM
   Muller K., 2011, JTC1SC29WG11 MPEG IS
   Norkin A., 2012, JTC1SC29WG11 MPEG IS
   Rusanovskyy D., 2012, PROC 3 M ITU TISOIEC
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Shimizu S., 2012, JCT3VA0140
   Smolic A., 2005, P IEEE SPEC ISS ADV
   SMOLIC A, 2007, MULTIVIEW VIDEO PLUS
   Stankiewicz O., 2012, JTC1SC29WG11 MPEG IS
   Suzuki T., 2012, 14496102012DAM2 ISOI, P13
   Tao SP, 2009, IEEE INT SYMP CIRC S, P2353, DOI 10.1109/ISCAS.2009.5118272
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
NR 27
TC 50
Z9 58
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 679
EP 688
DI 10.1016/j.jvcir.2013.03.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500008
DA 2024-07-18
ER

PT J
AU Zhang, YY
   Xiong, ZW
   Cong, PY
   Wu, F
AF Zhang, Yueyi
   Xiong, Zhiwei
   Cong, Pengyu
   Wu, Feng
TI Robust depth sensing with adaptive structured light illumination
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth sensing; Depth camera; Structured light; Speckle; Defocus;
   Overexposure; Underexposure; Adaptive illumination
ID ACQUISITION; SYSTEMS; PATTERN
AB Automatic focus and exposure are the key components in digital cameras nowadays, which jointly play an essential role for capturing a high quality image/video. In this paper, we make an attempt to address these two challenging issues for future depth cameras. Relying on a programmable projector, we establish a structured light system for depth sensing with focus and exposure adaptation. The basic idea is to change current illumination pattern and intensity locally according to the prior depth information. Consequently, multiple object surfaces appearing at different depths in the scene can receive proper illumination respectively. In this way, more flexible and robust depth sensing can be achieved in comparison with fixed illumination, especially at near depth. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Yueyi] Univ Sci & Technol China, Hefei 230026, Anhui, Peoples R China.
   [Xiong, Zhiwei; Wu, Feng] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Cong, Pengyu] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft Research Asia; Microsoft; Beijing Institute of
   Technology
RP Xiong, ZW (corresponding author), Microsoft Res Asia, 5 Danling St, Beijing 100080, Peoples R China.
EM zhyuey@mail.ustc.edu.cn; zhxiong@microsoft.com; congpengyu@bit.edu.cn;
   fengwu@microsoft.com
RI Wu, Feng/KCY-3017-2024
CR Albitar Chadi, 2007, INT C COMP VIS
   [Anonymous], COMPUTER VISION PATT
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755
   Chien H.-J., 2008, IMAGE VISION COMPUTI
   DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067
   Dudley D., 2003, STORAGE RETRIEVAL IM
   Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43
   Garcia Ricardo R., 2010, PROCAMS
   Goodman J., 2002, SPECKLE PHENOMENA OP
   Gupta M., 2009, COMPUTER VISION PATT
   HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771
   Inokuchi S., 1984, INT C PATT REC
   Jones A., 2007, SIGGRAPH
   Koninckx Thomas P., 2005, COMPUTER VISION PATT
   Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62
   Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448
   Levin A., 2007, SIGGRAPH
   Narasimhan S.G., 2008, EUR C COMP VIS
   Nayar Shree K., 2004, COMPUTER VISION PATT
   Petriu E.M., 1992, INT C INT ROB SYST
   POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Scharstein D., 2003, COMPUTER VISION PATT
   VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Zalevsky Z., 2010, U.S. Patent Application, Patent No. [2010/0177164, 20100177164]
   Zhang L., 2006, SIGGRAPH
   Zhang S, 2010, OPT LASER ENG, V48, P149, DOI 10.1016/j.optlaseng.2009.03.008
NR 29
TC 18
Z9 20
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 649
EP 658
DI 10.1016/j.jvcir.2013.06.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500005
DA 2024-07-18
ER

PT J
AU Seppänen, J
   Varela, M
   Sgora, A
AF Seppanen, Janne
   Varela, Martin
   Sgora, Aggeliki
TI An autonomous QoE-driven network management framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality of experience; Multimedia; Over-the-top; Management system;
   Access point; Admission Control; QoS; Monitoring
ID VIDEO APPLICATIONS; CHALLENGES; QUALITY
AB Recently, network researchers have taken a great interest in quality of experience (QoE) and in the new aspects it brings in the study of the link between network conditions and user satisfaction. Also, the realization that the information of users' satisfaction can be directly applied in the network management in a real-time manner has resulted in a fair amount of publications. Although the systems and frameworks presented in these publications tackle the subject of QoE-driven management quite successfully, they often concentrate on certain applications or technologies. We present a generic QoE management framework, which is applicable to a broad range of systems. We also demonstrate an instantiation of this framework as a network access point management system for RTP-based video. This system is not only able to positively affect the perceived quality of the multimedia application considered, but also to reduce over-prioritization and optimize resource usage. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Seppanen, Janne; Varela, Martin; Sgora, Aggeliki] VTT Tech Res Ctr Finland, Oulu 90571, Finland.
C3 VTT Technical Research Center Finland
RP Seppänen, J (corresponding author), VTT Tech Res Ctr Finland, PL 1100, Oulu 90571, Finland.
EM janne.seppanen@vtt.fi; martin.varela@vtt.fi; ext-angeliki.sgora@vtt.fi
RI Sgora, Aggeliki/AAM-6571-2021
FU Tekes, the Finnish Funding Agency for Technology and Innovation
FX The research behind this paper was conducted within the IPNQ-SIS (IP
   Network Monitoring for Quality of Service Intelligent Support), a Celtic
   Call 7 project and QuEEN, a Celtic Call 8 project. The authors would
   like to thank Tekes, the Finnish Funding Agency for Technology and
   Innovation, for financially supporting this research.
CR Agboma F., 2008, PROC 6 INT C ADV MOB, P111
   Amon P, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION, QUALITY AND TESTING, ROBOTICS (AQTR 2008), THETA 16TH EDITION, VOL I, PROCEEDINGS, P336, DOI 10.1109/AQTR.2008.4588764
   [Anonymous], J COMPUT NETW COMMUN
   [Anonymous], 2008, 2008 IEEE 68 VEH TEC
   [Anonymous], THESIS U RENNES 1 RE
   [Anonymous], METH SUBJ DET TRANSM
   Atenas M., 2010, 2010 Sixth International Conference on Networking and Services (ICNS), P36, DOI 10.1109/ICNS.2010.13
   Bergkvist A., 2013, WEBRTC 1 0 IN PRESS
   Brown M., LINUX TRAFFIC CONTRO
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Converging Networks Laboratory, VTT QOSM EN PASS QOS
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   Fajardo J.-O., COMPUT COMMUN, V33
   Gallo E, 2007, IEEE SYS MAN CYBERN, P3180
   Hirvonen M., 2009, THESIS U OULU
   Hossfeld T, 2012, IEEE COMMUN MAG, V50, P28, DOI 10.1109/MCOM.2012.6178831
   Hubert B., Linux advanced routing traffic control howto
   Hwa-Jong Kim, 2010, 2010 Third International Conference on Communication Theory, Reliability, and Quality of Service (CTRQ), P135, DOI 10.1109/CTRQ.2010.30
   Jelassi S, 2012, IEEE COMMUN SURV TUT, V14, P491, DOI 10.1109/SURV.2011.120811.00063
   Kafetzakis E., 2012, 2012 International Conference on Telecommunications and Multimedia (TEMU), P77, DOI 10.1109/TEMU.2012.6294736
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Krasic C., 2003, Proceedings of the 13th International Workshop on Network and Operating Systems Support for Digital Audio and Video, P112
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lloret J, 2012, COMPUT COMMUN, V35, P1855, DOI 10.1016/j.comcom.2012.06.002
   Lloret J, 2011, INT J COMMUN SYST, V24, P118, DOI 10.1002/dac.1145
   Maki T., 2013, P QOMEX 2013 KLAG AU
   Matos F., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P257, DOI 10.1109/INM.2011.5990699
   Mohamed S., 2003, THESIS U RENNES 1
   Mu Mu, 2009, International Journal of Internet Protocol Technology, V4, P54, DOI 10.1504/IJIPT.2009.024170
   Rubino G., 2004, 1 INT C QUAN EV SYST
   Seppänen J, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P1621
   Serral-Gracià R, 2010, LECT NOTES COMPUT SC, V6074, P252
   Sgora A, 2009, IEEE COMMUN SURV TUT, V11, P57, DOI 10.1109/SURV.2009.090405
   Universita degli Studi di Napoli Federico II, D ITG DISTR INT TRAF
   Vakili A., 2012, FUTURE INFORM TECHNO, V164, P191, DOI [10.1007/978-94-007-4516-2_19, DOI 10.1007/978-94-007-4516-2_19]
NR 35
TC 23
Z9 25
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 565
EP 577
DI 10.1016/j.jvcir.2013.11.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100006
DA 2024-07-18
ER

PT J
AU Javaherian, A
   Movafeghi, A
   Faghihi, R
   Yahaghi, E
AF Javaherian, Ashkan
   Movafeghi, Amir
   Faghihi, Reza
   Yahaghi, Effat
TI An exhaustive criterion for estimating quality of images in electrical
   impedance tomography with application to clinical imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Electrical impedance tomography; Image quality; Clinical imaging;
   Exhaustive criterion; Point spread function; Energy scattering; Weighted
   spatial variance; Image attributes
ID RECONSTRUCTION ALGORITHMS; EIT RECONSTRUCTION; CURRENT PATTERNS;
   BRAIN-FUNCTION; MODEL; ADJACENT
AB This study proposes a versatile criterion for estimating quality of images in electrical impedance tomography. The point spread function (PSF) is calculated throughout the domain based on the scattering of energy as responses to a small anomaly spirally moved from the centre to the boundary. The proposed PSF is a measure of weighted spatial variance (WSV) of the conductivity over the whole domain. For each element, the weighting factor is a normalized multiplication of the area of that element by its square intensity. The WSV collectively incorporates all image attributes, i.e., spatial resolution, artifact, amplitude response, positioning error and shape deformation. The location of artifacts, which significantly influences reconstructed images in reality, is taken into account as well. The results illustrate that the proposed measure is more tolerant than existing criteria in evaluating performance of EIT systems in both theory and practice. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Javaherian, Ashkan; Faghihi, Reza] Shiraz Univ, Dept Mech Engn, Shiraz, Iran.
   [Movafeghi, Amir] Nucl Sci & Technol Res Inst, Tehran, Iran.
   [Yahaghi, Effat] Imam Khomeini Int Univ Qazvin, Dept Phys, Qazvin, Iran.
C3 Shiraz University; Imam Khomeini International University
RP Javaherian, A (corresponding author), Shiraz Univ, Dept Mech Engn, Shiraz, Iran.
EM ashkan.javaherian@yahoo.com
RI Javaherian, Ashkan/KHT-5628-2024; yahaghi, effat/AAL-4502-2020;
   Movafeghi, Amir/AGR-6945-2022; Movafeghi, Amir/AAF-4671-2020
OI Javaherian, Ashkan/0000-0003-0798-3196; yahaghi,
   effat/0000-0001-5252-1746; Movafeghi, Amir/0000-0002-1249-6811;
   Movafeghi, Amir/0000-0002-1249-6811; Faghihi, Reza/0000-0003-3238-6887
CR Abascal JFPJ, 2008, NEUROIMAGE, V43, P258, DOI 10.1016/j.neuroimage.2008.07.023
   Adler A, 1996, IEEE T MED IMAGING, V15, P170, DOI 10.1109/42.491418
   Adler A, 2009, PHYSIOL MEAS, V30, pS35, DOI 10.1088/0967-3334/30/6/S03
   AVIS NJ, 1994, PHYSIOL MEAS, V15, pA153, DOI 10.1088/0967-3334/15/2A/020
   Bagshaw AP, 2003, NEUROIMAGE, V20, P752, DOI 10.1016/S1053-8119(03)00301-X
   Balleza M, 2009, ARCH BRONCONEUMOL, V45, P320, DOI 10.1016/j.arbres.2009.01.013
   Barber D C, 1988, Clin Phys Physiol Meas, V9 Suppl A, P101, DOI 10.1088/0143-0815/9/4A/017
   Bera TK, 2011, MEASUREMENT, V44, P518, DOI 10.1016/j.measurement.2010.11.015
   Boone KG, 1996, MED BIOL ENG COMPUT, V34, P351, DOI 10.1007/BF02520003
   EIDORS, 2012, EIDORS ELECT IMPEDAN
   Frerichs I, 2003, INTENS CARE MED, V29, P2312, DOI 10.1007/s00134-003-2029-z
   Gomez-Laberge C., 2006, THESIS U OTTAWA CANA
   Graham BM, 2006, PHYSIOL MEAS, V27, pS65, DOI 10.1088/0967-3334/27/5/S06
   Ijaz UZ, 2007, FLOW MEAS INSTRUM, V18, P47, DOI 10.1016/j.flowmeasinst.2006.12.005
   Javaherian Ashkan, 2012, Journal of Applied Sciences, V12, P518, DOI 10.3923/jas.2012.518.534
   Javaherian A, 2013, APPL MATH MODEL, V37, P5637, DOI 10.1016/j.apm.2012.11.022
   Kolehmainen V, 1997, PHYSIOL MEAS, V18, P289, DOI 10.1088/0967-3334/18/4/003
   Ledger PD, 2012, COMPUT METHOD APPL M, V225, P154, DOI 10.1016/j.cma.2012.02.015
   Lionheart WRB, 2004, PHYSIOL MEAS, V25, P125, DOI 10.1088/0967-3334/25/1/021
   MURAI T, 1985, IEEE T BIO-MED ENG, V32, P177, DOI 10.1109/TBME.1985.325526
   Ni AS, 2008, COMPUT MED IMAG GRAP, V32, P409, DOI 10.1016/j.compmedimag.2008.04.002
   Oh SH, 2007, IFMBE PROC, V17, P424
   Song XM, 2004, APPL OPTICS, V43, P1053, DOI 10.1364/AO.43.001053
   Tossavainen OP, 2006, CHEM ENG SCI, V61, P7717, DOI 10.1016/j.ces.2006.09.010
   Wheeler JL, 2002, PHYSIOL MEAS, V23, P169, DOI 10.1088/0967-3334/23/1/316
   Yasin M, 2011, PHYSIOL MEAS, V32, DOI 10.1088/0967-3334/32/7/S09
   YORKEY TJ, 1987, IEEE T BIO-MED ENG, V34, P843, DOI 10.1109/TBME.1987.326032
NR 27
TC 16
Z9 17
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 773
EP 785
DI 10.1016/j.jvcir.2013.05.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700004
DA 2024-07-18
ER

PT J
AU Du, H
   Liu, Z
   Jiang, JL
   Shen, LQ
AF Du, Huan
   Liu, Zhi
   Jiang, Jianliang
   Shen, Liquan
TI Stretchability-aware block scaling for image retargeting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Block scaling; Image retargeting; Stretchability; Stretchable space;
   Block partition; Saliency; Scaling factor; User study
ID VIDEO; MODEL
AB This paper proposes an efficient approach to retarget images based on stretchability-aware block scaling. The image stretchability is first evaluated based on gradient, saliency and color features, and is used to generate the stretchable space. Then the optimal size of the stretched image is determined under the constraint of stretchable space and the same aspect ratio as the target image. Based on the analysis of image stretchability measures, the original image is partitioned into non-stretchable blocks and stretchable blocks, and their scaling factors are calculated based on their stretchability measures and the stretched image size, in order to possibly preserve non-stretchable blocks without distortion and reasonably resize stretchable blocks. Finally, the stretched image is uniformly scaled to generate the target image. Experimental results on a variety of images and the user study demonstrate that our approach achieves an overall better retargeting performance compared to the state-of-the-art image retargeting approaches. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Du, Huan; Liu, Zhi; Jiang, Jianliang; Shen, Liquan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Liu, Zhi] IRISA, F-35042 Rennes, France.
   [Liu, Zhi; Shen, Liquan] Shanghai Univ, Minist Educ, Key Lab Adv Display & Syst Applicat, Shanghai 200072, Peoples R China.
C3 Shanghai University; Universite de Rennes; Shanghai University
RP Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
EM liuzhisjtu@163.com
RI LIU, Zhi/D-4518-2012; Shen, Liquan/D-4832-2012
OI LIU, Zhi/0000-0002-8428-1131; 
FU Shanghai Natural Science Foundation [11ZR1413000]; National Natural
   Science Foundation of China [61171144]; Innovation Program of Shanghai
   Municipal Education Commission [12ZZ086]; Key (Key grant) Project of
   Chinese Ministry of Education [212053]; Innovation Program for Graduate
   Students of Shanghai University [SHUCX120134]
FX This work was supported by Shanghai Natural Science Foundation (No.
   11ZR1413000), National Natural Science Foundation of China under Grant
   No. 61171144, Innovation Program of Shanghai Municipal Education
   Commission (No. 12ZZ086), the Key (Key grant) Project of Chinese
   Ministry of Education (No. 212053) and the Innovation Program for
   Graduate Students of Shanghai University (No. SHUCX120134). The authors
   would like to thank the anonymous reviewers and the associate editor for
   their valuable comments, and also thank Dr. Pal for providing the
   research code for comparison.
CR [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], P IEEE ICCV RIO DE J
   [Anonymous], P IEEE INT C IM PROC
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Chiang CK, 2009, IEEE T CIRC SYST VID, V19, P1588, DOI 10.1109/TCSVT.2009.2031462
   Cho T. S., 2008, PROC IEEE CVPR
   Conger DD, 2010, INT CONF ACOUST SPEE, P1450, DOI 10.1109/ICASSP.2010.5495481
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Fan Xin., 2003, P ACM MULTIMEDIA, P247
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Kim W, 2011, IEEE SIGNAL PROC LET, V18, P631, DOI 10.1109/LSP.2011.2165337
   Li B., 2011, PROC IEEE ICME
   Liang Y, 2012, SIGNAL PROCESS, V92, P1243, DOI 10.1016/j.sigpro.2011.11.018
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Liu Z, 2010, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2010.5652613
   Liu Z, 2010, OPT ENG, V49, DOI 10.1117/1.3281667
   Pal R, 2011, LECT NOTES COMPUT SC, V6744, P104, DOI 10.1007/978-3-642-21786-9_19
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Wang SF, 2011, IEEE T IMAGE PROCESS, V20, P855, DOI 10.1109/TIP.2010.2076293
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
NR 27
TC 29
Z9 35
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 499
EP 508
DI 10.1016/j.jvcir.2013.03.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400007
DA 2024-07-18
ER

PT J
AU Wong, A
   Wang, XY
AF Wong, Alexander
   Wang, Xiao Yu
TI Monte Carlo cluster refinement for noise robust image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monte Carlo; Clustering; Image; Noise robust; Segmentation; Stochastic;
   Local spatial-feature context; Maximum a posterior
ID FINITE MIXTURES; ALGORITHM; SPACE
AB This paper explores a stochastic approach to refining clustering results for data with spatial-feature context such as images under the presence of noise. We formulate the clustering problem as a maximum a posteriori (MAP) problem, and refine clustering results using importance-weighted Monte Carlo posterior estimates based on between-neighborhood error statistics to account for local spatial-feature context within a global framework. This cluster refinement approach is non-iterative and can be integrated with existing clustering methods to achieve improved clustering performance for image segmentation under high noise scenarios. Experiments on synthetic gray-level images, real-world natural images, and real-world satellite synthetic aperture radar imagery illustrate the proposed method's potential for improving clustering performance of existing clustering algorithms for image segmentation under high noise situations. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Wong, Alexander; Wang, Xiao Yu] Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Wong, A (corresponding author), Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
EM Alex.S.Wong@gmail.com
RI wang, xiaoyu/HJP-6901-2023; Wong, Alexander/GZM-2929-2022
OI Wong, Alexander/0000-0002-5295-2797
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This research has been partially sponsored by the Natural Sciences and
   Engineering Research Council of Canada (NSERC). We would also like to
   thank the Canadian Ice Service (CIS) for providing us with the
   RADARSAT-2 data.
CR Abascal F, 2002, BIOINFORMATICS, V18, P908, DOI 10.1093/bioinformatics/18.7.908
   Bensmail H, 2005, BIOINFORMATICS, V21, P2210, DOI 10.1093/bioinformatics/bti383
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fan JC, 2009, PATTERN RECOGN, V42, P2527, DOI 10.1016/j.patcog.2009.04.013
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Geman S., 1987, Bull. Internat. Statist. Inst., V4, P5
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Hou B, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P780, DOI 10.1109/ICOSP.2002.1181172
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Kang JY, 2009, DIGIT SIGNAL PROCESS, V19, P309, DOI 10.1016/j.dsp.2007.11.005
   Li QW, 2006, ICICIC 2006: First International Conference on Innovative Computing, Information and Control, Vol 2, Proceedings, P693
   Luo M, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P738
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Maddah M, 2008, MED IMAGE ANAL, V12, P191, DOI 10.1016/j.media.2007.10.003
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Martin D., 2002, Advances in Neural Information Processing Systems, V15
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   Niemeijer M, 2006, MED IMAGE ANAL, V10, P888, DOI 10.1016/j.media.2006.09.006
   Orbanz P, 2008, INT J COMPUT VISION, V77, P25, DOI 10.1007/s11263-007-0061-0
   Petty HR, 2007, MICROSC RES TECHNIQ, V70, P687, DOI 10.1002/jemt.20455
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Riffle M., 2010, BMC BIOINFORMATICS, V11, P9
   SAMADANI R, 1995, IEEE T IMAGE PROCESS, V4, P1182, DOI 10.1109/83.403427
   Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   Wang XY, 2010, DIGIT SIGNAL PROCESS, V20, P1173, DOI 10.1016/j.dsp.2009.11.007
   WILEY CA, 1985, IEEE T AERO ELEC SYS, V21, P440, DOI 10.1109/TAES.1985.310578
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang XY, 2004, IMAGE VISION COMPUT, V22, P735, DOI 10.1016/j.imavis.2004.04.003
   Yu QY, 2008, IEEE T PATTERN ANAL, V30, P2126, DOI 10.1109/TPAMI.2008.15
   Zhou DW, 2008, PATTERN RECOGN LETT, V29, P1694, DOI 10.1016/j.patrec.2008.04.014
NR 35
TC 0
Z9 0
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 984
EP 994
DI 10.1016/j.jvcir.2012.06.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900003
DA 2024-07-18
ER

PT J
AU Huang, DY
   Chen, CH
   Hu, WC
   Su, SS
AF Huang, Deng-Yuan
   Chen, Chao-Ho
   Hu, Wu-Chih
   Su, Sing-Syong
TI Reliable moving vehicle detection based on the filtering of swinging
   tree leaves and raindrops
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Traffic surveillance system; Motion detection; Motion estimation; Motion
   compensation; Background subtraction; Swinging trees filtering;
   Raindrops filtering; Shadow elimination
ID VIDEO OBJECT SEGMENTATION; TRACKING; ALGORITHM
AB An efficient method for detecting moving vehicles based on the filtering of swinging trees and raindrops is proposed. To extract moving objects from the background, an adaptive background subtraction scheme with a shadow elimination model is used. Swinging trees are removed from foreground objects to reduce the computational complexity of subsequent tracking. Raindrops are removed from foreground objects when necessary. Performance evaluations are carried out using seven real-world traffic image sequences. Experimental results show average recognition rates of 96.83% and 97.20% for swinging trees and raindrops, respectively, indicating the feasibility of the proposed method. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, Dacun 515, Changhua, Taiwan.
   [Chen, Chao-Ho; Su, Sing-Syong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.
   [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Makung 880, Penghu, Taiwan.
C3 Da Yeh University; National Kaohsiung University of Science &
   Technology; National Penghu University of Science & Technology
RP Huang, DY (corresponding author), Dayeh Univ, Dept Elect Engn, 168 Univ Rd, Dacun 515, Changhua, Taiwan.
EM kevin@mail.dyu.edu.tw; thouho@cc.kuas.edu.tw; wchu@npu.edu.tw;
   jacky.su1979@gmail.com
FU National Science Council, Taiwan, R.O.C. [NSC 96-2622-E-151-016-CC3]
FX This work is partially supported by National Science Council under Grant
   NSC 96-2622-E-151-016-CC3, Taiwan, R.O.C.
CR [Anonymous], J INFORM TECHNOLOGY
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2011, J INF HIDING MULTIM
   Chen C., 2012, J Inform Hiding Multimedia ., V3, P12
   Chen C. H., 2010, J INFORM HIDING MULT, V1, P110
   Chen TH, 2007, P 2 INT C INN COMP I, P238
   Chen TY, 2009, INT J INNOV COMPUT I, V5, P1797
   Chen TY, 2009, INT J INNOV COMPUT I, V5, P785
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Cord A, 2011, IEEE INT VEH SYM, P833, DOI 10.1109/IVS.2011.5940484
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853
   Galic S, 2000, IWISPA 2000: PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P63, DOI 10.1109/ISPA.2000.914892
   Gardner WF, 1996, IEEE T PATTERN ANAL, V18, P1115, DOI 10.1109/34.544082
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Gutchess D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P733, DOI 10.1109/ICCV.2001.937598
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hu WC, 2012, J VIS COMMUN IMAGE R, V23, P303, DOI 10.1016/j.jvcir.2011.10.008
   Hu WC, 2011, J VIS COMMUN IMAGE R, V22, P543, DOI 10.1016/j.jvcir.2011.03.009
   Hu WC, 2010, INT J INNOV COMPUT I, V6, P5115
   Huang LL, 2010, INT ASIA CONF INFORM, P324, DOI 10.1109/CAR.2010.5456534
   Koller D., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P189
   Lee DS, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P973
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Schiele B, 2006, IMAGE VISION COMPUT, V24, P1172, DOI 10.1016/j.imavis.2005.06.003
   Seki M, 2003, PROC CVPR IEEE, P65
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xinting Pan, 2010, Proceedings 2010 Second International Conference on Computer Modeling and Simulation (ICCMS), P314, DOI 10.1109/ICCMS.2010.75
   Zhang CR, 2000, 2000 IEEE 51ST VEHICULAR TECHNOLOGY CONFERENCE, PROCEEDINGS, VOLS 1-3, P323, DOI 10.1109/VETECS.2000.851471
NR 32
TC 16
Z9 18
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 648
EP 664
DI 10.1016/j.jvcir.2012.03.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500007
DA 2024-07-18
ER

PT J
AU Liu, QG
   Wang, SS
   Luo, JH
AF Liu, Qiegen
   Wang, Shanshan
   Luo, Jianhua
TI A novel predual dictionary learning algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dictionary learning; Sparse representation; Predual proximal point
   algorithm; Bregman iteration method; Iterated refinement property;
   Gradient descent; Majorization-minimization; Image denoising
ID ITERATIVE REGULARIZATION; SPARSE; REPRESENTATIONS; SHRINKAGE
AB Dictionary learning has been a hot topic fascinating many researchers in recent years. Most of existing methods have a common character that the sequences of learned dictionaries are simpler and simpler regularly by minimizing some cost function. This paper presents a novel predual dictionary learning (PDL) algorithm that updates dictionary via a simple gradient descent method after each inner minimization step of Predual Proximal Point Algorithm (PPPA), which was recently presented by Malgouyres and Zeng (2009) [F. Malgouyres, T. Zeng, A predual proximal point algorithm solving a non negative basis pursuit denoising model, Int.]. Comput. Vision 83 (3) (2009) 294-311]. We prove that the dictionary update strategy of the proposed method is different from the current ones because the learned dictionaries become more and more complex regularly. The experimental results on both synthetic data and real images consistently demonstrate that the proposed approach can efficiently remove the noise while maintaining high image quality and presents advantages over the classical dictionary learning algorithms MOD and K-SVD. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Liu, Qiegen; Wang, Shanshan; Luo, Jianhua] Shanghai Jiao Tong Univ, Coll Life Sci & Technol, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Luo, JH (corresponding author), Shanghai Jiao Tong Univ, Coll Life Sci & Technol, Shanghai 200240, Peoples R China.
EM jhluo@sjtu.edu.cn
RI Wang, Shanshan/T-6972-2017; Luo, jian/HGE-7331-2022; Shi,
   Yaolin/JXN-8322-2024
OI Wang, Shanshan/0000-0002-0575-6523; 
FU High Technology Research Development Plan (863 plan) of PR China
   [2006AA020805]; NSFC of China [30670574, 30911130364]; Shanghai
   International Cooperation Grant [06SR07109]; Region Rhone-Alpes of
   France; French ANR [ANR-09-BLAN-0372-01]
FX This work was partly supported by High Technology Research Development
   Plan (863 plan) of PR China under 2006AA020805, the NSFC of China under
   30670574, Shanghai International Cooperation Grant under 06SR07109,
   Region Rhone-Alpes of France under the project Mira Recherche 2008, and
   the joint project of Chinese NSFC (under 30911130364) and French ANR
   2009 (under ANR-09-BLAN-0372-01). We would also like to thank the
   anonymous reviewers for their helpful suggestions in the revision of
   this manuscript.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aharon M, 2008, SIAM J IMAGING SCI, V1, P228, DOI 10.1137/07070156X
   [Anonymous], 2008, TECHNION
   [Anonymous], ANN STAT
   BECT J, 2004, LECT NOTES COMPUTER
   Burger M, 2005, LECT NOTES COMPUT SC, V3752, P25
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Daubechies I, 2004, COMMUN PURE APPL MAT, V57, P3601
   Dobigeon N, 2010, IEEE T SIGNAL PROCES, V58, P2675, DOI 10.1109/TSP.2010.2041594
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   ENGAN K, 1999, P ISCS
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   He ZS, 2008, NEURAL COMPUT, V20, P636, DOI 10.1162/neco.2007.07-06-296
   Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   LEE H, 2007, ADV NIPS
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Malgouyres F, 2009, INT J COMPUT VISION, V83, P294, DOI 10.1007/s11263-009-0227-z
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251
   Rockafellar R. T., 1976, Mathematics of Operations Research, V1, P97, DOI 10.1287/moor.1.2.97
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Xu JJ, 2007, IEEE T IMAGE PROCESS, V16, P534, DOI 10.1109/TIP.2006.888335
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zhou M., 2009, Neural Information Processing Systems (NIPS)
NR 34
TC 14
Z9 19
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 182
EP 193
DI 10.1016/j.jvcir.2011.09.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100018
DA 2024-07-18
ER

PT J
AU Hamidouche, W
   Perrine, C
   Pousset, Y
   Olivier, C
AF Hamidouche, Wassim
   Perrine, Clency
   Pousset, Yannis
   Olivier, Christian
TI A solution to efficient power allocation for H.264/SVC video
   transmission over a realistic MIMO channel using precoder designs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Optimal power allocation; H.264/SVC; JSCC; MIMO channels; Precoder
   solutions; QoS precoder; E-d(min) precoder; 3D-ray tracer
ID EXTENSION; DISTANCE
AB In this paper we propose a novel scheme for real time SVC-based video transmission over MIMO channels in the context of joint Source Channel Coding (JSCC). This scheme compares the transmission of the H.264/SVC video over four precoder solutions, namely Max-SNR, WF, QoS and E-d(min). We exploit the high flexibility of the QoS precoder to minimize the total distortion of the received video. The proposed adaptive QoS precoder takes into account the scalability of the H.264/SVC standard jointly with the instantaneous MIMO channel statue. Finally, the proposed scheme is evaluated over both statistical and time varying realistic MIMO channels. This study provides the performance of these four precoder designs in term of BER, ML decoder complexity and the quality of the received video. We show that the precoder solutions providing the best BER performance are not usually the most appropriate for real time video transmission. However, the adaptive QoS precoder which uses three configurations, by considering both the importance of the video bitstream and the channel statue, provides the best Rate-Distortion performance regardless the channel conditions. We assess the accuracy of these four precoder solutions against channel estimation errors over time varying realistic MIMO channel. The results shows that the adaptive QoS precoder remains robust against channel estimation errors even at high mobility speed. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hamidouche, Wassim; Perrine, Clency; Pousset, Yannis; Olivier, Christian] Univ Poitiers, Dept Signal Image & Commun, XLIM Lab, CNRS,UMR 6172, Poitiers, France.
C3 Universite de Poitiers; Centre National de la Recherche Scientifique
   (CNRS)
RP Hamidouche, W (corresponding author), Univ Poitiers, Dept Signal Image & Commun, XLIM Lab, CNRS,UMR 6172, Poitiers, France.
EM hamidouche@sic.sp2mi.univ-poitiers.fr
FU French National Research Agency
FX This work is supported by the French National Research Agency as part of
   two projects: namely the CAIMAN project and the MOC-AMIMODYN project.
CR [Anonymous], P IEEE ICME
   [Anonymous], 35 IEEE C ICASSP DAL
   [Anonymous], OPTIMIZED SCANNING V
   [Anonymous], IEEE T CIRCUITS SYST
   Bhaskar V, 2007, INT J WIREL INF NETW, V14, P237, DOI 10.1007/s10776-007-0065-2
   Carlos P, 2009, IEEE T ANTENN PROPAG, V57, P1218, DOI 10.1109/TAP.2009.2015791
   Collin L, 2004, IEEE T SIGNAL PROCES, V52, P617, DOI 10.1109/TSP.2003.822365
   Foschini G. J., 1996, Bell Labs Technical Journal, V1, P41, DOI 10.1002/bltj.2015
   Hamidouche W, 2009, 2009 IEEE 20TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, P187, DOI 10.1109/PIMRC.2009.5450260
   Ji Z, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P3398
   Jubran MK, 2009, IEEE T IMAGE PROCESS, V18, P106, DOI 10.1109/TIP.2008.2006600
   Lin S., 2004, Error Control Coding, Vsecond
   Love DJ, 2008, IEEE J SEL AREA COMM, V26, P1341, DOI 10.1109/JSAC.2008.081002
   Oestges Claude., 2007, MIMO WIRELESS COMMUN
   Parsons J. D., 2000, The Mobile Radio Propagation Channel
   Sampath H, 2001, IEEE T COMMUN, V49, P2198, DOI 10.1109/26.974266
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sesia S., 2009, UMTS LONG TERM EVOLU
   Song D, 2008, J VIS COMMUN IMAGE R, V19, P520, DOI 10.1016/j.jvcir.2008.06.008
   Stoica P, 2002, IEEE T SIGNAL PROCES, V50, P3036, DOI 10.1109/TSP.2002.805266
   Telatar E, 1999, EUR T TELECOMMUN, V10, P585, DOI 10.1002/ett.4460100604
   Vrigneau B, 2008, IEEE J-STSP, V2, P135, DOI 10.1109/JSTSP.2008.922476
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WIEGAND T, 2007, JVTW201
NR 24
TC 9
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 563
EP 574
DI 10.1016/j.jvcir.2011.02.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000011
DA 2024-07-18
ER

PT J
AU Oh, JD
   Kuo, CCJ
AF Oh, Jong Dae
   Kuo, C. -C. Jay
TI Robust stereo matching with improved graph and surface models and
   occlusion handling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Graph model; Occlusion; Disparity estimation; Surface
   modeling; Ordering constraint; Color segmentation constraint; Disparity
   filling
AB We decompose the stereo matching problem into three sub-problems in this work: (1) disparity estimation for non-occlusion regions and occlusion detection, (2) disparity estimation for occlusion regions, and (3) surface model for the disparity map. A three-step procedure is proposed to solve them sequentially. At the first step, we perform an initial matching and develop a new graph model using the ordering and segmentation constraints to improve disparity values in non-occlusion regions and detect occlusion regions. At the second step, we determine disparity values in occlusion regions based on global optimization. Since the conventional segmentation-based stereo matching is not efficient in highly slanted or curved objects, we propose a post-processing technique for disparity map enhancement using a three-dimensional (3D) geometric structure. The proposed three-step stereo matching procedure yields excellent quantitative and qualitative results with Middlebury data sets. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Oh, Jong Dae; Kuo, C. -C. Jay] Univ So Calif, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Oh, JD (corresponding author), Univ So Calif, Los Angeles, CA 90089 USA.
EM jjongdean@hotmail.com
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261
   Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hong L, 2004, PROC CVPR IEEE, P74
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   LI G, 2006, P IEEE CS C COMP VIS, V2, P2355
   Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54
   Mordohai P, 2006, IEEE T PATTERN ANAL, V28, P968, DOI 10.1109/TPAMI.2006.129
   Ogale AS, 2004, PROC CVPR IEEE, P568
   OH JD, 2007, P C COMP VIS PATT RE, V1, P1
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sun J, 2005, PROC CVPR IEEE, P399
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16
   Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   TSIN Y, 2004, P C COMP VIS PATT RE, V1, P135
   YANG Q, 2007, P C COMP VIS PATT RE, V1, P1
NR 23
TC 11
Z9 12
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 404
EP 415
DI 10.1016/j.jvcir.2010.03.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600004
DA 2024-07-18
ER

PT J
AU Yendo, T
   Fujii, T
   Tanimoto, M
   Tehrani, MP
AF Yendo, Tomohiro
   Fujii, Toshiaki
   Tanimoto, Masayuki
   Tehrani, Mehrdad Panahpour
TI The Seelinder: Cylindrical 3D display viewable from 360 degrees
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Autostereoscopic display; Multi-view; Omnidirectional; Ray-space; Light
   field; Parallax barrier
ID VOLUMETRIC 3-DIMENSIONAL DISPLAY; IMAGES; ARRAY
AB We propose a 3D video display technique that allows multiple viewers to see 3D images from a 360-degree horizontal arc without wearing 3D glasses. This technique uses a cylindrical parallax barrier and a one-dimensional light source array. We have developed an experimental display system using this technique. Since this technique is based on the parallax panoramagram, the parallax number and resolution are limited by the diffraction at the parallax barrier. In order to solve this problem, we improved the technique by revolving the parallax barrier. The improved technique was incorporated into two experimental display systems. The newer one is capable of displaying 3D color video images within a 200-mm diameter and a 256-mm height. Images have a resolution of 1254 circumferential pixels and 256 vertical pixels, and are refreshed at 30 Hz. Each pixel has a viewing angle of 60 degrees that is divided into over 70 views so that the angular parallax interval of each pixel is less than 1 degree. These pixels are arranged on a cylindrical surface to allow for the produced 3D images to be observed from all directions. In this case, observers may barely perceive the discrete parallax. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Yendo, Tomohiro; Tanimoto, Masayuki; Tehrani, Mehrdad Panahpour] Nagoya Univ, Grad Sch Engn, Chikusa Ku, Nagoya, Aichi 4648603, Japan.
   [Fujii, Toshiaki] Tokyo Inst Technol, Grad Sch Sci & Engn, Meguro Ku, Tokyo 1528550, Japan.
C3 Nagoya University; Tokyo Institute of Technology
RP Yendo, T (corresponding author), Nagoya Univ, Grad Sch Engn, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648603, Japan.
EM yendo@nuee.nagoya-u.ac.jp
OI Teratani, Mehrdad/0000-0001-9332-1409; Fujii,
   Toshiaki/0000-0002-3440-5132
CR Cossairt O, 2004, P SOC PHOTO-OPT INS, V5291, P273, DOI 10.1117/12.525888
   Cossairt OS, 2007, APPL OPTICS, V46, P1244, DOI 10.1364/AO.46.001244
   CROSS L, 1977, P SPIE ANN TECHNICAL, P10
   DODGSON NA, 2000, SPIE P, V3597, P177
   ENDO T, 2000, SPIE P, V3957
   Favalora G, 2001, P SOC PHOTO-OPT INS, V4297, P227, DOI 10.1117/12.430821
   Ives HE, 1928, J OPT SOC AM REV SCI, V17, P435, DOI 10.1364/JOSA.17.000435
   Jones A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276427
   Kajiki Y, 1997, P SOC PHOTO-OPT INS, V3012, P154, DOI 10.1117/12.274452
   Kajiki Y, 1996, P SOC PHOTO-OPT INS, V2652, P106, DOI 10.1117/12.236051
   Liao HG, 2004, OPT EXPRESS, V12, P1067, DOI 10.1364/OPEX.12.001067
   Maeda H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P288, DOI 10.1109/ISMAR.2003.1240724
   Matsumoto K, 1997, P SOC PHOTO-OPT INS, V3012, P199, DOI 10.1117/12.274458
   Okano F, 1997, APPL OPTICS, V36, P1598, DOI 10.1364/AO.36.001598
   Okoshi T., 1976, 3 DIMENSIONAL IMAGIN
   Otsuka R, 2006, IEEE T VIS COMPUT GR, V12, P178, DOI 10.1109/TVCG.2006.38
   SUDO T, 2000, SPIE P, V3957, P215
   Takaki Y, 2003, P SOC PHOTO-OPT INS, V5003, P1, DOI 10.1117/12.483899
   TAKAKI Y, 2006, SPIE P, V6055, P1
   TANAKA K, 2006, SPIE P, V6055
   TRAVIS ARL, 1996, SPIE P, V2653, P154
NR 21
TC 47
Z9 54
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 586
EP 594
DI 10.1016/j.jvcir.2009.10.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600019
DA 2024-07-18
ER

PT J
AU Du, CH
   Yang, J
   Wu, Q
   Zhang, TH
AF Du, Chunhua
   Yang, Jie
   Wu, Qiang
   Zhang, Tianhao
TI Face recognition using message passing based clustering method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Message passing; Affinity propagation; Representative face image; Face
   recognition; Linear discriminant analysis (LDA)
ID COMPONENT ANALYSIS; PCA
AB Traditional subspace analysis methods are inefficient and tend to be affected by noise as they compare the test image to all training images, especifically when there are large numbers of training images. To solve such problem, we propose a fast face recognition (FR) technique called APLDA by combining a novel clustering method affinity propagation (AP) with linear discriminant analysis (LDA). By using AP on the reduced features derived from LDA, a representative face image for each subject can be reached. Thus, our APLDA uses only the representative images rather than all training images for identification. Obviously, APLDA is much more computationally efficient than Fisherface. Also, unlike Fisherface who uses pattern classifier for identification, APLDA performs the identification using AP once again to cluster,the test image into one of the representative images. Experimental results also indicate that APLDA outperforms Fisherface in terms of recognition rate. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Du, Chunhua; Yang, Jie; Zhang, Tianhao] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Du, Chunhua; Wu, Qiang] Univ Technol Sydney, Dept Comp Syst, Sydney, NSW 2007, Australia.
C3 Shanghai Jiao Tong University; University of Technology Sydney
RP Du, CH (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM dch3482275@163.com
RI Yang, Jie/JCD-9867-2023
OI Wu, Qiang/0000-0001-5641-2483
FU National Natural Science Foundation of China [60675023, 60602012]
FX The authors would like to thank the anonymous reviewers for their
   critical and constructive comments and suggestions. This research has
   been supported by the National Natural Science Foundation of China
   (Nos.: 60675023 and 60602012).
CR [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BELHUMEUR PN, YALE FACE DATABASE
   BRENDAN JF, 2007, SCIENCE, V315, P972, DOI DOI 10.1126/SCIENCE.1136800
   Dagher I, 2006, IEEE T PATTERN ANAL, V28, P996, DOI 10.1109/TPAMI.2006.118
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242
   KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu QS, 2002, INT C PATT RECOG, P362, DOI 10.1109/ICPR.2002.1048314
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Yang J, 2005, PATTERN RECOGN, V38, P1125, DOI 10.1016/j.patcog.2004.11.019
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang MH, 2000, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2000.900886
NR 20
TC 3
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 608
EP 613
DI 10.1016/j.jvcir.2009.09.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400010
DA 2024-07-18
ER

PT J
AU García, JA
   Rodriguez-Sánchez, R
   Fdez-Valdivia, J
AF Garcia, J. A.
   Rodriguez-Sanchez, Rosa
   Fdez-Valdivia, J.
TI A critical examination of the assumptions used in dynamic allocation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image transmission; Multiple quantizers; Dynamic allocation;
   Assumptions; Bit allocation; Knowledge; Coder evaluation; Compound gain;
   Congestion control
AB In dynamic allocation quantizers are capable of choosing between limited allocation of bits and bit allocation without restriction. The goal of this paper is to perform a comparative analysis of the assumptions used in a transmission system which still has quantizers using restrained bit allocation in the long time and in a transmission system for which all quantizers end up using heavy bit allocation. Then, based on the validity of the assumptions derived, we will be able to predict the performance of each system in a real problem. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Garcia, J. A.; Rodriguez-Sanchez, Rosa; Fdez-Valdivia, J.] Univ Granada, Dept Ciencias Computac & IA, CITIC UGR, Res Ctr Informat & Commun Technol, E-18071 Granada, Spain.
C3 University of Granada
RP Fdez-Valdivia, J (corresponding author), Univ Granada, Dept Ciencias Computac & IA, CITIC UGR, Res Ctr Informat & Commun Technol, E-18071 Granada, Spain.
EM jags@decsai.ugr.es; rosa@decsai.ugr.es; jfv@decsai.ugr.es
RI Rodriguez Sanchez, Rosa Maria/B-1847-2012; Garcia, Jose A./C-1703-2010;
   Fdez-Valdivia, J/B-1844-2012
OI Rodriguez Sanchez, Rosa Maria/0000-0001-7886-9329; Garcia, Jose
   A./0000-0001-7742-7270; Fdez-Valdivia, J/0000-0001-7181-1554
CR García JA, 2004, OPT ENG, V43, P615, DOI 10.1117/1.1646176
   García JA, 2002, OPT ENG, V41, P2216, DOI 10.1117/1.1496789
   García JA, 2001, IEEE T PATTERN ANAL, V23, P362, DOI 10.1109/34.917572
   GARCIA JA, 2004, PROGR IMAGE TRANSMIS, P230
   GARCIA JA, 2008, CONGESTION CONTROL D
   HUBERMAN BA, 1988, ECOLOGY COMPUTATION, P77
   Parisi G., 1998, Statistical field theory
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
NR 8
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2009
VL 20
IS 5
BP 351
EP 363
DI 10.1016/j.jvcir.2009.03.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 547LX
UT WOS:000273891500005
DA 2024-07-18
ER

PT J
AU Wu, SQ
   Lin, WS
   Xie, SL
   Lu, ZK
   Ong, EP
   Yao, SS
AF Wu, Shiqian
   Lin, Weisi
   Xie, Shoulie
   Lu, Zhongkang
   Ong, Ee Ping
   Yao, Susu
TI Blind blur assessment for vision-based applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blur identification; Point spread function; Line spread function; Blur
   model; Edge detection; Radon transform; Image interpolation; Blind image
   quality evaluation
ID IDENTIFICATION; IMAGE; RESTORATION
AB In this paper, a criterion for objective defocus blur measurement is theoretically derived from one image. The essential idea is to estimate the point spread function (PSF) from the line spread function (LSF), whereas the LSF is constructed from edge information. It is proven that an edge point corresponds to the local maximal gradient in a blurred image, and therefore edges can be extracted from blurred images by conventional edge detectors. To achieve high accuracy, local Radon transform is implemented and a number of LSFs are extracted from each edge. The experimental results on a variety of synthetic and real blurred images validate the proposed method. The algorithm can be implemented for image quality evaluation in vision-based applications as no reference images are needed. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Wu, Shiqian; Xie, Shoulie; Lu, Zhongkang; Ong, Ee Ping; Yao, Susu] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Nanyang Technological University
RP Wu, SQ (corresponding author), ASTAR, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis, Singapore 138632, Singapore.
EM shiqian@i2r.a-star.edu.sg; wslin@ntu.edu.sg
OI Lu, Zhongkang/0000-0001-7379-3193; Ong, Ee Ping/0000-0002-9239-8399
CR Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   BARNHAM MB, 1997, IEEE SIGNAL PROCESS, V14, P24
   Bones PJ, 2000, P SOC PHOTO-OPT INS, V4123, P133, DOI 10.1117/12.409264
   CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770
   CHALMOND B, 1991, CVGIP-GRAPH MODEL IM, V53, P364, DOI 10.1016/1049-9652(91)90039-M
   CHANG MM, 1991, IEEE T SIGNAL PROCES, V39, P2323, DOI 10.1109/78.91207
   Chen L, 2006, IEEE T SIGNAL PROCES, V54, P1557, DOI 10.1109/TSP.2006.870644
   FABIAN R, 1991, CVGIP-GRAPH MODEL IM, V53, P403, DOI 10.1016/1049-9652(91)90025-F
   Fortier N., 1993, Journal of Visual Communication and Image Representation, V4, P157, DOI 10.1006/jvci.1993.1014
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Keelan B., 2002, Handbook of image quality
   Kim SK, 1998, IEEE T CONSUM ELECTR, V44, P1071, DOI 10.1109/30.713236
   KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   LAGENDIJK RL, 1990, IEEE T ACOUST SPEECH, V38, P1180, DOI 10.1109/29.57545
   LAGENDIJK RL, 1990, OPT ENG, V29, P422, DOI 10.1117/12.55611
   Lehr J, 1998, IEEE T IMAGE PROCESS, V7, P258, DOI 10.1109/83.661006
   LI X, 2002, P INT C IM PROC NY
   LUXEN M, 2002, P PHOT COMP VIS IM A, pA205
   Malamas EN, 2003, IMAGE VISION COMPUT, V21, P171, DOI 10.1016/S0262-8856(02)00152-X
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   *MATH WORKS, 2006, IM PROC TOOLB VER 5
   Reeves SJ, 1992, IEEE T IMAGE PROCESS, V1, P301, DOI 10.1109/ICASSP.1992.226241
   ROM R, 1975, IEEE T INFORM THEORY, V21, P214, DOI 10.1109/TIT.1975.1055353
   Savakis AE, 1993, IEEE T IMAGE PROCESS, V2, P252, DOI 10.1109/83.217229
   Savakis AE, 1993, IEEE T IMAGE PROCESS, V2, P141, DOI 10.1109/83.217219
   SEZAN MI, 1991, INT CONF ACOUST SPEE, P2485, DOI 10.1109/ICASSP.1991.150905
   SUBBARAO M, 1995, P SOC PHOTO-OPT INS, V2598, P89, DOI 10.1117/12.220891
   Wolin D, 1998, IS&T'S NIP14: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, PROCEEDINGS, P603
   WU S, 2005, P 5 INT C INF COMM S, P334
   Ziou D, 2001, PATTERN RECOGN, V34, P855, DOI 10.1016/S0031-3203(00)00033-9
NR 31
TC 33
Z9 40
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2009
VL 20
IS 4
BP 231
EP 241
DI 10.1016/j.jvcir.2009.03.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 447EV
UT WOS:000266175300001
DA 2024-07-18
ER

PT J
AU Bayazit, U
   Orcay, O
   Konur, U
   Gurgen, FS
AF Bayazit, Ulug
   Orcay, Ozgur
   Konur, Umut
   Gurgen, Fikret S.
TI Predictive vector quantization of 3-D mesh geometry by representation of
   vertices in local coordinate systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE mesh geometry compression; entropy constrained vector quantization;
   local coordinate system; Shannon lower bound; parallelogram; prediction
ID COMPRESSION; CONNECTIVITY; ERROR
AB In predictive 3-D mesh geometry coding, the position of each vertex is predicted from the previously coded neighboring vertices and the resultant prediction error vectors are coded. In this work, the prediction error vectors are represented in a local coordinate system in order to cluster them around a subset of a 2-D planar subspace and thereby increase block coding efficiency. Alphabet entropy constrained vector quantization (AECVQ) of Rao and Pearlman is preferred to the previously employed minimum distortion vector quatitization (MDVQ) for block coding the prediction error vectors with high coding efficiency and low implementation complexity. Estimation and compensation of the bias in the parallelogram prediction rule and partial adaptation of the AECVQ codebook to the encoded vector source by normalization using source statistics, are the other salient features of the proposed coding system. Experimental results verify the advantage of the use of the local coordinate system over the global one. The visual error of the proposed coding system is lower than the predictive coding method of Touma and Gotsman especially at low rates, and lower than the spectral coding method of Karni and Gotsman at medium-to-high rates. (c) 2007 Elsevier Inc. All rights reserved.
C1 Isik Univ, Dept Elect Engn, Istanbul, Turkey.
   Isik Univ, Dept Comp Engn, Istanbul, Turkey.
   Bogazici Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Isik University; Isik University; Bogazici University
RP Bayazit, U (corresponding author), Isik Univ, Dept Elect Engn, Istanbul, Turkey.
EM bayazit@isikun.edu.tr; oorcay@dogus.edu.tr; konur@boun.edu.tr;
   gurgen@boun.edu.tr
RI Gurgen, Fikret/AAD-6623-2020; Konur, Umut/A-1835-2019; Bayazit,
   Ulug/ABB-2362-2020
OI Konur, Umut/0000-0003-1322-6669; Bayazit, Ulug/0000-0001-6556-4104
CR Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   BAYAZIT U, 2005, P EUSIPC0
   BERG T, 1971, RATE DISTORTION THEO
   CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498
   Chou PH, 2002, IEEE T VIS COMPUT GR, V8, P373, DOI 10.1109/TVCG.2002.1044522
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   COHEN D, 2002, MULTIWAY GEOMETRY EN
   DEERING M, 1995, P 22 ANN C COMP GRAP, P13
   Gumhold S, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P59
   Gumhold S., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P51, DOI 10.1109/VISUAL.1999.809868
   GUMHOLD S, 1998, P SIGGRAPH 98, P133
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Isenburg M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P141, DOI 10.1109/VISUAL.2002.1183768
   Isenburg M, 2002, PROC GRAPH INTERF, P161
   Isenburg M, 2000, COMP GRAPH, P263, DOI 10.1145/344779.344919
   ISENBURG M, 2005, 21 SPRING C COMP GRA, P147
   Karni M., 2001, CHEM ORGANIC SILICON, V3, P1
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Khalil H, 2001, IEEE T IMAGE PROCESS, V10, P15, DOI 10.1109/83.892439
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   KHODAKOVSKY A, 2002, NORMAL MESH COMPRESS
   KHODAKOVSKY A, 2002, NEAR FIXER COMPRESSI
   Klein R., 1996, Mesh reduction with error control, P311, DOI [10.1109/VISUAL.1996, DOI 10.1109/VISUAL.1996]
   LAVU S, 2003, P EUR ACM SIGGRAPH S, P52
   LEE ES, 2000, VERTEX DATA COMPRESS, P255
   Lee HY, 2002, COMPUT GRAPH FORUM, V21, P383, DOI 10.1111/1467-8659.t01-1-00598
   Li JL, 2006, IEEE SIGNAL PROC LET, V13, P616, DOI 10.1109/LSP.2006.877142
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Payan F, 2005, COMPUT AIDED GEOM D, V22, P466, DOI 10.1016/j.cagd.2005.04.001
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   RAO RP, 1991, OPT ENG, V30, P865, DOI 10.1117/12.55891
   RONDAOALFACE P, 2003, P INT C IM PROC, V1, P781
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sorkine O., P EUR ACM SIGGRAPH S, P42
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TAUBIN G, 1998, P SIGGRAPH 98, P123
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Xiong ZX, 1997, IEEE T IMAGE PROCESS, V6, P677, DOI 10.1109/83.568925
NR 42
TC 7
Z9 8
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2007
VL 18
IS 4
BP 341
EP 353
DI 10.1016/j.jvcir.2007.03.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 200NU
UT WOS:000248770900005
DA 2024-07-18
ER

PT J
AU Vince, A
AF Vince, A.
TI Indexing the aperture 3 hexagonal discrete global grid
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE discrete global grid; spherical tessellation; hexagonal tessellation
ID GEOGRAPHIC INFORMATION-SYSTEMS
AB Over the past decade there has been interest in the computer representation of global data based on multi-resolution subdivisions of regular polyhedra. A simple and efficient indexing of the cells of such a subdivision, called A3-coordinates, is introduced. These can be used to encode the 4 . 3(n) + 2 cells at the nth level of resolution of the octahedral aperture 3 hexagonal discrete global grid using n + 3 digits, each digit from the set {- 1, 0, 1}. (C) 2006 Elsevier Inc. All rights reserved.
C1 Univ Florida, Dept Math, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Vince, A (corresponding author), Univ Florida, Dept Math, Little Hall,POB 118105, Gainesville, FL 32611 USA.
EM vince@math.ufl.edu
OI Vince, Andrew/0000-0002-1022-1320
CR AHUJA N, 1983, COMPUT VISION GRAPH, V24, P200, DOI 10.1016/0734-189X(83)90043-9
   Barrett P, 1995, ASTR SOC P, V77, P472
   BAUMGARDNER JR, 1985, SIAM J NUMER ANAL, V22, P1107, DOI 10.1137/0722066
   Bell SBM, 1996, INT J GEOGR INF SYST, V10, P147, DOI 10.1080/026937996138106
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P79, DOI 10.14358/PERS.69.1.79
   DUTTON G, 1998, LECT NOTES EARTH SCI, V78
   FEKETE G, 1990, P SOC PHOTO-OPT INS, V1259, P242, DOI 10.1117/12.19991
   GOODCHILD MF, 1992, CVGIP-GRAPH MODEL IM, V54, P31, DOI 10.1016/1049-9652(92)90032-S
   Knuth DE., 2005, ART COMPUTER PROGRAM
   Lee Michael., 1998, Proc. 8th Intl. Symp. on Spatial Data Handling, P22
   OTOO EJ, 1993, LECT NOTES COMPUTER, V692, P510, DOI DOI 10.1007/3-540-56869-7_29
   Sahr K., 2003, CARTOGR GEOGR INF SC, V30, P121, DOI [DOI 10.1559/152304003100011090, 10.1559/152304003100011090]
   Snyder J., 1992, Cartographica, V29, P10, DOI [10.3138/27H7-8K88-4882-1752, DOI 10.3138/27H7-8K88-4882-1752]
   Szalay Alex., 2005, Indexing the sphere with the hierarchical triangular mesh
NR 14
TC 25
Z9 41
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1227
EP 1236
DI 10.1016/j.jvcir.2006.04.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200007
DA 2024-07-18
ER

PT J
AU Baek, SH
   Moon, YH
   Kim, JH
AF Baek, Seong Hak
   Moon, Yong Ho
   Kim, Jae Ho
TI An improved H.264/AVC video encoding based on a new syntax element
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; macroblock type; syntax element; mb_skip_run; mb_type
AB In H.264/AVC, various macroblock types are used for improving the compression efficiency. However, it is not efficient for the macroblock types to be coded by the mb_skip_run and mb_type syntax elements separately. In this paper, we propose an efficient coding method based on the new single combined syntax element of mb_skip_run and mbjype, as well as the effective VLC code. Simulation results show that the proposed method offers a further efficiency gain for various coding conditions. (c) 2005 Elsevier Inc. All rights reserved.
C1 Pusan Natl Univ, Dept Elect Engn, Pusan 609735, South Korea.
   Pusan Univ Foreign Studies, Div Digital & Informat Engn, Pusan 608738, South Korea.
C3 Pusan National University; Pusan University Foreign Studies
RP Baek, SH (corresponding author), Pusan Natl Univ, Dept Elect Engn, San 30,ChangJun, Pusan 609735, South Korea.
EM baeksh@pusan.ac.kr; yhmoon5@pufs.ac.kr; jhkim@pusan.ac.kr
CR BJONTEGAARD G, 2002, 3 M FAIRF VIRG US 6
   Cheung NM, 2001, INT CONF ACOUST SPEE, P1805, DOI 10.1109/ICASSP.2001.941292
   CHOI W, 2001, VLVB
   Itoh Y, 2000, IEEE IMAGE PROC, P940, DOI 10.1109/ICIP.2000.901115
   *JOINT VID TEAM, REF SOFTW JM8 2 JOIN
   Kamaci N, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P345
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 7
TC 1
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 345
EP 357
DI 10.1016/j.jvcir.2005.05.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000009
DA 2024-07-18
ER

PT J
AU Lindberg, S
   Fahlcrantz, CM
AF Lindberg, S
   Fahlcrantz, CM
TI Perceptual assessment of simulated print noise with random and periodic
   structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE print mottle; systematic disturbances; ordered noise; simulation;
   multidimensional scaling; two-dimensional scaling
ID TEXTURE; FEATURES; QUALITY
AB Lightness variation in a supposedly uniform printed surface is referred to as "print mottle." This phenomenon is one of the most detrimental to overall print quality. A fundamental problem in the evaluation of human sensitivity to a print quality variable such as mottle is the difficulty in controlling external variables, such as variations in color or in average print density, that arise in the printing process. These variables can influence the rating of quality. To analyze the impact of a systematic mottle pattern compared to that of the common case of a random pattern, a digital simulation technique was used to create gray test samples with various amounts of stochastic and systematic noise of different characters. The samples were printed using a high quality inkjet printer and evaluated by a panel of judges. Two different evaluation methods were used. Observers rated dissimilarity and preference in a pairwise comparison task, and also by positioning samples in the horizontal and vertical directions of a digitizing tablet. The results show that individuals rate the samples in a very consistent way and that systematic noise is perceived to be more annoying than random noise of a similar physical magnitude. Furthermore, the consistency between the two different evaluation methods is very good, which suggests that two-dimensional scaling on a digitizing tablet is a viable method for grouping samples in a plane. The results also show that digital simulation of print artifacts is a powerful too] for creating samples with controlled disturbances. (C) 2004 Elsevier Inc. All rights reserved.
C1 Swedish Pulp & Paper Res Inst, STFI, SE-11486 Stockholm, Sweden.
C3 Innventia
RP Lindberg, S (corresponding author), Swedish Pulp & Paper Res Inst, STFI, POB 5604, SE-11486 Stockholm, Sweden.
EM siv.lindberg@stfi.se; carlmagnus.fahlcrantz@stfi.se
OI Lindberg, Siv/0000-0002-9673-7984
CR A Johansson P., 1993, ADV PRINTING SCI TEC, V22, P403
   [Anonymous], 1988, Spatial Vision
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   Barten Peter G. J, 1999, Contrast sensitivity of the human eye and its effects on image quality
   BARTLESON CJ, 1982, J PHOTOGR SCI, V30, P33
   BURNINGHAM N, 1994, IS TS 10 INT C ADV N
   Fahlcrantz C-M., 2003, J GRAPHICS TECHNOLOG, V1, P19
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   Guilford J.P., 1954, Journal of Educational Psychology, Vsecond
   Gurnsey R, 2001, VISION RES, V41, P745, DOI 10.1016/S0042-6989(00)00307-2
   Heaps C, 1999, J EXP PSYCHOL HUMAN, V25, P299, DOI 10.1037/0096-1523.25.2.299
   JACOBSON RE, 1995, J PHOTOGR SCI, V43, P7
   Melara R.D., 1992, Psychophysical approaches to cognition, P303, DOI [DOI 10.1016/S0166-4115(08)61782-3, 10.1016/S0166-4115(08)61782-3]
   RAMSAY JO, 1982, J ROY STAT SOC A STA, V145, P285, DOI 10.2307/2981865
   RAMSAY JO, 1991, UNPUB MULTISCALE MAN
   RAO AR, 1993, CVGIP-GRAPH MODEL IM, V55, P218, DOI 10.1006/cgip.1993.1016
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   SCAVONE GP, 2002, 2002 INT C AUD DISPL
   YEE SN, 1996, IS TS NIP12 INT C DI
NR 19
TC 7
Z9 7
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 271
EP 287
DI 10.1016/j.jvcir.2004.11.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500003
DA 2024-07-18
ER

PT J
AU Chiu, CY
   Chao, SP
   Wu, MY
   Yang, SN
   Lin, HC
AF Chiu, CY
   Chao, SP
   Wu, MY
   Yang, SN
   Lin, HC
TI Content-based retrieval for human motion data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID COMPUTER VISION; VIDEO
AB In this study, we propose a novel framework for constructing a content-based human motion retrieval system. Two major components, including indexing and matching, are discussed and their corresponding algorithms are presented. In indexing, we introduce an affine invariant posture feature and propose an index map structure based on the posture distribution of raw data. To avoid the curse of dimensionality, the high-dimension posture feature of the entire skeleton is decomposed into the direct sum of low-dimension segment-posture features of skeletal segments. In matching, the start and end frames of a query example are first indexed into index maps to find candidate clips from the given motion collection. Then the similarity between the query example and each candidate clip is computed through dynamic time warping. Some experimental examples are given to demonstrate the effectiveness and efficiency of proposed algorithms. (C) 2004 Elsevier Inc. All rights reserved.
C1 Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   Chang Jung Christian Univ, Dept Informat Management, Tainan 711, Taiwan.
C3 National Tsing Hua University; Chang Jung Christian University
RP Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
EM snyang@cs.nthu.edu.tw
RI Chiu, Chih-Yi/AAN-2961-2020
OI Chiu, Chih-Yi/0000-0002-2859-6120
CR Ahanger G, 1996, J VIS COMMUN IMAGE R, V7, P28, DOI 10.1006/jvci.1996.0004
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Ardizzone E, 1997, MULTIMED TOOLS APPL, V4, P29, DOI 10.1023/A:1009630331620
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   BENABELKADER C, 2002, IEEE INT C PATTERN R, P11
   BOBICK AF, 2001, IEEE COMPUTER VISION
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   CHUA PT, 2003, IEEE INT C VIRT REAL
   Dagtas S, 2000, IEEE T IMAGE PROCESS, V9, P88, DOI 10.1109/83.817601
   Davidov JudithFryer., 1998, Women's Camera Work: Self/Body/Other in American Visual Culture, P13
   Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508
   DIMITROVA N, 1995, ACM T INFORM SYST, V13, P408, DOI 10.1145/211430.211433
   DUDA RO, 2001, PATTEN CLASSIFICATIO
   Freeman WT, 1999, COMPUT GRAPHICS-US, V33, P65, DOI 10.1145/345370.345417
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83
   Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355
   *ISO IEC, 2002, JTCISC29WG11
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   KOHLE M, 1937, IEEE S COMPUTER BASE, P138
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li CS, 1998, PROC SPIE, V3656, P2, DOI 10.1117/12.307561
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Lienhart R, 2000, MULTIMED TOOLS APPL, V10, P47, DOI 10.1023/A:1009663921899
   LU G, 1999, MUTLIMEDIA DATABASE
   Meyer D, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P78, DOI 10.1109/ICIP.1997.631988
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Multon F, 1999, J VISUAL COMP ANIMAT, V10, P39, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<39::AID-VIS195>3.0.CO;2-2
   Nabil M, 2001, MULTIMED TOOLS APPL, V13, P35, DOI 10.1023/A:1009677223697
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   PARENT R, 2002, COMPUTER ANIMATIONS
   Parsons T.W., 1986, Voice and Speech Processing
   PONCELON D, 1998, ACM INT C MULT, P99
   SAHOURIA E, 1999, IEEE INT C IM PROC O
   SALTON G, 1983, INTRO MODERN INFORMA
   Shearer K, 1996, J VIS COMMUN IMAGE R, V7, P325, DOI 10.1006/jvci.1996.0028
   Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653
   SUNDARAM H, 1999, SPIE STORAGE RETRIEV
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   1999, WEB3D WORKING GROUP
NR 44
TC 60
Z9 76
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 446
EP 466
DI 10.1016/j.jvcir.2004.04.004
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100010
DA 2024-07-18
ER

PT J
AU Kwon, M
   Kim, CS
   Lee, KM
   Lee, SU
AF Kwon, M
   Kim, CS
   Lee, KM
   Lee, SU
TI Progressive encoding of binary voxel models using pyramidal
   decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE progressive encoding; binary voxels
AB In this paper, we propose a progressive encoding algorithm for the geometric information of a 3D object, which is represented by binary voxels. Using the morphological pyramidal decomposition, the proposed algorithm first generates the multi-resolution models of a 3D object. Then, each resolution model is predicted from its lower resolution model, and the prediction errors are encoded using an arithmetic coding technique. To yield high compression ratio, each model is partitioned into the inside, boundary, and outside regions based on the lower resolution model. This partitioning method greatly reduces the amount of data to be encoded, since the prediction errors are compactly concentrated near the boundary region. Moreover, the neighborhood relation of each boundary voxel is used as the context for the arithmetic coding to further increase the compression efficiency. It is demonstrated by extensive simulation results that the proposed algorithm provides better coding gain than the conventional voxel and mesh compression algorithms. (C) 2003 Elsevier Inc. All rights reserved.
C1 Seoul Natl Univ, Sch Elect Engn, Seoul 151742, South Korea.
   Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.
C3 Seoul National University (SNU); Chinese University of Hong Kong
RP Seoul Natl Univ, Sch Elect Engn, Seoul 151742, South Korea.
EM musik@cvl.snu.ac.kr; sanguk@sting.snu.ac.kr
CR Aiazzi B, 1997, IEEE T IMAGE PROCESS, V6, P831, DOI 10.1109/83.585234
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   DEERING M, 1995, P SIGGRAPH95
   FOWLER J, 1994, 1994 S VOL VIS, P43
   GHAVAMNIA MH, 1995, IEEE C VIS
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   GOUTSIAS J, 2000, IEEE T IMAGE PROCESS, V9
   KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942
   Kaufman AE, 2000, VOLUME GRAPHICS, P3
   Kim CS, 2002, IEEE T IMAGE PROCESS, V11, P932, DOI 10.1109/TIP.2002.800891
   KREEGER K, 1999, SIGGRAPH EUR WORKSH
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   Park IK, 2002, EURASIP J APPL SIG P, V2002, P1127, DOI 10.1155/S1110865702206022
   Qiu GP, 1999, IEEE T IMAGE PROCESS, V8, P109, DOI 10.1109/83.736699
   REZK-SALAMA C., 2000, EGSIGGRAPH WORKSHOP, P109, DOI DOI 10.1145/346876.348238
   SRAMEK M, 1996, P VIRT ENV SCI VIS 9, P201
   TAUBIN G, 1997, VRML COMPRESSED BINA
   TAUBIN G, 1997, RC20340 IBM RES DIV
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   YAU MM, 1983, COMMUN ACM, V26, P504, DOI 10.1145/358150.358158
NR 21
TC 1
Z9 1
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2004
VL 15
IS 1
BP 44
EP 64
DI 10.1016/j.jvcir.2003.04.001
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 772PV
UT WOS:000188851200003
DA 2024-07-18
ER

PT J
AU Wongthanavasu, S
   Sadananda, R
AF Wongthanavasu, S
   Sadananda, R
TI A CA-based edge operator and its performance evaluation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE cellular automata; edge detection; finite state machine
AB This paper presents a new edge detector based on a cellular automata model. A uniform cellular automaton rule using a von Neumann neighborhood is proposed for carrying out edge detection on binary and gray-scaled images. A computational model and characterization of the state space of the rule are analyzed using a finite state machine. The work shows that a cellular automata-based model often provides an optimum edge map on binary images, and on average is better than the compared edge operators for gray-scaled images. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Khon Kaen Univ, Fac Sci, Dept Comp Sci, Khon Kaen 40002, Thailand.
C3 Khon Kaen University
RP Wongthanavasu, S (corresponding author), Khon Kaen Univ, Fac Sci, Dept Comp Sci, Khon Kaen 40002, Thailand.
RI Wongthanavasu, Sartra/AAE-9023-2020; Wongthanavasu,
   Sartra/JAC-7839-2023; Wongthanavasu, Sartra/JFA-0315-2023
OI Wongthanavasu, Sartra/0000-0002-4689-3006
CR ALLEN CR, 1995, VISION ASSISTANT SOF, P42
   Cattell K, 1999, IEEE T COMPUT, V48, P285, DOI 10.1109/12.754995
   CHOWDHURY DR, 1994, J ELECTRON TEST, V5, P67, DOI 10.1007/BF00971964
   CODD EF, 1968, CELLULAR AUTOMATA, P7
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   HERNANDEZ G, 1996, GMIP GRAPHICAL MODEL, V4, P82
   PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331
   STONE HS, 1973, DISCRETE MATH STRUCT, P51
   Wongthanavasu S, 2000, FR ART INT, V59, P343
NR 9
TC 23
Z9 27
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2003
VL 14
IS 2
BP 83
EP 96
DI 10.1016/S1047-3203(03)00022-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 680AJ
UT WOS:000182953900001
DA 2024-07-18
ER

PT J
AU Xue, H
   Ma, J
   Guo, XY
AF Xue, Hao
   Ma, Jing
   Guo, Xiaoyu
TI A hierarchical multi-modal cross-attention model for face anti-spoofing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial recognition; Face anti-spoofing; Multi-modal; Feature fusion;
   Hierarchical feature extraction; Cross-attention
AB Facial recognition has become popular in interactive systems as a means to authenticate identity. However, Facial recognition can be easily attacked illegally through face spoofing. In this paper, we propose a hierarchical multi-modal cross-attention model for face anti-spoofing, which can be flexibly applied in both single-modal and multi-modal scenarios. In order to map features among modalities thoroughly, we also design a novel attention mechanism, namely W-MSA-CA (Window-based Multihead Self-Attention and Cross Attention), which leverages both Multi-modal Multihead Self-Attention (MMSA) and Multi-modal Patch Cross attention (MPCA) to fuse multi-modal features. We test the proposed model on the public datasets and the results show that our model's capability to detect various types of spoofing is effective.
C1 [Xue, Hao; Ma, Jing; Guo, Xiaoyu] Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Ma, J (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Jiangsu, Peoples R China.
EM iamxuehao@nuaa.edu.cn; majing5525@nuaa.edu.cn; xiaoyu.guo@nuaa.edu.cn
FU National Natural Science Foundation of China [72174086]
FX This study was supported by the National Natural Science Foundation of
   China under grant number 72174086.
CR Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Cai RZ, 2023, Arxiv, DOI arXiv:2303.09914
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   George A., 2019, IEEE Trans. Inf. Forensics Secur.
   George A., 2019, 2019 INT C BIOMETRIC, P1
   George A, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI 10.1109/IJCB52358.2021.9484333
   George A, 2020, IEEE T INF FOREN SEC, V15, P42, DOI 10.1109/TIFS.2019.2916652
   Jia Y., 2020, P IEEECVF C COMPUTER, P8484, DOI DOI 10.1109/CVPR42600.2020.00851
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Kollreider K, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P75, DOI 10.1109/AUTOID.2005.20
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Li XB, 2016, INT C PATT RECOG, P4244, DOI 10.1109/ICPR.2016.7900300
   Liu AJ, 2022, IEEE T INF FOREN SEC, V17, P2497, DOI 10.1109/TIFS.2022.3188149
   Liu AJ, 2021, IEEE WINT CONF APPL, P1178, DOI 10.1109/WACV48630.2021.00122
   Liu SQ, 2018, LECT NOTES COMPUT SC, V11220, P577, DOI 10.1007/978-3-030-01270-0_34
   Liu SQ, 2016, LECT NOTES COMPUT SC, V9911, P85, DOI 10.1007/978-3-319-46478-7_6
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Nagpal C, 2019, IEEE IJCNN
   Nowara EM, 2017, IEEE INT CONF AUTOMA, P56, DOI 10.1109/FG.2017.16
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Pan G, 2011, TELECOMMUN SYST, V47, P215, DOI 10.1007/s11235-010-9313-3
   Parkin A, 2019, IEEE COMPUT SOC CONF, P1617, DOI 10.1109/CVPRW.2019.00204
   Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Qin YX, 2022, IEEE T PATTERN ANAL, V44, P6311, DOI 10.1109/TPAMI.2021.3091167
   Shen T, 2019, IEEE COMPUT SOC CONF, P1611, DOI 10.1109/CVPRW.2019.00203
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang GQ, 2019, IEEE COMPUT SOC CONF, P1584, DOI 10.1109/CVPRW.2019.00200
   Wang T, 2013, INT CONF BIOMETR
   Wang ZZ, 2023, IEEE T INF FOREN SEC, V18, P1127, DOI 10.1109/TIFS.2023.3235581
   Wang ZZ, 2019, Arxiv, DOI arXiv:1811.05118
   Wang Z, 2022, PROC CVPR IEEE, P4113, DOI 10.1109/CVPR52688.2022.00409
   Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362
   Yu Z., 2021, P 30 INT JOINT C ART
   Yu Z., 2023, arXiv
   Yu ZT, 2023, Arxiv, DOI arXiv:2202.08192
   Yu ZT, 2024, Arxiv, DOI arXiv:2208.05401
   Yu ZT, 2023, IEEE T PATTERN ANAL, V45, P5609, DOI 10.1109/TPAMI.2022.3215850
   Yu ZT, 2021, IEEE T PATTERN ANAL, V43, P3005, DOI 10.1109/TPAMI.2020.3036338
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Yu ZT, 2020, IEEE COMPUT SOC CONF, P2766, DOI 10.1109/CVPRW50498.2020.00333
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zitong Yu, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P285, DOI 10.1109/TBIOM.2021.3065526
   Zitong Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P557, DOI 10.1007/978-3-030-58571-6_33
NR 56
TC 1
Z9 1
U1 15
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103969
DI 10.1016/j.jvcir.2023.103969
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z4BK7
UT WOS:001111544400001
DA 2024-07-18
ER

PT J
AU Hong, J
   Lee, B
   Ko, K
   Ko, H
AF Hong, Jonghwan
   Lee, Bokyeung
   Ko, Kyungdeuk
   Ko, Hanseok
TI Fast Non-Local Attention network for light super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single Image Super-Resolution; Non-Local Attention; Light model
AB Although convolutional neural network-based methods have achieved significant performance improvement for Single Image Super-Resolution (SISR), their vast computational cost hinders real-world environment application. Thus, the interest in light networks for SISR is rising. Since existing SISR light models mainly focus on extracting fine local features using convolution operation, they have a limitation in that networks hardly capture global information. To capture the long-range dependency, Non-Local (NL) attention and Transformers have been explored in the SISR task. However, they are still suffering from a balancing problem between performance and computational cost. In this paper, we propose Fast Non-Local attention NETwork (FNLNET) for a super light SISR, which can capture the global representation. To acquire global information, we propose The Fast Non-Local Attention (FNLA) module that has low computational complexity while capturing global representation that reflects long-distance relationships between patches. Then, FNLA requires only 16 times lower computational cost than conventional NL networks while improving performance. In addition, we propose a powerful module called Global Self-Intension Mining (GSIM) that fuses the multi-information resources such as local, and global representation. Our FNLNET shows outstanding performance with fewer parameters and computational costs in the experiments on the benchmark datasets against state-of-the-art light SISR models.
C1 [Hong, Jonghwan; Lee, Bokyeung; Ko, Kyungdeuk; Ko, Hanseok] Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
C3 Korea University
RP Ko, H (corresponding author), Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
EM jhong2661@korea.ac.kr; bksain@korea.ac.kr; kdko@korea.ac.kr;
   hsko@korea.ac.kr
OI Ko, Hanseok/0000-0002-8744-4514
FU Major Project of the Korea Institute of Civil Engineering and Building
   Technology (KICT) [20220238-001]
FX This work was supported by the Major Project of the Korea Institute of
   Civil Engineering and Building Technology (KICT) [grant number
   20220238-001] .
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gwantae Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P1862, DOI 10.1109/CVPRW50498.2020.00236
   Heo B., 2020, SLOWING WEIGHT NORM
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jing YC, 2022, LECT NOTES COMPUT SC, V13667, P111, DOI 10.1007/978-3-031-20071-7_7
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing Yongcheng, 2021, P IEEE CVF INT C COM, P5301
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ko K., 2021, BRIT MACH VIS C BMVC
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lee B, 2023, NEUROCOMPUTING, V524, P59, DOI 10.1016/j.neucom.2022.12.050
   Lee B, 2022, IEEE SIGNAL PROC LET, V29, P1943, DOI 10.1109/LSP.2022.3205275
   Lee J., 2020, P IEEE CVF C COMP VI P IEEECVF C COMPUTER, P488
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu D, 2018, ADV NEUR IN, V31
   Lu ZS, 2022, IEEE COMPUT SOC CONF, P456, DOI 10.1109/CVPRW56347.2022.00061
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Muqeet Abdul, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P103, DOI 10.1007/978-3-030-67070-2_6
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Qin Z., 2021, 2021 IEEE INT C IM P, P1799
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Trockman A, 2022, Arxiv, DOI [arXiv:2201.09792, DOI 10.48550/ARXIV.2201.09792,09792]
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang X., 2020, P AS C COMP VIS
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang XY, 2022, Arxiv, DOI arXiv:2210.17409
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang YL, 2019, Arxiv, DOI arXiv:1903.10082
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 44
TC 0
Z9 0
U1 3
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103861
DI 10.1016/j.jvcir.2023.103861
EA JUN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3EG9
UT WOS:001022119200001
DA 2024-07-18
ER

PT J
AU Park, J
   Vien, AG
   Cha, M
   Pham, TT
   Kim, H
   Lee, C
AF Park, Jaemin
   Vien, An Gia
   Cha, Minhee
   Pham, Thuy Thi
   Kim, Hanul
   Lee, Chul
TI Multiple transformation function estimation for image enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image enhancement; Multiple transformation functions; Color
   representation; Histogram representation
ID CONTRAST ENHANCEMENT; GAMMA-CORRECTION; VISIBILITY; FRAMEWORK
AB Most deep learning-based image enhancement algorithms have been developed based on the image-to image translation approach, in which enhancement processes are difficult to interpret. In this paper, we propose a novel interpretable image enhancement algorithm that estimates multiple transformation functions to describe complex color mapping. First, we develop a histogram-based multiple transformation function estimation network (HMTF-Net) to estimate multiple transformation functions by exploiting both the spatial and statistical information of the input images. Second, we estimate pixel-wise weight maps, which indicate the contribution of each transformation function at each pixel, based on the local structures of the input image and the transformed images obtained by each transformation function. Finally, we obtain the enhanced image as the weighted sum of the transformed images using the estimated weight maps. Extensive experiments confirm the effectiveness of the proposed approach and demonstrate that the proposed algorithm outperforms state-of-the-art image enhancement algorithms for different image enhancement tasks.
C1 [Park, Jaemin; Vien, An Gia; Cha, Minhee; Pham, Thuy Thi; Lee, Chul] Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
   [Kim, Hanul] Seoul Natl Univ Sci & Technol, Dept Appl Artificial Intelligence, Seoul 01811, South Korea.
   [Park, Jaemin] LIG Nex1 Co Ltd, Dept EO IR Syst Res & Dev, Yongin 16911, Gyeonggi Do, South Korea.
C3 Dongguk University; Seoul National University of Science & Technology;
   LIG Nex1 Co., Ltd.
RP Lee, C (corresponding author), Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
EM jaemin@mme.dongguk.edu; viengiaan@mme.dongguk.edu;
   2019112531@mme.dongguk.edu; pham.thuy@mme.dongguk.edu;
   hukim@seoultech.ac.kr; chullee@dongguk.edu
RI Vien, An Gia/AHE-7143-2022
OI Vien, An Gia/0000-0003-0067-0285; Lee, Chul/0000-0001-9329-7365
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2022R1F1A1074402]; Culture, Sports and Tourism Ramp;D Program
   through the Korea Creative Content Agency (KOCCA) - Korea government
   (MCST) [R2022020120]
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2022R1F1A1074402) and in part by the Culture, Sports and Tourism R &
   D Program through the Korea Creative Content Agency (KOCCA) grant funded
   by the Korea government (MCST) (No. R2022020120) .
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Gong SJ, 2021, PATTERN RECOGN LETT, V152, P50, DOI 10.1016/j.patrec.2021.08.022
   Gonzalez R.C., 2018, Digital Image Processing
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Han-Ul Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P339, DOI 10.1007/978-3-030-58595-2_21
   He ZW, 2020, IEEE T MULTIMEDIA, V22, P1042, DOI 10.1109/TMM.2019.2937688
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jeon JJ, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108523
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Ju MY, 2018, IEEE SIGNAL PROC LET, V25, P1084, DOI 10.1109/LSP.2018.2839580
   Kim D, 2017, IEEE SIGNAL PROC LET, V24, P804, DOI 10.1109/LSP.2017.2687945
   Kim H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4439, DOI 10.1109/ICCV48922.2021.00442
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee JH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5087, DOI 10.1109/ICCV48922.2021.00506
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liang J, 2022, PROC CVPR IEEE, P5647, DOI 10.1109/CVPR52688.2022.00557
   Liang J, 2021, PROC CVPR IEEE, P9387, DOI 10.1109/CVPR46437.2021.00927
   Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361
   Lin YH, 2022, IEEE T IMAGE PROCESS, V31, P4897, DOI 10.1109/TIP.2022.3189805
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moran S, 2021, INT C PATT RECOG, P9796, DOI 10.1109/ICPR48806.2021.9412677
   Park J., 2022, PROC IEEE INT C IMAG, P1
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Qi Q, 2022, IEEE T CIRC SYST VID, V32, P1133, DOI 10.1109/TCSVT.2021.3074197
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sen D, 2011, IEEE T IMAGE PROCESS, V20, P1211, DOI 10.1109/TIP.2010.2083676
   Sharma G, 2003, EL EN AP SI, P1
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang YF, 2022, AAAI CONF ARTIF INTE, P2604
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu WH, 2022, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR52688.2022.00581
   Xu X., 2022, IEEECVF C COMPUT VIS, P17714
   Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004
   Yang KF, 2019, IEEE T CIRC SYST VID, V29, P640, DOI 10.1109/TCSVT.2018.2810212
   Yang WH, 2020, IEEE T IMAGE PROCESS, V29, P5737, DOI 10.1109/TIP.2020.2981922
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2021, IEEE T MULTIMEDIA, V23, P189, DOI 10.1109/TMM.2020.2982045
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang RK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2429, DOI 10.1145/3474085.3475410
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang WD, 2022, IEEE T IMAGE PROCESS, V31, P3997, DOI 10.1109/TIP.2022.3177129
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhang ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4086, DOI 10.1109/ICCV48922.2021.00407
   Zhao L., 2021, P IEEE CVF INT C COM, P12075
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang PX, 2022, IEEE T IMAGE PROCESS, V31, P5442, DOI 10.1109/TIP.2022.3196546
NR 72
TC 2
Z9 2
U1 3
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103863
DI 10.1016/j.jvcir.2023.103863
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P2OG5
UT WOS:001049079100001
DA 2024-07-18
ER

PT J
AU Malhotra, R
   Saini, BS
   Gupta, S
AF Malhotra, Radhika
   Saini, Barjinder Singh
   Gupta, Savita
TI CB-D2RNet-An efficient context bridge network for glioma segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MRI; Context bridge; Loss function; Dilated convolution
ID BRAIN-TUMOR SEGMENTATION; U-NET
AB The recent automatic glioma segmentation and localization techniques obtained promising results, but there is much scope for improvement in execution complexity and segmentation efficiency. These methods often fail to pinpoint small and isolated target locations in necrotic and enhancing glioma sub-regions. Moreover, the computational complexity and number of model parameters utilized in these techniques are also high. To address such issues, a Context Bridge-Dense Dilated Residual Net (CB-D2RNet) is proposed in this paper which reflects the five novel contributions. Firstly, a Dense Dilated Convolutional (DDC) block is formed with four cascade branches to cope with large morphological differences in gliomas. Secondly, the skip connections in traditional UNet are redesigned to overcome the large contextual gap between encoder-decoder. Thirdly, a new loss function is proposed that handles unequal class distribution in gliomas and provides a regularization impact. Fourthly, the precise selection of dilation rates is made for each dilated convolutional block in the feature encoder to gather a more receptive view of complex and multiple tumor regions. Lastly, only a single convolutional operation is included in the feature encoder and decoder, unlike other state-of-the-art models. The experiments are conducted on BraTS 2018 and BraTS 2019 benchmarks, demonstrating that the proposed model performs competitively in all three glioma sub-regions. It achieves dice similarity coefficient for the whole tumor, tumor core, and enhancing tumor as 0.982, 0.987, and 0.976, respectively for the BraTS 2018 dataset, whereas 0.983, 0.989, and 0.977 respectively for the BraTS 2019 dataset. Besides this, the model uses only 6.7 million parameters, the lowest among other compared models.
C1 [Malhotra, Radhika; Saini, Barjinder Singh] Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun, Jalandhar 144011, Punjab, India.
   [Gupta, Savita] Panjab Univ, UIET, Dept Comp Sci & Engg, Sect 25, Chandigarh 160023, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Panjab University
RP Malhotra, R (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun, Jalandhar 144011, Punjab, India.
EM radhikamalhotra0912@gmail.com
RI Saini, Barjinder Singh/Y-2321-2019
OI Saini, Barjinder Singh/0000-0003-0932-6851
CR Aboelenein NM, 2020, IEEE ACCESS, V8, P101406, DOI 10.1109/ACCESS.2020.2998601
   Ahmad P, 2019, ICBDC 2019: PROCEEDINGS OF 2019 4TH INTERNATIONAL CONFERENCE ON BIG DATA AND COMPUTING, P304, DOI 10.1145/3335484.3335516
   Ali M, 2020, IEEE ACCESS, V8, P153589, DOI 10.1109/ACCESS.2020.3018160
   Amian M., 2019, MULTIRESOLUTION 3D C, P1
   Ben Naceur M, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101692
   Cabezas M, 2018, Arxiv, DOI arXiv:1810.04274
   Castricato L., 2017, IMAGE SEGMENTATION P, V1, P118, DOI [10.1007/978-3-319-70096-0, DOI 10.1007/978-3-319-70096-0]
   Chaddad A, 2019, IEEE J BIOMED HEALTH, V23, P795, DOI 10.1109/JBHI.2018.2825027
   Crimi A., 2018, ENSEMBLE FULLY CONVO
   Crimi A., 2018, ENSEMBLES DENSELY CO
   Ding Y, 2019, IEEE ACCESS, V7, P152821, DOI 10.1109/ACCESS.2019.2948120
   Feng X, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00025
   Frey M, 2020, LECT NOTES COMPUT SC, V11992, P388, DOI 10.1007/978-3-030-46640-4_37
   Gan CQ, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.035
   Hamghalam M, 2020, LECT NOTES COMPUT SC, V11992, P153, DOI 10.1007/978-3-030-46640-4_15
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang Z, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102958
   Isensee F, 2019, LECT NOTES COMPUT SC, V11384, P234, DOI 10.1007/978-3-030-11726-9_21
   Ismail A, 2022, NEURAL COMPUT APPL, V34, P21777, DOI 10.1007/s00521-022-07633-3
   Ismail A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165413
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu P, 2020, IEEE ACCESS, V8, P34029, DOI 10.1109/ACCESS.2020.2973707
   Lopez MM, 2018, LECT NOTES COMPUT SC, V10670, P253, DOI 10.1007/978-3-319-75238-9_22
   Malhotra R, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169443
   McKinley R., 2020, TRIPLANAR ENSEMBLE 3
   Myronenko A, 2020, LECT NOTES COMPUT SC, V11993, P82, DOI 10.1007/978-3-030-46643-5_8
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Pawar K, 2020, LECT NOTES COMPUT SC, V11992, P359, DOI 10.1007/978-3-030-46640-4_34
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shoushtari FK, 2022, PHYS MEDICA, V100, P51, DOI 10.1016/j.ejmp.2022.06.007
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Sun L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00810
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang JJ, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106208
   Wang L, 2020, IEEE ACCESS, V8, P167939, DOI 10.1109/ACCESS.2020.3020475
   Xu H, 2019, LECT NOTES COMPUT SC, V11766, P420, DOI 10.1007/978-3-030-32248-9_47
   Xue YZ, 2020, LECT NOTES COMPUT SC, V11993, P255, DOI 10.1007/978-3-030-46643-5_25
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang TJ, 2020, J X-RAY SCI TECHNOL, V28, P95, DOI 10.3233/XST-190552
   Yue Zhang, 2021, Journal of Shanghai Jiaotong University (Science), V26, P93, DOI 10.1007/s12204-021-2264-x
   Zhang DW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107562
   Zhang DW, 2020, IEEE T IMAGE PROCESS, V29, P9032, DOI 10.1109/TIP.2020.3023609
   Zhang JX, 2020, IEEE ACCESS, V8, P58533, DOI 10.1109/ACCESS.2020.2983075
   Zhang JJ, 2021, NEUROCOMPUTING, V421, P195
   Zhang Z, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105395
   Zhou XY, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2021.114566
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 59
TC 1
Z9 1
U1 3
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103836
DI 10.1016/j.jvcir.2023.103836
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K0TF3
UT WOS:001013651400001
DA 2024-07-18
ER

PT J
AU Sharma, VK
   Dhiman, P
   Rout, RK
AF Sharma, Vipul Kumar
   Dhiman, Pankaj
   Rout, Ranjeet Kumar
TI Improved traffic sign recognition algorithm based on YOLOv4-tiny
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Traffic sign; YOLO; Attention networks; Octave convolutions; Computer
   vision
AB This study offers an enhanced yolov4-tiny traffic sign identification method for easy deployment on mobile or embedded devices to address the difficulties of a high number of parameters, low recognition accuracy, and poor real-time performance of traffic sign recognition models in complex scenarios. The yolov4-tiny network serves as the model's foundation. To begin, Octave Convolution is incorporated into the backbone network to eliminate low-frequency feature redundancy, lowering the number of parameters in the model and enhancing computational efficiency. Second, the convolutional block attention module is employed to improve the recognition accuracy of small and medium-sized targets by strengthening the weights of traffic sign regions and suppressing the weights of invalid features. Finally, in the feature fusion stage, the Feature Pyramid Networks structure is replaced with the Simplified Path Aggregation Network structure to improve the fusing of shallow feature information with deep semantic knowledge and lower the miss detection rate even more On the TT100K data set as well as on CCTSDB dataset, the experimental results suggest that our technique can achieve good recognition performance. With a 16MB model size, our solution improves the mean average precision by 3.5 percent and the Frame Per Second by 12.5 f/s when compared to the yolov4-tiny algorithm. Our method outperforms yolov4-tiny in terms of recognition accuracy and detection speed, and it can easily meet the real-time requirements for traffic sign recognition.
C1 [Sharma, Vipul Kumar; Dhiman, Pankaj] Jaypee Univ Informat Technol, Dept Comp Sci Engn & Informat Technol, Solan, India.
   [Rout, Ranjeet Kumar] Natl Inst Technol Srinagar, Dept Comp Sci & Engn, Srinagar, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Srinagar
RP Sharma, VK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci Engn & Informat Technol, Solan, India.
EM vipul.sharma@juitsolan.in; pankaj.dhiman@juitsolan.in;
   ranjeetkumarrout@nitsri.net
RI Sharma, Vipul/AAT-3816-2020; Rout, Ranjeet Kumar/JCE-3978-2023
OI Sharma, Vipul/0000-0003-4970-2778; 
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng Tianmin, 2020, Journal of Computer Applications, V40, P2872, DOI 10.11772/j.issn.1001-9081.2020020214
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang GB, 2004, IEEE IJCNN, P985
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang ZC, 2020, Arxiv, DOI [arXiv:2011.04244, DOI 10.48550/ARXIV.2011.04244]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liang Min-jian, 2017, Journal of Traffic and Transportation Engineering, V17, P151
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Takaki Masanari, 2009, Transactions of the Institute of Electrical Engineers of Japan, Part C, V129, P824, DOI 10.1541/ieejeiss.129.824
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu KJ, 2021, IEEE ACCESS, V9, P113889, DOI 10.1109/ACCESS.2021.3103522
   Zhang JM, 2022, J REAL-TIME IMAGE PR, V19, P1155, DOI 10.1007/s11554-022-01252-w
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang Xiaoxue, 2022, J PHYS C SERIES, V2303
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 32
TC 9
Z9 9
U1 8
U2 57
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103774
DI 10.1016/j.jvcir.2023.103774
EA FEB 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8X4EZ
UT WOS:000931968900001
DA 2024-07-18
ER

PT J
AU Liu, AA
   Du, HW
   Xu, N
   Zhang, Q
   Zhang, SY
   Tang, YJ
   Li, XY
AF Liu, An-An
   Du, Hongwei
   Xu, Ning
   Zhang, Quan
   Zhang, Shenyuan
   Tang, Yejun
   Li, Xuanya
TI Exploring visual relationship for social media popularity prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Social media popularity prediction; Visual relationship; Content-based
   filtering; Interpretability
AB Social media popularity prediction is an important channel to explore content sharing and communication on social networks. It aims to capture informative cues by analyzing multi-type data (such as images, user profiles, and text) to decide the popularity of a specified post. Intuitively, given an image, humans can volitionally focus on salient objects and relationships that are associated with their interests. For example, when we see the image including the relationship "elephant-attack-van", it is more natural to increase our interest than the image with "elephant-near-van". Therefore, exploiting such structural relationships is expected to help the prediction model search for evidence in support of the popularity of posts. However, most current works only focus on the global representation or the isolated objects, while ignoring the structure knowledge contained in images. To address this problem, we propose the relationship-aware social media popularity predictor. First, we extract inter-object relationships via a pre-trained scene graph generator. Then, we design a content-based filtering module to filter redundant relationships and capture the key ⟨subject-predicate-object⟩ information. Finally, we integrate relationship information with multi-type heterogeneous data and feed them into the CatBoost model for regression. Moreover, our predictor is capable of generating more intuitive interpretations by analyzing visual relationships in images to reasonably infer popularity scores. Extensive experiments conducted on the Social Media Prediction Dataset demonstrate that the proposed method can outperform other state-of-the-art models. Additional ablation studies and visualizations further validate the effectiveness and interpretability.
C1 [Liu, An-An; Du, Hongwei; Xu, Ning] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Liu, An-An] Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei 230088, Peoples R China.
   [Zhang, Quan] Peking Univ, Beijing 100871, Peoples R China.
   [Zhang, Shenyuan] Peoples Daily, Beijing 100733, Peoples R China.
   [Tang, Yejun] Kuaishou Technol, Beijing 100000, Peoples R China.
   [Li, Xuanya] Baidu, Beijing 100085, Peoples R China.
C3 Tianjin University; Peking University; Baidu
RP Xu, N (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM anan0422@gmail.com; duhw2020@tju.edu.cn; ningxu@tju.edu.cn;
   zhangshenyuan0@gmail.com; zhangshenyuan0@gmail.com;
   tangyejun@kuaishou.com; lixuanya@baidu.com
FU National Key Research and Development Program of China [2020YFB1406600];
   National Natural Science Foundation of China, China [U21B2024,
   62002257]; China Postdoctoral Science Foundation, China [2021M692395]
FX Acknowledgments This work was supported in part by the National Key
   Research and Development Program of China (2020YFB1406600) , the
   National Natural Science Foundation of China, China (U21B2024, 62002257)
   , the China Postdoctoral Science Foundation, China (2021M692395) .
CR [Anonymous], 2014, P INT C MULTIMEDIA R, DOI [DOI 10.1145/2578726.2578776, 10.1145/2578726.2578776, 10.1145]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen JH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2692, DOI 10.1145/3343031.3356072
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Ding KY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1979, DOI 10.1145/3343031.3351007
   Ding KY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2682, DOI 10.1145/3343031.3356062
   Gelli F, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P907, DOI 10.1145/2733373.2806361
   Goldfarb A, 2011, MARKET SCI, V30, P389, DOI 10.1287/mksc.1100.0583
   HANSEN PC, 1987, BIT, V27, P534, DOI 10.1007/BF01937276
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2672, DOI 10.1145/3343031.3356054
   Hidayati SC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1918, DOI 10.1145/3123266.3127903
   Hsu CC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4585, DOI 10.1145/3394171.3417332
   Hsu CC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2687, DOI 10.1145/3343031.3356064
   Hsu CC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2008, DOI 10.1145/3240508.3266443
   Hsu CC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1865, DOI 10.1145/3123266.3127894
   Huang FT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2013, DOI 10.1145/3240508.3266439
   Huang XW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1895, DOI 10.1145/3123266.3127899
   Kang PP, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2677, DOI 10.1145/3343031.3356060
   Ke GL, 2017, ADV NEUR IN, V30
   Lai X, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4565, DOI 10.1145/3394171.3416273
   Le Callet P, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57687-9_1
   Li C, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1959, DOI 10.1145/2783258.2788582
   Li LW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2003, DOI 10.1145/3240508.3266438
   Li LW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1912, DOI 10.1145/3123266.3127902
   Lv JN, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1883, DOI 10.1145/3123266.3127897
   Mazloom M., 2016, P ACM MULT, P197, DOI [10.1145/2964284.2967210, 10]
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Son JW, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1297, DOI 10.1145/3077136.3084139
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   Wang K, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4570, DOI 10.1145/3394171.3416294
   Wu B, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2667, DOI 10.1145/3343031.3356084
   Wu B, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3062
   Wu B, 2016, AAAI CONF ARTIF INTE, P272
   Wu B, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1336, DOI 10.1145/2964284.2964335
   Wu CC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P727, DOI 10.1145/2600428.2609569
   Xu KL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4580, DOI 10.1145/3394171.3416274
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
NR 45
TC 0
Z9 0
U1 6
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103738
DI 10.1016/j.jvcir.2022.103738
EA JAN 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8A0DL
UT WOS:000915919200001
DA 2024-07-18
ER

PT J
AU Xue, MQ
   Zhang, HF
   Huang, QH
   Song, J
   Song, ML
AF Xue, Mengqi
   Zhang, Haofei
   Huang, Qihan
   Song, Jie
   Song, Mingli
TI Learn decision trees with deep visual primitives
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interpretability; Deep neural network; Discrete representation learning
ID COMPUTER VISION
AB In this paper, we strive to propose a self-interpretable framework, termed PrimitiveTree, that incorporates deep visual primitives condensed from deep features with a conventional decision tree, bridging the gap between deep features extracted from deep neural networks (DNNs) and trees' transparent decision-making processes. Specifically, we utilize a codebook, which embeds the continuous deep features into a finite discrete space (deep visual primitives) to distill the most common semantic information. The decision tree adopts the spatial location information and the mapped primitives to present the decision-making process of the deep features in a tree hierarchy. Moreover, the trained interpretable PrimitiveTree can inversely explain the constituents of the deep features, highlighting the most critical and semantic-rich image patches attributing to the final predictions of the given DNN. Extensive experiments and visualization results validate the effectiveness and interpretability of our method.
C1 [Xue, Mengqi; Zhang, Haofei; Huang, Qihan; Song, Mingli] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Song, Jie] Zhejiang Univ, Sch Software Technol, Ningbo, Zhejiang, Peoples R China.
   [Xue, Mengqi] Zhejiang Univ, China Southern Power Grid Joint Res Ctr AI, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University
RP Song, J (corresponding author), Zhejiang Univ, Sch Software Technol, Ningbo, Zhejiang, Peoples R China.
EM mqxue@zju.edu.cn; haofeizhang@zju.edu.cn; qh.huang@zju.edu.cn;
   sjie@zju.edu.cn; brooksong@zju.edu.cn
RI Yuan, Ye/KBC-9835-2024; Qi, Ling/KHE-3068-2024; huang,
   qihan/GXF-7714-2022; Song, Jie/JXK-0735-2024; Yun, Wang/KHM-3009-2024
OI Yuan, Ye/0009-0008-1640-7047; Xue, Mengqi/0000-0003-4936-4887
FU National Natural Science Foundation of China [62106220, U20B2066];
   Ningbo Natural Science Foundation [2021J189]; Starry Night Science Fund
   of Zhejiang University Shanghai Institute for Advanced Study
   [SN-ZJU-SIAS-001]; Open Research Projects of Zhejiang Lab
   [2019KD0AD01/018]; Fundamental Research Funds for the Central
   Universities and Science; Technology Project of SGCC [52094022001J]
FX This work is supported by National Natural Science Foundation of China
   (62106220, U20B2066), Ningbo Natural Science Foundation (2021J189), the
   Starry Night Science Fund of Zhejiang University Shanghai Institute for
   Advanced Study (Grant No. SN-ZJU-SIAS-001), Open Research Projects of
   Zhejiang Lab (NO. 2019KD0AD01/018), the Fundamental Research Funds for
   the Central Universities and Science, and the Technology Project of SGCC
   (No. 52094022001J): human-machine collaborative hybrid-augmented
   intelligence technology and its application in regional power grid
   reliability analysis.
CR Agarwal Rishabh, 2021, ADV NEURAL INFORM PR, V34
   Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354
   Buhrmester V, 2021, MACH LEARN KNOW EXTR, V3, P966, DOI 10.3390/make3040048
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084
   Chen CF, 2019, ADV NEUR IN, V32
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen X, 2016, ADV NEUR IN, V29
   Chen Y., 2021, P IEEECVF INT C COMP, P5047
   Codella Noel C. F., 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P97, DOI 10.1007/978-3-030-02628-8_11
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   Dara Suresh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1795, DOI 10.1109/ICECA.2018.8474912
   Dastile X, 2021, IEEE ACCESS, V9, P50426, DOI 10.1109/ACCESS.2021.3068854
   Deng J., 2009, IEEE C COMP VIS PATT
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Fan FL, 2020, NEUROCOMPUTING, V374, P10, DOI 10.1016/j.neucom.2019.09.001
   Frosst N, 2017, Arxiv, DOI arXiv:1711.09784
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Garreau D, 2020, PR MACH LEARN RES, V108, P1287
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graziani M, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103865
   Hayashi Y, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081318
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2021, P IEEE CVF INT C COM, P672
   Huang HP, 2018, PHYS REV E, V98, DOI 10.1103/PhysRevE.98.062313
   Karthikeyan A, 2021, Arxiv, DOI arXiv:2102.07567
   Kim J, 2017, IEEE I CONF COMP VIS, P2961, DOI 10.1109/ICCV.2017.320
   Kontschieder P, 2015, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2015.172
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei Ba J., 2016, arXiv
   Li HL, 2022, Arxiv, DOI arXiv:2209.03415
   Liao RJ, 2016, ADV NEUR IN, V29
   Liao WM, 2020, IEEE J BIOMED HEALTH, V24, P1405, DOI 10.1109/JBHI.2019.2949075
   Liu Z, 2022, Arxiv, DOI [arXiv:2111.09883, 10.48550/arXiv.2111.09883]
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loh WY, 2011, WIRES DATA MIN KNOWL, V1, P14, DOI 10.1002/widm.8
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Mao C., 2022, INT C LEARNING REPRE
   Molle Pieter, 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P115, DOI 10.1007/978-3-030-02628-8_13
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Nauta M, 2021, PROC CVPR IEEE, P14928, DOI 10.1109/CVPR46437.2021.01469
   Radosavovic Ilija, 2020, P IEEE CVF C COMP VI, P10428
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Razavi A, 2019, ADV NEUR IN, V32
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sheu YH, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.551299
   Simonyan K, 2014, Arxiv, DOI arXiv:1312.6034
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singla Sahil, 2019, INT C MACHINE LEARNI, P5848
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Ross AS, 2017, Arxiv, DOI arXiv:1703.03717
   Smilkov D, 2017, Arxiv, DOI [arXiv:1706.03825, DOI 10.48550/ARXIV.1706.03825]
   Stone A, 2017, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2017.85
   Subramanian A, 2018, AAAI CONF ARTIF INTE, P4921
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanno R, 2019, PR MACH LEARN RES, V97
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   van den Oord A, 2017, ADV NEUR IN, V30
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan A., 2020, arXiv
   Wang HL, 2021, IEEE INT CONF ROBOT, P13731, DOI 10.1109/ICRA48506.2021.9561334
   Wu MK, 2018, AAAI CONF ARTIF INTE, P1670
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue M., 2021, INT C INTELLIGENT CO, P175
   Xue M., 2021, ARXIV
   Xue MQ, 2022, Arxiv, DOI arXiv:2208.10431
   Xue MQ, 2022, PROC CVPR IEEE, P150, DOI 10.1109/CVPR52688.2022.00025
   Yan HT, 2023, Arxiv, DOI arXiv:2201.01615
   Yang CL, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1563, DOI 10.1109/HPCC/SmartCity/DSS.2018.00256
   Yang XY, 2022, Arxiv, DOI arXiv:2207.03337
   You S, 2017, ADV NEUR IN, V30
   Zablocki E, 2021, Arxiv, DOI arXiv:2101.05307
   Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang QM, 2022, Arxiv, DOI [arXiv:2202.10108, 10.48550/arXiv.2202.10108]
   Zhang QS, 2019, PROC CVPR IEEE, P6254, DOI 10.1109/CVPR.2019.00642
   Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou J., 2022, INT C LEARNING REPRE
NR 89
TC 1
Z9 1
U1 5
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103682
DI 10.1016/j.jvcir.2022.103682
EA NOV 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600003
DA 2024-07-18
ER

PT J
AU Babu, KK
   Dubey, SR
AF Babu, Kancharagunta Kishan
   Dubey, Shiv Ram
TI CDGAN: Cyclic Discriminative Generative Adversarial Networks for
   image-to-image transformation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep networks; Computer vision; Generative Adversarial Nets;
   Image-to-image transformation; Cyclic-Discriminative Adversarial loss
AB Generative Adversarial Networks (GANs) have facilitated a new direction to tackle the image-to-image transformation problem. Different GANs use generator and discriminator networks with different losses in the objective function. Still there is a gap to fill in terms of both the quality of the generated images and close to the ground truth images. In this work, we introduce a new Image-to-Image Transformation network named Cyclic Discriminative Generative Adversarial Networks (CDGAN) that fills the above mentioned gaps. The proposed CDGAN generates high quality and more realistic images by incorporating the additional discriminator networks for cycled images in addition to the original architecture of the CycleGAN. The proposed CDGAN is tested over three image-to-image transformation datasets. The quantitative and qualitative results are analyzed and compared with the state-of-the-art methods. The proposed CDGAN method outperforms the state-of-the-art methods when compared over the three baseline Image-to-Image transformation datasets. The code is available at https://github.com/KishanKancharagunta/CDGAN.
C1 [Babu, Kancharagunta Kishan] Indian Inst Informat Technol, Sri City 517646, Andhra Pradesh, India.
   [Dubey, Shiv Ram] Indian Inst Informat Technol, Allahabad 211015, Uttar Pradesh, India.
   [Dubey, Shiv Ram] IIIT Sri City, Sri City, Andhra Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Babu, KK (corresponding author), Indian Inst Informat Technol, Sri City 517646, Andhra Pradesh, India.
EM kishanbabu.k@iiits.in; srdubey@iiita.ac.in
RI Dubey, Shiv Ram/T-7541-2019; Kishan Babu, Kancharagunta/ABH-1471-2020
OI Dubey, Shiv Ram/0000-0002-4532-8996; Kishan Babu,
   Kancharagunta/0000-0001-5613-804X
CR Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen JX, 2016, INT CONF SIGN PROCES, P663, DOI 10.1109/ICSP.2016.7877915
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Cui R, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102923
   Feng Z., 2018, NEURIPS
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo TT, 2016, IEEE GLOB CONF SIG, P237, DOI 10.1109/GlobalSIP.2016.7905839
   Hu YT, 2020, IEEE T CIRC SYST VID, V30, P3911, DOI 10.1109/TCSVT.2019.2915238
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kancharagunta K.B., 2019, ARXIV190103554
   Kazemi H, 2018, IEEE WINT CONF APPL, P1, DOI 10.1109/WACVW.2018.00006
   Kingma D. P., 2014, arXiv
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CY, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102956
   Liao K., 2019, IEEE T CIRC SYST VID
   Liu JY, 2019, IEEE T IMAGE PROCESS, V28, P699, DOI 10.1109/TIP.2018.2869722
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Niu Y., 2020, J VIS COMMUN IMAGE R
   Pang YW, 2019, IEEE T CIRC SYST VID, V29, P3211, DOI 10.1109/TCSVT.2018.2880223
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Radford A., 2015, ARXIV
   Tyleek R., 2013, GERM C PATT REC 2013
   Wang C., 2019, IEEE transactions on neural networks and learning systems
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang LD, 2018, IEEE INT CONF AUTOMA, P83, DOI 10.1109/FG.2018.00022
   Wang X., 2008, IEEE transactions on pattern analysis and machine intelligence, P1955
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen SP, 2019, IEEE T CIRC SYST VID, V29, P2337, DOI 10.1109/TCSVT.2018.2867934
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yuan MK, 2020, IEEE T CIRC SYST VID, V30, P4258, DOI 10.1109/TCSVT.2019.2953753
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang L, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102899
   Zhang LL, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P627, DOI 10.1145/2671188.2749321
   Zhang R., 2016, EUR C COMP VIS 2016
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang SC, 2019, IEEE T NEUR NET LEAR, V30, P1419, DOI 10.1109/TNNLS.2018.2869574
   Zhao H., 2020, J VIS COMMUN IMAGE R
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu MR, 2019, IEEE T NEUR NET LEAR, V30, P3096, DOI 10.1109/TNNLS.2018.2890018
NR 48
TC 4
Z9 6
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103382
DI 10.1016/j.jvcir.2021.103382
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z2GF
UT WOS:000790895000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, CQ
   Qian, YR
   Gong, WJ
   Cheng, JO
   Wang, YQ
   Wang, YF
AF Wang, Chaoqing
   Qian, Yurong
   Gong, Weijun
   Cheng, Junjong
   Wang, Yongqiang
   Wang, Yuefei
TI Cross-layer progressive attention bilinear fusion method for
   fine-grained visual classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained visual classification; Feature fusion; Attention;
   Progressive
AB Fine-grained visual classification (FGVC) is a critical task in the field of computer vision. However, FGVC is full of challenges due to the large intra-class variation and small inter-class variation of the classes to be classified on an image. The key in dealing with the problem is to capture subtle visual differences from the image and effectively represent the discriminative features. Existing methods are often limited by insufficient localization accuracy and insufficient feature representation capabilities. In this paper, we propose a cross-layer progressive attention bilinear fusion (CPABF in short) method, which can efficiently express the characteristics of discriminative regions. The CPABF method involves three components: 1) Cross-Layer Attention (CLA) locates and reinforces the discriminative region with low computational costs; 2) The Cross-Layer Bilinear Fusion Module (CBFM) effectively integrates the semantic information from the low-level to the high-level 3) Progressive Training optimizes the parameters in the network to the best state in a delicate way. The CPABF shows excellent performance on the four FGVC datasets and outperforms some state-of-the-art methods.
C1 [Wang, Chaoqing; Qian, Yurong] Xinjiang Univ, Coll Software Engn, Urumqi 830000, Peoples R China.
   [Gong, Weijun; Cheng, Junjong; Wang, Yongqiang] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi, Peoples R China.
   [Wang, Yuefei] Chengdu Univ, Coll Comp Sci, Chengdu 610106, Peoples R China.
C3 Xinjiang University; Xinjiang University; Chengdu University
RP Wang, CQ; Qian, YR (corresponding author), Xinjiang Univ, Coll Software Engn, Urumqi 830000, Peoples R China.
EM chandelierwang@gmail.com
RI Wang, Yuefei/I-1985-2018
FU National Science Foundation of China [U1803261]; National Natural
   Science Foundation of China [61562086]
FX Acknowledgement This work is partially supported by the National Science
   Foundation of China under Grant (U1803261) , and the National Natural
   Science Foundation of China (61562086) .
CR Ahn N, 2018, P IEEE C COMPUTER VI, P791
   [Anonymous], 2013, Tech. rep.
   Branson S., 2014, BIRD SPECIES CATEGOR, V1, P7
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Clevert D., 2016, ARXIV151107289
   Huynh D, 2020, PROC CVPR IEEE, P4482, DOI 10.1109/CVPR42600.2020.00454
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Gao Y, 2020, AAAI CONF ARTIF INTE, V34, P10818
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hutter Frank, 2016, ICLR POSTER
   Karras T, 2018, P INT C LEARN REPR I
   Khosla A., 2011, P IEEE C COMP VIS PA, V2
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li XL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2208
   Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555
   Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Ruoyi Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P153, DOI 10.1007/978-3-030-58565-5_10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ruyi Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10465, DOI 10.1109/CVPR42600.2020.01048
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song KT, 2020, IEEE T IMAGE PROCESS, V29, P7006, DOI 10.1109/TIP.2020.2996736
   Sun XX, 2019, AAAI CONF ARTIF INTE, P273
   Wah Catherine, 2011, Technical report
   Wang WY, 2020, NEURAL COMPUT APPL, V32, P14613, DOI 10.1007/s00521-020-05148-3
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Wang ZH, 2020, AAAI CONF ARTIF INTE, V34, P12289
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xin DJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051681
   Yang GF, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.600854
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Zhang CY, 2020, AAAI CONF ARTIF INTE, V34, P12781
   Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhao B, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2916757
   Zheng H., 2019, P NEURIPS, P4277
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2020, IEEE T IMAGE PROCESS, V29, P476, DOI 10.1109/TIP.2019.2921876
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 50
TC 3
Z9 3
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103414
DI 10.1016/j.jvcir.2021.103414
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400004
DA 2024-07-18
ER

PT J
AU Wu, HS
   Chen, JW
   Liu, X
   Hu, JL
AF Wu, Huishan
   Chen, Jiawei
   Liu, Xiao
   Hu, Junlin
TI Component-based metric learning for fully automatic kinship verification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kinship verification; Metric learning; Component; Feature combination;
   Facial image
ID FACE
AB This paper introduces a fully automatic method for kinship verification from facial images. Recently, a number of methods have been proposed to verify kinship from facial images, however, most of these methods are needed to exactly align face images before feature extraction in a manual manner. Unlike these methods, our method does not depend on face alignment. Firstly, we localize several facial feature points by utilizing a facial feature detector to extract SIFT descriptor around each feature point of a face image. Lastly, two ways, feature combination and distance metric learning, are used to verify the kinship of a pair of face images. For feature combination, three simple strategies of feature combination and support vector machine classifier are used for kinship verification. For metric learning, we propose a component-based metric learning (CML) method to measure the distance of each face pair, which jointly learns multiple local distance metrics, and one specific distance metric for each facial feature point. Experimental results show the effectiveness of our proposed approach on two popular kinship datasets.
C1 [Wu, Huishan] Beijing Language & Culture Univ, Sch Informat Sci, Beijing 100083, Peoples R China.
   [Chen, Jiawei; Liu, Xiao] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
   [Hu, Junlin] Beihang Univ, Sch Software, Beijing 100191, Peoples R China.
C3 Beijing Language & Culture University; Beijing University of Chemical
   Technology; Beihang University
RP Hu, JL (corresponding author), Beihang Univ, Sch Software, Beijing 100191, Peoples R China.
EM hujunlin@buaa.edu.cn
OI Hu, Junlin/0000-0002-0117-3494
FU Beijing Natural Science Foundation [4204108]; National Natural Science
   Foundation of China [62006013]
FX This work was supported in part by the Beijing Natural Science
   Foundation under Grant 4204108, and in part by the National Natural
   Science Foundation of China under Grant 62006013.
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dahan E, 2021, IEEE T PATTERN ANAL, V43, P2851, DOI 10.1109/TPAMI.2020.3036993
   Everingham M., 2006, P BRIT MACH VIS C, P899, DOI [DOI 10.5244/C.20.92, 10.5244/C.20.92]
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Goyal A, 2021, IEEE T IMAGE PROCESS, V30, P191, DOI 10.1109/TIP.2020.3034027
   Hu JL, 2019, IEEE IMAGE PROC, P1178, DOI [10.1109/ICIP.2019.8803754, 10.1109/icip.2019.8803754]
   Hu JL, 2018, IEEE T CIRC SYST VID, V28, P1875, DOI 10.1109/TCSVT.2017.2691801
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kohli N, 2019, IEEE T IMAGE PROCESS, V28, P1329, DOI 10.1109/TIP.2018.2840880
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Laiadi O, 2020, NEUROCOMPUTING, V377, P286, DOI 10.1016/j.neucom.2019.10.055
   Li WH, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102823
   Liang JQ, 2019, IEEE T IMAGE PROCESS, V28, P1149, DOI 10.1109/TIP.2018.2875346
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Song CH, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102891
   Tu ZG, 2019, IEEE T CIRC SYST VID, V29, P1423, DOI 10.1109/TCSVT.2018.2830102
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Wang MY, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patog.2020.10732
   Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI [10.1109/INTMAG.2018.8508542, 10.1109/TNNLS.2017.2771290, 10.1109/TPAMI.2018.2861871]
   Wei Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P613, DOI 10.1007/978-3-030-58542-6_37
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Yan HB, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107541
   Zhang HM, 2019, IEEE IMAGE PROC, P3856, DOI [10.1109/ICIP.2019.8803647, 10.1109/icip.2019.8803647]
   Zhou X., 2011, ACM Multimedia, P953
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 28
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103265
DI 10.1016/j.jvcir.2021.103265
EA AUG 2021
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800009
DA 2024-07-18
ER

PT J
AU Yang, Z
   Wang, ZP
   Luo, LK
   Gan, HP
   Zhang, T
AF Yang, Zhen
   Wang, Zhipeng
   Luo, Lingkun
   Gan, Hongping
   Zhang, Tao
TI SWS-DAN: Subtler WS-DAN for fine-grained image classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained; Classification; WS-DAN; SWS-DAN; Data augmentation; Loss
   function
AB Currently, weakly supervised data augmentation network (WS-DAN) has been proved to be one of the state-ofthe-art methods for fine-grained image classification due to its effectiveness on attention-guided data augmentation and bilinear attention pooling. Taking WS-DAN as the backbone, in this paper, we further propose a subtler WS-DAN recognition network, namely, SWS-DAN. Specifically, we first construct a novel "salience-guided data augmentation" scheme composed of cutblock, part-aware cropping, and SCutMix operations, which can more effectively expand the number of training dataset and improve the weakness addressed in the data augmentation procedure of WS-DAN. Meanwhile, the novel data-augmentation manner reduces background noise and mines more discriminative regions simultaneously, thereby avoiding the overfitting. In caring about the key issue in fine-grained image classification task is how to distinguish the extremely similar subclasses (e.g., Artic Tern, Elegant Tern, and Forsters Tern), we then design a "Top-k" loss function that mainly focuses on the similar classes so as to find their extraordinary subtle differences. Extensive experiments carried out on common fine-grained image datasets demonstrate that SWS-DAN can surpass WS-DAN with a significant margin in the classification performance.
C1 [Yang, Zhen; Wang, Zhipeng] Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, Nanchang, Jiangxi, Peoples R China.
   [Luo, Lingkun] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
   [Gan, Hongping] Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
   [Zhang, Tao] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
C3 Jiangxi Science & Technology Normal University; Shanghai Jiao Tong
   University; Northwestern Polytechnical University; Tsinghua University
RP Zhang, T (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
EM zhangtao8902@mail.tsinghua.edu.cn
RI Zhang, Tao/C-7740-2015
FU National Natural Science Foundation of China [61866016, 62006152]; China
   Postdoctoral Science Foundation [2020M680562]; Fundamental Research
   Funds for the Central Universities [G2020KY05110]; Science and
   Technology Project of Taicang [TC2020JC07]
FX This work is supported in partially by the National Natural Science
   Foundation of China under Grant 61866016 and 62006152, and by the China
   Postdoctoral Science Foundation under Grant 2020M680562, and by
   Fundamental Research Funds for the Central Universities under Grant
   G2020KY05110, and by Science and Technology Project of Taicang under
   Grant TC2020JC07.
CR [Anonymous], 2013, Tech. rep.
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   DeVries T, 2017, PREPRINT
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Harris Ethan, 2020, ARXIV200212047
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Tao, 2019, See better before looking closer: Weakly supervised data augmentation network for fine-grained visual classification
   Huang C, 2014, J VIS COMMUN IMAGE R, V25, P1299, DOI 10.1016/j.jvcir.2014.05.002
   Huang S.H., 2020, 2001040771 ARXIV
   Ji R., 2020, P IEEE CVF C COMP VI, P10468
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Qu Yingqi, 2020, ARXIV201008191
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruoyi Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P153, DOI 10.1007/978-3-030-58565-5_10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang YF, 2019, J VIS COMMUN IMAGE R, V59, P210, DOI 10.1016/j.jvcir.2018.12.049
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang Ze, 2018, P EUROPEAN C COMPUTE
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang Hongyi, 2017, ARXIV171009412
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou MH, 2020, PROC CVPR IEEE, P11771, DOI 10.1109/CVPR42600.2020.01179
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 35
TC 6
Z9 6
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103245
DI 10.1016/j.jvcir.2021.103245
EA AUG 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800001
DA 2024-07-18
ER

PT J
AU Sadeddine, K
   Chelali, ZF
   Djeradi, R
   Djeradi, A
   Benabderrahmane, S
AF Sadeddine, Khadidja
   Chelali, Zohra Fatma
   Djeradi, Rachida
   Djeradi, Amar
   Benabderrahmane, Sidahmed
TI Recognition of user-dependent and independent static hand gestures:
   Application to sign language*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Static hand gesture recognition; Sign language recognition; GLAC; Gabor
   wavelet; Curvelet transform; Combined classifiers
ID FACE RECOGNITION; FEATURE-EXTRACTION; GABOR FILTER; CLASSIFICATION;
   TRANSFORM; POSTURES; FEATURES; SYSTEM
AB Static hand gesture (HG) recognition for both user-dependent and user-independent is a challenging problem, especially when there are changes in lighting, hand position, and background, the recognition becomes more complex. To solve this problem, this paper proposes a static hand gesture recognition based on a set of image descriptors: Gradient Local Auto-Correlation (GLAC), Gabor Wavelet Transform (GWT), and Fast Discrete Curve Transform (FDCT). Principal Component Analysis (PCA) was used to reduce dimensionality. Tests were performed on three sign language datasets and one hand posture dataset using neural network classifiers, K-Nearest Neighbor (KNN) classifiers, and combined classifiers. The results obtained were compared to the state of the art and show an accuracy of 100% for user-independent and 98.33% for user-dependent gestures, despite the difficult acquisition conditions of the datasets.
C1 [Sadeddine, Khadidja; Chelali, Zohra Fatma; Djeradi, Rachida; Djeradi, Amar] Univ Sci & Technol Houari Boumed, Elect & Comp Sci Fac, Bab Ezzouar, Algeria.
   [Benabderrahmane, Sidahmed] Paris 8 Univ, CS Dept, LIASD, 2 Rue Liberte, F-93526 St Denis, France.
C3 University Science & Technology Houari Boumediene
RP Sadeddine, K (corresponding author), Univ Sci & Technol Houari Boumed, Elect & Comp Sci Fac, Bab Ezzouar, Algeria.
EM sadeddine_khadidja@yahoo.com
CR Abdo MZ, 2015, INT J ADV COMPUT SC, V6, P209
   Ahmed AA, 2014, I C ENG TECHNOL
   Akintola K.G., 2020, AM J INTELL SYST, V10, P1, DOI [10.5923/j.ajis.20201001.01, DOI 10.5923/J.AJIS.20201001.01]
   Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   Al-Jarrah O, 2007, APPL ARTIF INTELL, V21, P11, DOI 10.1080/08839510600938524
   AL-Rousan M, 2009, APPL SOFT COMPUT, V9, P990, DOI 10.1016/j.asoc.2009.01.002
   Alzohairi R, 2018, INT J ADV COMPUT SC, V9, P185
   [Anonymous], 2011, Res Lett Inf Math Sci
   Aowal M.A., 2014, IEEE REG 10 ANN INT, DOI [10.1109/TENCON.2014.7022345, DOI 10.1109/TENCON.2014.7022345]
   Ashfaq T, 2016, INT J ADV COMPUT SC, V7, P276
   Bamwenda J., 2019, Dicle Univ. J. Eng, V10, P561
   Baxter C. W., 2002, Journal of Environmental Engineering and Science, V1, P201, DOI 10.1139/s02-014
   Birk H, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P261
   Cand `es E.J., 1999, CURVELET SURPRISINGL
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Candes EmmanuelJ., 2003, NOTICES AMS, V50, P1402
   Dahmani D, 2019, MULTIMED TOOLS APPL, V78, P27957, DOI 10.1007/s11042-019-07859-9
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Dobbin KK, 2011, BMC MED GENOMICS, V4, DOI 10.1186/1755-8794-4-31
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4056, P12, DOI 10.1117/12.381679
   El-Bendary Nashwa, 2010, 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM 2010), P590, DOI 10.1109/CISIM.2010.5643519
   Elatawy SM, 2020, EDUC INF TECHNOL, V25, P5601, DOI 10.1007/s10639-020-10184-6
   Farhad SM, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING RESEARCH AND INNOVATION (ICCCRI), P1, DOI 10.1109/ICCCRI.2017.8
   Gasmi I., 2005, SETIT, P1
   Gautam A.K.A.K, 2017, INT J COMPUT SCI ENG, V9
   Guesmi F, 2016, IEEE SYS MAN CYBERN, P3561, DOI 10.1109/SMC.2016.7844785
   Hayat Shoaib, 2019, 2019 IEEE 2nd International Conference on Electronics Technology (ICET), P1, DOI 10.1109/ELTECH.2019.8839402
   Huang Z., 2010, INT C COMP DES APPL, V1, P1, DOI [10.1109/ICCDA.2010.5541177, DOI 10.1109/ICCDA.2010.5541177]
   Islam MZ, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P324, DOI [10.1109/iciev.2019.8858563, 10.1109/ICIEV.2019.8858563]
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Kapuscinski T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062132
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V5302, P346, DOI 10.1007/978-3-540-88682-2_27
   Kumar PP, 2010, INT J HUM ROBOT, V7, P331, DOI 10.1142/S0219843610002180
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Mandal T, 2007, LECT NOTES COMPUT SC, V4633, P806
   Mantecón T, 2016, LECT NOTES COMPUT SC, V10016, P47, DOI 10.1007/978-3-319-48680-2_5
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Masood S., 2018, SMART COMPUTING INFO, P403
   Nagarajan S., 2013, Int. J. Comput. Appl, V82, DOI [10.5120/14106-2145, DOI 10.5120/14106-2145]
   Rajeshri R.I., 2019, INT J SCI TECHNOL RE, V8, P3382
   Ranga V, 2018, J ENG SCI TECHNOL, V13, P2655
   Rybach D., 2006, THESIS RWTH AACHEN U, P1
   Sadeddine K., 2018, 6 INT C MULT COMP SY
   Sadeddine K, 2015, 3RD INTERNATIONAL CONFERENCE ON CONTROL, ENGINEERING & INFORMATION TECHNOLOGY (CEIT 2015)
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Sharma A., 2020, Proc. Comput. Sci, V173, P181, DOI [10.1016/j.procs.2020.06.022, DOI 10.1016/J.PROCS.2020.06.022]
   Shen LL, 2006, PATTERN RECOGN LETT, V27, P1758, DOI 10.1016/j.patrec.2006.02.005
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Tao W, 2018, P 2018 I IND SYST EN
   Toolbox C., 2004, TRANSFORM, P1
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Vinay A, 2015, PROCEDIA COMPUT SCI, V57, P650, DOI 10.1016/j.procs.2015.07.434
   Wang J., 2010, INT S INT SIGN PROC
   Wang WW, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P117, DOI 10.1109/IWFHR.2002.1030896
   Wu W, 2012, P INT C ENV MOD SOFT, P394
   Zhang Q, 2020, MATH BIOSCI ENG, V17, P1578, DOI 10.3934/mbe.2020082
NR 58
TC 14
Z9 15
U1 3
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103193
DI 10.1016/j.jvcir.2021.103193
EA JUL 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100012
DA 2024-07-18
ER

PT J
AU Tian, FZ
   Gao, YB
   Fang, ZJ
   Gu, J
   Yang, SQ
AF Tian, Fangzheng
   Gao, Yongbin
   Fang, Zhijun
   Gu, Jia
   Yang, Shuqun
TI 3D reconstruction with auto-selected keyframes based on depth completion
   correction and pose fusion*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D reconstruction; Depth completion and correction; Pose fusion
   estimation; Auto-selected keyframes
ID SIMULTANEOUS LOCALIZATION; VIEW
AB Dense 3D reconstruction is required for robots to safely navigate or perform advanced tasks. The accurate depth information of the image and its pose are the basis of 3D reconstruction. The resolution of depth maps obtained by LIDAR and RGB-D cameras is limited, and traditional pose calculation methods are not accurate enough. In addition, if each image is used for dense 3D reconstruction, the dense point clouds will increase the amount of calculation. To address these issues, we propose a 3D reconstruction system. Specifically, we propose a depth network of contour and gradient attention, which is used to complete and correct depth maps to obtain high-resolution and high-quality depth maps. Then, we propose a method of fusion of traditional algorithms and deep learning for pose estimation to obtain accurate localization results. Finally, we adopt the method of autonomous selection of keyframes to reduce the number of keyframes, the surfel-based geometric reconstruction is performed to reconstruct the dense 3D environment. On the TUM RGB-D, ICL-NIUM, and KITTI datasets, our method significantly improves the quality of the depth maps, the localization results, and the effect of 3D reconstruction. At the same time, we have also accelerated the speed of 3D reconstruction.
C1 [Tian, Fangzheng; Gao, Yongbin; Fang, Zhijun; Gu, Jia; Yang, Shuqun] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
C3 Shanghai University of Engineering Science
RP Gao, YB; Fang, ZJ (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
EM gaoyongbin@sues.edu.cn; zjfang@sues.edu.cn
RI Gu, Jia/KQU-3587-2024
OI Gu, Jia/0000-0002-0642-3966; Tian, Fangzheng/0000-0002-3053-8317
FU National Natural Science Foundation of China [61802253, 61772328,
   61831018, U2033218]; National Key Research and Development Project of
   Ministry of Science and Technology of China [2020AAA0109302,
   2020AAA0109300]; Chenguang Talented Program of Shanghai [17CG59]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61802253, 61772328, 61831018, U2033218,
   in part by the National Key Research and Development Project of Ministry
   of Science and Technology of China under Grant 2020AAA0109302,
   2020AAA0109300, in part by the Chenguang Talented Program of Shanghai
   under Grant 17CG59.
CR [Anonymous], 2018, EUR C COMP VIS
   Billy A, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P840, DOI 10.5220/0007386508400848
   Bloesch M, 2019, IEEE I CONF COMP VIS, P5854, DOI 10.1109/ICCV.2019.00595
   Bloesch M, 2018, PROC CVPR IEEE, P2560, DOI 10.1109/CVPR.2018.00271
   Bozorgtabar B, 2019, IEEE I CONF COMP VIS, P4209, DOI 10.1109/ICCV.2019.00431
   Bresson G, 2017, IEEE T INTELL VEHICL, V2, P194, DOI 10.1109/TIV.2017.2749181
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen GH, 2006, IEEE IMAGE PROC, P2929, DOI 10.1109/ICIP.2006.313132
   Chen YH, 2019, IEEE I CONF COMP VIS, P7062, DOI 10.1109/ICCV.2019.00716
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Eigen D, 2014, ADV NEUR IN, V27
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fácil JM, 2017, IEEE ROBOT AUTOM LET, V2, P1994, DOI 10.1109/LRA.2017.2715400
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Holzmann T, 2018, LECT NOTES COMPUT SC, V11218, P487, DOI 10.1007/978-3-030-01264-9_29
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Klein George, 2007, P1
   Kundu JN, 2018, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2018.00281
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Laidlow T, 2019, IEEE INT CONF ROBOT, P4068, DOI [10.1109/icra.2019.8793527, 10.1109/ICRA.2019.8793527]
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li J., 2021, IEEE Trans. Intell. Transp. Syst, V22, P4030, DOI DOI 10.1109/TITS.2020.3006482
   Li SW, 2016, LECT NOTES COMPUT SC, V9905, P349, DOI 10.1007/978-3-319-46448-0_21
   Li W, 2019, IEEE WINT CONF APPL, P1413, DOI 10.1109/WACV.2019.00155
   Liu H, 2021, IEEE T INSTRUM MEAS, V70, DOI [10.1109/TIM.2021.3063749, 10.1109/TIM.2021.3111076]
   Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024
   Maier R., 2017, P BRIT MACH VIS C
   Marton ZC, 2009, IEEE INT CONF ROBOT, P2829
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Morreale L, 2019, IEEE INT CONF ROBOT, P6891, DOI [10.1109/ICRA.2019.8793256, 10.1109/icra.2019.8793256]
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Pizzoli M, 2014, IEEE INT CONF ROBOT, P2609, DOI 10.1109/ICRA.2014.6907233
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Schops T., 2019, IEEE T PATTERN ANAL
   Schöps T, 2017, IEEE T VIS COMPUT GR, V23, P2455, DOI 10.1109/TVCG.2017.2734578
   Schreiberhuber S, 2019, IEEE INT CONF ROBOT, P140, DOI [10.1109/ICRA.2019.8793654, 10.1109/icra.2019.8793654]
   Shivakumar SS, 2019, IEEE INT CONF ROBOT, P6482, DOI [10.1109/icra.2019.8794023, 10.1109/ICRA.2019.8794023]
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Stachniss C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1153
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tang C., 2018, INT C LEARN REPR
   Tang JX, 2019, IEEE ROBOT AUTOM LET, V4, P530, DOI 10.1109/LRA.2019.2891433
   Tang SJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101589
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   van Dijk T, 2019, IEEE I CONF COMP VIS, P2183, DOI 10.1109/ICCV.2019.00227
   Wang KX, 2019, IEEE INT CONF ROBOT, P6919, DOI [10.1109/ICRA.2019.8794101, 10.1109/icra.2019.8794101]
   Wang KS, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296975.3186412, 10.1145/3186411.3186412]
   Wang W, 2019, IEEE INT C INT ROBOT, P7895, DOI [10.1109/IROS40897.2019.8967663, 10.1109/iros40897.2019.8967663]
   Wasenmüller O, 2017, LECT NOTES COMPUT SC, V10117, P34, DOI 10.1007/978-3-319-54427-4_3
   Whelan T., 2012, Proceedings of the RSS Workshop on RGB-D: Advanced Reasoning with Depth Cameras
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yang N, 2018, LECT NOTES COMPUT SC, V11212, P835, DOI 10.1007/978-3-030-01237-3_50
   Yang SC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1222, DOI 10.1109/IROS.2016.7759204
   Yang Y, 2019, IEEE INT CONF ROBOT, P5238, DOI [10.1109/ICRA.2019.8794355, 10.1109/icra.2019.8794355]
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 66
TC 4
Z9 4
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103199
DI 10.1016/j.jvcir.2021.103199
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100007
DA 2024-07-18
ER

PT J
AU Wang, XY
   Tian, J
   Tian, JL
   Niu, PP
   Yang, HY
AF Wang, Xiang-yang
   Tian, Jing
   Tian, Jia-lin
   Niu, Pan-pan
   Yang, Hong-ying
TI Statistical image watermarking using local RHFMs magnitudes and beta
   exponential distribution*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital watermarking; Local RHFMs magnitudes; Beta-exponential
   distribution; Modified maximum likelihood estimation; ML decision
   criterion
ID DETECTOR; DECODER; SCHEME
AB The imperceptibility, robustness and data payload are widely considered as the three main properties vital for any image watermarking systems. They are complimentary to each other and hence challenging to attain the right balance between them. The statistical model-based multiplicative watermarking is an effective way to achieve the tradeoff among imperceptibility, robustness and data payload. Radial harmonic Fourier moments (RHFMs) is a strong tool in image processing, which has many advantages, such as lower noise sensitivity, powerful image description ability and geometric invariance feature. In this paper, we propose a new statistical image watermarking scheme using local RHFMs magnitudes and Beta exponential distribution model. Our image watermarking scheme consists of two parts, namely, embedding and extraction. In the embedding process, we divide the host image into no-overlapping blocks and compute the local RHFMs of image blocks, then insert the watermark signal into the robust local RHFMs magnitudes through multiplicative approach. In the extraction phase, robust local RHFMs magnitudes are firstly modeled by employing the Beta exponential distribution, where the statistical properties of local RHFMs magnitudes are captured accurately. Then the modified maximum likelihood parameter estimation (MMLE) approach is introduced to estimate the statistical parameters of Beta exponential distribution model. And finally an image watermark decoder for multiplicative watermarking is developed using Beta exponential distribution and maximum likelihood decision criterion. Experimental results on some test images and comparison with well-known existing methods demonstrate the efficacy and superiority of the proposed statistical image watermarking.
C1 [Wang, Xiang-yang; Tian, Jing; Tian, Jia-lin; Niu, Pan-pan; Yang, Hong-ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023; TIAN, Jialin/E-4988-2015; Niu,
   Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; TIAN, Jialin/0000-0002-9991-9839; 
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Key Scientific Research
   Project of Liaoning Provincial Education Department (LZ2019001), and
   Natural Science Foundation of Liaoning Province (2019-ZD-0468).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Alghoniemy M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P73, DOI 10.1109/ICIP.2000.899229
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Ghouti L, 2019, ARAB J SCI ENG, V44, P3699, DOI 10.1007/s13369-018-3630-3
   Kumar S, 2016, COGENT MATH, V3, DOI 10.1080/23311835.2016.1168070
   Liu HM, 2018, INFORMATION, V9, DOI 10.3390/info9090239
   Liu JH, 2019, KSII T INTERNET INF, V13, P452, DOI 10.3837/tiis.2019.01.025
   Liu JH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120945
   Nadarajah S, 2006, RELIAB ENG SYST SAFE, V91, P689, DOI 10.1016/j.ress.2005.05.008
   Oral E., 2017, Biom Biostat Int J, V6, P00154
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Vaughan DC, 2000, MATH COMPUT MODEL, V32, P53, DOI 10.1016/S0895-7177(00)00119-9
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2020, PATTERN ANAL APPL, V23, P933, DOI 10.1007/s10044-019-00828-w
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P34867, DOI 10.1007/s11042-019-08058-2
   Wang XY, 2019, INFORM SCIENCES, V503, P274, DOI 10.1016/j.ins.2019.06.059
   Wang XY, 2019, J VIS COMMUN IMAGE R, V62, P309, DOI 10.1016/j.jvcir.2019.05.012
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Yang HY, 2015, AEU-INT J ELECTRON C, V69, P389, DOI 10.1016/j.aeue.2014.10.012
NR 30
TC 17
Z9 17
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103123
DI 10.1016/j.jvcir.2021.103123
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200002
DA 2024-07-18
ER

PT J
AU Elharrouss, O
   Almaadeed, N
   Al-Maadeed, S
AF Elharrouss, Omar
   Almaadeed, Noor
   Al-Maadeed, Somaya
TI A review of video surveillance systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Video surveillance system; Video analysis; Video surveillance systems
   trends
ID GLOBAL CALIBRATION METHOD; CAMERA CALIBRATION; OBJECT DETECTION;
   MULTI-CAMERA; ACTION RECOGNITION; TRACKING; MANAGEMENT; SAFETY; RISK;
   CLASSIFICATION
AB Automated surveillance systems observe the environment utilizing cameras. The observed scenario is then analysed using motion detection, crowd behaviour, individual behaviour, interaction between individuals, crowds and their surrounding environment. These automatic systems accomplish multitude of tasks which include, detection, interpretation, understanding, recording and creating alarms based on the analysis. Till recent, studies have achieved enhanced monitoring performance along with avoiding possible human failures by manipulation of different features of these systems. This paper presents a comprehensive review of such video surveillance systems as well as the components used with them. The description of the architectures used is presented which follows the most required analyses in these systems. For the bigger picture and wholesome view of the system, existing surveillance systems were compared in terms of characteristics, advantages, and difficulties which are tabulated in this paper. Adding to this, future trends are discussed which charts a path into the upcoming research directions.
C1 [Elharrouss, Omar; Almaadeed, Noor; Al-Maadeed, Somaya] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
C3 Qatar University
RP Almaadeed, N (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
EM n.alali@qu.edu.qa; s_alali@qu.edu.qa
OI Elharrouss, Omar/0000-0002-5341-5440
FU Qatar National Research Fund (Qatar Foundation) [NPRP8-140-2065]
FX This publication was made by NPRP grant #NPRP8-140-2065 from the Qatar
   National Research Fund (a member of the Qatar Foundation) . The
   statements made herein are solely the responsibility of the authors.
CR Abdallah ZS, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3158645
   Aghajan H, 2009, MULTI-CAMERA NETWORKS: PRINCIPLES AND APPLICATIONS, P1
   Agrawal A, 2013, IEEE I CONF COMP VIS, P2368, DOI 10.1109/ICCV.2013.294
   Akbari Y, 2021, ARTIF INTELL REV, V54, P3887, DOI 10.1007/s10462-020-09943-1
   Alcantarilla P.F., 2013, COMPUTATIONAL PERCEP, P1
   Almaadeed N., ARXIV PREPRINT ARXIV
   Andriulo S, 2014, RELIAB ENG SYST SAFE, V132, P154, DOI 10.1016/j.ress.2014.07.022
   Ang L. M., 2013, WIRELESS MULTIMEDIA
   Anjum N, 2007, INT CONF ACOUST SPEE, P281
   [Anonymous], 2017, P WORKSH SMART INT T
   [Anonymous], 2014, System safety engineering and risk assessment: a practical approach
   Ataer-Cansizoglu Esra, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P509, DOI 10.1109/3DV.2014.106
   Baidya S., IEEE T COGN COMMUN
   Banerjee S, 2018, NEUROCOMPUTING, V310, P299, DOI 10.1016/j.neucom.2018.05.038
   Belo LD, 2016, NEUROCOMPUTING, V173, P1001, DOI 10.1016/j.neucom.2015.08.057
   Birdal T., 2016, 2016 IEEE WINT C APP, P1
   Bouachir W., AUTOMATED VIDEO SURV
   Bouachir W, 2018, PATTERN RECOGN LETT, V110, P1, DOI 10.1016/j.patrec.2018.03.018
   Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Cao QG, 2012, SAFETY SCI, V50, P909, DOI 10.1016/j.ssci.2011.08.005
   Carrera G, 2011, IEEE INT CONF ROBOT, P2652, DOI 10.1109/ICRA.2011.5980294
   CAVEN T, 1982, J OCCUP ACCID, V4, P341, DOI 10.1016/0376-6349(82)90043-8
   Celes C, 2019, IEEE COMMUN MAG, V57, P20, DOI 10.1109/MCOM.2019.1800640
   Cermeño E, 2018, EXPERT SYST APPL, V91, P138, DOI 10.1016/j.eswa.2017.08.052
   Chen BH, 2018, NEUROCOMPUTING, V273, P481, DOI 10.1016/j.neucom.2017.08.002
   Chen G, 2012, OPTIK, V123, P731, DOI 10.1016/j.ijleo.2011.05.030
   Chen N., 2017, ADV MOBILE CLOUD COM, P203
   Chen N, 2016, 2016 FIRST IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC 2016), P95, DOI 10.1109/SEC.2016.25
   Chen N, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P105, DOI 10.1109/BigMM.2016.53
   Chen S., 2017, IEEE INTERNET COMPUT, V21, P4, DOI [10.1109/MIC.2017.39, DOI 10.1109/MIC.2017.39]
   Chen XY, 2019, IEEE WINT CONF APPL, P1941, DOI 10.1109/WACV.2019.00211
   Cheng FC, 2011, IEEE T BROADCAST, V57, P794, DOI 10.1109/TBC.2011.2160106
   Cheng JH, 2015, IEEE ANN INT CONF CY, P163, DOI 10.1109/CYBER.2015.7287928
   Cheng X, 2015, APPL SOFT COMPUT, V31, P81, DOI 10.1016/j.asoc.2015.03.002
   Cocca P, 2008, ACTA BIOENG BIOMECH, V10, P21
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Cook DJ, 2009, PERVASIVE MOB COMPUT, V5, P277, DOI 10.1016/j.pmcj.2009.04.001
   Corke P, 2010, P IEEE, V98, P1903, DOI 10.1109/JPROC.2010.2068530
   Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038
   David GC, 2005, OCCUP MED-OXFORD, V55, P190, DOI 10.1093/occmed/kqi082
   Dedeoglu Y, 2006, LECT NOTES COMPUT SC, V3979, P64
   Dong S, 2016, APPL OPTICS, V55, P6363, DOI 10.1364/AO.55.006363
   Du Ruofei., 2016, Proceedings of the 21st International Conference on Web3D Technology, P165, DOI 10.1145/2945292.2945299
   El Harrouss O., 2016, 2016 18 C OP INN, P1
   Elafi I, 2016, PATTERN RECOGN LETT, V84, P70, DOI 10.1016/j.patrec.2016.08.008
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Elharrouss O, 2019, INT WIREL COMMUN, P366
   Elharrouss O, 2018, IET COMPUT VIS, V12, P86, DOI 10.1049/iet-cvi.2017.0136
   Elharrouss O, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061615
   Esquivel S, 2007, LECT NOTES COMPUT SC, V4713, P82
   Foresti GL, 2012, MULTIMEDIA VIDEO BAS, V573
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Frahm J. -M., 2008, COMPUTER VISION PATT, P1
   Fuller CW, 2005, SAFETY SCI, V43, P213, DOI 10.1016/j.ssci.2005.05.002
   Galan-Hernandez JC, 2018, ENG APPL ARTIF INTEL, V69, P127, DOI 10.1016/j.engappai.2017.12.008
   Gao B, 2016, ELECTRON LETT, V52, DOI 10.1049/el.2016.2639
   Gayathri H, 2017, INT J DISAST RISK RE, V25, P82, DOI 10.1016/j.ijdrr.2017.07.017
   Gumaidah B., 2013, INT J MODERN ENG SCI, V2, P1
   Gurwicz Y, 2011, PATTERN RECOGN LETT, V32, P805, DOI 10.1016/j.patrec.2011.01.005
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Heng L, 2013, IEEE INT C INT ROBOT, P1793, DOI 10.1109/IROS.2013.6696592
   Hsu GS, 2018, IEEE T CIRC SYST VID, V28, P3194, DOI 10.1109/TCSVT.2017.2748379
   Hu Hao, 2012, Optics and Precision Engineering, V20, P369, DOI 10.3788/OPE.20122002.0369
   Hu M., OPTIK INT J LIGHT EL
   Huang GY, 2008, LECT NOTES COMPUT SC, V4976, P154
   Huang HF, 2015, INT CONF INFO SCI, P328, DOI 10.1109/ICIST.2015.7288991
   Hui BW, 2013, OPT LASER ENG, V51, P432, DOI 10.1016/j.optlaseng.2012.11.008
   Imani M, 2017, INT J REMOTE SENS, V38, P5524, DOI 10.1080/01431161.2017.1343513
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Jin CJ, 2017, PROCEDIA COMPUT SCI, V107, P498, DOI 10.1016/j.procs.2017.03.097
   JIN Cheng-Bin, 2017, ARXIV PREPRINT ARXIV
   Kachach R, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.3.033021
   Kai Jungling, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P197, DOI 10.1109/AVSS.2011.6027319
   Kalaivani P., 2017, REC TRENDS CHALL COM
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khan A, 2018, IEEE T CYBERNETICS, V48, P187, DOI 10.1109/TCYB.2016.2628161
   Kitahara I., LARGESCALE VIRTUALIZ
   Kneis B, 2018, COMM COM INF SC, V893, P71, DOI 10.1007/978-3-319-98204-5_6
   Kongsvik T, 2012, SAFETY SCI, V50, P1839, DOI 10.1016/j.ssci.2012.02.003
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Kurilkin AV, 2015, PROCEDIA COMPUT SCI, V66, P364, DOI 10.1016/j.procs.2015.11.042
   Kyriakidis M, 2012, SAFETY SCI, V50, P1535, DOI 10.1016/j.ssci.2012.03.004
   Lamprecht Bernhard, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P265, DOI 10.1109/ITSC.2007.4357679
   Laureshyn A, 2010, Application of automated video analysis to road user behaviour
   Lebraly P. L, CALIBRATION NONOVERL
   Li H, 2015, SAFETY SCI, V75, P107, DOI 10.1016/j.ssci.2015.01.013
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li YS, 2017, IEEE ACCESS, V5, P10323, DOI 10.1109/ACCESS.2017.2712789
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu QZ, 2012, CHIN J MECH ENG-EN, V25, P405, DOI 10.3901/CJME.2012.02.405
   LIU Xinchen, 2016, IEEE INT CON MULTI, P1
   Liu Z, 2013, OPT LASER ENG, V51, P643, DOI 10.1016/j.optlaseng.2012.11.009
   Liu Z, 2015, NEUROCOMPUTING, V168, P1144, DOI 10.1016/j.neucom.2015.05.008
   Lu GQ, 2012, SAFETY SCI, V50, P1898, DOI 10.1016/j.ssci.2012.05.007
   Lu RS, 2004, SENSOR ACTUAT A-PHYS, V116, P384, DOI 10.1016/j.sna.2004.05.019
   Lubobya SC, 2015, PROCEDIA COMPUT SCI, V45, P571, DOI 10.1016/j.procs.2015.03.110
   Lv T, 2018, APPL ACOUST, V129, P316, DOI 10.1016/j.apacoust.2017.08.016
   Martinel N, 2018, PATTERN RECOGN LETT, V112, P234, DOI 10.1016/j.patrec.2018.07.033
   McSween T.E., 2003, The values-based safety process: Improving your safety culture with behavior-based safety, V2nd, DOI DOI 10.1002/0471721611
   Ming-Jiang Yang, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P2432, DOI 10.1109/ICIEA.2009.5138638
   Minoli D, 2017, IEEE INTERNET THINGS, V4, P269, DOI 10.1109/JIOT.2017.2647881
   Moujahid D., 2015, 2015 3 WORLD C COMPL, P1, DOI [10.1109/ICoCS.2015.7483285, DOI 10.1109/ICOCS.2015.7483285]
   Moujahid D, 2018, PATTERN RECOGN LETT, V110, P79, DOI 10.1016/j.patrec.2018.03.026
   Murthy S. V. N., 2016, PERSPECTIVESCI, V8, P338, DOI [10.1016/j.pisc.2016.04.069, DOI 10.1016/J.PISC.2016.04.069]
   Nair K, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P589, DOI 10.1109/ICGCIoT.2015.7380533
   Najva N, 2016, PROCEDIA COMPUT SCI, V93, P351, DOI 10.1016/j.procs.2016.07.220
   Nambiar A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3243043
   Natarajan P, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2710128
   Neto AJV, 2018, IEEE ACCESS, V6, P11101, DOI 10.1109/ACCESS.2018.2803439
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Nischt Michael, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2164, DOI 10.1109/ICCVW.2009.5457548
   Ortega A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P303, DOI 10.1109/IROS.2009.5354294
   Pagel F, 2014, PROC SPIE, V9026, DOI 10.1117/12.2041221
   Patil N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P344, DOI 10.1109/ICCSP.2017.8286374
   Pflugfelder R, 2010, IEEE T PATTERN ANAL, V32, P709, DOI 10.1109/TPAMI.2009.56
   Porikli F, 2013, IEEE SIGNAL PROC MAG, V30, P190, DOI 10.1109/MSP.2013.2241312
   Reddy MKK, 2020, IEEE WINT CONF APPL, P2803, DOI [10.1109/WACV45572.2020.9093409, 10.1109/wacv45572.2020.9093409]
   Riachy C, 2019, IEEE ACCESS, V7, P20596, DOI 10.1109/ACCESS.2019.2896779
   Rodriguez-Silva D. A., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P991, DOI 10.1109/CLOUD.2012.44
   SanMiguel JC, 2014, COMPUTER, V47, P67, DOI 10.1109/MC.2014.133
   Shariff AM, 2012, SAFETY SCI, V50, P29, DOI 10.1016/j.ssci.2011.06.008
   Shen H, 2016, J NETW COMPUT APPL, V71, P30, DOI 10.1016/j.jnca.2016.05.013
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2016, ELECTRONICS-SWITZ, V5, DOI 10.3390/electronics5010010
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sochor J, 2017, COMPUT VIS IMAGE UND, V161, P87, DOI 10.1016/j.cviu.2017.05.015
   Song XH, 2016, NEUROCOMPUTING, V187, P66, DOI 10.1016/j.neucom.2015.07.131
   Stauffer C, 2003, PROC CVPR IEEE, P259
   Strau T, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2623, DOI 10.1109/ITSC.2014.6958110
   Such JM, 2014, KNOWL ENG REV, V29, P314, DOI 10.1017/S0269888913000180
   Sun JH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010077
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takahashi K, 2012, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2012.6247783
   Tang Y., 2013, ADV INTERNET THINGS, V3
   Tejero-de-Pablos A, 2018, IEEE T MULTIMEDIA, V20, P2000, DOI 10.1109/TMM.2018.2794265
   Tian B, 2017, IEEE T INTELL TRANSP, V18, P25, DOI 10.1109/TITS.2016.2552778
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Vasconcelos F, 2018, IEEE T PATTERN ANAL, V40, P791, DOI 10.1109/TPAMI.2017.2699648
   Wang Q., 2011, INSTRUMENTATION MEAS, P1
   Wang Qi, 2010, Environmental Control in Biology, V48, P59
   Wang Q, 2011, 2011 6TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P893, DOI 10.1109/ChinaCom.2011.6158281
   Wang Y, 2015, J ELECTR COMPUT ENG, V2015, DOI 10.1155/2015/295428
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Wu XL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060838
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xu LF, 2020, IEEE T INTELL TRANSP, V21, P209, DOI 10.1109/TITS.2018.2890570
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Yang H, 2017, IEEE IMAGE PROC, P355, DOI 10.1109/ICIP.2017.8296302
   Yaseen MU, 2018, FUTURE GENER COMP SY, V80, P286, DOI 10.1016/j.future.2017.02.003
   Yin F, 2015, IET COMPUT VIS, V9, P354, DOI 10.1049/iet-cvi.2013.0301
   Yue XJ, 2018, IEEE COMMUN MAG, V56, P90, DOI 10.1109/MCOM.2018.1700423
   Yufu Qu, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P66, DOI 10.1109/CVPR.2009.5204294
   Zhan D, 2015, SENSORS-BASEL, V15, P8664, DOI 10.3390/s150408664
   Zhang HY, 2017, APPL ACOUST, V126, P136, DOI 10.1016/j.apacoust.2017.05.024
   Zhang MMY, 2019, SIGNAL PROCESS-IMAGE, V75, P118, DOI 10.1016/j.image.2019.03.015
   Zhang QY, 2016, 2016 FIRST IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC 2016), P121, DOI 10.1109/SEC.2016.30
   Zhang SX, 2020, ISPRS J PHOTOGRAMM, V159, P114, DOI 10.1016/j.isprsjprs.2019.11.005
   Zhao FD, 2018, IMAGE VISION COMPUT, V70, P46, DOI 10.1016/j.imavis.2017.12.006
   Zhao FD, 2016, IEEE IMAGE PROC, P1180, DOI 10.1109/ICIP.2016.7532544
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
   Zhu SP, 2018, NEUROCOMPUTING, V275, P511, DOI 10.1016/j.neucom.2017.08.054
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
   Zou W, 2015, THESIS TOTTORI U
   Zou WH, 2015, IEEE T INTELL TRANSP, V16, P1348, DOI 10.1109/TITS.2014.2361666
   Zou Z., 2020, ARXIV PREPRINT ARXIV
NR 171
TC 65
Z9 67
U1 11
U2 69
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103116
DI 10.1016/j.jvcir.2021.103116
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700015
DA 2024-07-18
ER

PT J
AU Chang, J
   Ding, F
   Li, XL
   Zhu, GP
AF Chang, Jie
   Ding, Feng
   Li, Xiaolong
   Zhu, Guopu
TI Hybrid prediction-based pixel-value-ordering method for reversible data
   hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding (RDH); Pixel-value-ordering (PVO); Rhombus
   prediction; Embedding capacity
ID SCHEME
AB Pixel-value-ordering (PVO) is an effective and promising method of reversible data hiding (RDH) and has received much attention in recent years. To improve performance, a pixel-based PVO (PPVO) method was recently introduced to predict the pixels to be embedded in a pixel-wise manner instead of the block-wise manner used by PVO. However, for PPVO, the surrounding neighbors of the predicted pixels are underutilized; moreover, its embedding does not adapt to the local complexity of the image to be embedded. To overcome the shortcomings of PPVO, this paper proposes a novel PVO method based on hybrid prediction for RDH. First, the surrounding neighbors of the pixel to be predicted are fully utilized by a hybrid prediction method, which combines rhombus prediction and pixel-wise prediction. Second, a modified embedding scheme based on multiple histograms is presented for adaptive embedding. Experimental results show the superior performance of the proposed method by comparing it with state-of-the-art RDH methods.
C1 [Chang, Jie; Zhu, Guopu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Ding, Feng] Nanchang Univ, Sch Software, Nanchang 330047, Jiangxi, Peoples R China.
   [Li, Xiaolong] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Nanchang University; Beijing Jiaotong University
RP Zhu, GP (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM jie.chang@siat.ac.cn; fd26@njit.edu; lixl@bjtu.edu.cn; gp.zhu@siat.ac.cn
RI li, xiao/HJP-5134-2023; Li, xiaolong/GRS-9148-2022; li,
   xiao/GSN-6181-2022; li, xiao/HKV-8405-2023
OI Zhu, Guopu/0000-0001-7956-5343
FU National Natural Science Foundation of China [61872350, 61972031,
   61572489]; Tip-top Scientific and Technical Innovative Youth Talents of
   Guangdong Special Support Program [2019TQ05X696]; Basic Research Program
   of Shenzhen [JCYJ20170818163403748]
FX The authors thank the anonymous reviewers for their valuable comments.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872350, Grant 61972031 and Grant
   61572489, in part by the Tip-top Scientific and Technical Innovative
   Youth Talents of Guangdong Special Support Program under Grant
   2019TQ05X696, and in part by the Basic Research Program of Shenzhen
   under Grant JCYJ20170818163403748.
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Fridrich J., 2009, INFORM HIDING
   Guan B, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102744
   He Junhui, 2019, IEEE T INF FORENSICS
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang HJ, 2010, KSII T INTERNET INF, V4, P655, DOI 10.3837/tiis.2010.08.0012
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Lee S, 2006, IEEE INT C MULT EXP
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Pan ZB, 2018, J VIS COMMUN IMAGE R, V50, P186, DOI 10.1016/j.jvcir.2017.11.020
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian HW, 2013, IEEE T CYBERNETICS, V43, P2190, DOI 10.1109/TCYB.2013.2245415
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang YG, 2018, IEEE T CYBERNETICS, V48, P2307, DOI 10.1109/TCYB.2017.2735989
   Wang YG, 2018, IEEE T IMAGE PROCESS, V27, P2063, DOI 10.1109/TIP.2018.2795745
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Xiang H, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P191, DOI 10.1109/ICMIP.2017.39
   Xiang HY, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2585983
   Xiao MY, 2019, SIGNAL PROCESS, V158, P210, DOI 10.1016/j.sigpro.2019.01.008
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zheng HC, 2019, SIGNAL PROCESS, V164, P74, DOI 10.1016/j.sigpro.2019.05.035
NR 47
TC 9
Z9 10
U1 3
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103097
DI 10.1016/j.jvcir.2021.103097
EA APR 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700006
DA 2024-07-18
ER

PT J
AU Song, LC
   Yu, G
   Yuan, JS
   Liu, ZC
AF Song, Liangchen
   Yu, Gang
   Yuan, Junsong
   Liu, Zicheng
TI Human pose estimation and its application to action recognition: A
   survey*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pose estimation; Action recognition
ID FLEXIBLE MIXTURES; NETWORK
AB Human pose estimation aims at predicting the poses of human body parts in images or videos. Since pose motions are often driven by some specific human actions, knowing the body pose of a human is critical for action recognition. This survey focuses on recent progress of human pose estimation and its application to action recognition. We attempt to provide a comprehensive review of recent bottom-up and top-down deep human pose estimation models, as well as how pose estimation systems can be used for action recognition. Thanks to the availability of commodity depth sensors like Kinect and its capability for skeletal tracking, there has been a large body of literature on 3D skeleton-based action recognition, and there are already survey papers such as [1] about this topic. In this survey, we focus on 2D skeleton-based action recognition where the human poses are estimated from regular RGB images instead of depth images. We summarize the performance of recent action recognition methods that use pose estimated from color images as input, then show that there is much room for improvements in this direction.
C1 [Song, Liangchen; Yuan, Junsong] Univ Buffalo, Buffalo, NY 14260 USA.
   [Yu, Gang] Tencent, Shenzhen, Peoples R China.
   [Liu, Zicheng] Microsoft Res, Redmond, WA USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; Tencent; Microsoft
RP Song, LC (corresponding author), Univ Buffalo, Buffalo, NY 14260 USA.
EM lsong8@bufflo.edu
RI Yuan, Junsong/A-5171-2011; Song, Liangchen/AAZ-9431-2021
OI Song, Liangchen/0000-0002-8366-5088; Yuan, Junsong/0000-0002-7901-8793;
   Yu, Gang/0000-0001-5570-2710
FU University at Buffalo
FX This work is supported in part by the startup funds from University at
   Buffalo.
CR Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2019, IEEE T PATTERN ANAL
   [Anonymous], 2019, Information Processing and Management, DOI DOI 10.1109/TITS.2018.2888587
   [Anonymous], 2016, CORR
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13
   Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J., 2018, arXiv
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Carreira Joao, 2019, CoRR
   Charles J, 2016, PROC CVPR IEEE, P3063, DOI 10.1109/CVPR.2016.334
   Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Girdhar R, 2018, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2018.00044
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   Gong WJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16121966
   Haque A, 2016, LECT NOTES COMPUT SC, V9905, P160, DOI 10.1007/978-3-319-46448-0_10
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742
   Hidalgo G, 2019, IEEE I CONF COMP VIS, P6981, DOI 10.1109/ICCV.2019.00708
   Huang J., 2019, IEEE INT C COMP VIS
   Huang LJ, 2019, PATTERN RECOGN, V92, P165, DOI 10.1016/j.patcog.2019.03.010
   Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329
   Hussain M, 2018, IEEE INT CONF VLSI, P201, DOI 10.1109/VLSI-SoC.2018.8645051
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Iqbal U, 2017, IEEE INT CONF AUTOMA, P438, DOI 10.1109/FG.2017.61
   Iskakov K, 2019, IEEE I CONF COMP VIS, P7717, DOI 10.1109/ICCV.2019.00781
   Jahangiri E, 2017, IEEE INT CONF COMP V, P805, DOI 10.1109/ICCVW.2017.100
   Jain A., 2014, INT C LEARN REPR
   Jain A, 2015, LECT NOTES COMPUT SC, V9004, P302, DOI 10.1007/978-3-319-16808-1_21
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Johnson S., 2010, BMVC
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Kay W., 2017, CORR ABS170506950
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Kim K, 2019, PROC IEEE MICR ELECT, P853, DOI [10.1109/MEMSYS.2019.8870758, 10.1109/memsys.2019.8870758]
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kocabas M, 2018, LECT NOTES COMPUT SC, V11215, P437, DOI 10.1007/978-3-030-01252-6_26
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li C, 2019, PROC CVPR IEEE, P9879, DOI 10.1109/CVPR.2019.01012
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li Yingwei, 2018, P EUR C COMP VIS ECC
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin W., 2020, ARXIV200504490
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2019, AAAI CONF ARTIF INTE, P8762
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Luo Y, 2018, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2018.00546
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3177, DOI 10.1109/CVPR.2011.5995631
   Marín-Jiménez MJ, 2018, J VIS COMMUN IMAGE R, V55, P627, DOI 10.1016/j.jvcir.2018.07.010
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   McNally W, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P49, DOI 10.1109/CRV.2019.00015
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Moon G, 2019, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2019.00796
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   Nie X., 2019, IEEE INT C COMP VIS
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P705, DOI 10.1007/978-3-030-01228-1_42
   Nie XC, 2018, PROC CVPR IEEE, P2100, DOI 10.1109/CVPR.2018.00224
   Nie XC, 2019, IEEE T IMAGE PROCESS, V28, P924, DOI 10.1109/TIP.2018.2872628
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Park S, 2016, LECT NOTES COMPUT SC, V9915, P156, DOI 10.1007/978-3-319-49409-8_15
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Peng X, 2018, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2018.00237
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2014, LECT NOTES COMPUT SC, V8753, P678, DOI 10.1007/978-3-319-11752-2_56
   Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052
   Raaj Y, 2019, PROC CVPR IEEE, P4615, DOI 10.1109/CVPR.2019.00475
   Rafi U., 2016, BRIT MACH VIS C
   Ren B., 2020, ARXIV200205907
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronchi MR, 2017, IEEE I CONF COMP VIS, P369, DOI 10.1109/ICCV.2017.48
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Shafaei A, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P24, DOI 10.1109/CRV.2016.25
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simonyan K, 2014, ADV NEUR IN, V27
   Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450
   Siyuan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P769, DOI 10.1007/978-3-030-58580-8_45
   Song J, 2017, PROC CVPR IEEE, P5563, DOI 10.1109/CVPR.2017.590
   Song SJ, 2018, IEEE T IMAGE PROCESS, V27, P3459, DOI 10.1109/TIP.2018.2818328
   Soomro K., 2012, ARXIV12120402CS
   Su K, 2019, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2019.00582
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun K, 2017, IEEE I CONF COMP VIS, P5600, DOI 10.1109/ICCV.2017.597
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Tang W, 2018, LECT NOTES COMPUT SC, V11207, P197, DOI 10.1007/978-3-030-01219-9_12
   Tang W, 2019, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2019.00120
   Tekin B, 2019, PROC CVPR IEEE, P4506, DOI 10.1109/CVPR.2019.00464
   Thakkar K.C., 2018, BRIT MACH VIS C, P270
   Tkach A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980226
   Tompson J, 2014, ADV NEUR IN, V27
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L., 2016, P ECCV
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weinzaepfel Philippe, 2019, ARXIV PREPRINT ARXIV
   Wu J., 2017, CoRR abs/1711.06475
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xiong F., 2019, IEEE INT C COMP VIS
   Yan A, 2019, PROC CVPR IEEE, P7914, DOI 10.1109/CVPR.2019.00811
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yao A, 2012, INT J COMPUT VISION, V100, P16, DOI 10.1007/s11263-012-0532-9
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhang F, 2019, PROC CVPR IEEE, P3512, DOI 10.1109/CVPR.2019.00363
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   Zhao R, 2019, IEEE I CONF COMP VIS, P6881, DOI 10.1109/ICCV.2019.00698
   Zhou X., 2019, ABS190407850 CORR
   Zhu JG, 2019, IEEE SIGNAL PROC LET, V26, P1633, DOI 10.1109/LSP.2019.2942739
   Zhu JG, 2018, INT C PATT RECOG, P645, DOI 10.1109/ICPR.2018.8545710
NR 154
TC 62
Z9 65
U1 9
U2 92
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103055
DI 10.1016/j.jvcir.2021.103055
EA MAR 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700002
DA 2024-07-18
ER

PT J
AU Li, YQ
   Su, H
   Zhu, J
AF Li, Yueqiao
   Su, Hang
   Zhu, Jun
TI AdvCapsNet: To defense adversarial attacks based on Capsule networks*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Capsule; Adversarial; Defense; Robustness
AB Convolutional neural networks have achieved the state-of-the-art results across numerous applications, but recent work finds that these models can be easily fooled by adversarial perturbations. This is partially due to gradient calculation instability, which may be amplified throughout network layers (Liao et al., 2018). To address this issue, we propose a novel AdvCapsNet derived from Capsule (Sabour et al., 2017), which utilizes a significantly more complicated non-linearity, to defend against adversarial attacks. In this paper, we focus on the transfer-based black-box adversarial attacks, which are more practical than their white-box counterparts. Specifically, we investigate vanilla Capsule?s robustness and boost its performance by introducing an adversarial loss function as regularization. The weight updating between capsule layers is implemented via dynamic routing regularized by the additional adversarial term. Extensive experiments demonstrate that the proposed AdvCapsNet can significantly boost Capsule?s robustness and that AdvCapsNet is far more resistance to adversarial attacks than alternative baselines, including both CNN-and Capsule-based defense models.
C1 [Li, Yueqiao] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Su, Hang; Zhu, Jun] Tsinghua Univ, Inst AI, THBI Lab, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Li, YQ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM li-yq17@mails.tsinghua.edu.cn; suhangss@mail.tsinghua.edu.cn;
   dcszj@mail.tsinghua.edu.cn
FU National Key Research and Development Program of China [2017YFA0700904];
   NSFC [61620106010, 61621136008, 61571261]; Beijing NSF Project
   [L172037]; Beijing Academy of Artificial Intelligence (BAAI); Tiangong
   Institute for Intelligent Computing; JP Morgan Faculty Research Program;
   NVIDIA NVAIL Program; GPU/DGX Acceleration
FX This work was supported by the National Key Research and Development
   Program of China (No. 2017YFA0700904), NSFC Projects (Nos. 61620106010,
   61621136008, 61571261), Beijing NSF Project (No. L172037), Beijing
   Academy of Artificial Intelligence (BAAI), Tiangong Institute for
   Intelligent Computing, the JP Morgan Faculty Research Program and the
   NVIDIA NVAIL Program with GPU/DGX Acceleration.
CR Bojarski M., 2016, ARXIV PREPRINT ARXIV
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Du YP, 2019, IEEE ACCESS, V7, P39321, DOI 10.1109/ACCESS.2019.2906398
   Duarte K, 2018, ADV NEUR IN, V31
   Frosst N., 2018, ARXIV PREPRINT ARXIV
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2018, INT C LEARN REPR
   Howard J., 2019, Imagenette.
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kannan H., 2018, Adversarial logit pairing
   Kosiorek A.R., 2019, ARXIV PREPRINT ARXIV
   Krizhevsky A., 2014, The cifar-10 dataset
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin Alex., 2018, Ensemble adversarial training: Attacks and defenses
   LaLonde R., 2018, P INT C MED IM DEEP
   LeCun Y, 2004, PROC CVPR IEEE, P97
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li PC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2909
   Li S, 2020, ANIM BIOTECHNOL, V31, P59, DOI 10.1080/10495398.2018.1538014
   Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Madry A., 2018, ARXIV
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Pang TY, 2019, PR MACH LEARN RES, V97
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Sabour S, 2017, ADV NEUR IN, V30
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K., 2014, 14091556 ARXIV
   Su D, 2018, LECT NOTES COMPUT SC, V11216, P644, DOI 10.1007/978-3-030-01258-8_39
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Wang Dilin, 2018, An optimization view on dynamic routing between capsules
   Xiao H., 2017, ARXIV170807747
   Zhang S., 2018, INT S ART INT ROB, P301
   Zhang YC, 2019, PR MACH LEARN RES, V89, P684
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 41
TC 4
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103037
DI 10.1016/j.jvcir.2021.103037
EA FEB 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BY
UT WOS:000633494500005
DA 2024-07-18
ER

PT J
AU Xiong, YM
   Shao, F
   Meng, XC
   Jiang, QP
   Sun, WW
   Fu, RD
   Ho, YS
AF Xiong, Yiming
   Shao, Feng
   Meng, Xiangchao
   Jiang, Qiuping
   Sun, Weiwei
   Fu, Randi
   Ho, Yo-Sung
TI A large-scale remote sensing database for subjective and objective
   quality assessment of pansharpened images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pansharpened image quality assessment; Pansharpened Remote Sensing Image
   Quality Database (PRSIQD); Panchromatic; Multispectral; Pansharpening;
   Remote sensing
ID SPECTRAL RESOLUTION IMAGES; SPATIAL-RESOLUTION; LANDSAT TM; FUSION;
   MULTIRESOLUTION; CLASSIFICATION; SATELLITE; INFORMATION; MS
AB Pansharpening is a process to fuse a low spatial resolution multispectral image and a high spatial resolution panchromatic image to produce a high-resolution multispectral image. Quality assessment of pansharpened images is challenging due to without actual reference images. There are two main types of assessment methods: reduced resolution (RR) assessment based on Wald's protocol, and full resolution (FR) assessment without reference. Currently, it is lack of large-scale benchmark databases for subjective and objective performance evaluation of different image pansharpening methods. In this paper, we construct a large-scale database named Pansharpened Remote Sensing Image Quality Database (PRSIQD) from both qualitative and quantitative perspectives, which contains 13,620 pansharpened images acquired from IKONOS, QuickBird, Gaofen-1, WorldView-2, WorldView-3 and WorldView-4 satellite sensors. In addition, we have comprehensively analyzed the advantages and disadvantages of the existing pansharpening quality assessment methods on different satellite sensors, thematic datasets and bands.
C1 [Xiong, Yiming; Shao, Feng; Meng, Xiangchao; Jiang, Qiuping; Fu, Randi] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Sun, Weiwei] Ningbo Univ, Dept Geograp & Spatial Informat Tech, Ningbo 315211, Peoples R China.
   [Ho, Yo-Sung] Gwangju Inst Sci & Technol GIST, Sch Informat & Commun, Gwangju 500712, South Korea.
C3 Ningbo University; Ningbo University; Gwangju Institute of Science &
   Technology (GIST)
RP Shao, F; Meng, XC (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM shaofenng@nbu.edu.cn; mengxizng@nbu.edu.cn; jiangqiuping@nbu.edu.cn;
   sunweiwei@nbu.edu.cn; furandi@nbu.edu.cn; hoyo@gist.ac.kr
RI Jiang, Qiuping/AAL-8273-2020; 孙, 伟伟/GQG-8925-2022
FU Natural Science Foundation of China [62071261, 41801252]; Zhejiang
   Natural Science Foundation of China [R18F010008]; K. C. Wong Magna Fund
   in Ningbo University
FX This work was supported by the Natural Science Foundation of China
   (grant 62071261, 41801252), and the Zhejiang Natural Science Foundation
   of China (grant R18F010008). It was also sponsored by K. C. Wong Magna
   Fund in Ningbo University.
CR Agudelo-Medina OA, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070877
   Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B., 2014, P SOC PHOTO-OPT INS, V9244
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Alparone L, 2004, IEEE GEOSCI REMOTE S, V1, P313, DOI 10.1109/LGRS.2004.836784
   [Anonymous], 1999, P910 ITUT
   [Anonymous], 1999, P911 ITUT
   Ballester C, 2006, INT J COMPUT VISION, V69, P43, DOI 10.1007/s11263-006-6852-x
   Baronti S, 2011, IEEE J-STSP, V5, P446, DOI 10.1109/JSTSP.2011.2104938
   Bovolo F, 2010, IEEE GEOSCI REMOTE S, V7, P53, DOI 10.1109/LGRS.2009.2029248
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Garzelli A, 2009, IEEE GEOSCI REMOTE S, V6, P662, DOI 10.1109/LGRS.2009.2022650
   Gilbertson JK, 2017, COMPUT ELECTRON AGR, V134, P151, DOI 10.1016/j.compag.2016.12.006
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Hasanlou M, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2015-0
   Huang X, 2014, IEEE GEOSCI REMOTE S, V11, P753, DOI 10.1109/LGRS.2013.2278551
   Ibarrola-Ulzurrun E, 2017, CAN J REMOTE SENS, V43, P528, DOI 10.1080/07038992.2017.1371583
   Javan FD, 2013, REMOTE SENS-BASEL, V5, P6539, DOI 10.3390/rs5126539
   Jiang QP, 2019, IEEE T IMAGE PROCESS, V28, P1866, DOI 10.1109/TIP.2018.2881828
   Johnson B, 2014, ISPRS INT J GEO-INF, V3, P507, DOI 10.3390/ijgi3020507
   Kwan C, 2017, IEEE GEOSCI REMOTE S, V14, P1835, DOI 10.1109/LGRS.2017.2737820
   Laben C. A., 2000, US Patent, Patent No. 6,011,875
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Masi G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070594
   Meng XC, 2019, IEEE T GEOSCI REMOTE, V57, P2840, DOI 10.1109/TGRS.2018.2878007
   Meng XC, 2019, INFORM FUSION, V46, P102, DOI 10.1016/j.inffus.2018.05.006
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Palsson F, 2016, IEEE T GEOSCI REMOTE, V54, P1247, DOI 10.1109/TGRS.2015.2476513
   Palubinskas G, 2015, REMOTE SENS-BASEL, V7, P9292, DOI 10.3390/rs70709292
   Pohl C., 2017, INT ARCH PHOTOGRAMM, V42, P863, DOI [10.5194/isprs-archives-XLII-2-W7-863-2017, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W7-863-2017]
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Restaino R, 2017, IEEE T GEOSCI REMOTE, V55, P753, DOI 10.1109/TGRS.2016.2614367
   Rodríguez-Esparragón D, 2017, NEUROCOMPUTING, V255, P40, DOI 10.1016/j.neucom.2016.06.091
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Salehi B, 2012, REMOTE SENS-BASEL, V4, P2256, DOI 10.3390/rs4082256
   SCHOWENGERDT RA, 1980, PHOTOGRAMM ENG REM S, V46, P1325
   Selva M, 2018, IEEE GEOSCI REMOTE S, V15, P320, DOI 10.1109/LGRS.2017.2777916
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen HF, 2016, IEEE T GEOSCI REMOTE, V54, P7135, DOI 10.1109/TGRS.2016.2596290
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Sirguey P, 2008, IEEE GEOSCI REMOTE S, V5, P78, DOI 10.1109/LGRS.2007.908884
   Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448
   Updike T., 2010, TECH REP
   van Dijk A. M., 1995, P SPIE ADV IMAGE VID
   Vivone G, 2019, IEEE GEOSCI REMOTE S, V16, P437, DOI 10.1109/LGRS.2018.2876629
   Vivone G, 2018, IEEE T GEOSCI REMOTE, V56, P4820, DOI 10.1109/TGRS.2018.2839564
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wald L., 2000, 3 C FUS EARTH DAT ME, P99
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yuhas R., 1992, SUMMARIES 4 ANN JPL, P147
   Zhong J, 2016, SENSING IMAGING, V17, P1
   Zhou BZ, 2019, IEEE ACCESS, V7, P40388, DOI 10.1109/ACCESS.2019.2905615
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 68
TC 4
Z9 5
U1 3
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102947
DI 10.1016/j.jvcir.2020.102947
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000007
DA 2024-07-18
ER

PT J
AU Du, Y
   Wen, DS
   Liu, GZ
   Qiu, S
   Yao, DL
   Yi, HW
   Liu, MY
AF Du, Yun
   Wen, Desheng
   Liu, Guizhong
   Qiu, Shi
   Yao, Dalei
   Yi, Hongwei
   Liu, Meiying
TI A novel approach for space debris recognition based on the full
   information vectors of star points
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Space debris recognition; Star image; Binary classifier; Equal
   probability density curve; Full information vector
ID MOVING-OBJECTS; IMAGE; ALGORITHM; FUSION
AB The recognition and detection of space debris has become one of significant research fields recently. Compared with natural images, effective information are very few contained in star images. In the past years, the gray values of star points and the continuity of sequential star images are utilized by numerous algorithms to carry out the recognition and detection through fusion of consecutive star images, which have been achieved good performance. However, with the rapid increase of star image data, those algorithms seem to be inadequate in recognition ability. In this paper, we propose one novel approach based on the full information vectors of star points to recognize moving targets with the machine learning method which is never utilized in space debris recognition field. Besides gray values, we further deeply excavate the characteristics of each star point in a single frame by the equal probability density curve of Gaussian distribution. The elliptical pattern characteristic vectors of star points can be input into the machine learning method for classification of static stars and moving targets in a single frame. Finally, trajectories of moving targets can be determined within 3 frames by the full information vectors. Therefore, traditional processing methods are abandoned and the proposed brand new approach redefines the recognition technical route of space debris. The experimental results demonstrate that moving targets can be successfully recognized in a single frame and the coverage rate of moving targets can reach 100%. Compared with other traditional methods, the proposed approach has better performance and more robustness. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Du, Yun; Wen, Desheng; Qiu, Shi; Yao, Dalei; Yi, Hongwei; Liu, Meiying] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.
   [Du, Yun; Liu, Guizhong; Yao, Dalei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Du, Yun; Yao, Dalei; Liu, Meiying] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; Xi'an Jiaotong University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Du, Y (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.; Du, Y (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.; Du, Y (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM duyun@opt.ac.cn; ven@opt.ac.cn; liugz@xjtu.edu.cn; qiushi215@163.com;
   ydl1982@opt.ac.cn; yi_hongwei@126.com; liumeiying@opt.ac.cn
RI Qiu, Shi/HGI-9191-2022
FU National Hightech R&D Program (863 Program) [2015AA7046612]
FX This work is supported by No. 2015AA7046612, National Hightech R&D
   Program (863 Program).
CR Alsulami F, 2016, INT CONF ELECTRO INF, P357, DOI 10.1109/EIT.2016.7535265
   Anz-Meador P., 2018, NASA ORB DEB PROGRAM, V22, P1
   BLOSTEIN SD, 1991, IEEE T SIGNAL PROCES, V39, P1611, DOI 10.1109/78.134399
   Boonprong S, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7070274
   Boyle R, 2008, J AM CULTURE, V31, P373, DOI 10.1111/j.1542-734X.2008.00684.x
   Cao YZ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040445
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Danescu R, 2012, SENSORS-BASEL, V12, P12940, DOI 10.3390/s121012940
   Dannemiller K, 2015, INT CONF ELECTRO INF, P361, DOI 10.1109/EIT.2015.7293369
   Deng H, 2016, IEEE T AERO ELEC SYS, V52, P60, DOI 10.1109/TAES.2015.140878
   Deng L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091054
   ENDO Y, 1985, IEEE T ELECTRON DEV, V32, P1511, DOI 10.1109/T-ED.1985.22155
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   He JY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080896
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Irie K, 2008, IEEE T CIRC SYST VID, V18, P280, DOI 10.1109/TCSVT.2007.913972
   Karimi N, 2018, J VIS COMMUN IMAGE R, V55, P853, DOI 10.1016/j.jvcir.2018.04.001
   Kim S, 2015, SENSORS-BASEL, V15, P7267, DOI 10.3390/s150407267
   Kranjcic N, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060655
   Li PF, 2015, NEUROCOMPUTING, V169, P34, DOI 10.1016/j.neucom.2014.09.102
   Liu R, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071054
   Liu YM, 2008, SENSORS-BASEL, V8, P3429, DOI 10.3390/s8053429
   Millan VG, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121865
   Mohammadi MM, 2008, EUROP RADAR CONF, P9
   Oishi Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121236
   Piattoni J, 2014, ACTA ASTRONAUT, V103, P176, DOI 10.1016/j.actaastro.2014.05.025
   Polajzer B, 2017, IEEE T POWER SYST, V32, P2296, DOI 10.1109/TPWRS.2016.2605152
   Pulford GW, 2005, IEE P-RADAR SON NAV, V152, P291, DOI 10.1049/ip-rsn:20045064
   Qin HL, 2016, INFRARED PHYS TECHN, V76, P148, DOI 10.1016/j.infrared.2016.02.003
   Qiu S, 2016, CHINESE J ELECTRON, V25, P711, DOI 10.1049/cje.2016.07.009
   REED IS, 1990, IEEE T AERO ELEC SYS, V26, P434, DOI 10.1109/7.106120
   Rufino G, 2003, ACTA ASTRONAUT, V53, P135, DOI 10.1016/S0094-5765(02)00199-6
   Stavrakoudis DG, 2014, REMOTE SENS-BASEL, V6, P6897, DOI 10.3390/rs6086897
   Sun RY, 2015, ACTA ASTRONAUT, V110, P9, DOI 10.1016/j.actaastro.2015.01.001
   Wei BS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093005
   Xi JB, 2016, APPL OPTICS, V55, P7929, DOI 10.1364/AO.55.007929
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2010, COMPUT GRAPH FORUM, V29, P2187, DOI 10.1111/j.1467-8659.2010.01807.x
   Xue D., 2018, P 2018 IEEE 4 INT C, P1
   Zafari A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050575
   [张旭升 ZHANG Xusheng], 2005, [光学技术, Optical Technology], V31, P719
   Zhong ZF, 2017, IEEE T INTELL TRANSP, V18, P1109, DOI 10.1109/TITS.2016.2597441
NR 43
TC 2
Z9 2
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102716
DI 10.1016/j.jvcir.2019.102716
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900009
DA 2024-07-18
ER

PT J
AU Fan, JY
   Chen, T
   Zhou, F
AF Fan, Jiayuan
   Chen, Tao
   Zhou, Feng
TI BURSTS: A bottom-up approach for robust spotting of texts in scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Text spotting; CNN; Extremal region; Clustering
ID RECOGNITION
AB In this paper, we present a bottom-up approach for robust spotting of texts in scenes. In the proposed technique, character candidates are first detected using our proposed character detector, which leverages on the strengths of an Extremal Region (ER) detector and an Aggregate Channel Feature (ACF) detector for high character detection recall. The real characters are then identified by using a novel convolutional neural network (CNN) filter for high character detection precision. A hierarchical clustering algorithm is designed which combines multiple visual and geometrical features to group characters into word proposal regions for word recognition. The proposed technique has been evaluated on several scene text spotting datasets and experiments show superior spotting performance. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Fan, Jiayuan] Fudan Univ, Acad Engn & Technol, Shanghai 200433, Peoples R China.
   [Fan, Jiayuan] Shanghai Engn Res Ctr AI & Robot, Shanghai, Peoples R China.
   [Fan, Jiayuan] Minist Educ, Engn Res Ctr AI & Robot, Shanghai, Peoples R China.
   [Chen, Tao] Fudan Univ, Sch Informat Sci & Technol, Shanghai 200433, Peoples R China.
   [Zhou, Feng] Univ Michigan, Dept Ind & Mfg Syst Engn, Dearborn, MI 48128 USA.
C3 Fudan University; Fudan University; University of Michigan System;
   University of Michigan
RP Chen, T (corresponding author), Fudan Univ, Sch Informat Sci & Technol, Shanghai 200433, Peoples R China.
EM jyfan@fudan.edu.cn; eetchen@fudan.edu.cn; fezhou@umich.edu
OI Zhou, Feng/0000-0001-6123-073X
FU Shanghai Pujiang Program [19PJ1402000]; NSFC of China [U1909207]
FX This work is sponsored by Shanghai Pujiang Program (No. 19PJ1402000) and
   NSFC of China (No. U1909207).
CR Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Alsharif O., 2014, ARXIV13101811
   [Anonymous], 2016, ARXIV160402619
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Gomez L., 2014, Asian Conference on Computer Vision, V3, P157
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M., 2014, ARXIV
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Liu XL, 2015, PROC INT CONF DOC, P396, DOI 10.1109/ICDAR.2015.7333791
   Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110
   Sung MC, 2015, PROC INT CONF DOC, P426, DOI 10.1109/ICDAR.2015.7333797
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhu SY, 2016, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2016.74
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 31
TC 3
Z9 3
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102843
DI 10.1016/j.jvcir.2020.102843
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400017
DA 2024-07-18
ER

PT J
AU Shokri, M
   Harati, A
   Taba, K
AF Shokri, Mohammad
   Harati, Ahad
   Taba, Kimya
TI Salient object detection in video using deep non-local neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video saliency detection; Deep learning; Non-local neural networks;
   Fully convolutional neural networks
ID VISUAL-ATTENTION
AB Detection of salient objects in image and video is of great importance in many computer vision applications. In spite of the fact that the state of the art in saliency detection for still images has been changed substantially over the last few years, there have been few improvements in video saliency detection. This paper proposes a novel non-local fully convolutional network architecture for capturing global dependencies more efficiently and investigates the use of recently introduced non-local neural networks in video salient object detection. The effect of non-local operations is studied separately on static and dynamic saliency detection in order to exploit both appearance and motion features. A novel deep non-local fully convolutional network architecture is introduced for video salient object detection and tested on two well-known datasets DAVIS and FBMS. The experimental results show that the proposed algorithm outperforms state-of-the-art video saliency detection methods. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Shokri, Mohammad; Harati, Ahad; Taba, Kimya] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Harati, A (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM shokri@mail.um.ac.ir; a.harati@um.ac.ir
RI Harati, Ahad/P-4468-2015
OI Harati, Ahad/0000-0001-7263-0309
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2008, PROC INT CONF PATTER
   [Anonymous], CORR
   [Anonymous], CORR
   [Anonymous], ARXIV180403999
   [Anonymous], AAAI
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], CORR
   [Anonymous], 2017, CORR
   [Anonymous], 2006, LECT NOTES COMPUTER
   [Anonymous], CORR
   [Anonymous], 2017, IEEE INT C INTELL TR
   Appelbaum LG, 2009, J VISION, V9, DOI 10.1167/9.11.18
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Borji A., 2014, CoRR, Vabs/1411.5878
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen JZ, 2018, J VIS COMMUN IMAGE R, V50, P270, DOI 10.1016/j.jvcir.2017.12.006
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding G., 2018, DIGITAL TV WIRELESS, V815, P245
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fu HZ, 2017, IEEE T IMAGE PROCESS, V26, P1418, DOI 10.1109/TIP.2017.2651369
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo FJ, 2017, IEEE INFOCOM SER, DOI 10.1109/TCYB.2017.2761361
   Guo MW, 2014, NEUROCOMPUTING, V144, P184, DOI 10.1016/j.neucom.2014.04.054
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Kannan R, 2015, SIGNAL PROCESS-IMAGE, V36, P154, DOI 10.1016/j.image.2015.07.004
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Le T., 2017, CoRR
   Lei JJ, 2016, IEEE T MULTIMEDIA, V18, P1783, DOI 10.1109/TMM.2016.2592325
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Navalpakkam V., 2006, P IEEE C COMPUTER VI, P2049
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   Tang Y, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P362, DOI 10.1145/3206025.3206052
   Le TN, 2018, IEEE T IMAGE PROCESS, V27, P5002, DOI 10.1109/TIP.2018.2849860
   Wang LJ, 2020, IEEE T CYBERNETICS, V50, P1485, DOI 10.1109/TCYB.2018.2865499
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang Z, 2018, NEUROCOMPUTING, V287, P68, DOI 10.1016/j.neucom.2018.01.076
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Zhang JM, 2016, PROC CVPR IEEE, P5733, DOI 10.1109/CVPR.2016.618
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429
   Zhou XF, 2018, J VIS COMMUN IMAGE R, V51, P131, DOI 10.1016/j.jvcir.2018.01.014
NR 75
TC 23
Z9 24
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2020
VL 68
AR 102769
DI 10.1016/j.jvcir.2020.102769
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LO3GK
UT WOS:000533516900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, HK
   Yu, HM
   Hu, RL
   Zhang, GQ
   Hu, JG
   He, T
AF Zhou, Houkui
   Yu, Huimin
   Hu, Roland
   Zhang, Guangqun
   Hu, Junguo
   He, Tao
TI Analyzing multiple types of behaviors from traffic videos via
   nonparametric topic model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Nonparametric topic model; Motion pattern; Traffic pattern; Abnormality
   detection; Beta negative binomial process; Possion factor analysis
AB Intelligent video surveillance systems have garnered substantial research attention in recent years within the transportation surveillance field. The systems can assist in identifying activities, interactions, and abnormal behaviors of individuals in traffic. We propose a novel unsupervised learning framework based on a two-layer BNBP-PFA topic model to simultaneously model multiple types of behaviors in crowded and complicated traffic videos. We provide the model's structure, its inference algorithm, and design a corresponding likelihood function based on an abnormality detection algorithm. Compared to similar existing algorithms, ours readily reveals both the local topic-motion pattern and the global topic-traffic pattern. Comparative experiments on two public traffic video datasets show that our model outperforms the state-of-art algorithms in regards to effective topic discovery and abnormality detection. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhou, Houkui; Zhang, Guangqun; Hu, Junguo; He, Tao] ZheJiang A&F Univ, Sch Informat Engn, Hangzhou 311300, Zhejiang, Peoples R China.
   [Zhou, Houkui; Zhang, Guangqun; Hu, Junguo; He, Tao] Zhejiang Prov Key Lab Forestry Intelligent Monito, Hangzhou 311300, Zhejiang, Peoples R China.
   [Yu, Huimin; Hu, Roland] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yu, Huimin] State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang A&F University; Zhejiang University
RP Zhou, HK; Hu, JG; He, T (corresponding author), ZheJiang A&F Univ, Sch Informat Engn, Hangzhou 311300, Zhejiang, Peoples R China.
EM zhouhk@zju.edu.cn; hujunguo@zafu.edu.cn; hetao@zafu.edu.cn
RI Zhou, Houkui/JXY-6584-2024
OI Zhou, Houkui/0000-0001-7915-8684; He, Tao/0000-0001-5304-3010
FU National Nature Science Foundation of China [31971493, 31570629,
   61471321]; Zhejiang Provincial Natural Science Foundation of China
   [LY19F020048, LY16C160007, LY16F010004]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments and suggestions, which significantly contributed
   to improving the manuscript. This work was supported the National Nature
   Science Foundation of China (No. 31971493, No. 31570629, No. 61471321),
   the Zhejiang Provincial Natural Science Foundation of China
   (LY19F020048, No. LY16C160007, No. LY16F010004).
CR [Anonymous], 7 INT S TEL
   Bai Lu, 2013, ACM INT C WEB SEARCH, P315
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Fu W, 2012, IEEE IMAGE PROC, P29, DOI 10.1109/ICIP.2012.6466787
   Gilks W.R., 1995, MARKOV CHAIN MONTE C
   Gomar S, 2016, IEEE IJCNN, P213, DOI 10.1109/IJCNN.2016.7727201
   Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342
   Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Kaviani R., 2014, 4 INT C COMP KNOW EN
   Khoat Than, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P490, DOI 10.1007/978-3-642-33460-3_37
   Liao WT, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P166, DOI 10.1109/ICCVW.2015.31
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Song LB, 2011, MOBILE OPPORTUNISTIC NETWORKS: ARCHITECTURES, PROTOCOLS AND APPLICATIONS, P1, DOI 10.1145/1287791.1287799
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Williamson S., 2010, P 27 INT C MACH LEAR, P1151
   Yawen Fan, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P726, DOI 10.1109/ICIG.2011.56
   Zhou M., 2012, Artificial Intelligence and Statistics, P1462
   Zhou MY, 2015, IEEE T PATTERN ANAL, V37, P307, DOI 10.1109/TPAMI.2013.211
   Zhu J, 2011, EPD CONGRESS 2011, P883
NR 22
TC 5
Z9 5
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102649
DI 10.1016/j.jvcir.2019.102649
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600031
DA 2024-07-18
ER

PT J
AU Wang, RG
   Yao, XC
   Yang, J
   Xue, LX
   Hu, M
AF Wang, Ronggui
   Yao, Xuchen
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Hierarchical deep transfer learning for fine-grained categorization on
   micro datasets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained categorization; Convolutional neural network; Transfer
   learning; Multi-task learning; Model compression
AB Fine-grained categorization is challenging due to its small inter-class and large intra-class variance. Moreover, requiring domain expertise makes fine-grained labelled data much more expensive to acquire. Existing models predominantly require extra information such as bounding box and part annotation in addition to the image category labels, which involves heavy manual labor. In this paper, we propose a novel hierarchical deep transfer learning model, based on a compression convolutional neural network. Our model transfers the learned image representation from large-scale labelled fine-grained datasets to micro fine-grained datasets, which avoids using expensive annotations and realizes visual categorization task effectively. Firstly, we introduce a cohesion domain to measure correlation degree between source domain and target domain. Secondly, the source-domain convolutional neural network is adjusted according to its metrical feedback, in order to select task-specific features that are suitable for transferring to the target domain. Finally, we make most of perspective-class labels, which are inherent attributes of fine-grained data for multi-task learning and learn all the attributes through joint learning to extract more discriminative representations. The proposed model not only economizes training time effectively and achieves high categorization accuracy, but also verifies that the inter-domain feature transition can accelerate learning and optimization. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Ronggui; Yao, Xuchen; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM yangjuan6985@163.com
RI Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]; State Key
   Program of NSFC-Shenzhen Joint Foundation [U1613217]
FX We express our sincere thanks to all the suppliers for providing
   fine-grained datasets, and the authors would also like to thank the
   anonymous reviewers for their useful and suggestions to raise the
   standard of the paper. This work is partly supported by the National
   Natural Science Foundation of China under Grant No. 61672202 and State
   Key Program of NSFC-Shenzhen Joint Foundation under Grant No. U1613217.
CR [Anonymous], 2011, International Journal of Robotics Research
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], J INFORM TELECOMMUN
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], 2010, ADV NEUR INF PROC SY
   [Anonymous], 2016, ARXIV160207360
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2014, BRIT C MACH VIS
   [Anonymous], 2014, ARXIV14127054
   [Anonymous], MACH LEARN
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], COMPUT SCI
   [Anonymous], COMPUT SCI
   [Anonymous], 2017, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-017-4840-5
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], P CVPR WORKSH FIN GR
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Denton E, 2014, ADV NEUR IN, V27
   Han S., 2015, ARXIV151000149
   Hinton G., 2015, COMPUT SCI, V2
   Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Ionescu RT, 2015, LECT NOTES COMPUT SC, V9279, P97, DOI 10.1007/978-3-319-23231-7_9
   Iscen A, 2015, IEEE T IMAGE PROCESS, V24, P2369, DOI 10.1109/TIP.2015.2423557
   Escalante HJ, 2017, NEURAL COMPUT APPL, V28, P925, DOI 10.1007/s00521-016-2223-x
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Wu XH, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING APPLICATIONS (CSEA 2015), P1
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang X., 2017, ARXIV170701083
   Zhang Y, 2018, NATL SCI REV, V5, P30, DOI 10.1093/nsr/nwx105
NR 46
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 129
EP 139
DI 10.1016/j.jvcir.2019.05.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600012
DA 2024-07-18
ER

PT J
AU Xin, Z
   Wang, DH
AF Xin Zhang
   Wang Dahu
TI Application of artificial intelligence algorithms in image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Artificial intelligence algorithm; Image segmentation;
   Ant colony algorithm
ID TECHNOLOGY
AB As the main media of human communication and understanding of the world, image is one of the important information sources of human intelligence activities. With the development of the times, the demand for image processing technology is increasing day by day. The rapid development of computer technology also provides a platform for the application of image processing. In order to achieve better image processing effect, this paper focuses on the application of artificial intelligence algorithm in image processing. Image segmentation is a technology that decomposes images into regions with different characteristics and extracts useful targets. It can be regarded as a combinatorial optimization problem. It is completely feasible to apply artificial intelligence algorithm to optimization problems. Firstly, this paper introduces the ant colony algorithm in artificial intelligence algorithm, elaborates the basic principle and mathematical model of the ant colony algorithm. Secondly, in order to improve the ability of global search of ant colony algorithm, this paper introduces the crowding degree function of fish into the ant colony algorithm. Finally, the improved ant colony algorithm is used in image segmentation to improve the effect of image segmentation. The simulation results show that it is feasible to use ant colony algorithm in image segmentation. And the optimization improvement of ant colony algorithm is effective. The improved ant colony algorithm applied in image segmentation can significantly improve the segmentation performance. (C) 2019 Published by Elsevier Inc.
C1 [Xin Zhang] Jilin Business & Technol Coll, Engn Inst, Changchun, Jilin, Peoples R China.
   [Wang Dahu] Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo, Henan, Peoples R China.
C3 Jilin Business & Technology College; Henan Polytechnic University
RP Wang, DH (corresponding author), Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo, Henan, Peoples R China.
EM dahuwang2008@126.com
RI xin, zhang/KIL-2186-2024; Wang, Dahu/W-7194-2018
FU National Natural Science Foundation of China Youth Science Foundation
   [61601172]
FX This work was supported by National Natural Science Foundation of China
   Youth Science Foundation (No. 61601172).
CR Carleo G, 2017, SCIENCE, V355, P602, DOI 10.1126/science.aag2302
   Chavez J.J.S., 2016, International Journal of Industrial Engineering Computations, V7, P35, DOI DOI 10.5267/J.IJIEC.2015.8.003
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Feng Y, 2017, INT J HYDROGEN ENERG, V42, P14418, DOI 10.1016/j.ijhydene.2017.04.084
   Glauner P, 2017, INT J COMPUT INT SYS, V10, P760, DOI 10.2991/ijcis.2017.10.1.51
   Jiang YZ, 2016, INFORM SCIENCES, V369, P171, DOI 10.1016/j.ins.2016.06.020
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Larrère C, 2018, J SOC PHILOS, V49, P426, DOI 10.1111/josp.12255
   Last G, 2017, ADV APPL PROBAB, V49, P1260, DOI 10.1017/apr.2017.41
   Leng XX, 2016, PHOTOGRAMM REC, V31, P166, DOI 10.1111/phor.12145
   Liu M, 2016, ADV ENG INFORM, V30, P259, DOI 10.1016/j.aei.2016.04.005
   Liu S, 2014, PURE APPL GEOPHYS, V171, P1531, DOI 10.1007/s00024-013-0712-8
   Otero FEB, 2016, EVOL COMPUT, V24, P385, DOI 10.1162/EVCO_a_00155
   Pan G, 2016, SOFT COMPUT, V20, P555, DOI 10.1007/s00500-014-1522-3
   Saied A, 2016, NEUROCOMPUTING, V172, P385, DOI 10.1016/j.neucom.2015.04.101
   Shi EnXiu Shi EnXiu, 2014, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V45, P53
   Smith SD, 2014, J AM ASSOC LAB ANIM, V53, P700
   Sullivan A, 2016, INT J TECHNOL DES ED, V26, P3, DOI 10.1007/s10798-015-9304-5
   Tu Q, 2015, WATER RESOUR MANAG, V29, P2323, DOI 10.1007/s11269-015-0943-9
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Wang XY, 2016, INT ORTHOP, V40, P255, DOI 10.1007/s00264-015-2994-1
   Yuan G, 2017, ARTIF INTELL REV, V47, P123, DOI 10.1007/s10462-016-9477-7
   Zhang GH, 2016, RES J TEXT APPAR, V20, P24, DOI 10.1108/RJTA-09-2015-0027
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang R, 2016, RES J TEXT APPAR, V20, P37, DOI 10.1108/RJTA-08-2015-0022
NR 25
TC 25
Z9 29
U1 13
U2 91
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 42
EP 49
DI 10.1016/j.jvcir.2019.03.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100005
DA 2024-07-18
ER

PT J
AU Khosravi, MH
   Hassanpour, H
AF Khosravi, Mohammad Hossein
   Hassanpour, Hamid
TI Image quality assessment using a novel region smoothness measure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Full reference; Image region smoothness;
   Maximally stable extremal region; Percentile averaging
ID GRADIENT MAGNITUDE; SIMILARITY
AB One of the most efficient descriptions of image structure, which has been widely used in image quality assessment (IQA) studies, is the three-components model. Based on this model, the major structural components of an image are edges, textures and flat regions. We found that this model is basically derived from the abstract concept of image region smoothness. Indeed, each of these three components, is a particular region with special smoothness characteristics. Inspired by this fact, we developed an efficient general-purpose full-reference IQA technique, in which the amount of region smoothness degradation is gauged using our efficient WISER (maximally stable extremal region)-based region smoothness measure. For this, we build a block-based smoothness similarity map, and extract the image quality score, using a percentile averaging scheme. Experimental results are provided on popular benchmark databases, which confirm that the proposed approach has a reasonable prediction performance compared to the state-of-the-art image quality metrics. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Khosravi, Mohammad Hossein] Univ Birjand, Fac Elect & Comp Engn, Birjand, Iran.
   [Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn, Lab Image Proc & Data Min, Shahrood, Iran.
C3 University of Birjand; Shahrood University of Technology
RP Khosravi, MH (corresponding author), Univ Birjand, Fac Elect & Comp Engn, Birjand, Iran.
EM mohokhosravi@birjand.ac.ir
RI Khosravi, Mohammad Hossein/AAQ-9988-2021; Hassanpour,
   Hamid/AAL-7271-2020
OI Khosravi, Mohammad Hossein/0000-0003-3595-1829; Hassanpour,
   Hamid/0000-0002-5513-9822
CR [Anonymous], FIN REP VID QUAL EXP
   [Anonymous], J IMAGE GRAPH
   [Anonymous], 2011, THESIS
   [Anonymous], OBJECT RECOGNITION U
   [Anonymous], P COMP VIS WINT WORK
   [Anonymous], 2008, VLFEAT OPEN PORTABLE
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 2001, INTRO ALGORITHMS
   [Anonymous], 2017, INT J ENG T B APPL, DOI DOI 10.5829/IDOSI.IJE.2017.30.02B.00
   Ding L., 2017, IEEE T IMAGE PROCESS, VPP, P1, DOI [10.1109/11P.2017.2665972, DOI 10.1109/11P.2017.2665972]
   Donoser M., 2006, COMPUTER VISION PATT, V1, P553, DOI DOI 10.1109/CVPR.2006.107
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li JL, 2004, IEEE T FUZZY SYST, V12, P99, DOI 10.1109/TFUZZ.2003.822682
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Murphy-Chutorian E., 2006, BMVC, P739
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   RAN XN, 1995, IEEE T IMAGE PROCESS, V4, P401, DOI 10.1109/83.370671
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Sivic J, 2006, INT J COMPUT VISION, V67, P189, DOI 10.1007/s11263-005-4264-y
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang JF, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0134-5
   Zhan YB, 2017, IEEE T MULTIMEDIA, V19, P1837, DOI 10.1109/TMM.2017.2689923
   Zhang F, 2011, IEEE T MULTIMEDIA, V13, P615, DOI 10.1109/TMM.2011.2134079
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zhang Y, 2017, SIGNAL PROCESS-IMAGE, V55, P130, DOI 10.1016/j.image.2017.03.020
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 42
TC 5
Z9 6
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 217
EP 228
DI 10.1016/j.jvcir.2018.11.019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000024
DA 2024-07-18
ER

PT J
AU Kuo, CCJ
   Zhang, M
   Li, SY
   Duan, JL
   Chen, YR
AF Kuo, C-C. Jay
   Zhang, Min
   Li, Siyang
   Duan, Jiali
   Chen, Yueru
TI Interpretable convolutional neural networks via feedforward design
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interpretable machine learning; Convolutional neural networks; Principal
   component analysis; Linear least-squared regression; Cross entropy;
   Dimension reduction
AB The model parameters of convolutional neural networks (CNNs) are determined by backpropagation (BP). In this work, we propose an interpretable feedforward (FF) design without any BP. The FF design adopts a data-centric approach. It derives network parameters of the current layer based on data statistics from the output of the previous layer in a one-pass manner. To construct convolutional layers, we develop a new signal transform, called the Saab (Subspace approximation with adjusted bias) transform. It is a variant of the principal component analysis with an added bias vector to annihilate activation's nonlinearity. Multiple Saab transforms in cascade yield multiple convolutional layers. As to fully-connected layers, we construct them using a cascade of multi-stage linear least squared regressors. The classification and robustness performances of BP- and FF-designed CNNs applied to the MNIST and the CIFAR-10 datasets are compared. Finally, we comment on the relationship between BP and FF designs. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kuo, C-C. Jay; Zhang, Min; Li, Siyang; Duan, Jiali; Chen, Yueru] Univ Southern Calif, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Kuo, CCJ (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.
EM cckuo@sipi.usc.edu
RI Chen, Yueru/GWC-9924-2022; Zhang, Min/HPF-7130-2023; Zhang,
   Min/ADG-4442-2022; Kuo, C.-C. Jay/A-7110-2011
OI Zhang, Min/0000-0002-6940-7146; Kuo, C.-C. Jay/0000-0001-9474-5035; Li,
   Siyang/0000-0002-5991-649X
FU DARPA; Air Force Research Laboratory (AFRL) [FA8750-16-2-0173]
FX This material is partially based on research sponsored by DARPA and Air
   Force Research Laboratory (AFRL) under agreement number
   FA8750-16-2-0173. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purposes notwithstanding any
   copyright notation thereon. The views and conclusions contained herein
   are those of the authors and should not be interpreted as necessarily
   representing the official policies or endorsements, either expressed or
   implied, of DARPA and Air Force Research Laboratory (AFRL) or the U.S.
   Government. The authors would also like to give thanks to Dr. Pascal
   Frossard and Dr. Mauro Barni for their valuable comments to the draft of
   this work.
CR [Anonymous], ARXIV14126856
   [Anonymous], arXiv
   [Anonymous], ARXIV150905009
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Cameron A., 2013, Econometric Society Monographs, V53, DOI 10.1017/CBO9781139013567
   Chen Y., ARXIV190102154
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Dai J., ARXIV14126296
   Fan JQ, 2008, J ECONOMETRICS, V147, P186, DOI 10.1016/j.jeconom.2008.09.017
   Goodfellow I. J., 2015, INT C LEARN REPR
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo CCJ, 2018, J VIS COMMUN IMAGE R, V50, P237, DOI 10.1016/j.jvcir.2017.11.023
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Montavon G., ARXIV151202479
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Soltanolkotabi M., 2019, IEEE T INF THEORY
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sulam J., ARXIV170808705
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Szegedy C., arXiv
   Wang YL, 2018, PROC CVPR IEEE, P8906, DOI 10.1109/CVPR.2018.00928
   Wiatowski T., ARXIV151206293
   Xu H, 2018, APSIPA TRANS SIGNAL, V7, DOI 10.1017/ATSIP.2018.24
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Q., ARXIV171000935
NR 36
TC 80
Z9 84
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 346
EP 359
DI 10.1016/j.jvcir.2019.03.010
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000038
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, J
   Liu, C
   Fu, T
   Zheng, LL
AF Wang, Jia
   Liu, Chen
   Fu, Tian
   Zheng, Lili
TI Research on automatic target detection and recognition based on deep
   learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Target detection; Target recognition; In-depth
   learning
ID OBJECT DETECTION; ENHANCEMENT; CLASSIFIER; EXTRACTION
AB With the development of computer technology, the related achievements of image processing have been applied. Among them, the results of automatic target detection and recognition are widely used in the fields of reconnaissance, early warning and traffic control with the application of UAV. But now, the research of automatic target detection and tracking is becoming smaller and smaller. The original automatic target detection and recognition algorithm seems to be inadequate. The bottleneck of low-level feature design and optimization makes the accuracy and efficiency of automatic target detection inefficient. Therefore, based on in-depth learning, this paper establishes a method to automatically learn effective image features from images to achieve automatic target detection. Through the simulation of target detection in VEDAI database. The results show that the recognition rate of the proposed model is more than 95%. The results show that the proposed method can realize the automatic detection and recognition of targets very well. (C) 2019 Published by Elsevier Inc.
C1 [Wang, Jia] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Liu, Chen] Skyinfo Gen Aviat Beijing Technol Co Ltd, Beijing, Peoples R China.
   [Fu, Tian; Zheng, Lili] Beihang Univ, Inst Unmanned Syst, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Liu, C (corresponding author), Skyinfo Gen Aviat Beijing Technol Co Ltd, Beijing, Peoples R China.
EM liu513@vip.126.com
CR [Anonymous], IEEE T NEURAL NETW L
   [Anonymous], IEEE T SUSTAINABLE E
   Chen CLP, 2015, IEEE T FUZZY SYST, V23, P2163, DOI 10.1109/TFUZZ.2015.2406889
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Grady Mike, 2013, J Diabetes Sci Technol, V7, P970
   Greenberg S, 2000, OPT ENG, V39, P1369, DOI 10.1117/1.602511
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   JEWITT TW, 1990, P SOC PHOTO-OPT INS, V1305, P75, DOI 10.1117/12.2321788
   Jiang JL, 2015, NEUROCOMPUTING, V151, P817, DOI 10.1016/j.neucom.2014.10.017
   Kostakis J, 1999, P SOC PHOTO-OPT INS, V3718, P14, DOI 10.1117/12.359949
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Liu X, 2008, PATTERN RECOGN, V41, P484, DOI 10.1016/j.patcog.2007.06.004
   Pan XY, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4889-1
   [彭碧霞 PENG Bixia], 2006, [武汉大学学报. 工学版, Engineering journal of wuhan university. engineering edition], V39, P131
   Peng Bo, 2014, Journal of Highway and Transportation Research and Development (Chinese Edition), V31, P21, DOI 10.3969/j.issn.1002-0268.2014.05.004
   Qin Fu-tong, 2010, Computer Engineering and Applications, V46, P148, DOI 10.3778/j.issn.1002-8331.2010.05.045
   Silva-Saravia H., 2016, IEEE T POWER SYSTEMS, P1
   Sinha A, 2004, PROC SPIE, V5429, P95, DOI 10.1117/12.542903
   Tan W., 2016, MULTIMED TOOLS APPL, V75, P1
   Valova I, 2011, APPL INTELL, V35, P211, DOI 10.1007/s10489-010-0213-8
   Yamany SM, 1999, PATTERN RECOGN LETT, V20, P1431, DOI 10.1016/S0167-8655(99)00116-6
   Ying W, 2013, APPL MECH MATER, V415, P338, DOI 10.4028/www.scientific.net/AMM.415.338
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 36
TC 12
Z9 13
U1 4
U2 76
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 44
EP 50
DI 10.1016/j.jvcir.2019.01.017
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000006
DA 2024-07-18
ER

PT J
AU Basavaraju, S
   Gaj, S
   Sur, A
AF Basavaraju, Sathisha
   Gaj, Sibaji
   Sur, Arijit
TI Object Memorability Prediction using Deep Learning: Location and Size
   Bias
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object Memorability; Deep Learning; Transfer Learning
AB Object memorability prediction is a task of estimating the probability that a human recognises the recurrence of an object after a single view. Initial research on object memorability showed that it is possible to predict the object memorability scores from the intrinsic features of an object. Though the existing works proposed some of the features for object memorability prediction task, the influence of Spatial-location and Spatial-size of an object to its memorability have not been explored yet. In this work, the importance of these two characteristics in determining object memorability prediction is investigated and the same is demonstrated by building a baseline model. Further, a deep learning model is devised for automatic feature learning on these two object characteristics. Experimental results highlight that the Spatial-location and Spatial-size of an object play a significant role in object memorability prediction and the proposed models outperformed the existing methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Basavaraju, Sathisha; Gaj, Sibaji; Sur, Arijit] Indian Inst Technol Guwahati, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Basavaraju, S (corresponding author), Indian Inst Technol Guwahati, Gauhati, India.
EM b.sathisha@iitg.ac.in; sibaji@iitg.ac.in; arijit@iitg.ac.in
RI Sur, Arijit/AAB-4216-2020; Gaj, Sibaji/AAE-8920-2022
OI Gaj, Sibaji/0000-0002-6997-5717
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], IM PROC ICIP 2013 20
   [Anonymous], INTRINSIC EXTRINSIC
   [Anonymous], ADV NIPS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2014, CVPR
   [Anonymous], ARXIV161101714
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], NIPS
   [Anonymous], P 21 ACM INT C MULT
   Bainbridge WA, 2013, J EXP PSYCHOL GEN, V142, P1323, DOI 10.1037/a0033872
   Baveye Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P491, DOI 10.1145/2964284.2967269
   Berg AC, 2012, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2012.6248100
   Dubey R, 2015, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2015.130
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Khosla A., 2012, SIGGRAPH ASIA 2012 T
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
NR 20
TC 8
Z9 8
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 117
EP 127
DI 10.1016/j.jvcir.2019.01.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600012
DA 2024-07-18
ER

PT J
AU Ge, HQ
   Yu, HC
AF Ge, Hengqing
   Yu, Haichun
TI The application and design of neural computation in visual perception
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neural computing; Visual perception; Contour detection; Face recognition
ID OBJECT DETECTION; FREQUENCY; DEEP
AB Visual perception is an important way for organisms to perceive the external world. Simulation of visual cognitive process can enhance the cognitive ability of machine vision. Therefore, how to simulate visual perception system and make computer have a high world understanding ability is a hotspot of current neurocomputing. Based on the information processing mechanism of visual perception system, this paper establishes a neural computing model based on visual perception mechanism. The simulation results of standard face database and natural landscape images show that the proposed method can recognize face samples better when other noise samples are added to the face image samples. In landscape contour fitting simulation, the results show that although this method has little advantage for large contour image recognition, but for small contour recognition, this method is obviously superior to other methods. (C) 2019 Published by Elsevier Inc.
C1 [Ge, Hengqing; Yu, Haichun] Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223001, Peoples R China.
C3 Huaiyin Normal University
RP Yu, HC (corresponding author), Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223001, Peoples R China.
EM ghq@hytc.edu.cn; yhc@hytc.edu.cn
RI Ge, Hengqing/ITV-1524-2023
FU Industry-university-research prospective joint research project of
   Jiangsu Province [BY2016062-01]
FX This work was supported by Industry-university-research prospective
   joint research project of Jiangsu Province (BY2016062-01),
CR Bianconi G, 2016, PHYS REV E, V93, DOI 10.1103/PhysRevE.93.032315
   Cao H., 2015, LASER J
   Chacron MJ, 2003, NATURE, V423, P77, DOI 10.1038/nature01590
   Chen DW, 2016, NEURAL COMPUT APPL, V27, P1617, DOI 10.1007/s00521-015-1960-6
   Chen Y, 2011, IEEE T NEURAL NETWOR, V22, P880, DOI 10.1109/TNN.2011.2128880
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Du JG, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17040414
   Fleury L, 2016, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2016/01/004
   Grigorescu C, 2002, LECT NOTES COMPUT SC, V2525, P50
   Gruber O, 2001, CEREB CORTEX, V11, P350, DOI 10.1093/cercor/11.4.350
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hanakawa T, 2003, NEUROIMAGE, V19, P296, DOI 10.1016/S1053-8119(03)00050-8
   KAK S, 1995, INFORM SCIENCES, V83, P143, DOI 10.1016/0020-0255(94)00095-S
   Kolen, 2001, GRADIENT CALCULATION, DOI [10.1109/9780470544037.ch11, DOI 10.1109/9780470544037.CH11]
   Kucian Karin, 2006, Behav Brain Funct, V2, P31
   Lv Z., 2017, NEURAL COMPUT APPL, P1
   Mansouri I, 2018, NEURAL COMPUT APPL, V29, P873, DOI 10.1007/s00521-016-2492-4
   Maren A.J., 1990, HDB NEURAL COMPUTING, V18, P295
   PEARLMUTTER BA, 1995, IEEE T NEURAL NETWOR, V6, P1212, DOI 10.1109/72.410363
   Rodriguez Ricardo J., 2016, COMPUT J, V10
   Sudha M, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0823-3
   Triloka J, 2017, NEURAL COMPUT APPL, V28, pS65, DOI 10.1007/s00521-016-2312-x
   WEINSTEIN JN, 1992, SCIENCE, V258, P447, DOI 10.1126/science.1411538
   Yahya U, 2018, NEURAL COMPUT APPL, P1
   Zago L, 2001, NEUROIMAGE, V13, P314, DOI 10.1006/nimg.2000.0697
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 37
TC 3
Z9 3
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 309
EP 315
DI 10.1016/j.jvcir.2019.01.020
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600032
DA 2024-07-18
ER

PT J
AU Hu, WJ
   Ye, YQ
   Zeng, FL
   Meng, JH
AF Hu, Wenjin
   Ye, Yuqi
   Zeng, Fuliang
   Meng, Jiahao
TI A new method of Thangka image inpainting quality assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting quality assessment; Structural symmetry; Thangka image;
   Harris corner
AB In order to solve the problem of Thangka image inpainting quality assessment (IIQA) and existing quality evaluation methods are not suitable for inpainting Thangka image, this paper proposes a new non reference quality evaluation method which can effectively solve this problem. Firstly, due to lack of original Thangka image, the proposed method using symmetry of Thangka images to predicted an undamaged image. Secondly, we extract harries corner in Thangka inpainting images to show the structural feature of total graph. Thirdly, demonstrate subjective evaluation score of inpainting Thangka image by caparison difference of structural feature between in painting and predicted original area. Finally, in order to compensate the lack of Thangka images in existing database, we add Generative Adversarial Nets (GANs) to generate large number of available image. Experiments show that our proposed method generates a state-of-the-art index for Thangka image inpainting quality which correlated with human vision. (C) 2018 Published by Elsevier Inc.
C1 [Hu, Wenjin; Ye, Yuqi; Zeng, Fuliang; Meng, Jiahao] Northwest Minzu Univ, Sch Math & Comp Sci, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou 730000, Gansu, Peoples R China.
C3 Northwest Minzu University
RP Hu, WJ (corresponding author), Northwest Minzu Univ, Sch Math & Comp Sci, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou 730000, Gansu, Peoples R China.
EM wenjin_zhm@126.com
RI ye, yuqi/IVV-6836-2023
OI Meng, Jiahao/0000-0003-4350-3479; hu, wenjin/0000-0002-3120-5231
FU Nature Science Foundation of China [61561042, 61862057]; Fundamental
   Research Funds for the Central Universities [31920180117, 31920170143];
   special fund for talent introduction of northwestern nationalities
   university
FX This work was supported in part by The Nature Science Foundation of
   China under Grant No. 61561042 and No. 61862057, Fundamental Research
   Funds for the Central Universities (No. 31920180117, 31920170143) and by
   the special fund for talent introduction of northwestern nationalities
   university.
CR Ardis P.A., 2009, VISUAL COMMUN IMAGE, V7257, P1
   Ardis PA, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267088
   Chan T., 2013, INT C NAT COMPUT, V23, P1542
   Harris C., 1988, ALVEY VISION C, P147151
   Hojati M., 2014, INT J COMPUT APPL, V105, P1
   Jia Yanjun, 2015, THANGKA IMAGE INPAIN
   Le Philippe N, 2017, IEEE IMAGE PROC, P4347, DOI 10.1109/ICIP.2017.8297103
   Oncu AI, 2012, LECT NOTES COMPUT SC, V7583, P561, DOI 10.1007/978-3-642-33863-2_58
   Qiu N., 2005, ANAL TIBETAN THANGKA
   Qu L., 2015, J COMPUT INF SYST, V11, P185
   Qureshi MA, 2017, J VIS COMMUN IMAGE R, V49, P177, DOI 10.1016/j.jvcir.2017.09.006
   [沈为 Shen Wei], 2014, [上海大学学报. 自然科学版, Journal of Shanghai University. Natural Science Edition], V20, P715
   Venkatesh MV, 2010, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2010.5653640
   Wang S, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P786, DOI 10.1109/ICYCS.2008.461
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Jin, 2015, DIGITAL IMAGE INPAIN
NR 16
TC 9
Z9 10
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 292
EP 299
DI 10.1016/j.jvcir.2018.12.045
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600030
DA 2024-07-18
ER

PT J
AU Kong, YQ
   Huang, JH
   Huang, SS
   Wei, ZG
   Wang, SK
AF Kong, Yongqiang
   Huang, Jianhui
   Huang, Shanshan
   Wei, Zhengang
   Wang, Shengke
TI Learning spatiotemporal representations for human fall detection in
   surveillance video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fall detection; Human silhouette; Motion history image; Dynamic image;
   Convolutional Neural Networks; High-quality representation
ID DETECTION SYSTEM; NEURAL-NETWORK; RECOGNITION; TRACKING; CARE
AB In this paper, a computer vision based framework is proposed that detects falls from surveillance videos. Firstly, we employ background subtraction and rank pooling to model spatial and temporal representations in videos, respectively. We then introduce a novel three-stream Convolutional Neural Networks as an event classifier. Silhouettes and their motion history images serve as input to the first two streams, while dynamic images whose temporal duration is equal to motion history images, are used as input to the third stream. Finally, we apply voting on the results of event classification to perform multi camera fall detection. The main novelty of our method against the conventional ones is that high quality spatiotemporal representations in different levels are learned to take full advantage of the appearance and motion information. Extensive experiments have been conducted on two widely used fall data sets. The results have shown to demonstrate the effectiveness of the proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kong, Yongqiang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Huang, Jianhui] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
   [Huang, Shanshan; Wei, Zhengang; Wang, Shengke] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266100, Shandong, Peoples R China.
C3 Beihang University; Shandong University of Science & Technology; Ocean
   University of China
RP Kong, YQ (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM yqkong@buaa.edu.cn; wzgwzq@ouc.edu.cn; neverme@ouc.edu.cn
RI huang, shan/JVN-1240-2024
OI Kong, Yongqiang/0000-0001-6793-2492
FU National Natural Science Foundation of China [61379127, 61301241]; China
   Postdoctoral Science Foundation [2015M582140]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61379127 and 61301241) and in part by the China
   Postdoctoral Science Foundation under Grant No. 2015M582140.
CR Abbate S, 2012, PERVASIVE MOB COMPUT, V8, P883, DOI 10.1016/j.pmcj.2012.08.003
   Anderson Derek, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6388
   Anderson D, 2009, IEEE T FUZZY SYST, V17, P39, DOI 10.1109/TFUZZ.2008.2004498
   [Anonymous], IEEE T AUTOMAT SCI E
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2712608
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], PAC RIM C MULT
   [Anonymous], 1350 U MONTR DEP COM
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Baisa NL, 2018, J VIS COMMUN IMAGE R, V55, P464, DOI 10.1016/j.jvcir.2018.06.027
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan KB, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717707418
   Fan YX, 2017, NEUROCOMPUTING, V260, P43, DOI 10.1016/j.neucom.2017.02.082
   Feichtenhofer C., 2016, P INT C NEUR INF PRO, P3468
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gan WH, 2018, J VIS COMMUN IMAGE R, V53, P180, DOI 10.1016/j.jvcir.2018.03.016
   Gasparrini S, 2014, SENSORS-BASEL, V14, P2756, DOI 10.3390/s140202756
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Maldonado C, 2016, INT CONF ELECTR COMM, P94, DOI 10.1109/CONIELECOMP.2016.7438558
   Miaou SG, 2006, 1ST TRANSDISCIPLINARY CONFERENCE ON DISTRIBUTED DIAGNOSIS AND HOME HEALTHCARE, CONFERENCE PROCEEDINGS, P39, DOI 10.1109/DDHH.2006.1624792
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Pramerdorfer C, 2016, LECT NOTES COMPUT SC, V9914, P195, DOI 10.1007/978-3-319-48881-3_14
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Shibuya N, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORKING (ICMU), P66, DOI 10.1109/ICMU.2015.7061032
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Töreyin BU, 2005, LECT NOTES COMPUT SC, V3766, P211, DOI 10.1007/11573425_21
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, IEEE T CONSUM ELECTR, V60, P23, DOI 10.1109/TCE.2014.6780921
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Yu XG, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P42, DOI 10.1109/HEALTH.2008.4600107
   Yun YX, 2016, COMPUT VIS IMAGE UND, V148, P111, DOI 10.1016/j.cviu.2015.12.002
   Zhang C, 2017, J NETW COMPUT APPL, V89, P86, DOI 10.1016/j.jnca.2017.02.006
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 55
TC 41
Z9 42
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 215
EP 230
DI 10.1016/j.jvcir.2019.01.024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600023
DA 2024-07-18
ER

PT J
AU Shi, B
   Zang, HJ
   Zheng, RS
   Zhan, S
AF Shi, Biao
   Zang, Huaijuan
   Zheng, Rongsheng
   Zhan, Shu
TI An efficient 3D face recognition approach using Frenet feature of
   iso-geodesic curves
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial curves; Frenet framework; 3D face recognition; Iso-geodesic; Pose
   invariant
ID INVARIANT
AB Extracting efficient features from the large volume of 3D facial data directly is extremely difficult in 3D face recognition (3D-FR) with the latest methods, which mostly require heavy computations and manual processing steps. This paper presents a computationally efficient 3D-FR system based on a novel Frenet frame-based feature that is derived from the 3D facial iso-geodesic curves. In terms of the evaluation of the proposed method, we conducted a number of experiments on the CASIA 3D face database, and a superior recognition performance has been achieved. The performance evaluation suggests that the pose invariance attribute of the features relieves the need of an expensive 3D face registration in the face preprocessing procedure, where we take less time to process conversely. Our experiments further demonstrate that the proposed method not only achieves competitive recognition performance when compared with some existing techniques for 3D-FR, but also is computationally efficient. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Shi, Biao; Zang, Huaijuan; Zheng, Rongsheng; Zhan, Shu] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Zhan, S (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM shu_zhan@hfut.edu.cn
FU National Nature Science Foundation of China [61371156]
FX This work was supported by National Nature Science Foundation of China
   Grand No: 61371156. The authors would like to thank the anonymous
   reviews for their helpful and constructive comments and suggestions
   regarding this manuscript.
CR [Anonymous], BINARY PATTERN ANAL
   [Anonymous], P 2 IEEE INT WORKSH
   [Anonymous], 2006, CVPR '06
   Bowyer K. W., 2004, INT C PATT REC
   Canhui Cai, 2007, Signal, Image and Video Processing, V1, P53, DOI 10.1007/s11760-007-0006-7
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Chang  K.I, 2006, MULTIPLE NOSE REGION
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Emambakhsh M, 2017, IEEE T PATTERN ANAL, V39, P995, DOI 10.1109/TPAMI.2016.2565473
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Gao SS, 2010, IEEE T CIRC SYST VID, V20, P340, DOI 10.1109/TCSVT.2009.2035831
   Gilani S. Z., 2017, DEEP DENSE ACCURATE
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Koudelka M.L., 2005, 2005 IEEE COMP VIS P, P168
   Li L, 2008, PATTERN RECOGN LETT, V29, P1596, DOI 10.1016/j.patrec.2008.03.018
   Li  X., 2012, EFFICIENT 3D FACE RE, P350
   Li  Y., 2017, NEUROCOMPUTING
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Markus A. J. M. A., 2015, TIP, V25, P580
   Mayo  M., 2009, 3D FACE RECOGNITION
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Ocegueda O, 2013, IEEE T PATTERN ANAL, V35, P728, DOI 10.1109/TPAMI.2012.126
   Samir  C., 2006, 3 DIMENSIONAL FACE R
   Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Song ML, 2014, IEEE T IMAGE PROCESS, V23, P5108, DOI 10.1109/TIP.2014.2361204
   Sukno F.M., 2017, IEEE T CYBERNETICS, V45, P1717
   Tian J, 2009, SIGNAL IMAGE VIDEO P, V3, P217, DOI 10.1007/s11760-008-0078-z
   Tian J, 2010, J VIS COMMUN IMAGE R, V21, P232, DOI 10.1016/j.jvcir.2010.01.001
   Tian  Jing, 2011, SIGNAL IMAGE VIDEO P
   Wang C, 2015, J VIS COMMUN IMAGE R, V26, P255, DOI 10.1016/j.jvcir.2014.09.009
   Wang C, 2014, J VIS COMMUN IMAGE R, V25, P1416, DOI 10.1016/j.jvcir.2013.12.013
   Wang C, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2298973
   Wang XQ, 2010, INT CONF SIGN PROCES, P86, DOI 10.1109/ICOSP.2010.5656654
   Wang XW, 2010, SIGNAL IMAGE VIDEO P, V4, P39, DOI 10.1007/s11760-008-0093-0
   Wang Y. T., 2011, IEEE T IMAGE PROCESS
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Wei Z, 2012, IEEE T CIRC SYST VID, V22, P465, DOI 10.1109/TCSVT.2011.2168131
   Wu Z, 2008, SIGNAL IMAGE VIDEO P, V2, P225, DOI 10.1007/s11760-008-0052-9
   Yu X, 2017, PATTERN RECOGN, V65, P296, DOI 10.1016/j.patcog.2016.12.009
   Yu X, 2016, IEEE IMAGE PROC, P3016, DOI 10.1109/ICIP.2016.7532913
   Zeng H. Q., 2011, IEEE T CIRC SYST VID
   Zeng H. Q., 2010, IEEE T CIRC SYST VID
   Zeng H. Q., 2009, IEEE T CIRC SYST VID
   Zeng H. Q., 2014, IEEE T CIRC SYST VID
   Zhong BJ, 2010, IEEE T IMAGE PROCESS, V19, P2171, DOI 10.1109/TIP.2010.2046807
   Zhong BJ, 2009, IEEE T PATTERN ANAL, V31, P1517, DOI 10.1109/TPAMI.2008.295
   Zucker S, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P359
NR 51
TC 7
Z9 7
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 455
EP 460
DI 10.1016/j.jvcir.2019.02.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600049
DA 2024-07-18
ER

PT J
AU Xie, Z
   Wu, TF
   Yang, XM
   Zhang, LM
   Wu, KW
AF Xie, Zhao
   Wu, Tianfu
   Yang, Xingming
   Zhang, Luming
   Wu, Kewei
TI Jointly social grouping and identification in visual dynamics with
   causality-induced hierarchical Bayesian model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Group activity detection and recognition; Casual context; Granger casual
   topic model
ID LOW-RANK; REPRESENTATION; RECOGNITION
AB We concentrate on modeling the person-person interactions for group activity recognition. In order to solve the complexity and ambiguity problems caused by a large number of human objects, we propose a causality-induced hierarchical Bayesian model to tackle the interaction activity video, referring to the "what" interaction activities happen, "where" interaction atomic occurs in spatial, and "when" group interaction happens in temporal. In particular, Granger Causality has been characterized with multiple features to encode the interacting relationships between each individual in the group. Furthermore, to detect and identify the concurrent interactive simultaneously, we investigate the Relative Entropy as a metric to measure the reasonable motion dependency between two arbitrary individuals. Filtered by the causality dependency, causality motion features have been cast as the multiplicative probabilistic ingredients in Bayesian factors to formulate the compact learned latent interaction patterns aggregately that enable the power of discrimination. Experiments demonstrate our model outperforms state-of-the-art models. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xie, Zhao; Yang, Xingming; Wu, Kewei] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Xie, Zhao; Yang, Xingming; Wu, Kewei] Hefei Univ Technol, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
   [Wu, Tianfu] North Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27606 USA.
   [Zhang, Luming] Zhejiang Univ, Coll Comp Sci, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology; North
   Carolina State University; Zhejiang University
RP Xie, Z (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.; Xie, Z (corresponding author), Hefei Univ Technol, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
RI zhang, lu/GRO-2969-2022; Lei, Ming/JAD-1050-2023
OI Wu, Tianfu/0000-0001-8911-5506
FU National Key Research and Development Program of China [2017YFB1002203];
   National Nature Science Foundation of China [61503111, 61501467,
   61273273]; Anhui Natural Science Foundation [1808085MF168]
FX This research was supported by National Key Research and Development
   Program of China (2017YFB1002203), National Nature Science Foundation of
   China (61503111, 61501467, 61273273) and Anhui Natural Science
   Foundation (1808085MF168).
CR Aggarwal, 2010, IEEE International Conference on Pattern Recognition Workshops, P4
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], 2005, Advances in Neural Information Processing Systems
   [Anonymous], 2011, P BRIT MACH VIS C BM
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2009, IEEE C COMP VIS PATT
   Argyle M., 1994, The psychology of interpersonal behavior, V5th
   Ayazoglu M, 2013, IEEE I CONF COMP VIS, P3575, DOI 10.1109/ICCV.2013.444
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Chenxia Wu, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4362, DOI 10.1109/CVPR.2015.7299065
   Cho NG, 2017, NEUROCOMPUTING, V267, P169, DOI 10.1016/j.neucom.2017.06.009
   Choi W, 2014, IEEE T PATTERN ANAL, V36, P1242, DOI 10.1109/TPAMI.2013.220
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng Z, 2015, ARXIV150604191
   Feldmann M, 2011, IEEE T SIGNAL PROCES, V59, P1409, DOI 10.1109/TSP.2010.2101064
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Hajimirsadeghi H, 2015, PROC CVPR IEEE, P2596, DOI 10.1109/CVPR.2015.7298875
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hospedales T, 2012, INT J COMPUT VISION, V98, P303, DOI 10.1007/s11263-011-0510-7
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Knapp M.L., 2013, Cengage Learning
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090
   Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228
   Li RN, 2013, INT J COMPUT VISION, V101, P305, DOI 10.1007/s11263-012-0573-0
   Ni BB, 2009, PROC CVPR IEEE, P1470, DOI 10.1109/CVPRW.2009.5206853
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2017, IEEE T KNOWL DATA EN, V29, P1186, DOI 10.1109/TKDE.2017.2669982
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Pang SK, 2011, IEEE T AERO ELEC SYS, V47, P472, DOI 10.1109/TAES.2011.5705687
   Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342
   Richmond V., 1991, NONVERBAL BEHAV INTE
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Sener F, 2015, J VIS COMMUN IMAGE R, V32, P63, DOI 10.1016/j.jvcir.2015.07.016
   Setti F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123783
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Solera F, 2016, IEEE T PATTERN ANAL, V38, P995, DOI 10.1109/TPAMI.2015.2470658
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Vahdat A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1729, DOI 10.1109/ICCVW.2011.6130458
   Varadarajan J, 2013, INT J COMPUT VISION, V103, P100, DOI 10.1007/s11263-012-0596-6
   Wang HR, 2014, IEEE T IMAGE PROCESS, V23, P570, DOI 10.1109/TIP.2013.2292550
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang XY, 2015, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2015.7299071
   Was J, 2010, LECT NOTES ARTIF INT, V6114, P683, DOI 10.1007/978-3-642-13232-2_84
   Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
   Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51
   Zhang YM, 2013, IEEE T PATTERN ANAL, V35, P2468, DOI 10.1109/TPAMI.2013.33
   Zhou Y, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889686
NR 58
TC 15
Z9 15
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 62
EP 75
DI 10.1016/j.jvcir.2019.01.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600007
DA 2024-07-18
ER

PT J
AU Yuan, SY
   Hu, JB
AF Yuan, Shuyun
   Hu, Jianbo
TI Research on image compression technology based on Huffman coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compression; Wavelet transform; Huffman coding; JPEG picture
ID FEATURE-SELECTION
AB With the development of information technology, image has become the mainstream of information transmission. Compared with character, image contains more information, but because image and character need more storage capacity, it will occupy more bandwidth in network transmission. In order to transmit image information more quickly, image compression is a good choice. This paper is based on an eye of image compression. The method of image compression in this paper is that firstly, the image is filtered by wavelet transform to remove the redundant information in the image, and then the Huffman method is used to encode the image. The simulation results of JPEG format image show that the size of the image can be reduced in the same image effect. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yuan, Shuyun; Hu, Jianbo] Air Force Engn Univ, Equipment Management & UAV Engn Coll, Xian, Shaanxi, Peoples R China.
   [Yuan, Shuyun] Second Acad China Aerosp & Ind Corp, Inst 706, Beijing 100854, Peoples R China.
C3 Air Force Engineering University
RP Hu, JB (corresponding author), Air Force Engn Univ, Equipment Management & UAV Engn Coll, Xian, Shaanxi, Peoples R China.
EM 18s103149@stu.hit.edu.cn; jbhu@iipc.zju.edu.cn
FU National Key Basic Research Program [2014CB744900]; National Basic
   Research Program of Philosophy and Social Science [17GGL270]
FX This work was supported by the National Key Basic Research Program (No.
   2014CB744900) and National Basic Research Program of Philosophy and
   Social Science (No. 17GGL270).
CR Atlas L, 2000, INT CONF ACOUST SPEE, P3887, DOI 10.1109/ICASSP.2000.860252
   Barda JF, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P1126, DOI 10.1109/MMCS.1999.778678
   Criterion N., 2010, AEU-INT J ELECTRON C, V29, P251
   Engel S. J., 2002, P IEEE AEROSPACE C P, V6, P457
   GIBSON JD, 1980, P IEEE, V68, P488, DOI 10.1109/PROC.1980.11676
   Giurgiutiu V., 2001, P M SOC MACH FAIL PR
   Hao P., 2000, M ISO IEC JTC SC WG, V4115, P396
   Hardman W., 1999, 1999 IEEE Aerospace Conference. Proceedings (Cat. No.99TH8403), P473, DOI 10.1109/AERO.1999.793191
   Jack LB, 2000, IEE P-VIS IMAGE SIGN, V147, P205, DOI 10.1049/ip-vis:20000325
   Liu YM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P471, DOI 10.1109/ICPST.2002.1053587
   Polimac V, 2001, 2001 IEEE/PES TRANSMISSION AND DISTRIBUTION CONFERENCE AND EXPOSITION, VOLS 1 AND 2, P891, DOI 10.1109/TDC.2001.971357
   Shapiro Jerome M., 2002, IEEE T SIGNAL PROCES, V41, P124
   Smyth P. J., 1995, Hidden Markov Models for Fault Detection in Dynamic Systems: NASA STI/Recon Technical Report N, Patent No. [US 5465321 A, 546532]
   Staszewski WJ, 1998, J SOUND VIB, V211, P735, DOI 10.1006/jsvi.1997.1380
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   VILLASENOR JD, 1995, IEEE T IMAGE PROCESS, V4, P1053, DOI 10.1109/83.403412
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   WANG WJ, 1993, MECH SYST SIGNAL PR, V7, P193, DOI 10.1006/mssp.1993.1008
   ZHANG QH, 1993, PROCEEDINGS OF THE 32ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-4, P3688, DOI 10.1109/CDC.1993.325905
   Zhengya He, 1991, IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (Cat. No.91CH2954-6), P343, DOI 10.1109/PACRIM.1991.160749
NR 20
TC 29
Z9 29
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 33
EP 38
DI 10.1016/j.jvcir.2018.12.043
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600004
DA 2024-07-18
ER

PT J
AU Heydari, MJ
   Ghidary, SS
AF Heydari, Muhamad Javad
   Ghidary, Saeed Shiry
TI Cross-modal motion regeneration using Multimodal Deep Belief Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimodal deep learning; Multimodal Deep Belief Network; 2D/3D
   recovery; Cross-modal motion regeneration; Visual correspondence
AB In this paper, we propose a Multimodal Deep Belief Network (MDBN) for learning a generative model of 2D and 3D skeletal data. The MDBM learns the cross-modal relationship between these data in the form of a joint probability distribution over the space of multimodal inputs. It can regenerate any missing modality by sampling from the conditional distribution over the given data modality. The skeletal sequences are converted into the motion images which help us utilize the impressive power of the generative deep networks in the image processing. Furthermore, we use the variation of information (VI) as the training criterion, instead of the conventional maximum likelihood. It is proven that VI is efficient in cross-modal learning where some data modalities are missing. Our experimental results have shown that the model has an outstanding performance on the over-complete MHAD and CMU Mocap datasets in data-driven motion regeneration on a full-body 2D and 3D skeleton structures. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Heydari, Muhamad Javad] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Hafez Ave, Tehran, Iran.
   [Ghidary, Saeed Shiry] Amirkabir Univ Technol, Dept Math & Comp Sci, Hafez Ave, Tehran, Iran.
C3 Amirkabir University of Technology; Amirkabir University of Technology
RP Ghidary, SS (corresponding author), Amirkabir Univ Technol, Dept Math & Comp Sci, Hafez Ave, Tehran, Iran.
EM mj.heydari@aut.ac.ir; shiry@aut.ac.ir
RI ARSLAN, Okan/AAA-3232-2020; Ghidary, Saeed Shiry/AAH-7276-2021
OI Ghidary, Saeed Shiry/0000-0002-9019-3947; Heydari, Muhammad
   Javad/0000-0003-3300-174X
FU Cognitive Science and Technology Council of Iran (CSTC)
FX This work was supported by Cognitive Science and Technology Council of
   Iran (CSTC).
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Allen BF, 2009, LECT NOTES COMPUT SC, V5884, P219, DOI 10.1007/978-3-642-10347-6_20
   [Anonymous], 2005, AISTATS BRIDGETOWN B
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2014, Advances in neural information processing systems
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], 2017, P ACM SIGGRAPH EUR S
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], 2017, C COMP VIS PATT REC
   [Anonymous], 2017, Computer Vision and Pattern Recognition, 2017 IEEE Computer Society Conference on
   BaltruKaitis T., 2018, IEEE T PATTERN ANAL
   Barratt Shane, 2018, ARXIV180101973
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   CMU, 2013, CARN MELL U GRAPH LA
   Cover T. M., 2012, ELEMENTS INFORM THEO
   DERRICK TR, 1994, MED SCI SPORT EXER, V26, P919
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   GAYEN AK, 1951, BIOMETRIKA, V38, P219, DOI 10.2307/2332329
   Hess P., 2005, STYLE BASED INVERSE
   Holden D., 2015, P SIGGRAPH AS TECH B, DOI DOI 10.1145/2820903.2820918
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Huang M, 2018, NEUROCOMPUTING, V291, P84, DOI 10.1016/j.neucom.2018.02.056
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Iqbal U., 2018, COMPUT VIS IMAGE UND
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jie Tan, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2801121
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Laraba S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1782
   Lei P, 2016, INT C PATT RECOG, P1845, DOI 10.1109/ICPR.2016.7899905
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Li B., 2018, Master's Degree Thesis., P1
   Li Zimo, 2017, ARXIV170705363
   Lin Xiao, 2018, ARXIV180410652
   Luvizon D.C., 2018, IEEE C COMP VIS PATT, V2
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Meila M, 2003, LECT NOTES ARTIF INT, V2777, P173, DOI 10.1007/978-3-540-45167-9_14
   Merel J., 2017, Learning human behaviors from motion capture by adversarial imitation
   Mittelman R, 2014, PR MACH LEARN RES, V32, P1647
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pham H. H., 2018, COMPUT VIS IMAGE UND
   Saggese A., 2018, PATTERN RECOGN LETT
   Sanzari M, 2016, LECT NOTES COMPUT SC, V9912, P566, DOI 10.1007/978-3-319-46484-8_34
   Taylor G, 2009, P 26 ANN INT C MACH
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Upadhya V., 2017, ARXIV170907149
   Villegas R, 2018, PROC CVPR IEEE, P8639, DOI 10.1109/CVPR.2018.00901
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yasin H., 2013, P INT C VIS COMP GRA, P1
   Ye YT, 2010, COMPUT GRAPH FORUM, V29, P555, DOI 10.1111/j.1467-8659.2009.01625.x
   Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097
   Zhou Y, 2016, PATTERN RECOGN LETT, V83, P261, DOI 10.1016/j.patrec.2016.07.025
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
NR 65
TC 1
Z9 1
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 245
EP 260
DI 10.1016/j.jvcir.2018.11.042
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100025
DA 2024-07-18
ER

PT J
AU Shan, PF
   Lai, XP
AF Shan Pengfei
   Lai Xingping
TI Mesoscopic structure PFC∼2D model of soil rock mixture based on digital
   image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Soil rock mixture; PFC similar to 2D model; Particle flow simulation;
   Meso mechanical properties
ID EARTH
AB Soil-rock mixture (S/RM) is a very complex discontinuous medium material, which is a multiphase system consisting of high strength rock blocks (Rocks), relatively soft filling components (Soils) and corresponding pores. Because the mechanical properties of various components of soil-rock mixtures under external loads are very different, and there are extremely complex interactions between them. Therefore, the mechanical properties of this geotechnical material (such as stress transfer, failure mode, crack propagation, bearing capacity, etc.) are quite different from those of homogeneous geotechnical materials, and largely depend on the internal structure characteristics of soil-rock mixtures (such as particle size composition, particle shape, particle distribution and arrangement). Due to the complexity of the model, the simulation of its meso-mechanical properties is mostly confined to the random simulation of regular blocks. In this paper, an automatic generation method of PFC similar to 2D numerical model of soil-rock mixture microstructure based on digital image processing is proposed, and the experimental simulation is carried out with matlab. Thus, the rapid, real and automatic modeling of heterogeneous material microstructure by PFC similar to 2D software is realized. The PFC similar to 2D numerical calculation model of soil-rock mixtures is established. The results show that when the stone content is 80%, the analysis should be caused by the large amount of rock, which leads to the large internal voids, and the sudden unloading between the rock and the rock during compaction and then the structural reorganization. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Shan Pengfei; Lai Xingping] Xian Univ Sci & Technol, Sch Energy Engn, Xian 710054, Shaanxi, Peoples R China.
C3 Xi'an University of Science & Technology
RP Shan, PF (corresponding author), Xian Univ Sci & Technol, Sch Energy Engn, Xian 710054, Shaanxi, Peoples R China.
EM shanpengfei@xust.edu.cn; laixp@xust.edu.cn
FU 973 Key National Basic Research Program of China [2015CB251602]; China
   Postdoctoral Science Foundation [2017M623328XB]; science and technology
   innovation team project of Shaanxi Province [2018TD-038]; Natural
   Science Foundation of Shaanxi Province [2018JQ5194]; Hunan Province
   Engineering Research Center of Radioactive Control Technology in Uranium
   Mining and Metallurgy & Hunan Province Engineering Technology Research
   Center of Uranium Tailings Treatment Technology [2018YKZX2001]
FX Financial support for this work was provided by the 973 Key National
   Basic Research Program of China (no. 2015CB251602), the China
   Postdoctoral Science Foundation (no. 2017M623328XB), the science and
   technology innovation team project of Shaanxi Province (no. 2018TD-038),
   and the Natural Science Foundation of Shaanxi Province (no. 2018JQ5194),
   the Hunan Province Engineering Research Center of Radioactive Control
   Technology in Uranium Mining and Metallurgy & Hunan Province Engineering
   Technology Research Center of Uranium Tailings Treatment Technology (no.
   2018YKZX2001). Support from these agencies is gratefully acknowledged.
CR Almansa C, 2015, AQUACULT ENG, V69, P78, DOI 10.1016/j.aquaeng.2015.10.003
   Aurnou JM, 2015, PHYS EARTH PLANET IN, V246, P52, DOI 10.1016/j.pepi.2015.07.001
   Benedek Judit, 2017, J GEODESY, V2, P1
   Davidson R., 2016, PAC COAST GEOGR, V78, P279
   Govers Y, 2015, MECH SYST SIGNAL PR, V52-53, P105, DOI 10.1016/j.ymssp.2014.06.003
   Hu T., 2017, J CHINESE URBAN FORE
   Huilian M. A., 2017, J TAIYUAN NORMAL U
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Li XX, 2015, ONCOTARGET, V6, P18829, DOI 10.18632/oncotarget.4774
   Liao Q., 2016, CHINESE J NEUROSURG
   Liu ZP, 2014, ROCK SOIL MECH, V35, P2594
   Meng-Yi L. I., 2017, J N CHINA I SCI TECH
   Michaelis S., 2015, LASER SCANNER DEVICE
   Nassar JM, 2016, EXTREME MECH LETT, V9, P245, DOI 10.1016/j.eml.2016.04.011
   Nelms B, 2015, MED PHYS, V42, P4435, DOI 10.1118/1.4923175
   Noterdaeme P., 2015, A A, P577
   Papathoma-Köhle M, 2015, ENVIRON MODELL SOFTW, V63, P156, DOI 10.1016/j.envsoft.2014.10.003
   Perry G. L. W., 2016, OIKOS, V126
   Qiu S., 2017, J GREEN SCI TECHNOL
   Said AI, 2015, J PHOTOCH PHOTOBIO A, V311, P16, DOI 10.1016/j.jphotochem.2015.05.035
   Tu D., 2018, RSC ADV, P8
   Vishal V., 2018, TRANSPORT POROUS MED, P1
   Wang B, 2015, SOIL SCI SOC AM J, V79, P1213, DOI 10.2136/sssaj2015.03.0120
   Xu WJ, 2015, J CENT SOUTH UNIV, V22, P619, DOI 10.1007/s11771-015-2563-1
   Yoon S, 2014, MATER CHEM PHYS, V145, P376, DOI 10.1016/j.matchemphys.2014.02.026
   Zhang N, 2016, J MECH PHYS SOLIDS, V96, P204, DOI 10.1016/j.jmps.2016.07.021
   Zhang WP, 2017, SAUDI J BIOL SCI, V24, P563, DOI 10.1016/j.sjbs.2017.01.027
   Zhou Z, 2014, J GEOPHYS RES-EARTH, V119, P892, DOI 10.1002/2014JF003092
NR 28
TC 64
Z9 66
U1 15
U2 186
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 407
EP 415
DI 10.1016/j.jvcir.2018.12.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100040
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Zeng, JC
   Dong, WS
   Shi, GM
   Lin, WS
AF Wu, Jinjian
   Zeng, Jichen
   Dong, Weisheng
   Shi, Guangming
   Lin, Weisi
TI Blind image quality assessment with hierarchy: Degradation from local
   structure to deep semantics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image quality assessment; Hierarchical feature degradation; Local
   structure; Deep semantics
ID SELECTIVITY; INFORMATION; ARTIFACTS
AB Though blind image quality assessment (BIQA) is highly desired in perceptual-oriented image processing systems, it is extremely difficult to design a reliable BIQA method. With the help of the prior knowledge, the human visual system (HVS) hierarchically perceives the quality degradation during the visual recognition. Inspired by this, we suggest different levels of distortion generate individual degradations on hierarchical features, and propose to consider the degradations on both low and high level features for quality prediction. By mimicking the orientation selectivity (OS) mechanism in the primary visual cortex, an OS based local structure is designed for low-level visual information representation. At the meantime, the deep residual network, which possesses multiple levels for feature integration, is employed to extract the deep semantics for high-level visual content representation. By fusing the local structure and the deep semantics, a hierarchical feature set is acquired. Next, the correlations between the degradations of image qualities and their corresponding hierarchical feature sets are analyzed, and a novel hierarchical feature degradation (HFD) based BIQA (HFD-BIQA) method is built. Experimental results on the legacy and wild image quality assessment databases demonstrate the prediction accuracy of the proposed HFD-BIQA method, and verify that the HFD-BIQA performs highly consistent with the subjective perception. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wu, Jinjian; Zeng, Jichen; Dong, Weisheng; Shi, Guangming] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Xidian University; Nanyang Technological University
RP Wu, JJ (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
EM jinjian.wu@mail.xidian.edu.cn
RI Lin, Weisi/A-8011-2012; Wu, Jinjian/GQH-0222-2022; Lin,
   Weisi/A-3696-2011
OI Lin, Weisi/0000-0001-9866-1947
FU Ministry of Education [6141A020336]; NSF of China [61772388, 61632019,
   61621005, 61472301]; Young Star Science and Technology Project in Shanxi
   province [2018KJXX-030]
FX This work was partially supported by the Joint fund of the Ministry of
   Education (6141A020336), the NSF of China (Nos. 61772388, 61632019,
   61621005, 61472301), the Young Star Science and Technology Project (No.
   2018KJXX-030) in Shanxi province.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   BENYISHAI R, 1995, P NATL ACAD SCI USA, V92, P3844, DOI 10.1073/pnas.92.9.3844
   Cardin JA, 2007, J NEUROSCI, V27, P10333, DOI 10.1523/JNEUROSCI.1692-07.2007
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Gao F, 2015, IEEE T NEUR NET LEAR, V26, P2275, DOI 10.1109/TNNLS.2014.2377181
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Larson E.C., 2004, CATEGORICAL IMAGE QU
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li J, 2016, SIGNAL IMAGE VIDEO P, V10, P609, DOI 10.1007/s11760-015-0784-2
   Li LD, 2016, J VIS COMMUN IMAGE R, V38, P550, DOI 10.1016/j.jvcir.2016.04.006
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ni ZK, 2016, IEEE SIGNAL PROC LET, V23, P1394, DOI 10.1109/LSP.2016.2599294
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan F, 2004, SIGNAL PROCESS-IMAGE, V19, P499, DOI 10.1016/j.image.2004.04.001
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh H. R., 2006, Image and video quality assessment research at LIVE
   Sheskin David, 2011, Handbook of Parametric and Nonparametric Statistical Procedures
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Troyer TW, 1998, J NEUROSCI, V18, P5908
   Ungerleider Leslie G., 1994, Current Opinion in Neurobiology, V4, P157, DOI 10.1016/0959-4388(94)90066-3
   Wang SQ, 2018, IEEE COMPUT GRAPH, V38, P47, DOI 10.1109/MCG.2016.46
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2015, IEEE T IMAGE PROCESS, V24, P4602, DOI 10.1109/TIP.2015.2460467
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Xie XM, 2017, NEUROCOMPUTING, V266, P176, DOI 10.1016/j.neucom.2017.05.034
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
NR 49
TC 21
Z9 23
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 353
EP 362
DI 10.1016/j.jvcir.2018.12.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100035
DA 2024-07-18
ER

PT J
AU Xiong, F
   Chen, DY
   Chen, ZH
   Dai, SM
AF Xiong, Fan
   Chen, Dongyi
   Chen, Zhenghao
   Dai, Shumei
TI Cancellation of motion artifacts in ambulatory ECG signals using TD-LMS
   adaptive filtering techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive cancellation algorithm; Motion artifacts; Auxiliary dry
   electrode; Cosine transform
ID ELECTRODE
AB Wearable electrocardiogram (ECG) measurement systems have been widely used in patients with CVD (Cardiovascular Disease) which can be worn in daily lives. However, currently the main problem is motion artifact interference, and reducing motion artifacts (MA) is one of the most challenging problems encountered in the filtering and processing of physiological signals. In this paper, by analyzing the spectral energy changes during the input process of motion artifacts, a cosine transform LMS adaptive cancellation algorithm (DCT-LMS) implementation is proposed aiming to remove the motion artifacts from the ECG. In order to study the performance of the algorithm and effectively remove the motion artifacts in the ECG signal, this thesis collects ECG signals of people's daily activities from fabric-based chest straps with dry electrodes. It verifies the classic LMS adaptive elimination algorithm and the normalized one. Besides, two LMS adaptive cancellation algorithms based on sine and cosine transform are compared. The simulation and experimental results show that the cosine-based adaptive algorithm is superior to the classical LMS algorithm in eliminating high-amplitude motion artifact noise of ECG. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Xiong, Fan; Chen, Dongyi; Chen, Zhenghao; Dai, Shumei] Univ Elect Sci & Technol China, Sch Automat Engn, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Chen, DY (corresponding author), Univ Elect Sci & Technol China, Sch Automat Engn, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
EM xiongfan2010@qq.com; dychen@uestc.edu.cn; chenzhenghao_tust@163.com;
   dai_shumei@163.com
RI 熊, 帆/GZL-4336-2022
OI 熊, 帆/0000-0003-3802-7068
FU National Natural Science Foundation of China [61572110]; National Key
   Research & Development Plan of China [2016YFB1001401]
FX This work is supported by National Natural Science Foundation of China
   (no. 61572110) and National Key Research & Development Plan of China
   (no. 2016YFB1001401).
CR Acar B, 1999, IEEE T BIO-MED ENG, V46, P311, DOI 10.1109/10.748984
   Alkhidir T, 2015, IEEE ENG MED BIO, P3807, DOI 10.1109/EMBC.2015.7319223
   Banerjee S., 2008, MEASUREMENT, P474
   BEAUFAYS F, 1995, IEEE T SIGNAL PROCES, V43, P422, DOI 10.1109/78.348125
   Cömert A, 2015, PHYSIOL MEAS, V36, P1, DOI 10.1088/0967-3334/36/1/1
   Farhang-Boroujeny B., 2013, Adaptive Filters: Theory and Applications.
   Fortino G, 2013, IEEE T HUM-MACH SYST, V43, P115, DOI 10.1109/TSMCC.2012.2215852
   Geng Y., 2008, INFORM ELECT ENG, V6, P315
   Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005
   Griffiths A., 2007, J PHYS C SERIES
   Kalra A, 2016, J BIOSENS BIOELECTRO, V7, P1000204
   Kher Rahul, 2013, Journal of Medical Engineering & Technology, V37, P56, DOI 10.3109/03091902.2012.728676
   Kim H, 2014, IEEE T BIOMED CIRC S, V8, P257, DOI 10.1109/TBCAS.2013.2260159
   Ko Byung-hoon, 2012, 34 ANN INT C IEEE EM
   Kwon H, 2013, PROC SPIE, V8691, DOI 10.1117/12.2009681
   Lee JW, 2017, POLYMERS-BASEL, V9, DOI 10.3390/polym9090439
   Liu Yan, 2011, Biomed Instrum Technol, V45, P155, DOI 10.2345/0899-8205-45.2.155
   Milanesi M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3391
   Milanesi M, 2008, MED BIOL ENG COMPUT, V46, P251, DOI 10.1007/s11517-007-0293-8
   Niederhauser T, 2016, IEEE T BIOMED CIRC S, V10, P255, DOI 10.1109/TBCAS.2015.2395997
   Ottenbacher J, 2008, IEEE ENG MED BIO, P1695, DOI 10.1109/IEMBS.2008.4649502
   TAM HW, 1977, IEEE T BIO-MED ENG, V24, P134, DOI 10.1109/TBME.1977.326117
   THAKOR NV, 1991, IEEE T BIO-MED ENG, V38, P785, DOI 10.1109/10.83591
   Tu YW, 2012, ANN BIOMED ENG, V40, P1917, DOI 10.1007/s10439-012-0551-2
   van Helleputte N., IEEE T BIOMED CIRC S
   Weder M, 2015, SENSORS-BASEL, V15, P1750, DOI 10.3390/s150101750
   Widrow B., 1975, P IEEE, V63
   Wu S, 2013, MED INNOVATION CHINA, V10, P1, DOI DOI 10.1118/1.4829496
   Xu JW, 2011, IEEE T BIOMED CIRC S, V5, P555, DOI 10.1109/TBCAS.2011.2170985
   Xul Peng-Jun, 2016, C C 9 TEXT BIOENG IN, V1
   Yoon SW, 2008, J MED SYST, V32, P101, DOI 10.1007/s10916-007-9112-x
NR 31
TC 17
Z9 18
U1 4
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 606
EP 618
DI 10.1016/j.jvcir.2018.12.030
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100059
DA 2024-07-18
ER

PT J
AU Zhang, JH
   Lu, W
   Yin, XL
   Liu, WT
   Yeung, YLO
AF Zhang, Junhong
   Lu, Wei
   Yin, Xiaolin
   Liu, Wanteng
   Yeung, Yuileong
TI Binary image steganography based on joint distortion measurement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binary image steganography; Distortion measurement; Local texture
   pattern
ID AUTHENTICATION
AB Most state-of-the-art binary image steganography methods depend on the content of the image to determine where to embed secret messages, which is capacity-limited and indicates that their distortion measurement may be not precise enough. In this paper, we propose a kind of distortion measurement that is not only based on the discrimination effects after flipping the pixels but also depends on the visual effects of flipping corresponding pixels, which is called joint distortion measurement. Instead of selecting suitable position to embed secret messages, we then employ the syndrome-trellis code to minimize the embedding distortion and get messages embedded. And experimental results have demonstrated that the proposed distortion measurement has higher performance and the steganography scheme can achieve stronger statistical security with high capacity and image quality. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Junhong; Lu, Wei; Yin, Xiaolin; Liu, Wanteng; Yeung, Yuileong] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM zhangjh65@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   cyinxl6@mail2.sysu.edu.cn; liuwt25@mail2.sysu.edu.cn;
   yeungyl@mail2.sysu.edu.cn
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; National Key
   R&D Program of China [2017YFB0802500]; Natural Science Foundation of
   Guangdong [2016A030313350]; Special Funds for Science and Technology
   Development of Guangdong [2016KZ010103]; Key Project of Scientific
   Research Plan of Guangzhou [201804020068]; Fundamental Research Funds
   for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the National Key R&D Program of China (No.
   2017YFB0802500), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Chen J., J VISUAL COMMUN IMAG
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Cheng J, 2007, IEEE T IMAGE PROCESS, V16, P1691, DOI 10.1109/TIP.2007.896619
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P683, DOI 10.1109/ARES.2010.65
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P653, DOI 10.1109/ARES.2010.66
   Feng B., 2013, INT WORKSH DIG WAT, P514
   Feng B., 2014, P INT WORKSH DIG WAT, P574
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Mei Q, 2001, PROC SPIE, V4314, P369, DOI 10.1117/12.435420
   Meng Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1441, DOI 10.1109/ICPR.2010.356
   Theodoridis S., 2008, IEEE Transactions on Neural Networks, V19, P376, DOI DOI 10.1109/TNN.2008.929642
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Yang HJ, 2008, IEEE T MULTIMEDIA, V10, P339, DOI 10.1109/TMM.2008.917404
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
NR 22
TC 18
Z9 20
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 600
EP 605
DI 10.1016/j.jvcir.2018.12.038
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100058
DA 2024-07-18
ER

PT J
AU Mahmoudpour, S
   Schelkens, P
AF Mahmoudpour, Saeed
   Schelkens, Peter
TI Reduced-reference quality assessment of multiply-distorted images based
   on structural and uncertainty information degradation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality; Multiply-distortion types; Shearlet transform; Entropy
   analysis; Support vector regression; Privileged information
ID FREE-ENERGY PRINCIPLE; PRIVILEGED INFORMATION; BRAIN
AB The majority of existing objective Image Quality Assessment (IQA) methods are designed for evaluation of images corrupted by single distortion types. However, images may be degraded with multiple distortions during processing stages. In this paper, we propose a reduced-reference IQA algorithm to predict the quality of multiply-distorted images. An image is first decomposed into predicted and disorderly portions based on the internal generative mechanism theory. The structural information is captured from the predicted image by using a shearlet representation and Renyi directional entropy is deployed to measure the disorderly information changes. Finally, we introduce the application of a framework namely Learning Using Privileged Information (LUPI) to build a quality model and obtain quality scores. During training, the LUPI framework utilizes a set of additional privileged data to learn an improved quality model. Experimental results on multiply-distorted image datasets (MLIVE and MDID2015) confirm the effectiveness of the proposed IQA model. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Mahmoudpour, Saeed; Schelkens, Peter] Vrije Univ Brussel, Dept Elect & Informat, Pl Laan 2, B-1050 Brussels, Belgium.
   [Mahmoudpour, Saeed; Schelkens, Peter] Imec, Kapeldreef 75, B-3001 Leuven, Belgium.
C3 Vrije Universiteit Brussel; IMEC
RP Mahmoudpour, S (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, Pl Laan 2, B-1050 Brussels, Belgium.
EM smahmoud@etrovub.be; Peter.Schelkens@vub.be
RI ; Schelkens, Peter/B-7831-2008
OI Mahmoudpour, Saeed/0000-0003-1006-1838; Schelkens,
   Peter/0000-0003-0908-1655
FU European Research Council under the European Union [617779]; Horizon
   2020 Research and Innovation Programme [N688619]; European Research
   Council (ERC) [617779] Funding Source: European Research Council (ERC)
FX The research leading to these results has received funding from the
   European Research Council under the European Unions Seventh Framework
   Programme (FP7/2007-2013)/ERC Grant Agreement Nr. 617779 (INTERFERE) and
   Horizon 2020 Research and Innovation Programme under Grant Agreement
   N688619 (ImmersiaTV).
CR [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 2004, HDB PARAMETRIC NONPA
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P372
   Ding Y, 2017, SIGNAL PROCESS-IMAGE, V54, P81, DOI 10.1016/j.image.2017.03.001
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Friston KJ, 2006, J PHYSIOL-PARIS, V100, P70, DOI 10.1016/j.jphysparis.2006.10.001
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Fu J, 2016, INT CONF ACOUST SPEE, P1075, DOI 10.1109/ICASSP.2016.7471841
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kakadiaris IA, 2016, IEEE IMAGE PROC, P3156, DOI 10.1109/ICIP.2016.7532941
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Kutyniok G, 2012, APPL NUMER HARMON AN, P239, DOI 10.1007/978-0-8176-8316-0_7
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mahmoudpour S, 2016, SIGNAL IMAGE VIDEO P, V10, P1465, DOI 10.1007/s11760-016-0957-7
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Sarafianos N., 2017, P INT C PATT REC, P3115
   Sheikh H. R., IMAGE VIDEO QUALITY
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Wakin M., 2011, SPARSE IMAGE SIGNAL, V28
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
   Wu JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P16, DOI 10.1016/j.image.2016.05.008
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang H, 2015, IEEE T CIRC SYST VID, V25, P1507, DOI 10.1109/TCSVT.2015.2389492
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zhang Y, 2017, SIGNAL PROCESS-IMAGE, V55, P130, DOI 10.1016/j.image.2017.03.020
NR 55
TC 2
Z9 2
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 125
EP 137
DI 10.1016/j.jvcir.2018.10.027
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400016
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, QX
   Yang, HX
   Yu, YH
AF Wang, Qingxiang
   Yang, Huanxin
   Yu, Yanhong
TI Facial expression video analysis for depression detection in Chinese
   patients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depression detection; Facial expression; Video processing; Eye movement;
   Feature extraction
AB Emotional state analysis of facial expression is an important research content of emotion recognition. At the same time, in the medical field, the auxiliary early screening tools for depression are also urgently needed by clinics. Whether there are differences in facial expression changes between depressive patients and normal people in the same situation, and whether the characteristics can be obtained and recognized from the video images of depressive patients, so as to help doctors detect and diagnose potential depressive patients early are the contents of this study. In this paper, we introduce the videos collection process of depression patients and control group at Shandong Mental Health Center in China. The key facial features are extracted from the collected facial videos by person specific active appearance model. On the basis of locating facial features, we classified depression with the movement changes of eyes, eyebrows and corners of mouth by support vector machine. The results show that these features are effective for automatic classification of depression patients. (C) 2018 Published by Elsevier Inc.
C1 [Wang, Qingxiang] Qilu Univ Technol, Shandong Acad Sci, Coll Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Yang, Huanxin] Qilu Univ Technol, Shandong Acad Sci, Coll Bioengn, Jinan, Shandong, Peoples R China.
   [Yu, Yanhong] Shandong Univ Tradit Chinese Med, Coll Tradit Chinese Med, Jinan, Shandong, Peoples R China.
C3 Qilu University of Technology; Qilu University of Technology; Shandong
   University of Traditional Chinese Medicine
RP Wang, QX (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Coll Comp Sci & Technol, Jinan, Shandong, Peoples R China.; Yu, YH (corresponding author), Shandong Univ Tradit Chinese Med, Coll Tradit Chinese Med, Jinan, Shandong, Peoples R China.
EM wangqx@qlu.edu.cn; yhysdutcm@sdutcm.edu.cn
RI lan, lan/JWO-3679-2024; LU, CX/KFB-9510-2024; Yu, Yan/GYV-4514-2022
FU Shandong Provincial Natural Science Foundation, China [ZR2016FM14];
   National Natural Science Foundation of China [81573829, 81703941]
FX This work was supported by the Shandong Provincial Natural Science
   Foundation, China (Grant: ZR2016FM14), the National Natural Science
   Foundation of China (Grant: 81573829, 81703941)
CR Alghowinem S, 2013, IEEE IMAGE PROC, P4220, DOI 10.1109/ICIP.2013.6738869
   Alghowinem S, 2013, INT CONF AFFECT, P283, DOI 10.1109/ACII.2013.53
   [Anonymous], 2013, Major Depressive Disorder. Diagnostic and Statistical Manual of Mental Disorders, VFifth, P160, DOI DOI 10.1176/APPI.BOOKS.9780890425596.DSM04
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], P 2 INT C AUD VID BI
   [Anonymous], ACII 09
   [Anonymous], 2013, Panchvalkala: A Monograph, Experimental & Clinical Studies on the Use of Modified Panchavalkal (An Ayurvedic Formulation) in Leucorrhoea, DOI DOI 10.1109/FG.2013.6553796
   [Anonymous], 2016, J AMBIENT INTELL HUM, DOI [DOI 10.1007/S12652-016-0395-Y#CITEAS, 10.1007/s12652-016-0395-y#citeas, DOI 10.1007/810878-015-9987-2]
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Cepoiu M, 2008, J GEN INTERN MED, V23, P25, DOI 10.1007/s11606-007-0428-5
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dhall A, 2015, INT CONF AFFECT, P255, DOI 10.1109/ACII.2015.7344580
   Dibeklioglu H, 2018, IEEE J BIOMED HEALTH, V22, P525, DOI 10.1109/JBHI.2017.2676878
   Ekman Paul., 1972, UNIVERSALS CULTURAL, V19
   Girard JM, 2015, CURR OPIN PSYCHOL, V4, P75, DOI 10.1016/j.copsyc.2014.12.010
   Girard JM, 2014, IMAGE VISION COMPUT, V32, P641, DOI 10.1016/j.imavis.2013.12.007
   Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123
   HAMILTON M, 1960, J NEUROL NEUROSUR PS, V23, P56, DOI 10.1136/jnnp.23.1.56
   Jain V., 2014, 2014 ACM INT WORKSH, P87
   Joshi J, 2013, J MULTIMODAL USER IN, V7, P217, DOI 10.1007/s12193-013-0123-2
   Kaya Heysem., 2014, Proceedings of the ACM 4th International Workshop on Audio/Visual Emotion Challenge, P19, DOI [DOI 10.1145/2661806.2661814, 10.1145/2661806.2661814]
   Lang P. J., 2008, Q8 U FLOR
   Lucas GM, 2015, INT CONF AFFECT, P539, DOI 10.1109/ACII.2015.7344622
   Maddage NC, 2009, IEEE ENG MED BIO, P3723, DOI 10.1109/IEMBS.2009.5334815
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Pampouchidou A, 2019, IEEE T AFFECT COMPUT, V10, P445, DOI 10.1109/TAFFC.2017.2724035
   Poria S., 2015, UNDERSTANDING FACIAL
   Ringeval Fabien, 2017, P 7 ANN WORKSHOP AUD, P3, DOI DOI 10.1145/3133944.3133953
   Scherer S, 2014, IMAGE VISION COMPUT, V32, P648, DOI 10.1016/j.imavis.2014.06.001
   Song SY, 2018, IEEE INT CONF AUTOMA, P158, DOI 10.1109/FG.2018.00032
   Stratou G, 2015, J MULTIMODAL USER IN, V9, P17, DOI 10.1007/s12193-014-0161-4
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Williamson J.R, 2014, 2014 ACM INT WORKSH, P65
   Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2621478
   Zhang Z., 2016, INT J COMPUT VISION, V126, P550
NR 37
TC 28
Z9 32
U1 10
U2 78
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 228
EP 233
DI 10.1016/j.jvcir.2018.11.003
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400027
DA 2024-07-18
ER

PT J
AU Fei, HY
   Tu, B
   Chen, QQ
   He, DB
   Zhou, CL
   Peng, YS
AF Fei, Hongyan
   Tu, Bing
   Chen, Ququ
   He, Danbing
   Zhou, Chengle
   Peng, Yishu
TI An overview of face-related technologies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Face enhancement; 3D face reconstruction; Deep
   learning
AB In recent years, information technology is developing continuously and set off a burst of artificial intelligence boom in the field of science. The development of advanced technologies such as unmanned driving and AI chips, is the extensive application of artificial intelligence. Face-related technologies have a wide range of applications because of intuitive results and good concealment. Since 3D face information can provide more comprehensive facial information than 2D face information, and it can solve many difficulties that cannot be solved in 2D face recognition. Therefore, more and more researchers have studied 3D face recognition in recent years. Under the new circumstances, the research on face are experiencing all kinds of challenges. With the tireless of many scientists, the new technology is also making a constant progress, and in the development of many technologies it still maintained its leading position. In this paper, we simply sort out the present development process of facial correlation technology, and the general evolution of this technology is outlined. Finally, the practical significance of this technology development is briefly discussed. (C) 2018 Published by Elsevier Inc.
C1 [Fei, Hongyan; Tu, Bing; He, Danbing; Zhou, Chengle; Peng, Yishu] Hunan Inst Sci & Technol, Sch Informat Sci & Technol, Coll Informat & Commun Engn, Yueyang, Peoples R China.
   [Chen, Ququ] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hunan Institute of Science & Technology; Hefei University of Technology
RP Tu, B (corresponding author), Hunan Inst Sci & Technol, Sch Informat Sci & Technol, Coll Informat & Commun Engn, Yueyang, Peoples R China.
EM tubing@hnist.edu.cn
OI Zhou, Chengle/0000-0003-3107-5446
FU National Natural Science Foundation of China [51704115]; Key Laboratory
   Open Fund Project of Hunan Province University [17K040]; Science and
   Technology Program of Hunan Province [2016TP1021]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 51704115, by the Key Laboratory Open Fund Project of
   Hunan Province University under Grant 17K040, by the Science and
   Technology Program of Hunan Province under Grant 2016TP1021.
CR [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], NEURAL AGGREGATION N
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, CVPR
   Booth James, 2017, P IEEE C COMPUTERVIS
   Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583
   Cao Q., 2017, CVPR
   Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hao Z, 2017, IEEE C COM VIS PATT, V3
   Hayat M., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P2767
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Li C, 2017, P IEEE C COMP VIS PA, P3117
   Maninchedda F, 2017, PROC CVPR IEEE, P4608, DOI 10.1109/CVPR.2017.490
   Nech A, 2017, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2017.363
   Peng Weilong, 2017, P IEEE C COMP VIS PA, P6139
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578
   Trigeorgis G, 2017, 2017 IEEE C COMP VIS, P38
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yu X., 2017, CVPR
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P237, DOI 10.1145/2647868.2654903
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
NR 36
TC 2
Z9 2
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 139
EP 143
DI 10.1016/j.jvcir.2018.09.012
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500012
DA 2024-07-18
ER

PT J
AU Rabbouch, H
   Saâdaoui, F
AF Rabbouch, Hana
   Saadaoui, Foued
TI A wavelet-assisted subband denoising for tomographic image
   reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Denoising; Wavelets; Non-local means; Radon transform; Tomography;
   Medical imaging; Simulation
ID NONLOCAL MEANS FILTER; WIENER FILTER; SINOGRAM DATA; NOISE; MODEL; CT;
   INTERPOLATION; METHODOLOGY; REDUCTION; TRANSFORM
AB Many methods of image acquisition from medical multidimensional data rely on continuous techniques whereas in fact they are used in a finite discrete field. The discretization step is often accompanied by residuals diminishing the quality of the produced images. In addition, the acquisition phase does not occur in an ideal way and may cause artifacts and nonstandard noise. Therefore, denoising is mandatory for many algorithms in computer vision and image processing. In this paper, we propose a new denoising strategy for the tomographic image reconstruction. The method is based on a coupling of the wavelet techniques with the well-known Non Local Means (NLM) filter and operates adaptively during the data acquisition stage. Unlike other well-known denoising techniques, which are mainly based on the smoothing of the resultant image, this approach is instead based on the sinogram preprocessing. The numerical simulations show that the tomographic reconstruction based on the new denoising strategy is able to reduce enough noises present in various forms in the data. Additional robustness tests prove that the proposed approach is more stable than the basic NLM and other homologous methods.
C1 [Rabbouch, Hana] Univ Tunis, Inst Super Gest Tunis, Cite Bouchoucha, Tunis 2000, Tunisia.
   [Saadaoui, Foued] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Econ & Adm Sci, Dept Insurance & Risk Management, POB 5701, Riyadh, Saudi Arabia.
   [Rabbouch, Hana; Saadaoui, Foued] Univ Monastir, Lab Algebre Theorie Nombres & Anal Nonlineaire, Fac Sci, Monastir 5019, Tunisia.
C3 Universite de Tunis; Imam Mohammad Ibn Saud Islamic University (IMSIU);
   Universite de Monastir
RP Saâdaoui, F (corresponding author), Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Econ & Adm Sci, Dept Insurance & Risk Management, POB 5701, Riyadh, Saudi Arabia.
EM hana.rabbouch@gmail.com; foued.saadaoui@gmail.com
RI Saâdaoui, Foued/J-9710-2019; RABBOUCH, Hana/AAT-1468-2020
OI Saâdaoui, Foued/0000-0002-0574-2922; Rabbouch, Hana/0000-0001-9460-2579
CR Abella M, 2009, MED PHYS, V36, P1663, DOI 10.1118/1.3096707
   [Anonymous], 1996, THESIS LYNGBY
   Bian ZY, 2013, COMPUT MED IMAG GRAP, V37, P293, DOI 10.1016/j.compmedimag.2013.05.004
   BROOKS RA, 1978, J COMPUT ASSIST TOMO, V2, P577, DOI 10.1097/00004728-197811000-00010
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A., 1999, IMAGE DENOISING METH
   Chen QA, 2010, PATTERN RECOGN, V43, P4089, DOI 10.1016/j.patcog.2010.07.002
   Coupé P, 2012, IET IMAGE PROCESS, V6, P558, DOI 10.1049/iet-ipr.2011.0161
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Coupé P, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/590183
   Fang R., 2015, MIC CAI WORKSH MED C
   Fessler J. A., 1993, Information Processing in Medical Imaging. 13th International Conference, IPMI '93 Proceedings, P372, DOI 10.1007/BFb0013800
   FURUIE SS, 1994, PHYS MED BIOL, V39, P341, DOI 10.1088/0031-9155/39/3/003
   Ghael SP, 1997, P SOC PHOTO-OPT INS, V3169, P389, DOI 10.1117/12.292799
   Happonen A. P., 2002, Proceedings of Second IASTED International Conference Visualization, Imaging, and Image Processing, P339
   Happonen AP, 2007, INT J BIOMED IMAGING, V2007, DOI 10.1155/2007/38516
   Hejazi MR, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P429, DOI 10.1109/MMSP.2006.285345
   Hu JR, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/232685
   Hu JR, 2016, MAGN RESON IMAGING, V34, P990, DOI 10.1016/j.mri.2016.04.008
   Hu K, 2016, MAGN RESON IMAGING, V34, P1128, DOI 10.1016/j.mri.2016.05.011
   Huang J., 2012, IEEE INT S BIOM IM I
   Hung KW, 2015, SIGNAL PROCESS-IMAGE, V39, P26, DOI 10.1016/j.image.2015.07.003
   Isa IS, 2015, PROCEDIA COMPUT SCI, V60, P760, DOI 10.1016/j.procs.2015.08.231
   Karimi D, 2016, PHYS MED BIOL, V61, P3536, DOI 10.1088/0031-9155/61/9/3536
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Krestyannikov E, 2004, HELS UNIV TECHNOL S, V46, P77
   La Rivière PJ, 2005, MED PHYS, V32, P1676, DOI 10.1118/1.1915015
   Lee NY, 2001, IEEE T IMAGE PROCESS, V10, P79, DOI 10.1109/83.892445
   Li TF, 2004, IEEE T NUCL SCI, V51, P2505, DOI 10.1109/TNS.2004.834824
   Li X., 2001, IEEE Nuclear Science Symposium Conference Record, P2134
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Manduca A, 2009, MED PHYS, V36, P4911, DOI 10.1118/1.3232004
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Manjón JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003
   Morajab S., 2016, 1 INT C NEW PERSP EL
   Patra J., 2014, AM J ENG RES, V3, P207
   Peltonen S, 2011, IEEE NUCL SCI CONF R, P3125, DOI 10.1109/NSSMIC.2011.6152568
   Peltonen S, 2006, IEEE NUCL SCI CONF R, P2770, DOI 10.1109/NSSMIC.2006.356453
   Percival D. B., 2000, CA ST PR MA, V4
   ROWE RW, 1992, MED PHYS, V19, P1113, DOI 10.1118/1.596774
   Saâdaoui F, 2017, PHYSICA A, V482, P552, DOI 10.1016/j.physa.2017.04.074
   Saâdaoui F, 2015, IEEE T NANOBIOSCI, V14, P707, DOI 10.1109/TNB.2015.2477407
   Saadaoui F, 2014, EXPERT SYST APPL, V41, P6017, DOI 10.1016/j.eswa.2014.03.030
   Saâdaoui F, 2010, COMPUT STAT DATA AN, V54, P750, DOI 10.1016/j.csda.2008.11.011
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Teymurazyan A, 2013, J DIGIT IMAGING, V26, P447, DOI 10.1007/s10278-012-9511-5
   VARDI Y, 1985, J AM STAT ASSOC, V80, P8, DOI 10.2307/2288030
   Wang J, 2005, PROC SPIE, V5747, P2058, DOI 10.1117/12.595662
   Wang J, 2008, PHYS MED BIOL, V53, P3327, DOI 10.1088/0031-9155/53/12/018
   Wang YM, 2015, J COMPUT DES ENG, V2, P113, DOI 10.1016/j.jcde.2014.12.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen JH, 2013, INT J IMAG SYST TECH, V23, P36, DOI 10.1002/ima.22034
   Wilson D. W., 1991, P NUCL SCI S MED IM
   Yang L, 2010, J STRUCT BIOL, V172, P233, DOI 10.1016/j.jsb.2010.06.019
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang XB, 2014, J VIS COMMUN IMAGE R, V25, P254, DOI 10.1016/j.jvcir.2013.11.006
   Zhang XB, 2013, COMPUT ELECTR ENG, V39, P934, DOI 10.1016/j.compeleceng.2012.07.013
   Zhang YT, 2012, PATTERN RECOGN, V45, P2743, DOI 10.1016/j.patcog.2012.01.015
NR 60
TC 21
Z9 22
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 115
EP 130
DI 10.1016/j.jvcir.2018.05.004
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100011
DA 2024-07-18
ER

PT J
AU Wang, TW
   Liu, CC
   Wang, LT
   Ma, BX
   Gu, XJ
AF Wang, Tingwei
   Liu, Chuancai
   Wang, Liantao
   Ma, Bingxian
   Gu, Xingjian
TI Evolution modeling with multi-scale smoothing for action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Multi-scale representation; Rank pooling; Evolution
   modeling; Dynamics
ID TEMPORAL STRUCTURE; REPRESENTATION
AB The aim of this paper is to model long-term evolution of an action video with temporal multi-scale representation. This task is tough due to huge intra-class variations in motion speed. Most of the existing methods consider evolution modeling and multi-scale feature fusion in two separated phases, which generates sub-optimal representation. To address this issue, this paper proposes a novel method to integrate the evolution modeling and multi-scale representation into a unified framework. The core idea is to introduce a temporal multi-scale smoothing vector, which is used to define how the representations at different temporal scales are combined together for frame smoothing. By formulating the smoothing vector learning, evolution modeling and classifier training jointly, our method can learn a discriminative and flexible representation of multi-scale rather than a single scale or a fixed multi-scale smoothing. Experimental results on three datasets demonstrate the effectiveness of our method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Tingwei; Liu, Chuancai] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Wang, Tingwei; Ma, Bingxian] Univ Jinan, Sch Informat Sci & Engn, Jinan 250013, Shandong, Peoples R China.
   [Wang, Liantao] Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.
   [Gu, Xingjian] Nanjing Agr Univ, Coll Informat Sci & Technol, Nanjing 210095, Jiangsu, Peoples R China.
   [Liu, Chuancai] Minjiang Univ, Collaborat Innovat Ctr IoT Technol & Intelligent, Fuzhou 350108, Fujian, Peoples R China.
C3 Nanjing University of Science & Technology; University of Jinan; Hohai
   University; Nanjing Agricultural University; Minjiang University
RP Wang, TW; Liu, CC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM tingweiwang@ujn.edu.cn; chuancailiu@mail.njust.edu.cn;
   ltwang@hhu.edu.cn; ise_mabx@ujn.edu.cn
RI Wang, Ting-Wei/ABB-6079-2021
OI Wang, Ting-Wei/0000-0003-3463-643X
FU National Natural Science Fund of China [61373062, 61373063, 61473155,
   61703139]; Project of Ministry off Industry, Information Technology of
   PRC [E0310/1112/02-1]; Fundamental Research Funds for the Central
   Universities [2015B03114]; Collaborative Innovation Center of IoT
   Technology and Intelligent Systems, Minjiang University [IIC1701]
FX This work was supported by the National Natural Science Fund of China
   [Grant Nos. 61373062, 61373063, 61473155 and 61703139]; the Project of
   Ministry off Industry, Information Technology of PRC [Grant No.
   E0310/1112/02-1]; Fundamental Research Funds for the Central
   Universities [Grant No. 2015B03114]; and Collaborative Innovation Center
   of IoT Technology and Intelligent Systems, Minjiang University [Grant
   No. IIC1701].
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2008, P IEEE COMP SOC C CO
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2013, P IEEE INT C COMP VI
   Banerjee P, 2014, LECT NOTES COMPUT SC, V8690, P711, DOI 10.1007/978-3-319-10605-2_46
   Barrett DP, 2016, IEEE T CIRC SYST VID, V26, P2250, DOI 10.1109/TCSVT.2015.2502839
   Bertsekas D. P., 1982, REINFORCEMENT LEARNI
   Chen QQ, 2016, NEUROCOMPUTING, V173, P364, DOI 10.1016/j.neucom.2015.03.124
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Fernando B, 2016, PROC CVPR IEEE, P1924, DOI 10.1109/CVPR.2016.212
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Jung HJ, 2017, PATTERN RECOGN LETT, V85, P21, DOI 10.1016/j.patrec.2016.11.012
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Lin C.-J., 2007, INT C MACHINE LEARNI, P561
   Lin CJ, 1999, SIAM J OPTIMIZ, V9, P1100, DOI 10.1137/S1052623498345075
   Ma SG, 2015, PROC CVPR IEEE, P5024, DOI 10.1109/CVPR.2015.7299137
   Mangasarian OL, 2002, OPTIM METHOD SOFTW, V17, P913, DOI 10.1080/1055678021000028375
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Murthy OVR, 2015, IMAGE VISION COMPUT, V42, P22, DOI 10.1016/j.imavis.2015.06.009
   Ni BB, 2015, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2015.7298993
   Ni BB, 2015, INT J COMPUT VISION, V111, P229, DOI 10.1007/s11263-014-0742-4
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang LT, 2017, IEEE T CYBERNETICS, V47, P1313, DOI 10.1109/TCYB.2017.2647965
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214
   Wen JJ, 2016, PATTERN RECOGN, V60, P515, DOI 10.1016/j.patcog.2016.06.006
   Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334
   Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234
   Yu S, 2017, J VIS COMMUN IMAGE R, V49, P192, DOI 10.1016/j.jvcir.2017.09.007
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
NR 49
TC 3
Z9 3
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 778
EP 788
DI 10.1016/j.jvcir.2018.08.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100068
DA 2024-07-18
ER

PT J
AU Hsu, GSJ
   Arnbikapathi, A
   Chung, SL
   Shie, HC
AF Hsu, Gee-Sern (Jison)
   Arnbikapathi, ArulMurugan
   Chung, Sheng-Luen
   Shie, Hung-Cheng
TI Robust cross-pose face recognition using landmark oriented depth warping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Cross-pose; Facial landmarks; Depth warping; Sparse
   reconstruction; RTSM; PIE and Multi-PIE database
ID MODELS
AB A novel approach exploiting facial landmarks and depth warping is proposed for robust cross-pose face recognition. Unlike the existing 3-D reconstruction based cross-pose recognition algorithms, the proposed algorithm utilizes the automatically identified extensive facial landmarks to replace the computationally expensive 3-D reconstruction procedure, by depth warping. The given face is thereby registered to the most similar 3-D reference model. When matching to a probe face image, the registered depth-warped faces in the gallery are rotated to align to the orientation of the probe image, and sparse regression is then used to identify the correct person. Further, to handle the more challenging cases with eyeglasses, we devise and employ an enhanced Regressive Tree Structured Model (RTSM) combined with inpainting procedure, prior to depth warping. The proposed robust cross-pose recognition (RCPR) algorithm is rigorously validated on PIE and Multi-PIE databases, and compared with state-of-the-art contemporary approaches to demonstrate its superior efficacy.
C1 [Hsu, Gee-Sern (Jison)] Natl Taiwan Univ Sci & Technol, Dept Mech Engn, Artificial Vis Lab, Taipei 106, Taiwan.
   [Arnbikapathi, ArulMurugan] Utechzone Co Ltd, New Taipei 23552, Taiwan.
   [Chung, Sheng-Luen] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.
   [Shie, Hung-Cheng] Natl Taiwan Univ Sci & Technol, Dept Mech Engn, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology; National Taiwan University of
   Science & Technology
RP Hsu, GSJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Mech Engn, Artificial Vis Lab, Taipei 106, Taiwan.
EM jison@mail.ntust.edu.tw; aareul@ieee.org; slchung@mail.ntust.edu.tw;
   m10403417@mail.ntust.edu.tw
OI Hsu, Gee-Sern/0000-0003-2631-0448
CR Abiantun R, 2014, IEEE T PATTERN ANAL, V36, P2061, DOI 10.1109/TPAMI.2014.2313124
   Ali AM, 2014, IEEE T INF FOREN SEC, V9, P2158, DOI 10.1109/TIFS.2014.2362299
   [Anonymous], 2014, CVPR
   Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336
   Cootes T. F., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P173
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   González-Jiménez D, 2007, IEEE T INF FOREN SEC, V2, P413, DOI 10.1109/TIFS.2007.903543
   Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275
   Hsu GS, 2014, IEEE COMPUT SOC CONF, P34, DOI 10.1109/CVPRW.2014.11
   Hsu GS, 2015, IEEE I CONF COMP VIS, P3855, DOI 10.1109/ICCV.2015.439
   Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489
   Juefei-Xu F, 2015, IEEE T IMAGE PROCESS, V24, P4780, DOI 10.1109/TIP.2015.2468173
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957
   Li AN, 2011, PATTERN RECOGN LETT, V32, P1948, DOI 10.1016/j.patrec.2011.07.020
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Pal D. K., 2016, P IEEE INT C COMP VI
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Piotraschke M, 2016, PROC CVPR IEEE, P3418, DOI 10.1109/CVPR.2016.372
   Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123
   Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Roth Joseph, 2015, P IEEE C COMP VIS PA
   Roth Joseph, 2016, IEEE C COMP VIS PATT, P2
   Sharma A, 2012, COMPUT VIS IMAGE UND, V116, P1095, DOI 10.1016/j.cviu.2012.08.001
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang X., 2017, P IEEE C COMP VIS PA, P1548
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang Xinpeng, 2012, IEEE T INFORM FORENS, V7
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 40
TC 2
Z9 3
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 273
EP 280
DI 10.1016/j.jvcir.2018.03.013
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800025
DA 2024-07-18
ER

PT J
AU Xu, YY
   Hong, XP
   Liu, X
   Zhao, GY
AF Xu, Yingyue
   Hong, Xiaopeng
   Liu, Xin
   Zhao, Guoying
TI Saliency detection via bi-directional propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Bi-directional; Propagation
ID OBJECT DETECTION; MODEL; ATTENTION; IMAGE
AB Recent saliency models rely on propagation to compute the saliency map. Previous propagation methods are single directional, where foreground propagation and background propagation are separate (e.g., only foreground propagation, or background propagation after foreground propagation). Different from the previous approaches, we propose a bi-directional propagation model (BIP) for saliency detection. The BIP model propagates from the labeled foreground superpixels and the labeled background superpixels to the unlabeled ones in the same iteration. A difficulty-based rule is adopted to manipulate the prorogation sequence, which considers both the distinctness of the superpixel to its neighboring ones and its connectivity to the labeled sets. The BIP model outperforms fourteen state-of-the-art saliency models on four challenging datasets, and largely enhances the propagation efficiency compared to single directional propagation models.
C1 [Xu, Yingyue; Hong, Xiaopeng; Liu, Xin; Zhao, Guoying] Univ Oulu, Ctr Machine Vis & Signal Anal, POB 4500, Oulu 90014, Finland.
C3 University of Oulu
RP Zhao, GY (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal, POB 4500, Oulu 90014, Finland.
EM Yingyue.Xu@oulu.fi; Xiaopeng.Hong@oulu.fi; Xin.Liu@oulu.fi;
   Guoying.Zhao@oulu.fi
RI Liu, Xin/AAD-5166-2019; Zhao, Guoying/ABE-7716-2020; HONG,
   Xiaopeng/V-6078-2019
OI Liu, Xin/0000-0002-2242-6139; Zhao, Guoying/0000-0003-3694-206X; HONG,
   Xiaopeng/0000-0002-0611-0636
FU Academy of Finland; Infotech; Tekes Fidipro Program [1849/31/2015];
   Tekes project [3116/31/2017]; Natural Science Foundation of China
   [61772419, 61572205, 61601362]; NVIDIA Corporation
FX We express deep gratitude to the Academy of Finland, Infotech, Tekes
   Fidipro Program (Grant No. 1849/31/2015), Tekes project (Grant No.
   3116/31/2017), and Natural Science Foundation of China under the
   contract No. 61772419. The authors also wish to acknowledge CSC - IT
   Center for Science, Finland, for generous computational resources.
   Xiaopeng Hong is partly supported by the Natural Science Foundation of
   China under the contract No. 61572205. Xin Liu is partly supported by
   the Natural Science Foundation of China under the contract No. 61601362.
   The authors also wish to acknowledge the supports of NVIDIA Corporation
   with the donation of the Tesla K40 and K80 GPUs used for this research.
   Besides, we appreciate all the code and results from the corresponding
   authors, especially the code of TLLT model from Prof. Chen Gong and the
   code of BSCA model from Prof. Huchuan Lu.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Everingham M., PASCAL VISUAL OBJECT, P2274
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hati A, 2017, J VIS COMMUN IMAGE R, V43, P212, DOI 10.1016/j.jvcir.2017.01.007
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang M, 2014, LECT NOTES COMPUT SC, V8695, P17, DOI 10.1007/978-3-319-10584-0_2
   Jiang P, 2015, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2015.33
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li J, 2013, IEEE SIGNAL PROC LET, V20, P845, DOI 10.1109/LSP.2013.2268868
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu Q, 2017, IEEE T IMAGE PROCESS, V26, P4537, DOI 10.1109/TIP.2017.2703081
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren Z., 2010, Proceedings of the 18th ACM international conference on Multimedia, P1099
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Shen CY, 2014, LECT NOTES COMPUT SC, V8695, P33, DOI 10.1007/978-3-319-10584-0_3
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Tang H, 2016, IEEE SIGNAL PROC LET, V23, P1736, DOI 10.1109/LSP.2016.2617340
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Volokitin A., IEEE P CVPR
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu YY, 2015, LECT NOTES COMPUT SC, V9386, P637, DOI 10.1007/978-3-319-25903-1_55
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Zhang DW, 2015, PROC CVPR IEEE, P2994, DOI 10.1109/CVPR.2015.7298918
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou BJ, 2015, J VIS COMMUN IMAGE R, V33, P378, DOI 10.1016/j.jvcir.2015.09.017
NR 52
TC 5
Z9 6
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 113
EP 121
DI 10.1016/j.jvcir.2018.02.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, Y
   Nian, FD
   Li, T
   Meng, ZJ
   Wang, KQ
AF Wang, Yan
   Nian, Fudong
   Li, Teng
   Meng, Zhijun
   Wang, Kongqiao
TI Robust face anti-spoofing with depth information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face anti-spoofing; Depth information; Convolutional neural network
ID LIVENESS DETECTION
AB With the prevalence of face authentication applications, the prevention of malicious attack from fake faces such as photos or videos, i.e., face anti-spoofing, has attracted much attention recently. However, while an increasing number of works on the face anti-spoofing have been reported based on 2D RGB cameras, most of them cannot handle various attacking methods. In this paper we propose a robust representation jointly modeling 2D textual information and depth information for face anti-spoofing. The textual feature is learned from 2D facial image regions using a convolutional neural network (CNN), and the depth representation is extracted from images captured by a Kinect. A face in front of the camera is classified as live if it is categorized as live using both cues. We collected a face anti-spoofing experimental dataset with depth information, and reported extensive experimental results to validate the robustness of the proposed method. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Wang, Yan; Nian, Fudong; Li, Teng] Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Anhui, Peoples R China.
   [Meng, Zhijun] Beihang Univ, Beijing, Peoples R China.
   [Wang, Kongqiao] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Anhui University; Beihang University; Chinese Academy of Sciences;
   Institute of Automation, CAS
RP Meng, ZJ (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM mzj.beihang@gmail.com
FU National Natural Science Foundation (NSF) of China [61572029]; Science
   and Technology Project of Anhui Province [1604d0802019]
FX This work is supported by the National Natural Science Foundation (NSF)
   of China (No. 61572029), and partially supported by Science and
   Technology Project of Anhui Province (No. 1604d0802019).
CR Boulkenafet Z., 2015, 2015 IEEE INT C IM P
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   De Marsico M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P73, DOI 10.1109/ICB.2012.6199761
   Gahyun Kim, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P67, DOI 10.1109/ICB.2012.6199760
   KARSON CN, 1983, BRAIN, V106, P643, DOI 10.1093/brain/106.3.643
   Kollreider K, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P75, DOI 10.1109/AUTOID.2005.20
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lagorio A, 2013, I W BIOMETRIC FORENS
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Li S. Z, 2014, Learn convolutional neural network for face anti-spoofing
   Liu W., 2017, SPHEREFACE DEEP HYPE
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Pan G, 2011, TELECOMMUN SYST, V47, P215, DOI 10.1007/s11235-010-9313-3
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484
   Sun L, 2007, LECT NOTES COMPUT SC, V4642, P252
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Wang F, 2017, arXiv
   Wang T, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/871213
   Yan JJ, 2012, I C CONT AUTOMAT ROB, P188, DOI 10.1109/ICARCV.2012.6485156
   Yang J, 2013, SCI WORLD J, DOI 10.1155/2013/812469
   Zhang Z, 2012, J NANOMATER, V2012, DOI 10.1155/2012/238605
NR 27
TC 39
Z9 51
U1 1
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 332
EP 337
DI 10.1016/j.jvcir.2017.09.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800027
DA 2024-07-18
ER

PT J
AU Hao, T
   Wu, D
   Wang, Q
   Sun, JS
AF Hao, Tong
   Wu, Dan
   Wang, Qian
   Sun, Jin-Sheng
TI Multi-view representation learning for multi-view action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view learning; Multi-task learning; Sparse coding; Action
   recognition
ID MODEL; DICTIONARY
AB Although multiple methods have been proposed for human action recognition, the existing multi-view approaches cannot well discover meaningful relationship among multiple action categories from different views. To handle this problem, this paper proposes an multi-view learning approach for multi-view action recognition. First, the proposed method leverages the popular visual representation method, bag of -visual-words (BoVW)/fisher vector (FV), to represent individual videos in each view. Second, the sparse coding algorithm is utilized to transfer the low-level features of various views into the discriminative and high-level semantics space. Third, we employ the multi-task learning (MTL) approach for joint action modeling and discovery of latent relationship among different action categories. The extensive experimental results on (MI)-I-2 and IXMAS datasets have demonstrated the effectiveness of our proposed approach. Moreover, the experiments further demonstrate that the discovered latent relationship can benefit multi-view model learning to augment the performance of action recognition. (C) 2017 Published by Elsevier Inc.
C1 [Hao, Tong; Wu, Dan; Wang, Qian; Sun, Jin-Sheng] Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
   [Sun, Jin-Sheng] Tianjin Aquat Anim Infect Dis Control & Prevent C, Tianjin 300221, Peoples R China.
C3 Tianjin Normal University; Tianjin Center for Disease Control &
   Prevention
RP Sun, JS (corresponding author), Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
EM jinshsun@163.com
FU National High-Tech Research and Development Program of China (863
   programs) [2012AA10A401]; Grants of the Major State Basic Research
   Development Program of China (973 programs) [2012CB114405]; National
   Natural Science Foundation of China [21106095]; National Key Technology
   R D Program [2011BAD13B07, 2011BAD13B04]; Tianjin Applied Basic and
   Advanced Technology Research Program [15JCYBJC30700]; Project of
   introducing one thousand high level talents in three years [5KQM110003];
   Tianjin Normal University Academic Innovation Promotion Program for
   Young Teachers [52XC1403]; Tianjin Innovative Talent Training Program
   [ZX110170]
FX This work was funded by National High-Tech Research and Development
   Program of China (863 programs, 2012AA10A401), Grants of the Major State
   Basic Research Development Program of China (973 programs,
   2012CB114405), National Natural Science Foundation of China (21106095),
   National Key Technology R & D Program (2011BAD13B07, 2011BAD13B04),
   Tianjin Applied Basic and Advanced Technology Research Program
   (15JCYBJC30700), Project of introducing one thousand high level talents
   in three years (5KQM110003), Tianjin Normal University Academic
   Innovation Promotion Program for Young Teachers (52XC1403) and Tianjin
   Innovative Talent Training Program (ZX110170).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], ICPR
   [Anonymous], 2008 IEEE COMP SOC C
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2014, ABS14054506 CORR
   [Anonymous], CVPR
   [Anonymous], 2007, ICCV
   [Anonymous], 2008 IEEE COMP SOC C
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], MACH LEARN P 21 INT
   [Anonymous], VIEW INVARIANT REPRE
   [Anonymous], 2012, MALSAR: Multi-tAsk Learning via StructurAl Regularization
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 2008 IEEE COMP SOC C
   [Anonymous], 2009, P BRIT MACH VIS C
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   Farhadi A, 2009, IEEE I CONF COMP VIS, P948, DOI 10.1109/ICCV.2009.5459350
   Gao Z, 2016, NEUROCOMPUTING, V215, P138, DOI 10.1016/j.neucom.2016.01.113
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   Huang CH, 2012, LECT NOTES COMPUT SC, V7583, P342, DOI 10.1007/978-3-642-33863-2_34
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22
   Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu AA, 2012, IEEE T MED IMAGING, V31, P359, DOI 10.1109/TMI.2011.2169495
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Liu Man, 2016, IEEE T CYBERNET, V0, P1
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Parameswaran V, 2005, COMPUT VIS IMAGE UND, V98, P295, DOI 10.1016/j.cviu.2004.09.002
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Reddy KK, 2009, IEEE I CONF COMP VIS, P1010, DOI 10.1109/ICCV.2009.5459374
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Xu N., 2015, Proceedings of the 23rd acm international conference on multimedia, P1195, DOI DOI 10.1145/2733373.2806315
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Zha HY, 2002, ADV NEUR IN, V14, P1057
   Zheng J, 2012, NANOSCALE RES LETT, V7, P1, DOI 10.1186/1556-276X-7-157
   Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702
NR 54
TC 24
Z9 25
U1 1
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 453
EP 460
DI 10.1016/j.jvcir.2017.01.019
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700039
DA 2024-07-18
ER

PT J
AU Park, JS
   Ogunfunmi, T
AF Park, Jeoong Sung
   Ogunfunmi, Tokunbo
TI A 3D-DCT video encoder using advanced coding techniques for low power
   mobile device
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-DCT; Bit-plane coding; Video compression for low power
ID 3D; QUANTIZATION
AB The three-dimensional discrete cosine transform (3D-DCT) has been researched as an alternative to existing dominant video standards based on motion estimation and compensation. Since it does not need to search macro block for inter/intra prediction, 3D-DCT has great advantages for complexity. However, it has not been developed well because of poor video quality while video standards such as H.263(+) and HEVC have been blooming. In this paper, we propose a new 3D-DCT video coding as a new video solution for low power mobile technologies such as Internet of Things (loT) and Drone. We focus on overcoming drawbacks reported in previous research. We build a complete 3D-DCT video coding system by adopting existing advanced techniques and devising new coding algorithms to improve overall performance of 3DDCT. Experimental results show proposed 3D-DO outperforms H.264 low power profiles while offering less complexity. From GBD-PSNR, proposed 3D-DO provides better performance by average 4.6 dB. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Park, Jeoong Sung; Ogunfunmi, Tokunbo] Santa Clara Univ, 500 El Camino Real, Santa Clara, CA 95053 USA.
C3 Santa Clara University
RP Park, JS (corresponding author), Santa Clara Univ, 500 El Camino Real, Santa Clara, CA 95053 USA.
EM jeoongsung@gmail.com
OI Ogunfunmi, Tokunbo/0000-0003-3517-9779
CR Abdelhalim MB, 2003, SCS 2003: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, PROCEEDINGS, P389
   Adjeroh DA, 2009, IEEE T BROADCAST, V55, P178, DOI 10.1109/TBC.2009.2020447
   Aggoun A, 2001, ICECS 2001: 8TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND SYSTEMS, VOLS I-III, CONFERENCE PROCEEDINGS, P229, DOI 10.1109/ICECS.2001.957722
   Aijun Sang, 2010, Proceedings of the 2010 2nd International Conference on Future Computer and Communication (ICFCC 2010), P30, DOI 10.1109/ICFCC.2010.5497296
   Aminlou A, 2009, PICT COD S 2009 PCS, P1
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2013, WIGIG DISPLAY EXTENS
   [Anonymous], 2013, H 264 AVC REFERENCE
   Bazhyna A., 2007, P 26 PICT COD S PCS, P4
   Bhaskaranand M, 2009, INT CONF ACOUST SPEE, P793, DOI 10.1109/ICASSP.2009.4959703
   BjOntegaard G., 2001, VCEG M ITU T SG16 Q6
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Bozinovic N, 2005, SIGNAL PROCESS-IMAGE, V20, P510, DOI 10.1016/j.image.2005.03.007
   Bozinovic N, 2003, PROC SPIE, V5150, P1204, DOI 10.1117/12.503324
   Burg A., 2000, MOB MULT C MOMUC
   Chan RKW, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P188, DOI 10.1109/VSMM.1997.622346
   Fryza T., 2003, 13th International Czech - Slovak Scientific Conference. Radioelektronika 2003, P127
   Furman D., 2001, IAPR/IEEE Conference on Image and Vision Comp, P333
   Haiyan T., 2012, 2012 INT C COMP SCI, V1, P200
   Ikegaki Y., 2001, I EICE T INFORM SY D, P1409
   Institut fur Rundfunktechnik, 2005, ITU R BT 500 REC SAM
   *ITU, 2005, ITU T REC H 264 ADV
   Jalloh I, 2000, 2000 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: DESIGN AND IMPLEMENTATION, P238, DOI 10.1109/SIPS.2000.886721
   Jin Li, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1247, DOI 10.1109/ICOSP.2008.4697357
   Kozamernik F, 2005, SMPTE MOTION IMAG J, V114, P152, DOI 10.5594/J11535
   Li J, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P634, DOI 10.1109/ISCCSP.2008.4537302
   Li W., 2001, 1SC29WG11 ISOIEC JTC
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Li XA, 2010, IEEE INT CON MULTI, P685, DOI 10.1109/ICME.2010.5582589
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Markman D, 2001, IEEE IMAGE PROC, P114, DOI 10.1109/ICIP.2001.958966
   Park J. S., 2013, P 2013 IEEE SIGN PRO
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Saponara S, 2012, J REAL-TIME IMAGE PR, V7, P43, DOI 10.1007/s11554-010-0174-5
   Servais M, 1997, COMSIG '97 - PROCEEDINGS OF THE 1997 SOUTH AFRICAN SYMPOSIUM ON COMMUNICATIONS AND SIGNAL PROCESSING, P27, DOI 10.1109/COMSIG.1997.629976
   Tai SC, 2000, IEEE T INF TECHNOL B, V4, P259, DOI 10.1109/4233.870036
   Tan T. K., 2007, VCEG M ITU T Q 6 SG1
   Wu H.R., 2005, DIGITAL VIDEO IMAGE
   YEO BL, 1995, IEEE T VIS COMPUT GR, V1, P29, DOI 10.1109/2945.468390
   Zaharia R, 2002, SIGNAL PROCESS-IMAGE, V17, P231, DOI 10.1016/S0923-5965(01)00020-0
NR 40
TC 3
Z9 3
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 122
EP 135
DI 10.1016/j.jvcir.2017.06.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700010
DA 2024-07-18
ER

PT J
AU Tong, T
   Ling, L
AF Tong, Tang
   Ling, Li
TI Rate control for non-uniform video in HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rate control; HEVC; R-Q; Bit allocation
ID RATE CONTROL ALGORITHM; BIT ALLOCATION; QUANTIZATION MODEL; H.264/AVC;
   TEXTURE; DELAY
AB Rate control plays an important role in video coding, and most of the existing rate control schemes are based on the assumption that the video contents are uniform. However, for non-uniform video applications, such as screen content videos and movies, previous rate control schemes may cause severe quality degradation, since the bit allocation strategy is improper and the rate-quantization (R-Q) model parameters may extremely inaccurate. In this paper, firstly an adaptive bit allocation algorithm is proposed for the newest video coding standard high efficiency video coding (HEVC), next a key frame detection method is presented, and finally an accurate intra R-Q model, a model parameter adjusting strategy and a bit feedback strategy are developed for the scene change frame. Experimental results show that the proposed rate control method could achieve more accurate bitrates and better rate-distortion (R-D) performance than previous rate control methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Tong, Tang] Univ Sci & Technol China, Inst Informat Sci & Technol, Hefei, Anhui, Peoples R China.
   [Ling, Li] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Ling, L (corresponding author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
EM ttly@mail.ustc.edu.cn; lingli@ia.ac.cn
OI Li, Ling/0000-0001-8877-9052
FU Strategic Priority Research Program of Chinese Academy of Sciences
   [XDA06010402]; National Key Technology Support Program [Y4M1011GK1]; NSF
   of China [61672491]
FX This work is partially supported by the Strategic Priority Research
   Program of Chinese Academy of Sciences (under Grant XDA06010402), the
   National Key Technology Support Program (under Grant Y4M1011GK1), and
   the NSF of China (under Grant 61672491).
CR [Anonymous], 2012, JCT VC ITU T SG16 WP
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2012, P 11 JOINT COLL TEAM
   [Anonymous], IEEE T BROADCAST
   [Anonymous], IEEE INT C COMP NETW
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2015 VISUAL COMMUNIC
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2012, ITUTSG16 WP3
   [Anonymous], IEEE T CIRCUITS SYST
   Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Cherniavsky N, 2007, IEEE T CIRC SYST VID, V17, P59, DOI 10.1109/TCSVT.2006.887135
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Guo YY, 2015, IEEE INT SYMP CIRC S, P1118, DOI 10.1109/ISCAS.2015.7168834
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P1221, DOI 10.1109/76.974677
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Kamaci N, 2005, IEEE T CIRC SYST VID, V15, P994, DOI 10.1109/TCSVT.2005.852400
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lee H, 2012, IEEE T BROADCAST, V58, P47, DOI 10.1109/TBC.2011.2164308
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li L, 2016, IEEE T MULTIMEDIA, V18, P2023, DOI 10.1109/TMM.2016.2595264
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li Shengxi, 2015, IEEE INT C MULTIMEDI, P1
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   SORENSON HW, 1970, IEEE SPECTRUM, V7, P63, DOI 10.1109/MSPEC.1970.5213471
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan YH, 2012, IEEE T CIRC SYST VID, V22, P1236, DOI 10.1109/TCSVT.2012.2198132
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wen JT, 2015, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2015.35
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu CY, 2014, IEEE T CIRC SYST VID, V24, P113, DOI 10.1109/TCSVT.2013.2273656
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Yimin Zhou, 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P648, DOI 10.1109/ICCNC.2013.6504163
   Zhang DD, 2009, SIGNAL PROCESS-IMAGE, V24, P357, DOI 10.1016/j.image.2009.03.003
NR 39
TC 3
Z9 4
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 254
EP 267
DI 10.1016/j.jvcir.2017.06.014
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700020
DA 2024-07-18
ER

PT J
AU Xiong, JJ
   Liu, QG
   Wang, YH
   Xu, XL
AF Xiong, Jiaojiao
   Liu, Qiegen
   Wang, Yuhao
   Xu, Xiaoling
TI A two-stage convolutional sparse prior model for image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Image deblurring; CS-MRI; Fields-of-Experts; Convolutional sparse
   coding; Multi-view features prior; Alternating direction method of
   multipliers
ID RECONSTRUCTION; DECONVOLUTION; OPTIMIZATION; REPRESENTATION; ALGORITHM;
   DOMAIN
AB Image restoration (IR) from noisy, blurred or/and incomplete observed measurement is one of the important tasks in image processing community. Image prior is of utmost importance for recovering a high quality image. In this paper, we present a two-stage convolutional sparse prior model for efficient image restoration. The multi-view features prior is first obtained by convolving the image with the Fields-of Experts (FoE) filters and then the resulting multi-view features are represented by convolutional sparse coding (CSC) prior. By taking advantage of the convolutional filters, the proposed two-stage model inherits the strengths of multi-view features and CSC priors. The assembled multi-view features contain high frequency, redundancy, and large range of feature orientations, which are favor to be represented by CSC and consequently for better image recovery. Augmented Lagrangian and alternating direction method of multipliers are employed to decouple the nonlinear optimization problem in order to iteratively approach the optimum solution. The results of various experiments on image deblurring and compressed sensing magnetic resonance imaging (CS-MRI) reconstruction consistently demonstrate that the proposed algorithm efficiently recovers image and presents advantages over the current leading restoration approaches. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Xiong, Jiaojiao; Liu, Qiegen; Wang, Yuhao; Xu, Xiaoling] Nanchang Univ, Dept Elect Informat Engn, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, QG (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang, Jiangxi, Peoples R China.
EM liuqiegen@ncu.edu.cn
RI Li, Yuanyuan/J-3539-2014; WANG, Yuhao/O-9322-2019
OI Li, Yuanyuan/0000-0001-6151-9306; WANG, Yuhao/0000-0002-8445-0361
FU National Natureal Science Founding of China (NSFC) [61362001, 61503176,
   61661031]; Jiangxi advanced project for post-doctoral research fund
   [2014KY02]; Jiangxi province innovation projects for postgraduate funds
   [YC2016-S006]
FX The authors sincerely thank the anonymous reviewers for their valuable
   comments and constructive suggestions that are very helpful in the
   improvement of this paper. The authors also would like to thank M.D.
   Zeiler, W. Dong, J. Portilla, K. Dabov, and A. Beck for their source
   codes for comparisons. This work was supported by National Natureal
   Science Founding of China (NSFC) (61362001, 61503176, 61661031), Jiangxi
   advanced project for post-doctoral research fund (2014KY02) and Jiangxi
   province innovation projects for postgraduate funds (YC2016-S006).
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], ELECT IMAGING 2008
   [Anonymous], MULTISCALE MODEL SIM
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2010, COMPUT SCI
   [Anonymous], 2011, 2011 JOINT C IEEE IN
   [Anonymous], OPT EXPR
   Babacan SD, 2009, IEEE T IMAGE PROCESS, V18, P12, DOI 10.1109/TIP.2008.2007354
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bilgin A., 2010, Proceeding of International Society for Magnetic Resonance in Medicine, V18, P4887
   Bristow H, 2013, PROC CVPR IEEE, P391, DOI 10.1109/CVPR.2013.57
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1887, DOI 10.1109/TPAMI.2013.19
   Dogan Z, 2011, IEEE IMAGE PROC, P705, DOI 10.1109/ICIP.2011.6116651
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   Heide F, 2015, PROC CVPR IEEE, P5135, DOI 10.1109/CVPR.2015.7299149
   Hu XM, 2014, OPT LETT, V39, P3177, DOI 10.1364/OL.39.003177
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li X., 2008, INT WORKSH LOC NONL, P1
   Liu QG, 2013, SIAM J IMAGING SCI, V6, P1689, DOI 10.1137/110857349
   Liu QG, 2013, IEEE T IMAGE PROCESS, V22, P4652, DOI 10.1109/TIP.2013.2277798
   Liu QG, 2013, IEEE T MED IMAGING, V32, P1290, DOI 10.1109/TMI.2013.2256464
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Neelamani R, 2004, IEEE T SIGNAL PROCES, V52, P418, DOI 10.1109/TSP.2003.821103
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Portilla J, 2009, IEEE IMAGE PROC, P3909, DOI 10.1109/ICIP.2009.5413975
   Preibisch S, 2014, NAT METHODS, V11, P645, DOI [10.1038/NMETH.2929, 10.1038/nmeth.2929]
   Qu XB, 2012, MAGN RESON IMAGING, V30, P964, DOI 10.1016/j.mri.2012.02.019
   Ramani S, 2011, IEEE T MED IMAGING, V30, P694, DOI 10.1109/TMI.2010.2093536
   Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Samuel KGG, 2009, PROC CVPR IEEE, P477, DOI 10.1109/CVPRW.2009.5206774
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Wang S., 2012, PROC ASI C COMPUT VI, P231
   Welling Max., 2002, NIPS, P1359
   Wohlberg B, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854992
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Xu ZM, 2009, OPT LETT, V34, P1453, DOI 10.1364/OL.34.001453
   Yair W., 2007, IEEE C COMPUTER VISI, P1
   Yang SY, 2014, IEEE T IMAGE PROCESS, V23, P2793, DOI 10.1109/TIP.2014.2319742
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 58
TC 9
Z9 9
U1 3
U2 62
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 268
EP 280
DI 10.1016/j.jvcir.2017.07.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700021
DA 2024-07-18
ER

PT J
AU Acharya, A
   Meher, S
AF Acharya, Aditya
   Meher, Sukadev
TI Efficient fuzzy composite predictive scheme for effectual 2-D
   up-sampling of images for multimedia applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Up-scaling; Interpolation; De-blurring; Local variance; Laplacian; Fuzzy
   logic; Fuzzy inference system
ID PARALLEL FRAMEWORK; INTERPOLATION; HEVC; DECISION
AB In this paper, a highly nonlinear, fuzzy logic based, composite scheme is proposed by combining a preprocessing and a post-processing operation to efficiently restore high frequency (HF) and very high frequency (VHF) details in an up-scared image. The blurring in case of an up-sampled image is caused by the degradation of HF and VHF image details that correspond to fine details and edge regions during the up sampling process. The degradation of HF and VHF image details is more significant than that of the flat and slowly varying regions. In order to resolve this problem effectively, a fuzzy composite scheme is developed which is based on the inverse modeling approach of HF degradation. During the preprocessing operation, the VHF components of an image are boosted up using recursive Laplacian of Laplacian (LOL) operator prior to image up-scaling. Subsequent to the image up-scaling, a fuzzy local adaptive Laplacian post-processing scheme is used which enhances the HF image details more than the low frequency image details based on local statistics in the up-scaled image. The HF restoration performance of the fuzzy based composite scheme is enhanced by improving its nonlinearity through the variations of different parameters of the fuzzy inference system (FIS) such as slope, width and the number of input-, and output membership functions. The effective fusion of pre-processing and post-processing operations makes the proposed scheme much effective to tackle the non-uniform blurring than the standalone pre-processing and post-processing techniques. Experimental results reveal that the proposed composite scheme gives much less blurring in comparison to the standalone schemes and performs better than most of the widely used interpolation schemes in terms of objective and subjective measures. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Acharya, Aditya; Meher, Sukadev] Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Acharya, A (corresponding author), Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Rourkela 769008, India.
EM aditya.acharya2011@gmail.com; sukadevmeher@gmail.com
RI Meher, Sukadev/AAW-2774-2020; Meher, Sukadev/O-4489-2017
OI Meher, Sukadev/0000-0003-4397-3139
CR Acharya A, 2013, P ANN IEEE INT C IND
   Acharya A, 2013, P IEEE INT C FUZZ SY
   Acharya A, 2015, P IEEE INT C EL EL S
   Acharya A, 2013, IJCA SPECIAL ISSUE E, P29
   Acharya A., 2015, P ANN IEEE INT C IND
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   [Anonymous], 2010, WORKSH REM SYS SRS 1
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Burger W., 2009, PRINCIPLES DIGITAL I, P231
   Chen MJ, 2005, IMAGE VISION COMPUT, V23, P791, DOI 10.1016/j.imavis.2005.05.005
   Cho MK, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2234736
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hung KW, 2013, INT CONF ACOUST SPEE, P1419, DOI 10.1109/ICASSP.2013.6637885
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Hung KW, 2010, IEEE IMAGE PROC, P3297, DOI 10.1109/ICIP.2010.5652082
   Ketan Tang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P66, DOI 10.1109/ICIG.2011.155
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee S. W., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P177, DOI 10.1109/ICASSP.1993.319776
   Lehmann TM, 2001, IEEE T MED IMAGING, V20, P660, DOI 10.1109/42.932749
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Lim H, 2011, IEEE T CIRC SYST VID, V21, P879, DOI 10.1109/TCSVT.2011.2133250
   Marta M., 2003, P EUROCON 03, P233
   Mukherjee J, 2002, IEEE T CIRC SYST VID, V12, P620, DOI 10.1109/TCSVT.2002.800509
   Ren J, 2011, IEEE IMAGE PROC, P1177, DOI 10.1109/ICIP.2011.6115639
   Sajjad M., 2013, MULTIMED TOOLS APPL, V74, P8961
   SMIT T, 1990, IEEE T ACOUST SPEECH, V38, P1512, DOI 10.1109/29.60071
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wong CS, 2010, EUR SIGNAL PR CONF, P309
   Wu ZY, 2010, IEEE SIGNAL PROC LET, V17, P827, DOI 10.1109/LSP.2010.2059700
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan C., 2013, P DAT COMPR C DCC JU
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang S, 2008, IEEE T CONSUM ELECTR, V54, P1761, DOI 10.1109/TCE.2008.4711232
   Yaroslavsky L. P., 1996, Bioimaging, V4, P225, DOI 10.1002/1361-6374(199612)4:4<225::AID-BIO1>3.0.CO;2-G
   Ye W, 2011, IEEE T IMAGE PROCESS, V19
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 39
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 156
EP 186
DI 10.1016/j.jvcir.2017.01.031
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600015
DA 2024-07-18
ER

PT J
AU Dong, X
   Zhang, HX
   Sun, JD
   Wan, WB
AF Dong, Xiao
   Zhang, Huaxiang
   Sun, Jiande
   Wan, Wenbo
TI A two-stage learning approach to face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Collaborative representation; Collaborative coefficient; Face
   recognition; Small sample size
ID REPRESENTATION
AB This paper introduces the Collaborative Representation (CR) techniques to small sample size conditions, and propose a Two-Stage learning approach to face recognition based on Collaborative Representation (TSCR). Based on the assumption that the same class samples should lie in the same subspace, we first use the unlabeled samples as dictionary atoms to construct each labeled sample, and obtain the collaborative coefficients by CR. The unlabeled sample with the largest collaborative coefficient is assigned the same class label as the reconstructed labeled sample, and is added to the labeled data set. This process is repeated until about half of the unlabeled samples are labeled and added to the labeled dataset. After that, we employ the original CR approach to classify the left unlabeled samples based on the newly labeled dataset. Experimental results demonstrate that the proposed TSCR is effective on face recognition. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Dong, Xiao; Zhang, Huaxiang; Sun, Jiande; Wan, Wenbo] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang; Sun, Jiande; Wan, Wenbo] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@hotmail.com
RI Sun, Jiande/B-4681-2018
OI Dong, Xiao/0000-0001-9519-612X
FU National Natural Science Foundation of China [61373081, 61572298,
   61402268, 61401260, 61601268]; Technology and Development Project of
   Shandong [2013GGX10125]; Natural Science Foundation of Shandong China
   [BS2014DX006, ZR2014FM012]; Taishan Scholar Project of Shandong, China
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61373081, 61572298, 61402268, 61401260,
   61601268), the Technology and Development Project of Shandong (No.
   2013GGX10125), the Natural Science Foundation of Shandong China (Nos.
   BS2014DX006, ZR2014FM012) and the Taishan Scholar Project of Shandong,
   China.
CR A. archive of AT&T Laboratories Cambridge, 2002, ORL FAC DAT
   [Anonymous], IEEE T NEURAL NETW L
   [Anonymous], ARXIV150200873
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Fana Z., 2014, NEUROCOMPUTING, V151, P304
   Feichtinger HG., 2012, GABOR ANAL ALGORITHM
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Huang Y., 2012, INT J ADV COMPUT TEC, V4, P59
   Hui KH, 2012, PATTERN RECOGN LETT, V33, P661, DOI 10.1016/j.patrec.2011.11.010
   Jolliffe I.T., 2008, PRINCIPAL COMPONENT
   Kim HC, 2002, INT C PATT RECOG, P486, DOI 10.1109/ICPR.2002.1048344
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Martinez A. M., 1998, THE AR FACE DATABASE
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zang F, 2012, NEUROCOMPUTING, V97, P267, DOI 10.1016/j.neucom.2012.03.017
   Zhang L., 2014, COMPUTER VISION PATT
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zizhu Fan, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P54, DOI 10.1109/SMARTCOMP.2014.7043839
NR 26
TC 14
Z9 14
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 21
EP 29
DI 10.1016/j.jvcir.2016.12.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400003
DA 2024-07-18
ER

PT J
AU Hamzah, RA
   Ibrahim, H
   Abu Hassan, AH
AF Hamzah, Rostam Affendi
   Ibrahim, Haidi
   Abu Hassan, Anwar Hasni
TI Stereo matching algorithm based on per pixel difference adjustment,
   iterative guided filter and graph segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Iterative guided filter; Disparity map; Gradient difference; Absolute
   difference; Undirected graph segmentation; Stereo matching algorithm
ID COST AGGREGATION; DISPARITY ESTIMATION; ACCURATE STEREO; REAL-TIME
AB Stereo matching process is a difficult and challenging task due to many uncontrollable factors that affect the results. These factors include the radiometric variations and illumination inconsistence. The absolute differences (AD) algorithms work fast, but they are too sensitive to noise and low textured areas. Therefore, this paper proposes an improved algorithm to overcome these limitations. First, the proposed algorithm utilizes per-pixel difference adjustment for AD and gradient matching to reduce the radiometric distortions. Then, both differences are combined with census transform to reduce the effect of illumination variations. Second, a new approach of iterative guided filter is introduced at cost aggregation to preserve and improve the object boundaries. The undirected graph segmentation is used at the last stage in order to smoothen the low textured areas. The experimental results on the standard indoor and outdoor datasets show that the proposed algorithm produces smooth disparity maps and accurate results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hamzah, Rostam Affendi; Ibrahim, Haidi; Abu Hassan, Anwar Hasni] Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
   [Hamzah, Rostam Affendi] Univ Teknikal Malaysia Melaka, Fac Engn Technol, Dept Elect & Comp Engn Technol, Durian Tunggal 76100, Melaka, Malaysia.
C3 Universiti Sains Malaysia; Universiti Teknologi Malaysia; University
   Teknikal Malaysia Melaka
RP Hamzah, RA (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM rostamaffendi@utem.edu.my
RI Ibrahim, Haidi/B-3131-2011; Hasni, Anwar/D-5416-2016; Hamzah, Rostam
   Affendi/AAK-8035-2020
OI Hamzah, Rostam Affendi/0000-0003-2940-1281
FU Universiti Sains Malaysia [PLD-0025/13(R)]; Universiti Teknikal Malaysia
   Melaka
FX This work was supported by Universiti Sains Malaysia (No:
   PLD-0025/13(R)) and Universiti Teknikal Malaysia Melaka.
CR Bethmann F, 2015, INT ARCH PHOTOGRAMM, V40-3, P23, DOI 10.5194/isprsarchives-XL-3-W2-23-2015
   Chen DM, 2015, IEEE T CIRC SYST VID, V25, P730, DOI 10.1109/TCSVT.2014.2361422
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Einecke N, 2013, IEEE INT VEH SYM, P189, DOI 10.1109/IVS.2013.6629469
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   Hamzah R. A., 2015, J SENSORS, P1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   Hosni A, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6012131
   Humenberger M., 2010, 2010 IEEE COMP SOC C, P77, DOI [10.1109/CVPRW.2010.5543769, DOI 10.1109/CVPRW.2010.5543769]
   Jin HQ, 2014, COMM COM INF SC, V483, P445
   Jinglin Zhang, 2013, 2013 Conference on Design and Architectures for Signal and Image Processing (DASIP), P209
   Kordelas GA, 2016, IEEE T MULTIMEDIA, V18, P155, DOI 10.1109/TMM.2015.2505905
   Kordelas GA, 2015, IMAGE VISION COMPUT, V35, P31, DOI 10.1016/j.imavis.2014.12.001
   Lee S, 2015, IMAGE VISION COMPUT, V37, P1, DOI 10.1016/j.imavis.2015.01.003
   Lee Z, 2013, IEEE T MULTIMEDIA, V15, P1855, DOI 10.1109/TMM.2013.2270456
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Mattoccia S, 2007, LECT NOTES COMPUT SC, V4844, P517
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Mei X, 2011, PROC CVPR IEEE, P1257
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Mozerov MG, 2015, IEEE T IMAGE PROCESS, V24, P1153, DOI 10.1109/TIP.2015.2395820
   Peng Y., 2015, 3 DIMENSIONAL IMAGE
   Ploumpis S, 2015, IMAGE VISION COMPUT, V38, P13, DOI 10.1016/j.imavis.2015.04.001
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Scharstein Daniel., MIDDLEBURY STEREO EV
   Sinha SN, 2014, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2014.205
   Stentoumis C, 2014, ISPRS J PHOTOGRAMM, V91, P29, DOI 10.1016/j.isprsjprs.2014.02.006
   Tan P, 2014, IMAGE PROCESS ON LIN, V4, P252, DOI 10.5201/ipol.2014.78
   Tan X., SIGNAL PROCESS IMAGE, V29
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Wang H, 2013, PROCEEDINGS OF THE 5TH (2013) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS I AND II, P1, DOI 10.1109/ijcnn.2013.6706812
   Wang XF, 2015, OPTIK, V126, P545, DOI 10.1016/j.ijleo.2015.01.002
   Wang YK, 2014, VISUAL COMPUT, V30, P1157, DOI 10.1007/s00371-013-0896-z
   Wenzel K, 2013, INT ARCH PHOTOGRAMM, V40-5-W1, P251
   Yang C, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P105, DOI 10.1145/2902961.2902995
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yao ZT, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ARTIFICIAL INTELLIGENCE (CAAI 2015), P1, DOI 10.1109/PESGM.2015.7285696
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang K, 2012, INT C PATT RECOG, P356
   Zhang K, 2011, IEEE T CIRC SYST VID, V21, P867, DOI 10.1109/TCSVT.2011.2133150
   Zheng GW, 2013, APPL MECH MATER, V411-414, P1305, DOI 10.4028/www.scientific.net/AMM.411-414.1305
   Zhou Y, 2015, OPTIK, V126, P1052, DOI 10.1016/j.ijleo.2015.01.030
   Zhu SB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION PROBLEM-SOLVING (ICCP), P1, DOI [10.1109/PVSC.2015.7355773, 10.1109/ICCPS.2015.7454074]
   Zhu SP, 2015, KSII T INTERNET INF, V9, P224, DOI 10.3837/tiis.2015.01.013
   Zhu SQ, 2016, J VIS COMMUN IMAGE R, V39, P107, DOI 10.1016/j.jvcir.2016.05.012
NR 53
TC 52
Z9 59
U1 0
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 145
EP 160
DI 10.1016/j.jvcir.2016.11.016
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200012
DA 2024-07-18
ER

PT J
AU Zou, J
   Lu, GF
   Zhang, Y
   Liu, CC
AF Zou, Jian
   Lu, Gui-Fu
   Zhang, Yue
   Liu, Chuancai
TI Generalizing intersection kernel support vector machines for color
   texture based recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Perceptual uniform color space; Component-adaptive color co-occurrence
   matrices (CACCMs); CCM intersection kernel support vector machines
   (CIKSVMs); Color texture based recognition
ID CLASSIFICATION; FACE; OBJECT; SPACES
AB This paper presents a novel recognition approach in which the component-adaptive color co-occurrence matrices (CACCMs) are designed to characterize color and texture cues in the images, while histogram intersection kernel support vector machines (HIKSVMs) are generalized to the version compatible to color co-occurrence matrix (CCM), called CCM intersection kernel support vector machines (CIKSVMs). An ensemble learning framework is proposed for synchronously training the optimal marginal CIKSVMs and corresponding CACCMs' extractors. This learning architecture is applicable to an arbitrary color space employed for image coding, while we pay utmost attention to a perceptual uniform color space for the prominent potential in image proprieties' display. For the formulation of recognition algorithm, the set of multi-channel CACCMs (CAMCMs) of per sample is utilized to get a balance between discriminative power and computational efficiency, while multiple marginal CIKSVMs are combined by weighted majority voting. The effectiveness of our approach is validated by promising results obtained from four experimental datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zou, Jian; Zhang, Yue] Anhui Polytech Univ, Sch Math & Phys, Wuhu 241000, Anhui, Peoples R China.
   [Lu, Gui-Fu] Anhui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.
   [Liu, Chuancai] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
C3 Anhui Polytechnic University; Anhui Polytechnic University; Nanjing
   University of Science & Technology
RP Zou, J (corresponding author), Anhui Polytech Univ, Sch Math & Phys, Wuhu 241000, Anhui, Peoples R China.
EM jzouzj@ahpu.edu.cn
FU National Natural Science Foundation of China [NSFC11401006,
   NSFC61203139]; Anhui Natural Science Foundation [KJ2016A064,
   1308085MF95]
FX This paper was partially supported by National Natural Science
   Foundation of China under Grants NSFC11401006 and NSFC61203139, and
   Anhui Natural Science Foundation Grants KJ2016A064 and 1308085MF95.
CR [Anonymous], 1998, STAT LEARNING THEORY
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Banerji S, 2013, NEUROCOMPUTING, V117, P173, DOI 10.1016/j.neucom.2013.02.014
   Barilla M. E., 2001, P 5 ICEECS 2008 MEX, P358
   Barla A., P ICIP 2003, V3
   Bianconi F, 2012, EXPERT SYST APPL, V39, P11212, DOI 10.1016/j.eswa.2012.03.052
   Bianconi F, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3651210
   Bramao I, 2011, ACTA PSYCHOL, V138, P244, DOI 10.1016/j.actpsy.2011.06.010
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Didyk P., 2011, THESIS
   Drimbarean A, 2001, PATTERN RECOGN LETT, V22, P1161, DOI 10.1016/S0167-8655(01)00058-7
   El Maliani AD, 2014, J VIS COMMUN IMAGE R, V25, P1717, DOI 10.1016/j.jvcir.2014.06.004
   Genton MG, 2002, J MACH LEARN RES, V2, P299, DOI 10.1162/15324430260185646
   Hadid A, 2015, PATTERN RECOGN LETT, V68, P231, DOI 10.1016/j.patrec.2015.04.017
   Hongxun Z, 2006, LECT NOTES COMPUT SC, V4223, P887
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Kuncheva L.I., 2014, COMBINING PATTERN CL
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Losson O, 2013, COMPUT VIS IMAGE UND, V117, P747, DOI 10.1016/j.cviu.2013.03.001
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Niskanen M., 2008, P 12 SCIA BERG NORW, P336
   Odone F, 2005, IEEE T IMAGE PROCESS, V14, P169, DOI 10.1109/TIP.2004.840701
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Paris S, 2015, ADV INTELL SYST, V318, P191, DOI 10.1007/978-3-319-12610-4_12
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Pietikainen M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P833, DOI 10.1109/ICPR.1996.547285
   Qazi IUH, 2011, PATTERN RECOGN, V44, P16, DOI 10.1016/j.patcog.2010.07.007
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Quan YH, 2014, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2014.28
   Raafat HM, 2011, APPL SOFT COMPUT, V11, P3608, DOI 10.1016/j.asoc.2011.01.032
   ROBERTSON PK, 1988, IEEE COMPUT GRAPH, V8, P50, DOI 10.1109/38.7761
   ROSENFELD A, 1982, IEEE T SYST MAN CYB, V12, P79
   Ryan MJ, 2013, ANNU REV ECOL EVOL S, V44, P437, DOI 10.1146/annurev-ecolsys-110512-135901
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Sharma Gokarna., 2013, Algorithmica, P1
   Symon D. O. C., 1996, B152TT U BRIM SCH CO
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Vinay A, 2015, PROCEDIA COMPUT SCI, V57, P960, DOI 10.1016/j.procs.2015.07.493
   Vinay A, 2015, PROCEDIA COMPUT SCI, V57, P650, DOI 10.1016/j.procs.2015.07.434
   Wu CY, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P379, DOI 10.1109/FSKD.2007.355
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zheng ZL, 2007, SIGNAL PROCESS, V87, P2473, DOI 10.1016/j.sigpro.2007.03.006
NR 49
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 1
EP 14
DI 10.1016/j.jvcir.2016.08.018
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000001
DA 2024-07-18
ER

PT J
AU Feng, LB
   Lv, ZH
AF Feng, Liangbing
   Lv, Zhihan
TI Plane surface detection and reconstruction using segment-based tensor
   voting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tensor voting; Multi-view stereo; 3D reconstruction; Image segmentation
ID FEATURE-SELECTION; IMAGE; RECOGNITION
AB A Segment-based Tensor Voting (SBTV) algorithm is presented for planar surface detection and reconstruction of man-made objects. Our work is inspired by piecewise planar stereo reconstruction. During the vital procedure to detect and label the planar surface, the two main contributions are: first, tensor voting is used for obtaining the geometry attribute of the 3D points cloud. The candidate planar patches are generated through scene image segment of low variation of color and intensity. Second, we over segment the scene image into the segment and the candidate 3D planar patch is generated. The SBTV algorithm is used on 3D points cloud sets to identify the co-plane on the candidate patch. After detecting every planar patch, the geometry architecture of object is obtained. The experiments demonstrate the effectiveness of our proposed approach on either outdoor or indoor datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Feng, Liangbing; Lv, Zhihan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Feng, Liangbing] Guiling Univ Elect Technol, Guiling, Guangxi, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Guilin University of Electronic Technology
RP Lv, ZH (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM Ivzhihan@gmail.com
RI Lv, Zhihan/GLR-6000-2022; Lyu, Zhihan/I-3187-2014
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074
CR Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Kowdle A, 2011, PROC CVPR IEEE, P929, DOI 10.1109/CVPR.2011.5995638
   Medioni G, 2012, IEEE T PATTERN ANAL, V34, P1482, DOI [10.1109/TPAMI.2011.250, DOI 10.1109/TPAMI.2011.250]
   Medioni G., 2000, COMPUTATIONAL FRAMEW
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Wang Wei, 2015, P 5 ACM INT C MULT R
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2014, IEEE IMAGE PROC, P1071, DOI 10.1109/ICIP.2014.7025213
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Zebedin L, 2008, LECT NOTES COMPUT SC, V5305, P873, DOI 10.1007/978-3-540-88693-8_64
   Zhang LM, 2016, IEEE T AUTOM SCI ENG, V13, P894, DOI 10.1109/TASE.2015.2418223
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P1538, DOI 10.1109/TMM.2015.2451954
   Zhang Luming, 2015, P 23 ACM INT C MULT
NR 22
TC 4
Z9 5
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 831
EP 837
DI 10.1016/j.jvcir.2016.08.012
PN B
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600036
DA 2024-07-18
ER

PT J
AU Zhang, QB
   Lu, W
   Weng, J
AF Zhang, Qingbo
   Lu, Wei
   Weng, Jian
TI Joint image splicing detection in DCT and Contourlet transform domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image splicing detection; Discrete cosine transform; Contourlet
   transform; Markov features; Ensemble classifier
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION
AB Splicing is a fundamental and popular image forgery method and image splicing detection is urgently called for digital image forensics recently. In this paper, a Markov based approach is proposed to detect image splicing. The paper applies the Markov model in the block discrete cosine transform (DOT) domain and the Contourlet transform domain. First, the original Markov features of the inter-block between block DOT coefficients are improved by considering the different frequency ranges of each block DOT coefficients. Then, additional features are extracted in Contourlet transform domain to characterize the dependency of positions among Contourlet subband coefficients. And these features are extracted from single color channel for gray image while extracted from three color channels for color image. Finally, Support Vector Machines (SVMs) are exploited to classify the authentic and spliced images for the gray image dataset while ensemble classifier to the color image dataset. The experiment results demonstrate that the proposed detection scheme outperforms some state-of-the-art methods when applied to Columbia Image Splicing Detection Evaluation Dataset (DVMM), and ranks fourth in phase 1 on the Live Ranking of the first Image Forensics Challenge. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Qingbo; Lu, Wei] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Weng, Jian] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Jinan University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM zhangqb3@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   cryptjweng@gmail.com
OI Weng, Jian/0000-0003-4067-8230
FU Natural Science Foundation of Guangdong [2016A030313350]; Special Funds
   for Science and Technology Development of Guangdong [2016KZ010103];
   Fundamental Research Funds for the Central Universities [161gjc83]
FX The authors would like to thank the anonymous reviewers for their
   comments that greatly improve the manuscript. This work is supported by
   the Natural Science Foundation of Guangdong (No. 2016A030313350), the
   Special Funds for Science and Technology Development of Guangdong (No.
   2016KZ010103), and the Fundamental Research Funds for the Central
   Universities (No. 161gjc83).
CR [Anonymous], 2011, P SPIE INT SOC OPT E
   [Anonymous], 2004, 20320043 COL U
   Bahrami Khosro, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2654, DOI 10.1109/ICASSP.2014.6854081
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bahrami K, 2013, IEEE INT WORKS INFOR, P144, DOI 10.1109/WIFS.2013.6707809
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chang C., 2010, LIBSVM: A library for support vector machines 2010
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P158, DOI 10.1109/ICIP.2001.958075
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Granty Regina Elwin J., 2010, Proceedings of the 2010 International Conference on Communication and Computational Intelligence (INCOCCI), P431
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lu W, 2011, ENG APPL ARTIF INTEL, V24, P666, DOI 10.1016/j.engappai.2011.01.002
   Luo Weiqi, 2007, Frontiers of Computer Science in China, V1, P166, DOI 10.1007/s11704-007-0017-0
   Panchal UH, 2015, INT CONF COMM SYST, P591, DOI 10.1109/CSNT.2015.165
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Rao MP, 2014, IEEE T INF FOREN SEC, V9, P583, DOI 10.1109/TIFS.2014.2302895
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Shi YQ, 2008, LECT NOTES COMPUT SC, V5041, P158
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Vyas C, 2014, IEEE INT C COMPUTATI, P1
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
NR 35
TC 45
Z9 53
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 449
EP 458
DI 10.1016/j.jvcir.2016.07.013
PN B
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600005
DA 2024-07-18
ER

PT J
AU Lin, CY
   Muchtar, K
   Yeh, CH
AF Lin, Chih-Yang
   Muchtar, Kahlil
   Yeh, Chia-Hung
TI Robust techniques for abandoned and removed object detection based on
   Markov random field
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Abandoned object detection; Background modelling; GMM; Markov random
   field
AB This paper presents a novel framework for detecting abandoned objects by introducing a fully-automatic GrabCut object segmentation. GrabCut seed initialization is treated as a background (BG) modelling problem that focuses only on unhanded objects and objects that become immobile. The BG distribution is constructed with dual Gaussian mixtures that are comprised of high and low learning rate models. We propose a primitive BG model-based removed object validation and Haar feature-based cascade classifier for still-people detection once a candidate for a released object has been detected. Our system can obtain more robust and accurate results for real environments based on evaluations of realistic scenes from CAVIAR, PETS2006, CDnet 2014, and our own datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lin, Chih-Yang] Asia Univ, Dept Bioinformat & Med Engn, Taichung, Taiwan.
   [Lin, Chih-Yang] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
   [Muchtar, Kahlil; Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Asia University Taiwan; China Medical University Taiwan; China Medical
   University Hospital - Taiwan; National Sun Yat Sen University
RP Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
EM yeh@mail.ee.nsysu.edu.tw
RI Muchtar, Kahlil/P-8532-2019; Lin, Chih-Yang/HOF-2583-2023
OI Muchtar, Kahlil/0000-0001-5740-1938; Lin, Chih-Yang/0000-0002-0401-8473
FU National Science Council Taiwan [MOST 103-2221-E-468-007-MY2, MOST
   103-2221-E-110-045-MY3, NSC 102-2221-E-110-032-MY3]
FX This work was supported by National Science Council Taiwan, under Grants
   MOST 103-2221-E-468-007-MY2, MOST 103-2221-E-110-045-MY3, and NSC
   102-2221-E-110-032-MY3.
CR Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Caro Campos Luis, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P101, DOI 10.1109/AVSS.2011.6027302
   De Gregorio M, 2014, IEEE COMPUT SOC CONF, P409, DOI 10.1109/CVPRW.2014.66
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferryman J, 2013, PATTERN RECOGN LETT, V34, P789, DOI 10.1016/j.patrec.2013.01.018
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Goyette N, 2014, IEEE T IMAGE PROCESS, V23, P4663, DOI 10.1109/TIP.2014.2346013
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin CY, 2013, INT J INNOV COMPUT I, V9, P1373
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Park D, 2013, PATTERN RECOGN, V46, P1985, DOI 10.1016/j.patcog.2012.12.013
   Porikli F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/197875
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sajid H., 2015, INT C IM PROC ICIP Q
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tian YL, 2011, IEEE T SYST MAN CY C, V41, P565, DOI 10.1109/TSMCC.2010.2065803
   Varadarajan S, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P63, DOI 10.1109/AVSS.2013.6636617
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang B, 2014, IEEE COMPUT SOC CONF, P401, DOI 10.1109/CVPRW.2014.64
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 27
TC 5
Z9 6
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 181
EP 195
DI 10.1016/j.jvcir.2016.05.024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900018
DA 2024-07-18
ER

PT J
AU García, J
   Martinel, N
   Gardel, A
   Bravo, I
   Foresti, GL
   Micheloni, C
AF Garcia, Jorge
   Martinel, Niki
   Gardel, Alfredo
   Bravo, Ignacio
   Foresti, Gian Luca
   Micheloni, Christian
TI Modeling feature distances by orientation driven classifiers for person
   re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Pose and orientation recovery; Appearance
   models; Surveillance systems; Scene understanding; Tracking; Feature
   transformation; Dissimilarity learning
ID CLASSIFICATION; TRACKING
AB To tackle the re-identification challenges existing methods propose to directly match image features or to learn the transformation of features that undergoes between two cameras. Other methods learn optimal similarity measures. However, the performance of all these methods are strongly dependent from the person pose and orientation. We focus on this aspect and introduce three main contributions to the field: (i) to propose a method to extract multiple frames of the same person with different orientations in order to capture the complete person appearance; (ii) to learn the pairwise feature dissimilarities space (PFDS) formed by the subspaces of similar and different image pair orientations; and (iii) within each subspace, a classifier is trained to capture the multi-modal inter-camera transformation of pairwise image dissimilarities and to discriminate between positive and negative pairs. The experiments show the superior performance of the proposed approach with respect to state-of-the-art methods using two publicly available benchmark datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Garcia, Jorge; Gardel, Alfredo; Bravo, Ignacio] Univ Alcala de Henares, Dept Elect, Alcala De Henares 28801, Spain.
   [Martinel, Niki; Foresti, Gian Luca; Micheloni, Christian] Univ Udine, Dept Math & Comp Sci, I-33100 Udine, Italy.
C3 Universidad de Alcala; University of Udine
RP Micheloni, C (corresponding author), Univ Udine, Dept Math & Comp Sci, I-33100 Udine, Italy.
EM jorge.garcia@depeca.uah.es; niki.martinel@uniud.it;
   alfredo@depeca.uah.es; ibravo@depeca.uah.es; gianluca.foresti@uniud.it;
   christian.micheloni@uniud.it
RI Micheloni, Christian/E-5427-2012; GARDEL, ALFREDO/R-5727-2016;
   Esparteiro Garcia, Jorge/C-7694-2016; Bravo, Ignacio/R-6344-2016
OI GARDEL, ALFREDO/0000-0001-7887-4689; Bravo, Ignacio/0000-0002-6964-0036;
   Garcia, Jorge/0000-0001-7174-2827; Micheloni,
   Christian/0000-0003-4503-7483
FU University of Alcala through the project "Identificacion de Personas a
   partir de la Reconstruccion de Imagenes Multiples" (IPRIM)
   [CCG2013/EXP-064]
FX This work is partially supported by University of Alcala through the
   project "Identificacion de Personas a partir de la Reconstruccion de
   Imagenes Multiples" (IPRIM) with Ref.: CCG2013/EXP-064.
CR An L, 2016, IEEE T CIRC SYST VID, V26, P776, DOI 10.1109/TCSVT.2015.2416561
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], ADV VIDEO SIGNAL BAS
   [Anonymous], PROCEEDINGS OF THE B
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], INT C COMP VIS
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], INT C COMP VIS
   [Anonymous], PATTERN RECOG
   [Anonymous], 2015, INT C COMP VIS PATT
   [Anonymous], 2015, INT C COMP VIS PATT
   [Anonymous], BMVC06
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE SIGNAL PROCESS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2014, ICDSC
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], ECCV WORKSH DEM
   [Anonymous], INF SCI
   [Anonymous], 2012, DICTA
   [Anonymous], 2010, Asian Conference on Computer Vision
   Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38
   Bak S, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P175, DOI 10.1109/AVSS.2014.6918664
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Baltieri D, 2015, INT J COMPUT VISION, V111, P345, DOI 10.1007/s11263-014-0747-z
   Chen TH, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P129, DOI 10.1109/AVSS.2007.4425298
   Gabran W, 2013, IEEE ICC
   García J, 2014, INT C PATT RECOG, P4618, DOI 10.1109/ICPR.2014.790
   García J, 2013, IEEE T SYST MAN CY-S, V43, P606, DOI 10.1109/TSMCA.2012.2220540
   Guanwen Zhang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P677, DOI 10.1007/978-3-642-37431-9_52
   Hirzer M, 2012, IEEE IMAGE PROC, P1617, DOI 10.1109/ICIP.2012.6467185
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li AN, 2015, IEEE T CIRC SYST VID, V25, P869, DOI 10.1109/TCSVT.2014.2352552
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Lin Z, 2008, LECT NOTES COMPUT SC, V5358, P23, DOI 10.1007/978-3-540-89639-5_3
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Martinel N., 2012, 2012 IEEE COMPUTER S, P31, DOI 10.1109/CVPRW.2012.6239203
   Martinel N., 2013, INT C DISTRIBUTED SM, P1, DOI [10.1109/ICDSC.2013.6778209., DOI 10.1109/ICDSC.2013.6778209.]
   Martinel N, 2016, PATTERN RECOGN LETT, V71, P23, DOI 10.1016/j.patrec.2015.11.022
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Martinel N, 2015, IEEE SIGNAL PROC LET, V22, P455, DOI 10.1109/LSP.2014.2362573
   Martinel N, 2014, IEEE T SYST MAN CY-S, V44, P653, DOI 10.1109/TSMC.2013.2279661
   Micheloni C, 2009, J VISUAL LANG COMPUT, V20, P353, DOI 10.1016/j.jvlc.2009.01.008
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   SanMiguel JC, 2014, COMPUTER, V47, P67, DOI 10.1109/MC.2014.133
   Tao DP, 2015, IEEE T CYBERNETICS, V45, P242, DOI 10.1109/TCYB.2014.2323992
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu YL, 2013, IEEE I CONF COMP VIS, P3152, DOI 10.1109/ICCV.2013.391
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhou HY, 2010, ELMAR PROC, P33
   Zhou HY, 2010, NEUROCOMPUTING, V73, P1718, DOI 10.1016/j.neucom.2009.09.022
NR 71
TC 24
Z9 25
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 115
EP 129
DI 10.1016/j.jvcir.2016.02.009
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ha, J
   Jeong, H
AF Ha, Jeongmok
   Jeong, Hong
TI A fast scanning based message receiving method on four directed acyclic
   subgraphs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Markov random fields; Labeling problem; Fast inference method; Graphical
   model; Directed acyclic graph
ID ENERGY MINIMIZATION; IMAGE; SEGMENTATION; RESTORATION; SINGLE; MODEL;
   CUTS
AB We propose a message-receiving algorithm on a Directed Acyclic Subgraph (DAS) structure to approximate the solution of general labeling problems extremely quickly. The algorithm divides a graph into four subgraphs to get a joint distribution of all nodes, then passes messages in two fixed directions as inference on DASs. Message receiving is a modified version of message passing. When receiving messages on DAS structure, labeling results can be obtained after just four scans. The proposed algorithm was evaluated by using it to perform three labeling decision applications (binary segmentation, image denoising, and stereo matching). Compared to other highly-accurate iterative algorithms (alpha-expansion, alpha-beta swap, tree-reweighted message passing, sum-product belief propagation, max-product belief propagation, and FastPD), the proposed algorithm shows competitive accuracy but requires much less computational time. The proposed algorithm is appropriate for applications in which iterative schemes are undesirable, but which must get reliable labeling results within a limited time. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ha, Jeongmok; Jeong, Hong] Pohang Univ Sci & Technol, Dept Elect Engn, Pohang, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Ha, J (corresponding author), Pohang Univ Sci & Technol, Dept Elect Engn, Pohang, South Korea.
EM jmokha@postech.ac.kr
RI Jeong, Hong/JVY-8760-2024
OI Jeong, Hong/0000-0001-8464-6033
FU Ministry of Education (MOE); National Research Foundation of Korea (NRF)
   through the Human Resource Training Project for Regional Innovation
FX This work was supported by the Ministry of Education (MOE) and National
   Research Foundation of Korea (NRF) through the Human Resource Training
   Project for Regional Innovation.
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 1980, Markov Random Fields and Their Applications, volume 1 of Contemporary Mathematics
   Bang-Jensen J, 2009, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-1-84800-998-1_1
   BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466
   Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boyle, 2014, CENGAGE LEARNING
   Chen QF, 2014, PROC CVPR IEEE, P3914, DOI 10.1109/CVPR.2014.500
   Chen SY, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/814356
   Christofides N., 1975, AN ALGORITHMIC APPRO
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   DAGUM P, 1993, ARTIF INTELL, V60, P141, DOI 10.1016/0004-3702(93)90036-B
   Díaz J, 2006, IEEE T CIRC SYST VID, V16, P274, DOI 10.1109/TCSVT.2005.861947
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Ha J., 2015, 22 IEEE INT C IM PRO
   Ha J, 2014, LECT NOTES COMPUT SC, V8887, P815, DOI 10.1007/978-3-319-14249-4_78
   Jensen F.V., 1996, INTRO BAYESIAN NETWO, V210
   Jeong H, 2014, ARCHITECTURES FOR COMPUTER VISION: FROM ALGORITHM TO CHIP WITH VERILOG, P1, DOI 10.1002/9781118659199
   Jin S, 2010, IEEE T CIRC SYST VID, V20, P15, DOI 10.1109/TCSVT.2009.2026831
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Komodakis N., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007
   Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061
   Kuon I, 2007, FOUND TRENDS ELECTRO, V2, P135, DOI 10.1561/1000000005
   Li S. Z., 2009, Markov random field modeling in image analysis
   Mei X, 2011, PROC CVPR IEEE, P1257
   Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Park SC, 2008, OPT LETT, V33, P74, DOI 10.1364/OL.33.000074
   Park S, 2007, LECT NOTES COMPUT SC, V4599, P55, DOI 10.1007/978-3-540-73625-7_8
   Park S, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P751
   Park S, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-4
   Pauwels K, 2012, IEEE T COMPUT, V61, P999, DOI 10.1109/TC.2011.120
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stein F, 2004, LECT NOTES COMPUT SC, V3175, P79
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Van Leeuwen J., 1990, HDB THEORETICAL COMP, V137
   VANLEEUWEN J, 1990, HDB THEORETICAL COMP, VB
   Veksler O, 2005, PROC CVPR IEEE, P384
   Vineet Vibhav, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563095
   Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938
   Yang Q., 2006, P 17 BRIT MACHINE VI, P989
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 56
TC 2
Z9 2
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 161
EP 174
DI 10.1016/j.jvcir.2016.02.014
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100014
DA 2024-07-18
ER

PT J
AU Pattanaworapan, K
   Chamnongthai, K
   Guo, JM
AF Pattanaworapan, Kanjana
   Chamnongthai, Kosin
   Guo, Jing-Ming
TI Signer-independence finger alphabet recognition using discrete wavelet
   transform and area level run lengths
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sign language recognition; Finger alphabet recognition; Discrete wavelet
   transform; Sign grouping; Signer independence; Run length algorithm;
   Sign speaking system
ID CLASSIFICATION; SYSTEM
AB This paper proposes a method for finger alphabet recognition from backhand images with signer independence. Input images that are divided into fist sign and non-fist sign groups should be analyzed and processed in different ways. Finger alphabets in the fist group are represented by a one-dimensional signal that represents the external hand boundaries. Its low and high frequency components are then extracted by discrete wavelet transform, which are key features for recognition. The non-fist sign images, which are radically digitized into a 20 x 20 block mask in terms of the hand geometry, due to the hand's physical structure, can be recognized by the patterns of the occupied blocks. The experimental results show that the proposed method has a high likelihood of differentiating twenty-three static finger alphabets of backhand images. The proposed method reaches an improvement of 27.86% in recognition accuracy on a significant dataset of fist signs that includes multiple users, while the statistical distribution of the area level run length algorithm outperforms previous forehand approaches by 89.38% in recognition accuracy. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pattanaworapan, Kanjana; Chamnongthai, Kosin] King Mongkuts Univ Technol Thonburi, Fac Engn, Dept Elect & Telecommun Engn, 126 Pracha Uthit Rd, Bangkok 10140, Thailand.
   [Guo, Jing-Ming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, 43,Sect 4,Jilong Rd, Taipei 10607, Taiwan.
C3 King Mongkuts University of Technology Thonburi; National Taiwan
   University of Science & Technology
RP Chamnongthai, K (corresponding author), King Mongkuts Univ Technol Thonburi, Fac Engn, Dept Elect & Telecommun Engn, 126 Pracha Uthit Rd, Bangkok 10140, Thailand.
EM kanjana.pa@bu.ac.th; kosin.cha@kmutt.ac.th; jmguo@seed.net.tw
RI Chamnongthai, Kosin/AEX-9479-2022
OI Chamnongthai, Kosin/0000-0003-1509-5754
FU Bangkok University, Thailand
FX The financial support provided by Bangkok University, Thailand, faculty
   department program scholarship, for the first author is gratefully
   acknowledged.
CR Allen JM, 2003, PROCEEDINGS OF THE IEEE 29TH ANNUAL NORTHEAST BIOENGINEERING CONFERENCE, P285
   Amin MA, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2218
   [Anonymous], 2010, BIOMEDICAL IMAGING
   [Anonymous], ICPR2004
   [Anonymous], IEEE AS PAC C CIRC S
   [Anonymous], 3D MODEL BASED HAND
   [Anonymous], P 13 INT S COMM INF
   [Anonymous], INT C MULT EXP ICME
   [Anonymous], WCE 13
   [Anonymous], THESIS U TASMANIA
   [Anonymous], IEEE T BIOMED ENG
   [Anonymous], 19900312 CDR TR STAN
   [Anonymous], INT WORKSH ADV IM TE
   [Anonymous], IEEE T SYST MAN CYBE
   [Anonymous], 4 IASTED INT C VIS I
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], INT J MECH IND ENG I
   [Anonymous], IPCV 12
   [Anonymous], P INT C SYST MAN CYB
   [Anonymous], FRONTIERS INFORM TEC
   [Anonymous], P WORKSH INT GEST LA
   [Anonymous], HEAR IMP HEAR LOSS
   [Anonymous], IMTC 07
   [Anonymous], ADAS CAR FUTURE DESI
   [Anonymous], 35 EL ENG C DEC
   [Anonymous], EXPERT SYST APPL
   [Anonymous], CESAR SHAPE CLASSIFI
   [Anonymous], IEEE T SYST MAN CYBE
   Bin L., 2012, IOSR Journal of Computer Engineering (IOSRJCE), V2, P1
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Flasinski M, 2010, PATTERN RECOGN, V43, P2249, DOI 10.1016/j.patcog.2010.01.004
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Handouyahia M., 1999, Proceedings Vision Interface '99, P210
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Krishnaveni M, 2011, COMM COM INF SC, V204, P414
   Lamari M. V., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P2839, DOI 10.1109/IJCNN.1999.833533
   Lien CC, 1998, IMAGE VISION COMPUT, V16, P121, DOI 10.1016/S0262-8856(97)00041-3
   MacLean J, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P133, DOI 10.1109/RATFG.2001.938922
   Malima A., 2006, SIGNAL PROCESS COMMU, P1
   Marnik J, 2007, ADV INTEL SOFT COMPU, V45, P454
   Munib Q, 2007, EXPERT SYST APPL, V32, P24, DOI 10.1016/j.eswa.2005.11.018
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Santos RB, 2013, CHEM ENGINEER TRANS, V32, P1375, DOI 10.3303/CET1332230
   Shen Liqin, 1994, ISSIPNN '94. 1994 International Symposium on Speech, Image Processing and Neural Networks Proceedings (Cat. No.94TH0638-7), P37, DOI 10.1109/SIPNN.1994.344971
   Sifuzzaman M., 2009, J PHYSIOL SCI, V13, P121
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Svozil D, 1997, CHEMOMETR INTELL LAB, V39, P43, DOI 10.1016/S0169-7439(97)00061-0
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Uras C, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P711
   Yin XM, 2007, IMAGE VISION COMPUT, V25, P1291, DOI 10.1016/j.imavis.2006.08.003
   Zhuang J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2342, DOI 10.1109/ICAL.2008.4636559
NR 57
TC 20
Z9 20
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 658
EP 677
DI 10.1016/j.jvcir.2016.04.015
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100056
DA 2024-07-18
ER

PT J
AU Wang, XY
   Liang, LL
   Li, WY
   Li, DM
   Yang, HY
AF Wang, Xiang-Yang
   Liang, Lin-Lin
   Li, Wei-Yi
   Li, Dong-Ming
   Yang, Hong-Ying
TI A new SVM-based relevance feedback image retrieval using probabilistic
   feature and weighted kernel function
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Relevance feedback; Support vector
   machine; Adapted Gaussian mixture models; Kernel function weighting
ID SUPPORT VECTOR MACHINES
AB Relevance feedback (RF) is an effective approach to bridge the gap between low-level visual features and high-level semantic meanings in content-based image retrieval (CBIR). The support vector machine (SVM) based RF mechanisms have been used in different fields of image retrieval, but they often treat all positive and negative feedback samples equally, which will inevitably degrade the effectiveness of SVM-based RF approaches for CBIR. In fact, positive and negative feedback samples, different positive feedback samples, and different negative feedback samples all always have distinct properties. Moreover, each feedback interaction process is usually tedious and time-consuming because of complex visual features, so if too many times of iteration of feedback are asked, users may be impatient to interact with the CBIR system. To overcome the above limitations, we propose a new SVM-based RF approach using probabilistic feature and weighted kernel function in this paper. Firstly, the probabilistic features of each image are extracted by using principal components analysis (PCA) and the adapted Gaussian mixture models (AGMM) based dimension reduction, and the similarity is computed by employing Kullback-Leibler divergence. Secondly, the positive feedback samples and negative feedback samples are marked, and all feedback samples' weight values are computed by utilizing the samples-based Relief feature weighting. Finally, the SVM kernel function is modified dynamically according to the feedback samples' weight values. Extensive simulations on large databases show that the proposed algorithm is significantly more effective than the state-of-the-art approaches. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Xiang-Yang; Liang, Lin-Lin; Li, Wei-Yi; Li, Dong-Ming; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Liang, Li-Lin/AAB-3538-2022; Yang, Jing/JFK-4046-2023
OI Liang, Li-Lin/0000-0002-1585-9067; Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61472171, 61272416];
   Liaoning Research Project for Institutions of Higher Education of China
   [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472171 & 61272416, and Liaoning Research Project
   for Institutions of Higher Education of China under Grant No. L2013407.
CR [Anonymous], 2013, Handbook on neural information processing
   [Anonymous], ACM INT C IM VID RET
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Chang YC, 2006, IEEE T EVOLUT COMPUT, V10, P617, DOI 10.1109/TEVC.2005.863130
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hoo W.L., 2014, 22 INT C PATT REC IC
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huang SH, 2006, MULTIMEDIA SYST, V12, P14, DOI 10.1007/s00530-006-0028-y
   Kaczmarek AL, 2011, IEEE T IND ELECTRON, V58, P3168, DOI 10.1109/TIE.2010.2045315
   Kim DH, 2008, J SYST SOFTWARE, V81, P1525, DOI 10.1016/j.jss.2007.10.006
   Lee HY, 2013, IEEE T AUDIO SPEECH, V21, P1272, DOI 10.1109/TASL.2013.2248721
   Lei Z, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P721, DOI 10.1109/ICIP.2001.958595
   Li G., 2013, LECT NOTES ELECT ENG, V212, P429
   Liu DZ, 2009, IEEE T KNOWL DATA EN, V21, P729, DOI 10.1109/TKDE.2008.188
   Liu R, 2008, PATTERN RECOGN, V41, P2645, DOI 10.1016/j.patcog.2008.01.023
   Malegaonkar AS, 2007, IEEE T AUDIO SPEECH, V15, P1859, DOI 10.1109/TASL.2007.896665
   Marakakis A, 2011, IET IMAGE PROCESS, V5, P531, DOI 10.1049/iet-ipr.2009.0402
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Nguyen NV, 2012, J AMB INTEL HUM COMP, V3, P281, DOI 10.1007/s12652-012-0141-z
   Okabe M, 2007, IEEE T KNOWL DATA EN, V19, P1585, DOI 10.1109/TKDE.2007.190646
   Ozer S, 2011, PATTERN RECOGN, V44, P1435, DOI 10.1016/j.patcog.2010.12.017
   Papadopoulos GT, 2014, IEEE T MULTIMEDIA, V16, P440, DOI 10.1109/TMM.2013.2291535
   Pernkopf F, 2005, IEEE T PATTERN ANAL, V27, P1344, DOI 10.1109/TPAMI.2005.162
   Rahman MM, 2011, INFORM PROCESS MANAG, V47, P676, DOI 10.1016/j.ipm.2010.12.001
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Singh S.R., 2013, KNOWLEDGE DISCOVERY
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Sun YJ, 2007, IEEE T PATTERN ANAL, V29, P1035, DOI 10.1109/TPAMI.2007.1093
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang XY, 2014, NEUROCOMPUTING, V127, P214, DOI 10.1016/j.neucom.2013.08.007
   Wang Y, 2006, KNOWL-BASED SYST, V19, P696, DOI 10.1016/j.knosys.2006.05.005
   Weerkamp W, 2012, ACM T WEB, V6, DOI 10.1145/2382616.2382621
   Wu J, 2013, PATTERN RECOGN, V46, P2927, DOI 10.1016/j.patcog.2013.04.008
   Wu Y, 2000, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2000.855823
   Xu C, 2015, AAAI CONF ARTIF INTE, P1924
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Zagoris K, 2011, J VIS COMMUN IMAGE R, V22, P378, DOI 10.1016/j.jvcir.2011.03.002
   Zangooei MH, 2012, KNOWL-BASED SYST, V27, P424, DOI 10.1016/j.knosys.2011.11.002
   Zhang LN, 2014, IEEE T CIRC SYST VID, V24, P346, DOI 10.1109/TCSVT.2013.2276172
NR 47
TC 24
Z9 28
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 256
EP 275
DI 10.1016/j.jvcir.2016.03.008
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100022
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Cao, HH
   Jiang, HX
   Li, B
AF Zhang, Yongfei
   Cao, Haiheng
   Jiang, Hongxu
   Li, Bo
TI Memory-efficient high-speed VLSI implementation of multi-level discrete
   wavelet transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DWT; Multi-level; VLSI; Memory efficient; High speed
ID HIGH-PERFORMANCE; ARCHITECTURE
AB Memory requirements and critical path are essential for 2-D Discrete Wavelet Transform (DWT). In this paper, we address this problem and develop a memory-efficient high-speed architecture for multi-level two-dimensional DWT. First, dual data scanning technique is first adopted in 2-D 9/7 DWT processing unit to perform lifting operations, which doubles the throughputs per cycle. Second, for 2-D DWT architecture, the proposed Row Transform Unit and Column Transform Unit take advantage of input sample availabilities and provision computing resources accordingly to optimize the processing speed, in which the number of processors is further optimized to significantly reduce the hardware cost. Third, to address the problem of high cost of memory for the immediate computing results from each level and the computation time as resolution level increases, multiple proposed 2-D DWT units were combined to build a parallel multi-level architecture, which can perform up to six levels of 2-D DWT in a resolution level parallel way on any arbitrary image size at competitive hardware cost. Experimental results demonstrated that the proposed scheme achieves improved hardware performance with significantly reduced on-chip memory resource and computational time, which outperforms the-state-of-the-art schemes and makes it desirable in memory-constrained real-time application systems. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Yongfei; Cao, Haiheng; Jiang, Hongxu; Li, Bo] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhang, Yongfei; Jiang, Hongxu; Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, YF (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM yfzhang@buaa.edu.cn
RI Li, bo/IWL-9318-2023; Li, Bo/AAA-8968-2020; Jiang, Hongxu/GRY-0379-2022;
   Zhang, Yongfei/A-1505-2010
OI Li, Bo/0000-0002-7294-6888; Zhang, Yongfei/0000-0002-5080-1733
FU National Hi-Tech Research and Development Program (863 Program) of China
   [2014AA015102]; National Natural Science Foundation of China [61272502,
   61272347]
FX This work was partially supported by the National Hi-Tech Research and
   Development Program (863 Program) of China (2014AA015102), and the
   National Natural Science Foundation of China (61272502, 61272347).
CR Acharya T, 2006, J VLSI SIG PROC SYST, V42, P321, DOI 10.1007/s11266-006-4191-3
   [Anonymous], 2000, FCD154441 ISOIEC
   Aziz SM, 2012, COMPUT ELECTR ENG, V38, P1325, DOI 10.1016/j.compeleceng.2012.05.009
   Cheng C, 2008, IEEE T SIGNAL PROCES, V56, P393, DOI 10.1109/TSP.2007.900754
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Grzeszczak A, 1996, IEEE T VLSI SYST, V4, P421, DOI 10.1109/92.544407
   Hsia CH, 2013, IEEE T CIRC SYST VID, V23, P671, DOI 10.1109/TCSVT.2012.2211953
   Huang CT, 2005, IEEE T CIRC SYST VID, V15, P910, DOI 10.1109/TCSVT.2005.848307
   Huang CT, 2004, IEEE T SIGNAL PROCES, V52, P1080, DOI 10.1109/TSP.2004.823509
   International Organisation for Standardisation, 2020, ISO 129672020
   Kotteri KA, 2005, IEEE T CIRCUITS-II, V52, P256, DOI 10.1109/TCSII.2005.843496
   Lai YK, 2009, IEEE T CONSUM ELECTR, V55, P400, DOI 10.1109/TCE.2009.5174400
   Liao HY, 2004, IEEE T SIGNAL PROCES, V52, P1315, DOI 10.1109/TSP.2004.826175
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mansouri A, 2009, INT J COMPUT SCI NET, V9, P50
   Mei KZ, 2007, IEEE T CIRC SYST VID, V17, P1065, DOI 10.1109/TCSVT.2007.903555
   Mohanty BK, 2011, IEEE T SIGNAL PROCES, V59, P2072, DOI 10.1109/TSP.2011.2109953
   Qin LX, 2015, J VIS COMMUN IMAGE R, V32, P1, DOI 10.1016/j.jvcir.2015.07.010
   Shi GM, 2009, IEEE T CIRCUITS-II, V56, P290, DOI 10.1109/TCSII.2009.2015393
   Sweldens W., 1995, SPIE C 1995, P68
   Tian X, 2011, IEEE T COMPUT, V60, P1207, DOI 10.1109/TC.2010.178
   Wu B.-F., 2003, P 2003 INT S CIRC SY
   Wu BF, 2005, IEEE T CIRC SYST VID, V15, P1615, DOI 10.1109/TCSVT.2005.858610
   Wu PC, 2001, IEEE T CIRC SYST VID, V11, P536, DOI 10.1109/76.915359
   Zhang CJ, 2012, IEEE T CIRCUITS-I, V59, P1775, DOI 10.1109/TCSI.2011.2180432
NR 27
TC 5
Z9 5
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 297
EP 306
DI 10.1016/j.jvcir.2016.03.014
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100025
DA 2024-07-18
ER

PT J
AU Liu, MF
   Liu, Y
   Hu, HJ
   Nie, LQ
AF Liu, Maofu
   Liu, Ya
   Hu, Huijun
   Nie, Liqiang
TI Genetic algorithm and mathematical morphology based binarization method
   for strip steel defect image with non-uniform illumination
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Strip steel defect image; Mathematical morphology; Genetic algorithm;
   Image binarization; Non-uniform illumination; EOBMM; Top-hat
   transformation; Fitness function; Genetic operations
ID THRESHOLDING TECHNIQUES; SEGMENTATION; CLASSIFICATION; ENHANCEMENT;
   MACHINE
AB In order to precisely extract the image shape feature for the defect detection and classification, the strip steel image needs to firstly be binarized effectively. In this paper, the intelligent information processing, including mathematical morphology and genetic algorithm, is introduced to the strip steel defect image binarization. In order to eliminate the effect of non-uniform illumination and enhance the detailed information of the strip steel defect image, an enhancement operator based on mathematical morphology (EOBMM) is proposed firstly. And then, the binarization method based on genetic algorithm (BMBGA) is applied to the binarization of the strip steel defect image processed by EOBMM. The experiment results show that our method is effective and efficiency in the strip steel defect image binarization and outperforms the traditional image binarization methods, Otsu and Bernsen. (C) 2016 Published by Elsevier Inc.
C1 [Liu, Maofu; Liu, Ya; Hu, Huijun] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
   [Hu, Huijun] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
   [Nie, Liqiang] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 Wuhan University of Science & Technology; Wuhan University; National
   University of Singapore
RP Hu, HJ (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Peoples R China.
EM liumaofu@wust.edu.cn; 366594432@qq.com; huhuijun@wust.edu.cn;
   nieliqiang@gmail.com
FU National Natural Science Foundation of China [61100133]; Hubei Province
   Key Laboratory Open Foundation [znss2013B014]
FX The work in this paper was supported partially by the National Natural
   Science Foundation of China (No. 61100133) and Hubei Province Key
   Laboratory Open Foundation (No. znss2013B014).
CR Al-amri Salem Saleh., 2010, Journal of Computing, V2, P83
   Atif J., 2013, P 11 INT C FORM CONC, P28
   Bai XZ, 2012, OPT LASER TECHNOL, V44, P328, DOI 10.1016/j.optlastec.2011.07.009
   Bernsen J., 1986, ICPR 86, P1251
   Dougherty E., 1992, Mathematical Morphology in Image Processing
   Hadjadj Z, 2014, INT CONF FRONT HAND, P655, DOI 10.1109/ICFHR.2014.115
   Harvey I, 2011, P 10 EUR C ADV ART L, P126
   Heess N, 2011, LECT NOTES COMPUT SC, V6792, P9, DOI 10.1007/978-3-642-21738-8_2
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   Jovanovic R., 2012, P 5 WSEAS C APPL COM, V12, P157
   Kohmura H, 2006, INT C PATT RECOG, P661
   Koli V. Y., 2014, INT J INVENTIVE ENG, V12, P33
   Liu N., 2014, WSEAS T SIGNAL PROCE, V10, P627
   Otsu N., 1975, IEEE T SYST MAN CYB, V11, P23
   Paulinas M, 2007, INF TECHNOL CONTROL, V36, P278
   Raychaudhuri A., 2012, INT J COMPUT APPL, V50, P49
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sivaraj R., 2011, Int. J. Eng. Sci. Technol, V3, P3792
   SOON GK, 2013, P 2013 IEEE INT C CO, P493
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Yishu S.K.Y.A.N.Y.P., 2012, J MECH ENG, V48, P20
   Yongmin Y., 2011, OPT PRECIS ENG, V19, P1651
   YOSHIDA H, 2009, P MVA 2009 IAPR C MA, P70
   Yuan ZH, 2010, NONLINEAR ANAL-REAL, V11, P3479, DOI 10.1016/j.nonrwa.2009.12.008
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhang J, 2011, IEEE COMPUT INTELL M, V6, P68, DOI 10.1109/MCI.2011.942584
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang LM, 2011, LECT NOTES COMPUT SC, V7064, P657, DOI 10.1007/978-3-642-24965-5_74
NR 32
TC 38
Z9 44
U1 0
U2 52
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 70
EP 77
DI 10.1016/j.jvcir.2015.04.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700010
DA 2024-07-18
ER

PT J
AU Tasli, HE
   Sicre, R
   Gevers, T
AF Tasli, H. Emrah
   Sicre, Ronan
   Gevers, Theo
TI SuperPixel based mid-level image description for image recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Pattern recognition; Image classification; Image
   retrieval; Feature extraction; Mid-level cues; Superpixels; Feature
   encoding
AB This study proposes a mid-level feature descriptor and aims to validate improvement on image classification and retrieval tasks. In this paper, we propose a method to explore the conventional feature extraction techniques in the image classification pipeline from a different perspective where mid-level information is also incorporated in order to obtain a superior scene description. We hypothesize that the commonly used pixel based low-level descriptions are useful but can be improved with the introduction of mid-level region information. Hence, we investigate superpixel based image representation to acquire such mid-level information in order to improve the accuracy. Experimental evaluations on image classification and retrieval tasks are performed in order to validate the proposed hypothesis. We have observed a consistent performance increase in terms of Mean Average Precision (MAP) score for different experimental scenarios and image categories. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Tasli, H. Emrah; Sicre, Ronan; Gevers, Theo] Univ Amsterdam, Intelligent Syst Lab Amsterdam, Inst Informat, NL-1012 WX Amsterdam, Netherlands.
C3 University of Amsterdam
RP Gevers, T (corresponding author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Inst Informat, NL-1012 WX Amsterdam, Netherlands.
EM theo.gevers@uva.nl
RI sicre, ronan/HNP-6960-2023
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2010, CVPR
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2010, ECCV
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2011, BMVC
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2013, CVPR
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2005, ICCV
   [Anonymous], 2012, ECCV
   [Anonymous], ECCV
   [Anonymous], INT C COMP VIS
   [Anonymous], 2010, EUR C COMP VIS
   [Anonymous], 2013, CVPR
   Boureau Y., 2011, ICCV
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chua J, 2012, PROC CVPR IEEE, P2416, DOI 10.1109/CVPR.2012.6247955
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Divvala SK, 2012, LECT NOTES COMPUT SC, V7585, P31, DOI 10.1007/978-3-642-33885-4_4
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Fernando B., 2012, ECCV
   Gallagher AC, 2011, PROC CVPR IEEE
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jojic N., 2003, ICCV
   Juneja M., 2013, CVPR
   Lazebnik S., 2006, Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In Proc. CVPR
   Levinshtein A., 2009, IEEE PATTERN ANAL MA
   Li N, 2009, J NEUROPHYSIOL, V102, P360, DOI 10.1152/jn.90745.2008
   LIAO ZC, 2012, COMPUTER VISION PATT, P3442
   Martens G., 2008, WORKSH MULT SIGN PRO
   Martens P.L.G., 2010, SELF ORG MAPS
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Ojala T., 2002, T PAMI
   Pinto N., 2011, WORKSH APPL COMP VIS
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Pirsiavash H, 2012, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR.2012.6248058
   Rust NC, 2010, CURR OPIN NEUROBIOL, V20, P382, DOI 10.1016/j.conb.2010.04.013
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sicre R., 2015, COMPUT VIS IMAGE UND, P1
   Sicre R, 2014, INT C PATT RECOG, P3732, DOI 10.1109/ICPR.2014.641
   Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   Tasli HE, 2013, IEEE INT CON MULTI
   Tasli HE, 2015, SIGNAL PROCESS-IMAGE, V33, P71, DOI 10.1016/j.image.2015.02.005
   Tasli HE, 2014, IEEE IMAGE PROC, P1051, DOI 10.1109/ICIP.2014.7025209
   Veksler Olga, 2010, PERSPECTIVES NEURAL
   Vevaldi A., 2010, P ACM INT C MULT
   Zheng Songfeng., 2007, COMPUTER VISION PATT
NR 51
TC 5
Z9 5
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 301
EP 308
DI 10.1016/j.jvcir.2015.09.021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700027
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Verma, M
   Raman, B
AF Verma, Manisha
   Raman, Balasubramanian
TI Center symmetric local binary co-occurrence pattern for texture, face
   and bio-medical image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content based image retrieval; Local binary pattern; Center symmetric
   local binary pattern; Gray level co-occurrence matrix; Feature vector;
   Texture feature; MIT VisTex texture database; Brodatz texture database;
   ORL face database; OASIS MRI image database
ID FEATURE SETS; CLASSIFICATION; COLOR; RECOGNITION; DESCRIPTOR; EXTREMA;
   SYSTEM; MRI
AB Content based image retrieval is a common problem for a large image database. Many methods have been proposed for image retrieval for some particular type of datasets. In the proposed work, a new image retrieval technique has been introduced. This technique is useful for different kind of dataset. In the proposed method, center symmetric local binary pattern has been extracted from the original image to obtain the local information. Co-occurrence of pixel pairs in local pattern map have been observed in different directions and distances using gray level co-occurrence matrix. Earlier methods have utilized histogram to extract the frequency information of local pattern map but co-occurrence of pixel pairs is more robust than frequency of patterns. The proposed method is tested on three different category of images, i.e., texture, face and medical image database and compared with typical state-of-the-art local patterns. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Verma, Manisha] Indian Inst Technol Roorkee, Dept Math, Roorkee, Uttar Pradesh, India.
   [Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Verma, M (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee, Uttar Pradesh, India.
EM manisha.verma.in@ieee.org
RI verma, manisha/KIB-5458-2024
OI Verma, Manisha/0000-0002-5202-4325
FU Ministry of Human Resource and Development (MHRD) grant, India
   [MHRD-02-23-200-304]
FX This work was supported by the Ministry of Human Resource and
   Development (MHRD) grant, India under grant MHRD-02-23-200-304.
CR Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], VIS TEXT
   [Anonymous], 2002, P 5 NORD SIGN PROC S
   *AT T LAB CAMBR, 2002, AT T DAT FAC
   Celik T, 2009, PATTERN RECOGN LETT, V30, P331, DOI 10.1016/j.patrec.2008.10.006
   DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Felipe JC, 2003, COMP MED SY, P175
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kumar MPJ., 2013, INDIAN J SCI TECHNOL, V6, P1
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Loupias E, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P518, DOI 10.1109/ICIP.2000.899469
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Müller H, 2004, PRO BIOMED OPT IMAG, V5, P99
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, J VIS COMMUN IMAGE R, V25, P1324, DOI 10.1016/j.jvcir.2014.05.008
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, IEEE COMPUT SOC CONF, P444, DOI 10.1109/CVPRW.2013.73
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Safia A., 2013, NEW BRODATZ BASED IM
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Traina AJM, 2003, COMP MED SY, P150
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Vipparthi SK, 2014, COMPUT ELECTR ENG, V40, P163, DOI 10.1016/j.compeleceng.2014.04.018
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026
   Zhang D.S., 2000, PROC 1 IEEE PACIFIC, P392
   Zhang J, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P782, DOI 10.1109/HPCC.2008.55
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 51
TC 68
Z9 68
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 224
EP 236
DI 10.1016/j.jvcir.2015.08.015
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300019
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Hu, S
   Ma, XX
   Wang, LF
AF Pan, Zhibin
   Hu, Sen
   Ma, Xiaoxiao
   Wang, Lingfei
TI Reversible data hiding based on local histogram shifting with multilayer
   embedding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Histogram shifting; Localization; Multilayer
   embedding; Reference point; High embedding capacity; Low distortion;
   Continuous histogram
ID DIFFERENCE EXPANSION; IMAGE WATERMARKING; INTEGER TRANSFORM;
   PREDICTION-ERROR
AB In this paper, we present a new reversible data hiding method based on histogram shifting using localization. Our proposed method selects peak point as the reference point, then uses the two neighboring points of the peak point to achieve secret data embedding based on histogram shifting and the peak point keeps unchanged. In the extraction end, we no longer need the key information about the peak point, we can directly find the peak point from the histogram to extract the secret data. We also exploit the localization to make the histogram of embedded cover image become almost the same as the histogram of the original cover image. The embedding capacity is also increased rapidly by the localization with multilayer embedding. Experimental results show that our proposed method is effective and superior. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Pan, Zhibin; Hu, Sen; Ma, Xiaoxiao; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Hu, S (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn; husen.xjtu@gmail.com; xiao.77@stu.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Major Programs of National Natural Science Foundation of China
   [41390454]; Specialized Research Fund for the Doctoral Program of Higher
   Education [20130201110071]; Open Project Program of the National
   Laboratory of Pattern Recognition [201407370]; Open Project Program of
   the State Key Lab of CAD CG [A1512]
FX This work is supported in part by the Major Programs of National Natural
   Science Foundation of China (Grant No. 41390454), Specialized Research
   Fund for the Doctoral Program of Higher Education (Grant No.
   20130201110071), Open Project Program of the National Laboratory of
   Pattern Recognition (Grant No. 201407370) and Open Project Program of
   the State Key Lab of CAD & CG (Grant No. A1512).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Lee CF, 2011, IMAGING SCI J, V59, P278, DOI 10.1179/1743131X10Y.0000000018
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang C, 2010, IEEE IMAGE PROC, P217, DOI 10.1109/ICIP.2010.5652066
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 20
TC 59
Z9 66
U1 3
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 64
EP 74
DI 10.1016/j.jvcir.2015.05.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600006
DA 2024-07-18
ER

PT J
AU Yang, JC
   Liu, Y
   Gao, ZQ
   Chu, RR
   Song, ZJ
AF Yang, Jiachen
   Liu, Yun
   Gao, Zhiqun
   Chu, Rongrong
   Song, Zhanjie
TI A perceptual stereoscopic image quality assessment model accounting for
   binocular combination behavior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binocular vision; Image quality; Local amplitude; Gain control;
   Stereoscopic quality assessment; Difference channel; Summation channel;
   Symmetric distortion
ID STRUCTURAL SIMILARITY; SUBJECTIVE EVALUATION; VISUAL DISCOMFORT;
   DISPARITY
AB Stereoscopic image quality assessment (SIQA) plays an important role in the development of 3D image processing. In this paper, a full-reference object SIQA model is built based on binocular summation channel and binocular difference channel. In our frame work, binocular combination behavior and how to experience the depth perception are thought to be the key factors to evaluate the quality of stereoscopic images. Differing from the current depth map methods, this method focuses on a new aspect, and an effective combination model is proposed based on the physiological findings in the Human Visual System (HVS). Experimental results demonstrate that the proposed quality assessment metric significantly outperforms the existing metrics and can achieve higher consistency with subject quality assessment when predicting the quality of stereoscopic images that have been symmetrically distorted. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yang, Jiachen; Liu, Yun; Gao, Zhiqun; Chu, Rongrong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Song, Zhanjie] Tianjin Univ, Sch Sci, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liu, Y (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM yunliu@tju.edu.cn
RI Yang, Jiachen/ABH-5032-2020
OI Yang, Jiachen/0000-0003-2558-552X
FU National Natural Science Foundation of China [61471260, 61271324];
   Program for New Century Excellent Talents in University [NCET-12-0400]
FX The authors would like to thank Prof. Alan C. Bovik for providing the
   LIVE 3D IQA Database. This research is partially supported by the
   National Natural Science Foundation of China (Nos. 61471260 and
   61271324), and Program for New Century Excellent Talents in University
   (NCET-12-0400).
CR [Anonymous], 2013, 2013 VISUAL COMMUNIC
   ATICK JJ, 1992, NEURAL COMPUT, V4, P196, DOI 10.1162/neco.1992.4.2.196
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bensalma R, 2013, MULTIDIM SYST SIGN P, V24, P281, DOI 10.1007/s11045-012-0178-3
   Bose E, 2013, PROC SPIE, V8648, DOI 10.1117/12.2002410
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen GH, 2006, IEEE IMAGE PROC, P2929, DOI 10.1109/ICIP.2006.313132
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen W., 2012, 8288 INT SOC OPT PHO, V8288
   COGAN AI, 1987, VISION RES, V27, P2125, DOI 10.1016/0042-6989(87)90127-1
   De Silva HR, 1930, B J PSYCHOL-GEN SECT, V20, P241
   Gottschalk PG, 2005, ANAL BIOCHEM, V343, P54, DOI 10.1016/j.ab.2005.04.035
   Grossberg S, 1999, VISION RES, V39, P3796, DOI 10.1016/S0042-6989(99)00095-4
   Hanhart P., 2014, P SOC PHOTO-OPT INS, VXXV
   Howard Ian P, 1995, Binocular Vision and Stereopsis
   IJsselsteijn WA, 2000, IEEE T CIRC SYST VID, V10, P225, DOI 10.1109/76.825722
   Jiang Q., 2014, J SOFTW, V9
   Jung SW, 2012, IEEE SIGNAL PROC LET, V19, P303, DOI 10.1109/LSP.2012.2191616
   Kim D, 2011, IEEE T CIRC SYST VID, V21, P231, DOI 10.1109/TCSVT.2011.2106275
   Kingdom FAA, 2012, CURR BIOL, V22, pR22, DOI 10.1016/j.cub.2011.11.048
   Lambooij M, 2011, IEEE T CIRC SYST VID, V21, P1913, DOI 10.1109/TCSVT.2011.2157193
   Lee JS, 2013, MULTIMED TOOLS APPL, V67, P31, DOI 10.1007/s11042-012-1011-6
   Levelt W.J. M., 1968, BINOCULAR RIVALRY
   LI ZP, 1994, NETWORK-COMP NEURAL, V5, P157, DOI 10.1088/0954-898X/5/2/003
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Lv Z., 2014, SIGGRAPH AS 2014
   Lv Z., 2015, EUROGRAPHICS2015
   Maalouf A., 2011, IEEE INT C AC SPEECH
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Park J, 2015, IEEE T IMAGE PROCESS, V24, P1101, DOI 10.1109/TIP.2014.2383327
   López JP, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-62
   Qian N, 2000, NEURAL COMPUT, V12, P279, DOI 10.1162/089976600300015781
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang H, 2015, J VIS COMMUN IMAGE R, V26, P105, DOI 10.1016/j.jvcir.2014.11.001
   Yun N, 2013, NEUROCOMPUTING, V120, P121, DOI 10.1016/j.neucom.2012.06.059
   Zeng K, 2012, IEEE IMAGE PROC, P621, DOI 10.1109/ICIP.2012.6466936
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XD, 2013, IEEE SIGNAL PROC LET, V20, P319, DOI 10.1109/LSP.2013.2244081
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
NR 44
TC 29
Z9 31
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 138
EP 145
DI 10.1016/j.jvcir.2015.06.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600012
DA 2024-07-18
ER

PT J
AU Wang, J
   Wang, HZ
   Zhao, WL
AF Wang, Jun
   Wang, Hanzi
   Zhao, Wan-Lei
TI Affine hull based target representation for visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Particle filter; Affine hull; Histograms of sparse
   codes; Appearance model; Target representation; Generative tracking;
   Template set
ID APPROXIMATED NEAREST POINTS; OBJECT TRACKING; FACE RECOGNITION
AB Handling appearance variations is a challenging issue in visual tracking. Existing appearance models are usually built upon a linear combination of templates. With such kind of representation, accurate visual tracking is not desirable when heavy appearance variations are in presence. Under the framework of particle filtering, we propose a novel target representation for tracking. Namely, the target candidates are represented by affine combinations of a template set, which leads to better capability in describing unseen target appearances. Additionally, in order to adapt this representation to dynamic contexts across a video sequence, a novel template update scheme is presented. Different from conventional approaches, the scheme considers both the importance of one template to a target candidate in the current frame and the recentness of the template that is kept in the template set. Comprehensive experiments show that the proposed algorithm achieves superior performances in comparison with state-of-the-art works. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Jun; Wang, Hanzi; Zhao, Wan-Lei] Xiamen Univ, Sch Informat Sci & Technol, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
   [Wang, Jun] Xiamen Univ, Dept Cognit Sci, Xiamen 361005, Peoples R China.
   [Wang, Hanzi; Zhao, Wan-Lei] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China.
C3 Xiamen University; Xiamen University; Xiamen University
RP Wang, HZ (corresponding author), Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China.
EM wangjuncv@gmail.com; hanzi.wang@xmu.edu.cn; wlzhao@xmu.edu.cn
RI Wang, Han/GPW-9809-2022; wang, hao/HSE-7975-2023; wang,
   handong/HLH-5739-2023
FU National Natural Science Foundation of China [61472334, 61170179,
   61201359]; Fundamental Research Funds for the Central Universities
   [20720130720]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61472334, 61170179, and 61201359, and supported by
   the Fundamental Research Funds for the Central Universities under Grant
   20720130720.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Grabner H., 2006, BMVC, P47
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li X, 2013, IEEE T PATTERN ANAL, V35, P863, DOI 10.1109/TPAMI.2012.166
   Li X, 2012, PROC CVPR IEEE, P1760, DOI 10.1109/CVPR.2012.6247872
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie CJ, 2014, J VIS COMMUN IMAGE R, V25, P423, DOI 10.1016/j.jvcir.2013.12.012
   Yan J, 2015, J VIS COMMUN IMAGE R, V26, P231, DOI 10.1016/j.jvcir.2014.11.013
   Yoon JH, 2012, LECT NOTES COMPUT SC, V7575, P28, DOI 10.1007/978-3-642-33765-9_3
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang SP, 2013, NEUROCOMPUTING, V100, P31, DOI 10.1016/j.neucom.2011.11.031
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 41
TC 4
Z9 4
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 266
EP 276
DI 10.1016/j.jvcir.2015.04.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900024
DA 2024-07-18
ER

PT J
AU Wang, LL
   Yung, NHC
AF Wang, Li-Li
   Yung, Nelson H. C.
TI Hybrid graphical model for semantic image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Conditional Random Field; Bayesian Network;
   Graphical model; Spatial relationship; Hybrid model; Sub-scene;
   Contextual interaction
ID CONTEXT; WATERSHEDS
AB To make full use of both non-causal and causal cues in natural images, we propose a hybrid hierarchical Conditional Random Field (HCRF) and Bayesian Network (BN) model for semantic image segmentation in this paper. The HCRF is used to capture non-causal relationship, such as appearance features and interclass co-occurrence statistics, to produce initial semantic sub-scene predictions. Whereas, the BN is used to model contextual interactions for each semantic sub-scene in the form of class statistics from its neighboring regions, of which its conditional probabilities are learned automatically from training data. The learned BN structure is then used to encode the structure of contextual dependencies for sub-scenes in the initial predictions to generate final refined predictions. Experiments on the Stanford 8-class dataset and the LHI 15-class dataset show that the hybrid model outperforms pure CRF models by 2-4% in average classification accuracy. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Li-Li; Yung, Nelson H. C.] Univ Hong Kong, Dept Elect & Elect Engn, Lab Intelligent Transportat Syst Res, Hong Kong, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Wang, LL (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Lab Intelligent Transportat Syst Res, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
RI Yung, Nelson Hon Ching/C-1873-2009; wang, lili/HDL-7210-2022
FU Research Grant Council of the Hong Kong Special Administrative Region,
   China [HKU718912E]
FX This research was supported by a Grant from the Research Grant Council
   of the Hong Kong Special Administrative Region, China, under Project
   HKU718912E.
CR [Anonymous], MACH VIS APPL
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], OBJECT LOCALIZATION
   [Anonymous], 2008, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2008.4587799, DOI 10.1109/CVPR.2008.4587799]
   [Anonymous], COGNITIVE MODEL
   [Anonymous], LEARNING HIERARCHICA
   [Anonymous], 11 EUR S ART NEUR NE
   [Anonymous], 2009, 2009 26 INT C INT C
   [Anonymous], LEARNING MACHINES
   [Anonymous], INT J COMPUT VISION
   [Anonymous], PATT REC 2008 ICPR 2
   [Anonymous], LEARNING DYNAMIC HYB
   [Anonymous], IMPRFAST WAT ALG BAS
   [Anonymous], 1990, NIPS
   [Anonymous], 2001, PROC 18 INT C MACH L
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Huang Gary B., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562973
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Kumar S, 2005, IEEE I CONF COMP VIS, P1284
   Ladicky L, 2013, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2013.459
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Larlus D., 2008, COMPUTER VISION PATT, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S.Z., 2009, Markov random field modeling in image analysis, V26
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   McFee B, 2011, IEEE T IMAGE PROCESS, V20, P570, DOI 10.1109/TIP.2010.2068556
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Munoz D, 2010, LECT NOTES COMPUT SC, V6316, P57, DOI 10.1007/978-3-642-15567-3_5
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Pieczynski W., 2000, Machine Graphics & Vision, V9, P705
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Skiadopoulos S, 2004, ARTIF INTELL, V152, P143, DOI 10.1016/S0004-3702(03)00137-1
   Torralba A, 2004, PROC CVPR IEEE, P762
   Torralba Antonio., 2004, ADV NEURAL INFORM PR, P1401
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
NR 50
TC 7
Z9 7
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 83
EP 96
DI 10.1016/j.jvcir.2015.01.014
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000010
DA 2024-07-18
ER

PT J
AU Yang, H
   Fang, YM
   Yuan, Y
   Lin, WS
AF Yang, Huan
   Fang, Yuming
   Yuan, Yuan
   Lin, Weisi
TI Subjective quality evaluation of compressed digital compound images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital compound image; Quality assessment; Subjective test; Image
   compression; Subjective quality evaluation; Subjective database;
   Compound image quality assessment database; Paired Comparison
ID INFORMATION
AB Visual quality evaluation of compressed Digital Compound Images (DCIs) becomes important in many multi-device communication systems. In this paper, we study subjective quality evaluation for compressed DCIs and investigate whether existing Image Quality Assessment (IQA) metrics are effective to evaluate the visual quality of compressed DCIs. A new Compound Image Quality Assessment Database (CIQAD) is therefore constructed, including 24 reference and 576 compressed DCIs. The subjective scores of these DCIs are obtained via visual judgement of 62 subjects using Paired Comparison (PC) in which the Hodgerank decomposition is adopted to generate uncompleted but near balanced pairs. Fourteen state-of-the-art IQA metrics are adopted to assess quality of images in CIQAD, and experimental results indicate that the existing IQA methods are limited in evaluating visual quality of DCIs. Compression results of five coding methods are thus compared with respect to different quality metrics to illustrate the limitation. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yang, Huan; Yuan, Yuan; Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Jiangxi, Peoples R China.
C3 Nanyang Technological University; Jiangxi University of Finance &
   Economics
RP Fang, YM (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM hyang3@e.ntu.edu.sg; fa0001ng@e.ntu.edu.sg; yyuan004@e.ntu.edu.sg;
   wslin@ntu.edu.sg
RI Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012
OI Lin, Weisi/0000-0001-9866-1947; 
CR [Anonymous], 2005, SUBJECTIVE QUALITY A
   [Anonymous], 144922001 ISOIEC
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 37 AS C SIGN SYST CO
   [Anonymous], VIRTUALIZED SCREEN 3
   Bottou L, 1998, J ELECTRON IMAGING, V7, P410, DOI 10.1117/1.482609
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chang T.-H., 2011, ACM C HUM FACT COMP
   Ciszkowski T, 2012, TELECOMMUN SYST, V51, P283, DOI 10.1007/s11235-011-9435-2
   de Queiroz R. L., 2005, DOCUMENT IMAGE COMPR
   Erdos P., 1959, Publicationes Mathematicae Debrecen, V6, P18
   Guyon I., 1997, P SPIE DOCUMENT RECO
   Hase H, 2011, PROC INT CONF DOC, P1414, DOI 10.1109/ICDAR.2011.284
   International Telecommunications Union, 2012, 50013 I R BT
   Jiang X., 2011, MATH PROGRAM, V127, P6470
   Kumar Deepak., 2011, INT WORKSHOP CAMERA, P79
   Kumar Jayant., 2013, DIQA DOCUMENT IMAGE
   Lan CL, 2010, IEEE T IMAGE PROCESS, V19, P946, DOI 10.1109/TIP.2009.2038636
   Larson E., 2010, J ELECTRON IMAGING, V19
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lewis D., 2006, ACM SIGIR C RES DEV
   Li J., 2013, IEEE IM VID MULT SIG
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Obafemi-Ajayi T, 2012, IEEE T SYST MAN CY A, V42, P584, DOI 10.1109/TSMCA.2011.2170417
   Pan Z., 2011, IEEE INT S CIRC SYST
   Pan ZT, 2013, IEEE T CIRC SYST VID, V23, P949, DOI 10.1109/TCSVT.2013.2243056
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Quan HT, 2011, IEEE T BROADCAST, V57, P1, DOI 10.1109/TBC.2010.2086750
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shen H., 2009, IEEE INT C PERV COMP
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Xu Q, 2012, IEEE T MULTIMEDIA, V14, P844, DOI 10.1109/TMM.2012.2190924
   Yang H., 2012, IEEE INT WORKSH MULT
   Ye P., 2012, INT C PATT REC
   Ye P., 2013, INT C DOC AN REC
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 48
TC 8
Z9 9
U1 4
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 105
EP 114
DI 10.1016/j.jvcir.2014.11.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000010
DA 2024-07-18
ER

PT J
AU Cao, ZP
   Wei, ZZ
   Zhang, GJ
AF Cao, Zhipeng
   Wei, Zhenzhong
   Zhang, Guangjun
TI A no-reference sharpness metric based on the notion of relative blur for
   Gaussian blurred image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sharpness metric; Blur metric; Image quality assessment; Relative blur;
   Granularity; Object scale; Edge profile truncating; Perceptual blurr
ID QUALITY ASSESSMENT
AB This work presents a no-reference sharpness metric for Gaussian blurred image. The metric is based on the notion of relative blur. The key concept is that the judgement on the sharpness closely relates to the degree of convenience for recognizing image objects on a certain scale. Based on this concept, the proposed metric is defined as relative blur with respect to certain object scale using an absolute blur measure. The object scale is characterized by a granularity analysis of image content. And the absolute blur is built on an analysis of edge local gray level distribution. The performance of the metric is tested and compared with some outstanding existing metrics in this field on three widely used databases. The experiment results show that the proposed metric can predict the sharpness of images in varying databases with high accuracy and reliability. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Cao, Zhipeng; Wei, Zhenzhong; Zhang, Guangjun] Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Minist Educ, Key Lab Precise Optomechatron Technol, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhang, GJ (corresponding author), Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Minist Educ, Key Lab Precise Optomechatron Technol, Beijing 100191, Peoples R China.
EM zhipengcao@hotmail.com; gjzhang@buaa.edu.cn
CR [Anonymous], 2000, FIN REP VID EXP GROU
   Barland R, 2005, ISSPA 2005: The 8th International Symposium on Signal Processing and its Applications, Vols 1 and 2, Proceedings, P351
   Batten C.F., 2000, THESIS U CAMBRIDGE C
   Blanchet G., 2008, P INT C IM PROC, P1176
   Blanchet G., 2011, WORKING PAPER
   Caviedes J, 2004, SIGNAL PROCESS-IMAGE, V19, P147, DOI 10.1016/j.image.2003.08.002
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   COHEN J, 1994, AM PSYCHOL, V49, P997, DOI 10.1037/0003-066X.50.12.1103
   Ferzli R., 2007, Third International Workshop on Video Processing and Quality Metrics for Consumer Electronics, P25
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Ferzli Rony, 2005, P 1 INT WORKSH VID P
   Hassen R, 2011, LECT NOTES COMPUT SC, V6753, P40, DOI 10.1007/978-3-642-21593-3_5
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Karam LJ, 2009, IEEE J-STSP, V3, P189, DOI 10.1109/JSTSP.2009.2015485
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Maalouf A, 2010, EUR SIGNAL PR CONF, P1019
   Marichal X., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P386, DOI 10.1109/ICIP.1999.822923
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ong EP, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P469, DOI 10.1109/ISSPA.2003.1224741
   Ponomarenko N, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P407
   Ravkin I., 2005, IBCS IN C HIGH CONT
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   Saad M. A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3093, DOI 10.1109/ICIP.2011.6116319
   Shaked D, 2005, IEEE IMAGE PROC, P841
   Sheikh H. R., 2003, Live image quality assessment database
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2004, ADV NEURAL INFORM PR, P786
   Wang ZJ, 2011, IEEE SIGNAL PROC MAG, V28, P2, DOI 10.1109/MSP.2011.940297
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
NR 33
TC 6
Z9 6
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1763
EP 1773
DI 10.1016/j.jvcir.2014.06.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100025
DA 2024-07-18
ER

PT J
AU Wang, DY
   Yuan, C
   Sun, Y
   Zhang, J
   Jin, X
AF Wang, Dayong
   Yuan, Chun
   Sun, Yu
   Zhang, Jian
   Jin, Xin
TI A fast mode decision algorithm applied to Coarse-Grain quality Scalable
   Video Coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inter-layer correlation; Spatial correlation; Early termination; CGS
   coding; Scalable Video Coding; Quality SVC; Fast mode decision; Fast
   algorithm
ID DCT COEFFICIENTS
AB A fast mode decision algorithm is proposed for a Coarse-Grain Scalable (CGS) video encoder based on the encoding characteristics of quality Scalable Video Coding (SVC). First, candidate modes and coding orders are predicted, based on inter-layer and spatial correlations. Three early termination methods are then proposed based on CGS encoding structure. Finally, all candidate modes are checked sequentially, according to their predicted order with three early termination conditions, to improve the coding speed. Experimental results have demonstrated that the proposed algorithm could reduce the encoding time by an average of 84.39%, with negligible coding efficiency losses. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Dayong; Yuan, Chun; Jin, Xin] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518057, Peoples R China.
   [Sun, Yu] Univ Cent Arkansas, Dept Comp Sci, Conway, AR USA.
   [Zhang, Jian] Univ Technol Sydney, Sch Software, Sydney, NSW 2007, Australia.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   University of Central Arkansas; University of Technology Sydney
RP Yuan, C (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518057, Peoples R China.
RI jin, xin/GQZ-5811-2022
OI Zhang, Jian/0000-0002-7240-3541
FU National Significant Science and Technology Projects of China
   [2013ZX01039001-002-003]; NSFC [61401247, U1433112, 61170253, 61201247];
   Promotion Project of the Shenzhen Key Laboratory on Information Science
   and Technology; China Postdoctoral Science Foundation [2013M540953]
FX This work was supported by the National Significant Science and
   Technology Projects of China, under Grant No. 2013ZX01039001-002-003; by
   the NSFC under Grant Nos. 61401247, U1433112, 61170253 and 61201247; by
   the Promotion Project of the Shenzhen Key Laboratory on Information
   Science and Technology in 2012; and by the China Postdoctoral Science
   Foundation, No. 2013M540953.
CR Bjontegaard G., 2001, Document VCEG-M33
   Jung SW, 2010, IEEE T CIRC SYST VID, V20, P201, DOI 10.1109/TCSVT.2009.2031387
   Kim ST, 2009, IEEE T CONSUM ELECTR, V55, P1572, DOI 10.1109/TCE.2009.5278029
   Li H., 2006, IEEE INT C AC SPEECH, V5, P545
   Li H, 2006, IEEE T CIRC SYST VID, V16, P889, DOI 10.1109/TCSVT.2006.877404
   Lin HC, 2010, IEEE T CIRC SYST VID, V20, P732, DOI 10.1109/TCSVT.2010.2045832
   Lin Hung-Chih, 2007, IEEE INT C IM PROC, V9, P289
   Lu X, 2013, IEEE T CIRC SYST VID, V23, P846, DOI 10.1109/TCSVT.2012.2226525
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Park CS, 2009, IEEE T CIRC SYST VID, V19, P1915, DOI 10.1109/TCSVT.2009.2031520
   Ren JF, 2008, IEEE T CONSUM ELECTR, V54, P877, DOI 10.1109/TCE.2008.4560174
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Shen LQ, 2010, IEEE IMAGE PROC, P4229, DOI 10.1109/ICIP.2010.5651298
   Shen LQ, 2010, IEEE SIGNAL PROC LET, V17, P887, DOI 10.1109/LSP.2010.2066966
   [汪大勇 Wang Dayong], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P2541, DOI 10.3724/SP.J.1146.2009.01468
   Wang HL, 2007, IMAGE VISION COMPUT, V25, P922, DOI 10.1016/j.imavis.2006.07.007
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Yeh CH, 2010, IEEE T CIRC SYST VID, V20, P563, DOI 10.1109/TCSVT.2010.2041825
   Zhao TS, 2012, IEEE T IMAGE PROCESS, V21, P2607, DOI 10.1109/TIP.2012.2186148
NR 20
TC 3
Z9 3
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1631
EP 1639
DI 10.1016/j.jvcir.2014.07.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100014
DA 2024-07-18
ER

PT J
AU Chang, TY
   Tai, SC
   Lin, GS
AF Chang, Tang-You
   Tai, Shen-Chuan
   Lin, Guo-Shiang
TI A passive multi-purpose scheme based on periodicity analysis of CFA
   artifacts for image forensics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; PIM detection; Device class identification; Color
   filter array
ID JPEG IMAGES; DISCRIMINATION
AB We propose a passive multi-purpose scheme for photographic image (PIM) detection and a device class identification method. The motivation for the scheme is the periodicity phenomenon caused by color filter arrays (CFAs) and the demosaicing process. The phenomenon only occurs in the Fourier spectrum in PIMs. The proposed scheme exploits prediction error statistics, local peak detection, and a PIM classifier to analyze the phenomenon for PIM detection. We also develop a hierarchical classifier for device class identification based on the analysis of local peaks in the Fourier spectrum.
   To evaluate the scheme's performance, we compile a test dataset of PIMs and PRCG (photorealistic computer graphics) images, and analyze the impact of leak peak detection, JPEG lossy compression, and cropping operations on PIM detection. The accuracy rate of the scheme on 5805 test images is 95.56%, which is higher than that of the methods proposed in Sutthiwan et al. (2009) [1] and Gallagher and Chen (2008) [2]. In addition, for device class identification, the precision rate of the proposed method is at least 93% on Canon, Sony, and Nikon images. The experiment results demonstrate the efficacy of the proposed multi-purpose scheme. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chang, Tang-You; Tai, Shen-Chuan] Natl Cheng Kung Univ, Inst Comp & Commun Engn, Tainan 701, Taiwan.
   [Chang, Tang-You; Tai, Shen-Chuan] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 701, Taiwan.
   [Lin, Guo-Shiang] Da Yeh Univ, Dept Comp Sci & Informat Engn, Da Tsuen 515, Changhua County, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University; Da Yeh
   University
RP Lin, GS (corresponding author), Da Yeh Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Da Tsuen 515, Changhua County, Taiwan.
EM E2490668@gmail.com; sctai@mail.ncku.edu.tw; khlin@mail.dyu.edu.tw
CR [Anonymous], 2019, NEURAL NETWORK DESIG
   Bayram S, 2008, DIGIT INVEST, V5, P49, DOI 10.1016/j.diin.2008.06.004
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Chen YL, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P807
   Dang-Nguyen DT, 2012, EUR SIGNAL PR CONF, P1234
   Farid H, 2012, DIGIT INVEST, V8, P226, DOI 10.1016/j.diin.2011.06.003
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Filler Tomas, 2008, 2008 15th IEEE International Conference on Image Processing - ICIP 2008, P1296, DOI 10.1109/ICIP.2008.4712000
   Gallagher Andrew C., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562984
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Gonzalez LE, 2013, MEX INT CONF ARTIF I, P103, DOI 10.1109/MICAI.2013.18
   Hsu CC, 2007, P 6 WSEAS INT C ART, P170
   Huang W.T., 2010, IS T SPIE ELECT IMAG, V19
   Jin Zhi, 2013, 2013 17th International Conference on Information Visualisation, P545, DOI 10.1109/IV.2013.74
   Kaneko K, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P735, DOI 10.1109/CISIS.2013.132
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Li X, 2005, IEEE T IMAGE PROCESS, V14, P370, DOI 10.1109/TIP.2004.840683
   Lie WN, 2006, IEEE T INF FOREN SEC, V1, P330, DOI 10.1109/TIFS.2006.879297
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Lin GS, 2011, IEEE T CIRC SYST VID, V21, P421, DOI 10.1109/TCSVT.2011.2125370
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Lin GS, 2009, INT J PATTERN RECOGN, V23, P1179, DOI 10.1142/S0218001409007521
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Mckay C, 2008, INT CONF ACOUST SPEE, P1657, DOI 10.1109/ICASSP.2008.4517945
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Sutthiwan Patchara, 2009, Proceedings of the 2009 16th IEEE International Conference on Image Processing (ICIP 2009), P2913, DOI 10.1109/ICIP.2009.5413344
   Zhang R, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P226, DOI 10.1109/ICECC.2011.6067631
NR 30
TC 16
Z9 17
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1289
EP 1298
DI 10.1016/j.jvcir.2014.04.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100001
DA 2024-07-18
ER

PT J
AU Pyatykh, S
   Hesser, J
AF Pyatykh, Stanislav
   Hesser, Juergen
TI Salt and pepper noise removal in binary images using image block prior
   probabilities
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salt and pepper noise; Image denoising; Binary images; Bayesian
   inference; Training methods; Impulse noise; Image restoration; Image
   filtering
AB During scanning and transmission, images can be corrupted by salt and pepper noise, which negatively affects the quality of subsequent graphic vectorization or text recognition. In this paper, we present a new algorithm for salt and pepper noise suppression in binary images. The algorithm consists of the computation of block prior probabilities from training noise-free images; noise level estimation; and the maximum a posteriori probability estimation of each image block. Our experiments show that the proposed method performs significantly better than the state of the art techniques. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Pyatykh, Stanislav; Hesser, Juergen] Heidelberg Univ, Univ Med Ctr Mannheim, D-68167 Mannheim, Germany.
C3 Ruprecht Karls University Heidelberg
RP Pyatykh, S (corresponding author), Heidelberg Univ, Univ Med Ctr Mannheim, Theodor Kutzer Ufer 1-3, D-68167 Mannheim, Germany.
EM stanislav.pyatykh@medma.uni-heidelberg.de;
   juergen.hesser@medma.uni-heidelberg.de
FU AiF in the program support of cooperative industrial research (IGF) by
   the Federal Ministry of Economy and Technology of the German Federal
   Parliament [KF2769301FRO]
FX This IGF project (KF2769301FRO) was supported by AiF in the program
   support of cooperative industrial research (IGF) by the Federal Ministry
   of Economy and Technology on basis of a resolution of the German Federal
   Parliament.
CR Abdel-Dayem AR, 2004, LECT NOTES COMPUT SC, V3212, P191
   Al-Khaffaf H., 2008, 19 INT C PATT REC IC, P1
   Al-Khaffaf H., 2009, ARC SEGMENTATION CON
   Al-Khaffaf HSM, 2009, LECT NOTES COMPUT SC, V5857, P607, DOI 10.1007/978-3-642-05036-7_57
   Al-Khaffaf HSM, 2009, IEICE T INF SYST, VE92D, P689, DOI 10.1587/transinf.E92.D.689
   Buades A, 2004, TECHNICAL REPORT
   Chinnasarn K, 1998, APCCAS '98 - IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P459, DOI 10.1109/APCCAS.1998.743809
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Petrovic NI, 2008, IEEE T IMAGE PROCESS, V17, P1109, DOI 10.1109/TIP.2008.924388
   Schmidt U., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2625, DOI 10.1109/CVPR.2011.5995653
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Simard PY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P229
   STORY GA, 1992, COMPUTER, V25, P17, DOI 10.1109/2.156379
   Talib A., 2011, ARC SEGMENTATION CON
   Weissman T, 2005, IEEE T INFORM THEORY, V51, P5, DOI 10.1109/TIT.2004.839518
   Wenyin L., 2005, ARC SEGMENTATION CON
   Zhang P, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P472, DOI 10.1109/ICOSP.2000.894534
NR 18
TC 5
Z9 6
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 748
EP 754
DI 10.1016/j.jvcir.2014.02.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200003
DA 2024-07-18
ER

PT J
AU Zhang, H
   Liu, Y
   Xie, BJ
   Yu, J
AF Zhang, Hui
   Liu, Yi
   Xie, Bojun
   Yu, Jian
TI Orientation contrast model for boundary detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Orientation contrast; Boundary detection; Edge detection; Edge
   magnitude; Edge density; Suppression magnitude; Edge smoothness;
   Steerable filter
ID SURROUND SUPPRESSION; CONTOUR COMPLETION; VISUAL-ATTENTION; TEXTURE;
   SEGMENTATION; CLOSURE
AB The boundary detection task has been extensively studied in the field of computer vision and pattern recognition. Recently, researchers have formulated this task as supervised or unsupervised learning problems to leverage machine learning methods to improve detection accuracy. However, texture suppression, which is important for boundary detection, is not incorporated in this framework. To address this limitation, and also motivated by psychophysical and neurophysiological findings, we propose an orientation contrast model for boundary detection, which combines machine learning technique and texture suppression in a unified framework. Thus, the model is especially suited for detecting object boundaries surrounded by natural textures. Extensive experiments on several benchmarks demonstrate the improved boundary detection performance of the model. Specifically, its detection accuracy was improved by 10% on the Rug dataset compared with state-of-the-art unsupervised boundary detection algorithm, and its performance is also better or at least comparable with previous supervised boundary detection algorithms. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Hui; Liu, Yi; Xie, Bojun; Yu, Jian] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
   [Zhang, Hui; Xie, Bojun] Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding, Hebei, Peoples R China.
C3 Beijing Jiaotong University; Hebei University
RP Zhang, H (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
EM zhanghui@hbu.edu.cn
RI Yu, Jian/HJY-2670-2023
FU National Natural Science Foundation of China [61300072, 61033013];
   Research Fund for the Doctoral Program of Higher Education
   [20120009110006]; Beijing Jiaotong University [K12RC00090]; Research
   Foundation of Education Bureau of Hebei Province [Z2013124]; Science and
   Technology Bureau of Baoding City [13ZS001]
FX The authors acknowledge Grants from the National Natural Science
   Foundation of China (No. 61300072 and No. 61033013), Grants from
   Research Fund for the Doctoral Program of Higher Education (No.
   20120009110006), Grants from Beijing Jiaotong University (No.
   K12RC00090), Grants from Research Foundation of Education Bureau of
   Hebei Province (No. Z2013124) and Grants from Science and Technology
   Bureau of Baoding City (No. 13ZS001) to support this work.
CR [Anonymous], 2010, CVPR, P2520
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Catanzaro B, 2009, IEEE I CONF COMP VIS, P2381, DOI 10.1109/ICCV.2009.5459410
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Elder J. H., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P399, DOI 10.1007/BFb0015553
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hisashi S., 2011, INFORM COMMUN STUD, V44, P15
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kennedy R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2065, DOI 10.1109/CVPR.2011.5995739
   KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495
   Landy M. S., 2004, The visual neurosciences, V2, P1106
   LANDY MS, 1991, VISION RES, V31, P679, DOI 10.1016/0042-6989(91)90009-T
   MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Ming YS, 2012, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2012.6247755
   NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M
   Papari G, 2011, PATTERN RECOGN, V44, P1999, DOI 10.1016/j.patcog.2010.08.013
   Pratt W.K., 1977, DIGITAL IMAGE PROCES
   Ren XF, 2008, INT J COMPUT VISION, V77, P47, DOI 10.1007/s11263-007-0092-6
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Sun YR, 2003, ARTIF INTELL, V146, P77, DOI 10.1016/S0004-3702(02)00399-5
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   [张卉 Zhang Hui], 2012, [中国新药杂志, Chinese Journal New Drugs], V21, P2012
   Zhu QH, 2008, LECT NOTES COMPUT SC, V5303, P774
NR 35
TC 0
Z9 2
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 774
EP 784
DI 10.1016/j.jvcir.2014.01.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200006
DA 2024-07-18
ER

PT J
AU Canessa, A
   Chessa, M
   Gibaldi, A
   Sabatini, SP
   Solari, F
AF Canessa, Andrea
   Chessa, Manuela
   Gibaldi, Agostino
   Sabatini, Silvio P.
   Solari, Fabio
TI Calibrated depth and color cameras for accurate 3D interaction in a
   stereoscopic augmented reality environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D cameras; Human-computer interactions; Calibration and data
   pre-processing; Kinect device; Virtual reality; Spatially variant depth
   correction; Eyes' tracking; Mixed reality
ID KINECT
AB A Human-machine interaction system requires precise information about the user's body position, in order to allow a natural 3D interaction in stereoscopic augmented reality environments, where real and virtual objects should coherently coexist. The diffusion of RGB-D sensors seems to provide an effective solution to such a problem. Nevertheless, the interaction with stereoscopic 3D environments, in particular in peripersonal space, requires a higher degree of precision. To this end, a reliable calibration of such sensors and an accurate estimation of the relative pose of different RGB-D and visualization devices are crucial. Here, robust and straightforward procedures to calibrate a RGB-D camera, to improve the accuracy of its 3D measurements, and to co-register different calibrated devices are proposed. Quantitative measures validate the proposed approach. Moreover, calibrated devices have been used in an augmented reality system, based on a dynamic stereoscopic rendering technique that needs accurate information about the observer's eyes position. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Canessa, Andrea; Chessa, Manuela; Gibaldi, Agostino; Sabatini, Silvio P.; Solari, Fabio] Univ Genoa, Dept Informat Bioengn Robot & Syst Engn DIBRIS, I-16145 Genoa, Italy.
C3 University of Genoa
RP Solari, F (corresponding author), Univ Genoa, Dept Informat Bioengn Robot & Syst Engn DIBRIS, Via AllOpera Pia 13, I-16145 Genoa, Italy.
EM fabio.solari@unige.it
RI CANESSA, ANDREA/J-5587-2018; Sabatini, Silvio P./A-5500-2012; Chessa,
   Manuela/O-4628-2016; Gibaldi, Agostino/A-1219-2015; Solari,
   Fabio/O-4729-2016
OI CANESSA, ANDREA/0000-0001-8946-5290; Sabatini, Silvio
   P./0000-0002-0557-7306; Chessa, Manuela/0000-0003-3098-5894; Gibaldi,
   Agostino/0000-0003-4478-6351; Solari, Fabio/0000-0002-8111-0409
CR Chessa M., 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P15
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   De Araujo Bruno, 2012, 3DCHI 3 DIMENSION CH, P79
   Dutta T, 2012, APPL ERGON, V43, P645, DOI 10.1016/j.apergo.2011.09.011
   Franke T., 2011, Proceedings of the 16th International Conference on 3D Web Technology, P71, DOI DOI 10.1145/2010425.2010439
   Frati V., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P317, DOI 10.1109/WHC.2011.5945505
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   HELD RT, 2008, P 5 S APPL PERC GRAP, P23, DOI DOI 10.1145/1394281.1394285
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Herrera D, 2011, LECT NOTES COMPUT SC, V6855, P437, DOI 10.1007/978-3-642-23678-5_52
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Lensing P., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P261, DOI 10.1109/ISMAR.2011.6143892
   LI L, 2011, P 15 INT C KNOWL BAS, V6881, P424
   Liao HE, 2010, IEEE T BIO-MED ENG, V57, P1476, DOI 10.1109/TBME.2010.2040278
   Maimone A., 2012, REDUCING INTERFERENC, P51
   Maimone A, 2012, COMPUT GRAPH-UK, V36, P791, DOI 10.1016/j.cag.2012.04.011
   Oikonomidis I., 2011, BMVC 2011
   Raheja J. L., 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P248, DOI 10.1109/CIMSim.2011.51
   Sielhorst T, 2006, LECT NOTES COMPUT SC, V4190, P364
   Solari F, 2013, DISPLAYS, V34, P142, DOI 10.1016/j.displa.2012.08.001
   Stone E. E., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P71, DOI 10.4108/icst.pervasivehealth.2011.246034
   Stowers J., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics (ICM), P358, DOI 10.1109/ICMECH.2011.5971311
   Tang Y., 2011, ACM SIGGRAPH 2011
   Wang R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology. UIST '11, P549
   Wang RY., 2009, ACM transactions on graphics (TOG), V28, P1, DOI DOI 10.1145/1531326.1531369
   Wartell Z, 2002, IEEE T VIS COMPUT GR, V8, P129, DOI 10.1109/2945.998666
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
NR 29
TC 39
Z9 43
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 227
EP 237
DI 10.1016/j.jvcir.2013.02.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900020
DA 2024-07-18
ER

PT J
AU Garcia-Alvarez, JC
   Führ, H
   Castellanos-Dominguez, G
AF Garcia-Alvarez, J. C.
   Fuhr, H.
   Castellanos-Dominguez, G.
TI Evaluation of Region-of-Interest coders using perceptual image quality
   assessments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Region-of-Interest; Image coding; Wavelet; Distortion measure; Quality
   assessment; Perceptual evaluation; Human visual system; Mean-observed
   scores; Rate-distortion function
ID COMPRESSION; MAXSHIFT; OPTIONS
AB A perceptual measure emulates the human vision for image quality assessment. This paper illustrates the evaluation of Region-of-Interest (ROI) coders using perceptual image quality assessments. The goal of this evaluation is to characterize the coder performance by controlling the ROI quality. Perceptual measures are taken into account for evaluation since they behave as a human-made evaluation. Moreover, a perceptual assessment named Wavelet Quality Index (WQI), is introduced as another image coder evaluator. Proposed assessment aims at emulating the human vision by a weighted linear combination of three wavelet-based perceptual measures. We evaluate the following types of ROI-coders: those preserving the quality of ROI by coarse compression of background (Max-Shift coder), and those balancing the quality between ROI and background (SCM-Shift, and BB-Shift coders). Using considered assessments for the performance evaluation of coders, results show a variation of evaluation by nature of measurement. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Garcia-Alvarez, J. C.; Castellanos-Dominguez, G.] Univ Nacl Colombia, Signal Proc & Recognit Grp, Manizales, Colombia.
   [Garcia-Alvarez, J. C.; Fuhr, H.] Rhein Westfal TH Aachen, Lehrstuhl Math, Aachen, Germany.
C3 Universidad Nacional de Colombia; RWTH Aachen University
RP Garcia-Alvarez, JC (corresponding author), Univ Nacl Colombia, Signal Proc & Recognit Grp, Manizales, Colombia.
EM jcgarciaa@bt.unal.edu.co; fuehr@matha.rwth-aachen.de;
   cgcastellanosd@unal.edu.co
RI Castellanos-Dominguez, German/W-8196-2019; Garcia-Alvarez, Julio
   Cesar/B-3384-2008
OI Castellanos-Dominguez, German/0000-0002-0138-5489; Garcia-Alvarez, Julio
   Cesar/0000-0003-3153-5828
FU Faculty of Engineering and Architectural Science of the Universidad
   Nacional de Colombia; DAAD-ALECOL Research Visitor Fellowship in RWTH
   Aachen University; project: Servicio de Monitoreo Remoto de Actividad
   Cardiaca para el tamizaje clinico en la red de Telemedicina del
   Departamento de Caldas; Universidad Nacional de Colombia; Universidad de
   Caldas
FX This work is sponsored by the Faculty of Engineering and Architectural
   Science of the Universidad Nacional de Colombia and DAAD-ALECOL 2007
   Research Visitor Fellowship in RWTH Aachen University. This work is
   partially sponsored by the project: Servicio de Monitoreo Remoto de
   Actividad Cardiaca para el tamizaje clinico en la red de Telemedicina
   del Departamento de Caldas funded by the Universidad Nacional de
   Colombia and Universidad de Caldas. Authors wish to thank Professor
   Remco Duits at the Eindhoven University for his helpful observations.
CR Abdou I.E., 1986, ACM FALL JOINT COMP
   Aja-Fernandez S., 2006, 28 IEEE EMBS ANN INT
   Akhtar Pervez, 2008, Journal of Biomedical Science & Engineering, V1, P110, DOI 10.4236/jbise.2008.12018
   [Anonymous], 1998, OBJECTIVE IMAGE VIDE
   [Anonymous], 2003, ADV LEARN THEORY MET
   [Anonymous], 2003, THRITY 7 ASILOMAR C
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bartrina-Rapesta J., 2009, 43 AS C SIGN SYST CO, P558
   Bovik A, 2009, LAB IMAGE VIDEO ENG
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen Y, 2006, LECT NOTES COMPUTER
   Lo CS, 2006, IEEE SYS MAN CYBERN, P553, DOI 10.1109/ICSMC.2006.384442
   Dosselmann R., 1906, IEEE CAN C EL COMP E, P1906
   Duits R, 2007, INT J COMPUT VISION, V72, P79, DOI 10.1007/s11263-006-8894-5
   Ellinas J.N., 2007, INSTICC INT C COMP V
   García JC, 2008, ING COMPET, V10, P73
   Garcia-Alvarez J.-C., 2009, INT C BROADBAND COMM
   Garcia-Alvarez J.-C., 2013, 6 INT C COMP VIS COM
   Ginesu G, 2006, SIGNAL PROCESS-IMAGE, V21, P316, DOI 10.1016/j.image.2005.11.005
   Gonzales R.C., 2003, DIGITAL IMAGE PROCES, V2nd
   Hekstra AP, 2002, SIGNAL PROCESS-IMAGE, V17, P781, DOI 10.1016/S0923-5965(02)00056-5
   Koenen R, 2000, SIGNAL PROCESS-IMAGE, V16, P5, DOI 10.1016/S0923-5965(00)00014-X
   Kosheleva O.M., 2002, IEEE SW S IM AN INT
   Laparra V, 2010, J OPT SOC AM A, V27, P852, DOI 10.1364/JOSAA.27.000852
   Li XL, 2009, SIGNAL PROCESS, V89, P548, DOI 10.1016/j.sigpro.2008.10.007
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Mahmoudi-Aznaveh A, 2009, OPT REV, V16, P30, DOI 10.1007/s10043-009-0007-6
   Przelaskowski A., ACM S APPL COMP ACM, P249
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2004, IEEE INT C AC SPEECH
   Tahoces PG, 2008, COMPUT VIS IMAGE UND, V109, P139, DOI 10.1016/j.cviu.2007.07.001
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   van der Weken D, 2007, IMAGE VISION COMPUT, V25, P184, DOI 10.1016/j.imavis.2006.01.032
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P81, DOI 10.1109/ICIP.2002.1038908
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   You KS, 2006, LECT NOTES CONTR INF, V345, P334
   Zhang T., IEEE INT C EL COMP T, P495
   Zhang Y, 2004, IEEE T MED IMAGING, V23, P613, DOI 10.1109/TMI.2004.826359
   Zhu H., IEEE INT GEOSC REM S, P696
NR 40
TC 4
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1316
EP 1327
DI 10.1016/j.jvcir.2013.09.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700009
OA Bronze
DA 2024-07-18
ER

PT J
AU Lee, TK
   Chan, YL
   Siu, WC
AF Lee, Tsz-Kwan
   Chan, Yui-Lam
   Siu, Wan-Chi
TI Motion estimation in low-delay hierarchical p-frame coding using motion
   vector composition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Vector composition; Low-delay hierarchical P structure;
   Distant reference pictures; H.264 standard; Fast algorithm; Motion
   estimation; Motion vector selection
ID VIDEO; EFFICIENCY; COMPRESSION
AB Low-delay hierarchical prediction structure is currently adopted in various new video coding standards. The only hurdle of this structure is the need of motion estimation in distant reference frames. To maintain high coding efficiency, a large search range for motion estimation can improve the coding efficiency in distant reference pictures. Computational complexity will thus be increased dramatically. In this paper, a fast motion estimation scheme for a low-delay hierarchical P-frame structure is proposed. The proposed scheme adopts a motion vector composition strategy to expedite the motion estimation process for distant reference frames in the hierarchical P structure. In addition, a motion vector composition algorithm is tailor-made with the proposed hierarchical P coding scheme to further improve the coding efficiency. Simulation results show that the proposed scheme can deliver a remarkable complexity savings and coding efficiency improvement on coding a frame in low temporal layers of the hierarchical P structure. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Lee, Tsz-Kwan; Chan, Yui-Lam; Siu, Wan-Chi] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Chan, YL (corresponding author), Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
EM enylchan@polyu.edu.hk
RI ; Chan, Yui-Lam/C-3799-2014
OI Lee, Tsz-Kwan/0000-0003-4176-2215; Chan, Yui-Lam/0000-0002-1473-094X
FU Centre for Signal Processing; Internal Competitive Research Grant,
   Department of Electronic and Information Engineering, The Hong Kong
   Polytechnic University [PolyU G-YL20]
FX The work described in this paper is partially supported by the Centre
   for Signal Processing and a grant from the Internal Competitive Research
   Grant, Department of Electronic and Information Engineering, The Hong
   Kong Polytechnic University (PolyU G-YL20). T.K. Lee acknowledges the
   research studentships provided by the University.
CR [Anonymous], 2007, SCAL VID COD
   [Anonymous], 2006, 1381822000COR ISOIEC
   [Anonymous], 2012, 14496102005VER162012
   [Anonymous], JCTVCK1100 JCTVC
   [Anonymous], 2005, VID COD LOW BIT RAT
   [Anonymous], 2010, 1449622004COR42010 I
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Diaz-Honrubia A.J., 2012, P WORKSH MULT DAT CO, P1
   Fezza S. A., 2011, 2011 7th International Workshop on Systems, Signal Processing and their Applications (WOSSPA 2011), P111, DOI 10.1109/WOSSPA.2011.5931426
   Fu CH, 2010, J VIS COMMUN IMAGE R, V21, P939, DOI 10.1016/j.jvcir.2010.09.003
   Hierarchical B, 2005, JVTP014 ISOIEC MPEG
   Hong D., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P146, DOI 10.1109/PCS.2010.5702445
   ITU-T, 1993, VID COD AUD SERV P 6
   Jaemoon Kim, 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P11, DOI 10.1109/ICCE-Berlin.2012.6336484
   Lee B, 2012, IEEE T BROADCAST, V58, P285, DOI 10.1109/TBC.2012.2184154
   Leontaris A, 2007, IEEE T IMAGE PROCESS, V16, P1726, DOI 10.1109/TIP.2007.896681
   Maarif H.A.Q., 2010, ADV MULTIMEDIA INT J, V1, P12
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Ohm JR, 2013, IEEE SIGNAL PROC MAG, V30, P152, DOI 10.1109/MSP.2012.2219672
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Sullivan J., 2010, P SOC PHOTO-OPT INS, V7798, P7798
   Tanj YP, 2003, IEEE T CONSUM ELECTR, V49, P1098, DOI 10.1109/TCE.2003.1261202
   TIAN G, 2009, P INT C INF TECHN CO, P433
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wan WX, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P301
   WINKEN M, 2007, P IEEE INT C IM PROC, V4, P89
   Yang S., 2005, P INT C IM PROC ICIP, P668
   Youn J, 1999, IEEE T MULTIMEDIA, V1, P30, DOI 10.1109/6046.748169
NR 32
TC 4
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1243
EP 1251
DI 10.1016/j.jvcir.2013.08.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700003
DA 2024-07-18
ER

PT J
AU Wang, SZ
   Wang, ZY
   Hu, RM
AF Wang, Shi-zheng
   Wang, Zhong-yuan
   Hu, Rui-min
TI Surveillance video synopsis in the compressed domain for fast video
   browsing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Surveillance video; Compressed domain; Video synopsis; Video labeling;
   Scalable browsing; Fast browsing; Background modeling; Intelligent video
ID MOVING OBJECT SEGMENTATION
AB The traditional pixel-domain based video analysis methods have taken dominated places for long. However, due to the rapidly increasing volume and resolution of surveillance video, the desirable fast and scalable browsing encounters significant challenges in terms of efficiency and flexibility. Under this circumstance, operating surveillance video in compressed domain has aroused great concern in academy and industry. In order to perform the intelligent video analysis task on the premise of preserving accuracy and controlling complexity, this paper presents a compressed-domain approach for massive surveillance video synopsis generation, labeling and browsing. The main work and achievements include: (1) a compressed-domain scheme is established to condense the compressed surveillance video and record the synopsis results; (2) a background modeling method via the Motion Vector based Local Binary Pattern (MVLBP) is introduced to extract moving objects in an efficient way; (3) an object flags based synopsis labeling method is proposed to represent the object regions as well as their display modes in a flexible way. Experimental results show that the video analysis system based on this framework can provide not only efficient synopsis generation but also flexible scalable or playback browsing. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Shi-zheng; Wang, Zhong-yuan; Hu, Rui-min] Wuhan Univ, Wuhan 430072, Peoples R China.
   [Wang, Shi-zheng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Wuhan University; Chinese Academy of Sciences; Institute of Automation,
   CAS
RP Wang, ZY (corresponding author), Wuhan Univ, Wuhan 430072, Peoples R China.
EM wzy_hope@163.com
RI Wang, Zhongyuan/ABD-2189-2020
FU National Science Foundation of China [61231015, 61172173, 61070080,
   61003184, 61170023]; major national science and technology special
   project [2010ZX03004-003-03]; National Basic Research Program of China
   (973Program) [20-09CB320906]
FX This work was supported by the grants of the National Science Foundation
   of China (61231015, 61172173, 61070080, 61003184, 61170023), the major
   national science and technology special project (2010ZX03004-003-03),
   and the National Basic Research Program of China (973Program)
   (20-09CB320906).
CR Akdemir U., 2008, Proc. ACMMM, P709, DOI DOI 10.1145/1459359.1459466
   Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   [Anonymous], P 16 ACM INT C MULT
   [Anonymous], 10 ECCV 3
   [Anonymous], P 2006 IEEE COMP SOC
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Avrithis YS, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P91, DOI 10.1109/IVL.1998.694508
   Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337
   Carlier Axel, 2010, P 18 ACM INT C MULT, P201
   Chen YM, 2011, IEEE T MULTIMEDIA, V13, P421, DOI 10.1109/TMM.2011.2127464
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Huang KQ, 2011, IEEE T SYST MAN CY B, V41, P307, DOI 10.1109/TSMCB.2009.2037923
   Ji S, 2000, ELECTRON LETT, V36, P1769, DOI 10.1049/el:20001279
   Li Z., 2008, Proceedings of the 16th ACM international conference on Multimedia, P671
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Liu HW, 2011, J VIS COMMUN IMAGE R, V22, P432, DOI 10.1016/j.jvcir.2011.03.010
   Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paul M., 2013, EURASIP Journal on Advances in Signal Processing, P1
   Paul M, 2011, IEEE T CIRC SYST VID, V21, P1242, DOI 10.1109/TCSVT.2011.2138750
   Philip D., 2010, P ACM INT C MULT, P371, DOI [10.1145/1873951.1874002, DOI 10.1145/1873951.1874002]
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P428, DOI 10.1016/j.jvcir.2009.05.001
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   SAMET H, 1985, COMMUN ACM, V28, P973, DOI 10.1145/4284.4290
   Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3
   Shikun Feng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P17, DOI 10.1109/ICPR.2010.13
   Shizheng Wang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1947, DOI 10.1109/ICCVW.2011.6130487
   Smith MA, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P61, DOI 10.1109/CAIVD.1998.646034
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Wang WQ, 2008, IEEE T CIRC SYST VID, V18, P670, DOI 10.1109/TCSVT.2008.918800
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu chiFeng., 2008, Proceeding of ACM Multimedia 2008), Vancouver, British Columbia, P745
   YILDIRIM A, 2008, INT J COMPUT MATH, DOI DOI 10.1080/00207160802247646
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
   Zhang XY, 2012, PROCEEDINGS OF THE ASME 10TH FUEL CELL SCIENCE, ENGINEERING, AND TECHNOLOGY CONFERENCE, 2012, P1, DOI 10.1109/ACC.2007.4282196
NR 40
TC 16
Z9 19
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1431
EP 1442
DI 10.1016/j.jvcir.2013.10.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700017
DA 2024-07-18
ER

PT J
AU Duan, YP
   Huang, WM
AF Duan, Yuping
   Huang, Weimin
TI A fixed-point augmented Lagrangian method for total variation
   minimization problems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convex optimization; Dual approaches; Augmented Lagrangian method;
   Fixed-point method; Alternating minimization algorithm; Total variation;
   First-order algorithm; Image denoising
ID SPLIT BREGMAN ITERATION; PRIMAL-DUAL METHOD; ALGORITHM; DECOMPOSITION;
   RESTORATION; ROF; TV
AB In this paper, we propose a fixed-point augmented Lagrangian method (FPALM) for general convex problems arising in image processing. We can easily obtain the alternating minimization algorithm (AMA) referred to [1] from the proposed FPALM. The proof for the convergence of the FPALM is provided under some mild assumptions. We present two kinds of first-order augmented Lagrangian schemes and show their connections to first-order primal-dual algorithms [2]. Furthermore, we apply an acceleration rule to both the FPALM and AMA to achieve better convergence rates. Numerical examples on different image denosing models including the ROF model, the vectorial TVmodel, high order models and the TV-L-1 model are provided to demonstrate the efficiency of the proposed algorithms. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Duan, Yuping; Huang, Weimin] ASTAR, Inst Infocomm Res, Singapore, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Duan, YP (corresponding author), ASTAR, Inst Infocomm Res, Singapore, Singapore.
EM duany@i2r.a-star.edu.sg; wmhuang@i2r.a-star.e-du.sg
RI wang, tong/HTR-5412-2023; Duan, Yuping/AAH-5030-2020
CR Aujol JF, 2006, J VIS COMMUN IMAGE R, V17, P916, DOI 10.1016/j.jvcir.2005.02.001
   Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Bresson X, 2008, INVERSE PROBL IMAG, V2, P455, DOI 10.3934/ipi.2008.2.455
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Dong YQ, 2009, SIAM J IMAGING SCI, V2, P1168, DOI 10.1137/090758490
   Esser E., 2009, 0931 UCLA CAM DEP MA
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Huang YM, 2008, MULTISCALE MODEL SIM, V7, P774, DOI 10.1137/070703533
   Jia RQ, 2010, ADV COMPUT MATH, V33, P231, DOI 10.1007/s10444-009-9128-5
   LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Nesterov Y., 1983, SOV MATH DOKL, V27, P372
   Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Rockafellar R. T., 1976, Mathematics of Operations Research, V1, P97, DOI 10.1287/moor.1.2.97
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tai X.-C., 1994, CONT MATH, V180, P355
   Tai XC, 1998, SIAM J NUMER ANAL, V35, P1558, DOI 10.1137/S0036142996297461
   Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502
   TSENG P, 1991, SIAM J CONTROL OPTIM, V29, P119, DOI 10.1137/0329006
   Vogel CR, 1998, IEEE T IMAGE PROCESS, V7, P813, DOI 10.1109/83.679423
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Weickert J, 1996, THESIS U KAISERSLAUT
   Wu CL, 2012, J SCI COMPUT, V50, P145, DOI 10.1007/s10915-011-9477-3
   Wu CL, 2011, INVERSE PROBL IMAG, V5, P237, DOI 10.3934/ipi.2011.5.237
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Yin WT, 2010, SIAM J IMAGING SCI, V3, P856, DOI 10.1137/090760350
   Yuan, ACCELERATION AUGMENT
   Zhang XQ, 2011, J SCI COMPUT, V46, P20, DOI 10.1007/s10915-010-9408-8
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
   Zhu M., 2008, 0834 UCLA CAM DEP MA
NR 47
TC 6
Z9 8
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1168
EP 1181
DI 10.1016/j.jvcir.2013.07.014
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700040
DA 2024-07-18
ER

PT J
AU Rahman, SA
   Leung, MKH
   Cho, SY
AF Rahman, Shah Atiqur
   Leung, M. K. H.
   Cho, Siu-Yeung
TI Human action recognition employing negative space features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Negative space; Silhouette; Dynamic Time
   Warping; Complex activity; Fuzzy function; Computer vision; Region
   partitioning
ID IMAGE; SHAPE; APPEARANCE; TRACKING; POINTS; SEARCH; FLOW
AB We proposed a region based method to recognize human actions from video sequences. Unlike other region based methods, it works with the surrounding regions of the human silhouette termed as negative space. This paper further extends the idea of negative space to cope with the changes in viewpoints. It also addresses the problem of long shadows which is one of the major challenges of human action recognition. Some systems attempt suppressing shadows during the segmentation process but our system takes input of segmented binary images of which the shadow is not suppressed. This makes our system less dependent on segmentation process. Further, this approach can complement the positive space (silhouette) based methods to boost recognition. The system consists of a hierarchical processing: histogram analysis on segmented input image, followed by motion and shape feature extraction, pose sequence analysis by employing Dynamic Time Warping and at last classification by Nearest Neighbor classifier. We evaluated our system by most commonly used datasets and achieved higher accuracy than the state of the arts methods. Our system can also retrieve video sequences from queries of human action sequences. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Rahman, Shah Atiqur] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Leung, M. K. H.] Univ Tunku Abdul Rahman Kampar, FICT, Kampar, Perak, Malaysia.
   [Cho, Siu-Yeung] Univ Nottingham Ningbo, Sch EEE, Ningbo, Zhejiang, Peoples R China.
C3 Nanyang Technological University; University of Nottingham Ningbo China
RP Rahman, SA (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM shah0018@ntu.edu.sg; asmkleung@gmail.com; davidcho@pmail.ntu.edu.sg
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], ACM INT C MULT ACM V
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], INT C IM PROC COMP V
   [Anonymous], 2007, 2007 IEEE C COMPUTER
   [Anonymous], HUMAN ACTION RECOGNI
   [Anonymous], ACM INT C IM VID RET
   Bian W, 2012, IEEE T SYST MAN CY B, V42, P298, DOI 10.1109/TSMCB.2011.2166761
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2012, PATTERN RECOGN, V45, P1220, DOI 10.1016/j.patcog.2011.08.014
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chen CH, 2011, PATTERN RECOGN, V44, P988, DOI 10.1016/j.patcog.2010.10.021
   Cheung GKM, 2000, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2000.854944
   Davis JW, 2006, IMAGE VISION COMPUT, V24, P455, DOI 10.1016/j.imavis.2006.01.012
   Diaf A, 2010, LECT NOTES COMPUT SC, V6111, P167, DOI 10.1007/978-3-642-13772-3_18
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Fathi A., 2008, COMPUT VIS PATTERN R, P1
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Goldenberg R, 2005, PATTERN RECOGN, V38, P1033, DOI 10.1016/j.patcog.2004.11.024
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   GUO Y, 1994, INT C PATT RECOG, P325, DOI 10.1109/ICPR.1994.576929
   Han J, 2005, IEEE COMP SOC C COMP, P17
   Ikizler N, 2008, INT J COMPUT VISION, V80, P337, DOI 10.1007/s11263-008-0142-8
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Ji RR, 2011, PATTERN RECOGN, V44, P624, DOI 10.1016/j.patcog.2010.08.022
   Jia K., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587732
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35
   LEUNG MK, 1995, IEEE T PATTERN ANAL, V17, P359, DOI 10.1109/34.385981
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lin HW, 2012, LECT NOTES COMPUT SC, V7131, P266
   Lin WY, 2008, IEEE INT SYMP CIRC S, P2737, DOI 10.1109/ISCAS.2008.4542023
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahman SA, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P354, DOI 10.1109/CW.2010.29
   Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Saleemi I, 2010, PROC CVPR IEEE, P2069, DOI 10.1109/CVPR.2010.5539884
   Schindler K., 2008, COMPUT VIS PATTERN R, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Shen Y., 2008, IEEE C COMPUTER VISI, P1, DOI DOI 10.1109/CVPR.2008.4587755
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Wang L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P1
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Wanqing Li, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P175, DOI 10.1109/MMSP.2008.4665070
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wilkins G., 2009, AFRICON, P1
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu XX, 2010, PATTERN RECOGN, V43, P4190, DOI 10.1016/j.patcog.2010.07.012
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
NR 64
TC 12
Z9 12
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 217
EP 231
DI 10.1016/j.jvcir.2012.12.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200002
DA 2024-07-18
ER

PT J
AU Wang, XY
   Niu, PP
   Yang, HY
   Chen, LL
AF Wang, Xiang-yang
   Niu, Pan-pan
   Yang, Hong-ying
   Chen, Li-li
TI Affine invariant image watermarking using intensity probability
   density-based Harris Laplace detector
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking; Geometric distortion; Intensity probability density;
   Affine invariant local ellipse region; Nonsubsampled contourlet
   transform; Harris-Laplace detector; Image feature point; Synchronization
   error
ID SCALE; RESILIENT; ROTATION; REGIONS; SCHEME
AB Feature point based image watermarking against geometric distortions has attracted great attention in recent years. However, for the state-of-the-art intensity based feature points detectors, the feature points often gather at textured portions of the image or on the edges where the change of intensity is significant, so that many feature points capture the same portion of the image, which makes the watermark be vulnerable to local geometric distortions. In this paper, we propose an affine invariant image watermarking scheme with good visual quality and reasonable resistance toward local geometric distortions, which utilizes the intensity probability density-based Harris-Laplace detector. Firstly, the uniform and robust feature points are extracted by utilizing modified Harris-Laplace detector, in which the intensity probability density gradient is used instead of intensity gradient. Then, the affine invariant local ellipse regions (LERs) are constructed adaptively according to the variation of local intensity probability density. Finally, the digital watermark is embedded into the affine invariant LERs in nonsubsampled contourlet transform (NSCT) domain by modulating the lowpass NSCT coefficients. By binding the watermark with the affine invariant LERs, the watermark detection can be done without synchronization error. Experimental results show that the proposed image watermarking is not only invisible and robust against common image processing operations such as sharpening, noise adding, and JPEG compression, but also robust against the global affine transforms and local geometric distortions. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Wang, Xiang-yang; Niu, Pan-pan; Yang, Hong-ying; Chen, Li-li] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-yang] Chinese Acad Sci, Inst Software, State Key Lab Informat Secur, Beijing 100190, Peoples R China.
C3 Liaoning Normal University; Chinese Academy of Sciences; Institute of
   Software, CAS
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [60773031, 60873222]; Open
   Foundation of State Key Laboratory of Information Security of China
   [04-06-1]; Open Foundation of Network and Data Security Key Laboratory
   of Sichuan Province; Liaoning Research Project for Institutions of
   Higher Education of China [L2010230, 2008351]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 60773031 and 60873222, the Open Foundation of
   State Key Laboratory of Information Security of China under Grant No.
   04-06-1, the Open Foundation of Network and Data Security Key Laboratory
   of Sichuan Province, and Liaoning Research Project for Institutions of
   Higher Education of China under Grant Nos. L2010230 and 2008351.
CR Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Deng Cheng, 2010, Acta Automatica Sinica, V36, P221, DOI 10.3724/SP.J.1004.2010.00221
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Guijun Nian, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P43, DOI 10.1109/MMIT.2010.93
   Khan MK, 2011, MULTIMED TOOLS APPL, V52, P257, DOI 10.1007/s11042-011-0741-1
   KUMAR A, 1994, INT J DEV NEUROSCI, V12, P31, DOI 10.1016/0736-5748(94)90093-0
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lee HY, 2007, MULTIMED TOOLS APPL, V34, P337, DOI 10.1007/s11042-007-0112-0
   Li JZ, 2010, APPL OPTICS, V49, P6302, DOI 10.1364/AO.49.006302
   Li LD, 2011, IEICE T FUND ELECTR, VE94A, P889, DOI 10.1587/transfun.E94.A.889
   Li LD, 2010, INFORM SCIENCES, V180, P2875, DOI 10.1016/j.ins.2010.04.009
   Li L, 2011, J SYST SOFTWARE, V84, P923, DOI 10.1016/j.jss.2011.01.025
   [李旭东 LI Xu-dong], 2010, [光电工程, Opto-Electronic Engineering], V37, P96
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Lin YT, 2011, IET IMAGE PROCESS, V5, P328, DOI 10.1049/iet-ipr.2009.0264
   Lingfang Zhang, 2010, 2010 Proceedings of the Third International Symposium on Information Processing (ISIP 2010), P389, DOI 10.1109/ISIP.2010.127
   Liu Y, 2007, MULTIMED TOOLS APPL, V34, P57, DOI 10.1007/s11042-006-0072-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu W, 2010, COMPUT ELECTR ENG, V36, P2, DOI 10.1016/j.compeleceng.2009.04.002
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Pei SC, 2010, IEEE INT CON MULTI, P122, DOI 10.1109/ICME.2010.5583883
   Pham VQ, 2008, IEICE T INF SYST, VE91D, P2027, DOI 10.1093/ietisy/e91-d.7.2027
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Sun Da, 2008, Acta Automatica Sinica, V34, P854, DOI 10.3724/SP.J.1004.2008.00854
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Tuytelaars Tinne., 2008, FNT COMPUTER GRAPHIC, V1, P1
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Wang XY, 2009, EXPERT SYST APPL, V36, P9056, DOI 10.1016/j.eswa.2008.12.040
   Wang XY, 2007, IEEE T INF FOREN SEC, V2, P655, DOI 10.1109/TIFS.2007.908233
   Wu J., 2006, J SHANGHAI JIAOTONG, V40, P481
   Wu JZ, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P572, DOI 10.1109/IAS.2009.176
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang L, 2010, TELECOMMUN SYST, V44, P205, DOI 10.1007/s11235-009-9260-z
   Zhang XP, 2008, IEEE T CIRC SYST VID, V18, P769, DOI 10.1109/TCSVT.2008.919088
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
   Zhu HQ, 2010, DIGIT SIGNAL PROCESS, V20, P1612, DOI 10.1016/j.dsp.2010.01.010
NR 47
TC 16
Z9 18
U1 0
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 892
EP 907
DI 10.1016/j.jvcir.2012.05.008
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900007
DA 2024-07-18
ER

PT J
AU Yang, SM
   Tai, SC
AF Yang, Shih-Ming
   Tai, Shen-Chuan
TI A design framework for hybrid approaches of image noise estimation and
   its application to noise reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Noise estimation; Noise reduction; Image restoration; Image enhancement;
   Bilateral filter; Non-local mean filter; Laplacian operator; Sobel
   operator
ID ENHANCEMENT; FILTERS
AB Noise estimation is an important process in digital imaging systems. Many noise reduction algorithms require their parameters to be adjusted based on the noise level. Filter-based approaches of image noise estimation usually were more efficient but had difficulty on separating noise from images. Block-based approaches could provide more accurate results but usually required higher computation complexity. In this work, a design framework for combining the strengths of filter-based and block-based approaches is presented. Different homogeneity analyzers for identifying the homogeneous blocks are discussed and their performances are compared. Then, two well-known filters, the bilateral and the non-local mean, are reviewed and their parameter settings are investigated. A new bilateral filter with edge enhancement is proposed. A modified non-local mean filter with much less complexity is also present. Compared to the original non-local mean filter, the complexity is dramatically reduced by 75% and yet the image quality is maintained. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Yang, Shih-Ming; Tai, Shen-Chuan] Natl Cheng Kung Univ, Inst Comp & Commun Engn, Dept Elect Engn, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Yang, SM (corresponding author), Natl Cheng Kung Univ, Inst Comp & Commun Engn, Dept Elect Engn, 1 Univ Rd, Tainan 701, Taiwan.
EM vincentnutn@gmail.com; sctai@mail.ncku.edu.tw
CR Aja-Fernández S, 2009, IMAGE VISION COMPUT, V27, P756, DOI 10.1016/j.imavis.2008.08.002
   Amer A, 2005, IEEE T CIRC SYST VID, V15, P113, DOI 10.1109/TCSVT.2004.837017
   Bilcu R. C., 2005, P IEEE EUR INT WORKS, P290
   Bilcu R.C., 2006, WSEAS T CIRCUITS SYS, V5
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Calvagno G, 2004, IEEE T CIRC SYST VID, V14, P1156, DOI 10.1109/TCSVT.2004.833167
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Ghazal M, 2008, IEEE T CIRC SYST VID, V18, P1797, DOI 10.1109/TCSVT.2008.2004925
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gunn SR, 1999, PATTERN RECOGN, V32, P1463, DOI 10.1016/S0031-3203(98)00163-0
   Gunturk B.K., 2011, COMPUTATIONAL PHOTOG
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Khalil HH, 2008, GEOMETRIC MODELING & IMAGING: MODERN TECHNIQUES AND APPLICATIONS, P92, DOI 10.1109/GMAI.2008.7
   LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   MASTIN GA, 1985, COMPUT VISION GRAPH, V31, P103, DOI 10.1016/S0734-189X(85)80078-5
   OLSEN SI, 1993, CVGIP-GRAPH MODEL IM, V55, P319, DOI 10.1006/cgip.1993.1022
   Paris S., 2007, ACM SIGGRAPH
   Rank K, 1999, IEE P-VIS IMAGE SIGN, V146, P80, DOI 10.1049/ip-vis:19990238
   Russo F, 2007, IEEE T INSTRUM MEAS, V56, P1435, DOI 10.1109/TIM.2007.899887
   Russo F, 2006, IEEE T INSTRUM MEAS, V55, P1935, DOI 10.1109/TIM.2006.884347
   Russo F, 2006, IEEE T INSTRUM MEAS, V55, P1362, DOI 10.1109/TIM.2006.876404
   Salmeri M, 2001, IEEE IMAGE PROC, P517, DOI 10.1109/ICIP.2001.959067
   Shin DH, 2005, IEEE T CONSUM ELECTR, V51, P218, DOI 10.1109/TCE.2005.1405723
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yang S.M., 2011, 1 INT C EL CONTR COM
   Yang SM, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3476329
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang M, 2008, INT CONF ACOUST SPEE, P929
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
NR 34
TC 9
Z9 11
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 812
EP 826
DI 10.1016/j.jvcir.2012.04.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400011
DA 2024-07-18
ER

PT J
AU Chen, SK
   Lin, SJ
AF Chen, Shang-Kuan
   Lin, Sian-Jheng
TI Optimal (2, n) and (2, infinity) visual secret sharing by generalized
   random grids
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast; Random grids; Visual cryptography; Visual secret sharing;
   Generalized random grids; Image sharing; Secret image sharing; Optimal
   contrast
ID IMAGE ENCRYPTION; CRYPTOGRAPHY; SCHEMES
AB Based on generalized random grids, this paper proposes two visual cryptography methods denoted as (2, n) GRG and (2, infinity) GRG. The (2, n) GRG is suitable for the pre-decided number of shares, and the (2, infinity) method is suitable for the adjustable number of shares. The proposed (2, n) GRG achieves better contrast on the stacking result, and the proposed (2, infinity) GRG enables extending the number of shares anytime. Based on the definition of contrast in Shyu's work in 2007, we also demonstrate that the stacking result of (2, n) GRG is close to the theoretical bound of the contrast, and the stacking result of (2, infinity) GRG achieves the theoretical bound of the contrast. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Chen, Shang-Kuan] Yuanpei Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
   [Lin, Sian-Jheng] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan.
C3 Academia Sinica - Taiwan
RP Chen, SK (corresponding author), Yuanpei Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
EM skchen@mail.ypu.edu.tw; sjlin@citi.sinica.edu.tw
FU National Science Council, Taiwan [NSC 100-2221-E-264-013]
FX We would like to thank the anonymous reviewers for their valuable
   comments and suggestions. This research is supported by the National
   Science Council, Taiwan under the grant NSC 100-2221-E-264-013.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Chen SK, 2009, OPT ENG, V48, DOI 10.1117/1.3262345
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Fang WP, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2193912
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wang DS, 2011, INFORM SCIENCES, V181, P2189, DOI 10.1016/j.ins.2011.01.019
   Yang CN, 2005, PATTERN RECOGN LETT, V26, P193, DOI 10.1016/j.patrec.2004.08.025
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 16
TC 14
Z9 16
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 677
EP 684
DI 10.1016/j.jvcir.2012.03.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500009
DA 2024-07-18
ER

PT J
AU Cheng, HY
   Hwang, JN
AF Cheng, Hsu-Yung
   Hwang, Jenq-Neng
TI Integrated video object tracking with applications in trajectory-based
   event detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tracking; Kalman Filter; Adaptive particle sampling; Data Association;
   Trajectory analysis; Event detection; Intelligent Surveillance; Video
   Analysis
ID PARTICLE FILTERS; SURVEILLANCE; RECOGNITION; APPEARANCE; ALGORITHMS;
   TUTORIAL; MOTION; MODELS
AB This work presents an automated and integrated framework that robustly tracks multiple targets for video-based event detection applications. Integrating the advantages of adaptive particle sampling and mathematical tractability of Kalman filtering, the proposed tracking system achieves both high tracking accuracy and computational simplicity. Occlusion and segmentation error cases are analyzed and resolved by constructing measurement candidates via adaptive particle sampling and an enhanced version of probabilistic data association. Also, we integrate the initial occlusion handling module in the tracking system to backtrack and correct the object trajectories. The reliable tracking results can serve as the foundation for automatic event detection. We also demonstrate event detection by classifying the trajectories of the tracked objects from both traffic monitoring and human surveillance applications. The experimental results have shown that the proposed tracking mechanism can solve the occlusion and segmentation error problems effectively and the events can be detected with high accuracy. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Cheng, Hsu-Yung] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taoyuan County, Taiwan.
   [Hwang, Jenq-Neng] Univ Washington, Dept Elect Engn, Paul Allen Ctr, Seattle, WA 98195 USA.
C3 National Central University; University of Washington; University of
   Washington Seattle
RP Cheng, HY (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.
EM chengsy@csie.ncu.edu.tw; hwang@u.washington.edu
OI Cheng, Hsu-Yung/0000-0002-8342-7450
CR [Anonymous], 1974, Pattern Recognition Principles, DOI DOI 10.1002/ZAMM.19770570626
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BARSHALOM Y, 1975, AUTOMATICA, V11, P451, DOI 10.1016/0005-1098(75)90021-7
   Bashir F., 2004, PROC 6 ACM SIGMM INT, P235
   Chen LCL, 2004, PACLIC 18: Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation, P227, DOI 10.1145/1026711.1026749
   Cheng HY, 2009, SIGNAL PROCESS, V89, P1844, DOI 10.1016/j.sigpro.2009.03.034
   CHENG HY, 2007, 2007 IEEE INT C AC S
   Conte D, 2006, PATTERN RECOGN, V39, P562, DOI 10.1016/j.patcog.2005.10.012
   Foresti GL, 1998, IEEE T CIRC SYST VID, V8, P697, DOI 10.1109/76.728411
   Foresti GL, 1999, IEEE T CIRC SYST VID, V9, P1045, DOI 10.1109/76.795058
   FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kalman R.E., 1961, J BASIC ENG-T ASME, V83, P95, DOI 10.1115/1.3658902
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0
   Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8
   MAGGIO E, 2005, P IEEE SIGN PROC SOC, P221
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Qu W, 2007, IEEE T MULTIMEDIA, V9, P511, DOI 10.1109/TMM.2006.886266
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   SENIOR A, 2001, P 2 INT WORKSH PERF
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   UHLMANN JK, 1992, AM SCI, V80, P128
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   WU L, 2006, 6 WORLD C INT CONTR, V1, P4331
   Xu G, 2005, IEEE T CIRC SYST VID, V15, P1422, DOI 10.1109/TCSVT.2005.856903
   Zhong H, 2004, PROC CVPR IEEE, P819
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 31
TC 31
Z9 33
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 673
EP 685
DI 10.1016/j.jvcir.2011.07.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800010
DA 2024-07-18
ER

PT J
AU Xiao, S
   Wang, H
   Kuo, CCJ
AF Xiao, Song
   Wang, Hui
   Kuo, C. -C. Jay
TI A practical bit stream organization algorithm for robust H.264/SVC
   transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable video coding (SVC); Priority ordering; Combined 3D scalability;
   Rate-distortion; Post processing; Path selection; Bit stream
   organization; Unequal error protection (UEP)
ID SCALABLE VIDEO MULTICAST; PROTECTION; EXTENSION; QUALITY
AB The H.264/SVC standard, due to its desired scalable functionality and coding efficiency, provides an ideal candidate for video transmission in many scenarios such as erasure networks and networks with heterogeneous clients. In order to reduce the impact of network bandwidth fluctuation, an adaptive priority ordering (APO) algorithm for H.264/SVC bit stream organization is proposed. It arranges H.264/SVC coding layers according to their rate-distortion (R-D) tradeoff within a GOP so that transmitted video quality can be preserved in the presence of dynamic bandwidth conditions. A practical path model is developed to reduce the time and space complexity of the APO algorithm. It is shown by simulation results that the APO algorithm offers better performance than the default H.264/SVC ordering method adopted by the JSVM software and the quality layer-based ordering method proposed previously in preserving smooth video quality under the same bandwidth. The proposed algorithms could be used together with the unequal error protection (UEP) method and the joint source-channel coding scheme to combat packet loss. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Xiao, Song] Xidian Univ, ISN Key Lab, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Hui; Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 Xidian University; University of Southern California
RP Xiao, S (corresponding author), Xidian Univ, ISN Key Lab, Xian 710071, Shaanxi, Peoples R China.
EM xiaosong_xidian@hotmail.com
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU NSFC [60702058, 60532060, 60832001]; CAST; SRF for ROCS; SEM;
   Fundamental Research Funds for the Central Universities; "111" project
   [B08038]
FX This work is supported by NSFC (No. 60702058, No. 60532060 and No.
   60832001), the CAST innovation fund, the SRF for ROCS, the SEM, the
   Fundamental Research Funds for the Central Universities and the "111"
   project (No. B08038).
CR Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   Amon P, 2007, IEEE T CIRC SYST VID, V17, P1174, DOI 10.1109/TCSVT.2007.905521
   Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   [Anonymous], IEEE COMPUTER COMMUN
   Fang T, 2006, IEEE T IMAGE PROCESS, V15, P1323, DOI 10.1109/TIP.2005.864159
   *ISO IEC MPEG ITU, 2007, JVTX201 ISOIEC MPEG
   Kim J, 2004, IEEE T IMAGE PROCESS, V13, P1547, DOI 10.1109/TIP.2004.837552
   Kondi LP, 2002, IEEE T IMAGE PROCESS, V11, P1043, DOI 10.1109/TIP.2002.802507
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   Reichel J., 2007, JOINT SCALABLE VIDEO
   SCHWARZ H, 2007, JVTV126 ISOIEC MPEG
   Song Xiao, 2008, 2008 22nd International Conference on Advanced Information Networking and Applications - Workshops, P896, DOI 10.1109/AINA.2008.149
   Stoufs M, 2008, IEEE T CIRC SYST VID, V18, P1657, DOI 10.1109/TCSVT.2008.2004922
   Vukobratovic D, 2009, IEEE T MULTIMEDIA, V11, P1094, DOI 10.1109/TMM.2009.2026087
   Wang YK, 2007, IEEE T CIRC SYST VID, V17, P1149, DOI 10.1109/TCSVT.2007.906827
   WIEGAND T, 2007, JVTW201
   WIEGAND T, 2006, JTCSC29WG11 ISOIEC
   Xiao S, 2007, LECT NOTES COMPUT SC, V4810, P520
NR 19
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 871
EP 879
DI 10.1016/j.jvcir.2010.08.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500011
DA 2024-07-18
ER

PT J
AU Chen, WC
   Chou, HL
   Chen, Z
AF Chen, Wen-Chao
   Chou, Hong-Long
   Chen, Zen
TI A quality controllable multi-view object reconstruction method for 3D
   imaging systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D imaging system; Modeling from silhouettes; Octree model; XOR
   projection error; System performance; Dynamic modeling; Progressive
   transmission; Multi-camera system
ID OCTREE CONSTRUCTION; CAPTURE; REPRESENTATION; TECHNOLOGIES
AB This paper addresses a novel multi-view visual hull mesh reconstruction for 3D imaging with a system quality control capability. There are numerous 3D imaging methods including multi-view stereo algorithms and various visual hull/octree reconstruction methods known as modeling from silhouettes. The octree based reconstruction methods are conceptually simple to implement, while encountering a conflict between model accuracy and memory size. Since the tree depth is discrete, the system performance measures (in terms of accuracy, memory size, and computation time) are generally varying rapidly with the pre-specified tree depth. This jumping system performance is not suitable for practical applications; a desirable 3D reconstruction method must have a finer control over the system performance. The proposed method aims at the visual quality control along with better management of memory size and computation time. Furthermore, dynamic object modeling is made possible by the new method. Also, progressive transmission of the reconstructed model from coarse to fine is provided. The reconstruction accuracy of the 3D model acquired is measured by the exclusive OR (XOR) projection error between the pairs of binary images: the reconstructed silhouettes and the true silhouettes in the multiple views. Interesting properties of the new method and experimental comparisons with other existing methods are reported. The performance comparisons are made under either a comparable silhouette inconsistency or a similar triangle number of the mesh model. It is shown that under either condition the new method requires less memory size and less computation time. (C) 2010 Published by Elsevier Inc.
C1 [Chen, Wen-Chao; Chen, Zen] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Chou, Hong-Long] Altek Corp, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, Z (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM chaody.cs94g@nctu.edu.tw; hlchou@altek.com.tw; zchen@cs.nctu.edu.tw
CR Alatan AA, 2007, IEEE T CIRC SYST VID, V17, P1587, DOI 10.1109/TCSVT.2007.909974
   Bouguet J., CAMERA CALIBRATION T
   Chou HL, 2006, J INF SCI ENG, V22, P641
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Erol A, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P234
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Farbiz F, 2005, IEEE T MULTIMEDIA, V7, P514, DOI 10.1109/TMM.2005.846787
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Fujii T, 2002, PROC SPIE, V4864, P175, DOI 10.1117/12.454905
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2009, INT J COMPUT VISION, V84, P257, DOI 10.1007/s11263-009-0232-2
   GOESELE M, 2006, P IEEE C COMP VIS PA, P17
   HABBECKE M, 2007, P IEEE C COMP VIS PA, P1
   Hernández C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   Kato H, ARTOOLKIT
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kim H, 2007, 17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE, ICAT 2007, PROCEEDINGS, P210, DOI 10.1109/ICAT.2007.29
   LADIKOS A, 2008, P IEEE COMP SOC C CO
   Liang C, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P597
   LIU YB, FREE VIEWPOINT VIDEO
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   LOU JG, 2005, P 13 ANN ACM INT C M, P161
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Nguyen THD, 2005, IEEE T VIS COMPUT GR, V11, P706, DOI 10.1109/TVCG.2005.105
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Stoykova E, 2007, IEEE T CIRC SYST VID, V17, P1568, DOI 10.1109/TCSVT.2007.909975
   SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029
   TANIMOTO M, 2006, WORKSH IEEE C COMP V, P172
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Yemez Y, 2003, IEEE T VIS COMPUT GR, V9, P551, DOI 10.1109/TVCG.2003.1260748
   Zhang R, 2007, IEEE T CONSUM ELECTR, V53, P1177, DOI 10.1109/TCE.2007.4341602
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 37
TC 4
Z9 6
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 427
EP 441
DI 10.1016/j.jvcir.2010.03.004
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600006
DA 2024-07-18
ER

PT J
AU Barrat, S
   Tabbone, S
AF Barrat, Sabine
   Tabbone, Salvatore
TI Modeling, classifying and annotating weakly annotated images using
   Bayesian network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Probabilistic graphical models; Bayesian networks; Image classification;
   Image annotation; Semantic similarity; Wordnet; Visual features;
   Bayesian classifier
AB In this paper, we propose a probabilistic graphical model to represent weakly annotated images. We consider an image as weakly annotated if the number of keywords defined for it is less than the maximum number defined in the ground truth. This model is used to classify images and automatically extend existing annotations to new images by taking into account semantic relations between keywords. The proposed method has been evaluated in visual-textual classification and automatic annotation of images. The visual-textual classification is performed by using both visual and textual information. The experimental results, obtained from a database of more than 30,000 images, show an improvement by 50.5% in terms of recognition rate against only visual information classification. Taking into account semantic relations between keywords improves the recognition rate by 10.5%. Moreover. the proposed model can be used to extend existing annotations to weakly annotated images, by computing distributions of missing keywords. Semantic relations improve the mean rate of good annotations by 6.9%. Finally, the proposed method is competitive with a state-of-art model. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Barrat, Sabine; Tabbone, Salvatore] LORIA, UMR 7503, F-54506 Vandoeuvre Les Nancy, France.
C3 Universite de Lorraine
RP Barrat, S (corresponding author), LORIA, UMR 7503, BP 239, F-54506 Vandoeuvre Les Nancy, France.
EM barrat@loria.fr
CR [Anonymous], IJCAI
   [Anonymous], CVPR
   Aslandogan YA, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P286, DOI 10.1145/278459.258591
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Benitez AB, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P189, DOI 10.1109/ICME.2002.1035750
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Bouguila N, 2007, J VIS COMMUN IMAGE R, V18, P295, DOI 10.1016/j.jvcir.2007.02.005
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang CY, 2009, EXPERT SYST APPL, V36, P10560, DOI 10.1016/j.eswa.2009.03.041
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Feller W., 1968, An Introduction to Probability Theory and Its Applications, V1
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Gao Y., 2006, MULTI-MEDIA '06, P901
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   GROSKY WI, 2001, SOFSEM 01, P33
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jeong JW, 2007, LECT NOTES COMPUT SC, V4577, P184
   JIN R, 2004, MULTIMEDIA 04, P892
   JIN Y, 2005, MULTIMEDIA 2005, P706, DOI DOI 10.1145/1101149.1101305
   Kherfi ML, 2004, INT C PATT RECOG, P961, DOI 10.1109/ICPR.2004.1334418
   Lavrenko V, 2003, P 16 C ADV NEUR INF
   LIU S, 2004, SIGIR 2004, P266
   Magalhaes J., 2007, International Conference on Image and Video Retrieval, P619, DOI DOI 10.1145/1282280.1282368
   MAGALHAES J, 2006, SEMANTIC BASED VISUA
   Metzler D, 2004, LECT NOTES COMPUT SC, V3115, P42
   MORI Y, 2000, RIAO, P285
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P131, DOI 10.1016/j.jvcir.2008.12.002
   Rahman MM, 2009, J VIS COMMUN IMAGE R, V20, P450, DOI 10.1016/j.jvcir.2009.06.001
   ROBERT C, 1997, DECISION THEORETIC M
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Saber E, 1997, J VIS COMMUN IMAGE R, V8, P3, DOI 10.1006/jvci.1997.0344
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TABBONE S, 2002, ICPR 02, V2, P200
   TOLLARI S, 2008, EVALUATING SYSTEMS M
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Zhang RF, 2005, IEEE I CONF COMP VIS, P846
NR 40
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 355
EP 363
DI 10.1016/j.jvcir.2010.02.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ralli, J
   Díaz, J
   Ros, E
AF Ralli, J.
   Diaz, J.
   Ros, E.
TI A method for sparse disparity densification using voting mask
   propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Disparity densification; Voting based propagation; Voting based
   disparity disambiguation and densification; Stereo disambiguation by
   voting; Directional mask driven voting for densification; Disparity
   densification by anisotropic voting process; Disparity spatial support
   driven by a voting process; Gradient driven stereo densification
ID SCALE-SPACE; IMAGE; INTERPOLATION; EXPLICIT
AB We describe a novel method for propagating disparity values using directional masks and a voting scheme. The driving force of the propagation direction is image gradient, making the process anisotropic, whilst ambiguities between propagated values are resolved using a voting scheme. This kind of anisotropic densification process achieves significant density enhancement at a very low error cost: in some cases erroneous disparities are voted out, resulting not only in a denser but also a more accurate final disparity map. Due to the simplicity of the method it is suitable for embedded implementation and can also be included as part of a system-on-chip (SOC). Therefore, it can be of great interest to the sector of the machine vision community that deals with embedded and/or real-time applications. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Ralli, J.; Diaz, J.; Ros, E.] Univ Granada, Dept Arquitectura & Technol Computadores, Escuela Tecn Super Ingn & Telecommun, E-18071 Granada, Spain.
C3 University of Granada
RP Ralli, J (corresponding author), Univ Granada, Dept Arquitectura & Technol Computadores, Escuela Tecn Super Ingn & Telecommun, Calle Periodista Daniel,Saucedo Aranda S-N, E-18071 Granada, Spain.
EM jarno@ralli.fl; jdiaz@atc.ugr.es; eros@atc.ugr.es
RI Ralli, Jarno/J-6096-2012; Diaz, Javier/C-2387-2012; Ros,
   Eduardo/B-1107-2012
OI Diaz, Javier/0000-0002-1849-8068; Ros, Eduardo/0000-0001-6613-5256
FU EU [IST-016276-2]; DINAM-VISION [DP12007-61683]; RECVIS
   [TIN2008-06893-C03-02, P06-TIC-02007, TIC-3873]
FX This work was supported by the EU research Project DRIVSCO
   (IST-016276-2) and the Spanish Grants DINAM-VISION (DP12007-61683),
   RECVIS (TIN2008-06893-C03-02), P06-TIC-02007 and TIC-3873. The authors
   thank A.L. Tate for revising their English text.
CR Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482
   ALVAREZ L, 2004, INT J COMPUT VISION, V39, P41
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Brox T., 2005, Ph.D. thesis
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   FUAGERAS O, 1997, P 1 INT C SCAL SPAC, P272
   Gong ML, 2007, IEEE T IMAGE PROCESS, V16, P879, DOI 10.1109/TIP.2006.891344
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   KOLMOGOROV V, 2003, THESIS CORNELL U
   Krüger N, 2004, PATTERN RECOGN LETT, V25, P849, DOI 10.1016/j.patrec.2004.01.021
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RALLI J, 2008, DISPARITY DISAMBIGUA
   Ralli J, 2007, LECT NOTES COMPUT SC, V4729, P298
   SABATINI S, 2007, P VISAPP, V1, P213
   Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424
   Solari F, 2001, ELECTRON LETT, V37, P1382, DOI 10.1049/el:20010941
   Ting HC, 1997, J VIS COMMUN IMAGE R, V8, P338, DOI 10.1006/jvci.1997.0364
   WEICKERT J, 1998, THESIS U KAISERSLAUT
   Xiao JJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P603, DOI 10.1109/ICCV.2003.1238403
   Yoo H, 2007, ELECTRON LETT, V43, P210, DOI 10.1049/el:20073606
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 22
TC 3
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 67
EP 74
DI 10.1016/j.jvcir.2009.08.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200008
DA 2024-07-18
ER

PT J
AU Akyüz, AO
   Reinhard, E
AF Akyuez, Ahmet Oguz
   Reinhard, Erik
TI Noise reduction in high dynamic range imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE noise; noise reduction; high dynamic range (HDR) imaging; image
   enhancement
ID TONE REPRODUCTION
AB A common method to create high dynamic range (HDR) images is to combine several different exposures of the same scene. In this approach, the use of higher ISO settings will reduce exposure times, and thereby the total capture time. This is advantageous in certain environments where it may help minimize ghosting artifacts. However, exposures taken at high sensitivity settings tend to be noisy, which is further amplified by the HDR creation algorithm. We present a robust and efficient technique to significantly reduce noise in an HDR image even when its constituent exposures are taken at very high ISO settings. The method does not introduce blur or other artifacts, and leverages the wealth of information available in a sequence of aligned exposures. (C) 2007 Elsevier Inc. All rights reserved.
C1 Univ Cent Florida, Orlando, FL 32816 USA.
   Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany.
   Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
C3 State University System of Florida; University of Central Florida; Max
   Planck Society; University of Bristol
RP Akyüz, AO (corresponding author), Univ Cent Florida, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM oguz@cs.ucf.edu
RI Akyuz, Ahmet O/A-7956-2018
OI Reinhard, Erik/0000-0001-9079-6572; Akyuz, Ahmet/0000-0001-7685-5572
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], ICCV WORKSH COL PHOT
   [Anonymous], 1997, SIGGRAPH, DOI DOI 10.1145/258734.258884
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708
   Grossberg MD, 2003, PROC CVPR IEEE, P602
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Robertson MA, 2003, J ELECTRON IMAGING, V12, P219, DOI 10.1117/1.1557695
   SIDIROPOULOS ND, 1994, IEEE T IMAGE PROCESS, V3, P382, DOI 10.1109/83.298394
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
NR 17
TC 55
Z9 71
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 366
EP 376
DI 10.1016/j.jvcir.2007.04.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000003
DA 2024-07-18
ER

PT J
AU Mannami, H
   Sagawa, R
   Mukaigawa, Y
   Echigo, T
   Yagi, Y
AF Mannami, Hidetoshi
   Sagawa, Ryusuke
   Mukaigawa, Yasuhiro
   Echigo, Tomio
   Yagi, Yasushi
TI Adaptive dynamic range camera with reflective liquid crystal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE reflective liquid crystal; adaptive radiance control; wide dynamic range
   camera
ID CMOS IMAGE SENSOR
AB Wide dynamic range images (WDRIs) are needed for capturing scenes which include drastic lighting changes. This paper presents a method to widen the dynamic range of a camera by using a reflective liquid crystal. The system consists of a camera and a reflective liquid crystal placed in front of the camera. By controlling the attenuation ratio of the liquid crystal, scene radiance of each pixel is controlled adaptively. After applying the control, the original scene radiance is derived from the attenuation ratio of the liquid crystal and the radiance obtained by the camera. We have implemented a prototype system and conducted experiments in a scene that includes drastic lighting changes. These lighting changes require that we control the radiance of each pixel independently. We show how WDRIs are obtained by calculating the original scene radiance from these results. (C) 2007 Elsevier Inc. All rights reserved.
C1 Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan.
   Osaka Electrocommun Univ, Fac Informat & Commun Engn, Dept Informat Engn, Osaka 5728530, Japan.
C3 Osaka University; Osaka Electro-Communication University
RP Mannami, H (corresponding author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Osaka 5670047, Japan.
EM mannami@am.sanken.osaka-u.ac.jp
RI Tomio, Echigo/AAI-6575-2020; Sagawa, Ryusuke/M-4271-2016
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   Brajovic V, 1999, IEEE T ROBOTIC AUTOM, V15, P67, DOI 10.1109/70.744603
   Brajovic V, 2004, PROC CVPR IEEE, P189
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   HANDY RJ, 1986, Patent No. 4623928
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Kavadias S, 2000, IEEE J SOLID-ST CIRC, V35, P1146, DOI 10.1109/4.859503
   KONISHI M, 1995, Patent No. 5420635
   Lai LW, 2004, IEEE SENS J, V4, P122, DOI 10.1109/JSEN.2003.820339
   Madden B. C., 1993, MSCIS9396 U PENNS
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Nayar SK, 2004, PROC CVPR IEEE, P436
   Nayar SK, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1168
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   NAYAR SK, 2002, P ECCV, V4, P636
   OI R, 2003, P ICIP, V2, P583
   STREET RA, 1998, Patent No. 5789737
NR 17
TC 11
Z9 16
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 359
EP 365
DI 10.1016/j.jvcir.2007.06.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000002
DA 2024-07-18
ER

PT J
AU Cheng, SC
   Wu, TL
AF Cheng, Shyi-Chyi
   Wu, Tian-Luu
TI Fast indexing method for image retrieval using <i>k</i> nearest
   neighbors searches by principal axis analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE high-dimensional image database; content-based image retrieval;
   principal axis analysis; vector ordering; k-N-N search
ID COLOR
AB This paper presents a fast indexing scheme for content-based image retrieval based on the principal axis analysis. Image databases often represent the image objects as high-dimensional feature vectors and access them via the feature vectors and similarity measure. A similarity measure similar to the quadratic histogram distance measure is defined for this indexing method. The computational complexity of similarity measure in high-dimensional image database is very huge and hence the applications of image retrieval are restricted to certain areas. In this work, feature vectors in a given image are ordered by the principal axis analysis to speed up the similarity search in a high-dimensional image database using k nearest neighbor searches. To demonstrate the effectiveness of the proposed algorithm, we conducted extensive experiments and compared the performance with the IBM's query by image content (QBIC) method, Jain and Vailay's method, and the LPC-file method. The experimental results demonstrate that the proposed method outperforms the compared methods in retrieval accuracy and execution speed. The execution speed of the proposed method is much faster than that of QBIC method and it can achieve good results in terms of retrieval accuracy compared with Jain's method and QBIC method. (c) 2005 Elsevier Inc. All rights reserved.
C1 Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
   Yung Ta Inst Technol Commerce, Dept Elect Engn, Pingtung 909, Taiwan.
C3 National Kaohsiung University of Science & Technology
RP Cheng, SC (corresponding author), Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, 1 Univ Rd, Kaohsiung 824, Taiwan.
EM csc@ccms.nkfust.edu.tw
CR Cha GH, 2002, IEEE T MULTIMEDIA, V4, P76
   Cha GH, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P152, DOI 10.1109/MMCS.1998.693634
   Cheng SC, 2003, IEE P-VIS IMAGE SIGN, V150, P270, DOI 10.1049/ip-vis:20030520
   David H.A., 1980, Order Statistics, Vsecond
   Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Lu GJ, 2002, IEEE T MULTIMEDIA, V4, P372, DOI 10.1109/TMM.2002.802831
   NG R, 1996, P SPIE STOR RETR IM
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WEBBER R, 1998, P INT C VER LARG DAT, P194
NR 13
TC 7
Z9 10
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 42
EP 56
DI 10.1016/j.jvcir.2005.08.006
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900003
DA 2024-07-18
ER

PT J
AU Cho, SD
   Pearlman, WA
AF Cho, SD
   Pearlman, WA
TI Multilayered protection of embedded video bitstreams over binary
   symmetric and packet erasure channels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video compression; video transmission; robust source coding; error
   resilient transmission; joint source and channel coding; 3-D wavelet
   transform; embedded wavelet coding
ID IMAGE COMPRESSION; WAVELET; SELECTION
AB This paper presents a multilayered protection of embedded video bitstreams over bit errors and packet erasure channels using Error Resilient and Error Concealment 3-D SPIHT (ERC-SPIHT) algorithm, which is based on the 3-D SPIHT concepts. A robust source coder is created to give error resilience in source level of the codestream. This robustness is achieved by partitioning the wavelet coefficients into many independent sub-bitstreams while maintaining spatio-temporal tree structures. For higher protection against channel noise, we use a product code. In each packet, the concatenation of a rate compatible punctured convolutional (RCPC) code and an error detecting parity check (CRC) code is used. Across the packets, Reed-Solomon codes are used. These steps provide the robust source coder with additional layers of protection against channel noise. Finally, in the decoder side, an error concealment function is performed for the lost blocks. Simulations show that the multilayered protection of 3-D SPIHT outperforms the methods that use single layer protection in terms of average PSNRs and the PSNR ranges, and provides higher average PSNR's and lower PSNR variances. (C) 2004 Elsevier Inc. All rights reserved.
C1 Rensselaer Polytech Inst, Ctr Image Proc Res, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Rensselaer Polytechnic Institute
RP Pearlman, WA (corresponding author), Rensselaer Polytech Inst, Ctr Image Proc Res, Dept Elect Comp & Syst Engn, 110 8th St, Troy, NY 12180 USA.
EM s-d.cho@samsung.com; pearlman@rpi.edu
OI Pearlman, William/0000-0002-4978-6812
CR Cho S, 2002, IEEE T CIRC SYST VID, V12, P157
   CHO S, 2001, P PICT COD S PCS 200, P283
   Cho SD, 2002, SIGNAL PROCESS, V82, P1545, DOI 10.1016/S0165-1684(02)00301-8
   Cosman PC, 2000, IEEE T IMAGE PROCESS, V9, P982, DOI 10.1109/83.846241
   Creusere CD, 1997, IEEE T IMAGE PROCESS, V6, P1436, DOI 10.1109/83.624967
   Dragotti PL, 2000, IEEE T GEOSCI REMOTE, V38, P416, DOI 10.1109/36.823937
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   He C, 2003, IEEE T CIRC SYST VID, V13, P961, DOI 10.1109/TCSVT.2003.816514
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Lin S., 1983, Error Control Coding: Fundamentals and Applications
   PYUN J, 2002, IEEE T COMSUMER ELEC, V48
   Rane SD, 2002, IEEE IMAGE PROC, P309
   Rizzo L., 1997, ACM COMPUTER COMMUNI, V27, P24, DOI DOI 10.1145/263876.263881
   Rogers JK, 1998, IEEE SIGNAL PROC LET, V5, P105, DOI 10.1109/97.668942
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Sherwood PG, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P324, DOI 10.1109/ICIP.1998.723484
   Sherwood PG, 1997, IEEE DATA COMPR CONF, P72, DOI 10.1109/DCC.1997.581971
   Stankovic V, 2004, IEEE T MULTIMEDIA, V6, P240, DOI 10.1109/TMM.2003.822789
   Ulichney R., 1987, DIGITAL HALFTONING
   Wu DP, 2000, IEEE J SEL AREA COMM, V18, P977, DOI 10.1109/49.848251
   XIONG Z, 1998, P ICIP 98, V1, P334
NR 22
TC 5
Z9 5
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 359
EP 378
DI 10.1016/j.jvcir.2004.08.001
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500007
DA 2024-07-18
ER

PT J
AU Ye, MT
   Chen, ZX
   Guo, YX
   Yu, KL
   Liu, LC
   Wu, QMJ
AF Ye, Mengting
   Chen, Zhenxue
   Guo, Yixin
   Yu, Kaili
   Liu, Longcheng
   Wu, Q. M. Jonathan
TI BNDCNet: Bilateral nonlocal decoupled convergence network for semantic
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation
AB The perceptual scope of deep convolutional neural networks is inherently confined to a local scale due to the inherent limitations of convolution operations. This confinement subsequently hampers a comprehensive understanding of intricate scenes. In response, an innovative approach called Bilateral Non-Local Decoupled Convergence Network (BNDCNet) is proposed to facilitate contextual interaction of global information. The proposed module decouples the information from the input feature map and uses a bilateral non-local architecture for system processing. This strategy facilitates inter-pixel interaction and aggregates global information. An important aspect of our approach involves the computation of adaptive convolutional channel weights for the feature map. This innovation greatly improves the efficacy and performance of the model. The proposed method achieved high performance on the competitive scene-parsing datasets CamVid, Cityscapes, and KITTI, and thus demonstrated effectiveness and generality. Code has been released: https://github.com/ Mantee0810/BNDC.
C1 [Ye, Mengting; Chen, Zhenxue; Guo, Yixin; Yu, Kaili; Liu, Longcheng] Shandong Univ, Qianfoshan Campus, Jinan 520000, Peoples R China.
   [Wu, Q. M. Jonathan] Univ Windsor, Windsor, ON N9B 3P4, Canada.
C3 Shandong University; University of Windsor
RP Chen, ZX (corresponding author), Shandong Univ, Qianfoshan Campus, Jinan 520000, Peoples R China.
EM chenzhenxue@sdu.edu.cn
RI Zhang, Youmin/AAT-7095-2020
OI Zhang, Youmin/0000-0002-9731-5943; Chen, Zhenxue/0000-0001-9637-5170
CR Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chandra S, 2017, IEEE I CONF COMP VIS, P5113, DOI 10.1109/ICCV.2017.546
   Chandra S, 2016, LECT NOTES COMPUT SC, V9911, P402, DOI 10.1007/978-3-319-46478-7_25
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chiu HP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P423, DOI 10.1109/VR.2018.8447560
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Ertenli CU, 2022, LECT NOTES COMPUT SC, V13671, P189, DOI 10.1007/978-3-031-20083-0_12
   Fauqueur J, 2007, IEEE I CONF COMP VIS, P2309
   Fritsch J, 2013, IEEE INT C INTELL TR, P1693, DOI 10.1109/ITSC.2013.6728473
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Geng ZY, 2021, Arxiv, DOI arXiv:2109.04553
   Guo MH, 2022, Arxiv, DOI [arXiv:2209.08575, DOI 10.48550/ARXIV.2209.08575, 10.48550/arXiv.2209.08575]
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   Hénaff OJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10066, DOI 10.1109/ICCV48922.2021.00993
   Hong YD, 2021, Arxiv, DOI [arXiv:2101.06085, DOI 10.48550/ARXIV.2101.06085]
   Jiang W, 2022, INT J PAVEMENT ENG, V23, P2049, DOI 10.1080/10298436.2020.1837826
   Kumar VR, 2023, Arxiv, DOI arXiv:2102.07448
   Li G, 2019, Arxiv, DOI arXiv:1907.11357
   Li S, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3221745
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu SW, 2022, Arxiv, DOI arXiv:2207.03620
   Liu W, 2015, Arxiv, DOI [arXiv:1506.04579, 10.48550/arXiv.1506.04579]
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Lo S. Y., 2019, P ACM MULTIMEDIA ASI, P1, DOI DOI 10.1145/3338533.3366558
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu M., 2020, Factorized and regular blocks network for semantic segmentation in road scene
   Lu MX, 2022, IEEE T INTELL TRANSP, V23, P20991, DOI 10.1109/TITS.2022.3182311
   Mahaur B, 2023, NEURAL NETWORKS, V157, P305, DOI 10.1016/j.neunet.2022.10.023
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Nirkin Y, 2021, PROC CVPR IEEE, P4060, DOI 10.1109/CVPR46437.2021.00405
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Raghu M, 2021, ADV NEUR IN, V34
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Treml M., 2016, SPEEDING SEMANTIC SE, V2, P1
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZH, 2017, Arxiv, DOI arXiv:1711.08278
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Yang CG, 2022, PROC CVPR IEEE, P12309, DOI 10.1109/CVPR52688.2022.01200
   Yi P., 2021, arXiv
   Yi YG, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1056226
   Yu C., 2021, INT J COMPUT VISION, V129, P3051, DOI [DOI 10.1007/s11263-021-01515-2, 10.1007/s11263-021-01515-2]
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yuan Y., 2018, Object context network for scene parsing
   Zhang XT, 2019, IEEE T IND INFORM, V15, P1183, DOI 10.1109/TII.2018.2849348
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B., 2014, arXiv
NR 58
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104028
DI 10.1016/j.jvcir.2023.104028
EA DEC 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FG9S2
UT WOS:001144733500001
DA 2024-07-18
ER

PT J
AU Fu, SM
   Wang, HL
   Hu, HJ
   He, XX
   Long, YW
   Bai, JH
   Ou, YT
   Huang, YJ
   Zhou, MQ
AF Fu, Siming
   Wang, Hualiang
   Hu, Haoji
   He, Xiaoxuan
   Long, Yongwen
   Bai, Jianhong
   Ou, Yangtao
   Huang, Yuanjia
   Zhou, Mengqiu
TI Class semantic enhancement network for semantic segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Attention; Graph module
AB Existing semantic segmentation methods favor class semantic consistency by extracting long-range contextual features through multi-scale and attention strategies. These methods ignore the relations between feature channels and classes, which are essential to represent consistent class semantics. To this end, we propose the Class Semantic Enhancement Network (CSENet) which boosts the segmentation performance of a backbone network in a coarse-to-fine manner. CSENet consists of two basic modules - (1) the Class Semantic Channel Graph Module (CSCG) module, which captures inter-dependencies among channels and strengthens the channel-class relation, and (2) the Class Prior Fully Convolution (CP-FC) module, which utilizes the channel class relation as class priors to refine the segmentation results. Extensive experiments have demonstrated that the proposed CSENet is able to learn discriminative feature representations and achieves state-of-the-art performance on three benchmark datasets, including PASCAL Context, ADE20K and COCO Stuff.
C1 [Fu, Siming; Wang, Hualiang; Hu, Haoji; He, Xiaoxuan; Bai, Jianhong; Zhou, Mengqiu] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
   [Long, Yongwen; Ou, Yangtao; Huang, Yuanjia] Foshan Shunde Midea Elect Heating Appliances Mfg C, Foshan, Peoples R China.
   [Hu, Haoji] Zhejiang Prov Key Lab Informat Proc Commun & Netwo, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Hu, HJ (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.; Hu, HJ (corresponding author), Zhejiang Prov Key Lab Informat Proc Commun & Netwo, Hangzhou, Peoples R China.
EM fusiming@zju.edu.cn; hualiang_wang@zju.edu.cn; haoji_hu@zju.edu.cn;
   Xiaoxuan_He@zju.edu.cn; longyw@midea.com; JianhongBai@zju.edu.cn;
   ouyangtao4@midea.com; yuanjia.huang@midea.com; zhoumq1002@zju.edu.cn
RI Bai, Jianhong/JFA-3919-2023
OI Hu, Haoji/0000-0001-6048-6549
FU National Natural Science Foundation of China [U21B2004]; Zhejiang
   Provincial key RD Program of China [2021C01119]; Core Technology
   Research Project of Foshan, Guangdong Province, China [1920001000498]
FX This work is supported by the National Natural Science Foundation of
   China (U21B2004) , the Zhejiang Provincial key RD Program of China
   (2021C01119) , and the Core Technology Research Project of Foshan,
   Guangdong Province, China (1920001000498) .
CR Islam MA, 2017, Arxiv, DOI [arXiv:1703.00551, DOI 10.48550/ARXIV.1703.00551]
   Bousselham W, 2022, Arxiv, DOI arXiv:2111.13280
   BRANDT A, 1977, MATH COMPUT, V31, P333, DOI 10.1090/S0025-5718-1977-0431719-X
   Briggs William, 2000, A Multigrid Tutorial, Vsecond
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chandra S, 2017, IEEE I CONF COMP VIS, P5113, DOI 10.1109/ICCV.2017.546
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen LC, 2017, Arxiv, DOI arXiv:1606.00915
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen T.-W., 2021, P IEEECVF C COMPUTER, P3182
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2019, IEEE I CONF COMP VIS, P6818, DOI 10.1109/ICCV.2019.00692
   Ding HH, 2019, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2019.00909
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo MH, 2021, Arxiv, DOI arXiv:2105.02358
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Huang SF, 2020, IEEE T IMAGE PROCESS, V29, P8251, DOI 10.1109/TIP.2020.3013142
   Huang Y, 2022, AAAI CONF ARTIF INTE, P1016
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jin XJ, 2017, AAAI CONF ARTIF INTE, P4096
   Ke TW, 2018, LECT NOTES COMPUT SC, V11205, P605, DOI 10.1007/978-3-030-01246-5_36
   Li X., 2020, P IEEE CVF C COMP VI, P8950, DOI 10.1109/CVPR42600.2020.00897
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Li Y, 2018, ADV NEUR IN, V31
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xie GS, 2021, PROC CVPR IEEE, P5471, DOI 10.1109/CVPR46437.2021.00543
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yuan YH, 2021, Arxiv, DOI arXiv:1909.11065
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang L., 2019, P 30 BRIT MACH VIS C, P254
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhong Z., 2020, P IEEE CVF C COMP VI, P13065, DOI DOI 10.1109/CVPR42600.2020.01308
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 52
TC 0
Z9 0
U1 15
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103924
DI 10.1016/j.jvcir.2023.103924
EA AUG 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FH7F3
UT WOS:001144930000001
DA 2024-07-18
ER

PT J
AU Buades, A
   Martorell, O
   Pereira-Sánchez, I
AF Buades, Anton
   Martorell, Onofre
   Pereira-Sanchez, Ivan
TI HDR video synthesis by a nonlocal regularization variational model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HDR video synthesis; Variational methods; Nonlocal regularization
AB High dynamic range (HDR) video synthesis is a very challenging task. Consecutive frames are acquired with alternate expositions, generally two or three different exposure times. Classical methods aim at registering neighboring frames and fuse them using image HDR techniques. However, the registration often fails to obtain accurate results and the fusion produces ghosting artifacts. Deep learning techniques have recently appeared imitating the structure of existing classical methods. The neural network is intended to estimate the registration function and choose the fusion weights. In this paper, we propose a new method for HDR video synthesis using a variational model. The proposed model uses a nonlocal regularization term to combine pixel information from neighboring frames. The obtained results are competitive with state-of-the-art. Moreover, the proposed method gives a more reliable and understandable solution than deep-learning based ones.
C1 [Buades, Anton; Martorell, Onofre; Pereira-Sanchez, Ivan] Univ Illes Balears, Dept Math & Comp Sci, E-07122 Palma De Mallorca, Spain.
   [Buades, Anton; Martorell, Onofre; Pereira-Sanchez, Ivan] Univ Illes Balears, IAC3, E-07122 Palma De Mallorca, Spain.
C3 Universitat de les Illes Balears; Universitat de les Illes Balears
RP Martorell, O (corresponding author), Univ Illes Balears, Dept Math & Comp Sci, E-07122 Palma De Mallorca, Spain.; Martorell, O (corresponding author), Univ Illes Balears, IAC3, E-07122 Palma De Mallorca, Spain.
EM toni.buades@uib.es; o.martorell@uib.cat; i.pereira@uib.cat
FU EU [PID2021-125711OB-I00, MCIN/AEI/10.13039/501100011033/FEDER]
FX The publication is part of the project PID2021-125711OB-I00, financed by
   MCIN/AEI/10.13039/501100011033/FEDER, EU.
CR ANAND M., 2021, Materials Today: Proceedings
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 1994, Graph. Gems, DOI DOI 10.1016/B978-0-12-336156-1.50054-9
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chen GY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2482, DOI 10.1109/ICCV48922.2021.00250
   Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163
   Cogalan U, 2022, COMPUT GRAPH-UK, V105, P57, DOI 10.1016/j.cag.2022.04.008
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Duran J, 2021, SIAM J IMAGING SCI, V14, P879, DOI 10.1137/20M1379113
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Gryaditskaya Y, 2015, COMPUT GRAPH FORUM, V34, P119, DOI 10.1111/cgf.12684
   Jung MY, 2009, LECT NOTES COMPUT SC, V5567, P401, DOI 10.1007/978-3-642-02256-2_34
   Kalantari NK, 2019, COMPUT GRAPH FORUM, V38, P193, DOI 10.1111/cgf.13630
   Kalantari NK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508402
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Karaduzovic-Hadziabdic K, 2017, COMPUT GRAPH-UK, V63, P1, DOI 10.1016/j.cag.2017.01.002
   Kim JW, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102903
   Kobler E, 2017, LECT NOTES COMPUT SC, V10496, P281, DOI 10.1007/978-3-319-66709-6_23
   Li YL, 2017, IEEE T IMAGE PROCESS, V26, P1143, DOI 10.1109/TIP.2016.2642790
   Mangiat S, 2010, SPIE, V7798, P307
   Mangiat S, 2011, IEEE IMAGE PROC, P1317, DOI 10.1109/ICIP.2011.6115678
   Mann S., 1994, MIT Media Lab Perceptual, V1, P2
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Martorell O, 2022, VISIGRAPP, P666, DOI 10.5220/0010908300003124
   Martorell O, 2019, SIGNAL PROCESS-IMAGE, V78, P409, DOI 10.1016/j.image.2019.07.020
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Niu YZ, 2021, IEEE T IMAGE PROCESS, V30, P3885, DOI 10.1109/TIP.2021.3064433
   Prabhakar KR, 2021, IEEE T COMPUT IMAG, V7, P1228, DOI 10.1109/TCI.2021.3112920
   Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Song JW, 2022, LECT NOTES COMPUT SC, V13677, P288, DOI 10.1007/978-3-031-19790-1_18
   Tocci MD, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964936
   Vo TV, 2020, IEEE ACCESS, V8, P24576, DOI 10.1109/ACCESS.2020.2970857
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   Tursun OT, 2016, COMPUT GRAPH FORUM, V35, P139, DOI 10.1111/cgf.12818
   Tursun OT, 2015, COMPUT GRAPH FORUM, V34, P683, DOI 10.1111/cgf.12593
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P8874, DOI 10.1109/TPAMI.2021.3123686
   Ward G., 2003, Journal of Graphics Tools, V8, P17, DOI 10.1080/10867651.2003.10487583
   Yan QS, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103079
   Yan QS, 2020, IEEE T IMAGE PROCESS, V29, P4308, DOI 10.1109/TIP.2020.2971346
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
NR 43
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103883
DI 10.1016/j.jvcir.2023.103883
EA JUL 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N0DJ0
UT WOS:001033823000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, CP
   Sun, FR
   Xia, ZQ
   Li, Q
   Li, J
   Han, B
   Ma, B
AF Wang, Chunpeng
   Sun, Fanran
   Xia, Zhiqiu
   Li, Qi
   Li, Jian
   Han, Bing
   Ma, Bin
TI Wavelet-FCWAN: Fast and Covert Watermarking Attack Network in Wavelet
   Domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Watermarking attack; Wavelet transform; Deep learning; Digital
   watermarking; Imperceptibility
ID COLOR
AB The protection of digital image content has become an important topic of scientific research with the continuous development and updates of Internet and multimedia technology. In the past few years, various watermarking algorithms with good robustness and imperceptibility have been proposed, but the development of watermarking attack techniques has stagnated. In this paper, we have attempted to use deep learning to develop a new watermarking attack scheme and present the Fast and Covert Watermarking Attack Network in Wavelet Domain (Wavelet-FCWAN). The watermarking attack scheme employs noise filling as a preprocessing step for the watermarked image, performs wavelet transform operation on the preprocessed watermarked image, and inputs the wavelet transformed sub-image into Wavelet-FCWAN along with the noise level map in parallel. The network can be trained quickly and produces a better watermarking attack effect while ensuring the visual quality and detail retention of the attacked image. The experiments show that Wavelet-FCWAN demonstrates the superiority of its watermarking attack effect by comparing different attack strategies, and it can produce varying degrees of attack effects on various image watermarking algorithms with high levels of universality and imperceptibility.
C1 [Wang, Chunpeng; Sun, Fanran; Xia, Zhiqiu; Li, Qi; Li, Jian; Han, Bing; Ma, Bin] Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Jinan 250353, Peoples R China.
   [Xia, Zhiqiu; Ma, Bin] Qilu Univ Technol, Shandong Acad Sci, Sch Comp Sci & Technol, 3501 Daxue Rd, Jinan 250353, Peoples R China.
C3 Qilu University of Technology; Qilu University of Technology
RP Xia, ZQ; Ma, B (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Comp Sci & Technol, 3501 Daxue Rd, Jinan 250353, Peoples R China.
EM xzqjsdtc@163.com; sddxmb@126.com
FU Taishan Scholar Program of Shandong, Youth Innovation Team of Colleges
   and Universities in Shandong Province [2022KJ124]; "Chunhui Plan"
   Cooperative Scientific Research Project of Ministry of Education
   [HZKY20220482]; National Natural Science Foundation of China [62272255];
   National Key Research and Development Program of China [2021YFC3340602];
   Shandong Provincial Natural Science Foundation [ZR202208310038,
   ZR2020MF054]; Shandong Provincial Science and Technology SME Innovation
   Capability Improving Project [2022TSGC2485]; Jinan City "20
   universities" Funding Projects [2020GXRC056, 202228016]; Project of
   Jinan City-School Integration Development [JNSX2021030]
FX This work was funded by the Taishan Scholar Program of Shandong, Youth
   Innovation Team of Colleges and Universities in Shandong Province
   (2022KJ124) , The "Chunhui Plan" Cooperative Scientific Research Project
   of Ministry of Education (HZKY20220482) , National Natural Science
   Foundation of China (62272255) , National Key Research and Development
   Program of China (2021YFC3340602) , Shandong Provincial Natural Science
   Foundation (ZR202208310038, ZR2020MF054) , Shandong Provincial Science
   and Technology SME Innovation Capability Improving Project
   (2022TSGC2485) , Jinan City "20 universities" Funding Projects
   (2020GXRC056, 202228016) , Project of Jinan City-School Integration
   Development (JNSX2021030) .
CR Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Ansari Rahim, 2012, INT C COMM INF COMP
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Avila-Domenech E, 2021, LECT NOTES COMPUT SC, V13055, P327, DOI 10.1007/978-3-030-89691-1_32
   Azzeh J., 2018, JOIV: International Journal on Informatics Visualization, V2, P252, DOI DOI 10.30630/JOIV.2.4.151
   Bae W, 2017, IEEE COMPUT SOC CONF, P1141, DOI 10.1109/CVPRW.2017.152
   Coady J, 2019, I CONF SENS TECHNOL, DOI 10.1109/icst46873.2019.9047683
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Daren H., 2001, IEEE INT C MULTIMEDI, P80
   Geng LF, 2020, J REAL-TIME IMAGE PR, V17, P631, DOI 10.1007/s11554-020-00941-8
   Gunjal BaisaL., 2010, Journal of Emerging Trends in Computing and Information Sciences, V2, P37
   Hatoum M., 2021, Image Commun., V90
   HOLSCHNEIDER M, 1991, INVERSE PROBL, V7, P853, DOI 10.1088/0266-5611/7/6/008
   Kaur M, 2015, Int J, V5, P210
   Kaur P, 2011, INT J COMPUT ELECT E, V3, P319
   Li N, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P942, DOI 10.1109/ISECS.2008.140
   Ma B, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107544
   Marino F, 2001, IEEE T SIGNAL PROCES, V49, P1248, DOI 10.1109/78.923307
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Munoz-Ramirez David-Octavio, 2018, 2018 IEEE 9th International Conference on Dependable Systems, Services and Technologies (DESSERT), P619, DOI 10.1109/DESSERT.2018.8409206
   Rakshit S, 2007, PATTERN RECOGN, V40, P890, DOI 10.1016/j.patcog.2006.02.008
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Shinde G., 2019, INT J INNOV ENG RES, V6, P1
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Woo W.L., 2015, SECURING IRIS IMAGES
   Yadav B., 2018, Adv. Intell. Syst. Comput, V583, P25
   Yang JD, 2017, I COMP CONF WAVELET, P229, DOI 10.1109/ICCWAMTIP.2017.8301485
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
NR 31
TC 2
Z9 2
U1 4
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103875
DI 10.1016/j.jvcir.2023.103875
EA JUN 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N0PE3
UT WOS:001034130800001
DA 2024-07-18
ER

PT J
AU Wang, DW
   Chen, YB
   Wang, WM
   Tie, ZX
   Fang, X
   Ke, W
AF Wang, Dengwen
   Chen, Yanbing
   Wang, Wangmeng
   Tie, Zhixin
   Fang, Xian
   Ke, Wei
TI Uncertainty-guided joint attention and contextual relation network for
   person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Uncertainty-guided joint attention; Contextual
   relation network; Relation between features; Attention mechanism
AB Due to the influence of factors such as camera angle and pose changes, some salient local features are often suppressed in person re-identification tasks. Moreover, many existing person re-identification methods do not consider the relation between features. To address these issues, this paper proposes two novel approaches: (1) To solve the problem of being confused and misidentified when local features of different individuals have similar attributes, we design a contextual relation network that focuses on establishing the relationship between local features and contextual features, so that all local features of the same person both contain contextual information. (2) To fully and correctly express key local features, we propose an uncertainty-guided joint attention module. The module focuses on the joint representation of individual pixels and local spatial features to enhance the credibility of local features. Finally, our method achieves competitive performance on four widely recognized datasets compared with state-of-the-art methods.
C1 [Wang, Dengwen; Chen, Yanbing; Wang, Wangmeng; Tie, Zhixin; Fang, Xian] Zhejiang Sci Tech Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Tie, Zhixin] Zhejiang Sci Tech Univ, KeYi Coll, Shaoxing 312369, Peoples R China.
   [Ke, Wei] Macao Polytech Univ, Fac Appl Sci, Macau 999078, Peoples R China.
C3 Zhejiang Sci-Tech University; Zhejiang Sci-Tech University; Macao
   Polytechnic University
RP Chen, YB (corresponding author), Zhejiang Sci Tech Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM cyb@zstu.edu.cn
RI Fang, Xian/KMY-0913-2024; Ke, Wei/JXM-8153-2024
OI Fang, Xian/0000-0001-5161-2574; Tie, Zhixin/0000-0002-6468-2309; Ke,
   Wei/0000-0003-0952-0961; chen, yanbing/0000-0002-6818-0437
FU National Natural Science Foundation of China (NSFC) [61170110]; Zhejiang
   Provincial Nat-ural Science Foundation of China [LY13F020043];
   scientific research project of Zhejiang Provincial Department of
   Education, China [21030074-F]
FX This study is partially supported by the National Natural Science
   Foundation of China (NSFC) (No. 61170110) , Zhejiang Provincial Nat-ural
   Science Foundation of China (No. LY13F020043) , and the scientific
   research project of Zhejiang Provincial Department of Education, China
   (No. 21030074-F) . Thank you for the support from our group.
CR Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen F, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106939
   Chen S., 2022, CHI EA 19 EXTENDED A
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cho Y., 2022, CVPR, P7308
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Felzenszwalb P., 2008, 2008 IEEE C COMP VIS, DOI [10.1109/CVPR.2008.4587597, DOI 10.1109/CVPR.2008.4587597]
   Ge Y., 2018, ADV NEUR IN, P1222
   Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Guo M, 2023, NAT PROD RES, V37, P1411, DOI 10.1080/14786419.2021.2011271
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, Arxiv, DOI arXiv:1810.07399
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hong PX, 2021, PROC CVPR IEEE, P10508, DOI 10.1109/CVPR46437.2021.01037
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Ji HXY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3641, DOI 10.1109/ICCV48922.2021.00364
   Jin HY, 2022, IEEE T CIRC SYST VID, V32, P2170, DOI 10.1109/TCSVT.2021.3088446
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li DX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010092
   Li HJ, 2021, PROC CVPR IEEE, P6725, DOI 10.1109/CVPR46437.2021.00666
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Y, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.07.003
   Liu HM, 2021, NEUROCOMPUTING, V423, P57, DOI 10.1016/j.neucom.2020.10.019
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu YT, 2021, NEUROCOMPUTING, V447, P80, DOI 10.1016/j.neucom.2021.02.084
   Mei GX, 2022, NEUROCOMPUTING, V468, P276, DOI 10.1016/j.neucom.2021.10.001
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Pang YX, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103772
   Park H, 2020, AAAI CONF ARTIF INTE, V34, P11839
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shao ZF, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103302
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Specker A, 2021, IEEECVF CVPR, P4173
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang YZ, 2020, NEURAL NETWORKS, V124, P223, DOI 10.1016/j.neunet.2020.01.012
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090585
   Wang SQ, 2020, J REAL-TIME IMAGE PR, V17, P73, DOI 10.1007/s11554-019-00908-4
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164431
   Yang S., 2022, IEEE T CIRC SYST VID
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang AG, 2021, PROC CVPR IEEE, P598, DOI 10.1109/CVPR46437.2021.00066
   Zhang HJ, 2020, IEEE ACCESS, V8, P83685, DOI 10.1109/ACCESS.2020.2991838
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu YJ, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103714
NR 62
TC 4
Z9 4
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103822
DI 10.1016/j.jvcir.2023.103822
EA APR 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F6RW9
UT WOS:000983607900001
DA 2024-07-18
ER

PT J
AU Lyu, WL
   Yue, YJ
   Yin, ZX
AF Lyu, WanLi
   Yue, YaJie
   Yin, Zhaoxia
TI Reversible data hiding based on automatic contrast enhancement using
   histogram expansion*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Histogram shifting; Automatic image enhancement;
   Reversible contrast enhancement; Histogram expansion
ID IMAGE QUALITY ASSESSMENT
AB A lot of Reversible Data Hiding (RDH) methods aim to generate a stego image infinitely approaches the original image while the quality of the original image is leaved out of consideration. Juxtaposed with a plain image, a contrast enhanced version always improves the user experience significantly. Reversible Data Hiding with Contrast Enhancement (RDHCE) enhances the stego image contrast combined with its payloads and enables the cover image to be regained accurately after the payloads have been extracted. This study presents a novel RDHCE method using histogram expansion. First, a new local histogram selecting strategy is proposed to improve the contrast of the whole image. Meanwhile, the global average brightness is used as a reference to determine the shifting direction of the local histogram to prevent the image from being over-enhanced. Moreover, the contrast can be improved adaptively when a reasonable number of data is embedded at the selected embedding points. Experimental results show that, with a given payload, the proposed method achieves better contrast and maintains good visual quality compared with state-of-the-arts.
C1 [Lyu, WanLi; Yue, YaJie] Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei 230601, Peoples R China.
   [Yin, Zhaoxia] East China Normal Univ, Shanghai Key Lab Multidimens Informat Proc, Shanghai 200241, Peoples R China.
   [Yin, Zhaoxia] East China Normal Univ, Sch Commun & Elect Engn, Shanghai 200241, Peoples R China.
C3 Anhui University; East China Normal University; East China Normal
   University
RP Yin, ZX (corresponding author), East China Normal Univ, Shanghai Key Lab Multidimens Informat Proc, Shanghai 200241, Peoples R China.; Yin, ZX (corresponding author), East China Normal Univ, Sch Commun & Elect Engn, Shanghai 200241, Peoples R China.
EM zxyin@cee.ecnu.edu.cn
RI Yin, Zhaoxia/HRD-7425-2023
OI Yin, Zhaoxia/0000-0003-0387-4806
FU Natural Science Foundation of China [62172001, 61872003]
FX This work was supported in part by the Natural Science Foundation of
   China (Grant 62172001, Grant 61872003) .
CR [Anonymous], 2021, J KING SAUD U COMPUT
   [Anonymous], 2021, J VIS COMMUN IMAGE R, V78
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Chen HS, 2020, COMPUT J, V63, P1584, DOI 10.1093/comjnl/bxaa072
   Chen HS, 2016, LECT NOTES COMPUT SC, V10039, P134, DOI 10.1007/978-3-319-48671-0_13
   Fragoso-Navarro E, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10050841
   Franzen Rich, 1999, KODAK LOSSLESS TRUE, V4
   Gao GY, 2022, J INF SECUR APPL, V68, DOI 10.1016/j.jisa.2022.103223
   Gao GY, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107817
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gao GY, 2015, IEEE SIGNAL PROC LET, V22, P2078, DOI 10.1109/LSP.2015.2459055
   Gao M.-Z., 2013, Adv. Intell. Syst. Appl., V2, P331, DOI [10.1007/978-3-642-35473-133, DOI 10.1007/978-3-642-35473-133]
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P2271, DOI 10.1109/TCSVT.2018.2869935
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Mansouri S, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103359
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Qiu YQ, 2018, J VIS COMMUN IMAGE R, V52, P86, DOI 10.1016/j.jvcir.2018.02.005
   Ri YW, 2017, COMM COM INF SC, V772, P284, DOI 10.1007/978-981-10-7302-1_24
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Suah Kim, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P291, DOI 10.1109/ICIVC47709.2019.8980970
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2020, IET IMAGE PROCESS, V14, P327, DOI 10.1049/iet-ipr.2019.0423
   Wu HT, 2019, IEEE ACCESS, V7, P83332, DOI 10.1109/ACCESS.2019.2921407
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
   Yao H, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102795
   Yin ZX, 2021, IEEE T SIGNAL INF PR, V7, P336, DOI 10.1109/TSIPN.2021.3081373
   Ying QC, 2019, IEEE ACCESS, V7, P46506, DOI 10.1109/ACCESS.2019.2909560
   You Zhengwei, 2021, 2021 IEEE International Workshop on Electromagnetics: Applications and Student Innovation Competition (iWEM), P1, DOI 10.1109/iWEM53379.2021.9790683
   Zhang TC, 2022, IEEE T IND ELECTRON, V69, P10573, DOI 10.1109/TIE.2022.3140403
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
NR 35
TC 4
Z9 4
U1 4
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103798
DI 10.1016/j.jvcir.2023.103798
EA MAR 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G7QF1
UT WOS:000991052700001
DA 2024-07-18
ER

PT J
AU Cao, CH
   Duan, HX
   Gao, XP
AF Cao, Chunhong
   Duan, Hongxuan
   Gao, Xieping
TI Hyperspectral image classification based on three-dimensional adaptive
   sampling and improved iterative shrinkage-threshold algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature learning; Discriminative feature; Three-dimensional adaptive
   sampling; Hyperspectral images classification
ID CONVOLUTIONAL NEURAL-NETWORK; LOSSLESS COMPRESSION; AUTOENCODER; COMPACT
AB Abundant spectral information of hyperspectral images (HSI) provides rich information for HSI classification, which often brings high dimensional data resulting in the dilemma between the demand for fine data and the limited resources such as computation, storage as well as transmission band-width. To address this issue, we propose a deep hierarchical feature representation model based on three-dimensional adaptive sampling and improved iterative shrinkage-threshold algorithm (ISTA) for HSI classification. Due to the adaptive sampling, we improve ISTA with deep learning network for spectral-spatial feature representation since the ISTA is no longer applicable for the sampled data reconstruction. Through end-to-end joint learning, the proposed method can not only effectively reduce the required data, but also learn discriminative features for HSI classification, which will be meaningful for the HSI's transmission from the space satellites and fast classification. Experimental results demonstrate the effectiveness and superiority of the proposed method on three public HSI datasets.
C1 [Cao, Chunhong; Duan, Hongxuan] Xiangtan Univ, MOE Key Lab Intelligent Comp & Informat Proc, Xiangtan 411100, Peoples R China.
   [Gao, Xieping] Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language Inf, Changsha 410081, Peoples R China.
C3 Xiangtan University; Hunan Normal University
RP Gao, XP (corresponding author), Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language Inf, Changsha 410081, Peoples R China.
EM caoch@xtu.edu.cn; xpgao@xtu.edu.cn
RI Duan, Hongxuan/JKJ-5751-2023
FU Research Foundation of Education De-partment of Hunan Province of China;
   Natural Science Foundation of Hunan Province of China; National Natural
   Science Founda-tion of China; National Key R&D Program of China; 
   [19A496];  [21A0109];  [21B0172];  [2022JJ30552];  [2022JJ30571]; 
   [61972333];  [2020YFA0713504]
FX Acknowledgments This work is supported by Research Foundation of
   Education De-partment of Hunan Province of China (19A496, 21A0109,
   21B0172) , the Natural Science Foundation of Hunan Province of China
   (2022JJ30552, 2022JJ30571) , the National Natural Science Founda-tion of
   China (CN) (61972333) and National Key R&D Program of China
   (2020YFA0713504) .
CR Bai J, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3066485
   Can E., 2018, 2018 26 SIGNAL PROCE, P1
   Cao XH, 2017, IEEE GEOSCI REMOTE S, V14, P2147, DOI 10.1109/LGRS.2017.2755541
   Chen ST, 2021, MULTIMED TOOLS APPL, V80, P1859, DOI 10.1007/s11042-020-09480-7
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Elmaizi A, 2019, PROCEDIA COMPUT SCI, V148, P126, DOI 10.1016/j.procs.2019.01.016
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Ghaderizadeh S, 2021, IEEE J-STARS, V14, P7570, DOI 10.1109/JSTARS.2021.3099118
   Greenwood G. W., 1997, IEEE Transactions on Evolutionary Computation, V1, P244, DOI 10.1109/4235.687884
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P1424, DOI 10.1109/TGRS.2020.3003341
   Hao SY, 2021, IEEE T GEOSCI REMOTE, V59, P2448, DOI 10.1109/TGRS.2020.3005623
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Jiang YA, 2021, IEEE T GEOSCI REMOTE, V59, P10425, DOI 10.1109/TGRS.2021.3049282
   Kingma D. P., 2014, arXiv
   Li YS, 2017, PATTERN RECOGN, V63, P371, DOI 10.1016/j.patcog.2016.10.019
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI 10.1109/TGRS.2020.3018879
   Luo JQ, 2019, INT J MACH LEARN CYB, V10, P2619, DOI 10.1007/s13042-019-00937-2
   Mao XJ, 2016, Arxiv, DOI [arXiv:1603.09056, DOI 10.48550/ARXIV.1603.09056]
   Mathews J., 2004, Numerical Methods Using Matlab, Vfourth
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Mou LC, 2018, IEEE T GEOSCI REMOTE, V56, P391, DOI 10.1109/TGRS.2017.2748160
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Sellami A, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108224
   Song JW, 2019, REMOTE SENS LETT, V10, P401, DOI 10.1080/2150704X.2018.1562257
   Tu B, 2022, IEEE J-STARS, V15, P184, DOI 10.1109/JSTARS.2021.3133009
   van der Meer FD, 2012, INT J APPL EARTH OBS, V14, P112, DOI 10.1016/j.jag.2011.08.002
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Wang GX, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12233879
   Wang LZ, 2019, PROC CVPR IEEE, P8024, DOI 10.1109/CVPR.2019.00822
   Wang Q, 2018, IEEE T GEOSCI REMOTE, V56, P5910, DOI 10.1109/TGRS.2018.2828161
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yang C, 2018, IEEE T GEOSCI REMOTE, V56, P7230, DOI 10.1109/TGRS.2018.2849443
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Yang XG, 2017, IEEE T GEOSCI REMOTE, V55, P2525, DOI 10.1109/TGRS.2016.2646420
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P2365, DOI 10.1109/LGRS.2017.2765339
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zhang L, 2019, IEEE T GEOSCI REMOTE, V57, P8276, DOI 10.1109/TGRS.2019.2919938
   Zhang X, 2016, IEEE J-STARS, V9, P4117, DOI 10.1109/JSTARS.2016.2577339
   Zhang X, 2021, IEEE T GEOSCI REMOTE, V59, P10473, DOI 10.1109/TGRS.2020.3046840
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
NR 43
TC 3
Z9 3
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103693
DI 10.1016/j.jvcir.2022.103693
EA NOV 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200009
DA 2024-07-18
ER

PT J
AU Kumar, S
   Gupta, SK
   Kaur, M
   Gupta, U
AF Kumar, Sanjeev
   Gupta, Suneet K.
   Kaur, Manjit
   Gupta, Umesh
TI VI-NET: A hybrid deep convolutional neural network using VGG and
   inception V3 model for copy-move forgery classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move forgery; COMOFOD dataset; Convolution neural network; VGG16;
   Inception V3
ID LOCALIZATION
AB Nowadays, various image editing tools are available that can be utilized for manipulating the original images; here copy-move forgery is most common forgery. In copy-move forgery, some part of the original image is copied and pasted into the same image at some other location. However, Artificial Intelligence (AI) based approaches can extract manipulated features easily. In this study, a deep learning-based method is proposed to classify the copy-move forged images. For classifying the forged images, a deep learning (DL) based hybrid model is pre-sented named as VI-NET using fusion of two DL architectures, i.e., VGG16 and Inception V3. Further, output of two models is concatenated and connected with two additional convolutional layers. Cross-validation protocols, K10 (90 % training, 10 % testing), K5 (80 % training, 20 % testing), and K2 (50 % training, 50 % testing) are applied on the COMOFOD dataset. Moreover, the performance of VI-NET is compared with transfer learning and machine learning models using evaluation metrics such as accuracy, precision, recall, F1 score, etc. Proposed hybrid model performed better than other approaches with classification accuracy of 99 +/- 0.2 % in comparison to accuracy of 95 +/- 4 % (Inception V3), 93 +/- 5 % (MobileNet), 59 +/- 8 % (VGG16), 60 +/- 1 % (Decision tree), 87 +/- 1 % (KNN), 54 +/- 1 % (Naive Bayes) and 65 +/- 1 % (random forest) under K10 protocol. Similarly, results are evaluated based on K2 and K5 validation protocols. It is experimentally observed that the proposed model performance is better than existing standard and customized deep learning architectures.
C1 [Kumar, Sanjeev; Gupta, Suneet K.; Gupta, Umesh] Bennett Univ, CSE Dept, Greater Noida, UP, India.
   [Kumar, Sanjeev] Delhi NCR, KIET Grp Inst, Dept IT, Ghaziabad, India.
   [Kaur, Manjit] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea.
C3 KIET Group of Institutions; Gwangju Institute of Science & Technology
   (GIST)
RP Kumar, S (corresponding author), Bennett Univ, CSE Dept, Greater Noida, UP, India.; Kumar, S (corresponding author), Delhi NCR, KIET Grp Inst, Dept IT, Ghaziabad, India.
RI GUPTA, UMESH/AAC-4589-2021; Gupta, Dr. SUneet/ABG-7279-2022; Kumar, Dr.
   Sanjeev/AAJ-7172-2021
OI GUPTA, UMESH/0000-0002-1547-7974; Gupta, Dr. SUneet/0000-0002-0757-1290;
   Kumar, Dr. Sanjeev/0000-0001-9977-8004
CR Abdalla Y, 2019, INFORMATION, V10, DOI 10.3390/info10090286
   Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Agarwal Mohit, 2022, Advanced Computing: 11th International Conference, IACC 2021, Revised Selected Papers. Communications in Computer and Information Science (1528), P99, DOI 10.1007/978-3-030-95502-1_8
   Agarwal Mohit, 2020, Smart Systems and IoT: Innovations in Computing. Proceeding of SSIC 2019. Smart Innovation, Systems and Technologies (SIST 141), P391, DOI 10.1007/978-981-13-8406-6_37
   Agarwal M, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03793-1
   Agarwal M, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2020.100473
   Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Agarwal M, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), P246, DOI [10.1109/ICTS.2019.8850964, 10.1109/icts.2019.8850964]
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   [Anonymous], 1992, J CHROMATOGR LIB, V52, P55, DOI [10.1016/S0301-4770(08)60330-9, DOI 10.1016/S0301-4770(08)60330-9]
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Badr A., 2020, 8 INT S DIG FOR SEC
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Chauhan D, 2016, PROCEDIA COMPUT SCI, V85, P206, DOI 10.1016/j.procs.2016.05.213
   Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   cs.fau.de, 2021, IMD DATASET REPOSITO
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   Du MN, 2020, Arxiv, DOI arXiv:1909.05999
   Gupta D, 2021, MULTIMED TOOLS APPL, V80, P30091, DOI 10.1007/s11042-020-10242-8
   Gupta U, 2021, INT J MACH LEARN CYB, V12, P1311, DOI 10.1007/s13042-020-01235-y
   Islam MM, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091500
   kaggle.com, 2021, KAGGLE DATASET REPOS
   Kumar Sanjeev, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P253, DOI 10.1109/ICRITO48877.2020.9197955
   Kuznetsov A., 2019, Journal of Physics: Conference Series, V1368, DOI 10.1088/1742-6596/1368/3/032028
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Maind Rohini A, 2014, INT J SOFT COMPUT EN, V4, P49
   Marra F, 2020, IEEE ACCESS, V8, P133488, DOI 10.1109/ACCESS.2020.3009877
   Mayer O, 2020, IEEE T INF FOREN SEC, V15, P1331, DOI 10.1109/TIFS.2019.2924552
   Mushtaq S, 2018, INT J FUTUR GENER CO, V11, P11, DOI 10.14257/ijfgcn.2018.11.2.02
   Narayanan Shibu S., 2020, 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT), DOI 10.1109/ICCCNT49239.2020.9225658
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Sridevi M, 2012, ADV COMPUTER SCI ENG, P715, DOI DOI 10.1007/978-3-642-30157-5_71
   Sun Y, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1301290
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   unifi.it, 2021, MICC F220 PUBLIC REP
   unipa.it, 2021, DIID DATASET REPOSIT
   vcl.fer.hr, 2021, COMOFOD DATASET REPO
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Zheng LL, 2019, J VIS COMMUN IMAGE R, V58, P380, DOI 10.1016/j.jvcir.2018.12.022
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhou Y, 2021, IEEE T CYBERNETICS, V51, P1626, DOI 10.1109/TCYB.2019.2928174
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 54
TC 6
Z9 6
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103644
DI 10.1016/j.jvcir.2022.103644
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300005
DA 2024-07-18
ER

PT J
AU Delibasoglu, I
   Kosesoy, I
   Kotan, M
   Selamet, F
AF Delibasoglu, Ibrahim
   Kosesoy, Irfan
   Kotan, Muhammed
   Selamet, Feyza
TI Motion detection in moving camera videos using background modeling and
   FlowNet
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion detection; Moving object detection; Dense optical flow; Moving
   camera
ID OBJECT DETECTION; MIXTURE; ROBUST
AB Real-time moving object detection is challenging for moving cameras due to the moving background. Many studies use homography matrix to compensate for global motion by warping the background model to the current frame. Then, the pixel difference between the current frame and the background model is used for background subtraction. Moving pixels are extracted by applying adaptive threshold and some post-processing techniques. On the other hand, deep learning-based dense optical flow can be efficient enough to extract the moving pixels, but it increases computational cost. This study proposes a method to enhance a classical background modeling method with deep learning-based dense optical flow. The main contribution of this paper is to propose a fusing algorithm for dense optical flow and background modeling approach. The background modeling methods are error-prone, especially with continuous camera movement, while the optical flow method alone may not always be efficient. Our hybrid method fuses both techniques to improve the detection accuracy. We propose a software architecture to run background modeling and dense optical flow methods in parallel processes. The proposed implementation approach significantly increases the method's working speed, while the proposed fusion and combining strategy improve detection results. The experimental results show that the proposed method can run at high speed and has satisfying performance against the methods in the literature.
C1 [Delibasoglu, Ibrahim] Sakarya Univ, Fac Comp & Informat Sci, Software Engn, Sakarya, Turkey.
   [Kosesoy, Irfan] Kocaeli Univ, Fac Engn, Software Engn, Kocaeli, Turkey.
   [Kotan, Muhammed] Sakarya Univ, Fac Comp & Informat Sci, Informat Syst Engn, Sakarya, Turkey.
   [Selamet, Feyza] Sakarya Univ, Fac Comp & Informat Sci, Comp Engn, Sakarya, Turkey.
C3 Sakarya University; Kocaeli University; Sakarya University; Sakarya
   University
RP Delibasoglu, I (corresponding author), Sakarya Univ, Fac Comp & Informat Sci, Software Engn, Sakarya, Turkey.
EM ibrahimdelibasoglu@sakarya.edu.tr
RI Delibasoglu, Ibrahim/AAH-6523-2021; Kotan, Muhammed/AAD-2451-2020;
   Kösesoy, irfan/AFQ-2029-2022; SELAMET, Feyza/ADZ-4909-2022
OI Delibasoglu, Ibrahim/0000-0001-8119-2873; Kotan,
   Muhammed/0000-0002-5218-8848; Kösesoy, irfan/0000-0001-5219-5397;
   SELAMET, Feyza/0000-0002-1596-1109
CR Allebosch G, 2015, LECT NOTES COMPUT SC, V9386, P130, DOI 10.1007/978-3-319-25903-1_12
   Anthwal S, 2019, IMAGING SCI J, V67, P284, DOI 10.1080/13682199.2019.1641316
   Babaryka Anatolii, 2022, Future Intent-Based Networking: On the QoS Robust and Energy Efficient Heterogeneous Software Defined Networks. Lecture Notes in Electrical Engineering (831), P468, DOI 10.1007/978-3-030-92435-5_26
   Bouwmans T, 2014, Background modeling and foreground detection for video surveillance
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Burt Peter, 2000, VSAM final report, P1
   Chapel MN, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100310
   Chen CLZ, 2022, IEEE T CIRC SYST VID, V32, P2732, DOI 10.1109/TCSVT.2021.3095843
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CLZ, 2018, IEEE SIGNAL PROC LET, V25, P154, DOI 10.1109/LSP.2017.2775212
   Chen CLZ, 2016, PATTERN RECOGN, V52, P410, DOI 10.1016/j.patcog.2015.09.033
   Darwich A, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070092
   De Gregorio M., 2017, ESANN
   Delibasoglu I, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.6.063027
   Delibasoglu Ibrahim., 2021, BILISIM TEKNOLOJILER, V14, P223
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Giraldo JH, 2021, IEEE INT CONF COMP V, P225, DOI 10.1109/ICCVW54120.2021.00030
   Giraldo JH, 2021, COMM COM INF SC, V1405, P31, DOI 10.1007/978-3-030-81638-4_3
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Huang JJ, 2018, Arxiv, DOI arXiv:1807.04890
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Javed S, 2018, 2018 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P836, DOI 10.1109/SSP.2018.8450718
   Kurnianggoro L, 2016, INT C CONTR AUTOMAT, P704, DOI 10.1109/ICCAS.2016.7832395
   Li YX, 2021, IEEE T CIRC SYST VID, V31, P2315, DOI 10.1109/TCSVT.2020.3023080
   Lixing Zhao, 2011, 2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC 2011), P4387, DOI 10.1109/AIMSEC.2011.6010154
   Mandal M, 2022, IEEE T INTELL TRANSP, V23, P6101, DOI [10.1109/TITS.2021.3077883, 10.3233/IP-200233]
   Messelodi S, 2005, LECT NOTES COMPUT SC, V3617, P163, DOI 10.1007/11553595_20
   Munteanu O., 2015, T ELECT COMMUN, V60, P1
   Rodríguez P, 2015, IEEE IMAGE PROC, P537, DOI 10.1109/ICIP.2015.7350856
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Varadarajan S, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P63, DOI 10.1109/AVSS.2013.6636617
   Yi KM, 2013, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2013.9
   Yu Y, 2019, INT J CONTROL AUTOM, V17, P1866, DOI 10.1007/s12555-018-0234-3
   Yun KM, 2017, PATTERN RECOGN LETT, V88, P57, DOI 10.1016/j.patrec.2017.01.017
   Zhao ZJ, 2012, COMM COM INF SC, V346, P177
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 39
TC 4
Z9 4
U1 3
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103616
DI 10.1016/j.jvcir.2022.103616
EA SEP 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800009
DA 2024-07-18
ER

PT J
AU Zhang, ZN
   Pan, ZG
   Li, WQ
   Su, ZY
AF Zhang, Zhenning
   Pan, Zhigeng
   Li, Weiqing
   Su, Zhiyong
TI Imitative Collaboration: A mirror-neuron inspired mixed reality
   collaboration method with remote hands and local replicas
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mixed reality; Remote collaboration; Mirror-neuron; Gestural
   interaction; Point cloud interaction
ID CUES
AB Mixed reality can overlay and display 3D digital content in the real world, convey abstract concepts to users, and promote the understanding of complex tasks. However, the abstract graphics overlaid on the physical space may cause a certain cognitive load for local users and reduce the efficiency of collaboration. To improve the efficiency of remote collaboration, we conducted an elicitation study on assembly tasks, explored the user needs for collaboration, and defined the design goals of our remote collaboration method. Inspired by the mirror-neuron mechanism, we present an imitative collaboration method that allows local users to imitate the interaction behavior of remote users to complete tasks. We also propose a series of interaction methods for remote users to select, copy, and interact with the local point clouds to facilitate the expression of collaboration intentions. Finally, the results of a user study evaluating our imitative collaboration method on assembly tasks are reported, confirming that our method improves collaboration efficiency while reducing the cognitive load of local users.
C1 [Zhang, Zhenning; Li, Weiqing] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing, Peoples R China.
   [Su, Zhiyong] Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Information Science & Technology; Nanjing University of Science &
   Technology
RP Li, WQ (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.; Pan, ZG (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing, Peoples R China.
EM zgpan@hznu.edu.cn; li_weiqing@njust.edu.cn
OI Zhang, Zhenning/0000-0001-5989-3593; su, zhiyong/0000-0001-9483-5268
FU Pre-research Project of the 14th Five-Year Plan [50904040201]
FX Acknowledgments We thank the anonymous reviewers for their constructive
   comments and the user study participants for their time. This work was
   supported by the Pre-research Project of the 14th Five-Year Plan (grant
   number: 50904040201) .
CR Ayres P, 2009, COMPUT HUM BEHAV, V25, P348, DOI 10.1016/j.chb.2008.12.013
   Ballestin G, 2021, IEEE ACCESS, V9, P64828, DOI 10.1109/ACCESS.2021.3075780
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Brihmat N, 2018, BRAIN IMAGING BEHAV, V12, P1363, DOI 10.1007/s11682-017-9804-x
   Burgess R, 2015, IFIP ADV INF COMM TE, V450, P188, DOI 10.1007/978-3-319-16766-4_20
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Chessa M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1749, DOI [10.1109/vr.2019.8798155, 10.1109/VR.2019.8798155]
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Ferrari V., 2020, IEEE T VIS COMPUT GR
   Funk M, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P253, DOI 10.1145/2836041.2836067
   Gao L, 2018, SA'18: SIGGRAPH ASIA 2018 VIRTUAL & AUGMENTED REALITY, DOI 10.1145/3275495.3275515
   Gurevich P., 2012, P SIGCHI C HUM FACT, P619
   HART S G, 1988, P139
   Hu X, 2022, IEEE J BIOMED HEALTH, V26, P910, DOI 10.1109/JBHI.2021.3088442
   Huang WD, 2019, J VIS COMMUN IMAGE R, V58, P428, DOI 10.1016/j.jvcir.2018.12.010
   Jasche F, 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445724
   Johnson JanetG., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kim SW, 2016, IEEE INTEL TRANSP SY, V8, P23, DOI 10.1109/MITS.2016.2573339
   Kim S, 2020, J MULTIMODAL USER IN, V14, P321, DOI 10.1007/s12193-020-00335-x
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kim S, 2014, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2014.6948412
   Kirk D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1039
   Kleinholdermann U, 2013, J VISION, V13, DOI 10.1167/13.8.23
   Kommalapati R, 2016, IEEE ENG MED BIO, P5849, DOI 10.1109/EMBC.2016.7592058
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Ludwig T, 2021, COMPUT SUPP COOP W J, V30, P119, DOI 10.1007/s10606-021-09393-5
   Mao HW, 2020, BRAIN BEHAV, V10, DOI 10.1002/brb3.1729
   Marques B, 2021, IEEE T VIS COMPUT GR
   Montano-Murillo RA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P53, DOI [10.1109/VR46266.2020.1581198507712, 10.1109/VR46266.2020.00-81]
   Muller Leon, 2021, P 2021 CHI C HUMAN F, P1
   Nuernberger B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1233, DOI 10.1145/2858036.2858250
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Oprea S, 2019, COMPUT GRAPH-UK, V83, P77, DOI 10.1016/j.cag.2019.07.003
   Rhee T, 2020, IEEE T VIS COMPUT GR, V26, P1923, DOI 10.1109/TVCG.2020.2973065
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sasikumar P, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P393, DOI 10.1109/ISMAR-Adjunct.2019.000-3
   Sodhi R. S., 2013, P SIGCHI C HUMAN FAC, P179
   Tian H., 2018, 2018 IEEE C VIRT REA, P1
   Valentin J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751556
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P31059, DOI 10.1007/s11042-020-09731-7
   Wang P, 2019, INT J ADV MANUF TECH, V105, P3031, DOI 10.1007/s00170-019-04434-2
   Yamamoto S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P71
   Yu LY, 2016, IEEE T VIS COMPUT GR, V22, P886, DOI 10.1109/TVCG.2015.2467202
   Yue YT, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P427, DOI 10.1145/3126594.3126601
   Zillner J, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P38, DOI 10.1109/ISMAR-Adjunct.2018.00028
NR 47
TC 3
Z9 3
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103600
DI 10.1016/j.jvcir.2022.103600
EA AUG 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4H2GN
UT WOS:000849699300004
DA 2024-07-18
ER

PT J
AU Wang, BW
   Wang, WS
   Zhao, P
AF Wang, Baowei
   Wang, Weishen
   Zhao, Peng
TI A zero-watermark algorithm for multiple images based on visual
   cryptography and image fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero-watermark; Multipleimages; Copyrightprotection;
   Non-extendedvisualcryptography; Gray-weightedaverageimagefusion
ID COPYRIGHT PROTECTION; ROBUST WATERMARKING; SCHEME
AB At present, it is difficult for the multiple images zero-watermark algorithm to protect all the images in the image set, and repeated operations will reduce the efficiency of the algorithm. To solve these issues, the proposed algorithm can design a reasonable copyright protection scheme according to the number of images in the image set to realize the protection of all images, and reduce the cost of time and storage. The gray-weighted average image fusion method is used to fuse multiple normalized standard images into one image. The LWT(Lifting the Wavelet Transform)-QR decomposition is applied to the effective area of the fusion image to obtain the robust feature image. Non-extended visual cryptography is used to enhance the security of the algorithm. A zero-watermark image is obtained by using the XOR manipulation for the feature image and the public shared image. Experimental results demonstrate that the proposed algorithm has good performance.
C1 [Wang, Baowei; Wang, Weishen; Zhao, Peng] Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.
   [Wang, Baowei] Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Wang, Baowei] Minist Educ, Engn Res Ctr Digital Forens, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Wang, BW (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.
EM wang@nuist.edu.cn
FU National Natural Science Foun-dation of China [61972207, U1836208,
   U1836110, 61672290]; Major Program of the National Social Science Fund
   of China [17ZDA092]; National Key R&D Pro-gram of China
   [2018YFB1003205]; Collaborative Innovation Center of Atmospheric
   Environment and Equipment Tech-nology (CICAEET) fund, China; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD) , China fund
FX This work is supported by the National Natural Science Foun-dation of
   China [grant numbers 61972207, U1836208, U1836110, 61672290] ; the Major
   Program of the National Social Science Fund of China [grant number
   17ZDA092] , by the National Key R&D Pro-gram of China [grant number
   2018YFB1003205] ; by the Collaborative Innovation Center of Atmospheric
   Environment and Equipment Tech-nology (CICAEET) fund, China; by the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD) , China fund.
CR Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen HH, 2016, IEEE T PARALL DISTR, V27, P1116, DOI 10.1109/TPDS.2015.2427155
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Computer Vision Group University of Granada, 2002, MISC GRAY LEV IM
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Edris K, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN (ICED), P219, DOI 10.1109/ICED.2014.7015802
   Fatahbeygi A, 2019, J INF SECUR APPL, V45, P71, DOI 10.1016/j.jisa.2019.01.005
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Li D., 2020, INT C INTELLIGENT IN, V1304, P984
   Li MJ, 2013, INT CONF MEASURE, P341, DOI 10.1109/MIC.2013.6757979
   Liu XL, 2017, PROC SPIE, V10225, DOI 10.1117/12.2267045
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Sang J, 2006, OPT ENG, V45, DOI 10.1117/1.2354076
   Shakeri M, 2011, LECT NOTES COMPUT SC, V7088, P359, DOI 10.1007/978-3-642-25346-1_32
   Shakfa M.K., 2011, 2011 Ger. Microw. Conf, P1
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Sun L., 2015, MathSJ, V9, P2023, DOI DOI 10.12785/AMIS/090442
   SWELDENS W, 1995, P SOC PHOTO-OPT INS, V2569, P68, DOI 10.1117/12.217619
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wen Q., 2001, P 3 CHIN INF HID MUL, P102
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   [熊祥光 Xiong Xiangguang], 2018, [自动化学报, Acta Automatica Sinica], V44, P160
   Xu Xiaoyan, 2015, Applied Mechanics and Materials, V731, P187, DOI 10.4028/www.scientific.net/AMM.731.187
   Yang KY, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P236, DOI 10.1109/IAEAC.2018.8577943
   Yongchang Chen, 2019, 2019 International Conference on Intelligent Computing, Automation and Systems (ICICAS), P726, DOI 10.1109/ICICAS48597.2019.00157
   Yuan ZH, 2017, AER ADV ENG RES, V61, P117
   Zhao J, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/7672839
NR 35
TC 7
Z9 7
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103569
DI 10.1016/j.jvcir.2022.103569
EA JUL 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3C7GN
UT WOS:000828788400001
DA 2024-07-18
ER

PT J
AU Zhou, W
   Min, XK
   Li, H
   Jiang, QP
AF Zhou, Wei
   Min, Xiongkuo
   Li, Hong
   Jiang, Qiuping
TI A brief survey on adaptive video streaming quality assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Quality of experience; Video quality assessment; Adaptive streaming;
   Performance analysis; Deep convolutional neural network; Spatio-temporal
   characteristics
ID MODELS
AB Quality of experience (QoE) assessment for adaptive video streaming plays a significant role in advanced network management systems. It is especially challenging in case of dynamic adaptive streaming schemes over HTTP (DASH) which has increasingly complex characteristics including additional playback issues. In this paper, we provide a brief overview of adaptive video streaming quality assessment. Upon our review of related works, we analyze and compare different variations of objective QoE assessment models with or without using machine learning techniques for adaptive video streaming. Through the performance analysis, we observe that hybrid models perform better than both quality-of-service (QoS) driven QoE approaches and signal fidelity measurement. Moreover, the machine learning-based model slightly outperforms the model without using machine learning for the same setting. In addition, we find that existing video streaming QoE assessment models still have limited performance, which makes it difficult to be applied in practical communication systems. Therefore, based on the success of deep learned feature representations for traditional video quality prediction, we also apply the off-the-shelf deep convolutional neural network (DCNN) to evaluate the perceptual quality of streaming videos, where the spatio-temporal properties of streaming videos are taken into consideration. Experiments demonstrate its superiority, which sheds light on the future development of specifically designed deep learning frameworks for adaptive video streaming quality assessment. We believe this survey can serve as a guideline for QoE assessment of adaptive video streaming.
C1 [Zhou, Wei] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada.
   [Zhou, Wei] Univ Sci & Technol China, Geospatial Informat Proc & Applicat Syst, CAS Key Lab Technol, Hefei 230027, Peoples R China.
   [Min, Xiongkuo] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
   [Li, Hong] Ningbo Univ, Coll Sci & Technol, Ningbo 315211, Peoples R China.
   [Jiang, Qiuping] Ningbo Univ, Sch Informat Sci & Engn, Ningbo 315211, Peoples R China.
C3 University of Waterloo; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; Shanghai Jiao Tong University;
   Ningbo University; Ningbo University
RP Jiang, QP (corresponding author), Ningbo Univ, Sch Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM jiangqiuping@nbu.edu.cn
RI Jiang, Qiuping/AAL-8273-2020; Zhou, Wei/AAG-8797-2020; Min,
   Xiongkuo/A-7097-2019
OI Min, Xiongkuo/0000-0001-5693-0416; Qiuping, Jiang/0000-0002-6025-9343
FU Zhejiang Natural Science Foundation [LR22F020002]; Natural Science
   Foundation of China [61901236]
FX Acknowledgments This work was supported in part by the Zhejiang Natural
   Science Foundation under Grant LR22F020002 and in part by the Natural
   Science Foundation of China under Grants 61901236.
CR Akhtar Z, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P44, DOI 10.1145/3230543.3230558
   Alreshoodi M., 2013, International Journal of Distributed and Parallel Systems, V4, P53
   [Anonymous], 2008, QUAL EXP REQ IPTV SE
   Bampis C. G., 2017, arXiv:1703.00633
   Bampis CG, 2021, IEEE T IMAGE PROCESS, V30, P5182, DOI 10.1109/TIP.2021.3073294
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P5217, DOI 10.1109/TIP.2017.2729891
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Chen C, 2014, IEEE T IMAGE PROCESS, V23, P2206, DOI 10.1109/TIP.2014.2312613
   Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   Chen ZB, 2016, IEEE T CIRC SYST VID, V26, P1029, DOI 10.1109/TCSVT.2015.2441432
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Deng J., 2009, IEEE C COMP VIS PATT
   Duanmu Z., 2020, ARXIV PREPRINT ARXIV
   Duanmu ZF, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1752, DOI 10.1145/3123266.3123418
   Duanmu ZF, 2018, IEEE T BROADCAST, V64, P474, DOI 10.1109/TBC.2018.2822870
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   Fang YM, 2019, J VIS COMMUN IMAGE R, V58, P400, DOI 10.1016/j.jvcir.2018.12.006
   Ghadiyaram D, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P989, DOI 10.1109/GlobalSIP.2014.7032269
   Hossfeld Tobias, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P494, DOI 10.1109/ISM.2011.87
   Jiang QP, 2015, J VIS COMMUN IMAGE R, V33, P123, DOI 10.1016/j.jvcir.2015.09.009
   Kibria MG, 2018, IEEE ACCESS, V6, P32328, DOI 10.1109/ACCESS.2018.2837692
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Li LD, 2016, J VIS COMMUN IMAGE R, V38, P550, DOI 10.1016/j.jvcir.2016.04.006
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Lin JY, 2015, J VIS COMMUN IMAGE R, V30, P1, DOI 10.1016/j.jvcir.2015.02.012
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lopez-Martin M, 2018, IEEE COMMUN MAG, V56, P110, DOI 10.1109/MCOM.2018.1701156
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Rehman A, 2015, PROC SPIE, V9394, DOI 10.1117/12.2077917
   Rodríguez DZ, 2012, IEEE T CONSUM ELECTR, V58, P985, DOI 10.1109/TCE.2012.6311346
   Seshadrinathan K, 2010, PROC SPIE, V7527, DOI 10.1117/12.845382
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Vega M.T., 2016, INT J PERVASIVE COMP
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2017, PROC SMPTE MOTION IM, P1
   Wang Z., 2016, Electron. Imag., V2016, P1
   Xu JH, 2018, LECT NOTES COMPUT SC, V11164, P589, DOI 10.1007/978-3-030-00776-8_54
   Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhou W, 2020, IEEE I C VI COM I PR, P338, DOI 10.1109/vcip49819.2020.9301764
   Zhou W, 2018, LECT NOTES COMPUT SC, V11166, P482, DOI 10.1007/978-3-030-00764-5_44
   Zhou W, 2019, IEEE T IMAGE PROCESS, V28, P3946, DOI 10.1109/TIP.2019.2902831
NR 45
TC 9
Z9 10
U1 7
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103526
DI 10.1016/j.jvcir.2022.103526
EA MAY 2022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1V1LX
UT WOS:000805861200006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pan, TH
   Wang, Z
   Fan, Y
AF Pan, Tianhong
   Wang, Zheng
   Fan, Yuan
TI Optimized convolutional pose machine for 2D hand pose estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional block attention module (CBAM); Convolutional pose machine
   (CPM); 2D hand pose estimation; Resnet-18; Feature fusion
AB Hand pose estimation is a challenging task owing to the high flexibility and serious self-occlusion of the hand. Therefore, an optimized convolutional pose machine (OCPM) was proposed in this study to estimate the hand pose accurately. Traditional CPMs have two components, a feature extraction module and an information processing module. First, the backbone network of the feature extraction module was replaced by Resnet-18 to reduce the number of network parameters. Furthermore, an attention module called the convolutional block attention module (CBAM) is embedded into the feature extraction module to enhance the information extraction. Then, the structure of the information processing module was adjusted through a residual connection in each stage that consist of a series of continuous convolutional operations, and requires a dense fusion between the output from all previous stages and the feature extraction module. The experimental results on two public datasets showed that the OCPM network achieved excellent performance.
C1 [Pan, Tianhong; Wang, Zheng; Fan, Yuan] Anhui Univ, Sch Elect Engn & Automat, Hefei, Peoples R China.
C3 Anhui University
RP Fan, Y (corresponding author), Anhui Univ, Sch Elect Engn & Automat, Hefei, Peoples R China.
EM thpan@live.com; 631753565@qq.com; yuanf@ahu.edu.cn
RI FAN, Yuan/B-7164-2008; Pan, Tianhong/J-8591-2012
OI Pan, Tianhong/0000-0002-0993-3937
FU National Natural Science Foundation of China [61873113]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61873113.
CR [Anonymous], 2014, P ADV NEUR INF PROC
   Cai YJ, 2021, IEEE T PATTERN ANAL, V43, P3739, DOI 10.1109/TPAMI.2020.2993627
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chen YF, 2020, IEEE WINT CONF APPL, P370, DOI [10.1109/WACV45572.2020.9093271, 10.1109/wacv45572.2020.9093271]
   Ge L., 2018, IEEE T IMAGE PROCESS, V27
   gitcode, ABOUT US
   Gomez-Donoso F, 2019, IMAGE VISION COMPUT, V81, P25, DOI 10.1016/j.imavis.2018.12.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Lee T, 2009, IEEE T VIS COMPUT GR, V15, P355, DOI 10.1109/TVCG.2008.190
   Li XF, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115692
   Liu LY, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329055
   Lu D., 2021, J VIS COMMUN IMAGE R, V79
   Mahmud S, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P768, DOI [10.1109/CCWC47524.2020.9031244, 10.1109/ccwc47524.2020.9031244]
   Malik S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P117, DOI 10.1109/ISMAR.2002.1115080
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Santavas N, 2021, IEEE SENS J, V21, P11488, DOI 10.1109/JSEN.2020.3018172
   Seo NJ, 2016, J REHABIL RES DEV, V53, P321, DOI 10.1682/JRRD.2015.03.0045
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Simonyan K., 2014, 14091556 ARXIV
   Sun J, 2020, IET IMAGE PROCESS, V14, P3579, DOI 10.1049/iet-ipr.2019.0924
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang YG, 2019, IEEE T CIRC SYST VID, V29, P3258, DOI 10.1109/TCSVT.2018.2879980
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2018, IEEE T BIOMED CIRC S, V12, P1322, DOI 10.1109/TBCAS.2018.2878395
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Zagoruyko S., 2017, P INT C LEARN REPR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 33
TC 7
Z9 7
U1 5
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103461
DI 10.1016/j.jvcir.2022.103461
EA FEB 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6OC
UT WOS:000819856800005
DA 2024-07-18
ER

PT J
AU Cai, L
   Fu, YL
   Zhu, T
   Xiang, YJ
   Zeng, HQ
AF Cai, Lei
   Fu, Yuli
   Zhu, Tao
   Xiang, Youjun
   Zeng, Huanqiang
TI Proximal-Gen for fast compressed sensing recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed sensing; Generative models; Generator range; Reconstruction
   efficiency
AB Compressed sensing (CS) can recover an image from a few random measurements by exploiting the sparsit y assumption on the structu r e of images. Some recent generative model-based CS recover y methods have removed the sparsity constraint, but their recover y process is slow and the recovered signal is constrained to be in the generator range. Here, we propose a new framework, called Proximal-Gen, for CS recovery. Specifically, we first formulate a general domain of the recovered signals, this allow s the subsequent recover y algorithms to recover the signals that deviate from the generator range. Then based on the general domain, we develop a fast recovery algorithm, which mainly consists of two sub-algorithms, namely network-based projected gradient descent (NPGD) and denoiser-based proximal gradient descent (DPGD). The NPGD is used to obtain an intermediate signal lying in the generator range, while the DPGD is proposed to recover a deviation signal. Compared with multiple recent generative model-based recover y methods, ou r method can achieve better reconstruction performance and higher efficienc y under most measurements.
C1 [Cai, Lei; Fu, Yuli; Zhu, Tao; Xiang, Youjun] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China.
   [Zeng, Huanqiang] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen 361021, Peoples R China.
C3 South China University of Technology; Huaqiao University
RP Xiang, YJ (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China.
EM eelcai@mail.scut.edu.cn; fuyuli@scut.edu.cn; ee_zt_21@mail.scut.edu.cn;
   yjxiang@scut.edu.cn; zeng0043@hqu.edu.cn
RI Zhu, Tao/JEF-1129-2023; Zeng, Huanqiang/U-2017-2018; zhu,
   tao/KHY-3114-2024
OI Zhu, Tao/0009-0001-1499-8700; 
CR Aggarwal HK, 2019, IEEE T MED IMAGING, V38, P394, DOI 10.1109/TMI.2018.2865356
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Bickel PJ, 2009, ANN STAT, V37, P1705, DOI 10.1214/08-AOS620
   Blumensath T, 2010, IEEE J-STSP, V4, P298, DOI 10.1109/JSTSP.2010.2042411
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Bora A, 2017, PR MACH LEARN RES, V70
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Dhar M., 2018, INT C MACHINE LEARNI
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Goodfellow M.M. I., 2014, ADV NEURAL INFORM PR, P2672
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kabkab M, 2018, AAAI CONF ARTIF INTE, P2297
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, ARXIV13126114
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Liu YL, 2020, IEEE T COMPUT IMAG, V6, P434, DOI 10.1109/TCI.2019.2956877
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mahdizadehaghdam S., 2019, IEEE CVF INT C COMP
   Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1
   Meinhardt T, 2017, IEEE I CONF COMP VIS, P1799, DOI 10.1109/ICCV.2017.198
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Pati Y.C., 1993, AS C SIGN SYST COMP, P40
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Radford A., 2015, ARXIV
   Raj A, 2019, IEEE I CONF COMP VIS, P5601, DOI 10.1109/ICCV.2019.00570
   Rousset F, 2017, IEEE T COMPUT IMAG, V3, P36, DOI 10.1109/TCI.2016.2637079
   Schlemper J, 2018, IEEE T MED IMAGING, V37, P491, DOI 10.1109/TMI.2017.2760978
   Shah V, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4609, DOI 10.1109/ICASSP.2018.8462233
   Sharma K, 2016, IEEE COMMUN SURV TUT, V18, P1838, DOI 10.1109/COMST.2016.2524443
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wu YF, 2019, PR MACH LEARN RES, V97
   Xu SJ, 2019, INT CONF ACOUST SPEE, P2967, DOI [10.1109/ICASSP.2019.8683641, 10.1109/icassp.2019.8683641]
   Yu Fisher, 2015, ARXIV150603365
   Zbontar J., 2018, arXiv preprint arXiv:1811.08839
   Zeng W, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115701
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang XJ, 2018, IEEE T VEH TECHNOL, V67, P1146, DOI 10.1109/TVT.2017.2749254
NR 43
TC 2
Z9 2
U1 3
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103358
DI 10.1016/j.jvcir.2021.103358
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z2GF
UT WOS:000790895000003
DA 2024-07-18
ER

PT J
AU Wang, X
   Chang, CC
   Lin, CC
   Chang, CC
AF Wang, Xu
   Chang, Ching-Chun
   Lin, Chia-Chen
   Chang, Chin-Chen
TI Reversal of pixel rotation: A reversible data hiding system towards
   cybersecurity in encrypted images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Encrypted images; Pixel rotation; Lossless
   scheme
ID EXPANSION; SCHEME
AB Due to privacy and security concerns, the researches of reversible data hiding in encrypted images (RDHEI) have become increasingly important. Conventional schemes vacate the spare room after image encryption (VRAE) suffer from the low embedding rate, high error rate of data extraction, and imperfect image recovery. To address these issues, we propose a separable reversible data hiding scheme for encrypted images that utilizes a novel pixel rotation technique to embed data into fully encrypted images. The block complexities of four decrypted rotation states are considered when recovering image. To realize perfect image recovery, we further devise a lossless version (LPR-RDHEI). Experimental results demonstrate that the proposed PR-RDHEI scheme achieves an embedding rate of 0.4994 bpp on average and ensures lossless data extraction. Meanwhile, the proposed LPRRDHEI scheme still has a 0.4494 bpp embedding rate on average. The embedding rates of our two schemes are significantly improved compared with state-of-the-arts.
C1 [Wang, Xu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Ching-Chun] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
C3 Feng Chia University; University of Warwick; National Chin-Yi University
   of Technology
RP Lin, CC (corresponding author), Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
EM wx1990555@gmail.com; c.c.chang@warwickgrad.net; ally.cclin@ncut.edu.tw;
   alan3c@gmail.com
RI 王, 旭/GPX-0697-2022; Chang, Ching-Chun/JAN-6210-2023; 王, 旭/JAX-6722-2023
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., Image database of BOWS-2.
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang CC, 2020, IEEE ACCESS, V8, P198425, DOI 10.1109/ACCESS.2020.3034936
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chen B, 2022, IEEE T DEPEND SECURE, V19, P978, DOI 10.1109/TDSC.2020.3011923
   Chen B, 2018, J VIS COMMUN IMAGE R, V57, P272, DOI 10.1016/j.jvcir.2018.11.017
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2013, SIGNAL PROCESS, V93, P2529, DOI 10.1016/j.sigpro.2013.03.029
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Shiu PF, 2019, SIGNAL PROCESS-IMAGE, V74, P64, DOI 10.1016/j.image.2019.01.003
   Su GD, 2020, IEEE ACCESS, V8, P26984, DOI 10.1109/ACCESS.2020.2966234
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103203
   Wang X, 2021, INFORM SCIENCES, V567, P375, DOI 10.1016/j.ins.2021.02.079
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 46
TC 13
Z9 13
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103421
DI 10.1016/j.jvcir.2021.103421
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400008
DA 2024-07-18
ER

PT J
AU Zhu, ZQ
   Luo, YQ
   Chen, SX
   Qi, GQ
   Mazur, N
   Zhong, CY
   Li, QW
AF Zhu, Zhiqin
   Luo, Yaqin
   Chen, Sixin
   Qi, Guanqiu
   Mazur, Neal
   Zhong, Chengyan
   Li, Qiwang
TI Camera style transformation with preserved self-similarity and
   domain-dissimilarity in unsupervised person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised domain adaptation; Person re-identification; Cross-domain;
   Circle loss; Maximum mean discrepancy
ID ADAPTATION; NETWORK; GAN
AB The inconsistency caused by different factors, such as different camera imaging methods, complex imaging environments, and changes in light, present a huge challenge to person re-identification (re-ID). Unsupervised domain adaptation (UDA) can solve the inconsistency issue to a certain extent, but different datasets may not have any overlapping of people's identities. Therefore, it is necessary to pay attention to people's identities in solving domain-dissimilarity. A camera imaging style transformation with preserved self-similarity and domain-dissimilarity (CSPSD) is proposed to solve the cross-domain issue in person re-ID. First, CycleGAN is applied to determine the style conversion between source and target domains. Intra-domain identity constraints are used to maintain identity consistency between source and target domains during the image style transformation process. Maximum mean difference (MMD) is used to reduce the difference in feature distribution between source and target domains. Then, a one-to-n mapping method is proposed to achieve the mapping between positive pairs and distinguish negative pairs. Any sample image from the source domain and its transformed image or a transformed image with the same identity information compose a positive pair. The transformed image and any image from the target domain compose a negative pair. Next, a circle loss function is used to improve the learning speed of positive and negative pairs. Finally, the proposed CSPSD that can effectively reduce the difference between domains and an existing feature learning network work together to learn a person re-ID model. The proposed method is applied to three public datasets, Market-1501, DukeMTMC-reID, and MSMT17. The comparative experimental results confirm the proposed method can achieve highly competitive recognition accuracy in person re-ID.
C1 [Zhu, Zhiqin; Luo, Yaqin; Zhong, Chengyan; Li, Qiwang] Chongqing Univ Posts & Telecommun, Coll Automat, Chongqing 400065, Peoples R China.
   [Chen, Sixin] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
   [Qi, Guanqiu; Mazur, Neal] State Univ New York Buffalo State, Comp Informat Syst Dept, Buffalo, NY 14222 USA.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications; State University of New York (SUNY)
   System; Buffalo State College
RP Qi, GQ (corresponding author), State Univ New York Buffalo State, Comp Informat Syst Dept, Buffalo, NY 14222 USA.
EM zhuzq@cqupt.edu.cn; s190301035@stu.cqupt.edu.cn;
   s200201126@stu.cqupt.edu.cn; qig@buffalostate.edu;
   mazurnm@buffalostate.edu; s190301022@stu.cqupt.edu.cn;
   liqiwang2627@126.com
RI Qi, Guanqiu/M-8332-2017
OI Zhu, Zhiqin/0000-0002-3883-2529; Qi, Guanqiu/0000-0001-9562-3865
FU National Natural Science Foundation of China [61803061, 61906026];
   Chongqing Natural Science Foundation [cstc2020jcyj-msxmX0577,
   cstc2020jcyjmsxmX0634]; Ministry of Education China Mobile Research Fund
   [MCM 20180404]; Chongqing Municipal Education Commission
   [KJCXZD2020028]; Science and Technology Research Program of Chongqing
   Municipal Education Commission, China [KJQN202000602]; Special key
   project of Chongqing technology innovation and application development
   [cstc2019jscx-zdztzx0068]
FX This work is jointly supported by the National Natural Science
   Foundation of China under Grant No. 61803061, 61906026; Innovation
   research group of universities in Chongqing; the Chongqing Natural
   Science Foundation under Grant cstc2020jcyj-msxmX0577,
   cstc2020jcyjmsxmX0634; Ministry of Education China Mobile Research Fund
   (MCM 20180404); "Chengdu-Chongqing Economic Circle" innovation funding
   of Chongqing Municipal Education Commission KJCXZD2020028; the Science
   and Technology Research Program of Chongqing Municipal Education
   Commission, China grants KJQN202000602; Special key project of Chongqing
   technology innovation and application development:
   cstc2019jscx-zdztzx0068.
CR [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], 2020, IEEE INT SYMP CIRC S, DOI [DOI 10.1109/iscas45731.2020.9180667, DOI 10.1109/JIOT.2020.2982699.]
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen Y., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P10451
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chuanchen Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P224, DOI 10.1007/978-3-030-58555-6_14
   Dai Y., 2021, IEEE T CIRC SYST VID, P1
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Fuxiang Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9579, DOI 10.1109/CVPR42600.2020.00960
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Kang BN, 2019, IEEE I CONF COMP VIS, P5471, DOI 10.1109/ICCV.2019.00557
   Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503
   Kingma D.P., 2014, ARXIV ARXIVPREPRINTA
   Li HF, 2022, IEEE T CIRC SYST VID, V32, P2814, DOI 10.1109/TCSVT.2021.3099943
   Li HF, 2021, IEEE T INF FOREN SEC, V16, P1480, DOI 10.1109/TIFS.2020.3036800
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li YY, 2021, J IMAGING, V7, DOI 10.3390/jimaging7040062
   Liu JL, 2019, IEEE ACCESS, V7, P114021, DOI 10.1109/ACCESS.2019.2933910
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Qi GQ, 2021, J IMAGING, V7, DOI 10.3390/jimaging7010006
   Qi GQ, 2019, CAAI T INTELL TECHNO, V4, P80, DOI 10.1049/trit.2018.1045
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taigman Y., 2020, ARXIV161102200
   Tu ZG, 2019, IEEE T CIRC SYST VID, V29, P1423, DOI 10.1109/TCSVT.2018.2830102
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xiao N, 2021, PROC CVPR IEEE, P15237, DOI 10.1109/CVPR46437.2021.01499
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yuanyuan Li, 2021, Proceedings of 2020 Chinese Intelligent Systems Conference. Lecture Notes in Electrical Engineering (LNEE 705), P590, DOI 10.1007/978-981-15-8450-3_62
   Zhai Y, 2020, COMPUTER VISION ECCV, P594, DOI DOI 10.1007/978-3-030-58571-6_35
   Zhang L, 2021, IEEE T CIRC SYST VID, V31, P1490, DOI 10.1109/TCSVT.2020.3002956
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng MY, 2020, IEEE SENS J, V20, P8062, DOI 10.1109/JSEN.2020.2981719
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhipu Liu, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P4289, DOI 10.1145/3394171.3413689
   Zhong C., J ARTIF INTELL TECHN, V1, P110
   Zhong Z., 2020, IEEE T PATTERN ANAL
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
   Zhu ZQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163104
   Zhu ZQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132432
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 71
TC 18
Z9 18
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103303
DI 10.1016/j.jvcir.2021.103303
EA SEP 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900001
DA 2024-07-18
ER

PT J
AU Lao, GH
   Liu, SL
   Tan, CW
   Wang, Y
   Li, GZ
   Xu, L
   Feng, L
   Wang, FL
AF Lao, Guihong
   Liu, Shenglan
   Tan, Chenwei
   Wang, Yang
   Li, Guangzhe
   Xu, Li
   Feng, Lin
   Wang, Feilong
TI Three Degree Binary Graph and Shortest Edge Clustering for re-ranking in
   multi-feature image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised re-ranking; Image retrieval; Multi-feature fusion; Graph
   learning
ID OBJECT RETRIEVAL; COLOR; REPRESENTATIONS; FUSION; SCALE
AB Graph methods have been widely employed in re-ranking for image retrieval. Although we can effectively find visually similar images through these methods, the ranking lists given by those approaches may contain some candidates which appear to be irrelevant to a query. Most of these candidates fall into two categories: (1) the irrelevant outliers located near to the query images in a graph; and (2) the images from another cluster which close to the query. Therefore, eliminating these two types of images from the ordered retrieval sets is expected to further boost the retrieval precision. In this paper, we build a Three Degree Binary Graph (TDBG) to eliminate the outliers and utilize a set-based greedy algorithm to reduce the influence of adjacent manifolds. Moreover, a multi-feature fusion method is proposed to enhance the retrieval performance further. Experimental results obtained on three public datasets demonstrate the superiority of the proposed approach.
C1 [Liu, Shenglan; Tan, Chenwei; Wang, Yang; Feng, Lin; Wang, Feilong] Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Liaoning, Peoples R China.
   [Lao, Guihong; Li, Guangzhe] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Liaoning, Peoples R China.
   [Xu, Li] Alibaba Inc, Hangzhou, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology;
   Alibaba Group
RP Wang, FL (corresponding author), Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Liaoning, Peoples R China.
EM wangfeilong@dlut.edu.cn
FU National Natural Science Foundation of the People's Republic of China
   [61972064]; National Key Scientific Instrument and Equipment Development
   Project, China [61627808]; Development of Science and Technology of
   Guangdong Province Special Fund Project, China [2016B090910001]; Liao
   Ning Revitalization Talents Program [XLYC1806006]; Dalian Youth Star of
   Science and Technology, China [2019RQ035]
FX This study was funded by National Natural Science Foundation of the
   People's Republic of China (No. 61972064), the National Key Scientific
   Instrument and Equipment Development Project, China (No. 61627808), the
   Development of Science and Technology of Guangdong Province Special Fund
   Project, China Grants (No. 2016B090910001). The Liao Ning Revitalization
   Talents Program (No. XLYC1806006), Dalian Youth Star of Science and
   Technology, China (No. 2019RQ035). All the authors declare that they
   have no conflict of interest.
CR [Anonymous], 2011, Proc. NIPS, DOI DOI 10.1109/TPAMI.2013.57
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai S, 2019, IEEE T PATTERN ANAL, V41, P1213, DOI 10.1109/TPAMI.2018.2828815
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Cai YZ, 2016, J VIS COMMUN IMAGE R, V37, P32, DOI 10.1016/j.jvcir.2015.06.003
   Chen JH, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P443, DOI 10.1145/2671188.2749287
   Christakis N. A., 2009, Connected: The Surprising Power of Our Social Networks and How They Shape Our Lives
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Pedronette DCG, 2019, IEEE T IMAGE PROCESS, V28, P5824, DOI 10.1109/TIP.2019.2920526
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li QL, 2018, PATTERN RECOGN, V84, P39, DOI 10.1016/j.patcog.2018.07.002
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu ZQ, 2017, IEEE T IMAGE PROCESS, V26, P3128, DOI 10.1109/TIP.2017.2660244
   Luo L, 2013, IEEE T MULTIMEDIA, V15, P1174, DOI 10.1109/TMM.2013.2242450
   Mardones T, 2016, J VIS COMMUN IMAGE R, V38, P641, DOI 10.1016/j.jvcir.2016.04.012
   Niwattanakul Suphakit, 2013, IMECS 2013 Proceedings of International Multiconference of Engineers and Computer Scientists, P380
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Voravuthikunchai Winn., 2014, ICMR, P129
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang B, 2012, PATTERN RECOGN, V45, P1569, DOI 10.1016/j.patcog.2011.09.006
   Wang W., 2016, ARXIV PREPRINT ARXIV
   Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [DOI 10.1145/2072298.2072034, 10.1145/2072298.2072034]
   Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111
   Xingwei Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2369, DOI 10.1109/CVPR.2011.5995325
   Yang F, 2015, IEEE WINT CONF APPL, P572, DOI 10.1109/WACV.2015.82
   Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60
   Yu FX, 2011, ELECTRON LETT, V47, P100, DOI 10.1049/el.2010.3232
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zhou Y, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P447, DOI 10.1145/2671188.2749288
NR 49
TC 7
Z9 7
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103282
DI 10.1016/j.jvcir.2021.103282
EA SEP 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900003
DA 2024-07-18
ER

PT J
AU Lee, SH
   Kim, CS
AF Lee, Seon-Ho
   Kim, Chang-Su
TI SAF-Nets: Shape-Adaptive Filter Networks for 3D point cloud processing*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Point cloud processing; Shape-adaptive filter; Deep learning
AB A deep learning framework for 3D point cloud processing is proposed in this work. In a point cloud, local neighborhoods have various shapes, and the semantic meaning of each point is determined within the local shape context. Thus, we propose shape-adaptive filters (SAFs), which are dynamically generated from the distributions of local points. The proposed SAFs can extract robust features against noise or outliers, by employing local shape contexts to suppress them. Also, we develop the SAF-Nets for classification and segmentation using multiple SAF layers. Extensive experimental results demonstrate that the proposed SAF-Nets significantly outperform the state-of-the-art conventional algorithms on several benchmark datasets. Moreover, it is shown that SAFs can improve scene flow estimation performance as well.
C1 [Lee, Seon-Ho; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
C3 Korea University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
EM seonholee@mcl.korea.ac.kr; changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2018R1A2B3003896, NRF-2021R1A4A1031864]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grants funded by the Korea government (MSIT) (No.
   NRF-2018R1A2B3003896 and No. NRF-2021R1A4A1031864) .
CR Atzmon M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201301
   Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939
   Ben-Shabat Y, 2018, IEEE ROBOT AUTOM LET, V3, P3145, DOI 10.1109/LRA.2018.2850061
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Hua BS, 2018, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2018.00109
   Cao K., 2019, CVPR
   Chen C, 2019, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR.2019.00513
   Chen X, 2017, IEEE PHOTON CONF
   Clevert D. A., 2015, FAST ACCURATE DEEP N
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Duan YQ, 2019, PROC CVPR IEEE, P949, DOI 10.1109/CVPR.2019.00104
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Gadelha M, 2018, LECT NOTES COMPUT SC, V11211, P105, DOI 10.1007/978-3-030-01234-2_7
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Han WK, 2020, AAAI CONF ARTIF INTE, V34, P10925
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hieu LC, 2005, ASSEMBLY AUTOM, V25, P284, DOI 10.1108/01445150510626415
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jampani V, 2016, PROC CVPR IEEE, P4452, DOI 10.1109/CVPR.2016.482
   Kingma D. P., 2014, arXiv
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Lang I., 2020, CVPR
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Lee SH, 2019, IEEE ACCESS, V7, P156569, DOI 10.1109/ACCESS.2019.2949785
   Lei H, 2019, PROC CVPR IEEE, P9623, DOI 10.1109/CVPR.2019.00986
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562
   Li GH, 2020, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR42600.2020.00169
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li YZ, 2018, ADV NEUR IN, V31
   Liu XY, 2019, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2019.00062
   Liu YC, 2019, IEEE I CONF COMP VIS, P5238, DOI 10.1109/ICCV.2019.00534
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Milioto A, 2019, IEEE INT C INT ROBOT, P4213, DOI 10.1109/IROS40897.2019.8967762
   Qi C. R., 2017, Advances in neural information processing systems, P5099
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Ronneberger O., 2015, PATTERN RECOGN, V2015, p1505.04597, DOI 10.1007/978-3-319-24574-4_28
   Sankaranarayanan J., 2006, SPBG
   Schwarz B., 2010, Nature Photonics, V4, P429, DOI [DOI 10.1038/NPHOTON.2010.148, 10.1038/nphoton.2010.148, 10.1038/nphoton.2010.14]
   Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu BC, 2019, IEEE INT CONF ROBOT, P4376, DOI [10.1109/ICRA.2019.8793495, 10.1109/icra.2019.8793495]
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu Y, 2018, ADV SOC SCI EDUC HUM, V284, P87
   Yang JC, 2019, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2019.00344
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   You Y, 2020, AAAI CONF ARTIF INTE, V34, P12717
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
   Zreik M, 2016, I S BIOMED IMAGING, P40, DOI 10.1109/ISBI.2016.7493206
NR 71
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103246
DI 10.1016/j.jvcir.2021.103246
EA AUG 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800005
DA 2024-07-18
ER

PT J
AU Wu, ZJ
   Li, J
   Xu, JH
   Yang, WK
AF Wu, Zhijian
   Li, Jun
   Xu, Jianhua
   Yang, Wankou
TI Beyond ITQ: Efficient binary multi-view subspace learning for instance
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Instance retrieval; Multi-view fusion; Hamming subspace; Unsupervised
   learning
ID IMAGE; FEATURES
AB The existing hashing methods mainly handle either the feature based nearest-neighbor search or the category level image retrieval, whereas a few efforts are devoted to instance retrieval problem. In this paper, we propose a binary multi-view fusion framework for directly recovering a latent Hamming subspace from the multi view features for instance retrieval. More specifically, the multi-view subspace reconstruction and the binary quantization are integrated in a unified framework so as to minimize the discrepancy between the original multi-view high-dimensional Euclidean space and the resulting compact Hamming subspace. Besides, our method is essentially an unsupervised learning scheme without any labeled data involved, and thus can be used in the cases when the supervised information is unavailable or insufficient. Experiments on public benchmark and large-scale datasets reveal that our method achieves competitive retrieval performance comparable to the state-of-the-arts and has excellent scalability in large-scale scenario.
C1 [Wu, Zhijian; Li, Jun; Xu, Jianhua] Nanjing Normal Univ, Sch Comp & Elect Informat, Nanjing 210023, Peoples R China.
   [Yang, Wankou] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
C3 Nanjing Normal University; Southeast University - China
RP Li, J (corresponding author), Nanjing Normal Univ, Sch Comp & Elect Informat, Nanjing 210023, Peoples R China.
EM 192235022@njnu.edu.cn; lijuncst@njnu.edu.cn; xujianhua@njnu.edu.cn;
   wkyang@seu.edu.cn
RI zheng, yi/JOZ-7204-2023; wang, qiang/IZW-1751-2023; Yang,
   Bo/JTS-4309-2023; wu, zhi/GXH-3041-2022
OI Li, Jun/0000-0002-9781-8954
FU National Natural Science Foundation of China [61703096, 61773117];
   Natural Science Foundation of Jiangsu Province, China [BK20170691]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61703096, 61773117 and the Natural Science Foundation
   of Jiangsu Province, China under Grant BK20170691.
CR Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bandara R., 2020, VISUAL COMPUT
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li J, 2021, VISUAL COMPUT, V37, P619, DOI 10.1007/s00371-020-01828-2
   Li J, 2019, IEEE T KNOWL DATA EN, V31, P2393, DOI 10.1109/TKDE.2018.2876834
   Li J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P486, DOI 10.1109/ROBIO.2018.8665207
   Li J, 2016, NEUROCOMPUTING, V207, P202, DOI 10.1016/j.neucom.2016.04.047
   Li WJ, 2016, IJCAI, P1711
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin K, 2019, IEEE T PATTERN ANAL, V41, P1501, DOI 10.1109/TPAMI.2018.2833865
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu XL, 2015, IEEE I CONF COMP VIS, P1107, DOI 10.1109/ICCV.2015.132
   Liu Z, 2016, IEEE T CIRC SYST VID, V26, P375, DOI 10.1109/TCSVT.2015.2409693
   Nister David, 2006, CVPR
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shen XB, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178119
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   Simonyan K., 2014, CORR
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Tang C, 2022, IEEE T KNOWL DATA EN, V34, P4705, DOI 10.1109/TKDE.2020.3048678
   Tang C, 2020, IEEE T KNOWL DATA EN, V32, P1747, DOI 10.1109/TKDE.2019.2911946
   Do TT, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3314051
   Tolias G., 2015, ARXIV151105879
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang Jun., 2010, ICML, P1127
   Wu Z., 2020, ICONIP, P59
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xie LX, 2016, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2016.36
   Yu FX, 2014, PR MACH LEARN RES, V32, P946
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zhou WG, 2018, IEEE T PATTERN ANAL, V40, P1154, DOI 10.1109/TPAMI.2017.2676779
   Zhu L, 2020, IEEE T IMAGE PROCESS, V29, P4643, DOI 10.1109/TIP.2020.2974065
NR 68
TC 2
Z9 2
U1 4
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103234
DI 10.1016/j.jvcir.2021.103234
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100004
DA 2024-07-18
ER

PT J
AU Khatib, R
   Simon, D
   Elad, M
AF Khatib, Rajaei
   Simon, Dror
   Elad, Michael
TI Learned Greedy Method (LGM): A novel neural architecture for sparse
   coding and beyond
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Orthogonal Matching Pursuit; Unfolding pursuit
   algorithms; Interpretable image processing architectures; Denoising;
   Deraining
ID IMAGE-RESTORATION; REPRESENTATION; ALGORITHM; GUARANTEES
AB The fields of signal and image processing have been deeply influenced by the introduction of deep neural networks. Despite their impressive success, the architectures used in these solutions come with no clear justification, being "black box'' machines that lack interpretability. A constructive remedy to this drawback is a systematic design of networks by unfolding well-understood iterative algorithms. A popular representative of this approach is LISTA, evaluating sparse representations of processed signals. In this paper, we revisit this task and propose an unfolded version of a greedy pursuit algorithm for the same goal. More specifically, we concentrate on the well-known OMP algorithm, and introduce its unfolded and learned version. Key features of our Learned Greedy Method (LGM) are the ability to accommodate a dynamic number of unfolded layers, and a stopping mechanism based on representation error. We develop several variants of the proposed LGM architecture and demonstrate their flexibility and efficiency.
C1 [Khatib, Rajaei; Simon, Dror; Elad, Michael] Technion, Comp Sci Dept, IL-3200003 Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Khatib, R (corresponding author), Technion, Comp Sci Dept, IL-3200003 Haifa, Israel.
EM rajaee95@technion.ac.il; dror.simon@cs.technion.ac.il;
   elad@cs.technion.ac.il
RI , Miki/AAH-4640-2019
OI Simon, Dror/0000-0002-9056-2933; Khatib, Rajaei/0000-0002-1376-1840
FU Israel Science Foundation (ISF) [335/18]; Technion Hiroshi Fujiwara
   Cyber Security Research Center; Israel Cyber Bureau
FX This research was partially supported by the Israel Science Foundation
   (ISF) under Grant 335/18 and the Technion Hiroshi Fujiwara Cyber
   Security Research Center and the Israel Cyber Bureau.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2008, TECHNION
   [Anonymous], 2012, CORTEX
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ben-Haim Z, 2010, IEEE T SIGNAL PROCES, V58, P5030, DOI 10.1109/TSP.2010.2052460
   Chen XH, 2018, ADV NEUR IN, V31
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   De-An Huang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P164, DOI 10.1109/ICME.2012.92
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Giryes R, 2014, IEEE IMAGE PROC, P2839, DOI 10.1109/ICIP.2014.7025574
   Gregor K., 2010, P 27 INT C INT C MAC, P399
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Horev I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P592
   Huang B, 2014, IEEE T GEOSCI REMOTE, V52, P1693, DOI 10.1109/TGRS.2013.2253612
   King DB, 2015, ACS SYM SER, V1214, P1
   Lecouat B., 2019, ARXIV PREPRINT ARXIV
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Li YL, 2020, IEEE T COMPUT IMAG, V6, P666, DOI 10.1109/TCI.2020.2964202
   Liu J., 2019, P INT C LEARNING REP, P1
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mairal J., 2007, 2007 IEEE INT C IM P 2007 IEEE INT C IM P, V3
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Milanfar P, 2020, P IEEECVF C COMPUTER, P524
   Monga V., 2019, ARXIV PREPRINT ARXIV
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Niknejad M, 2015, IEEE T IMAGE PROCESS, V24, P3624, DOI 10.1109/TIP.2015.2447836
   Papyan V, 2017, IEEE T SIGNAL PROCES, V65, P5687, DOI 10.1109/TSP.2017.2733447
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Petersen K. B., 2012, MATRIX COOKBOOK
   Pfister Luke, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6914, DOI 10.1109/ICASSP.2014.6854940
   Plaut E, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6847, DOI 10.1109/ICASSP.2018.8461543
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Romano Y, 2017, SIAM J IMAGING SCI, V10, P1804, DOI 10.1137/16M1102884
   Scetbon M., 2019, ARXIV PREPRINT ARXIV
   Simon D., 2019, Advances in Neural Information Processing Systems, P2274
   Sreter H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2191, DOI 10.1109/ICASSP.2018.8462313
   Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yavneh I., 2008, 4 WORLD C IASC
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 62
TC 7
Z9 7
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
DI 10.1016/j.jvcir.2021.103095
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Niu, P
   Wang, C
   Chen, W
   Yang, H
   Wang, X
AF Niu, P.
   Wang, C.
   Chen, W.
   Yang, H.
   Wang, X.
TI Fast and effective Keypoint-based image copy-move forgery detection
   using complex-valued moment invariants
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move forgery detection; Complex-valued moment invariants;
   Magnitude-phase hierarchical matching; Adaptive clustering; Gaussian
   weighted similarity measure; Two-stage false matches filtering
ID DIGITAL IMAGES; LOCALIZATION
AB Copy-move forgery is one of the most common image tampering schemes, with the potential use for misleading the opinion of the general public. Keypoint-based detection methods exhibit remarkable performance in terms of computational cost and robustness. However, these methods are difficult to effectively deal with the cases when 1) forgery only involves small or smooth regions, 2) multiple clones are conducted or 3) duplicated regions undergo geometric transformations or signal corruptions. To overcome such limitations, we propose a fast and accurate copy-move forgery detection algorithm, based on complex-valued invariant features. First, dense and uniform keypoints are extracted from the whole image, even in small and smooth regions. Then, these keypoints are represented by robust and discriminative moment invariants, where a novel fast algorithm is designed especially for the computation of dense keypoint features. Next, an effective magnitude-phase hierarchical matching strategy is proposed for fast matching a massive number of keypoints while maintaining the accuracy. Finally, a reliable post-processing algorithm is developed, which can simultaneously reduce false negative rate and false positive rate. Extensive experimental results demonstrate the superior performance of our proposed scheme compared with existing state-of-the-art algorithms, with average pixel-level F-measure of 94.54% and average CPU-time of 36.25 s on four publicly available datasets.
C1 [Niu, P.; Wang, C.; Chen, W.; Yang, H.; Wang, X.] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Yang, H; Wang, X (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM yhy_65@126.com; wxy37@126.com
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019ZD0468]; China Postdoctoral Science Foundation [2017M621135,
   2018T110220]; Highlevel Innovation Talents Foundation of Dalian
   [2017RQ055]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212) , Key Scientific Research
   Project of Liaoning Provincial Education Department (No. LZ2019001) ,
   Natural Science Foundation of Liaoning Province (No. 2019ZD0468) , China
   Postdoctoral Science Foundation (Nos. 2017M621135 & 2018T110220) , and
   Highlevel Innovation Talents Foundation of Dalian (No. 2017RQ055) .
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2015, INT C AC SPEECH SIGN
   [Anonymous], 2017, 2017 INT C COMP COMM, DOI DOI 10.1109/ICCUBEA.2017.8463695
   [Anonymous], 2010, IEEE T INF FOREN SEC, DOI DOI 10.1109/TIFS.2010.2078506
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen BJ, 2018, IEEE ACCESS, V6, P56637, DOI 10.1109/ACCESS.2018.2871952
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dixit R, 2017, IET IMAGE PROCESS, V11, P746, DOI 10.1049/iet-ipr.2016.0322
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hilal A, 2017, 2017 SENS NETW SMART, P1
   Hoang T. T., 2011, THESIS
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Kalsi DK, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P284, DOI 10.1109/RISE.2017.8378168
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muzaffer G., 2017, P INT ARTIFICIAL INT, P1
   Muzaffer G, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P595, DOI 10.1109/TSP.2017.8076056
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shahroudnejad A, 2016, 2016 2ND INTERNATIONAL CONFERENCE OF SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P149, DOI 10.1109/ICSPIS.2016.7869896
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Teerakanok S, 2018, P INT COMP SOFTW APP, P365, DOI 10.1109/COMPSAC.2018.10259
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P2311, DOI 10.1007/s11042-018-6354-1
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Wang Y, 2017, IEEE INT SYM MULTIM, P553, DOI 10.1109/ISM.2017.108
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang HY, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107177
   Yuan J, 2007, PROC CVPR IEEE, P1930, DOI 10.1109/CVPR.2007.383222
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
NR 52
TC 24
Z9 24
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103068
DI 10.1016/j.jvcir.2021.103068
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SF9SQ
UT WOS:000653087000002
DA 2024-07-18
ER

PT J
AU Tagore, NK
   Singh, A
   Manche, S
   Chattopadhyay, P
AF Tagore, Nirbhay Kumar
   Singh, Ayushman
   Manche, Sumanth
   Chattopadhyay, Pratik
TI Person re-identification from appearance cues and deep Siamese features?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hierarchical re-identification approach; Color-based clustering;
   Silhouette part-based analysis; Siamese Convolution Box; IIT(BHU)
   re-identification data set
AB Automated person re-identification in a multi-camera surveillance setup is very important for effective tracking and monitoring crowd movement. In this paper, we propose an efficient hierarchical re-identification approach in which color histogram-based comparison is employed to find the closest matches in the gallery set, and next deep feature-based comparison is carried out using the Siamese network. Reduction in search space after the first level of matching helps in improving the accuracy as well as efficiency of prediction by the Siamese network by eliminating dissimilar elements. A silhouette part-based feature extraction scheme is adopted in each level of hierarchy to preserve the relative locations of the different body parts and make the appearance descriptors more discriminating. The proposed approach has been evaluated on five public data sets and also a new data set captured in our laboratory. Results reveal that it outperforms most state-of-the-art approaches in terms of overall accuracy.
C1 [Tagore, Nirbhay Kumar; Manche, Sumanth; Chattopadhyay, Pratik] Banaras Hindu Univ, Comp Sci & Engn Dept, Pattern Recognit Lab, Indian Inst Technol, Varanasi, Uttar Pradesh, India.
   [Singh, Ayushman] Banaras Hindu Univ, Mech Engn Dept, Indian Inst Technol, Varanasi, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi); Indian Institute of Technology System (IIT System); Indian
   Institute of Technology BHU Varanasi (IIT BHU Varanasi); Banaras Hindu
   University (BHU)
RP Chattopadhyay, P (corresponding author), Banaras Hindu Univ, Comp Sci & Engn Dept, Pattern Recognit Lab, Indian Inst Technol, Varanasi, Uttar Pradesh, India.
EM nirbhaykrtag.rs.cse17@itbhu.ac.in; ayushman.singh.mec16@itbhu.ac.in;
   manche.sumanth.cse16@itbhu.ac.in; pratik.cse@iitbhu.ac.in
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2006, P BRIT MACH VIS C
   [Anonymous], 2007, P IEEE INT WORKSH PE
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chattopadhyay P, 2015, IET IMAGE PROCESS, V9, P969, DOI 10.1049/iet-ipr.2014.0773
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   Javed O, 2005, PROC CVPR IEEE, P26
   Kang JM, 2004, INT C PATT RECOG, P759, DOI 10.1109/ICPR.2004.1333883
   King DB, 2015, ACS SYM SER, V1214, P1
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Lin J, 2017, PROC CVPR IEEE, P3396, DOI 10.1109/CVPR.2017.362
   Luo B., 2018, IEEE T SYSTEMS MAN C P IEEE 4 INT C MULT, P1
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Subramaniam A, 2016, ADV NEUR IN, V29
   Tu PH, 2007, PROC SPIE, V6562, DOI 10.1117/12.729215
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhou JH, 2018, PROC CVPR IEEE, P5373, DOI 10.1109/CVPR.2018.00563
NR 42
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103029
DI 10.1016/j.jvcir.2021.103029
EA JAN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BY
UT WOS:000633494500004
DA 2024-07-18
ER

PT J
AU Ongun, MF
   Güdükbay, U
   Aksoy, S
AF Ongun, Mehmet Faruk
   Gueduekbay, Ugur
   Aksoy, Selim
TI Recognition of occupational therapy exercises and detection of
   compensation mistakes for Cerebral Palsy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gesture recognition; Cerebral palsy; Occupational therapy; Compensation
   mistake; Hidden Markov model; Virtual rehabilitation
ID HAND-GESTURE RECOGNITION; HUMAN-COMPUTER INTERACTION; HIDDEN
   MARKOV-MODELS; CLASSIFICATION-SYSTEM; REHABILITATION; CHILDREN; MOTION;
   HMM
AB Depth camera-based virtual rehabilitation systems are gaining attention in occupational therapy for cerebral palsy patients. When developing such a system, domain-specific exercise recognition is vital. To design such a gesture recognition method, some obstacles need to be overcome: detection of gestures not related to the defined exercise set and recognition of incorrect exercises performed by the patients to compensate for their lack of ability. We propose a framework based on hidden Markov models for the recognition of upper extremity functional exercises. We determine critical compensation mistakes together with restrictions for classifying these mistakes with the help of occupational therapists. We first eliminate undefined gestures by evaluating two models that produce adaptive threshold values. Then we utilize specific negative models based on feature thresholding and train them for each exercise to detect compensation mistakes. We perform various tests using our method in a laboratory environment under the supervision of occupational therapists.
C1 [Ongun, Mehmet Faruk; Gueduekbay, Ugur; Aksoy, Selim] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM mehmet.ongun@bilkent.edu.tr; gudukbay@cs.bilkent.edu.tr;
   saksoy@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011
OI Gudukbay, Ugur/0000-0003-2462-6959
CR Ar I, 2014, IEEE T NEUR SYS REH, V22, P1160, DOI 10.1109/TNSRE.2014.2326254
   Argyros A, 2009, UNIVERSAL ACCESS HDB, P341
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Barros P, 2017, COMPUT VIS IMAGE UND, V155, P139, DOI 10.1016/j.cviu.2016.10.006
   Bax M, 2005, DEV MED CHILD NEUROL, V47, P571, DOI 10.1017/S001216220500112X
   Binh N.D., 2005, Proceedings of International Conference on Graphics, Vision and Image Processing GVIP-05, P362
   Biswas K. K., 2011, 2011 5th International Conference on Automation, Robotics and Applications (ICARA 2011), P100, DOI 10.1109/ICARA.2011.6144864
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Calin AD, 2016, INT SYMP SYMB NUMERI, P264, DOI [10.1109/SYNASC.2016.43, 10.1109/SYNASC.2016.049]
   Campbell LW, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P157, DOI 10.1109/AFGR.1996.557258
   Chang YJ, 2013, RES DEV DISABIL, V34, P3654, DOI 10.1016/j.ridd.2013.08.021
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dennemont Y, 2012, INT CONF IMAG PROC, P299, DOI 10.1109/IPTA.2012.6469509
   Devineau G, 2018, IEEE INT CONF AUTOMA, P106, DOI 10.1109/FG.2018.00025
   Eliasson AC, 2006, DEV MED CHILD NEUROL, V48, P549, DOI 10.1017/S0012162206001162
   Sucar LE, 2010, IEEE ENG MED BIO, P3690, DOI 10.1109/IEMBS.2010.5627458
   Ertunc HM, 2001, INT J MACH TOOL MANU, V41, P1363, DOI 10.1016/S0890-6955(00)00112-7
   Ghodsi S, 2018, J VIS COMMUN IMAGE R, V55, P729, DOI 10.1016/j.jvcir.2018.08.001
   Granger N, 2017, LECT NOTES COMPUT SC, V10635, P147, DOI 10.1007/978-3-319-70096-0_16
   Hu MC, 2015, IEEE T CYBERNETICS, V45, P742, DOI 10.1109/TCYB.2014.2335540
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Lefebvre G, 2015, ARTIFICIAL NEURAL NETWORKS, P393, DOI 10.1007/978-3-319-09903-3_19
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liang CW, 2018, IEEE T CIRC SYST VID, V28, P2920, DOI 10.1109/TCSVT.2017.2715045
   Lin JFS, 2014, IEEE T NEUR SYS REH, V22, P168, DOI 10.1109/TNSRE.2013.2259640
   Maqueda AI, 2015, COMPUT VIS IMAGE UND, V141, P126, DOI 10.1016/j.cviu.2015.07.009
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Morris C, 2004, DEV MED CHILD NEUROL, V46, P60, DOI 10.1017/S0012162204000118
   Mutsaarts M, 2005, MOTOR CONTROL, V9, P439, DOI 10.1123/mcj.9.4.439
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pedraza-Hueso M, 2015, PROCEDIA COMPUT SCI, V75, P161, DOI 10.1016/j.procs.2015.12.233
   Pérez-Muñoz A, 2018, PROCEEDINGS OF THE 2018 IEEE 25TH INTERNATIONAL CONFERENCE ON ELECTRONICS, ELECTRICAL ENGINEERING AND COMPUTING (INTERCON 2018)
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reid LB, 2015, NAT REV NEUROL, V11, P390, DOI 10.1038/nrneurol.2015.97
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Saleh A, 2018, PATTERN RECOGN LETT, V105, P4, DOI 10.1016/j.patrec.2017.06.010
   Schultz-Krohn W., 2013, FACTSBOOK
   Sempena Samsu., 2011, P INT C EL ENG INF, P1, DOI DOI 10.1109/ICEEI.2011.6021605
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Thomas J.A, 2001, ELEMENTS INFORM THEO, P12
   Uddin MZ, 2010, IEEE IMAGE PROC, P713, DOI 10.1109/ICIP.2010.5651953
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang HJ, 2013, J VIS COMMUN IMAGE R, V24, P1458, DOI 10.1016/j.jvcir.2013.10.004
   Webster D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-108
   Wu D, 2013, IEEE T CIRC SYST VID, V23, P236, DOI 10.1109/TCSVT.2012.2203731
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang Z, 2012, INT CONF COMP SCI ED, P360, DOI 10.1109/ICCSE.2012.6295092
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Ye M., 2013, LECT NOTES COMPUTER, P149, DOI [10.1007/978-3-642-44964-2_8, DOI 10.1007/978-3-642-44964-2_8]
   Youngstrom MJ, 2002, AM J OCCUP THER, V56, P609
   Yu WT, 2004, IEEE INT CONF ROBOT, P2074
   Zhang L, 2018, IEEE T CIRC SYST VID, V28, P2562, DOI 10.1109/TCSVT.2017.2721108
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
NR 63
TC 3
Z9 3
U1 3
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102970
DI 10.1016/j.jvcir.2020.102970
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA PE7QO
UT WOS:000598558100003
DA 2024-07-18
ER

PT J
AU Hu, T
   Liang, C
   Min, GY
   Li, KQ
   Xiao, CX
AF Hu, Tao
   Liang, Chao
   Min, Geyong
   Li, Keqin
   Xiao, Chunxia
TI Generating video animation from single still image in social media based
   on intelligent computing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Animation; Convolutional neural network; Image motion analysis; Shape
   context; Stochastic motion texture
AB Bringing a single still image into reality is a challenging topic in computer animation because the driven and structural information in single still image is inadequate. In this paper, we present an image animating method for enhancing single still image in social media with virtual realistic and animated motions without prior information. We imitate the interaction between the active objects in an image and their neighboring passive objects. The existing actions in the image and the virtual specified force are employed to animate the active objects. Observing that the change between two subsequent motions of the active objects derives a motion tendency, we can calculate a virtual driving force based on the motion tendency. By virtue of the virtual driving force, the stochastic motion texture is used to animate the passive objects. Finally, the convolutional neural network is employed to optimize the virtual motion animations. In this way, the proposed method produces visually natural results while guaranteeing motion harmony between active objects and passive objects. To demonstrate the applicability and rationality of virtual animation driving force, our method generates several animations from still images in Social Media. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Hu, Tao; Liang, Chao; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Hu, Tao] Hubei Minzu Univ, Sch Informat Engn, Enshi 445000, Hubei, Peoples R China.
   [Min, Geyong] Univ Exeter, Coll Engn Math & Phys Sci, Exeter EX4 4QF, Devon, England.
   [Li, Keqin] SUNY Coll New Paltz, Dept Comp Sci, New Paltz, NY 12561 USA.
C3 Wuhan University; Hubei Minzu University; University of Exeter; State
   University of New York (SUNY) System; SUNY New Paltz
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
EM cliang@whu.edu.cn; g.min@exeter.ac.uk; lik@newpaltz.edu;
   cxxiao@whu.edu.cn
OI hu, tao/0009-0002-6661-2723
FU Key Technological Innovation Projects of Hubei Province [2018AAA062];
   Wuhan Science and Technology Plan Project [2017010201010109]; National
   Key Research and Development Program of China [2017YFB1002600]; National
   Natural Science Foundation of China [61672390, 61562025, 61972298,
   61962019]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This work was supported by The Key Technological
   Innovation Projects of Hubei Province under Grants 2018AAA062, and Wuhan
   Science and Technology Plan Project under Grant 2017010201010109, and
   The National Key Research and Development Program of China under Grant
   2017YFB1002600, and National Natural Science Foundation of China under
   Grants 61672390, 61562025, 61972298, 61962019.
CR Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Chen K, 2015, PROCEEDINGS - I3D 2015, P69, DOI 10.1145/2699276.2699281
   Chen PS, 2015, IEEE INT CON MULTI
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Ding B, 2019, IEEE I CONF COMP VIS, P10212, DOI 10.1109/ICCV.2019.01031
   Jain E, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077349
   Jain Eakta., 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symp. on Computer Animation, P93
   Jhou WC, 2016, IEEE T MULTIMEDIA, V18, P4, DOI 10.1109/TMM.2015.2500031
   Joshi D.W. Neil, 2017, DEEP MOTION CONVOLUT
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Liu XM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2294543
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Nie YW, 2014, IEEE T VIS COMPUT GR, V20, P1303, DOI 10.1109/TVCG.2013.2297931
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Okabe M, 2011, COMPUT GRAPH FORUM, V30, P1973, DOI 10.1111/j.1467-8659.2011.02062.x
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Sun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P96
   Tang NC, 2014, IEEE T MULTIMEDIA, V16, P47, DOI 10.1109/TMM.2013.2283844
   White B.Y., 1984, COGNITION INSTRUCT, V1, P69
   Xiao CX, 2014, IEEE T CIRC SYST VID, V24, P49, DOI 10.1109/TCSVT.2013.2276153
   Xu Z, 2016, IEEE T CIRC SYST VID, V26, P1393, DOI 10.1109/TCSVT.2015.2437111
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Zachevsky I, 2016, IEEE T IMAGE PROCESS, V25, P2130, DOI 10.1109/TIP.2016.2539689
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zilman G, 2015, IEEE T GEOSCI REMOTE, V53, P609, DOI 10.1109/TGRS.2014.2326519
NR 30
TC 2
Z9 2
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102812
DI 10.1016/j.jvcir.2020.102812
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400005
DA 2024-07-18
ER

PT J
AU Lu, WP
   Zhang, X
   Lu, HM
   Li, FF
AF Lu, Wenpeng
   Zhang, Xu
   Lu, Huimin
   Li, Fangfang
TI Deep hierarchical encoding model for sentence semantic matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hierarchical encoding model; Hierarchical measure mechanism; Sentence
   similarity; Semantic equivalence identification; Text representation
ID SPARSE
AB Sentence semantic matching (SSM) always plays a critical role in natural language processing. Measuring the intrinsic semantic similarity among sentences is very challenging and has not been substantially addressed. The latest SSM research usually relies on a shallow text representation and interaction between sentence pairs, which might not be enough to capture the complex semantic features and lead to limited performance. To capture more semantic context features and interactions, we propose a hierarchical encoding model (HEM) for sentence representation, further enhanced by a hierarchical matching mechanism for sentence interaction. Given two sentences, HEM generates intermediate and final representations in encoding layer, which are further handled by a novel hierarchical matching mechanism to capture more multi-view interactions in matching layer. The comprehensive experiments demonstrate that our model is capable to capture more sentence semantic features and interactions, which significantly outperforms the existing state-of-the-art neural models on the public real-world dataset. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Lu, Wenpeng; Zhang, Xu] Qilu Univ Technol, Sch Comp Sci & Technol, Shandong Acad Sci, Jinan 250014, Peoples R China.
   [Lu, Huimin] Kyushu Inst Technol, Kitakyushu, Fukuoka 8048550, Japan.
   [Li, Fangfang] Ooh Media, Sydney, NSW 2060, Australia.
C3 Qilu University of Technology; Kyushu Institute of Technology
RP Lu, WP (corresponding author), Qilu Univ Technol, Sch Comp Sci & Technol, Shandong Acad Sci, Jinan 250014, Peoples R China.
EM Wenpeng.Lu@qlu.edu.cn; Xuzhang.p@foxmail.com; Dr.Huimin.Lu@ieee.org;
   Fangfang.Li@oohmedia.com.au
OI Zhang, Xu/0000-0002-9294-2841; Lu, Wenpeng/0000-0002-1840-3540
FU National Nature Science Foundation of China [61502259]; National Key
   Research and Development Program of China [2018YFC0831700]; Taishan
   Scholar Program of Shandong Province in China
FX The research work is supported by National Nature Science Foundation of
   China under Grant No. 61502259, National Key Research and Development
   Program of China under Grant No. 2018YFC0831700, and Taishan Scholar
   Program of Shandong Province in China (Directed by Prof. Yinglong Wang).
CR [Anonymous], 2014, Advances in Neural Information Processing Systems
   [Anonymous], 2014, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   [Anonymous], 2017, P 26 INT C WORLD, DOI [10.1145/3038912.3052579, DOI 10.1145/3038912.3052579]
   Bai S., 2018, EMPIRICAL EVALUATION
   Chen J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4946
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   De Boom C, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1229, DOI 10.1109/ICDMW.2015.86
   Denil M., 2014, ARXIV14063830
   Duan CQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4033
   Gong Y., 2017, ARXIV170904348
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Johnson R., 2016, INT C MACHINE LEARNI, P526
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Lan RS, 2019, APPL SOFT COMPUT, V74, P693, DOI 10.1016/j.asoc.2018.08.049
   Lan RS, 2020, IEEE T CYBERNETICS, V50, P1498, DOI 10.1109/TCYB.2018.2880290
   Liu Y., 2016, CoRR
   Liu ZH, 2019, NEUROCOMPUTING, V362, P129, DOI 10.1016/j.neucom.2019.06.073
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu WP, 2019, CMC-COMPUT MATER CON, V61, P197, DOI 10.32604/cmc.2019.06068
   Lu WP, 2019, CLUSTER COMPUT, V22, pS7549, DOI 10.1007/s10586-018-1899-3
   Lu WP, 2018, IEICE T INF SYST, VE101D, P225, DOI 10.1587/transinf.2017EDP7090
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Meng F, 2018, J QILU U TECHNOLOGY, V32, P66
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mueller J, 2016, AAAI CONF ARTIF INTE, P2786
   [庞亮 Pang Liang], 2017, [计算机学报, Chinese Journal of Computers], V40, P985
   Pang L, 2016, AAAI CONF ARTIF INTE, P2793
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rus V., 2008, FLAIRS conference, P201
   Wan SX, 2016, AAAI CONF ARTIF INTE, P2835
   Wang CL, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2061, DOI 10.1145/3097983.3098140
   Wang SJ, 2018, AAAI CONF ARTIF INTE, P2532
   Wang Z., 2016, P COLING 2016 26 INT
   Wang Z, 2017, IEEE IJCNN, P1411, DOI 10.1109/IJCNN.2017.7966018
   Wu H., 2017, P 11 INT WORKSH SEM, P77
   Xia L, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2911451.2911498
   Xiang LY, 2019, NEURAL PROCESS LETT, V49, P1055, DOI 10.1007/s11063-018-9892-7
   Xu X., 2019, IEEE T CYBERN, V77, P21847
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yin W., 2016, Transactions of the Association for computational linguistics, V4, P259, DOI [DOI 10.1162/TACL_A_00097, DOI 10.1162/TACLA00244, 10.1162/tacla00097, DOI 10.1162/TACLA00097]
   Yin W., 2018, Trans. Assoc. Comput. Linguistics, V6, P687, DOI 10.1162/tacl_a_00249.
   Zeng DJ, 2019, J INTELL FUZZY SYST, V36, P3971, DOI 10.3233/JIFS-169958
   Zhang X., 2020, P 24 PAC AS C KNOWL
   Zhang X, 2019, CMC-COMPUT MATER CON, V61, P601, DOI 10.32604/cmc.2019.06045
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
   Zhou Q, 2016, PATTERN RECOGN, V59, P312, DOI 10.1016/j.patcog.2016.03.023
NR 49
TC 47
Z9 49
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102794
DI 10.1016/j.jvcir.2020.102794
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400004
DA 2024-07-18
ER

PT J
AU Gui, B
   Zhu, YH
   Zhen, T
AF Gui, Bian
   Zhu, Yuhua
   Zhen, Tong
TI Adaptive single image dehazing method based on support vector machine
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SVM; Adaptive dehazing; Automatic binary classification; Quality
   evaluation index
ID QUALITY ASSESSMENT; VISIBILITY
AB A dehazing method often only shows good results when processing the image for a certain haze concentration. So an adaptive hazy image dehazing method based on SVM is proposed. The innovation points are as follows: Firstly, combining the characteristics of the degraded images of haze weather, the dark channel histogram and texture features of the input images are extracted to form the feature vectors. These are trained by supervised learning through SVM algorithm to realize automatic binary classification of images; Secondly, the defined dehazing methods are called to process the classified result as a hazy image and the same quality evaluation indexes are used to evaluate each image output by different dehazing methods. Then, it outputs the highest evaluation image after haze removal. Finally, the output image is classified again by SVM until the image reaches the clearest it can be. The experimental results show that the proposed algorithm exhibits good contrast, brightness and color saturation from the visual effect. Also the scene adaptability and robustness of the algorithm are improved. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Gui, Bian; Zhen, Tong] Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
   [Zhu, Yuhua] Yellow River Conservancy Tech Inst, Kaifeng 475000, Peoples R China.
C3 Henan University of Technology; Yellow River Conservancy Technical
   Institute
RP Zhen, T (corresponding author), Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
EM 1752011658@qq.com
FU National Key Research and Development Project [2017YFD0401004]; Open
   Fund of Key Laboratory of Grain Information Processing and Control(Henan
   University of Technology),Ministy of Education [KFJJ-2016-103]
FX This work was supported by National Key Research and Development Project
   (No: 2017YFD0401004). Open Fund of Key Laboratory of Grain Information
   Processing and Control(Henan University of Technology),Ministy of
   Education(KFJJ-2016-103).
CR Al Bataineh A, 2019, INT J ADV COMPUT SC, V10, P5
   Bala J, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919500568
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Ji WP, 2019, J VIS COMMUN IMAGE R, V58, P195, DOI 10.1016/j.jvcir.2018.11.038
   Kaur M, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919500222
   Khosravi MH, 2019, J VIS COMMUN IMAGE R, V60, P217, DOI 10.1016/j.jvcir.2018.11.019
   Khosravi MH, 2019, APPL INTELL, V49, P1172, DOI 10.1007/s10489-018-1313-0
   Khosravi MH, 2018, MULTIMED TOOLS APPL, V77, P7357, DOI 10.1007/s11042-017-4636-7
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Luan Zhong, 2018, Journal of Southeast University (Natural Science Edition), V48, P25, DOI 10.3969/j.issn.1001-0505.2018.01.005
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Pannu HS, 2018, CLEAN-SOIL AIR WATER, V46, DOI 10.1002/clen.201700162
   Pannu HS, 2019, NEURAL COMPUT APPL, V31, P2195, DOI 10.1007/s00521-017-3181-7
   Singh D., 2018, ARCH COMPUT METHOD E
   Singh D, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-017-9433-4
   Singh D, 2019, SIGNAL PROCESS-IMAGE, V70, P131, DOI 10.1016/j.image.2018.09.011
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P27363, DOI 10.1007/s11042-018-5924-6
   Singh D, 2018, COMPUT ELECTR ENG, V69, P14, DOI 10.1016/j.compeleceng.2018.05.015
   Singh D, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013004
   Singh D, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918500513
   Singh D, 2017, IMAGING SCI J, V65, P282, DOI 10.1080/13682199.2017.1329792
   Singh D, 2017, J MOD OPTIC, V64, P2165, DOI 10.1080/09500340.2017.1344736
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   [王萍 WANG Ping], 2006, [计算机应用, Computer Applications], V26, P152
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie FY, 2018, IEEE ACCESS, V6, P67982, DOI 10.1109/ACCESS.2018.2879893
   Xin Z, 2019, J VIS COMMUN IMAGE R, V61, P42, DOI 10.1016/j.jvcir.2019.03.004
   Yu J, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED MECHANICS, MECHATRONICS AND INTELLIGENT SYSTEMS (AMMIS2015), P364
   [翟艺书 ZHAI Yishu], 2007, [大连海事大学学报, Journal of Dalian Maritime University], V33, P55
   [祝培 Zhu Pei], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P124
NR 31
TC 11
Z9 11
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102792
DI 10.1016/j.jvcir.2020.102792
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900010
DA 2024-07-18
ER

PT J
AU Kang, XB
   Zhao, F
   Chen, YJ
   Lin, GF
   Jing, CN
AF Kang, Xiaobing
   Zhao, Fan
   Chen, Yajun
   Lin, Guangfeng
   Jing, Cuining
TI Combining polar harmonic transforms and 2D compound chaotic map for
   distinguishable and robust color image zero-watermarking algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Polar harmonic transforms; Zero-watermarking; Geometric attacks; Chaos
   encryption
ID DIGITAL RIGHTS MANAGEMENT; BLIND WATERMARKING; SCHEME; EXPONENT
AB Although zero-watermarking can provide an effective and distortion-free scheme for image copyright protection, its robustness and discriminability do not meet expectations in existing methods. Some cannot resist effectively geometric attacks, others do not consider the discriminability and equalization. For that reason, this paper proposes a robust and distinguishable color image zero-watermarking algorithm based on polar harmonic transforms (PHTs) and compound chaotic map. In the proposed algorithm, firstly three PHTs moments of an image are computed simultaneously and accurate moments are selected for the robustness. Then, content-based binary feature sequence is acquired by judging the relation between magnitudes of adjacent moments for the discriminability. Finally, compound chaotic map is employed to encrypt copyright logo for ensuring security and scramble binary feature sequence for improving the equalization. Experimental results show that the proposed zero-watermarking algorithm has good equalization and discriminability, and an advantage in robustness compared with other zero-watermarking and traditional watermarking. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Kang, Xiaobing; Zhao, Fan; Chen, Yajun; Lin, Guangfeng; Jing, Cuining] Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Kang, XB (corresponding author), Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
EM kangxb@xaut.edu.cn
RI Lin, Guangfeng/AAA-8654-2021; Lin, Guangfeng/E-4420-2013
OI Lin, Guangfeng/0000-0002-6191-1102; Lin, Guangfeng/0000-0002-6191-1102
FU Scientific Research Program - Education Department of Shaanxi Provincial
   Government [15JK1504]; National Natural Science Foundation of China
   [61671374, 61671376, 61771386]
FX This work was supported by the Scientific Research Program Funded by the
   Education Department of Shaanxi Provincial Government (Program No.
   15JK1504) and the National Natural Science Foundation of China (Grant
   No. 61671374, 61671376, 61771386).
CR Ali Z, 2018, FUTURE GENER COMP SY, V88, P400, DOI 10.1016/j.future.2018.05.058
   Ali Z, 2018, IEEE ACCESS, V6, P7930, DOI 10.1109/ACCESS.2018.2799604
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen H, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P490, DOI 10.1109/ICICEE.2012.136
   Chen L, 2017, SIGNAL PROCESS-IMAGE, V54, P56, DOI 10.1016/j.image.2017.02.011
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Liu F., 2018, J. Inf. Hiding Multimed. Signal Process. C, V9, P629
   Liu XY, 2018, PROC SPIE, V10579, DOI 10.1117/12.2292852
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Liu YZ, 2017, CLUSTER COMPUT, V20, P3667, DOI 10.1007/s10586-017-1251-3
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Sang J, 2006, OPT ENG, V45, DOI 10.1117/1.2354076
   Schmitz R, 2014, INT J MULTIMED DATA, V5, P36, DOI 10.4018/ijmdem.2014100103
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Tsougenis ED, 2013, OPT LASER TECHNOL, V54, P84, DOI 10.1016/j.optlastec.2013.05.004
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Wang XY, 2015, COMPUT ELECTR ENG, V46, P403, DOI 10.1016/j.compeleceng.2015.04.001
   Wang X, 2019, MULTIMED TOOLS APPL, V78, P27001, DOI 10.1007/s11042-017-4666-1
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   [熊祥光 Xiong Xiangguang], 2018, [自动化学报, Acta Automatica Sinica], V44, P160
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zhou WJ, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.080701
   Zou BJ, 2018, MULTIMED TOOLS APPL, V77, P28685, DOI 10.1007/s11042-018-5995-4
NR 34
TC 37
Z9 39
U1 1
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102804
DI 10.1016/j.jvcir.2020.102804
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900018
DA 2024-07-18
ER

PT J
AU Yin, XL
   Lu, W
   Zhang, JH
   Chen, JF
   Liu, WT
AF Yin, Xiaolin
   Lu, Wei
   Zhang, JunHong
   Chen, Jianfei
   Liu, Wanteng
TI Reversible data hiding in binary images by flipping pattern pair with
   opposite center pixel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Binary images; Pattern pair with opposite center
   pixel; Visual quality; Embedding payload
ID WATERMARKING SCHEME; DISTORTION MEASURE; DIFFERENCE; EXPANSION
AB In this paper, a novel RDH scheme by flipping pattern pairs with opposite center pixel (PPOCPs) in binary images is proposed, aiming at decreasing the distortion while increasing the embedding payload. First, 25 patterns in the 3 x 3 block are designed which construct the PPOCPs according to the distance level providing a guarantee for reversibility. Then, a balanced score is designed which considers both visual distortion and embedding payload to select the optimal PPOCP, and the secret messages are embedded in the optimal PPOCP. For the receiver, the secret messages can be extracted precisely and the original binary image can be recovered by scanning the optimal PPOCP. PPOCP is a novel RDH model which fully considers the visual distortion caused by flipping pixels. Experimental results demonstrate the feasibility of the proposed RDH method for binary images, and the visual quality is satisfactory under high embedding payload and smallest pure flipping rate. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Yin, Xiaolin; Lu, Wei; Zhang, JunHong; Liu, Wanteng] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Minist Educ,Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
   [Chen, Jianfei] Digital Guangdong Co Ltd, Dept Informat Secur, Guangzhou 510000, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Minist Educ,Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.; Chen, JF (corresponding author), Digital Guangdong Co Ltd, Dept Informat Secur, Guangzhou 510000, Peoples R China.
EM yinxl6@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   zhangjh65@mail2.sysu.edu.cn; jianfeichen@digitalgd.com.cn;
   liuwt25@mail2.sysu.edu.cn
FU Key Areas R&D Program of Guangdong [2019B010136002]; National Natural
   Science Foundation of China [U1736118]; Key Scientific Research Program
   of Guangzhou [201804020068]; Natural Science Foundation of Guangdong
   [2016A030313350]; Special Funds for Science and Technology Development
   of Guangdong [2016KZ010103]
FX This work is supported by the Key Areas R&D Program of Guangdong (No.
   2019B010136002), the National Natural Science Foundation of China (No.
   U1736118), the Key Scientific Research Program of Guangzhou (No.
   201804020068), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103).
CR Boato G., 2012, J ELECTRON IMAGING, V21, P777
   Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Cheng J, 2007, IEEE T IMAGE PROCESS, V16, P1691, DOI 10.1109/TIP.2007.896619
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   El-sayed HS, 2016, ARAB J SCI ENG, V41, P1091, DOI 10.1007/s13369-015-1956-7
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Guo JM, 2012, DIGIT SIGNAL PROCESS, V22, P776, DOI 10.1016/j.dsp.2012.04.004
   Guorong X., 2008, P 19 INT C PATT REC, P1
   Ho YA, 2009, COMPUT STAND INTER, V31, P787, DOI 10.1016/j.csi.2008.09.014
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Kim C, 2014, INT C CONTR AUTOMAT, P1031, DOI 10.1109/ICCAS.2014.6987942
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Lu W, 2019, IEEE T CIRC SYST VID, V29, P1608, DOI 10.1109/TCSVT.2018.2852702
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai CL, 2005, PATTERN RECOGN, V38, P1993, DOI 10.1016/j.patcog.2005.03.001
   Tuncer T, 2016, J FAC ENG ARCHIT GAZ, V31, P951, DOI 10.17341/gazimmfd.278450
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xue YJ, 2019, J REAL-TIME IMAGE PR, V16, P601, DOI 10.1007/s11554-018-0822-8
   Yang Chyuan-Huei Thomas, 2014, 2014 International Conference on Trustworthy Systems and their Applications, P69, DOI 10.1109/TSA.2014.20
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yeung YL, 2020, IEEE T CIRC SYST VID, V30, P1423, DOI 10.1109/TCSVT.2019.2903432
   Yin XL, 2020, ADV INTELL SYST, V895, P891, DOI 10.1007/978-3-030-16946-6_73
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
NR 42
TC 4
Z9 4
U1 3
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102816
DI 10.1016/j.jvcir.2020.102816
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900021
DA 2024-07-18
ER

PT J
AU Zhu, HP
AF Zhu, Hongpeng
TI Massive-scale image retrieval based on deep visual feature
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Visual feature; DNN
AB This paper proposes an image retrieval algorithm towards massive-scale multimedia data. In order to be consistent with human visual system, we first design a color attention function to describe the important of different image patches. Subsequently, we combine color and texture to construct candidate regions, which will be fed into a deep neural network (DNN) for deep representation extraction. Then, we design a similarity function to calculate the distance among different images, where top-ranking images are considered as the required images. Experimental results show the effectiveness and robustness of our proposed method. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Zhu, Hongpeng] Shaoyang Univ, Shaoyang 422000, Hunan, Peoples R China.
C3 Shaoyang University
RP Zhu, HP (corresponding author), Shaoyang Univ, Shaoyang 422000, Hunan, Peoples R China.
CR [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2013, NIPS
   Cai D., 2007, P 20 INT JOINT C ART
   Chai JY, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1198296.1198299
   Cheng M.M., COMPUTATIONAL VISUAL, P1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Edwardes A.J., 2007, ACM WORKSH GEOGR INF
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howarth P., 2004, 3 INT C CIVR 2004 DU
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Li CC, 2022, IEEE T AFFECT COMPUT, V13, P729, DOI 10.1109/TAFFC.2019.2954394
   Li L.-j., 2010, NIPS
   Li Y., 2019, INVEST CLIN, V60, P1468
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Perez Mendoza, 2019, INVEST CLIN, V60, P1239
   Russakovsky O., 2010, EUR C TRENDS TOP COM
   Schmid C., 2001, IEEE COMP SOC C COMP
   Sharma A, 2012, WOODHEAD PUBL FOOD S, P73
   Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Tollari S., 2009, EXPLOITING VISUAL CO
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Zepeda J., 2015, IEEE C COMP VIS PATT
NR 33
TC 6
Z9 7
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102738
DI 10.1016/j.jvcir.2019.102738
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900002
DA 2024-07-18
ER

PT J
AU Yao, H
   Wei, HB
   Qiao, T
   Qin, C
AF Yao, Heng
   Wei, Hongbin
   Qiao, Tong
   Qin, Chuan
TI JPEG quantization step estimation with coefficient histogram and
   spectrum analyses
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; JPEG compression; Quantization-step estimation;
   Periodicity analysis
ID COMPRESSION HISTORY; MATRIX ESTIMATION
AB This paper proposes a new method for estimating quantization steps (QSs) from an image that has been previously JPEG-compressed and stored in a lossless format. In this method, DCT coefficients of each frequency band of JPEG-compressed image are aggregated in the QS and its multiples. The entire estimation process can be grouped into two categories: alternating and direct current bands. Considering that DCT coefficients under different QSs show different periodicity, QS estimation for each band is then further divided into three steps, which involve identifying whether the QS is one, two, or another value. For each step, the periodicity of DCT coefficients can be well exploited with the analyses of the DCT-coefficient histogram and its corresponding frequency magnitude spectrum. Experimental results demonstrate the efficacy of the proposed method and the superiority in QS estimation for previously JPEG-compressed images, especially in the case that the actual QSs are higher than two. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Wei, Hongbin] Univ Shanghai Sci & Technol, Sch Mech Engn, Shanghai 200093, Peoples R China.
   [Qiao, Tong] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Hangzhou Dianzi University
RP Qin, C (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM hyao@usst.edu.cn; tong.qiao@hdu.edu.cn; qin@usst.edu.cn
RI qin, chuan/ABG-4508-2020; Yao, Heng/J-9457-2019; Qin, Chuan/C-1106-2017
OI Yao, Heng/0000-0002-3784-4157; Qin, Chuan/0000-0002-0370-4623
FU National Natural Science Foundation of China [61702332, 61672354,
   61702150]
FX This work was supported in part by the National Natural Science
   Foundation of China (61702332, 61672354, 61702150). The authors would
   like to thank the anonymous reviewers for their helpful comments.
CR [Anonymous], MATLAB JPEG TOOLBOX
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bayar B, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P147, DOI 10.1145/3082031.3083249
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Clarke R.J., 1985, TRANSFORM CODING IMA
   Dalmia N, 2018, SIGNAL PROCESS-IMAGE, V61, P9, DOI 10.1016/j.image.2017.10.011
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fridrich J, 2001, PROC SPIE, V4518, P275, DOI 10.1117/12.448213
   Galvan F, 2014, IEEE T INF FOREN SEC, V9, P1299, DOI 10.1109/TIFS.2014.2330312
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Pasquini C, 2017, IEEE T INF FOREN SEC, V12, P2890, DOI 10.1109/TIFS.2017.2725201
   Pasquini C, 2014, IEEE INT WORKS INFOR, P113, DOI 10.1109/WIFS.2014.7084313
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   Thai TH, 2017, IEEE T INF FOREN SEC, V12, P123, DOI 10.1109/TIFS.2016.2604208
   Wu YH, 2017, ASIAPAC SIGN INFO PR, P842, DOI 10.1109/APSIPA.2017.8282150
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Yang JQ, 2015, DIGIT SIGNAL PROCESS, V41, P90, DOI 10.1016/j.dsp.2015.03.014
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107430
   Yu LY, 2016, FORENSIC SCI INT, V259, P200, DOI 10.1016/j.forsciint.2015.10.024
NR 24
TC 13
Z9 14
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2020
VL 69
AR 102795
DI 10.1016/j.jvcir.2020.102795
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LZ3UM
UT WOS:000541153600003
DA 2024-07-18
ER

PT J
AU Zhou, HC
   Zhou, S
AF Zhou, Huachun
   Zhou, Sheng
TI Scene categorization towards urban tunnel traffic by image quality
   assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene categorization; Tunnel traffic analysis; Information entropy;
   Rough clustering; Image quality model
AB Scene categorization is an indispensable technique in intelligent systems, such as scene parsing, video surveillance or autonomous driving. Considering traffic analysis under big data, in this paper, we propose scene categorization towards urban tunnel traffic based on image quality assessment. Specifically, the dataset is obtained through analyzing urban tunnel traffic incidents from 2016 to 2018. And we classify the traffic accidents in the big data environment. Then, the vehicles in the surveillance videos are extracted using conventional detector. The spatial information of vehicles in the image reflects the traffic situation. In order to encode such important information, we leverage the information clustering algorithm based on information entropy for image classification. Afterward, we establish a quality evaluation model based on each clustered images. The trained image quality assessment model will guide tunnel traffic classification and event analysis. The experimental results show the correct rate is more than 90%, and the overall detection effect is better than the k-modes algorithm and the Ng'k-modes algorithm. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhou, Huachun] ChongQing Coll Elect Engn, Sch Elect & Internet Things, Chongqing, Peoples R China.
   [Zhou, Sheng] Wuhan Donghu Univ, Sch Management, Wuhan, Hubei, Peoples R China.
C3 Chongqing College of Electronic Engineering; Wuhan Donghu University
RP Zhou, S (corresponding author), Wuhan Donghu Univ, Sch Management, Wuhan, Hubei, Peoples R China.
EM dafengqi32@126.com
CR [Anonymous], 2018, J DIABETES RES, DOI DOI 10.1016/j.patrec.2018.02.001
   [Anonymous], 2016, DES IMPL HIGHW TUNN
   Asakura Y., 2016, TRANSPORT RES C-EMER
   AYISI CL, 2017, POWER SYST TECHNOL, V2, P67, DOI DOI 10.1016/J.AAF.2017.02.001
   Cai Xiaotong, 2009, LOGIST ENG MANAGE, V31, P147
   Chen HX, 2013, MECH SYST SIGNAL PR, V40, P469, DOI 10.1016/j.ymssp.2013.06.023
   D'Andre E, 2017, EXPERT SYST APPL, V73, P43, DOI 10.1016/j.eswa.2016.12.018
   Fan Xiao-ting, 2016, Computer Engineering and Design, V37, P37, DOI 10.16208/j.issn1000-7024.2016.01.008
   Gang Peng, 2017, JIANGXI BUILD MAT, V16, P183
   Haibing Deng, 2018, CHINA HIGHWAY, V3
   Hatri C.E., 2017, INT C INT SYST COMP
   Huang Jiajun, 2017, CHINESE J ECOL, V13
   Jia Yibin, 2018, COMPUT SCI, V45
   Li Guilin, 2016, J CHIFENG U NATL SCI, V32, P63
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Lin L., 2015, THESIS
   Nikolaev A.B., 2017, INT J APPL ENG RES, V12, P4765
   Qi Qichun, 2017, J CENTRAL S U NATL S, V48, P12
   Qiang Tu., 2018, TRAFFIC INFORM SECUR, V3
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Sun LB, 2019, TRANSP LETT, V11, P558, DOI 10.1080/19427867.2018.1453273
   Sun Wenbiao, 2016, CONTINENTAL BRIDGE V, V6
   Tan pinpin, 2007, MODELING SIMULATION
   Tian Q., 2010, J TRANS ENG INF, V8, P99
   Wang Qin, 2008, Journal of Computer Applications, V28, P1886, DOI 10.3724/SP.J.1087.2008.01886
   Wang Weicai, 2017, INFORM COMPUT, V20, P39
   Wang Xu., 2016, CHINESE J ENV SCI, V36
   Weil R, 1998, MATH COMPUT MODEL, V27, P257, DOI 10.1016/S0895-7177(98)00064-8
   WEN HM, 2005, J COMMUNICATION TRAN, V5, P25
   Wenxing Zh.u., 2016, DATA ACQUIS PROCESS, V6, P1115
   Xiang Huaikun, 2005, SHENZHEN SPECIAL ZON, V11, P432
   Yang L, 2019, NEURAL COMPUT APPL, V31, P4463, DOI 10.1007/s00521-018-3525-y
   Zeng L, 2018, CORROS SCI, V144, P258, DOI 10.1016/j.corsci.2018.08.045
   Zhang YL, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/621264
   Zhou Chenghu, 2018, J IMAGE GRAPH, V4, P946
   Zhu JG, 2019, ADV DIFFER EQU-NY, DOI 10.1186/s13662-018-1908-0
   Zhu JG, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.022006
NR 37
TC 10
Z9 10
U1 1
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102655
DI 10.1016/j.jvcir.2019.102655
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700012
DA 2024-07-18
ER

PT J
AU An, GY
   Zheng, ZX
   Wu, DP
   Zhou, W
AF An, Gaoyun
   Zheng, Zhenxing
   Wu, Dapeng
   Zhou, Wen
TI Deep spectral feature pyramid in the frequency domain for long-term
   action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Deep learning; Spectral feature; Video
   classification
ID ATTENTION NETWORK; REPRESENTATION; HISTOGRAMS; VIDEO
AB In this paper, we propose a novel Deep Spectral Feature Pyramid in the Frequency domain (DSFP) to share the merits of deep features and spectral approaches for long-term action recognition. More specifically, in the spatial domain, deep features of sparse sampled frames are extracted by Convolutional Neural Networks (CNNs) to cover long-term temporal structure. In the frequency domain, appearance features of sampled frames are partitioned recursively along the time dimension and spectral transform is applied to each partitioned feature respectively. All coefficients of partitioned features are then concatenated into a video-level feature to better model the spatio-temporal structure of actions in the form of a pyramid. So DSFP could model actions from both microcosmic and macroscopic aspects. Extensive experiments conducted on two challenging action benchmarks UCF101 and HMDB51 show that our proposed DSFP is effective for spatio-temporal representation of actions and achieves comparable performance with the state-of-the-arts. (C) 2019 Elsevier Inc. All rights reserved.
C1 [An, Gaoyun; Zheng, Zhenxing; Zhou, Wen] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [An, Gaoyun; Zheng, Zhenxing; Zhou, Wen] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 Beijing Jiaotong University; Beijing Jiaotong University; State
   University System of Florida; University of Florida
RP Zheng, ZX (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM zhxzheng@bjtu.edu.cn
RI Zheng, Zhenxing/AAJ-1312-2020
OI Wu, Dapeng/0000-0003-1755-0183; Zheng, Zhenxing/0000-0002-6749-4952
FU fundamental research funds for the central universities [2018YJS048];
   National Natural Science Foundation of China [61772067, 61472030]
FX This work was supported partly by the fundamental research funds for the
   central universities (2018YJS048), the National Natural Science
   Foundation of China (61772067, 61472030).
CR [Anonymous], 2018, ARXIV181004028
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2018, P EUR C COMP VIS
   [Anonymous], 2015, Adv Neural Inf Proces Syst
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], 2018, P EUR C COMP VIS
   [Anonymous], INT J SCI RES
   [Anonymous], P EMP METH NAT LANG
   [Anonymous], 2012, CoRR
   Arivazhagan S, 2007, INT J WAVELETS MULTI, V5, P451, DOI 10.1142/S0219691307001847
   Beaudry C, 2014, IEEE IMAGE PROC, P1445, DOI 10.1109/ICIP.2014.7025289
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Forestier N, 1998, NEUROSCI LETT, V252, P187, DOI 10.1016/S0304-3940(98)00584-9
   Fujieda S., 2018, ARXIV180508620
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   Hao T, 2017, J VIS COMMUN IMAGE R, V48, P453, DOI 10.1016/j.jvcir.2017.01.019
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Imtiaz H, 2015, PROCEDIA COMPUT SCI, V60, P430, DOI 10.1016/j.procs.2015.08.161
   Jing LL, 2018, J VIS COMMUN IMAGE R, V52, P58, DOI 10.1016/j.jvcir.2018.01.016
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li MK, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P200, DOI 10.1109/SOLI.2016.7551687
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shah D, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5304, DOI 10.1109/IROS.2016.7759780
   Smith JS, 2018, LECT NOTES ARTIF INT, V10841, P235, DOI 10.1007/978-3-319-91253-0_23
   Sun L, 2017, IEEE I CONF COMP VIS, P2166, DOI 10.1109/ICCV.2017.236
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Tong M, 2019, NEUROCOMPUTING, V325, P90, DOI 10.1016/j.neucom.2018.09.086
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang TW, 2018, J VIS COMMUN IMAGE R, V55, P778, DOI 10.1016/j.jvcir.2018.08.014
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yu S, 2017, J VIS COMMUN IMAGE R, V49, P192, DOI 10.1016/j.jvcir.2017.09.007
   Yuan Y, 2018, NEUROCOMPUTING, V315, P221, DOI 10.1016/j.neucom.2018.06.071
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang MX, 2018, SIGNAL PROCESS, V145, P137, DOI 10.1016/j.sigpro.2017.12.008
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316
NR 59
TC 3
Z9 3
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102650
DI 10.1016/j.jvcir.2019.102650
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600029
DA 2024-07-18
ER

PT J
AU Galshetwar, GM
   Waghmare, LM
   Gonde, AB
   Murala, S
AF Galshetwar, G. M.
   Waghmare, L. M.
   Gonde, A. B.
   Murala, S.
TI Local energy oriented pattern for image indexing and retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local Binary Patterns (LBP); Local Mesh Patterns (LMeP); Local
   Directional Mask Maximum Edge Patterns (LDMaMEP)
ID BINARY PATTERNS; COLOR; CLASSIFICATION; WAVELET; DESCRIPTOR
AB A novel image indexing algorithm for Content Based Image Retrieval (CBIR) using Local Energy Oriented Patterns (LEOP) is proposed in this paper. LEOP encodes pixel level energy orientations to find minute spatial features of an image whereas existing methods use neighborhood relationship. LEOP maps four pixel progression orientations to find top two maximum energy changes for each reference pixel in the image i.e. for each reference 3 x 3 grid, two more 3 x 3 grids out of four pixel progression are extracted. Finally, LEOP encodes the relationship among pixels of three 3 x 3 local grids extracted. LEOP is applied on four different image databases named MESSIDOR, VIA/I-ELCAP, COREL and ImageNet Database using traditional CBIR framework. To test the robustness of proposed feature descriptor the experiment is extended to a learning based CBIR approach on COREL database. The LEOP outperformed state-of-the-art methods in both traditional as well as learning environments and hence it is a strong descriptor. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Galshetwar, G. M.; Gonde, A. B.] SGGSIET, Dept ECE, COESIP, Nanded, Maharashtra, India.
   [Waghmare, L. M.] SGGSIET, Dept Instrumentat Engn, Nanded, Maharashtra, India.
   [Murala, S.] IIT Ropar, Comp Vis & Pattern Recognit Lab, Dept EE, Rupnagar, Punjab, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology; Shri
   Guru Gobind Singhji Institute of Engineering & Technology; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Ropar
RP Galshetwar, GM (corresponding author), SGGSIET, Dept ECE, COESIP, Nanded, Maharashtra, India.
EM gmgalshetwar@gmail.com
RI Murala, Subrahmanyam/D-1397-2017; WAGHMARE, LAXMAN/AAG-1602-2019
OI Waghmare, Laxman/0000-0002-4236-7359
CR Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   [Anonymous], 1992, Active perception and robot vision, DOI [10.1007/978-3-642-77225-2_13, DOI 10.1007/978-3-642-77225-2_13]
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Ashizawa K, 1999, ACAD RADIOL, V6, P2, DOI 10.1016/S1076-6332(99)80055-5
   Baby CG, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P195, DOI 10.1109/ICSIPR.2013.6497987
   Biradar KM, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P80
   Deep G, 2016, PROCEDIA COMPUT SCI, V85, P954, DOI 10.1016/j.procs.2016.05.287
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dharani T, 2013, 2013 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, INFORMATICS AND MEDICAL ENGINEERING (PRIME)
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Dudhane A, 2017, ADV INTEL SYS RES, V137, P515
   Dudhane Akshay A., 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P345, DOI 10.1007/978-981-10-7895-8_27
   Galshetwar GM, 2017, PROCEDIA COMPUT SCI, V115, P440, DOI 10.1016/j.procs.2017.09.103
   Gonde AB, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P170
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang J, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P325, DOI 10.1145/266180.266383
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Lu X., 2017, MULTIMED TOOLS APPL, V78, P1
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Misty Y., 2013, INT J INNOV RES COMP, V1, P1828
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Rehman M., 2012, WORLD APPL SCI J, V19, P404, DOI [DOI 10.5829/idosi.wasj.2012.19.03.1506, 10.5829/idosi.wasj.2012.19.03.1506]
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Yong., 1996, PROC 1 INT WORKSHOP, P22
   Singhai N., 2010, International Journal of Computer Applications IJCA, V4, P22, DOI DOI 10.5120/802-1139
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Subrahmanyam M, 2012, EXPERT SYST APPL, V39, P5104, DOI 10.1016/j.eswa.2011.11.029
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Veltkamp RemcoC., 2002, Department of Computing Science, Utrecht University, P1
   Vipparthi SK, 2016, IET COMPUT VIS, V10, P182, DOI 10.1049/iet-cvi.2015.0035
   Vipparthi SK, 2015, INT J SIGNAL IMAGING, V8, P137, DOI 10.1504/IJSISE.2015.070485
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
NR 54
TC 20
Z9 20
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102615
DI 10.1016/j.jvcir.2019.102615
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600011
DA 2024-07-18
ER

PT J
AU Fanfani, M
   Bellavia, F
   Iuliani, M
   Piva, A
   Colombo, C
AF Fanfani, Marco
   Bellavia, Fabio
   Iuliani, Massimo
   Piva, Alessandro
   Colombo, Carlo
TI FISH: Face intensity-shape histogram representation for automatic face
   splicing detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Scene level analysis; Geometric constraints; Lighting
   environment; Face splicing detection
ID ILLUMINATION; FORGERIES
AB Tampered images spread nowadays over any visual media influencing our judgement in many aspects of our life. This is particularly critical for face splicing manipulations, where recognizable identities are put out of context. To contrast these activities on a large scale, automatic detectors are required.
   In this paper, we present a novel method for automatic face splicing detection, based on computer vision, that exploits inconsistencies in the lighting environment estimated from different faces in the scene. Differently from previous approaches, we do not rely on an ideal mathematical model of the lighting environment. Instead, our solution, built upon the concept of histogram-based features, is able to statistically represent the current interaction of faces with light, untied from the actual and unknown reflectance model. Results show the effectiveness of our solution, that outperforms existing approaches on real-world images, being more robust to face shape inaccuracies. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Fanfani, Marco; Bellavia, Fabio; Iuliani, Massimo; Piva, Alessandro; Colombo, Carlo] Univ Florence, Dept Informat Engn, Florence, Italy.
   [Iuliani, Massimo; Piva, Alessandro] Univ Florence, FORLAB Multimedia Forens Lab, Prato, Italy.
C3 University of Florence; University of Florence
RP Fanfani, M (corresponding author), Univ Florence, Dept Informat Engn, Florence, Italy.
EM marco.fanfani@unifi.it
RI Fanfani, Marco/V-9052-2018; Colombo, Carlo/AAC-6675-2019; Piva,
   Alessandro/B-8948-2008; Bellavia, Fabio/N-6790-2018
OI Fanfani, Marco/0000-0003-3741-1842; Piva,
   Alessandro/0000-0002-3047-0519; Bellavia, Fabio/0000-0002-1688-8476
FU Air Force Research Laboratory; Defense Advanced Research Projects Agency
   [FA8750-16-2-0188]
FX This material is based on research sponsored by the Air Force Research
   Laboratory and the Defense Advanced Research Projects Agency under
   agreement number FA8750-16-2-0188. The U.S. Government is authorized to
   reproduce and distribute reprints for Governmental purposes
   notwithstanding any copyright notation thereon.
CR [Anonymous], 2015, 2015 7 WORKSHOP HYPE
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Bellavia F, 2018, IEEE T PATTERN ANAL, V40, P931, DOI 10.1109/TPAMI.2017.2697849
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Fan W, 2012, EUR SIGNAL PR CONF, P1777
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Iuliani M, 2017, J VIS COMMUN IMAGE R, V42, P65, DOI 10.1016/j.jvcir.2016.11.010
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Kee E, 2010, IEEE INT WORKS INFOR
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Peng B, 2016, IEEE IMAGE PROC, P3932, DOI 10.1109/ICIP.2016.7533097
   Peng B, 2017, IEEE T INF FOREN SEC, V12, P479, DOI 10.1109/TIFS.2016.2623589
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448
   Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321
   Trigeorgis G, 2017, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2017.44
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhou W, 2008, IMAGE VISION COMPUT, V26, P415, DOI 10.1016/j.imavis.2006.12.003
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 32
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102586
DI 10.1016/j.jvcir.2019.102586
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200018
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zhong, WL
   Zhang, T
   Jiang, LF
   Ji, JS
   Zhang, ZH
   Xiong, HL
AF Zhong, Weilin
   Zhang, Tao
   Jiang, Linfeng
   Ji, Jinsheng
   Zhang, Zenghui
   Xiong, Huilin
TI Discriminative representation learning for person re-identification via
   multi-loss training
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Multi-loss training; Inter-center loss
ID RECOGNITION; NETWORK; FACE
AB The identification model that employs softmax loss to minimize person identity classification errors has gradually gained popularity in person re-identification community due to its easy implementations. However, the softmax loss only encourages the separation of different identities. The intra-class differences caused by large view variations such as spatial misalignment and human pose change are not considered in the model training process. In this paper, we present a hybrid deep model that combines multiple loss functions to handle this problem. Specifically, the multi-loss function contains three terms, namely softmax loss, center loss, and a novel loss called inter-center loss. The center loss penalizes the distance between deep features and their center, aiming to reduce intra-class differences. The inter center loss maximizes the distances between different class centers, aiming to further enlarge interclass separation. Extensive experiments conducted on three public benchmark datasets including Market1501, CUHK03, and DukeMTMC-reID demonstrate the effectiveness of our method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhong, Weilin; Zhang, Tao; Jiang, Linfeng; Ji, Jinsheng; Xiong, Huilin] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Zhang, Zenghui; Xiong, Huilin] Shanghai Jiao Tong Univ, Inst Sensing & Nav, Shanghai, Peoples R China.
   [Zhang, Zenghui; Xiong, Huilin] Shanghai Jiao Tong Univ, Shanghai Key Lab Intelligent Sensing & Recognit, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai
   Jiao Tong University
RP Xiong, HL (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM hlxiong@sjtu.edu.cn
RI huang, libo/JMB-4345-2023; JI, JINSHENG/KHW-3948-2024; Zhang,
   Zenghui/GVS-8983-2022
OI JI, JINSHENG/0000-0002-5360-919X; 
FU National Natural Science Foundation of China [61673274]; Shanghai
   Science and Technology Commission Scientific Research Project
   [171321100803]
FX This study is partially supported by National Natural Science Foundation
   of China under Grant 61673274, and Shanghai Science and Technology
   Commission Scientific Research Project with project Nos. 171321100803.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], ARXIV170307737
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2749576
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2018, P EUR C COMP VIS
   [Anonymous], 2016, NIPS 16 P 30 INT C N, DOI DOI 10.5555/3157096.3157304
   [Anonymous], ARXIV170307220
   [Anonymous], ARXIV170107732
   [Anonymous], ARXIV160107255
   [Anonymous], 2017, P IEEE C COMPUTER VI
   [Anonymous], 2015, PROC 28 INT C NEURAL
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Davis J. V., 2007, ICML, P209
   Duan YQ, 2018, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2018.00294
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gao MF, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1077, DOI 10.1109/FSKD.2017.8392913
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538
   Lu JW, 2017, IEEE SIGNAL PROC MAG, V34, P76, DOI 10.1109/MSP.2017.2732900
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng J, 2017, J NONLINEAR FUNCT AN, DOI 10.23952/jnfa.2017.14
   Zheng L., ARXIV161002984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong WL, 2019, NEUROCOMPUTING, V334, P68, DOI 10.1016/j.neucom.2019.01.005
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 69
TC 8
Z9 10
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 267
EP 278
DI 10.1016/j.jvcir.2019.06.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600026
DA 2024-07-18
ER

PT J
AU Kossyk, I
   Márton, ZC
AF Kossyk, Ingo
   Marton, Zoltan-Csaba
TI Discriminative regularization of the latent manifold of variational
   auto-encoders
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Variational auto-encoder; Regularization; Knowledge representation;
   Perceptual data compaction; Semi-supervised learning; Statistical
   performance analysis
AB We present an approach on training classifiers or regressors using the latent embedding of variational auto-encoders (VAE), an unsupervised deep learning method, as features. Usually VAEs are trained using unlabeled data and independently from the classifier, whereas we investigate and analyze the performance of a classifier or regressor that is trained jointly with the variational deep network. We found that models trained this way can improve the embedding s.t. to increase classification performance, and also can be used for semi-supervised learning, building up the information extracting latent representation in an incremental fashion.
   The model was tested on two widely known computer vision benchmarks, and its generalization power was evaluated on an independent dataset. Additionally, generally applicable statistical methods are presented for evaluating similarly performing classifiers, and used to quantify the performance increase. The general applicability and ease-of-use of deep learning approaches allows for a wide applicability of the method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kossyk, Ingo; Marton, Zoltan-Csaba] German Aerosp Ctr DLR, Robot & Mechatron Ctr, Muenchner Str 20, D-82234 Oberpfaffenhofen, Wessling, Germany.
   [Kossyk, Ingo] DLR, Cologne, Germany.
   [Kossyk, Ingo] Hexagon Technol Ctr GmbH, Heinrich Wild Str, CH-9435 Heerbrugg, Switzerland.
C3 Helmholtz Association; German Aerospace Centre (DLR); Helmholtz
   Association; German Aerospace Centre (DLR)
RP Márton, ZC (corresponding author), German Aerosp Ctr DLR, Robot & Mechatron Ctr, Muenchner Str 20, D-82234 Oberpfaffenhofen, Wessling, Germany.
FU European Union Project RobDREAM under the H2020 framework programme
   [645403]; H2020 - Industrial Leadership [645403] Funding Source: H2020 -
   Industrial Leadership
FX This work was partly funded by the European Union Project RobDREAM under
   the H2020 framework programme grant agreement No. 645403 (no involvement
   in study design; in the collection, analysis and interpretation of data;
   in the writing of the report; and in the decision to submit the article
   for publication).
CR [Anonymous], ARXIV160203220
   [Anonymous], ACM T MATH SOFTWARE
   [Anonymous], PROC CVPR IEEE
   [Anonymous], J STAT PLAN INFER
   [Anonymous], 2018 14 IEEE INT C A
   [Anonymous], 2016, P 29 C NEUR INF PROC
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2011, NEURAL INFORM PROCES
   [Anonymous], 1950, BIOL MONOGRAPHS MANU
   [Anonymous], SUBSTANCE USE MISUSE
   [Anonymous], 2014, Proc. of ICML
   [Anonymous], WORKSH METR EMB LEAR
   [Anonymous], J ROY STAT SOC
   [Anonymous], 1998, The mnist database of handwritten digits
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   BAUER DF, 1972, J AM STAT ASSOC, V67, P687, DOI 10.2307/2284469
   Brown LD, 2001, STAT SCI, V16, P101, DOI 10.1214/ss/1009213286
   Campbell I, 2007, STAT MED, V26, P3661, DOI 10.1002/sim.2832
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Huang G., 2018, CVPR, V3, P11
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma D. P., 2014, Advances in neural information processing systems, P3581
   Kingma D. P., 2013, ARXIV13126114
   Kingma DP, 2016, 30 C NEURAL INFORM P, V29
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   Krizhevsky A., 2014, The cifar-10 dataset
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kulkarni TD, 2015, ADV NEUR IN, V28
   Maaloe L., 2016, PMLR
   Makhzani Alireza, 2016, CoRR abs/1511.05644
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Tolstikhin I., 2017, ARXIV171101558
   Tomczak J. M., 2016, ARXIV161109630
NR 37
TC 3
Z9 3
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 121
EP 129
DI 10.1016/j.jvcir.2019.03.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100013
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, S
   Wang, H
   Gao, JG
   Xing, CQ
AF Zhang Shuang
   Wang Hua
   Gao Jin-gang
   Xing Chun-qi
TI Frequency domain point cloud registration based on the Fourier transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fourier transform; Point cloud data; Frequency domain; Registration
ID IMAGE; OBJECTS; DEEP
AB Due to the limited measurement range and occlusion of single-line structured light, it is impossible to detect the side data of the whole part. It is proposed that point cloud registration method obtained from multiple rotations of parts in frequency domain by Fourier transform. In the process of point cloud registration, cross-section point cloud data are restored to the corresponding size matrix firstly. Secondly, Fourier transform is carried out to calculate the point cloud data. When calculating the rotation angle, the polar coordinate transformation is carried out at first, and then the cross power spectrum of the two matrices is obtained, so that the rotation and translation matrix of the point cloud can also be obtained. In this process, considering point cloud noise existence, the Sinc function is approximately replaced by the non-noise inverse Fourier transform of cross power spectrum, so that the noise has no influence on the determination of registration parameters in frequency domain registration. The registration accuracy of point cloud is checked by high precision rotation and multiple measurements of mobile platform. Finally, the rotation matrix and translation values are obtained. (C) 2019 Published by Elsevier Inc.
C1 [Zhang Shuang; Wang Hua; Gao Jin-gang] Changchun Inst Technol, Sch Mechatron Engn, Changchun 130012, Jilin, Peoples R China.
   [Wang Hua; Xing Chun-qi] Changchun Univ Technol, Sch Mechatron Engn, Changchun 130012, Jilin, Peoples R China.
C3 Changchun Institute Technology; Changchun University of Technology
RP Wang, H (corresponding author), Changchun Inst Technol, Sch Mechatron Engn, Changchun 130012, Jilin, Peoples R China.; Wang, H (corresponding author), Changchun Univ Technol, Sch Mechatron Engn, Changchun 130012, Jilin, Peoples R China.
EM wwang_hua@sohu.com
FU Jilin province science and technology development funding project
   [20170204012GX]
FX This work was supported by Jilin province science and technology
   development funding project. The title of research project: Research on
   Key Technologies of On-line Detection of Wheelbase Size and Shape and
   Position Deviation of Train Bogies, and project serial number:
   20170204012GX.
CR Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   [Anonymous], REGISTRATION INTEGRA
   Bae KH, 2008, ISPRS J PHOTOGRAMM, V63, P36, DOI 10.1016/j.isprsjprs.2007.05.012
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chen C. S., 1999, IEEE T PAMI, V21
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Chung DH, 1998, PATTERN RECOGN, V31, P457, DOI 10.1016/S0031-3203(97)00063-0
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   [浮丹丹 Fu Dandan], 2014, [测绘工程, Engineering of Surveying and Mapping], V23, P20
   Fuersattel P, 2018, MACH VISION APPL, V29, P313, DOI 10.1007/s00138-017-0901-z
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hoffmann Ryan, 2018, REV SCI INSTRUM, V89
   Ji SJ, 2017, OPTIK, V140, P451, DOI 10.1016/j.ijleo.2017.01.041
   Jinting X. U., 2007, CHINESE J MECH ENG, V43, P175
   Li F, 2018, J MOD OPTIC, V65, P30, DOI 10.1080/09500340.2017.1375566
   Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160
   [梅元刚 Mei Yuangang], 2014, [中国科学. 技术科学, Scientia Sinica Technologica], V44, P108
   Meng Y. U., 2011, VISUAL COMPUTER
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501
   Rodrigues MA, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P841, DOI 10.1109/ICIP.2002.1039103
   Rubinsztein-Dunlop H, 2017, J OPTICS-UK, V19, DOI 10.1088/2040-8978/19/1/013001
   Rusu R. B., 2008, P IROS, P384
   Symbol Technologies LLC, 2018, US, Patent No. 9940535
   Thirion JP, 1996, INT J COMPUT VISION, V19, P115, DOI 10.1007/BF00055800
   Timmons N, 2017, ASTROPHYS J LETT, V849, DOI 10.3847/2041-8213/aa89e8
   Vrbanec D, 2016, MON NOT R ASTRON SOC, V457, P666, DOI 10.1093/mnras/stv2993
   Wang Xue-wei, ELECT OPTICS CONTROL
   Wood Darren, 2018, POWER MAG POWER GENE, V162, P16
   Xianbo LU. O., 2004, J TSINGHUA U SCI TEC, V44, P1104
   Xiao T., 2014, Geotech. Investig. Surv, V42, P79
   Zhang B., 2017, APPL MECH MAT, V870, P249, DOI [10.4028/www.scientific.net/AMM.870.249, DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.870.249]
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zhu Yanjuan, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P475
   2018, COMPUT METHOD BIOMEC, V21, P498, DOI DOI 10.1080/10255842.2018.1484914
   2002, IEEE T IMAGE PROCESS, V11, P188
   2018, EUR J REMOTE SENS, V51, P301, DOI DOI 10.1080/22797254.2018.1432293
   2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI DOI 10.1109/TGRS.2014.2374218
NR 49
TC 14
Z9 16
U1 5
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 170
EP 177
DI 10.1016/j.jvcir.2019.03.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100018
DA 2024-07-18
ER

PT J
AU Fan, X
   Jiang, W
   Luo, H
   Fei, MJ
AF Fan, Xing
   Jiang, Wei
   Luo, Hao
   Fei, Mengjuan
TI SphereRelD: Deep hypersphere manifold embedding for person
   re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Classification; Feature embedding; CNN;
   Hypersphere
AB Many current successful Person Re-Identification (ReID) methods train a model with the softmax loss function to classify images of different persons and obtain the feature vectors at the same time. However, the underlying feature embedding space is ignored. In this paper, we use a modified softmax function, termed Sphere Softmax, to solve the classification problem and learn a hypersphere manifold embedding simultaneously. A balanced sampling strategy is also introduced. Finally, we propose a convolutional neural network called SphereRelD adopting Sphere Softmax and training a single model endto-end with a new warming-up learning rate schedule on four challenging datasets including Market-1501, DukeMTMC-relD, CHHK-03, and CUHK-SYSU. Experimental results demonstrate that this single model outperforms the state-of-the-art methods on all four datasets without fine-tuning or re-ranking. For example, it achieves 94.4% rank-1 accuracy on Market-1501 and 83.9% rank-1 accuracy on DukeMTMC-relD. The code and trained weights of our model will be released. (C) 2019 Published by Elsevier Inc.
C1 [Fan, Xing; Jiang, Wei; Luo, Hao; Fei, Mengjuan] Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Jiang, W (corresponding author), Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Zhejiang, Peoples R China.
EM jiangwei_zju@zju.edu.cn
RI jiang, wei/J-6317-2018; Luo, Hao/AAG-2570-2020; Fan, Xing/AAY-6418-2020
OI jiang, wei/0000-0002-9240-5851; Luo, Hao/0000-0002-6405-4011; Fan,
   Xing/0000-0003-2622-2210
FU Public Projects of Zhejiang Province, China [LGF18F030002]; National
   Natural Science Foundation of China [61633019]
FX Our work was supported by the Public Projects of Zhejiang Province,
   China (No. LGF18F030002) and the National Natural Science Foundation of
   China (No. 61633019).
CR [Anonymous], 2017, P 25 ACM INT C MULT
   [Anonymous], 2016, CORR
   [Anonymous], ARXIV161005047
   [Anonymous], 2018, COSFACE LARGE MARGIN
   [Anonymous], THE IEEE CONFERENCE
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, DEEP TRANSFER LEARNI
   [Anonymous], 2016, LARGE MARGIN SOFTMAX
   [Anonymous], 2015, THE IEEE INTERNATION
   [Anonymous], 2017, Beyond part models: Person retrieval with refined part pooling. Proceedings of European Conference on Computer Vision
   [Anonymous], 2017, ARXIV170307737
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], POSE DRIVEN DEEP CON
   [Anonymous], ADDITIVE MARGIN SOFT
   [Anonymous], 2017, DARKRANK ACCELERATIN
   [Anonymous], ALIGNEDRELD SURPASSI
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2017, PERSON TRANSFER GAN
   [Anonymous], 2018, ARCFACE ADDITIVE ANG
   [Anonymous], RE RANKING PERSON RE
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], PERSON REIDENTIFICAT
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2017, POSE SENSITIVE EMBED
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], THE IEEE INTERNATION
   [Anonymous], 2017, POSE INVARIANT EMBED
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2017, POSE NORMALIZED IMAG
   [Anonymous], 2015, PROC 28 INT C NEURAL
   [Anonymous], 2017, IEEE C COMP VIS PATT
   Bai Xiang, 2017, DEEP PERSON LEARNING
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Gu SQ, 2017, IEEE INT SYMP ELEC
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huo YF, 2017, IEEE INT SYMP ELEC
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Zhang Y., 2017, DEEP REPRESENTATION
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
NR 64
TC 136
Z9 148
U1 3
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 51
EP 58
DI 10.1016/j.jvcir.2019.01.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, K
   Zhao, W
   Cui, JJ
   Cui, YP
   Hu, JW
AF Wang, Kun
   Zhao, Wei
   Cui, Junjie
   Cui, Yanpeng
   Hu, Jianwei
TI A K-anonymous clustering algorithm based on the analytic hierarchy
   process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Clustering algorithm; Analytic hierarchy process
ID MODEL
AB To protect the privacy of users, tables generally must be anonymized before publication. All existing anonymous methods have deficiencies. They do not consider the differences in attributes, or the optimization of information loss and time efficiency. his paper proposes a new method called KACM to realize k-anonymity. This method is mainly used for hybrid tables. The calculation of the distance between records considers the connection between quasi-identifier attributes and sensitive attributes, their effect on the sensitive privacy, and the information loss during the anonymity process. In the clustering process, the records with the minimum distance are always selected to add, and the clustering is individually controlled according to k to realize the equalization division of the equivalence class and reduce the total amount of distance calculation. Finally, the validity and practicability of the method are proved using theory and experiment. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Kun; Zhao, Wei; Cui, Junjie; Cui, Yanpeng; Hu, Jianwei] Xidian Univ, Sch Cyber Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Wang, K (corresponding author), Xidian Univ, Sch Cyber Engn, Xian 710071, Shaanxi, Peoples R China.
EM kunwang156@sina.com
RI Wang, Kun/AAP-2480-2020
OI Wang, Kun/0000-0001-5523-1330
CR Aggarwal Gagan., 2006, PODS, P153, DOI DOI 10.1145/1142351.1142374
   [Anonymous], J ETHNOPHARMACOL
   [Anonymous], 2004, TECHNICAL REPORT
   [Anonymous], 2005, P SIGMOD
   Bayardo RJ, 2005, PROC INT CONF DATA, P217
   Domingo-Ferrer J, 2005, DATA MIN KNOWL DISC, V11, P195, DOI 10.1007/s10618-005-0007-5
   Gao TH, 2014, I C INNOV MOBILE INT, P533, DOI 10.1109/IMIS.2014.78
   Ge JK, 2014, 2014 IEEE 13TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI-CC), P329, DOI 10.1109/ICCI-CC.2014.6921479
   Guo  C., 2015, COMP SOFTW APPL C CO, V3, P104
   [郭昆 Guo Kun], 2013, [软件学报, Journal of Software], V24, P1852
   Han J. M., 2010, ACTA ELECT SINICA, V7
   Herrmann  M., 2011, INT S PRIV ENH TECHN, P155
   Jiang Huo-Wen, 2017, Journal of Software, V28, P341, DOI 10.13328/j.cnki.jos.005015
   Kabir ME, 2011, ACTA INFORM, V48, P51, DOI 10.1007/s00236-010-0131-6
   Laszlo M, 2005, IEEE T KNOWL DATA EN, V17, P902, DOI 10.1109/TKDE.2005.112
   Li JY, 2006, LECT NOTES COMPUT SC, V4081, P405
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Li RX, 2010, IEICE T INF SYST, VE93D, P491, DOI 10.1587/transinf.E93.D.491
   Lin JL, 2010, EXPERT SYST APPL, V37, P3256, DOI 10.1016/j.eswa.2009.09.054
   Liu Jie, 2017, J Inf Hiding Multimed Signal Process, V8, P12
   Lu JF, 2011, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2011-101
   Machanavajjhala Ashwin, 2006, NULL, P24
   Meyerson A, 2004, P 23 ACM SIGMOD SIGA, P223
   Radojevic Z, 2007, IET GENER TRANSM DIS, V1, P357, DOI 10.1049/iet-gtd:20060139
   Saaty T.L., 2013, GROUP DECISION MAKIN
   Saaty TL, 2008, RACSAM REV R ACAD A, V102, P251, DOI 10.1007/BF03191825
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   [王波 Wang Bo], 2012, [电子学报, Acta Electronica Sinica], V40, P883
   Xu J., 2006, P 12 ACM SIGKDD INT, P785
   Yang Xiao-Chun, 2006, Journal of Software, V17, P1222, DOI 10.1360/jos171222
   Zhang F. X., 2015, NETINFO SECURITY, V8, P53
   Zhang JP, 2014, INT C COMP SUPP COOP, P319, DOI 10.1109/CSCWD.2014.6846862
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
NR 37
TC 12
Z9 18
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 76
EP 83
DI 10.1016/j.jvcir.2018.12.052
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600008
DA 2024-07-18
ER

PT J
AU Li, DD
   Wen, GJ
   Kuai, YL
   Xiao, JJ
   Porikli, F
AF Li, Dongdong
   Wen, Gongjian
   Kuai, Yangliu
   Xiao, Jingjing
   Porikli, Fatih
TI Learning target-aware correlation filters for visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Correlation filter; Target likelihood map; Visual tracking
ID OBJECT TRACKING
AB Discriminative Correlation Filters (DCF) have achieved enormous popularity in the tracking community. Generally, DCF based trackers assume that the target can be well shaped by an axis-aligned bounding box. Therefore, in terms of irregularly shaped objects, the learned correlation filter is unavoidably deteriorated by the background pixels inside the bounding box. To tackle this problem, we propose Target-Aware Correlation Filters (TACF) for visual tracking. A target likelihood map is introduced to impose discriminative weight on filter values according to the probability of this location belonging to the foreground target. According to the TACF formulation, we further propose an optimization strategy based on the Preconditioned Conjugate Gradient method for efficient filter learning. With hand-crafted features (HOG), our approach achieves state-of-the-art performance (62.8% AUC) on OTB100 while running in real-time (24 fps) on a single CPU. With shallow convolutional features, our approach achieves 66.7% AUC on OTB100 and the top rank in EAO on the V0T2016 challenge. (C) 2018 Published by Elsevier Inc.
C1 [Li, Dongdong; Wen, Gongjian; Kuai, Yangliu] Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
   [Xiao, Jingjing] Xinqiao Hosp, Dept Med Engn, Chongqing, Peoples R China.
   [Porikli, Fatih] Australian Natl Univ, Canberra, ACT, Australia.
C3 National University of Defense Technology - China; Army Medical
   University; Australian National University
RP Li, DD (corresponding author), Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
EM moqimubai@sina.cn
RI xiao, jing/HRB-7391-2023
OI Xiao, Jingjing/0000-0001-5020-638X
FU National Natural Science Foundation of China (NSFC) [41601487, 61701506]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) (No. 41601487, 61701506).
CR [Anonymous], 2016, THE VISUAL OBJECT TR
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bibi A, 2016, LECT NOTES COMPUT SC, V9910, P419, DOI 10.1007/978-3-319-46466-4_25
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Guan T, 2009, IEEE T MULTIMEDIA, V11, P1393, DOI 10.1109/TMM.2009.2032684
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Lee KH, 2015, IEEE T MULTIMEDIA, V17, P1429, DOI 10.1109/TMM.2015.2455418
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang L, 2017, P INT C DIG IM COMP, P1
   Wu GL, 2017, IEEE T MULTIMEDIA, V19, P1730, DOI 10.1109/TMM.2017.2691538
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
NR 39
TC 11
Z9 12
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 149
EP 159
DI 10.1016/j.jvcir.2018.11.036
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100016
DA 2024-07-18
ER

PT J
AU Wang, Y
   Huang, L
   Guo, SY
   Gong, LG
   Bai, T
AF Wang, Ye
   Huang, Lan
   Guo, Shuyu
   Gong, Leiguang
   Bai, Tian
TI A novel MEDLINE topic indexing method using image presentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MEDLINE; Data visualization; Customized retrieval; Image presentation
ID RETRIEVAL; VISUALIZATION; INFORMATION; STRATEGIES; DATABASE; HEALTH
AB MEDLINE is one of the largest databases of biomedical literatures. The search results from MEDLINE for medical terms are in the form of lists of articles with PubMed IDs. To further explore and select articles that may help identify potentially interesting interactions between terms, users need to navigate through the lists of URLs to retrieve and read actual articles to find relevancies among these terms. Such work becomes extremely time consuming and unbearably tedious when each query returns tens of thousands results with an uncertain recall rate. To overcome this problem, we develop a topic-specific image indexing and presentation method for discovering interactions or relatedness of medical terms from MEDLINE, based on which a prototype tool is implemented to help discover interactions between terms of types of diseases. The merits of the method is illustrated by search examples using the tool and MEDLINE abstract dataset. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Ye; Huang, Lan; Guo, Shuyu; Gong, Leiguang; Bai, Tian] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Huang, Lan; Bai, Tian] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
   [Huang, Lan] Zhuhai Coll Jilin Univ, Dept Comp Sci & Technol, Zhuhai Lab Key Lab Symbol Computat & Knowledge En, Minist Educ, Zhuhai 519041, Peoples R China.
   [Gong, Leiguang] Yantai Intelligent Informat Technol Ltd, Yantai, Peoples R China.
C3 Jilin University; Jilin University
RP Bai, T (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
EM wang_ye15@mails.jlu.edu.cn; huanglan@jlu.edu.cn;
   syguo17@mails.jlu.edu.cn; baitian@jlu.edu.cn
RI Wang, Ye/GWQ-7482-2022
FU National Natural Science Foundation of China [61702214, 61472159]; Jilin
   Provincial Key Laboratory of Big Data Intelligent Computing
   [20180622002JC]; Development Project of Jilin Province of China
   [20170101006JC]; China Postdoctoral Science Foundation [2014M561293];
   Premier-Discipline Enhancement Scheme - Zhuhai Government; Premier Key
   Discipline Enhancement Scheme
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61702214, 61472159). This work is also supported in
   part by Jilin Provincial Key Laboratory of Big Data Intelligent
   Computing (20180622002JC), Development Project of Jilin Province of
   China (Nos.20170101006JC), China Postdoctoral Science Foundation
   (2014M561293), Premier-Discipline Enhancement Scheme supported by Zhuhai
   Government, Premier Key Discipline Enhancement Scheme supported
   Guangdong Government Funds.
CR Allot A, 2018, NUCLEIC ACIDS RES, V46, pW530, DOI 10.1093/nar/gky355
   Andronis C., BRIEF BIOINF
   Zulueta MA, 2011, SCIENTOMETRICS, V88, P679, DOI 10.1007/s11192-011-0455-1
   Badgett RG, 2015, PEERJ, V3, DOI 10.7717/peerj.913
   Baladron C., J AM MED INFORM ASS, V25
   Becker KG, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-61
   Beynon R., 2013, SEARCH STRATEGIES ID
   Cantiello P, 2014, INT J COMPUT SCI ENG, V9, P222, DOI 10.1504/IJCSE.2014.060678
   Chen Dongquan, 2005, BMC Med Inform Decis Mak, V5, P6, DOI 10.1186/1472-6947-5-6
   Damarell RA, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-86
   Du H., 2006, AMIA ANN S P AMIA S, P944
   Esn V., 2018, SAO PAULO MED J, V136
   Ewuoso C, 2017, S AFR J BIOETH LAW, V10, P75, DOI 10.7196/SAJBL.2017.v10i2.00610
   Helal RM, 2014, ANN MED HEALTH SCI R, V4, P278, DOI 10.4103/2141-9248.141972
   Jimeno-Yepes A. J., 2013, BMC BIOINFORM, V14
   Kim J, 2016, COMP MED SY, P290, DOI 10.1109/CBMS.2016.61
   Kim S, 2016, BIOINFORMATICS, V32, P3044, DOI 10.1093/bioinformatics/btw331
   Liu SB, 2014, SCIENTOMETRICS, V101, P1293, DOI 10.1007/s11192-014-1233-7
   Lu ZY, 2009, J AM MED INFORM ASSN, V16, P32, DOI 10.1197/jamia.M2935
   Pillastrini P, 2015, J MANIP PHYSIOL THER, V38, P159, DOI 10.1016/j.jmpt.2014.11.005
   Poulter GL, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-108
   Skupin A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058779
   Stapley B J, 2000, Pac Symp Biocomput, P529
   Stoyanovich J, 2010, PROC INT CONF DATA, P860, DOI 10.1109/ICDE.2010.5447931
   Sun K., 2018, SCI DATA, V5
   Volpato ESN, 2014, J EVAL CLIN PRACT, V20, P117, DOI 10.1111/jep.12094
   Xuan Weijian, 2007, Comput Syst Bioinformatics Conf, V6, P359, DOI 10.1142/9781860948732_0036
   Xue Y, 2016, INT J COMPUT SCI ENG, V13, P66, DOI 10.1504/IJCSE.2016.10000013
   Yoo S, 2010, J BIOMED INFORM, V43, P686, DOI 10.1016/j.jbi.2010.04.005
   Zghal HB, 2014, MULTIMED TOOLS APPL, V72, P2393, DOI 10.1007/s11042-013-1527-4
   Zhao A. P., INT COMPUT SCI ENG, V13
NR 31
TC 7
Z9 7
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 130
EP 137
DI 10.1016/j.jvcir.2018.11.022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HK1MD
UT WOS:000457668100014
DA 2024-07-18
ER

PT J
AU Pan, XF
   Zhang, JQ
   Wang, SS
   Wang, SQ
   Zhou, Y
   Ding, WH
   Yang, YH
AF Pan, Xiaofei
   Zhang, Jiaqi
   Wang, Shanshe
   Wang, Shiqi
   Zhou, Yun
   Ding, Wenhua
   Yang, Yahui
TI HDR video quality assessment: Perceptual evaluation of compressed HDR
   video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range (HDR); Subjective quality assessment; Video
   compression
AB Compared with standard dynamic range (SDR) video, the high dynamic range (HDR) video can provide us significantly enhanced viewing experience. In particular, compared to SDR video, the HDR video has better contrast and preserves more details for the same scene. With the rapid development of HDR video compression technology, there is a lack of trusted quality measure of HDR video compression. In order to facilitate the future development of objective HDR quality assessment, we build a HDR video quality assessment database, in which the bitstream is created by compressing a series of HDR video sequences. In the compression, the quantization parameters (QP) are set to 12 levels according to the configuration of the codec. The subjective quality of each bitstream is rated by 22 viewers. It is revealed that the subject viewers have arrived at a reasonable agreement on the subjective quality of different QP levels. This paper presents the results of subjective quality assessment of HDR compressed video, which also exhibits that there is significant room to further improve the objective HDR video quality assessment algorithms. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Pan, Xiaofei; Yang, Yahui] Peking Univ, Sch Software & Microelect, Beijing, Peoples R China.
   [Zhang, Jiaqi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Wang, Shanshe] Peking Univ, Sch Elect Engn & Comp Sci, Beijing, Peoples R China.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Zhou, Yun] Acad Broadcasting Sci, SAPPRFT, Beijing, Peoples R China.
   [Pan, Xiaofei; Ding, Wenhua] China Cent Televis, Beijing, Peoples R China.
C3 Peking University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Peking University; City University of Hong Kong
RP Wang, SS (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Beijing, Peoples R China.
EM panxiaofei@cctv.com; zhangjiaqi17@mails.ucas.edu.cn; sswang@pku.edu.cn
RI Zhang, Jiaqi/JCO-6818-2023
CR [Anonymous], 2002, P COL IM C
   [Anonymous], 2020 PAR VAL ULTR DE
   [Anonymous], 2015, HIGH DYNAMIC RANGE E, P1
   Aydin TO, 2008, PROC SPIE, V6806, DOI 10.1117/12.765095
   B. ITU-Recommendation, B ITU REC METH SUBJ
   Baroncini V., 2016, P JCTVC X1018 24 JCT
   Borer T., 2016, SMPTE Motion Imaging Journal, V125, P50
   Borer T, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P71, DOI 10.1109/DMIAF.2016.7574905
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Ferwerda J. A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P249, DOI 10.1145/237170.237262
   François E, 2016, IEEE T CIRC SYST VID, V26, P63, DOI 10.1109/TCSVT.2015.2461911
   Gao W., 2014, Advanced Video Coding Systems, P35
   Hanhart P, 2016, QOMEX, P1
   Hanhart P, 2015, PROC SPIE, V9599, DOI 10.1117/12.2193832
   Heidrich Wolfgang, ERIK REINHARD
   Jansen K., POINTERS GAMUT THE C
   Kunkel Timo., 2010, P 7 S APPL PERCEPTIO, P17, DOI DOI 10.1145/1836248.1836251
   Luthra A., MPEG2014N14549 ISOIE
   Luthra A., MPEG2014
   Ma SW, 2013, IEEE IMAGE PROC, P1500, DOI 10.1109/ICIP.2013.6738308
   Ma SW, 2015, IEEE SIGNAL PROC MAG, V32, P172, DOI 10.1109/MSP.2014.2371951
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mukherjee R, 2016, SIGNAL PROCESS-IMAGE, V47, P426, DOI 10.1016/j.image.2016.08.001
   Munkberg J, 2006, ACM T GRAPHIC, V25, P698, DOI 10.1145/1141911.1141944
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   POINTER MR, 1980, COLOR RES APPL, V5, P145, DOI 10.1002/col.5080050308
   Rerabek M., MPEG2014M35273 ISOIE
   Sector R., R SECT IM PAR VAL HI
   Segall A., 2017, 162017 JVET ITUT SG
   STEVENS JC, 1963, J OPT SOC AM, V53, P375, DOI 10.1364/JOSA.53.000375
   Strom J., 2016, 2016 PICTURE CODING, P1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tourapis A. M., MPEG2016M38422 ISOIE
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie LJ, 2016, IEEE INT SYMP CIRC S, P2218, DOI 10.1109/ISCAS.2016.7539023
   Yu L, 2005, P SOC PHOTO-OPT INS, V5960, P679, DOI 10.1117/12.632515
   Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3827, DOI 10.1109/TIP.2018.2815841
   Zhang YB, 2013, IEEE T CIRC SYST VID, V23, P1097, DOI 10.1109/TCSVT.2012.2223792
   Zhao Y., 2014, P IEEE C EXP TRANSP, P340, DOI [DOI 10.1109/ICME.2014.6890211, DOI 10.1007/978-3-319-16628-5_25]
NR 42
TC 9
Z9 9
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 76
EP 83
DI 10.1016/j.jvcir.2018.10.016
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400010
DA 2024-07-18
ER

PT J
AU Fan, XJ
   Yang, XB
   Ye, QL
   Yang, Y
AF Fan, Xijian
   Yang, Xubing
   Ye, Qiaolin
   Yang, Yin
TI A discriminative dynamic framework for facial expression recognition in
   video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Histogram of gradients; Facial expression; Feature extraction
ID AUTOMATIC-ANALYSIS; FACE
AB Facial expression involves a dynamic process, leading to the variation of different facial components over time. Thus, dynamic descriptors are essential for recognising facial expressions. In this paper, we extend the spatial pyramid histogram of gradients to spatio-temporal domain to give 3-dimensional facial features. To enhance the spatial information, we divide the whole face region into a group of smaller local regions to extract local 3D features, and a weighting strategy based on fisher separation criterion is proposed to enhance the discrimination ability of local features. A multi-class classifier based on support vector machine is applied for recognising facial expressions. Experiments on the CK+ and MMI datasets using leave-one-out cross validation scheme show that the proposed framework perform better than using the descriptor of simple concatenation. Compared with state-of-the-art methods, the proposed framework demonstrates a superior performance. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Fan, Xijian; Yang, Xubing; Ye, Qiaolin; Yang, Yin] Nanjing Forestry Univ, Dept Comp Sci, Nanjing, Jiangsu, Peoples R China.
   [Yang, Yin] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
C3 Nanjing Forestry University; University of New Mexico
RP Fan, XJ (corresponding author), Nanjing Forestry Univ, Dept Comp Sci, Nanjing, Jiangsu, Peoples R China.
EM xijian.fan@njfu.edu.cn; xbyang@njfu.edu.cn; yqlcom@njfu.edu.cn;
   yangy@unm.edu
RI yang, fly/AAF-4722-2020; Fan, Xijian/GRR-2740-2022
OI Fan, Xijian/0000-0002-7017-7667; Yang, Yin/0000-0001-7645-5931
FU National Natural Science Foundation of China [61871444]
FX This research is supported by National Natural Science Foundation of
   China (Grant No. 61871444).
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   [Anonymous], 2010, CHAPTER AFFECTIVE CO
   [Anonymous], P BRIT C MACH VIS
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Cohn JF, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P396, DOI 10.1109/AFGR.1998.670981
   Cornelis C, 2007, LECT NOTES ARTIF INT, V4482, P87
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Fan XJ, 2015, PATTERN RECOGN, V48, P3407, DOI 10.1016/j.patcog.2015.04.025
   Fang H, 2014, PATTERN RECOGN, V47, P1271, DOI 10.1016/j.patcog.2013.09.023
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jeni L.A., 2013, Proc. 10th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit, P1
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Martinez Brais, 2019, IEEE Transactions on Affective Computing, V10, P325, DOI 10.1109/TAFFC.2017.2731763
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414
   Yeasin M, 2004, PROC CVPR IEEE, P922
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu Y., 2007, INFORM FUSION 2007 1, P1
NR 34
TC 7
Z9 7
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 182
EP 187
DI 10.1016/j.jvcir.2018.09.011
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500018
DA 2024-07-18
ER

PT J
AU Dai, B
   Ye, WJ
   Zheng, J
   Chai, QY
   Yao, YY
AF Dai, Bo
   Ye, Weijing
   Zheng, Jing
   Chai, Qianyi
   Yao, Yiyang
TI RETRACTED: Deep network for visual saliency prediction by encoding image
   composition (Retracted article. See vol. 67, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Deep network; Visual saliency regions; Image composition
ID PERFORMANCE ANALYSIS
AB This article will be visual significance into the graphical guidance (the chart is a medium-sized join subgraph). Deep structure, from the level of learning a significant map. The original image pixel to the object level graphic (oGL), and further Space level graphics (sGL). In particular, we first sample Super pixels from each image, and they are used as buildings Block of each object. In order to seamlessly describe different objects, the number of oGLs is generated by spatial adjacent links. The super pixel oGL object response mapping is obtained by obtaining, Transfer, the semantics of the image tag to oGL. As space, the layout of the object plays an important role in the prominence of the object based on the relevant learning distribution proposed sGL OGL position between. Finally, in order to imitate the "winner of all" Biological vision mechanism, the largest majority of voting programs, The sGL of the image, is probabilistically combined into a significant graph. Experimental results show that oGLs and sGLs capture the object level well and space-level visual cues, resulting in competitiveness significant detection accuracy. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Dai, Bo; Ye, Weijing; Zheng, Jing; Chai, Qianyi; Yao, Yiyang] State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Dai, B (corresponding author), State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
EM 553641039@qq.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bi D, 2004, IEEE T IND ELECTRON, V51, P491, DOI 10.1109/TIE.2004.825277
   Borji A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.85
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710
   Borji Ali., 2012, Proceedings of the AAAI Conference on Artificial Intelligence, V26, P1529
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   EINHAUSER W, 2008, JOV, V8
   Gao CH, 2012, IEEE T IND ELECTRON, V59, P1134, DOI 10.1109/TIE.2011.2159693
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Grgic S, 2001, IEEE T IND ELECTRON, V48, P682, DOI 10.1109/41.925596
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Juang CF, 2012, IEEE T IND ELECTRON, V59, P3309, DOI 10.1109/TIE.2011.2159949
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kaczmarek AL, 2011, IEEE T IND ELECTRON, V58, P3168, DOI 10.1109/TIE.2010.2045315
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Li X, 2017, IEEE COMMUN LETT, V21, P1449, DOI 10.1109/LCOMM.2017.2672960
   Liang YN, 2017, IEEE T WIREL COMMUN, V16, P4817, DOI 10.1109/TWC.2017.2703168
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Long Y, 2017, INF SCI
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Platt JC, 2000, ADV NEUR IN, P61
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Rasiwasia N, 2012, IEEE T PATTERN ANAL, V34, P902, DOI 10.1109/TPAMI.2011.175
   Reed JM, 1996, IEEE T IND ELECTRON, V43, P346, DOI 10.1109/41.499806
   Stejic Z, 2003, IEEE T IND ELECTRON, V50, P839, DOI 10.1109/TIE.2003.817497
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Vázquez-Sánchez E, 2012, IEEE T IND ELECTRON, V59, P1397, DOI 10.1109/TIE.2011.2161651
   Wang H, 2010, LECT NOTES COMPUT SC, V6316, P126, DOI 10.1007/978-3-642-15567-3_10
   Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zeng W., 2018, IEEE T VEH TECHNOL
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang J., 2018, IEEE COMMUN MAG
   Zhang JY, 2018, IEEE T VEH TECHNOL, V67, P2766, DOI 10.1109/TVT.2017.2766784
   Zhang JY, 2018, IEEE WIREL COMMUN LE, V7, P14, DOI 10.1109/LWC.2017.2750162
   Zhang JY, 2017, IEEE T VEH TECHNOL, V66, P11404, DOI 10.1109/TVT.2017.2727078
   Zhang JY, 2017, IEEE J SEL AREA COMM, V35, P1327, DOI 10.1109/JSAC.2017.2687278
   Zhang JY, 2016, IEEE T VEH TECHNOL, V65, P8800, DOI 10.1109/TVT.2015.2504428
   Zhang JY, 2016, IEEE COMMUN LETT, V20, P842, DOI 10.1109/LCOMM.2016.2535132
   Zunino R, 2000, IEEE T IND ELECTRON, V47, P159, DOI 10.1109/41.824138
NR 53
TC 2
Z9 2
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 789
EP 794
DI 10.1016/j.jvcir.2018.08.010
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100069
DA 2024-07-18
ER

PT J
AU Zhou, H
   Chen, KJ
   Zhang, WM
   Qian, ZX
   Yu, NH
AF Zhou, Hang
   Chen, Kejiang
   Zhang, Weiming
   Qian, Zhenxing
   Yu, Nenghai
TI Targeted attack and security enhancement on texture synthesis based
   steganography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Texture image; Steganalysis; Texture synthesis; Steganography
ID STEGANALYSIS; MODELS
AB We describe an effective and efficient strategy building steganography detector for patch synthesis based steganography, one case of which is reversible texture synthesis based steganography method proposed by Wu et al. (2015). By exploiting the observation that steganography destroys optimization of matching extent between the synthetic patch and optimal candidate patch, we reconstruct the two patches from an overlapped region to extract the existence of optimality, which are distinct between cover and stego images, to form features. Support vector machine (SVM) is implemented for classification. Meanwhile, a variant of Wu et al.'s steganographic method is proposed with reinforced security, by padding redundant regions carrying no message around the periphery of the synthesized image and generating additional candidate patches to increase capacity. Experiments demonstrate that the modified algorithm offers not only better resistance against the state-of-the-art steganalysis methods and steganalytic attack we developed, but also a larger embedding capacity.
C1 [Zhou, Hang; Chen, Kejiang; Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
   [Qian, Zhenxing] Fudan Univ, Sch Comp Sci, Shanghai 201203, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Fudan University
RP Zhang, WM (corresponding author), Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
EM zh2991@mail.ustc.edu.cn; chenkj@mail.ustc.edu.cn; zhangwm@ustc.edu.cn;
   zxqian@fudan.edu.cn; ynh@ustc.edu.cn
RI Chen, Kejiang/ABD-7057-2020; Zhou, Hang/AAI-5565-2021; Qian,
   Zhenxing/AHC-9176-2022
OI Zhou, Hang/0000-0001-7860-8452; Zhang, Weiming/0000-0001-5576-6108;
   Chen, Kejiang/0000-0002-9868-3414
FU Natural Science Foundation of China [U1636201, 61572452, U1536108,
   61572308, U1736213]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1636201, Grant 61572452, Grant U1536108, Grant
   61572308 and Grant U1736213.
CR [Anonymous], 2015, LIB LARG LIN CLASS
   [Anonymous], P 12 INT C INT INF H
   Denemark T., 2014, P 6 IEEE INT WORKSH
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kodovsky J., 2010, IS T SPIE ELECT IMAG
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Otori H, 2007, LECT NOTES COMPUT SC, V4569, P146
   Otori H, 2009, IEEE COMPUT GRAPH, V29, P74, DOI 10.1109/MCG.2009.127
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Wu KC, 2015, IEEE T IMAGE PROCESS, V24, P130, DOI 10.1109/TIP.2014.2371246
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Zhou H, 2017, IEEE T IMAGE PROCESS, V26, P1623, DOI 10.1109/TIP.2017.2657886
   Zhou WB, 2017, IEEE T INF FOREN SEC, V12, P2654, DOI 10.1109/TIFS.2017.2718480
NR 24
TC 5
Z9 6
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 100
EP 107
DI 10.1016/j.jvcir.2018.04.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800009
DA 2024-07-18
ER

PT J
AU Cedillo-Hernandez, A
   Cedillo-Hernandez, M
   Miyatake, MN
   Meana, HP
AF Cedillo-Hernandez, Antonio
   Cedillo-Hernandez, Manuel
   Nakano Miyatake, Mariko
   Perez Meana, Hector
TI A spatiotemporal saliency-modulated JND profile applied to video
   watermarking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video watermarking; Visual attention; Saliency regions;
   Just-Noticeable-Distortion (JND)
ID JUST-NOTICEABLE-DISTORTION; DETECTION MODEL; IMAGE; ATTENTION; MOTION;
   INFORMATION; VISIBILITY
AB The just noticeable distortion (JND) has been considered a suitable solution for controlling the watermark strength and generating robust watermarking schemes with distortions that are below the sensitivity threshold. However, JND assumes the same attention level for all image regions, which does not reflect the behavior of an observer. Recently, several models have utilized the modulatory effect of visual attention over JND to improve the efficiency of watermarking schemes. However, most of them have focused on still images. In this paper, we propose a saliency-modulated JND profile for improving video watermarking schemes. Our method aims to adapt the watermark strength to obtain the most robust possible scheme with an imperceptible watermark. Moreover, it has the advantage of fully exploiting the spatiotemporal properties of video to minimize its perceptual redundancies and achieve low computational complexity. Experimental results show the effectiveness of our proposed method and its contributions to video watermarking process.
C1 [Cedillo-Hernandez, Antonio; Cedillo-Hernandez, Manuel; Nakano Miyatake, Mariko; Perez Meana, Hector] Inst Politecn Nacl, ESIME Culhuacan, Secc Estudios Posgrad & Invest, Santa Ana Av 1000, Mexico City 04430, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Cedillo-Hernandez, A (corresponding author), Inst Politecn Nacl, ESIME Culhuacan, Secc Estudios Posgrad & Invest, Santa Ana Av 1000, Mexico City 04430, DF, Mexico.
EM acedillo@itesm.mx; mcedilloh@ipn.mx; mnakano@ipn.mx; hmperezm@ipn.mx
RI Cedillo-Hernandez, Antonio/IYJ-5019-2023; Cedillo-Hernandez,
   Manuel/R-2154-2018
OI Cedillo-Hernandez, Manuel/0000-0002-9149-9841; Cedillo-Hernandez,
   Antonio/0000-0003-3420-6851
FU Instituto Politecnico Nacional
FX The authors would like to thank the Instituto Politecnico Nacional for
   support in the realization of this research.
CR Agarwal H., 2015, MULTIMED TOOLS APPL, P1
   AHUMADA AJ, 1992, P SOC PHOTO-OPT INS, V1666, P365
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], 2008, NIPS
   [Anonymous], 2012, Technical Report
   [Anonymous], 2007, P IEEE C COMP VIS PA
   Bandekar N., 2009, THESIS
   Bartolini F, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P450, DOI 10.1109/ICIP.1998.723523
   Bayoudh I, 2017, LECT NOTES COMPUT SC, V10617, P493, DOI 10.1007/978-3-319-70353-4_42
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cavalli F, 2002, PROCEEDINGS VIPROMCOM-2002, P227, DOI 10.1109/VIPROM.2002.1026660
   Cedillo-Hernandez A, 2014, SIGNAL PROCESS, V97, P40, DOI 10.1016/j.sigpro.2013.08.019
   Chen B, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P273, DOI 10.1109/MMSP.1998.738946
   Chen DD, 2015, CHIN CONTR CONF, P4568, DOI 10.1109/ChiCC.2015.7260346
   Chin Y.-J., 1999, CIRCUITS SYST VIDEO, V9, P438, DOI DOI 10.1109/76.754773
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   Do QB, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P281, DOI 10.1109/ICME.2008.4607426
   Duan LJ, 2015, SIGNAL PROCESS-IMAGE, V38, P45, DOI 10.1016/j.image.2015.08.005
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hernandez MC, 2015, IEICE T INF SYST, VE98D, P1702, DOI 10.1587/transinf.2015EDL8016
   *ISO IEC, 2004, 144922 ISOIEC
   ISO/IEC JTC1, 1999, 144922 ISOIEC
   ISO/IEC JTC1, 2000, 144922 ISOIEC
   Itti L., 2002, ADV NEURAL INFORM PR, V14
   Itti L., 2006, ADV NEURAL INFORM PR, V46, P1194
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Luck SJ, 1998, P NATL ACAD SCI USA, V95, P825, DOI 10.1073/pnas.95.3.825
   Moorthy A K., 2010, P SOC PHOTO-OPT INS, V7527
   Nguyen PB, 2008, IEEE INT SYM MULTIM, P418, DOI 10.1109/ISM.2008.73
   Niu YQ, 2013, SIGNAL PROCESS-IMAGE, V28, P917, DOI 10.1016/j.image.2012.07.009
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Treue S, 1999, NATURE, V399, P575, DOI 10.1038/21176
   Tsotsos JK, 2001, INT J COMPUT VISION, V45, P265, DOI 10.1023/A:1013666302043
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wan WB, 2015, ELECTRON LETT, V51, P758, DOI 10.1049/el.2014.4329
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson A.B., 1993, SID INT S, V24, P946
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
NR 55
TC 25
Z9 26
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 106
EP 117
DI 10.1016/j.jvcir.2018.02.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300011
DA 2024-07-18
ER

PT J
AU Gao, L
   Li, YS
   Ning, JF
AF Gao, Long
   Li, Yunsong
   Ning, Jifeng
TI Improved kernelized correlation filter tracking by using spatial
   regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Correlation filter; Spatial regularization; Kernel
   method
ID OBJECT TRACKING; ROBUST
AB The correlation filter based trackers have drawn much attention due to their encouraging performance on precision, robustness and speed. In this paper, we introduce the spatial regularization component into the ridge regression model used by classical kemelized correlation filter (KCF) to improve its performance. It overcomes the fact that the traditional KCF does not consider the prior spatial constraint of the feature distribution of the target. We found that, after adding the spatial regularized function, we can solve the ridge regression formula efficiently with the property of circulant matrices. In this way, we can simultaneously keep the realtime and improve the tracking performance. Finally, we evaluate the proposed SRKCF tracker on the OTB-2013 and OTB-2015 comparing with 36 trackers and our tracker achieves state-of-art. Comparing with the SRDCF which applies the spatial regularized function, our algorithm achieves comparable performance with the obvious advantages in speed.
C1 [Gao, Long; Li, Yunsong; Ning, Jifeng] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, 2 South Taibai St, Xian 710071, Shaanxi, Peoples R China.
   [Gao, Long; Li, Yunsong] Xidian Univ, Sch Telecommun Engn, Joint Lab High Speed Multisource Image Coding & P, 2 South Tathai St, Xian 710071, Shaanxi, Peoples R China.
   [Ning, Jifeng] Northwest A&F Univ, Coll Informat Engn, Angling 712100, Peoples R China.
C3 Xidian University; Xidian University; Northwest A&F University - China
RP Li, YS (corresponding author), Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, 2 South Taibai St, Xian 710071, Shaanxi, Peoples R China.
EM ysii@mail.xidian.edu.cn
RI Gao, Long/JCP-4696-2023
OI Gao, Long/0000-0003-1617-1325
FU National Nature Science Foundation of China [61571345, 91538101,
   61501346, 615023676]; 111 Project [B08038]; Shaanxi province science and
   technology innovation team project [2013KCT-02]; State Key Laboratory of
   Integrated Services Networks Foundation [ISN17-08]
FX This work is supported by the National Nature Science Foundation of
   China under Grants 61571345, 91538101, 61501346, 615023676, by the 111
   Project (B08038), by Shaanxi province science and technology innovation
   team project (2013KCT-02) and it is also supported by the State Key
   Laboratory of Integrated Services Networks Foundation (ISN17-08).
CR [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bolme D.S., 2010, IEEE C COMP VIS PATT, P1113
   Chen DP, 2013, IEEE I CONF COMP VIS, P1113, DOI 10.1109/ICCV.2013.142
   Chen W, 2016, NEUROCOMPUTING, V214, P607, DOI 10.1016/j.neucom.2016.06.048
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Grabner H., 2008, EUR C COMP VIS, P34
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques J, 2012, EUR C COMP VIS, P702
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Hong CQ, 2015, INFORM SCIENCES, V320, P395, DOI 10.1016/j.ins.2015.03.032
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Song HH, 2017, ELECTRON LETT, V53, P20, DOI 10.1049/el.2016.3011
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
NR 34
TC 12
Z9 13
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 74
EP 82
DI 10.1016/j.jvcir.2017.11.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700008
DA 2024-07-18
ER

PT J
AU Yan, XH
   Lu, YL
   Liu, LT
   Wang, S
AF Yan, Xuehu
   Lu, Yuliang
   Liu, Lintao
   Wang, Shen
TI Partial secret image sharing for (<i>k</i>,<i>n</i>) threshold based on
   image inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Partial secret image sharing; Image inpainting;
   Linear congruence; Color image; Lossless recovery
ID VISUAL CRYPTOGRAPHY; QUALITY; SCHEME
AB The traditional (k,n) threshold secret image sharing (SIS) schemes dealt with the full secret image neglecting the possible situation that only part of the secret image needs protection. However, in some applications, only target part of the secret image may need to be protected while other parts may be not in a full image. In this paper, we consider the partial secret image sharing (PSIS) issue as well as propose a PSIS scheme for (k,n) threshold based on image inpainting and linear congruence (LC)-based SIS. The full secret image including the secret target part and other parts will be recovered by collecting any k or more shadow images, which can be further reconstructed losslessly by adding all the inpainted meaningful shadow images. Furthermore, the proposed scheme can share irregular target in a progressive way. Experiments are conducted to evaluate the efficiency of the proposed scheme.
C1 [Yan, Xuehu; Lu, Yuliang; Liu, Lintao] Hefei Elect Engn Inst, Hefei 230037, Anhui, Peoples R China.
   [Wang, Shen] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Yan, XH (corresponding author), Hefei Elect Engn Inst, Hefei 230037, Anhui, Peoples R China.
EM publictiger@126.com
RI Yan, Xuehu/AAG-1718-2022; Yan, Xuehu/AFK-3139-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720; Lu,
   Yuliang/0000-0002-8502-9907
FU National Natural Science Foundation of China [61602491]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work is supported by the National Natural
   Science Foundation of China (Grant No. 61602491).
CR Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   [Anonymous], 2016, J REAL TIME IMAGE PR
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Fu Z.-x., 2014, VISUAL CRYPTOGRAPHY, P109
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu L. B., 2016, P 10 EUROPEAN C ANTE, P1
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   WANG S, 2012, RES J APPL SCI ENG T, V4, P4962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Xuehu Yan, 2018, Multimedia Tools and Applications, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2016, J REAL-TIME IMAGE PR, V12, P483, DOI 10.1007/s11554-015-0511-9
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 29
TC 16
Z9 17
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 135
EP 144
DI 10.1016/j.jvcir.2017.11.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700014
DA 2024-07-18
ER

PT J
AU Chen, BJ
   Qi, XM
   Sun, XM
   Shi, YQ
AF Chen, Beijing
   Qi, Xiaoming
   Sun, Xingming
   Shi, Yun-Qing
TI Quaternion pseudo-Zernike moments combining both of RGB information and
   depth information for color image splicing detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quaternion; Splicing detection; Pseudo-Zernike moment; Back-propagation
   neural network; Depth information
ID FAST COMPUTATION; FOURIER-TRANSFORMS; FACE RECOGNITION; DCT;
   HYPERCOMPLEX; ALGORITHM
AB The quaternion representation (QR) used in current quaternion-based color image processing creates redundancy when representing a color image of three components by a quaternion matrix having four components. In this paper, both RGB and depth (RGB-D) information are considered to improve QR for efficiently representing RGB-D images. The improved QR fully utilizes the four-dimensional quaternion domain. Using this improved QR, firstly we define the new quaternion pseudo-Zernike moments (NQPZMs) and then propose an efficient computational algorithm for NQPZMs through the conventional pseudo-Zernike moments (PZMs). Finally, we propose an algorithm for color image splicing detection based on the NQPZMs and the quaternion back-propagation neural network (QBPNN). Experimental results on four public datasets (DVMM, CASIA v1.0 and v2.0, Wild Web) demonstrate that the proposed splicing detection algorithm can achieve almost 100% accuracy with the appropriate feature dimensionality and outperforms 14 existing algorithms. Moreover, the comparison of six color spaces (RGB, HSI, HSV, YCbCr, YUV, and YIQ) shows that the proposed algorithm using YCbCr color space has the overall best performance in splicing detection. (c) 2017 Published by Elsevier Inc.
C1 [Chen, Beijing; Qi, Xiaoming; Sun, Xingming; Shi, Yun-Qing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Chen, Beijing; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Jiangsu, Peoples R China.
   [Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; New Jersey Institute of
   Technology
RP Shi, YQ (corresponding author), New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
EM shi@njit.edu
RI Shi, Yun/JWP-3360-2024; Sun, Xingming/AAD-1866-2019; zhen,
   wang/KBA-3844-2024
FU NSFC [61572258, 61232016, 61572257, 61602253]; Natural Science
   Foundation of Jiangsu Province of China [BK20151530, BK20150925]; PAPD
   fund; China Scholarship Council; Qing Lan Project
FX This work was supported by the NSFC under Grants 61572258, 61232016,
   61572257, and 61602253, the Natural Science Foundation of Jiangsu
   Province of China under Grants BK20151530, and BK20150925, the PAPD
   fund, the China Scholarship Council, and sponsored by Qing Lan Project.
CR Al-Rawi MS, 2010, J REAL-TIME IMAGE PR, V5, P3, DOI 10.1007/s11554-009-0118-0
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   [Anonymous], 2032004 COL U
   [Anonymous], MULTIMED TOOLS APPL
   Assefa D, 2016, LECT NOTES ARTIF INT, V9876, P231, DOI 10.1007/978-3-319-45246-3_22
   Assefa D, 2011, SIGNAL PROCESS, V91, P1887, DOI 10.1016/j.sigpro.2011.02.011
   Bai J, 2015, NEUROCOMPUTING, V165, P280, DOI 10.1016/j.neucom.2015.03.017
   Browatzki B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1189, DOI 10.1109/ICCVW.2011.6130385
   Chan WL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P996
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2017, NEUROCOMPUTING, V266, P293, DOI 10.1016/j.neucom.2017.05.047
   Chen BJ, 2015, IEEE T SIGNAL PROCES, V63, P5424, DOI 10.1109/TSP.2015.2451107
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Cheng YH, 2015, COMPUT VIS IMAGE UND, V139, P149, DOI 10.1016/j.cviu.2015.05.007
   Chong CW, 2003, INT J PATTERN RECOGN, V17, P1011, DOI 10.1142/S0218001403002769
   Dong Jing., 2011, CASIA TAMPERED IMAGE
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Goh J, 2015, INT J ELECTRON SECUR, V7, P76, DOI 10.1504/IJESDF.2015.067996
   Goswami G, 2014, IEEE T INF FOREN SEC, V9, P1629, DOI 10.1109/TIFS.2014.2343913
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Han JG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023031
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hussain M, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015400163
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Le Bihan N, 2003, IEEE IMAGE PROC, P809
   Li C, 2015, LECT NOTES ARTIF INT, V9227, P297, DOI 10.1007/978-3-319-22053-6_32
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lillo I, 2017, IMAGE VISION COMPUT, V59, P63, DOI 10.1016/j.imavis.2016.11.004
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Matsui N, 2004, J INTELL FUZZY SYST, V15, P149
   Moghaddasi Z, 2014, SCI WORLD J, DOI 10.1155/2014/606570
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Nitta T., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P2753, DOI 10.1109/ICNN.1995.488166
   Ouyang JL, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978572
   Pei SC, 2003, IEEE IMAGE PROC, P805
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Sun YF, 2011, PATTERN RECOGN LETT, V32, P597, DOI 10.1016/j.patrec.2010.11.004
   Tang JH, 2015, IEEE T MULTIMEDIA, V17, P1899, DOI 10.1109/TMM.2015.2476660
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
NR 45
TC 38
Z9 39
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 283
EP 290
DI 10.1016/j.jvcir.2017.08.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800023
DA 2024-07-18
ER

PT J
AU Gouiffès, M
   Terán, ARMY
   Lacassagne, L
AF Gouiffes, Michele
   Mier y Teran, Andres Romero
   Lacassagne, Lionel
TI Color enhanced local binary patterns in covariance matrices descriptors
   (ELBCM)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Covariance matrices; Region descriptors; LBP; Image matching; Texture;
   Color; Object retrieval; Person re-identification
ID CLASSIFICATION
AB This paper proposes a new version of LBP and its inclusion into covariance region descriptors for image matching and recognition. Starting from the non-rotation invariant uniform LBP (called nriLBP), the pattern is described by the cosine and sine values of the angular portion defined by the '1's. The use of this four-value vector leads to a better resilience of the feature to noise and small neighborhood rotations. Several color versions of this feature are proposed. For region description, these local features are included in covariance matrices, noted ELBCM for Enhanced-LBP Covariance Matrix. Experimental evaluations confirm the relevance of the proposed models on three databases designed for texture analysis, object retrieval and person re-identification. A study is also made on the impact of the colorspace included in the covariance descriptor and used for LBP definition. The experiments show that ELBCM has better recognition performance than the 12 other descriptors tested.
C1 [Gouiffes, Michele; Mier y Teran, Andres Romero] Univ Paris Saclay, Univ Paris Sud, CNRS, LIMSI, Paris, France.
   [Lacassagne, Lionel] UPMC Univ Paris 06, Sorbonne Univ, CNRS UMR 7606, LIP6, Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS); Sorbonne Universite
RP Gouiffès, M (corresponding author), Univ Paris Saclay, Univ Paris Sud, CNRS, LIMSI, Paris, France.
EM michele.gouiffes@limsi.fr; andres.romero@gmail.com;
   lionel.lacassagne@lip6.fr
CR Bak S, 2014, ADV COMPUT VIS PATT, P71, DOI 10.1007/978-1-4471-6296-4_4
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chao Zhu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3065, DOI 10.1109/ICPR.2010.751
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Choi JY, 2010, IEEE IMAGE PROC, P4541, DOI 10.1109/ICIP.2010.5653653
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Forstner W., 1999, Quo Vadis Geodesia, P113
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Gouiffès M, 2012, COMPUT VIS IMAGE UND, V116, P896, DOI 10.1016/j.cviu.2012.04.002
   Guo S, 2011, 2011 IET 4TH INTERNATIONAL CONFERENCE ON WIRELESS, MOBILE & MULTIMEDIA NETWORKS (ICWMMN 2011), P237, DOI 10.1049/cp.2011.0997
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71
   Laguzet F, 2015, J REAL-TIME IMAGE PR, V10, P403, DOI 10.1007/s11554-013-0358-x
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Li PH, 2012, LECT NOTES COMPUT SC, V7574, P469, DOI 10.1007/978-3-642-33712-3_34
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Z, 2017, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2017.7952478
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nielsen F., 2012, Matrix Information Geometry
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Romero A., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P277, DOI 10.1109/ICSIPA.2011.6144104
   Romero A., 2012, AS C COMP VIS 2012 A
   Romero A., 2013, ACM INT C P SERIES
   Said S, 2015, LECT NOTES COMPUT SC, V9389, P371, DOI 10.1007/978-3-319-25040-3_40
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Tou JY, 2009, LECT NOTES COMPUT SC, V5507, P745, DOI 10.1007/978-3-642-03040-6_91
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Varior RR, 2016, IEEE T IMAGE PROCESS, V25, P3395, DOI 10.1109/TIP.2016.2531280
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yao J, 2011, COMPUT VIS IMAGE UND, V115, P1414, DOI 10.1016/j.cviu.2011.06.002
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 43
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 447
EP 458
DI 10.1016/j.jvcir.2017.09.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800038
DA 2024-07-18
ER

PT J
AU Wu, J
   Feng, L
   Liu, SL
   Sun, MX
AF Wu, Jun
   Feng, Lin
   Liu, Shenglan
   Sun, Muxin
TI Image retrieval framework based on texton uniform descriptor and
   modified manifold ranking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Texton uniform descriptor; Modified manifold ranking;
   Landmark
ID COLOR; SCALE
AB Image representation and ranking are crucial parts in image retrieval. These two steps are independently constructed in most retrieval models, but the compatibility between descriptors and ranking algorithms play an important role. Inspired by human vision perception and manifold learning, we propose a novel image retrieval framework in this paper. We first propose an image representation called texton uniform descriptor, and then illustrate the preservation of the intrinsic manifold structure through visualizing the distribution of image representations on the two-dimensional manifold. This characteristic provides the foundation for subsequent manifold-based ranking. To further improve the efficiency in image retrieval, we propose modified manifold ranking (MMR) which aims at selecting small-scale images randomly as landmarks to propagate adjacent similarity among images iteratively. The extensive experiments in four public datasets demonstrate that our framework has better performance than other state-of-the-art methods in image retrieval. (c) 2017 Published by Elsevier Inc.
C1 [Wu, Jun; Feng, Lin; Sun, Muxin] Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Liaoning, Peoples R China.
   [Feng, Lin] Dalian Univ Technol, Sch Comp Sci & Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Liaoning, Peoples R China.
   [Liu, Shenglan] Dalian Univ Technol, Sch Control Sci & Engn, Fac Elect Informat & Elect Engn, Dalian 116024, Liaoning, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University of Technology
RP Feng, L (corresponding author), Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Liaoning, Peoples R China.
EM fenglin@dlut.edu.cn
FU National Natural Science Foundation of P.R. China [61370200, 61210009];
   China Postdoctoral Science Foundation [ZX20150629]
FX This work was supported by National Natural Science Foundation of P.R.
   China (61370200, 61210009) and China Postdoctoral Science Foundation
   (ZX20150629).
CR Androutsos D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P770, DOI 10.1109/ICIP.1998.723652
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brin S., 1998, P 7 WORLD WID WEB C
   Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89
   Chen JH, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P443, DOI 10.1145/2671188.2749287
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng Y, 2014, IEEE T CYBERNETICS, V44, P1924, DOI 10.1109/TCYB.2014.2300192
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Feng L, 2015, J VIS COMMUN IMAGE R, V33, P104, DOI 10.1016/j.jvcir.2015.09.002
   Fu Y, 2008, COMPUT VIS IMAGE UND, V110, P390, DOI 10.1016/j.cviu.2007.09.017
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   He J., 2004, P 12 ANN ACM INT C M, P9, DOI DOI 10.1145/1027527.1027531
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang SH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P52, DOI 10.1145/2964284.2967182
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Koffka Kurt, 2013, PRINCIPLES GESTALT P
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Lin Z, 2010, LECT NOTES COMPUT SC, V6316, P294, DOI 10.1007/978-3-642-15567-3_22
   Liu GH, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P506, DOI 10.1109/FSKD.2016.7603225
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu Y., 2016, ICPR
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rao LK, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0044-z
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xia Y, 2014, PROC SPIE, V9069, DOI 10.1117/12.2049916
   Xiao J, 2009, IEEE INT CON MULTI, P314, DOI 10.1109/ICME.2009.5202498
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Yu FX, 2011, ELECTRON LETT, V47, P100, DOI 10.1049/el.2010.3232
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
NR 45
TC 9
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 78
EP 88
DI 10.1016/j.jvcir.2017.08.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800007
DA 2024-07-18
ER

PT J
AU Feng, BW
   Weng, J
   Lu, W
   Pei, B
AF Feng, Bingwen
   Weng, Jian
   Lu, Wei
   Pei, Bei
TI Steganalysis of content-adaptive binary image data hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binary image; Content-adaptive data hiding; Steganography; Steganalysis;
   l-shape pattern
ID AUTHENTICATION
AB Most state-of-the-art binary image data hiding methods concentrate the embedding changes on the centers of l-shape patterns. This embedding criterion, however, introduces an unbalanced modification on boundary structures. This paper proposes a steganalytic scheme to detect recently developed content adaptive binary image data hiding by exploiting the embedding effect associated with the l-shape pattern-based embedding criterion. We first assess how changing l-shape patterns affects the distribution of a special 4 x 3 sized pattern. Based on the assessment, 4 classes of patterns that model the distribution of two pixels oriented the direction of pattern changing are employed to define a 32-dimensional steganalytic feature set. Experimental results show that, despite of the low dimensionality, the proposed steganalytic features can effectively detect state-of-the-art binary image data hiding schemes, especially those pattern-tracing-based approaches. (C) 2017 Published by Elsevier Inc.
C1 [Feng, Bingwen; Weng, Jian] Jinan Univ, Dept Comp Sci, Guangzhou 510632, Guangdong, Peoples R China.
   [Lu, Wei] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Pei, Bei] Minist Publ Secur, Key Lab Informat Network Secur, Shanghai 200000, Peoples R China.
C3 Jinan University; Sun Yat Sen University; Ministry of Public Security
   (China)
RP Weng, J (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou 510632, Guangdong, Peoples R China.; Pei, B (corresponding author), Minist Publ Secur, Key Lab Informat Network Secur, Shanghai 200000, Peoples R China.
EM bingwfeng@gmail.com; cryptjweng@gmail.com; luwei3@mail.sysu.edu.cn;
   peibei@stars.org.cn
OI Weng, Jian/0000-0003-4067-8230
FU Natural Science Foundation of Guangdong [2016A030313350]; Special Funds
   for Science and Technology Development of Guangdong [2016KZ010103]; Key
   Lab of Information Network Security, Ministry of Public Security
FX This work is supported by the Natural Science Foundation of Guangdong
   (No. 2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), and the Key Lab of
   Information Network Security, Ministry of Public Security.
CR [Anonymous], ELECT IMAGING INT SO
   [Anonymous], DATA HIDING BINARY T
   [Anonymous], 2011, INT J COMPUT SCI ENG
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Cheng J, 2005, IEEE INT SYMP CIRC S, P4405
   Cheng J, 2005, INT CONF ACOUST SPEE, P689
   Cheng J., 2005, IEEE INT C IMAGE PRO, pIII
   Cheng J, 2007, IEEE T IMAGE PROCESS, V16, P1691, DOI 10.1109/TIP.2007.896619
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P683, DOI 10.1109/ARES.2010.65
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P653, DOI 10.1109/ARES.2010.66
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goljan M, 2014, IEEE INT WORKS INFOR, P185, DOI 10.1109/WIFS.2014.7084325
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Jiang M, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P883, DOI 10.1109/ICME.2004.1394342
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Kodovsky J, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P69
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Meng Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1441, DOI 10.1109/ICPR.2010.356
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P63, DOI 10.1007/978-3-642-36373-3_5
   Tan SQ, 2012, IEEE SIGNAL PROC LET, V19, P336, DOI 10.1109/LSP.2012.2194702
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Yang HJ, 2008, IEEE T MULTIMEDIA, V10, P339, DOI 10.1109/TMM.2008.917404
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
NR 33
TC 24
Z9 24
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 119
EP 127
DI 10.1016/j.jvcir.2017.01.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500011
DA 2024-07-18
ER

PT J
AU Lee, YG
AF Lee, Yun Gu
TI Novel video stabilization for real-time optical character recognition
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video stabilization; Optical character recognition; Real-time
ID QUALITY ASSESSMENT
AB This paper presents a novel video stabilization algorithm for real-time optical character recognition (OCR) applications. The proposed method generates output frames in order to stabilize the position of a target word that will be recognized by the OCR application. Unlike in conventional algorithms, in the proposed algorithm, a causal low pass filter is not applied to the trajectory of the target word for reducing the high frequency component of camera motion. The proposed algorithm directly calculates the stable position of the word using two forces: the force used to pull the target word to the center of an output frame and a back force used to return the center of an output frame to the center of an input frame. Hence, the proposed algorithm significantly minimizes the time take to respond to sudden camera movement. Although the proposed method may not outperform state-of-the-art video stabilization in terms of video stability, the proposed technique is much more appropriate for real-time OCR applications than the conventional techniques in terms of accuracy, computational cost, processing delay, and the time taken to respond to sudden camera movement. Simulation results prove the superiority of the proposed method over conventional techniques for real-time OCR applications. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Lee, Yun Gu] Kwangwoon Univ, Dept Comp Sci & Engn, Kwangwoonro 20,Nowongu, Seoul 139701, South Korea.
C3 Kwangwoon University
RP Lee, YG (corresponding author), Kwangwoon Univ, Dept Comp Sci & Engn, Kwangwoonro 20,Nowongu, Seoul 139701, South Korea.
EM harmony96@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [NRF-2014R1A1A2054105]
FX This present research has been conducted by the Research Grant of
   Kwangwoon University in 2015. This research was supported by Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education, Science and Technology
   (NRF-2014R1A1A2054105).
CR [Anonymous], 2012, P 2012 IEEE INT C CO
   [Anonymous], 2010, J COMPUTING
   Baker S, 2010, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2010.5539932
   Cho WH, 2007, IEEE T CONSUM ELECTR, V53, P979, DOI 10.1109/TCE.2007.4341576
   Chun H.J.J.B., 2009, IEEE T CONSUM ELECTR, V54, P1479
   Gómez L, 2014, INT C PATT RECOG, P3110, DOI 10.1109/ICPR.2014.536
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jin J. S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P32, DOI 10.1109/6979.869019
   Lee Y., 2014, J ELECTRON IMAGING
   Lee YG, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.093101
   Liang CK, 2008, IEEE T IMAGE PROCESS, V17, P1323, DOI 10.1109/TIP.2008.925384
   Liang GZ, 2015, IEEE T IMAGE PROCESS, V24, P4488, DOI 10.1109/TIP.2015.2465169
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Wang SQ, 2016, IEEE T IMAGE PROCESS, V25, P3838, DOI 10.1109/TIP.2016.2573597
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Zhang JT, 2014, IEEE IJCNN, P1197, DOI 10.1109/IJCNN.2014.6889596
NR 19
TC 4
Z9 4
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 148
EP 155
DI 10.1016/j.jvcir.2017.01.027
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600014
DA 2024-07-18
ER

PT J
AU Xie, ZP
AF Xie, Zhipeng
TI A primal-dual method with linear mapping for a saddle point problem in
   image deblurring
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total variational image deblurring; Sub-differential operator;
   Prediction and correction; Pairwise primal-dual stepsize
ID ALTERNATING DIRECTION METHOD; CONVERGENCE ANALYSIS; ALGORITHMS;
   OPTIMIZATION
AB In this paper, a simple primal-dual method named PDL is proposed for a convex concave saddle problem and applied to total variational image deblurring. Introduction of linear mapping on proximal term relaxes convergence requirement on pairwise primal-dual stepsize. Simple proof is presented for 0(1/N) convergence rate in ergodic sense. Experiments show that performance of PDL is comparable with proximal PDHG (Zhu et al., 2010; Bonettini and Ruggiero, 2012) and PDCP (Chambolle and Pock, 2011) on Gaussian or Salt-Pepper noisy image deblurring. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xie, Zhipeng] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Fujian, Peoples R China.
C3 Huaqiao University
RP Xie, ZP (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Fujian, Peoples R China.
EM pxie@hqu.edu.cn
FU PHD project of Huaqiao University in China [13BS418]
FX This work is partially supported by PHD project 13BS418 of Huaqiao
   University in China.
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Almeida MSC, 2013, IEEE T IMAGE PROCESS, V22, P3074, DOI 10.1109/TIP.2013.2258354
   [Anonymous], CAM REPORTS
   Bonettini S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/9/095001
   Bonettini S, 2012, J MATH IMAGING VIS, V44, P236, DOI 10.1007/s10851-011-0324-9
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bredies K, 2015, J MATH IMAGING VIS, V52, P317, DOI 10.1007/s10851-015-0564-1
   Bredies Kristian, SIAM J NUMER ANAL, V53
   Chambolle A, 2016, MATH PROGRAM, V159, P253, DOI 10.1007/s10107-015-0957-3
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chan Raymond H., INERTIAL PRIMAL DUAL
   Chen CH, 2015, SIAM J OPTIMIZ, V25, P2120, DOI 10.1137/140980910
   CHEN G, 1994, MATH PROGRAM, V64, P81, DOI 10.1007/BF01582566
   Drori Y, 2015, OPER RES LETT, V43, P209, DOI 10.1016/j.orl.2015.02.001
   Eckstein J., MATH PROGRAM, V55
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   He BS, 2015, NUMER MATH, V130, P567, DOI 10.1007/s00211-014-0673-6
   He BS, 2014, SIAM J IMAGING SCI, V7, P2526, DOI 10.1137/140963467
   He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936
   He BS, 2012, SIAM J IMAGING SCI, V5, P119, DOI 10.1137/100814494
   Nemirovski A, 2004, SIAM J OPTIMIZ, V15, P229, DOI 10.1137/S1052623403425629
   Ng MK, 2011, SIAM J SCI COMPUT, V33, P1643, DOI 10.1137/100807697
   Shefi R, 2014, SIAM J OPTIMIZ, V24, P269, DOI 10.1137/130910774
   Tseng P, 1997, SIAM J OPTIMIZ, V7, P951, DOI 10.1137/S1052623495279797
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Yang TB, 2015, MACH LEARN, V98, P369, DOI 10.1007/s10994-014-5436-1
   Zhang BX, 2016, J VIS COMMUN IMAGE R, V38, P814, DOI 10.1016/j.jvcir.2016.04.025
   Zhang XQ, 2011, J SCI COMPUT, V46, P20, DOI 10.1007/s10915-010-9408-8
   Zhu MQ, 2010, COMPUT OPTIM APPL, V47, P377, DOI 10.1007/s10589-008-9225-2
NR 31
TC 3
Z9 4
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 112
EP 120
DI 10.1016/j.jvcir.2016.11.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200009
DA 2024-07-18
ER

PT J
AU Marcelino, S
   Soares, S
   de Faria, SMM
   Assuncao, P
AF Marcelino, Sylvain
   Soares, Salviano
   de Faria, Sergio M. M.
   Assuncao, Pedro
TI Reconstruction of lost depth data in multiview video-plus-depth
   communications using geometric transforms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview video-plus-depth; Depth map reconstruction; Depth loss; Error
   concealment; Geometric transforms
ID ERROR CONCEALMENT
AB This paper addresses depth data recovery in multiview video-plus-depth communications affected by transmission errors and/or packet loss. The novel aspects of the proposed method rely on the use of geometric transforms and warping vectors, capable of capturing complex motion and view-dependent deformations, which are not efficiently handled by traditional motion and/or disparity compensation methods. By exploiting the geometric nature of depth information, a region matching approach combined with depth contour reconstruction is devised to achieve accurate interpolation of arbitrary shapes within lost regions of depth maps. The simulation results show that, for different packet loss rates, up to 20%, the depth maps recovered by the proposed method produce virtual views with better quality than existing methods based on motion information and spatial interpolation. An average PSNR gain of 1.48 dB is obtained in virtual views synthesised from depth maps using the proposed method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Marcelino, Sylvain; Soares, Salviano] Univ Tras Os Montes & Alto Douro, ECT Engn Dept, Vila Real, Portugal.
   [Soares, Salviano] IEETA, UA Campus, Aveiro, Portugal.
   [Marcelino, Sylvain; de Faria, Sergio M. M.; Assuncao, Pedro] Inst Telecomunicacoes, Leiria, Portugal.
   [de Faria, Sergio M. M.; Assuncao, Pedro] Inst Politecn Leiria, ESTG, Leiria, Portugal.
C3 University of Tras-os-Montes & Alto Douro; Universidade de Aveiro;
   Polytechnic Institute of Leiria
RP Assuncao, P (corresponding author), Inst Telecomunicacoes, IPLeiriai ESTG, Campus 2, P-2401911 Leiria, Portugal.
EM amado@co.it.pt
RI Soares, Salviano Pinto/ABC-8044-2020; Assuncao, Pedro A.
   Amado/A-4827-2017; Faria, Sérgio/C-5245-2011; Pinto Soares,
   Salviano/AAD-6332-2019
OI Soares, Salviano Pinto/0000-0001-5862-5706; Assuncao, Pedro A.
   Amado/0000-0001-9539-8311; Faria, Sérgio/0000-0002-0993-9124; Pinto
   Soares, Salviano/0000-0001-5862-5706
FU Fundacao para a Ciencia e Tecnologia, Portugal [SFRH/BD/64988/2009,
   UID/EEA/50008/2013]; Project 3DVQM; Fundação para a Ciência e a
   Tecnologia [SFRH/BD/64988/2009] Funding Source: FCT
FX This work was supported by the Fundacao para a Ciencia e Tecnologia,
   Portugal under Ph.D. Grant SFRH/BD/64988/2009 and R&D Unit
   UID/EEA/50008/2013, Project 3DVQM.
CR [Anonymous], 2011, P 3DTV C MAY
   [Anonymous], IWSSIP 16 18 JUN
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Chung TY, 2011, IEEE T CONSUM ELECTR, V57, P1336, DOI 10.1109/TCE.2011.6018892
   Chung TY, 2010, IEEE IMAGE PROC, P441, DOI 10.1109/ICIP.2010.5654236
   GHANBARI M, 1995, SIGNAL PROCESS-IMAGE, V7, P567, DOI 10.1016/0923-5965(95)00031-2
   Guo K, 2011, OPT ENG, V50, DOI 10.1117/1.3572137
   Hewage C., 2011, Multimedia and Expo (ICME), 2011 IEEE International Conference on, P1
   Hewage Chaminda T. E. R., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P149, DOI 10.1109/3DTV.2008.4547830
   Hou Y, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P176, DOI 10.1109/ChinaSIP.2015.7230386
   Jain R., 2010, TECH REP
   Kuan YK, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-38
   Lee P.-J., 2015, INT J FUZZY SYST, P1
   Lie WN, 2015, J VIS COMMUN IMAGE R, V32, P237, DOI 10.1016/j.jvcir.2015.08.012
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Liu SJ, 2008, IEEE INT SYMP CIRC S, P3470, DOI 10.1109/ISCAS.2008.4542206
   Liu XM, 2011, PROCEEDINGS OF CHINA DISPLAY/ASIA DISPLAY 2011, P208, DOI 10.1109/ISCE.2011.5973815
   Liu YQ, 2010, IEEE T CIRC SYST VID, V20, P600, DOI 10.1109/TCSVT.2009.2035838
   Lykourgiotis A, 2014, IEEE WIREL COMMUN, V21, P62, DOI 10.1109/MWC.2014.6845050
   Marcelino S, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P253, DOI 10.1109/PCS.2012.6213340
   Merkle P., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P245, DOI 10.1109/3DTV.2008.4547854
   Micallef BW, 2010, IEEE MEDITERR ELECT, P1215, DOI 10.1109/MELCON.2010.5475912
   Olivares J., 2006, INT C FIELD PROGRAMM, P1
   Stankiewicz O., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P498, DOI 10.1109/PCS.2010.5702546
   Tanimoto M., M16090 ISOIEC JTC1SC
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Doan VH, 2013, IEEE INT SYMP CIRC S, P2900, DOI 10.1109/ISCAS.2013.6572485
   Xiang XG, 2014, INT CONF INSTR MEAS, P857, DOI 10.1109/IMCCC.2014.180
   Xiang XG, 2011, INT CONF ACOUST SPEE, P849
   Yan B., 2012, IEEE T MULTIM
   Yin P, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P853
   Zhang YH, 2014, J VIS COMMUN IMAGE R, V25, P916, DOI 10.1016/j.jvcir.2014.02.010
NR 32
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 589
EP 599
DI 10.1016/j.jvcir.2016.07.024
PN B
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600016
DA 2024-07-18
ER

PT J
AU Pereira, EM
   Cardoso, JS
   Morla, R
AF Pereira, Eduardo M.
   Cardoso, Jaime S.
   Morla, Ricardo
TI Long-range trajectories from global and local motion representations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Long trajectories; Motion representations; Flow information
ID FLOW
AB Motion is a fundamental cue for scene analysis and human activity understanding in videos. It can be encoded in trajectories for tracking objects and for action recognition, or in form of flow to address behavior analysis in crowded scenes. Each approach can only be applied on limited scenarios. We propose a motion-based system that represents the spatial and temporal features of the flow in terms of I ong-range trajectories. The novelty resides on the system formulation, its generic approach to handle scene variability and motion variations, motion integration from local and global representations, and the resulting long-range trajectories that overcome trajectory-based approach problems. We report the results and conclusions that state its pertinence on different scenarios, comparing and correlating the extracted trajectories of individual pedestrians, manually annotated. We also propose an evaluation framework and stress the diverse system characteristics that can be used for human activity tasks, namely on motion segmentation. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pereira, Eduardo M.] INESC TEC, Campus FEUP,Rua Dr Roberto Frias, P-4200465 Oporto, Portugal.
   Univ Porto, Fac Engn, Rua Dr Roberto Frias S-N, P-4200465 Oporto, Portugal.
C3 INESC TEC; Universidade do Porto
RP Pereira, EM (corresponding author), INESC TEC, Campus FEUP,Rua Dr Roberto Frias, P-4200465 Oporto, Portugal.
EM ejmp@inesctec.pt; jaime.cardoso@inesctec.pt; ricardo.morla@fe.up.pt
RI Cardoso, Jaime S/I-3286-2013
OI Cardoso, Jaime S/0000-0002-3760-2473; Morla, Ricardo/0000-0002-5162-3019
FU FCT - Fundacao para a Ciencia e Tecnologia (Portuguese Foundation for
   Science and Technology) [SFRH/BD/51430/2011]; Fundação para a Ciência e
   a Tecnologia [SFRH/BD/51430/2011] Funding Source: FCT
FX The first author would like to thank FCT - Fundacao para a Ciencia e
   Tecnologia (Portuguese Foundation for Science and Technology) for the
   financial support for the PhD grant with reference SFRH/BD/51430/2011.
CR Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1
   Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], TECHNOMETRICS
   [Anonymous], VARIATIONAL APPROACH
   [Anonymous], 2010, LECT NOTES COMPUTER
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], 2007, CVPR
   [Anonymous], LONGER LONG RANGE MO
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], APPL STAT
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hu M, 2008, INT C PATT RECOG, P9
   Hubert M, 2008, COMPUT STAT DATA AN, V52, P5186, DOI 10.1016/j.csda.2007.11.008
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jobard B, 2001, IEEE VISUAL, P53, DOI 10.1109/VISUAL.2001.964493
   Jobard Bruno., 1997, VISUALIZATION SCI CO, P43, DOI DOI 10.1007/978-3-7091-6876-9_5
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Mebarki A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P479
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Ozturk Ovgu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3533, DOI 10.1109/ICPR.2010.862
   Pereira EM, 2013, LECT NOTES COMPUT SC, V7887, P340
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Sun J, 2010, IEEE INT CON MULTI, P322, DOI 10.1109/ICME.2010.5583046
   THOMPSON R, 1985, J ROY STAT SOC B MET, V47, P53
   Verma V, 2000, IEEE VISUAL, P163, DOI 10.1109/VISUAL.2000.885690
   Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9
   Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6
   Weinkauf T, 2010, IEEE T VIS COMPUT GR, V16, P1225, DOI 10.1109/TVCG.2010.198
   Wu KQ, 2010, IEEE T VIS COMPUT GR, V16, P791, DOI 10.1109/TVCG.2009.206
   Zhao XM, 2012, LECT NOTES COMPUT SC, V7573, P315, DOI 10.1007/978-3-642-33709-3_23
   Zhou BL, 2012, LECT NOTES COMPUT SC, V7573, P857, DOI 10.1007/978-3-642-33709-3_61
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 42
TC 2
Z9 2
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 265
EP 287
DI 10.1016/j.jvcir.2016.06.020
PN A
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500024
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, T
   Zhang, YN
   Yang, T
   Sahli, H
AF Chen, Ting
   Zhang, Yanning
   Yang, Tao
   Sahli, Hichem
TI Tracking with dynamic weighted compressive model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive tracking; Dynamic weighted compressive model; Random matrix
ID MULTISCALE SHIP TRACKING; ROBUST VISUAL TRACKING; OBJECT TRACKING
AB Fast compressive tracking utilizes a very sparse measurement matrix to capture the appearance model of targets. Such model performs well when the tracked targets are well defined. However, when the targets are low-grain, low-resolution, or small, a single fixed size sparse measurement matrix is not sufficient enough to preserve the image structure of the target. In this work, we propose a multi-sparse measurement matrices scheme along with a weight map to select the best measurement matrix that preserves the image structure of the targets during tracking. The weight map combines a contrast weight and a feature weight to efficiently characterize the target appearance and location. Moreover, a dispersion function is used for the online update of the target template, allowing tracking both the location and scale of the target. Extensive experimental results have demonstrated that the proposed DWCM tracking algorithm outperforms several state-of-the-art tracking algorithms as well as compressive tracker. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Ting; Zhang, Yanning; Yang, Tao; Sahli, Hichem] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
   [Chen, Ting; Sahli, Hichem] Vrije Univ Brussel, AVSP Lab, Dept Elect & Informat ETRO, Brussels, Belgium.
   [Sahli, Hichem] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
C3 Northwestern Polytechnical University; Vrije Universiteit Brussel; IMEC
RP Chen, T (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.; Chen, T (corresponding author), Vrije Univ Brussel, AVSP Lab, Dept Elect & Informat ETRO, Brussels, Belgium.
EM chentingnwpu@163.com
OI Sahli, Hichem/0000-0002-1774-2970
FU CSC-VUB scholarship [201406290121]; National Natural Science Foundation
   of China [61231016, 61272288, 61303123, 61502364]; Northwestern
   Polytechnical University (NPU) New AoXiang Star [G2015KY0301]; NPU New
   People and New Directions Foundation [13GH014604]; Natural Science
   Foundation of Shaanxi Province [2015JQ6256]; Fundamental Research Funds
   for the Central Universities [3102015AX007]
FX This work is supported by the CSC-VUB scholarship (Grant No.
   201406290121), the National Natural Science Foundation of China (Nos.
   61231016, 61272288, 61303123, 61502364), the Northwestern Polytechnical
   University (NPU) New AoXiang Star (No. G2015KY0301), the NPU New People
   and New Directions Foundation (No. 13GH014604), the Natural Science
   Foundation of Shaanxi Province (No. 2015JQ6256), the Fundamental
   Research Funds for the Central Universities (No. 3102015AX007).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2001, PYRAMIDAL IMPLEMENTA
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen S, 2014, J VIS COMMUN IMAGE R, V25, P793, DOI 10.1016/j.jvcir.2014.01.010
   Chen T., 2013, P INT C ADV MOB COMP, P518
   Collins R., 2005, PROC IEEE INT WORKSH, V2, P35
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Lu HC, 2012, IEEE T CIRC SYST VID, V22, P1365, DOI 10.1109/TCSVT.2012.2201794
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shen CH, 2010, IEEE T CIRC SYST VID, V20, P119, DOI 10.1109/TCSVT.2009.2031393
   Teng F, 2015, SIGNAL PROCESS-IMAGE, V31, P76, DOI 10.1016/j.image.2014.12.006
   Teng F, 2014, SIGNAL IMAGE VIDEO P, V8, P1069, DOI 10.1007/s11760-014-0629-4
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu YX, 2015, VISUAL COMPUT, V31, P471, DOI 10.1007/s00371-014-0942-5
   Yang F, 2014, IEEE T CIRC SYST VID, V24, P242, DOI 10.1109/TCSVT.2013.2276145
   Yao R, 2012, LECT NOTES COMPUT SC, V7574, P158, DOI 10.1007/978-3-642-33712-3_12
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 43
TC 2
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 253
EP 265
DI 10.1016/j.jvcir.2016.06.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900024
DA 2024-07-18
ER

PT J
AU Madrid-Cuevas, FJ
   Aguilera-Aguilera, EJ
   Carmona-Poyato, A
   Muñoz-Salinas, R
   Medina-Carnicer, R
   Fernández-García, NL
AF Madrid-Cuevas, F. J.
   Aguilera-Aguilera, E. J.
   Carmona-Poyato, A.
   Munoz-Salinas, R.
   Medina-Carnicer, R.
   Fernandez-Garcia, N. L.
TI An efficient unsupervised method for obtaining polygonal approximations
   of closed digital planar curves
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Closed digital planar curve; Polygonal approximation; Split-merge;
   Convex hull
ID DOMINANT POINT DETECTION; MANY-CORE PROCESSORS; PARALLEL FRAMEWORK;
   SUPPRESSION; ALGORITHM; TREE
AB The contour of a shape is a powerful feature that enables its description and subsequent recognition. However, the direct use of a contour introduces redundancy. Many algorithms have been proposed for simplification of a contour while its most outstanding features are maintained. However, several inconveniences can be found in these methods, mainly the need for user interaction to set proper values for the parameters and, in some cases, for each specific contour. The proposed algorithm obtains polygonal approximations of contours and does not have parameters that must be adjusted, which provides the best balance between fidelity and efficiency, and has a modest algorithmic complexity. The method is based on an analysis of the convexity/concavity tree of the contour, and an efficient split/merge strategy is used. The experiments conducted show that the proposed method overcomes the state-of-the-art, using both synthetic data and a broad dataset of real contours. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Madrid-Cuevas, F. J.; Aguilera-Aguilera, E. J.; Carmona-Poyato, A.; Munoz-Salinas, R.; Medina-Carnicer, R.; Fernandez-Garcia, N. L.] Univ Cordoba, Dept Comp & Numer Anal, Maimonides Inst Biomed Res IMIBIC, Cordoba, Spain.
C3 Universidad de Cordoba
RP Madrid-Cuevas, FJ (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, Maimonides Inst Biomed Res IMIBIC, Cordoba, Spain.
EM fjmadrid@uco.es
RI Cuevas, Francisco José Madrid/H-1396-2015; Fernández García, Nicolás
   Luis/AAP-9118-2021; Munoz-Salinas, Rafael/K-5999-2014; Carmona-Poyato,
   Angel/G-1593-2015; Medina-Carnicer, Rafael/G-3401-2015
OI Fernández García, Nicolás Luis/0000-0002-1267-6986; Munoz-Salinas,
   Rafael/0000-0002-8773-8571; Carmona-Poyato, Angel/0000-0002-8820-8396;
   Medina-Carnicer, Rafael/0000-0003-4481-0614
FU Science and Technology Ministry of Spain [TIN2012-32952]; BROCA -
   Science and Technology Ministry of Spain; FEDER [TIN2012-32952]
FX This work has been developed with the support of the Research Projects
   called TIN2012-32952 and BROCA, which were both financed by the Science
   and Technology Ministry of Spain and FEDER.
CR Aguilera-Aguilera EJ, 2014, J VIS COMMUN IMAGE R, V25, P1905, DOI 10.1016/j.jvcir.2014.09.012
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Carmona-Poyato A, 2012, IMAGE VISION COMPUT, V30, P513, DOI 10.1016/j.imavis.2012.05.003
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Chan W.S., 1993, APPROXIMATION POLYGO
   Doran H.E., 1989, Applied Regression Analysis in Econometrics
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Grauman K, 2004, PROC CVPR IEEE, P220
   Hershberger J., 1994, P 10 ANN S COMP GEOM, P383
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   Parvez MT, 2010, PATTERN RECOGN LETT, V31, P1997, DOI 10.1016/j.patrec.2010.06.007
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Prasad DK, 2012, IMAGE VISION COMPUT, V30, P843, DOI 10.1016/j.imavis.2012.06.010
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 21
TC 9
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 152
EP 163
DI 10.1016/j.jvcir.2016.05.021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900015
DA 2024-07-18
ER

PT J
AU Chen, CC
   Chen, SC
AF Chen, Chien-Chang
   Chen, Shih-Chang
TI Two-layered structure for optimally essential secret image sharing
   scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Essential; Non-essential; Two-layered structure;
   Optimal sharing ratios
ID AUTHENTICATION
AB This paper presents a two-layered structure for optimally sharing a secret image among s essential and n - s non-essential shared shadows using the (t,s,k,n) essential thresholds, that t essential shared shadows and totally k shared shadows are needed to recover the secret image. The presented two-layered structure includes one user-defined parameter in to determine different kinds of optimal results. m =1 leads to minimum size of total shared shadows (ST) and size of an essential shared shadow is close to size of a non-essential shared shadow. On the other hand, m = t leads to size of an essential shared shadow being twice of size of a non-essential shared shadow to signify the importance of an essential shared shadow. Moreover, the proposed structure overcomes the threshold fulfillment problem in Chen's scheme (Chen, 2016). Theoretical analyses and experimental results show that the proposed scheme exhibits secure with optimal sharing ratios among related works. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Chien-Chang; Chen, Shih-Chang] Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
C3 Tamkang University
RP Chen, CC (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM ccchen34@mail.tku.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
FU National Science Council of the Republic of China [NSC
   103-2221-E-032-051]
FX This paper was partially supported by the National Science Council of
   the Republic of China under contract NSC 103-2221-E-032-051.
CR Chang CC, 2011, INFORM SCIENCES, V181, P3073, DOI 10.1016/j.ins.2011.03.002
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen CC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013008
   Chen SK, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.1.013103
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Le THN, 2011, DIGIT SIGNAL PROCESS, V21, P734, DOI 10.1016/j.dsp.2011.07.004
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu ZJ, 2008, OPT COMMUN, V281, P5322, DOI 10.1016/j.optcom.2008.07.048
   Stalling W., 2003, CRYPTOGRAPHY NETWORK, P126
   Subba Rao Y. V., 2014, International Journal of Network Security, V16, P249
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tso HK, 2008, OPT ENG, V47, DOI 10.1117/1.2955502
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang RZ, 2010, J VIS COMMUN IMAGE R, V21, P751, DOI 10.1016/j.jvcir.2010.06.001
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yang C.N., 2016, J SYST SOFT IN PRESS
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
NR 23
TC 22
Z9 22
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 595
EP 601
DI 10.1016/j.jvcir.2016.04.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100051
DA 2024-07-18
ER

PT J
AU Cheng, X
   Zeng, M
   Liu, XG
AF Cheng, Xuan
   Zeng, Ming
   Liu, Xinguo
TI Spatially constrained level-set tracking and segmentation of non-rigid
   objects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Segmentation-based tracking; Level-set; Hough voting; Back-projection
ID VISUAL TRACKING
AB Level-set is a widely used technique in segmentation-based tracking due to its flexibility in handling 2D topological changes and computational efficiency. Most existing level-set models aim at grouping pixels that have similar features into a region, without consideration of the spatial relationship of these pixels. In this paper, we present a novel level-set tracking method that incorporates spatial information to improve the robustness and accuracy of tracking non-rigid objects. Both tracking and segmentation are performed in a unified probabilistic framework, with additional spatial constraints from a part-based model the Hough Forests. In the stage of tracking, the rigid motion of the target object is estimated by rigid registration in both the color space and the Hough voting space. Then in the stage of segmentation, some support points are obtained from back-projection, and guide the level-set evolution to capture the shape deformation. We conduct quantitative evaluation on two recently proposed public benchmarks: a non-rigid object tracking dataset and the CVPR2013 online tracking benchmark, involving 61 sequences in total. The experimental results demonstrate that our tracking method performs comparably to the state-of-the-arts in the CVPR2013 benchmark, while shows significantly improved performance in tracking non-rigid objects. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Cheng, Xuan; Liu, Xinguo] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Zeng, Ming] Xiamen Univ, Software Sch, Xiamen, Peoples R China.
C3 Zhejiang University; Xiamen University
RP Liu, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM chengxuan90@gmail.com; xgliu@cad.zju.edu.cn
RI Zeng, Ming/GXF-3628-2022
OI Zeng, Ming/0000-0003-2836-9240
FU NSFC [61379068, 61402387]; Open Project Program of State Key Lab of
   CADAMP;CG, Zhejiang University [A1419]
FX We thank the editor and the anonymous reviewers for their constructive
   comments. This work was partially supported by NSFC (Nos. 61379068 and
   61402387), and the Open Project Program of State Key Lab of CAD&CG,
   Zhejiang University (No. A1419).
CR [Anonymous], 2012, P CVPR
   [Anonymous], 2011, P ICCV
   [Anonymous], 2008, P ECCV
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Belagiannis V., 2012, P ECCV
   Bibby C., 2010, P CVPR
   Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Duffner S., 2013, P ICCV
   Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Godec M., 2011, P ICCV
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Horbert E., 2011, P ICCV
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z., 2010, P CVPR
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Mitzel D., 2010, P ECCV
   Nejhum SMS, 2010, COMPUT VIS IMAGE UND, V114, P901, DOI 10.1016/j.cviu.2010.04.002
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Sun X., 2011, P CVPR
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 33
TC 0
Z9 0
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 745
EP 752
DI 10.1016/j.jvcir.2016.04.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100062
DA 2024-07-18
ER

PT J
AU Hua, KL
   Hidayati, SC
   He, FL
   Wei, CP
   Wang, YCF
AF Hua, Kai-Lung
   Hidayati, Shintami Chusnul
   He, Fang-Lin
   Wei, Chia-Po
   Wang, Yu-Chiang Frank
TI Context-aware joint dictionary learning for color image demosaicking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color demosaicking; Dictionary learning; Self-learning; Sparse
   representation
ID SPARSE REPRESENTATION; SUPERRESOLUTION; SIMILARITY; ALGORITHM
AB Most digital cameras are overlaid with color filter arrays (CFA) on their electronic sensors, and thus only one particular color value would be captured at every pixel location. When producing the output image, one needs to recover the full color image from such incomplete color samples, and this process is known as demosaicking. In this paper, we propose a novel context-constrained demosaicking algorithm via sparse-representation based joint dictionary learning. Given a single mosaicked image with incomplete color samples, we perform color and texture constrained image segmentation and learn a dictionary with different context categories. A joint sparse representation is employed on different image components for predicting the missing color information in the resulting high-resolution image. During the dictionary learning and sparse coding processes, we advocate a locality constraint in our algorithm, which allows us to locate most relevant image data and thus achieve improved demosaicking performance. Experimental results show that the proposed method outperforms several existing or state-of-the-art techniques in terms of both subjective and objective evaluations. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hua, Kai-Lung; Hidayati, Shintami Chusnul; He, Fang-Lin] Natl Taiwan Univ Sci & Technol, Dept CSIE, Taipei, Taiwan.
   [Wei, Chia-Po; Wang, Yu-Chiang Frank] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan.
C3 National Taiwan University of Science & Technology; Academia Sinica -
   Taiwan
RP Wang, YCF (corresponding author), Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan.
EM ycwang@citi.sinica.edu.tw
RI Hidayati, Shintami Chusnul/AAK-7047-2020
OI Hidayati, Shintami Chusnul/0000-0001-5045-4842; Hua,
   Kai-Lung/0000-0002-7735-243X
FU Ministry of Science and Technology of Taiwan
   [MOST104-2221-E-011-091-MY2, MOST103-2221-E-011-105,
   MOST103-2221-E-001-021-MY2]
FX This work was supported in part by Ministry of Science and Technology of
   Taiwan via MOST104-2221-E-011-091-MY2, MOST103-2221-E-011-105, and
   MOST103-2221-E-001-021-MY2.
CR [Anonymous], 2009, P IEEE INT C COMP VI
   [Anonymous], 2009, P ADV NEUR INF PROC
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Dubois E., 2005, FREQUENCY DOMAIN MET
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Hirakawa K, 2005, IEEE T IMAGE PROCESS, V14, P360, DOI 10.1109/TIP.2004.838691
   Ho JS, 2010, IEEE INT CON MULTI, P1475, DOI 10.1109/ICME.2010.5582951
   Horé A, 2011, IEEE T IMAGE PROCESS, V20, P3136, DOI 10.1109/TIP.2011.2159229
   Huang Y., 2006, IEEE WORKSH MACH LEA, P353
   Itoh Y, 2011, IEEE T CONSUM ELECTR, V57, P597, DOI 10.1109/TCE.2011.5955197
   Lukac R, 2005, PATTERN RECOGN, V38, P2208, DOI 10.1016/j.patcog.2005.04.008
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Malvar H.S., 2004, P IEEE INT C AC SPEE
   Moghadam A., 2013, COMPPRESSIVE DEMOSAI
   Moghadam AA, 2013, IEEE T IMAGE PROCESS, V22, P2356, DOI 10.1109/TIP.2013.2244215
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Pekkucuksen I, 2012, IEEE T IMAGE PROCESS, V21, P393, DOI 10.1109/TIP.2011.2155073
   Pekkucuksen I, 2011, INT CONF ACOUST SPEE, P993
   Rehman A, 2011, INT CONF ACOUST SPEE, P1121
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siddiqui H, 2010, INT CONF ACOUST SPEE, P1034, DOI 10.1109/ICASSP.2010.5495325
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu X., 2010, P IEEE INT C IM PROC
   Yang C.-Y., 2010, P AS C COMP VIS
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang M.-C., 2011, P IEEE INT C IM PROC
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Zhang F, 2009, IEEE T IMAGE PROCESS, V18, P2706, DOI 10.1109/TIP.2009.2029987
NR 40
TC 14
Z9 15
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 230
EP 245
DI 10.1016/j.jvcir.2016.03.004
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100020
DA 2024-07-18
ER

PT J
AU Wang, XT
   Shen, SS
   Shi, GM
   Xu, YN
   Zhang, PY
AF Wang, Xiaotian
   Shen, Shanshan
   Shi, Guangming
   Xu, Yuannan
   Zhang, Peiyu
TI Iterative non-local means filter for salt and pepper noise removal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salt and pepper noise removal; Non-local means; Iterative filtering
ID SWITCHING MEDIAN FILTER; VALUED IMPULSE NOISE; FUZZY FILTER; ALGORITHM;
   IMAGES
AB Salt and Pepper noise (S&P noise) removal is an active research area in digital image processing. Existing techniques commonly use the local statistics within a neighborhood to estimate the centered noisy pixel, and tend to damage image details due to the image local diversity singularity and non-stationarity. To address this problem, in this paper, iterative nonlocal means filter (INLM) is proposed to exploit the image non-local similarity feature in the S&P noise removal procedure. Moreover, the proposed iterative framework update the similarity weights and the estimated values for higher accuracy. The experimental results show that the proposed INLM produces better results than state-of-art methods over a wide range of scenes both subjectively and objectively, and it is robust to the detection results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Xiaotian; Shen, Shanshan; Shi, Guangming; Zhang, Peiyu] Xidian Univ, Xian 710071, Shaanxi, Peoples R China.
   [Xu, Yuannan] Sci & Technol Opt Radiat Lab, Beijing 100854, Peoples R China.
C3 Xidian University
RP Wang, XT (corresponding author), Xidian Univ, Xian 710071, Shaanxi, Peoples R China.
EM xtwang@mail.xidian.edu.cn; kksss_333@l63.com; gmshi@xidian.edu.cn;
   xuyuannan@126.com; zhangpeiyu@stu.xidian.edu.cn
FU NSF of China [61401333, 61401325, 61201289, 61372071, 61100155]; Shaanxi
   province natural science foundation of China [2014JQ8296]; Research Fund
   for the Doctoral Program of Higher Education of China [20130203120009];
   Fundamental Research Funds for the Central Universities of China
   [JB140227, K5051302096, JB140207]; National Defense Fund
   [9140C610304150C61268]
FX This work is supported by NSF of China (Nos. 61401333, 61401325,
   61201289, 61372071, 61100155), Shaanxi province natural science
   foundation of China (No. 2014JQ8296), Research Fund for the Doctoral
   Program of Higher Education of China (No. 20130203120009), and
   Fundamental Research Funds for the Central Universities of China (Nos.
   JB140227, K5051302096, JB140207), and the National Defense Fund (No.
   9140C610304150C61268).
CR Aizenberg I, 2005, IEEE SIGNAL PROC LET, V12, P63, DOI 10.1109/LSP.2004.838198
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Camarena JG, 2008, J VIS COMMUN IMAGE R, V19, P20, DOI 10.1016/j.jvcir.2007.04.003
   Chen T., IEEE T CIRC SYST 2, V48
   Çivicioglu P, 2004, EURASIP J APPL SIG P, V2004, P2434, DOI 10.1155/S1110865704403151
   Civicioglu P, 2007, IEEE T IMAGE PROCESS, V16, P759, DOI 10.1109/TIP.2007.891067
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Deng ZF, 2007, IEEE SIGNAL PROC LET, V14, P31, DOI 10.1109/LSP.2006.881524
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Gao GR, 2015, J VIS COMMUN IMAGE R, V32, P83, DOI 10.1016/j.jvcir.2015.07.014
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gupta V, 2015, J VIS COMMUN IMAGE R, V26, P296, DOI 10.1016/j.jvcir.2014.10.004
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P956, DOI 10.1016/j.jvcir.2013.06.012
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Kalyoncu C, 2013, IET IMAGE PROCESS, V7, P777, DOI 10.1049/iet-ipr.2013.0146
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Luo WB, 2006, IEEE T CONSUM ELECTR, V52, P523, DOI 10.1109/TCE.2006.1649674
   Morillas S, 2008, SIGNAL PROCESS, V88, P390, DOI 10.1016/j.sigpro.2007.05.019
   Morillas S, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2767335
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   Schulte S., IEEE T IMAGE PROCESS, V15
   Smolka B, 2008, LECT NOTES COMPUT SC, V5197, P699, DOI 10.1007/978-3-540-85920-8_85
   Smolka B, 2010, PATTERN RECOGN LETT, V31, P484, DOI 10.1016/j.patrec.2009.09.012
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Wei P, 2007, IEEE INT SYMP CIRC S, P3427
   Yüksel ME, 2006, IEEE T IMAGE PROCESS, V15, P928, DOI 10.1109/TIP.2005.863941
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
   Zhou Z, 2012, IEEE T IMAGE PROCESS, V21, P3157, DOI 10.1109/TIP.2012.2189577
   Zuo ZY, 2013, OPTIK, V124, P3503, DOI 10.1016/j.ijleo.2012.10.014
NR 34
TC 45
Z9 53
U1 1
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 440
EP 450
DI 10.1016/j.jvcir.2016.03.024
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100038
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhu, LW
   Zhang, Y
   Li, N
   Jiang, GY
   Kwong, S
AF Zhu, Linwei
   Zhang, Yun
   Li, Na
   Jiang, Gangyi
   Kwong, Sam
TI Machine learning based fast H.264/AVC to HEVC transcoding exploiting
   block partition similarity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID VIDEO TRANSCODER; MODE DECISION; MPEG-2
AB Video transcoding is to convert one compressed video stream to another. In this paper, a fast H.264/AVC to High Efficiency Video Coding (HEVC) transcoding method based on machine learning is proposed by considering the similarity between compressed streams, especially the block partition correlations, to reduce the computational complexity. This becomes possible by constructing three-level binary classifiers to predict quad-tree Coding Unit (CU) partition in HEVC. Then, we propose a feature selection algorithm to get representative features to improve predication accuracy of the classification. In addition, we propose an adaptive probability threshold determination scheme to achieve a good trade-off between low coding complexity and high compression efficiency during the CU depth prediction in HEVC. Extensive experimental results demonstrate the proposed transcoder achieves complexity reduction of 50.2% and 49.2% on average under lowdelay P main and random access configurations while the rate distortion degradation is negligible. The proposed scheme is proved more effective as comparing with the state-of-the-art benchmarks. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhu, Linwei; Zhang, Yun; Li, Na] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Zhu, Linwei; Kwong, Sam] City Univ Wong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Jiang, Gangyi] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Ningbo University; Shenzhen Research Institute, City University of
   Hong Kong; City University of Hong Kong
RP Li, N (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM lwzhu2-c@my.cityu.edu.hk; yun.zhang@siat.ac.cn; na.li1@siat.ac.cn;
   jianggangyi@nbu.edu.cn; cssamk@cityu.edu.hk
RI jiang, gang/KII-8233-2024; Kwong, Sam/C-9319-2012; Zhang,
   Yun/V-7261-2019
OI Kwong, Sam/0000-0001-7484-7261; Zhang, Yun/0000-0001-9457-7801; ,
   linwei/0000-0002-9385-9054
FU National Natural Science Foundation of China [61471348, U1301257,
   61272289]; Shenzhen Overseas High-Caliber Personnel Innovation and
   Entrepreneurship Project [KQCX20140520154115027]; Guangdong Special
   Support Program for Youth Science and Technology Innovation Talents
   [2014TQ01X345]; National High-tech R&D Program of China [2015AA015901];
   Zhejiang Provincial Natural Science Foundation of China [LY15F010005]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61471348, U1301257 and 61272289, in part by Shenzhen
   Overseas High-Caliber Personnel Innovation and Entrepreneurship Project
   under Grant KQCX20140520154115027, and in part by Guangdong Special
   Support Program for Youth Science and Technology Innovation Talents
   under Grant 2014TQ01X345, in part by the National High-tech R&D Program
   of China under Grant 2015AA015901, and by Zhejiang Provincial Natural
   Science Foundation of China under Grant LY15F010005.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   Bjontegaard G., 2001, M33 ITUT VCEG
   Bossen F., 2012, JCTVCJ1100 ITUT SG16
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YC, 2015, IEEE T CIRC SYST VID, V25, P1423, DOI 10.1109/TCSVT.2014.2380231
   Chiang CK, 2011, IEEE T CIRC SYST VID, V21, P1304, DOI 10.1109/TCSVT.2011.2147250
   De Cock J, 2011, J VIS COMMUN IMAGE R, V22, P391, DOI 10.1016/j.jvcir.2011.03.001
   Dong Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P651, DOI 10.1109/ICME.2012.112
   Fernández-Escribano G, 2010, IEEE T CIRC SYST VID, V20, P763, DOI 10.1109/TCSVT.2010.2045914
   Franc V., 2011, P IEEE INT C MACH LE
   Fung KT, 2005, IEEE INT SYMP CIRC S, P908
   ITU-T, JOINT MOD JM H 264 A
   Jiang W, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.0329
   Kalva H, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.93
   Kim S., 2005, P IEEE INT C IM PROC, P656
   Liu XG, 2010, J VIS COMMUN IMAGE R, V21, P155, DOI 10.1016/j.jvcir.2009.05.002
   Liu YW, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348821
   McCann K., 2014, JCTVCP1002 ITUT SG16
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Petjanski B., 2006, 2006 Digest of Technical Papers. International Conference on Consumer Electronics, P419
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen T, 2013, IEEE DATA COMPR CONF, P241, DOI 10.1109/DCC.2013.32
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Shu HY, 2008, IEEE T MULTIMEDIA, V10, P97, DOI 10.1109/TMM.2007.911300
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Zhang F, 2014, J VIS COMMUN IMAGE R, V25, P542, DOI 10.1016/j.jvcir.2013.11.011
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
NR 30
TC 13
Z9 14
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 824
EP 837
DI 10.1016/j.jvcir.2016.04.020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100069
DA 2024-07-18
ER

PT J
AU Setkov, A
   Gouiffès, M
   Jacquemin, C
AF Setkov, Aleksandr
   Gouiffes, Michele
   Jacquemin, Christian
TI Evaluation of color descriptors for projector-camera systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature descriptors; Feature matching; Color invariance; Geometry
   compensation; Smart projection; Projector-camera systems;
   Projection-based augmented reality; Spatial augmented reality
ID ADAPTATION; OBJECT
AB Spatial Augmented Reality applications generally use projector-camera systems to control the visual projection appearance by comparing the initial projected and the acquired images. To obtain an accurate geometric compensation, a non-intrusive feature-point matching approach can be exploited which must handle complex photometric distortions due to the spectral devices responses, complex illumination and the mixing of the projected image with the projection surface.
   This paper first discusses the invariance properties of existing color descriptors in that application for non-intrusive geometric compensation. Their performance is evaluated using the framework of Setkov et al. (2013) extended by adding the several new test cases: modeled synthetic projections, real-world projections under various illuminants on one and two planar surfaces. Our experimental results show two main conclusions: (1) classical color vision models are hardly suitable to model the distortions in a projector-camera system, and (2) the LHE-based descriptor (Local Histogram Equalization) is the most reliable to compensate real-projections. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Setkov, Aleksandr; Gouiffes, Michele; Jacquemin, Christian] Univ Paris Saclay, Univ Paris 11, CNRS, LIMSI, Bat 508,Campus Univ, F-91405 Orsay, France.
C3 Universite Paris Cite; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Saclay
RP Setkov, A (corresponding author), Univ Paris Saclay, Univ Paris 11, CNRS, LIMSI, Bat 508,Campus Univ, F-91405 Orsay, France.
EM aleksandr.setkov@limsi.fr
CR [Anonymous], 2005, IEEE T PATTERN ANAL
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], TECHNICAL REPORT
   Bao H, 2012, COMPUT INFORM, V31, P971
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Bimber O, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P14
   Bimber O., 2006, Projector-Based Augmentation, P64
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Caldelli R., 2012, 2012 5th International Symposium on Communications Control and Signal Processing, P1
   Chandraker M, 2011, IEEE T PATTERN ANAL, V33, P2122, DOI 10.1109/TPAMI.2011.124
   Chen X, 2012, IEEE T MULTIMEDIA, V14, P3, DOI 10.1109/TMM.2011.2167223
   Cotting D, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P100, DOI 10.1109/ISMAR.2004.30
   Cotting D., 2011, CONTINUOUS UNIFIED C
   Dehos J., 2008, P 2008 ACM S VIRT RE, P130
   Drouin M. -A., 2010, 2010 IEEE COMP SOC C, P33
   Falcao G., 2008, PLANE BASED CALIBRAT
   Finlayson G, 2005, PATTERN RECOGN, V38, P179, DOI 10.1016/j.patcog.2004.04.010
   Finlayson GD, 2005, IEEE IMAGE PROC, P2617
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fujii K, 2005, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.2005.41
   Funt B, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P112
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   Grossberg MD, 2004, PROC CVPR IEEE, P452
   Grossberg MD, 2003, PROC CVPR IEEE, P602
   Kanan C, 2010, LECT NOTES COMPUT SC, V6453, P199
   Lourenço M, 2012, IEEE T ROBOT, V28, P752, DOI 10.1109/TRO.2012.2184952
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Mazin B., 2012, 2012 21st International Conference on Pattern Recognition (ICPR 2012), P2667
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Nayar S. K., 2003, ICCV WORKSH PROJ CAM
   Ng TT, 2012, INT J COMPUT VISION, V96, P235, DOI 10.1007/s11263-011-0467-6
   Ng TT, 2009, IEEE I CONF COMP VIS, P1889, DOI 10.1109/ICCV.2009.5459418
   Park H, 2006, LECT NOTES COMPUT SC, V3852, P892
   Park H, 2008, IEEE T CIRC SYST VID, V18, P110, DOI 10.1109/TCSVT.2007.903322
   Park H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1313, DOI 10.1109/ICME.2006.262780
   Perrin MJ, 2008, P BRIT MACH VIS C 20, P1
   Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158
   Setkov A., 2013, P 6 INT C COMP VIS C
   Shen S., 2010, T IMG PROC, V19, P512
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Verma A., 2010, INT C COMP APPL COMP, P819
   Yamanaka T., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P307, DOI 10.1109/ICPR.2010.84
   Yang R, CECG 01
   Zollmann S., 2007, JVRB J VIRTUAL REAL, V4, P10
NR 51
TC 2
Z9 2
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 11
EP 27
DI 10.1016/j.jvcir.2016.01.006
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200002
DA 2024-07-18
ER

PT J
AU Suo, JL
   Bian, LH
   Chen, F
   Dai, QH
AF Suo, Jinli
   Bian, Liheng
   Chen, Feng
   Dai, Qionghai
TI Signal-dependent noise removal for color videos using temporal and
   cross-channel priors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color video denoising; Signal dependent noise; Poisson-Gaussian noise;
   Temporal prior; Low rank matrix recovery; Cross channel prior; Color
   aberration correction; Augmented lagrangian multiplier method
ID WAVELET-DOMAIN; IMAGE; FILTER; TRANSFORM
AB Noise widely exists in video acquisition, and is especially large under low illumination conditions. Existing video denoising methods are usually at the risk of losing perceptually crucial scene details and introducing unpleasant artifacts. Inspired by high sensitivity of human vision system to thin structures and color aberration in natural images, we incorporate two video priors into a joint optimization framework besides the constraint from the adopted Poisson-Gaussian noise model: (i) we force the motion compensated frames to be a low rank matrix to separate thin structures from large noise. (ii) we utilize the consistency of image pixel gradients in different color channels as a cross channel prior to eliminate color fringing artifacts. To solve this non-convex optimization model, we derive a numerical algorithm via the augmented Lagrangian multiplier method. The effectiveness of our approach is validated by a series of experiments, with both objective and subjective evaluations. (C) 2016 Published by Elsevier Inc.
C1 [Suo, Jinli; Bian, Liheng; Chen, Feng; Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Suo, JL (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
EM jlsuo@tsinghua.edu.cn
RI Bian, Liheng/Q-2459-2016
OI Bian, Liheng/0000-0002-8016-0375
FU National Natural Science Foundation of China [61120106003, 61305026,
   61327902]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61120106003, 61305026 and 61327902).
CR [Anonymous], SIGGRAPH
   [Anonymous], CVPR
   Barzigar N, 2012, CONF REC ASILOMAR C, P1684, DOI 10.1109/ACSSC.2012.6489319
   Bhat D.N., 1996, CVPR
   Bonet J.S.D., 1997, RETHINKING ARTIFICIA
   Boracchi G., 2008, INT WORKSH LOC NONL
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Cho TS, 2012, IEEE T PATTERN ANAL, V34, P683, DOI 10.1109/TPAMI.2011.166
   Cho TS, 2010, PROC CVPR IEEE, P183, DOI 10.1109/CVPR.2010.5540212
   Dabov K., 2007, EUSIPCO
   Dai JJ, 2013, IEEE T CIRC SYST VID, V23, P128, DOI 10.1109/TCSVT.2012.2203203
   Dai JJ, 2010, IEEE INT SYMP CIRC S, P2992, DOI 10.1109/ISCAS.2010.5538013
   Danielyan A., 2009, INT WORKSH LOC NONL
   Deng Y, 2012, IEEE J-STSP, V6, P566, DOI 10.1109/JSTSP.2012.2195472
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   Foi A, 2007, IEEE SENS J, V7, P1456, DOI 10.1109/JSEN.2007.904864
   Foi A, 2009, SIGNAL PROCESS, V89, P2609, DOI 10.1016/j.sigpro.2009.04.035
   Ghoniem M, 2010, SIGNAL PROCESS, V90, P2445, DOI 10.1016/j.sigpro.2009.09.004
   Guichard F., 2009, SPIE IS T ELECT IMAG
   Guo LW, 2007, IEEE T CIRC SYST VID, V17, P1423, DOI 10.1109/TCSVT.2007.903797
   Guo LW, 2010, IEEE T CIRC SYST VID, V20, P236, DOI 10.1109/TCSVT.2009.2031453
   Heo YongSeok., 2007, CVPR
   Hirakawa K, 2005, INT CONF ACOUST SPEE, P29
   Irie K, 2008, IEEE T CIRC SYST VID, V18, P280, DOI 10.1109/TCSVT.2007.913972
   Janesick J.R., 2007, Photon Transfer DN
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Jovanov L, 2009, IEEE T CIRC SYST VID, V19, P417, DOI 10.1109/TCSVT.2009.2013491
   Lin Z., 2009, Technical Report (No. UILU-ENG-09-2215
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Liu G., 2010, P INT C MACH LEARN, P663
   Luisier F, 2010, IEEE T CIRC SYST VID, V20, P913, DOI 10.1109/TCSVT.2010.2045819
   Maggioni M., Image and video denoising by sparse 3D transform-domain collaborative filtering
   Maggioni M.T., 2015, THESIS TAMPERE U TEC
   Maggioni M.T., 2010, THESIS TAMPERE U TEC
   Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725
   Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   PUKELSHEIM F, 1994, AM STAT, V48, P88, DOI 10.2307/2684253
   Rahman SMM, 2007, IEEE T CIRC SYST VID, V17, P187, DOI 10.1109/TCSVT.2006.887079
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Rosales-Silva AJ, 2012, J VIS COMMUN IMAGE R, V23, P143, DOI 10.1016/j.jvcir.2011.09.007
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sheikh H. R., IMAGE VIDEO QUALITY
   Suo JL, 2014, IEEE T IMAGE PROCESS, V23, P1154, DOI 10.1109/TIP.2014.2298976
   Tombari F., 2007, ICIAP
   Varghese G, 2010, IEEE T CIRC SYST VID, V20, P1032, DOI 10.1109/TCSVT.2010.2051366
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JY, 2009, IEEE T CIRC SYST VID, V19, P642, DOI 10.1109/TCSVT.2009.2017402
   Yu SG, 2010, IEEE T CIRC SYST VID, V20, P780, DOI 10.1109/TCSVT.2010.2045806
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang Haichao., 2011, ICCV
   Zhang L., 2009, CVPR
NR 57
TC 10
Z9 11
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 130
EP 141
DI 10.1016/j.jvcir.2016.01.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200011
DA 2024-07-18
ER

PT J
AU Cheon, M
   Lee, JS
AF Cheon, Manri
   Lee, Jong-Seok
TI Evaluation of objective quality metrics for multidimensional video
   scalability
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality of experience (QoE); Video scalability; Objective quality
   metric; Mean opinion score (MOS); Scalable video coding; Benchmarking;
   Video quality; Subjective quality
ID IMAGE; QUANTIZATION; INFORMATION; EXTENSION
AB Multidimensional video scalability refers to the possibility that a video sequence can be adapted according to given conditions of video consumption by adjusting one or more of its features such as frame size, frame rate, and spatial quality. An important issue in implementing an adaptive video distribution scheme using scalability is how to maximize the quality of experience for the delivered contents, which raises a more fundamental issue, that is, how to estimate perceived quality of scalable video contents. This paper evaluates existing state-of-the-art objective quality metrics, including both generic image/ video metrics and ones particularly developed for scalable videos, on the problem of quality assessment of multidimensional video scalability. It is shown that, on the whole, some recently developed metrics targeting scalability perform best. The results are thoroughly discussed in relation to the nature of the problem in comparison to what has been reported in existing studies for other problems. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Cheon, Manri; Lee, Jong-Seok] Yonsei Univ, Sch Integrated Technol, 162-1 Songdo Dong, Inchon 406840, South Korea.
C3 Yonsei University
RP Lee, JS (corresponding author), Yonsei Univ, Sch Integrated Technol, 162-1 Songdo Dong, Inchon 406840, South Korea.
EM jong-seok.lee@yonsei.ac.kr
RI Lee, Jong-Seok/AAF-5197-2020
OI Lee, Jong-Seok/0000-0001-5255-4425
FU Ministry of Science, ICT and Future Planning (MSIP), Korea, under the IT
   Consilience Creative Program [IITP-2015-R0346-15-1008]; Basic Science
   Research Program through the National Research Foundation of Korea -
   MSIP [2013R1A1A1007822]
FX This work was supported by the Ministry of Science, ICT and Future
   Planning (MSIP), Korea, under the IT Consilience Creative Program
   supervised by the Institute for Information and Communications
   Technology Promotion (IITP-2015-R0346-15-1008), and by the Basic Science
   Research Program through the National Research Foundation of Korea
   funded by the MSIP (2013R1A1A1007822).
CR Adami N, 2007, IEEE T CIRC SYST VID, V17, P1238, DOI 10.1109/TCSVT.2007.906828
   [Anonymous], 2000, FIN REP VID QUAL EXP
   [Anonymous], P ICIP BRUSS BELG
   ANSARI AR, 1960, ANN MATH STAT, V31, P1174, DOI 10.1214/aoms/1177705688
   Brunnstrom Kjell, 2009, IEEE Signal Processing Magazine, V26, P96, DOI 10.1109/MSP.2009.932162
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Feghali R, 2007, IEEE T BROADCAST, V53, P441, DOI 10.1109/TBC.2007.891700
   Hanhart P, 2013, INT CONF DIGIT SIG
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Kim CS, 2008, IEICE T COMMUN, VE91B, P1269, DOI 10.1093/ietcom/e91-b.5.1269
   Lee JS, 2012, IEEE IMAGE PROC, P693, DOI 10.1109/ICIP.2012.6466954
   Lee JS, 2012, IEEE COMMUN MAG, V50, P38, DOI 10.1109/MCOM.2012.6178832
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lu ZK, 2005, PROC SPIE, V5666, P554, DOI 10.1117/12.596845
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Nur G, 2012, IEEE T CIRC SYST VID, V22, P225, DOI 10.1109/TCSVT.2011.2160600
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Raman N, 2009, SIGNAL PROCESS-IMAGE, V24, P510, DOI 10.1016/j.image.2009.02.008
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sohn H, 2010, IEEE T BROADCAST, V56, P269, DOI 10.1109/TBC.2010.2050628
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yen-Fu Ou, 2011, 2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis, P117, DOI 10.1109/IVMSPW.2011.5970365
NR 34
TC 5
Z9 5
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 132
EP 145
DI 10.1016/j.jvcir.2015.12.008
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600012
DA 2024-07-18
ER

PT J
AU Wu, AX
   Feng, GR
   Zhang, XP
   Ren, YL
AF Wu, Anxin
   Feng, Guorui
   Zhang, Xinpeng
   Ren, Yanli
TI Unbalanced JPEG image steganalysis via multiview data match
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganalysis; Unbalanced images; Dimension reduction; Multiview match
   resampling; Weighted fisher linear discriminant; K-means;
   High-dimensional feature; Semi-supervised learning
AB Image steganalysis must address the matter of learning from unbalanced training sets where the cover objects (normal images) always greatly outnumber the stego ones. But the research in unbalanced image steganalysis is seldom seen. This work just focuses on the problem of unbalance JPEG images steganalysis. In this paper, we propose a frame of feature dimension reduction based semi-supervised learning for high-dimensional unbalanced JPEG image steganalysis. Our method uses standard steganalysis features, and selects the confident stego images from the unlabeled examples by multiview match resampling method to rebalance the unbalanced training images. Furthermore, weighted Fisher linear discriminant (WFLD) is proposed to find the proper feature subspace where K-means provides the weight factor for WFLD in return. Finally, WFLD and K-means both work in an iterative fashion until convergence. Experimental results on the MBs and nsF5 steganographic methods show the usefulness of the developed scheme over current popular feature spaces. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wu, Anxin; Feng, Guorui; Zhang, Xinpeng; Ren, Yanli] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Feng, GR (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM fgr2082@aliyun.com
FU National Natural Science Foundation of China [61373151, 61202367,
   61472235, 61525203]; Natural Science Foundation of Shanghai, China
   [13ZR1415000]; Innovation Program of Shanghai Municipal Education
   Commission [14YZ019]
FX This work was supported by the National Natural Science Foundation of
   China under Grants (61373151, 61202367, 61472235, 61525203), the Natural
   Science Foundation of Shanghai, China (13ZR1415000), and Innovation
   Program of Shanghai Municipal Education Commission (14YZ019).
CR [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], IS T SPIE ELECT IMAG
   Cao Peng, 2013, NEURAL NETWORKS IJCN, P1
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Ding C., 2007, P 24 INT C MACH LEAR, P521
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kubat M., 1997, ADDRESSING CURSE IMB, V97, P179
   Li FY, 2013, IEEE SIGNAL PROC LET, V20, P233, DOI 10.1109/LSP.2013.2240385
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Ye J., 2008, P ADV NEUR INF PROC, P1649
NR 14
TC 10
Z9 10
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 103
EP 107
DI 10.1016/j.jvcir.2015.10.013
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400009
DA 2024-07-18
ER

PT J
AU Zeng, ZY
   Song, LW
   Zheng, QC
   Chi, YL
AF Zeng, Zhiyong
   Song, Liwei
   Zheng, Qicai
   Chi, Yanling
TI A new image retrieval model based on monogenic signal representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monogenic signal representation; Local binary pattern; Directional
   texture descriptor; Content-based image retrieval; Block-based Fisher
   linear discriminant; Feature fusion; Amplitude; Orientation; Phase
ID SCALE
AB This paper proposes a novel image retrieval model based on monogenic signal representation. An original image is decomposed into three complementary components: amplitude, orientation and phase by monogenic signal representation. The monogenic variation in each local region and monogenic feature in each pixel are encoded, and then the statistical features of the local features encoded are calculated. In order to overcome the problem of high feature dimensionality, the local statistical features extracted from the complementary monogenic components are projected by block-based fisher discriminant analysis, which not only reduces the dimensionality of the features extracted, but also enhances its discriminative power. Finally, these features reduced are fused for effective image retrieval. Experimental results show that our scheme can effectively describe an image, and obviously improve the average retrieval precision. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zeng, Zhiyong; Song, Liwei; Zheng, Qicai; Chi, Yanling] Fujian Normal Univ, Fac Software, Fuzhou 350108, Peoples R China.
C3 Fujian Normal University
RP Zeng, ZY (corresponding author), Fujian Normal Univ, Fac Software, Fuzhou 350108, Peoples R China.
EM zzyong@fjnu.edu.cn
FU National Natural Science Foundation of China [61370078, 60805016]; Key
   Research Funds of Fujian Province [2013H0020]
FX This research is supported by the National Natural Science Foundation of
   China (Nos. 61370078 and 60805016), and the Key Research Funds of Fujian
   Province (No. 2013H0020).
CR [Anonymous], 2010, Computer Vision Winter Workshop
   Choy SK, 2010, IEEE T IMAGE PROCESS, V19, P281, DOI 10.1109/TIP.2009.2033400
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang A, 2010, IEEE T IMAGE PROCESS, V19, P2737, DOI 10.1109/TIP.2010.2048965
   Jiang W, 2009, IEEE T SYST MAN CY B, V39, P1036, DOI 10.1109/TSMCB.2008.2011646
   Kafai M, 2014, IEEE T MULTIMEDIA, V16, P1090, DOI 10.1109/TMM.2014.2305633
   Kwok TH, 2010, IEEE T IMAGE PROCESS, V19, P3106, DOI 10.1109/TIP.2010.2052270
   Lategahn H, 2010, IEEE T IMAGE PROCESS, V19, P1548, DOI 10.1109/TIP.2010.2042100
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P2289, DOI 10.1007/s11042-014-2129-5
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marks TK, 2010, IEEE T PATTERN ANAL, V32, P348, DOI 10.1109/TPAMI.2008.278
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P193, DOI 10.1007/978-0-85729-748-8_13
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   [宋克臣 Song Kechen], 2013, [自动化学报, Acta Automatica Sinica], V39, P730
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   Su Yu, 2010, Journal of Software, V21, P1849, DOI 10.3724/SP.J.1001.2010.03627
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vargas JF, 2011, PATTERN RECOGN, V44, P375, DOI 10.1016/j.patcog.2010.07.028
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   [毋小省 Wu Xiaosheng], 2013, [光电子·激光, Journal of Optoelectronics·Laser], V24, P184
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang WC, 2009, PATTERN ANAL APPL, V12, P301, DOI 10.1007/s10044-008-0123-0
   [周书仁 Zhou Shuren], 2013, [软件学报, Journal of Software], V24, P1909
NR 34
TC 9
Z9 9
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 85
EP 93
DI 10.1016/j.jvcir.2015.08.014
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700009
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Ye, WZ
AF Zhang, Yong
   Ye, Wanzhou
TI <i>L</i><sub>2/3</sub> regularization: Convergence of iterative
   thresholding algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE L-1/2 regularization; L-2/3 regularization; Iterative thresholding
   algorithm; Thresholding formula; Convergence; Sparse signal recovery;
   Asymptotical convergence rate; Local minimizer
ID L-1/2 REGULARIZATION; RECONSTRUCTION; SPARSITY; SIGNALS
AB The L-2/3 regularization is a nonconvex and nonsmooth optimization problem. Cao et al. (2013) investigated that the L-2/3 regularization is more effective in imaging deconvolution. The convergence issue of the iterative thresholding algorithm of L-2/3 regularization problem (the L-2/3 algorithm) hasn't been addressed in Cao et al. (2013). In this paper, we study the convergence of the L-2/3 algorithm. As the main result, we show that under certain conditions, the sequence {X-(n)} generated by the L-2/3 algorithm converges to a local minimizer of L-2/3 regularization, and its asymptotical convergence rate is linear. We provide a set of experiments to verify our theoretical assertions and show the performance of the algorithm on sparse signal recovery. The established results provide a theoretical guarantee for a wide range of applications of the algorithm. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Yong; Ye, Wanzhou] Shanghai Univ, Coll Sci, Dept Math, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Ye, WZ (corresponding author), Shanghai Univ, Coll Sci, Dept Math, Shanghai 200444, Peoples R China.
EM 13820161@shu.edu.cn; wzhy@shu.edu.cn
FU Natural Science Foundation of Shanghai [15ZR1416300]; National Science
   Foundation of China [61071186, 11171205]
FX We thank deeply the referees and the editor for their helpful
   suggestions and comments on the paper, which have improved the
   presentation. This paper is partially supported by the Natural Science
   Foundation of Shanghai under grands (15ZR1416300) and the National
   Science Foundation of China under grands (61071186,11171205).
CR [Anonymous], 2012, ACM T MULTIMEDIA COM
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Blumensath T., 2007, IEEE T ACOUST SPEECH, V3
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Cao WF, 2013, J VIS COMMUN IMAGE R, V24, P31, DOI 10.1016/j.jvcir.2012.10.006
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Chartrand R, 2008, INVERSE PROBL, V24, DOI 10.1088/0266-5611/24/3/035020
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Foucart S, 2009, APPL COMPUT HARMON A, V26, P395, DOI 10.1016/j.acha.2008.09.001
   Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001
   Krishnan D., 2009, P ADV NEUR INF PROC, P1
   Liu L, 2015, ASIA PAC J OPER RES, V32, DOI 10.1142/S0217595915500232
   Liu T.L., 2015, PERFORMANCE MANHATTA
   Nie F., 2012, AAAI, P655
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2015, KNOWL INF SYST, V42, P525, DOI 10.1007/s10115-013-0713-z
   Rudelson M, 2008, COMMUN PUR APPL MATH, V61, P1025, DOI 10.1002/cpa.20227
   Sun QY, 2012, APPL COMPUT HARMON A, V32, P329, DOI 10.1016/j.acha.2011.07.001
   Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760
   Tao H., 2015, EFFECTIVE DISCRIMINA
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Xu ZB, 2010, SCI CHINA INFORM SCI, V53, P1159, DOI 10.1007/s11432-010-0090-0
   Zeng JS, 2014, IEEE T SIGNAL PROCES, V62, P2317, DOI 10.1109/TSP.2014.2309076
   Zhou TY, 2013, IEEE T IMAGE PROCESS, V22, P244, DOI 10.1109/TIP.2012.2202678
NR 28
TC 19
Z9 20
U1 2
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 350
EP 357
DI 10.1016/j.jvcir.2015.10.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700031
OA Bronze
DA 2024-07-18
ER

PT J
AU Kiliboz, NÇ
   Güdükbay, U
AF Kiliboz, Nurettin Cagri
   Gudukbay, Ugur
TI A hand gesture recognition technique for human-computer interaction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic gesture recognition; Hand gesture; Finite state machine-based
   recognition; Gestural interfaces; Gesture-based interaction;
   Human-computer interaction; Intuitive interfaces; Hand trajectory
   recognition; Adaptive gestures
AB We propose an approach to recognize trajectory-based dynamic hand gestures in real time for human-computer interaction (HCI). We also introduce a fast learning mechanism that does not require extensive training data to teach gestures to the system. We use a six-degrees-of-freedom position tracker to collect trajectory data and represent gestures as an ordered sequence of directional movements in 2D. In the learning phase, sample gesture data is filtered and processed to create gesture recognizers, which are basically finite-state machine sequence recognizers. We achieve online gesture recognition by these recognizers without needing to specify gesture start and end positions. The results of the conducted user study show that the proposed method is very promising in terms of gesture detection and recognition performance (73% accuracy) in a stream of motion. Additionally, the assessment of the user attitude survey denotes that the gestural interface is very useful and satisfactory. One of the novel parts of the proposed approach is that it gives users the freedom to create gesture commands according to their preferences for selected tasks. Thus, the presented gesture recognition approach makes the HCI process more intuitive and user specific. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kiliboz, Nurettin Cagri; Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM gudukbay@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011
OI Gudukbay, Ugur/0000-0003-2462-6959
FU Scientific and Technological Research Council of Turkey (TUBITAK) under
   BIDEB 2210 Graduate Scholarship
FX The first author is supported by The Scientific and Technological
   Research Council of Turkey (TUBITAK) under BIDEB 2210 Graduate
   Scholarship.
CR Bao J, 2011, 2011 INT C ELECT INF, P338
   Bimber O., 1999, 7th International Conference in Central Europe on Computer Graphics, Visualization and Interactive Digital Media'99. in co-operation with EUROGRAPHICS and IFIP WG 5.10. WSCG'99. Conference Proceedings, P24
   Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Chen-Chiung Hsieh, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P394, DOI 10.1109/ICSPS.2010.5555462
   David Ciprian, 2011, 2011 6th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI), P165, DOI 10.1109/SACI.2011.5872993
   Eickeler S, 1998, INT C PATT RECOG, P1206, DOI 10.1109/ICPR.1998.711914
   Hong Pengyu, 2000, P 4 IEEE INT C AUT F, P410
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Nölker C, 2002, IEEE T NEURAL NETWOR, V13, P983, DOI 10.1109/TNN.2002.1021898
   Norman Donald A., 2010, interactions, V17, P6, DOI [DOI 10.1145/1744161.1744163, 10.1145/1744161.1744163]
   Oz C, 2005, LECT NOTES COMPUT SC, V3776, P280
   Panwar Meenakshi, 2011, P INT C IM INF PROC
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren G, 2013, COMPUT GRAPH-UK, V37, P101, DOI 10.1016/j.cag.2012.12.006
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Rigoll G., 1998, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop Proceedings, P69
   Roccaro M, 2011, METHODS MOL BIOL, V712, P45, DOI 10.1007/978-1-61737-998-7_5
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Roccetti Marco, 2010, COMPUT ENTERTAINMENT, V8, P5
   Shackel Brian, 2009, USABILITY CONTEXT FR
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Wang XY, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/986134
   Wang Youwen, 2012, P 4 INT C INT HUM MA, V1, P394
   Weissmann J., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P2043, DOI 10.1109/IJCNN.1999.832699
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   Yang Z, 2012, INT CONF COMP SCI ED, P360, DOI 10.1109/ICCSE.2012.6295092
   Yanghee Nam, 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P51
   Yeasin M, 2000, PATTERN RECOGN, V33, P1805, DOI 10.1016/S0031-3203(99)00175-2
NR 33
TC 62
Z9 65
U1 0
U2 66
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 97
EP 104
DI 10.1016/j.jvcir.2015.01.015
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000011
DA 2024-07-18
ER

PT J
AU Gupta, V
   Chaurasia, V
   Shandilya, M
AF Gupta, Vikas
   Chaurasia, Vijayshri
   Shandilya, Madhu
TI Random-valued impulse noise removal using adaptive dual threshold median
   filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image de-noising; Median filter; Noise detection; Noise removal;
   Random-valued impulse noise; Dual threshold; Two-stage scheme; Filtering
   window
ID HIGHLY CORRUPTED IMAGES; ALGORITHM
AB Noise detection and its removal is very important in the image processing. Detection of noise is very crucial and significant in random valued impulse noise because it does not hamper the image pixels uniformly. This paper presents a novel and unique concept of adaptive dual threshold for the detection of random valued impulse noise along with simple median filter at noise removal stage. Simulation results shows that an efficient noise detection leads to a superior quality of de-noised image as compared to existing adaptive threshold based image de-noising techniques. Proposed threshold computation is based on averaging of pixel values of window which enhances the PSNR of our system as compared to existing median filter based image de-noising methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Gupta, Vikas; Chaurasia, Vijayshri; Shandilya, Madhu] Maulana Azad Natl Inst Technol, Bhopal, MP, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Gupta, V (corresponding author), Maulana Azad Natl Inst Technol, Bhopal, MP, India.
EM vgup24@yahoo.com; vijayshree21@gmail.com; madhu_shandilya@yahoo.in
RI ; Chaurasia, Vijayshri/A-5554-2016
OI shandilya, madhu/0009-0009-3874-456X; Chaurasia,
   Vijayshri/0000-0002-3347-5630
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   Akkoul S, 2010, IEEE SIGNAL PROC LET, V17, P587, DOI 10.1109/LSP.2010.2048646
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Awad AS, 2011, IEEE SIGNAL PROC LET, V18, P407, DOI 10.1109/LSP.2011.2154330
   Burger H., 2011, IEEE INT C COMP PHOT, P1
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Civicioglu P, 2009, IEEE T CONSUM ELECTR, V55, P2097, DOI 10.1109/TCE.2009.5373774
   COYLE EJ, 1989, IEEE T ACOUST SPEECH, V37, P2037, DOI 10.1109/29.45552
   Dinneen L.C., 1973, APPL STAT, V22
   Dong Fuguo, 2010, INT J DIGITAL CONTEN, V4, P79
   Faouzi Benzarti, 2011, 8 IEEE INT MULT SYST, P1
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Harding E.F., 1983, APPL STAT, P33
   Karita Yuji, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P3096, DOI 10.1109/SICE.2008.4655196
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Lan X, 2014, OPTIK, V125, P1101, DOI 10.1016/j.ijleo.2013.07.114
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   NIEMINEN A, 1987, IEEE T PATTERN ANAL, V9, P74, DOI 10.1109/TPAMI.1987.4767873
   Shen J, 2013, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2013.157
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Sveinsson JR, 2000, INT GEOSCI REMOTE SE, P1666, DOI 10.1109/IGARSS.2000.857306
   Turkmen I, 2013, AEU-INT J ELECTRON C, V67, P771, DOI 10.1016/j.aeue.2013.03.006
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Yu HC, 2008, IEEE SIGNAL PROC LET, V15, P922, DOI 10.1109/LSP.2008.2005051
NR 24
TC 68
Z9 71
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 296
EP 304
DI 10.1016/j.jvcir.2014.10.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000027
DA 2024-07-18
ER

PT J
AU Lin, PY
   Hsieh, WF
AF Lin, Pei-Yu
   Hsieh, Wei-Fan
TI Media pattern exhibition mechanism via mobile devices
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Histogram; Mobile device; Imperceptible; Visible; Watermarking;
   Dilation; Concealment; Robust
ID REVERSIBLE WATERMARKING; DIGITAL WATERMARKING; NETWORKS; IMAGES
AB This paper describes a new methodology of pattern exhibition for digital media that can conceal an imperceptible but recognizable watermark on the media captured with mobile devices. From the human perception, the imperceptible watermark of marked media can preserve the fidelity and readability of the image's content. With the designed, window-based histogram operation, the embedded pattern of the marked media can be exhibited and recognized visually. That is, the designed mechanism can satisfy the essentials of both visible and invisible watermarking techniques to promote significant pattern sharing and identification for mobile applications. Simulations demonstrate that the peak signal-to-noise ratio (PSNR) of the marked image is superior (around 50-70 dB) to many of the existing watermarking algorithms. The process is of low computational complexity, efficient and can be applied in the real world via mobile devices via inner histogram operation. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lin, Pei-Yu; Hsieh, Wei-Fan] Yuan Ze Univ, Innovat Ctr Big Data & Digital Convergence, Dept Informat Commun, Chungli 32003, Taiwan.
C3 Yuan Ze University
RP Lin, PY (corresponding author), Yuan Ze Univ, Innovat Ctr Big Data & Digital Convergence, Dept Informat Commun, 135 Yuan Tung Rd, Chungli 32003, Taiwan.
EM pylin@saturn.yzu.edu.tw
OI Lin, Pei-Yu/0000-0001-8809-1063
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fridrich J., 2012, IEEE T INF FORENSICS, V7
   Hsieh WF, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P1002, DOI 10.1109/UIC-ATC.2012.13
   Huang CH, 2009, IEEE T INF FOREN SEC, V4, P193, DOI 10.1109/TIFS.2009.2020778
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Lin PY, 2009, IEEE T CIRC SYST VID, V19, P1169, DOI 10.1109/TCSVT.2009.2020263
   Lin YH, 2012, INT CONF ACOUST SPEE, P1801, DOI 10.1109/ICASSP.2012.6288250
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Naor N., 1994, LECT NOTE COMPUTER S, P1
   Nezhadarya E., IEEE T INF FORENSICS, V6
   Nicholson D.R., 2009, LIB INFORM SCI RES E, V19
   Piva A, 2002, IEEE INTERNET COMPUT, V6, P18, DOI 10.1109/MIC.2002.1003126
   Roy SD, 2013, IEEE T CIRC SYST VID, V23, P300, DOI 10.1109/TCSVT.2012.2203738
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   YEUNG MM, 1997, P IEEE 1 WORKSH MULT, P357
   Yip SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P853, DOI 10.1109/ICME.2006.262635
NR 23
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1856
EP 1864
DI 10.1016/j.jvcir.2014.09.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300005
DA 2024-07-18
ER

PT J
AU Cosar, S
   Çetin, M
AF Cosar, Serhan
   Cetin, Mujdat
TI Feature compression: A framework for multi-view multi-person tracking in
   visual sensor networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual sensor networks; Camera networks; Human tracking; Decentralized
   tracking; Communication constraints; Feature compression; Compressing
   likelihood functions; Bandwidth-efficient tracking
AB Visual sensor networks (VSNs) consist of image sensors, embedded processors and wireless transceivers which are powered by batteries. Since the energy and bandwidth resources are limited, setting up a tracking system in VSNs is a challenging problem. In this paper, we present a framework for human tracking in VSNs. The traditional approach of sending compressed images to a central node has certain disadvantages such as decreasing the performance of further processing (i.e., tracking) because of low quality images. Instead, we propose a feature compression-based decentralized tracking framework that is better matched with the further inference goal of tracking. In our method, each camera performs feature extraction and obtains likelihood functions. By transforming to an appropriate domain and taking only the significant coefficients, these likelihood functions are compressed and this new representation is sent to the fusion node. As a result, this allows us to reduce the communication in the network without significantly affecting the tracking performance. An appropriate domain is selected by performing a comparison between well-known transforms. We have applied our method for indoor people tracking and demonstrated the superiority of our system over the traditional approach and a decentralized approach that uses Kalman filter. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Cosar, Serhan; Cetin, Mujdat] Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Tuzla Istanbul, Turkey.
C3 Sabanci University
RP Cosar, S (corresponding author), Sabanci Univ, Fac Engn & Nat Sci, Orta Mahalle,Univ Caddesi 27, TR-34956 Tuzla Istanbul, Turkey.
EM serhancosar@sabanciuniv.edu; mcetin@sabanciuniv.edu
OI Cosar, Serhan/0000-0003-4358-1063; Cetin, Mujdat/0000-0002-9824-1229
FU Turkish Academy of Sciences; Scientific and Technological Research
   Council of Turkey
FX This work was partially supported by a Turkish Academy of Sciences
   Distinguished Young Scientist Award and by a graduate scholarship from
   the Scientific and Technological Research Council of Turkey.
CR Akyildiz IF, 2007, IEEE WIREL COMMUN, V14, P32, DOI 10.1109/MWC.2007.4407225
   [Anonymous], ECCV WORKSH MULT MUL
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   Dieber B, 2011, IEEE T CIRC SYST VID, V21, P1424, DOI 10.1109/TCSVT.2011.2162770
   Fleck S, 2007, EURASIP J EMBED SYST, DOI 10.1155/2007/29858
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Gupta A, 2008, IEEE T PATTERN ANAL, V30, P493, DOI 10.1109/TPAMI.2007.1173
   Hengstler S, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P360, DOI 10.1109/IPSN.2007.4379696
   Hofmann Michael, 2009, CVPR
   Karuppiah DR, 2010, MACH VISION APPL, V21, P517, DOI 10.1007/s00138-008-0182-7
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Medeiros H, 2008, IEEE J-STSP, V2, P448, DOI 10.1109/JSTSP.2008.2001310
   Mittal A, 2008, INT J COMPUT VISION, V76, P31, DOI 10.1007/s11263-007-0057-9
   Monari Eduardo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P40, DOI 10.1109/AVSS.2010.66
   Oto E, 2006, LECT NOTES COMPUT SC, V4179, P299
   Pahalawatta PV, 2004, IEEE IMAGE PROC, P3073
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Song B, 2008, IEEE J-STSP, V2, P582, DOI 10.1109/JSTSP.2008.925992
   Taj M, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940281
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Ten Daubechies I., 1992, lecture on wavelets
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Winger LL, 1998, INT CONF ACOUST SPEE, P2681, DOI 10.1109/ICASSP.1998.678075
   Wolf W, 2002, COMPUTER, V35, P48, DOI 10.1109/MC.2002.1033027
   Yoder J, 2010, IEEE T IMAGE PROCESS, V19, P2551, DOI 10.1109/TIP.2010.2049179
   Yu C, 2010, IEEE T IMAGE PROCESS, V19, P2042, DOI 10.1109/TIP.2010.2046794
NR 29
TC 7
Z9 8
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 864
EP 873
DI 10.1016/j.jvcir.2014.02.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200015
DA 2024-07-18
ER

PT J
AU Hua, KL
   Wang, HC
   Rusdi, AH
   Jiang, SY
AF Hua, Kai-Lung
   Wang, Hong-Cyuan
   Rusdi, Aulia Hakim
   Jiang, Shin-Yi
TI A novel multi-focus image fusion algorithm based on random walks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-focus images; Image Fusion; Random walks; Shallow depth of field;
   Connected graph; Power law normalization; Focus measure; Color
   consistency
ID SEGMENTATION; PERFORMANCE
AB In multi-focus image fusion, the aim is to create a single image where the whole scene is focused by fusing multiple images captured with different focus distances. The fused image has greater depth of field than each of the input images. In this paper, we present a new method for multi-focus image fusion via random walks on graphs. The proposed method first evaluates the focus areas in a local sense and identifies nodes corresponding to consistency of nodes in a global sense. Several popular feature sets based on focus measure and color consistency are evaluated and employed to create a fully connected graph to model the global and local characteristics, respectively, of the random walks. The behavior of random walks on the graph is utilized to compute the weighting factor for each of the shallow depth-of-field input image. Experimental results show that the proposed method outperforms many state-of-the-art techniques in both subjective and objective image quality measures. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Hua, Kai-Lung; Wang, Hong-Cyuan; Rusdi, Aulia Hakim; Jiang, Shin-Yi] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Hua, KL (corresponding author), 43 Sec 4,Keelung Rd, Keelung, Taiwan.
EM hua@mail.ntust.edu.tw
OI Hua, Kai-Lung/0000-0002-7735-243X
FU Ministry of Science and Technology [MOST102-2221-E-011-162]
FX This work was supported by the Ministry of Science and Technology under
   Grant MOST102-2221-E-011-162.
CR Anish A, 2012, INT J ADV RES COMPUT, V1
   Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Aslantas V, 2009, OPT COMMUN, V282, P3231, DOI 10.1016/j.optcom.2009.05.021
   BURT PJ, 1984, MULTIRESOLUTION IMAG, P6, DOI [DOI 10.1007/978-3-642-51590-3_2, 10.1007/978-3-642-51590-3_2]
   Chai Y, 2011, OPT COMMUN, V284, P4376, DOI 10.1016/j.optcom.2011.05.046
   Choi KS, 1999, IEEE T CONSUM ELECTR, V45, P820, DOI 10.1109/30.793616
   De I, 2006, IMAGE VISION COMPUT, V24, P1278, DOI 10.1016/j.imavis.2006.04.005
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Doyle P.G., 1984, Random Walks and Electric Networks, V22
   Grady L, 2005, PROC CVPR IEEE, P763
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Tian J, 2010, IEEE IMAGE PROC, P1205, DOI 10.1109/ICIP.2010.5651791
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang YJ, 2009, DIGIT SIGNAL PROCESS, V19, P186, DOI 10.1016/j.dsp.2008.11.002
   Zhao HJ, 2013, PATTERN RECOGN, V46, P1002, DOI 10.1016/j.patcog.2012.09.012
NR 27
TC 38
Z9 43
U1 2
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 951
EP 962
DI 10.1016/j.jvcir.2014.02.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200023
DA 2024-07-18
ER

PT J
AU Kang, SH
   Shafei, B
   Steidl, G
AF Kang, Sung Ha
   Shafei, Behrang
   Steidl, Gabriele
TI Supervised and transductive multi-class segmentation using
   <i>p</i>-Laplacians and RKHS methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-class; Segmentation; Supervised learning; p-Laplacian; Reproducing
   kernel Hilbert space (RKHS); Primal-dual hybrid gradient algorithm
   (PDHGMp) a combined model; Medical image application
ID MULTIPHASE IMAGE SEGMENTATION; REGULARIZATION; FRAMEWORK; SNAKES; MODEL
AB This paper considers supervised multi-class image segmentation: from a labeled set of pixels in one image, we learn the segmentation and apply it to the rest of the image or to other similar images. We study approaches with p-Laplacians, Reproducing Kernel Hilbert Spaces (RKHSs) and combinations of both. In all approaches we construct segment membership vectors. In the p-Laplacian model the segment membership vectors have to fulfill a certain probability simplex constraint. Interestingly, we could prove that this is not really a constraint in the case p = 2 but is automatically fulfilled. While the 2-Laplacian model gives a good general segmentation, the case of the 1-Laplacian tends to neglect smaller segments. The RKHS approach has the benefit of fast computation. We further consider an improvement by combining p-Laplacian and RKHS methods. Finally, we present challenging applications to medical image segmentation. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Kang, Sung Ha] Georgia Inst Technol, Sch Math, Atlanta, GA 30332 USA.
   [Shafei, Behrang] Fraunhofer ITWM, D-67663 Kaiserslautern, Germany.
   [Steidl, Gabriele] Univ Kaiserslautern, Dept Math, D-67663 Kaiserslautern, Germany.
C3 University System of Georgia; Georgia Institute of Technology;
   University of Kaiserslautern
RP Kang, SH (corresponding author), Georgia Inst Technol, Sch Math, 686 Cherty St NW, Atlanta, GA 30332 USA.
EM kang@math.gatech.edu; shafei@itwm.fraunhofer.de;
   steidl@mathematik.uni-kl.de
OI Kang, Sung Ha/0000-0002-0312-6595
CR Amghibech S, 2003, ARS COMBINATORIA, V67, P283
   [Anonymous], 2003, INT C MACH LEARN
   [Anonymous], NUMERISCHE MATH
   [Anonymous], P 27 INT C MACH LEAR
   [Anonymous], 2004, Int. J. Numer. Anal. Model
   ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Vu BC, 2013, ADV COMPUT MATH, V38, P667, DOI 10.1007/s10444-011-9254-8
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bresson X., 2012, ARXIV12100699
   Bresson X., 2012, 1203 CAM UCLA
   Brox T, 2004, LECT NOTES COMPUT SC, V3175, P415
   Buhler T., 2009, P 26 INT C MACH LEAR
   Cai X., 2012, UCLA CAM REPORT, P12
   Carmeli C, 2006, ANAL APPL, V4, P377, DOI 10.1142/S0219530506000838
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan T, 2008, CAM REPORTS
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P53, DOI 10.1016/j.acha.2006.04.004
   Combettes P, 2012, SET-VALUED VAR ANAL, V20, P307, DOI 10.1007/s11228-011-0191-y
   Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10
   Delong A, 2009, IEEE I CONF COMP VIS, P285, DOI 10.1109/ICCV.2009.5459263
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Eriksson A, 2011, J MATH IMAGING VIS, V39, P45, DOI 10.1007/s10851-010-0223-5
   Esser J.E., 2010, THESIS UCLA
   Gelasca ED, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-368
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gilboa G, 2007, MULTISCALE MODEL SIM, V6, P595, DOI 10.1137/060669358
   Hagen L., 1991, 1991 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (91CH3026-2), P10, DOI 10.1109/ICCAD.1991.185177
   Hein M., 2010, P ADV NEURAL INFORM, V23
   Horn R. A., 2013, Topics in Matrix Analysis, V2nd
   Jung YM, 2007, SIAM J APPL MATH, V67, P1213, DOI 10.1137/060662708
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3
   Law YN, 2012, IEEE T IMAGE PROCESS, V21, P2955, DOI 10.1109/TIP.2012.2187670
   Lellmann J, 2009, LECT NOTES COMPUT SC, V5567, P150, DOI 10.1007/978-3-642-02256-2_13
   Lézoray O, 2010, PATTERN RECOGN LETT, V31, P2201, DOI 10.1016/j.patrec.2010.03.022
   Li F, 2010, SIAM J IMAGING SCI, V3, P277, DOI 10.1137/080736752
   Miccai workshop, 2009, MICC WORKSH CARD MR
   Micchelli CA, 2005, NEURAL COMPUT, V17, P177, DOI 10.1162/0899766052530802
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Petitjean C, 2011, MED IMAGE ANAL, V15, P169, DOI 10.1016/j.media.2010.12.004
   Peyré G, 2008, MULTISCALE MODEL SIM, V7, P703, DOI 10.1137/07068881X
   Pock T., 2009, LNCS
   Quang MH, 2010, J MATH IMAGING VIS, V37, P49, DOI 10.1007/s10851-010-0192-8
   Schwartz Laurent, 1964, J ANAL MATH, V13, P115, DOI DOI 10.1007/BF02786620
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Shafei B, 2012, J VIS COMMUN IMAGE R, V23, P611, DOI 10.1016/j.jvcir.2012.02.006
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sindhwani V., 2005, ICML, V2005, P74
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Suykens J. A. K., 2002, LEAST SQUARES SUPPOR
   Tai XC, 2002, MATH COMPUT, V71, P105
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Zach C., 2008, VIS MOD VIS WORKSH
   Zhou D., 2005, P 27 DAGM S
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zhu W, 2013, INT J COMPUT MATH, V90, P124, DOI 10.1080/00207160.2012.695355
NR 62
TC 16
Z9 17
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1136
EP 1148
DI 10.1016/j.jvcir.2014.03.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200040
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jung, JI
   Ho, YS
AF Jung, Jae-Il
   Ho, Yo-Sung
TI Geometric and colorimetric error compensation for multi-view images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view image; Geometric compensation; Color correction; Uniform view
   interval; Vertical disparity reduction; Projective transformation;
   Visual fatigue; 3DTV
ID RECTIFICATION
AB In general, excessive colorimetric and geometric errors in multi-view images induce visual fatigue to users. Various works have been proposed to reduce these errors, but conventional works have only been available for stereoscopic images while requiring cumbersome additional tasks, and often showing unstable results. In this paper, we propose an effective multi-view image refinement algorithm. The proposed algorithm analyzes such errors in multi-view images from sparse correspondences and compensates them automatically. While the conventional works transform every view to compensate geometric errors, the proposed method transforms only the source views with consideration of a reference view. Therefore this approach can be extended regardless of the number of views. In addition, we also employ uniform view intervals to provide consistent depth perception among views. We correct color inconsistency among views from the correspondences by considering importance and channel properties. Various experimental results show that the proposed algorithm outperforms conventional approaches and generates more visually comfortable multi-view images. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Jung, Jae-Il; Ho, Yo-Sung] GIST, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Ho, YS (corresponding author), GIST, 123 Cheomdangwagi Ro, Kwangju 500712, South Korea.
EM hoyo@gist.ac.kr
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2012-0009228]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (No. 2012-0009228).
CR [Anonymous], BT50011 IRR ITU
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], IMAGE VISION COMPUT
   [Anonymous], CS20050821 UCSD CSE
   Bay H., 2006, P EUR C COMP VIS, P407
   Brown MS, 2006, IEEE T IMAGE PROCESS, V15, P1544, DOI 10.1109/TIP.2006.871082
   Fecker U, 2008, IEEE T CIRC SYST VID, V18, P1258, DOI 10.1109/TCSVT.2008.926997
   Fusiello A, 2008, INT C PATT RECOG, P1490
   GILL PE, 1978, SIAM J NUMER ANAL, V15, P977, DOI 10.1137/0715063
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Jung JI, 2014, SIGNAL IMAGE VIDEO P, V8, P955, DOI 10.1007/s11760-012-0341-1
   Kang YS, 2011, IEEE T CONSUM ELECTR, V57, P1041, DOI 10.1109/TCE.2011.6018853
   Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Li Hyung-Chul O., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P213, DOI 10.1109/3DTV.2008.4547846
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   Mallon J, 2005, IMAGE VISION COMPUT, V23, P643, DOI 10.1016/j.imavis.2005.03.002
   Nozick Vincent, 2011, Proceedings of the 2011 1st International Symposium on Access Spaces (ISAS), P277, DOI 10.1109/ISAS.2011.5960962
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Tehrani MP, 2010, J VIS COMMUN IMAGE R, V21, P377, DOI 10.1016/j.jvcir.2010.03.007
   Wang Q, 2011, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2011.6116722
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
NR 25
TC 5
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 698
EP 708
DI 10.1016/j.jvcir.2013.04.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500010
DA 2024-07-18
ER

PT J
AU Theodorakopoulos, I
   Kastaniotis, D
   Economou, G
   Fotopoulos, S
AF Theodorakopoulos, Ilias
   Kastaniotis, Dimitris
   Economou, George
   Fotopoulos, Spiros
TI Pose-based human action recognition via sparse representation in
   dissimilarity space
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Sparse representation; Dissimilarity representation;
   Pose representation; Articulated human motion; RGB-D sensors; Angular
   features; Pose encoding
AB Human actions can be considered as a sequence of body poses over time, usually represented by coordinates corresponding to human skeleton models. Recently, a variety of low-cost devices have been released, able to produce markerless real time pose estimation. Nevertheless, limitations of the incorporated RGB-D sensors can produce inaccuracies, necessitating the utilization of alternative representation and classification schemes in order to boost performance. In this context, we propose a method for action recognition where skeletal data are initially processed in order to obtain robust and invariant pose representations and then vectors of dissimilarities to a set of prototype actions are computed. The task of recognition is performed in the dissimilarity space using sparse representation. A new publicly available dataset is introduced in this paper, created for evaluation purposes. The proposed method was also evaluated on other public datasets, and the results are compared to those of similar methods. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Theodorakopoulos, Ilias; Kastaniotis, Dimitris; Economou, George; Fotopoulos, Spiros] Univ Patras, Dept Phys, Elect Lab, Patras 26500, Greece.
C3 University of Patras
RP Theodorakopoulos, I (corresponding author), Univ Patras, Dept Phys, Elect Lab, Patras 26500, Greece.
EM iltheodorako@upatras.gr
RI Theodorakopoulos, Ilias/AAS-4622-2021
OI Theodorakopoulos, Ilias/0000-0002-9392-8902; Economou,
   George/0000-0001-9938-0768
FU European Union (European Social Fund - ESF); Greek national funds
   through the Operational Program "Education and Lifelong Learning" of the
   National Strategic Reference Framework (NSRF) - Research Funding
   Program: Heracleitus II. Investing in knowledge society through the
   European Social Fund
FX This research has been co-financed by the European Union (European
   Social Fund - ESF) and Greek national funds through the Operational
   Program "Education and Lifelong Learning" of the National Strategic
   Reference Framework (NSRF) - Research Funding Program: Heracleitus II.
   Investing in knowledge society through the European Social Fund.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   [Anonymous], DYNAMIC PROGRAMMING
   Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3
   Chen S.S., 1998, SIAM J SCI COMPUT, V20, P2845
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Duin RPW, 2010, LECT NOTES COMPUT SC, V6218, P324, DOI 10.1007/978-3-642-14980-1_31
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fang SC, 2009, PATTERN RECOGN, V42, P1824, DOI 10.1016/j.patcog.2008.11.020
   Faundez-Zanuy M, 2011, PATTERN ANAL APPL, V14, P37, DOI 10.1007/s10044-010-0176-8
   FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Labusch K, 2009, NEUROCOMPUTING, V72, P1547, DOI 10.1016/j.neucom.2008.11.027
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012
   Pekalska E., 2005, The Dissimilarity Representation for Pattern Recognition
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M., 2011, P ACM SIGGRAPH EUR S, P976
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Theodorakopoulos I., 2013, ICPRAM IN PRESS
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 34
TC 67
Z9 75
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 12
EP 23
DI 10.1016/j.jvcir.2013.03.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900003
DA 2024-07-18
ER

PT J
AU Zhao, GQ
   Xiao, XH
   Yuan, JS
   Ng, GW
AF Zhao, Gangqiang
   Xiao, Xuhong
   Yuan, Junsong
   Ng, Gee Wah
TI Fusion of 3D-LIDAR and camera data for scene parsing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene parsing; Velodyne scanner; Camera; Fuzzy logic; Temporal fusion;
   MRF; Object detection; RGBD
ID SEMANTIC SEGMENTATION; OBJECT RECOGNITION; CLASSIFICATION; TEXTURE
AB Fusion of information gathered from multiple sources is essential to build a comprehensive situation picture for autonomous ground vehicles. In this paper, an approach which performs scene parsing and data fusion for a 3D-LIDAR scanner (Velodyne HDL-64E) and a video camera is described. First of all, a geometry segmentation algorithm is proposed for detection of obstacles and ground areas from data collected by the Velodyne scanner. Then, corresponding image collected by the video camera is classified patch by patch into more detailed categories. After that, parsing result of each frame is obtained by fusing result of Velodyne data and that of image using the fuzzy logic inference framework. Finally, parsing results of consecutive frames are smoothed by the Markov random field based temporal fusion method. The proposed approach has been evaluated with datasets collected by our autonomous ground vehicle testbed in both rural and urban areas. The fused results are more reliable than that acquired via analysis of only images or Velodyne data. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhao, Gangqiang; Yuan, Junsong] Nanyang Technol Univ, Sch EEE, Singapore 639798, Singapore.
   [Xiao, Xuhong; Ng, Gee Wah] DSO Natl Labs, Singapore, Singapore.
C3 Nanyang Technological University
RP Zhao, GQ (corresponding author), Nanyang Technol Univ, Sch EEE, Singapore 639798, Singapore.
EM GQZhao@ntu.edu.sg
RI Yuan, Junsong/R-4352-2019; Yuan, Junsong/A-5171-2011
OI Yuan, Junsong/0000-0002-7901-8793
FU Nanyang Assistant Professorship [SUG M4080134]; JSPS-NTU joint project
   [M4080882]; NTU CoE seed grant [M4081039]; NTU-DSO joint project
   [M4060969]
FX This work is supported in part by Nanyang Assistant Professorship SUG
   M4080134, JSPS-NTU joint project M4080882, NTU CoE seed grant M4081039,
   and NTU-DSO joint project M4060969.
CR [Anonymous], 2012, CVPR
   [Anonymous], 2010, BRIT MACH VIS C AB U
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2011, ECMR
   [Anonymous], 2009, P BMVC BRIT MACH VIS
   [Anonymous], CVPR
   [Anonymous], 2012, HDL 64E
   [Anonymous], 2012, COMPUTER VISION PATT
   [Anonymous], 2012, KIN
   Batra D., 2008, CVPR
   Behley J, 2012, IEEE INT CONF ROBOT, P4391, DOI 10.1109/ICRA.2012.6225003
   Bouguet JY, 2012, Camera calibration toolbox for matlab
   BRADLEY D, 2007, IEEE INT C ROB AUT
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Burr D., 2011, SENS CUE INTEGR, P167
   DOUILLARD B, 2009, P 5 INT C INT SENS S
   Douillard Bertrand, 2010, INT S EXP ROB 2010
   Farabet C., 2012, P INT C MACH LEARN I
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2010.5540067
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Galleguillos Carolina., 2008, CVPR
   Garcia F., 2010, P INT TRANSP SYST C
   Habtemariam B.K., 2011, P 14 INT C FUS FUSIO
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   Himmelsbach M, 2011, KUNSTL INTELL, V25, P145, DOI 10.1007/s13218-011-0091-1
   Jacoby L., 2011, TECHNICAL REPORT
   Kaempchen N., 2005, INT VEH S 4
   Kidono K., 2012, 15 INT IEEE C INT TR
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Labayrade R, 2005, AUTON ROBOT, V19, P117, DOI 10.1007/s10514-005-0611-7
   Ladicky L'ubor, 2010, Computer Vision - ECCV 2010. Proceedings 11th European Conference on Computer Vision, P424, DOI 10.1007/978-3-642-15561-1_31
   Laible S., 2012, Autonomous Mobile Systems 2012: 22. Fachgesprach Stuttgart, P21
   Larlus D., 2008, C COMP VIS PATT REC
   Lin C.-.T., 1996, Neural Fuzzy Systems: A Neuro-Fuzzy Synergism to Intelligent Systems
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Mamdani EH, 1999, INT J HUM-COMPUT ST, V51, P135, DOI 10.1006/ijhc.1973.0303
   Martin S., 2011, P 14 INT C FUS FUSIO
   Matthaei R., 2011, P 14 INT C FUS FUSIO
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Pantofaru C, 2008, LECT NOTES COMPUT SC, V5304, P481, DOI 10.1007/978-3-540-88690-7_36
   Pascal G., 2010, ECCV WORKSH COMP VIS
   Premebida C, 2009, J FIELD ROBOT, V26, P696, DOI 10.1002/rob.20312
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Schneider S, 2010, IEEE INT VEH SYM, P388, DOI 10.1109/IVS.2010.5548079
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Spinello L, 2011, IEEE INT CONF ROBOT, P1304, DOI 10.1109/ICRA.2011.5980085
   Tang W., 2011, P 14 INT C FUS FUSIO
   Teichman Alex., 2011, Robotics: Science and Systems
   Teutsch M., 2011, P 14 INT C FUS FUSIO
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tu ZW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P18, DOI 10.1109/ICCV.2003.1238309
   Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174
   Xiao JX, 2009, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2009.5459249
   Xu Y, 2009, P 22 AUSTR JOINT C A
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao G., 2012, 15 INT C INF FUS FUS
NR 61
TC 41
Z9 45
U1 1
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 165
EP 183
DI 10.1016/j.jvcir.2013.06.008
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900015
DA 2024-07-18
ER

PT J
AU Inoue, N
   Shinoda, K
AF Inoue, Nakamasa
   Shinoda, Koichi
TI q-Gaussian mixture models for image and video semantic indexing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic indexing; Gaussian mixture models; q-Gaussian mixture models;
   GMM supervector; Image classification; Bag-of-words; Codebook; Tsallis
   statistics
AB Gaussian mixture models which extend Bag-of-Visual-Words (BoW) to a probabilistic framework have been proved to be effective for image and video semantic indexing. Recently, the q-Gaussian distribution, derived from Tsallis statistics [11], has been shown to be useful for representing patterns in many complex systems in physics. We propose q-Gaussian mixture models (q-GMMs), mixture models of q-Gaussian distributions with a parameter q to control its tail-heaviness, for image and video semantic indexing [1]. The long-tailed distributions obtained for q>1 are expected to effectively represent complexly correlated data, and hence, to improve robustness against outliers. The main improvements over our previous study [1] are q-GMM super-vector representation to efficiently compute the q-GMM kernel, and detailed experimental analysis showing accuracy and testing-cost comparison with recent kernel methods. Our proposed method outperformed BoW and achieved 49.42% and 10.90% in Mean Average Precision on the PASCAL VOC 2010 and the TRECVID 2010 Semantic Indexing, respectively. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Inoue, Nakamasa; Shinoda, Koichi] Tokyo Inst Technol, Dept Comp Sci, Tokyo 1528552, Japan.
C3 Tokyo Institute of Technology
RP Inoue, N (corresponding author), Tokyo Inst Technol, Dept Comp Sci, Tokyo 1528552, Japan.
EM inoue@ks.cs.titech.ac.jp; shinoda@cs.titech.ac.jp
RI Shinoda, Koichi/D-3198-2014
OI Shinoda, Koichi/0000-0003-1095-3203
FU JSPS KAKENHI [24650079, 11J04223]; Grants-in-Aid for Scientific Research
   [11J04223, 24650079] Funding Source: KAKEN
FX This work was partly supported by JSPS KAKENHI Grant No. 24650079 and
   11J04223.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 1967, KYBERNETIKA
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   Ayache S., 2008, P ECIR
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Fabbri R, 2012, PHYSICA A, V391, P4487, DOI 10.1016/j.physa.2012.05.001
   Inoue N., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P1357
   Inoue N., 2012, P ACCV
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Lin QQ, 2012, SIGNAL PROCESS, V92, P2931, DOI 10.1016/j.sigpro.2012.05.025
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Perronnin F., 2007, P IEEE CVPR, P1
   Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Sahoo PK, 2006, PATTERN RECOGN LETT, V27, P520, DOI 10.1016/j.patrec.2005.09.017
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Tsallis C, 1998, PHYSICA A, V261, P534, DOI 10.1016/S0378-4371(98)00437-3
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Williams C.K.I., PASCAL VISUAL OBJECT
   Yan Li, 2006, 2006 4th IEEE International Conference on Industrial Informatics, P943
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zha Z.-J., 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587384
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 33
TC 4
Z9 5
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1450
EP 1457
DI 10.1016/j.jvcir.2013.10.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Horng, SJ
   Rosiyadi, D
   Li, TR
   Takao, T
   Guo, MY
   Khan, MK
AF Horng, Shi-Jinn
   Rosiyadi, Didi
   Li, Tianrui
   Takao, Terano
   Guo, Minyi
   Khan, Muhammad Khurram
TI A blind image copyright protection scheme for e-government
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind; Quantizing value; Discrete cosine transform; Singular value
   decomposition; E-government; Genetic algorithm; Pick signal to noise
   ratio; Minimum square error
ID WATERMARKING
AB An efficient blind copyright protection for e-government document images is proposed through a combination of the discrete cosine transform (DCT) and the singular value decomposition (SVD) based on genetic algorithm (GA). This combination could lead the watermarked image to be resistant to various attacks as well as to improve its performance, security and robustness. DCT, in this case, is applied to the entire image and mapped by a zigzag manner to four areas from the lowest to the highest frequencies. SVD, meanwhile, is applied in each area and then the singular value of DCT-transformed host image, subsequently, is modified in each area with the quantizing value using GA to increase the visual quality and the robustness. The host image is not needed in the watermark extraction and it is more useful than non-blind one in real-world applications. Experiment results demonstrate that the proposed method outperforms other existing methods under several types of attacks. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Horng, Shi-Jinn; Li, Tianrui] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Horng, Shi-Jinn; Rosiyadi, Didi] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Takao, Terano] Tokyo Inst Technol, Dept Computat Intelligence & Syst Sci, Tokyo 152, Japan.
   [Guo, Minyi] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh 11451, Saudi Arabia.
C3 Southwest Jiaotong University; National Taiwan University of Science &
   Technology; Tokyo Institute of Technology; Shanghai Jiao Tong
   University; King Saud University
RP Horng, SJ (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM horngsj@yahoo.com.tw; didi.rosiyadi@gmail.com; trli@swjtu.edu.cn;
   terano@plum.plala.orjp; my@cs.sjtu.edu.cn; mkhurram@ksu.edu.sa
RI Nusa, Nuhammad/JXY-5819-2024; Horng, Shi-Jinn/GVU-0488-2022; Khan,
   Muhammad/IXN-8470-2023; Li, Tianrui/A-4889-2012; Li,
   Tianrui/F-4974-2019; rosiyadi, didi/AAG-9137-2021; KHAN, MUHAMMAD
   KHURRAM/E-4836-2014
OI Li, Tianrui/0000-0001-7780-104X; KHAN, MUHAMMAD
   KHURRAM/0000-0001-6636-0533
FU  [11:04/SK/KPPI/II/2007]
FX This paper was developed on the PhD research in National Taiwan
   University of Science and Technology, and the basis of LI-PI's
   competitive research entitled e-government Development Framework-Based
   Open Source in 2007-2008, no contract 11:04/SK/KPPI/II/2007.
CR Agarwal P, 2009, IEEE T INF FOREN SEC, V4, P36, DOI 10.1109/TIFS.2008.2011081
   Aslantas V., 2007, IEEE INT S INT SIGN, P1
   Kim Kyung-Su, 2008, P 3 INT C INT INF HI, P477
   Kumar Sharma D, 2007, DIGITAL WATERMARKING, P182
   Lai CC, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P469, DOI 10.1109/IIH-MSP.2008.168
   Leung HY, 2011, LECT NOTES COMPUT SC, V6526, P148, DOI 10.1007/978-3-642-18405-5_12
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Liu F, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P283, DOI 10.1109/ICICISYS.2009.5357687
   Ma XH, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1063, DOI 10.1109/ICALIP.2008.4590092
   Makhloghi M., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P219, DOI 10.1109/ISSPIT.2010.5711780
   Modaghegh Hamed, 2009, 2009 International Conference on Innovations in Information Technology (IIT), P6, DOI 10.1109/IIT.2009.5413374
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Tong M, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P655, DOI 10.1109/CISP.2008.47
   Wang Hui-Qin, 2010, Proceedings of the 2010 6th International Conference on Digital Content, Multimedia Technology and its Applications (IDC 2010), P59
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhao X, 2010, STUD COMPUT INTELL, V282, P337
NR 18
TC 50
Z9 54
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1099
EP 1105
DI 10.1016/j.jvcir.2013.07.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700033
DA 2024-07-18
ER

PT J
AU Peng, JY
   Shen, Y
   Fan, JP
AF Peng, Jinye
   Shen, Yi
   Fan, Jianping
TI Cross-modal social image clustering and tag cleansing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-modal image clustering; Social tag cleansing; Weakly-tagged social
   images; K-way min-max cut; Mixture-of-kernels; Spectral clustering; Spam
   tag detection; Image similarity measurement
ID SEMANTIC GAP; RETRIEVAL
AB In this paper, a cross-modal approach is developed for social image clustering and tag cleansing. First, a semantic image clustering algorithm is developed for assigning large-scale weakly-tagged social images into a large number of image topics of interest. Spam tags are detected automatically via sentiment analysis and multiple synonymous tags are merged as one super-topic according to their inter-topic semantic similarity contexts. Second, multiple base kernels are seamlessly combined by maximizing the correlations between the visual similarity contexts and the semantic similarity context, which can achieve more precise characterization of cross-modal (semantic and visual) similarity contexts among weakly-tagged social images. Finally, a K-way min-max cut algorithm is developed for social image clustering by minimizing the cumulative inter-cluster cross-modal similarity contexts while maximizing the cumulative intra-cluster cross-modal similarity contexts. The optimal weights for base kernel combination are simultaneously determined by minimizing the cumulative within-cluster variances. The polysemous tags and their ambiguous images are further split into multiple sub-topics for reducing their within-topic visual diversity. Our experiments on large-scale weakly-tagged Flickr images have provided very positive results. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Peng, Jinye; Fan, Jianping] NW Univ Xian, Sch Informat Sci & Technol, Xian 710069, Peoples R China.
   [Shen, Yi; Fan, Jianping] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 Northwest University Xi'an; University of North Carolina; University of
   North Carolina Charlotte
RP Fan, JP (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM jfan@uncc.edu
RI Shen, Yi/B-1433-2010; Peng, Jin/HZH-6965-2023
OI Shen, Yi/0000-0003-0063-1200; 
FU National Science Foundation of China [61272285, 61103062, 61075014];
   Doctoral Program of Higher Education of China [20126101110022,
   20116102110027, 20116102120031]; Program for New Century Excellent
   Talents in University [NCET-10-0071]
FX The authors would like to than the reviewers for their insightful
   comments and suggestions to make this paper more readable. This research
   is partly supported by National Science Foundation of China under Grants
   61272285, 61103062 and 61075014, Doctoral Program of Higher Education of
   China (Grant No. 20126101110022, 20116102110027, 20116102120031) and
   Program for New Century Excellent Talents in University under
   NCET-10-0071.
CR Ames M., 2007, CHI
   [Anonymous], 2003, CSDTR0302 U LOND
   [Anonymous], WWW
   [Anonymous], 2006, P 15 INT C WORLD WID, DOI [DOI 10.1145/1135777.1135794, 10.1145/1135777.1135794]
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2001, ICDM
   [Anonymous], P IEEE CVPR
   Bao S., 2007, P 16 INT C WORLD WID, P501, DOI DOI 10.1145/1242572.1242640
   Barnard K, 2005, ARTIF INTELL, V167, P13, DOI 10.1016/j.artint.2005.04.009
   Barnard K, 2001, PROC CVPR IEEE, P434
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Begelman G., 2006, ACM WWW
   Ben-Haim N., 2006, IEEE CVPR WORKSH SLA
   Borthwick A., 1998, 7 MESS UND C MUC 7 P
   Bosch A., 2007, ACM CIVR
   Brooks C.H., 2006, ACM WWW
   Cai D., 2004, ACM Multimedia
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Cristianini N, 2002, J INTELL INF SYST, V18, P127, DOI 10.1023/A:1013625426931
   Dai YH, 2006, MATH PROGRAM, V106, P403, DOI 10.1007/s10107-005-0595-2
   Dave K., 2003, ACM WWW
   Dhillon I., 2004, KDD
   Fan J., 2012, IEEE T MULTIMEDIA, V14
   Fan J., 2009, ACM CIVR
   Fan J., 2009, IEEE T CSVT, V19
   Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Frome A., 2007, IEEE ICCV
   Gao Bin., 2005, ACM MULTIMEDIA
   Gemmell J., 2008, AAAI WORKSH
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Grineva M., 2008, AAAI
   Gu M., 2001, TECHNICAL REPORT
   Han J., 2006, DATA MINING CONCEPTS
   Jiang Y.-G., 2007, ACM CIVR
   Jindal N., 2007, ACM WWW
   Koutrika G., 2007, AIRWEB
   Liu B., 2005, ACM WWW
   Loeff N., 2006, P COLINGACL, P547
   Lu YJ, 2010, IEEE T MULTIMEDIA, V12, P288, DOI 10.1109/TMM.2010.2046292
   Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   Nyuyen G.P., 2006, J VISUAL LANG COMPUT
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Shi J., 2000, IEEE T PAMI
   Simpson E., 2007, HPL2007190
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Stella X. Y., 2003, ICCV, P313, DOI DOI 10.1109/ICCV.2003.1238361
   Sussna M., 1993, CIKM 93. Proceedings of the Second International Conference on Information and Knowledge Management, P67, DOI 10.1145/170088.170106
   Varma M., 2007, IEEE ICCV
   Wang X.-J., 2004, ACM MULTIMEDIA
   Wu B., 2006, ACM WWW
   Yuan D., 2009, KDD
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 56
TC 5
Z9 6
U1 3
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 895
EP 910
DI 10.1016/j.jvcir.2013.06.004
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700015
DA 2024-07-18
ER

PT J
AU Li, DY
   Li, WF
   Liao, QM
AF Li, Danyi
   Li, Weifeng
   Liao, Qingmin
TI Active contours driven by local and global probability distributions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Signed pressure force function; Active contour
   model; Intensity inhomogeneity; Level set method; Local probability
   distribution; Data-based prior probability; Hybrid model
ID IMAGE SEGMENTATION; MUMFORD; EVOLUTION; SNAKES
AB In this paper, we propose a new local signed pressure force (SPF) function, which is defined based on the local probability distributions. According to different methods of probability density estimation, the SPF function is categorized into two classes: parametric and non-parametric SPF function. By incorporating the SPF function into a generalized geodesic active contour model, we obtain a novel local segmentation model. This model is capable of extracting the desired target, whose intensity possesses nonuniform property and boundaries suffer from fuzzyness. Moreover, a data-based prior probability is introduced to influence the signs of the SPF function, and the segmentation results appear to be more accurate with its assistance. In order to release our proposed technique from rigorous initialization, we incorporate a global force into this local framework to form a hybrid model. Experimental results on synthetic and real images demonstrate the superior performance of our methods. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Li, Danyi; Li, Weifeng; Liao, Qingmin] Tsinghua Univ, Dept Elect Engn, Shenzhen 518055, Peoples R China.
C3 Tsinghua University
RP Liao, QM (corresponding author), Tsinghua Univ, Dept Elect Engn, Shenzhen 518055, Peoples R China.
EM lidanyi815@sina.com; li.weifeng@sz.tsinghua.edu.cn;
   liaoqm@tsinghua.edu.cn
FU National Natural Science Foundation; Guangdong Province [U1201257]
FX The authors thank the anonymous reviewers for their critical and
   constructive comments and suggestions, which are helpful to improve both
   technical and the literary quality of this paper. We also thanks Doctor
   J.M. Constans (CHU de Caen) and Doctor Shaowu Li (Tiantan Hospital,
   Beijing) for providing the MRI data used in this study. This work is
   supported by the key joint program of National Natural Science
   Foundation and Guangdong Province under Grant No. U1201257.
CR [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P203
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Gonzales R.C., 2002, Digital image processing
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Lehmann EL., 1959, TESTING STAT HYPOTHE
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Shi YG, 2005, PROC CVPR IEEE, P34
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P258, DOI 10.1109/TIP.2012.2214046
   Zhang KH, 2010, IEEE IMAGE PROC, P4105, DOI 10.1109/ICIP.2010.5651554
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 29
TC 26
Z9 29
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 522
EP 533
DI 10.1016/j.jvcir.2013.03.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900002
DA 2024-07-18
ER

PT J
AU Wu, XT
   Liu, T
   Sun, W
AF Wu, Xiaotian
   Liu, Tong
   Sun, Wei
TI Improving the visual quality of random grid-based visual secret sharing
   via error diffusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; Visual cryptography; Visual quality; Random grid;
   Error diffusion; Noise balanced; Homogeneous distribution; Pixel
   expansion
ID MULTIPLE SECRETS; IMAGE ENCRYPTION; CRYPTOGRAPHY; SCHEMES
AB Random grid (RG) is an approach to implement visual secret sharing (VSS) without pixel expansion. However, visual quality of the recovered secret image in RG-based VSS is not satisfactory. In this paper, two methodologies are introduced for improving image quality. Firstly, a random noise balanced error diffusion (RNBED) algorithm is proposed for generating RGs whose black pixels are distributed homogeneously. By combining the proposed RNBED algorithm and existing RG-based VSS schemes, two approaches for enhancing the recovered image quality are presented. Experimental results are provided, illustrating that competitive visual quality is achieved. (C) 2013 Published by Elsevier Inc.
C1 [Wu, Xiaotian] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Liu, Tong] China Criminal Police Univ, Dept Audiovisual & Image Technol, Shenyang 110854, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Sun, W (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM sunwei@mail.sysu.edu.cn
OI Wu, Xiaotian/0000-0002-1484-2247
FU Science and Technology Development Fund of Macao Special Administrative
   Region [006/2011/A1]; Sun Yat-sen University
FX The authors gratefully acknowledge the helpful comments and suggestions
   of the reviewers, which have improved the presentation. This work was
   partially supported by Science and Technology Development Fund of Macao
   Special Administrative Region under Contract 006/2011/A1 and innovative
   talent training program of Sun Yat-sen University.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Floyd R., P SID, V17, P75
   Hou YC, 2005, J RES PRACT INF TECH, V37, P179
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lau D., 2001, Modern digital halftoning, V8
   Lau DL, 2003, IEEE SIGNAL PROC MAG, V20, P28, DOI 10.1109/MSP.2003.1215229
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 21
TC 25
Z9 25
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 552
EP 566
DI 10.1016/j.jvcir.2013.03.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900005
DA 2024-07-18
ER

PT J
AU Yuan, Y
   Wu, F
   Shao, J
   Zhuang, YT
AF Yuan, Ying
   Wu, Fei
   Shao, Jian
   Zhuang, Yueting
TI Image annotation by semi-supervised cross-domain learning with group
   sparsity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-domain; Manifold regularization; Group sparsity; Multiple kernel
   learning; Multi-label; Image annotation; Semi-supervise; Discriminant
   analysis
AB With the explosive growth of multimedia data in the web, multi-label image annotation has been attracted more and more attention. Although the amount of available data is large and growing, the number of labeled data is quite small. This paper proposes an approach to utilize both unlabeled data in target domain and labeled data in auxiliary domain to boost the performance of image annotation. Moreover, since different kinds of heterogeneous features in images have different intrinsic discriminative power for image understanding, group sparsity is introduced in our approach to effectively utilize those heterogeneous visual features with data of target and auxiliary domains. We call this approach semi-supervised cross-domain learning with group sparsity (S(2)CLGS). The strength of the proposed S(2)CLGS method for multi-label image annotation is to integrate semi-supervised discriminant analysis, cross-domain learning and sparse coding together. Experiments demonstrate the effectiveness of S(2)CLGS in comparison with other image annotation algorithms. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Yuan, Ying; Wu, Fei; Shao, Jian; Zhuang, Yueting] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Shao, J (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
EM tracy1108@zju.edu.cn; wufei@zju.edu.cn; jshao@zju.edu.cn;
   yzhuang@zju.edu.cn
FU National Basic Research Program of China [2010CB327904]; NSFC [61070068,
   61105074]; Fundamental Research Funds for the Central Universities
FX This work is supported in part by National Basic Research Program of
   China (2010CB327904), NSFC (61070068, 61105074), and the Fundamental
   Research Funds for the Central Universities.
CR [Anonymous], 2003, P ADV NEUR INF PROC
   [Anonymous], 2008, AAAI
   [Anonymous], 2006, P 14 ACM INT C MULTI
   [Anonymous], P INT C MULT
   [Anonymous], INT J MULTIMEDIA INF
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2005, Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM'05, DOI [DOI 10.1145/1099554.1099591, 10.1145/1099554.1099591]
   [Anonymous], 2011, ACM T GRAPHIC
   [Anonymous], 2007, Proceedings of the 24th interna- tional conference on Machine learning
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Cao LL, 2009, IEEE I CONF COMP VIS, P1095, DOI 10.1109/ICCV.2009.5459401
   Cheng WW, 2009, MACH LEARN, V76, P211, DOI 10.1007/s10994-009-5127-5
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Daume III Hal, 2007, ACL 2007, P256
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Duan Lixin, 2009, P 26 ANN INT C MACH, P289
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269
   Han YH, 2010, AAAI CONF ARTIF INTE, P469
   Ji S., 2008, P 14 ACM SIGKDD INT, P381, DOI [DOI 10.1145/1401890.1401939, 10.1145/1401890.1401939]
   Ji SW, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1077
   Jiang W, 2008, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2008.4711716
   Jin R., 2003, Adv. Neural Inf. Process. Syst., V16, P921
   Li H, 2009, INT CONF DAT MIN WOR, P164, DOI 10.1109/ICDMW.2009.46
   Loui Alexander., 2007, MIR 07, P245
   Meagher M, 2007, IEEE INT CONF INF VI, P601
   Shen HF, 2010, IEEE INT CON MULTI, P980, DOI 10.1109/ICME.2010.5583900
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wu F., 2010, Proceedings of the International Conference on Multimedia (MM'10), P15, DOI DOI 10.1145/1873951.1873957
   Wu F, 2010, NEUROCOMPUTING, V73, P1641, DOI 10.1016/j.neucom.2009.11.040
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhuang YT, 2011, SCI CHINA INFORM SCI, V54, P2508, DOI 10.1007/s11432-011-4483-5
NR 36
TC 8
Z9 9
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 95
EP 102
DI 10.1016/j.jvcir.2012.02.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000002
DA 2024-07-18
ER

PT J
AU Elguebaly, T
   Bouguila, N
AF Elguebaly, Tarek
   Bouguila, Nizar
TI Generalized Gaussian mixture models as a nonparametric Bayesian approach
   for clustering using class-specific visual features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mixture models; Generalized Gaussian; Feature selection; Nonparametric
   Bayes; MCMC; Gibbs sampling; Photographic; Painting; Segmentation;
   Infrared images
ID FACIAL EXPRESSION RECOGNITION; DIRICHLET PROCESS MIXTURE; DISTINGUISHING
   PAINTINGS; AUTOMATIC-ANALYSIS; FEATURE-SELECTION; OBJECT DETECTION;
   IMAGE; SEGMENTATION; DISTRIBUTIONS; CONVERGENCE
AB Recently, there has been a growing interest in the problem of learning mixture models from data. The reasons and motivations behind this interest are clear, since finite mixture models offer a formal approach to the important problems of clustering and data modeling. In this paper, we address the problem of modeling non-Gaussian data which are largely present, and occur naturally, in several computer vision and image processing applications via the learning of a generative infinite generalized Gaussian mixture model. The proposed model, which can be viewed as a Dirichlet process mixture of generalized Gaussian distributions, takes into account the feature selection problem, also, by determining a set of relevant features for each data cluster which provides better interpretability and generalization capabilities. We propose then an efficient algorithm to learn this infinite model parameters by estimating its posterior distributions using Markov Chain Monte Carlo (MCMC) simulations. We show how the model can be used, while comparing it with other models popular in the literature, in several challenging applications involving photographic and painting images categorization, image and video segmentation, and infrared facial expression recognition. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Elguebaly, Tarek; Bouguila, Nizar] Concordia Univ, Fac Engn & Comp Sci, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
C3 Concordia University - Canada
RP Bouguila, N (corresponding author), Concordia Univ, Fac Engn & Comp Sci, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
EM t_elgue@encs.concordia.ca; bouguila@ciise.concordia.ca
RI Bouguila, Nizar/AAJ-2518-2020; Bouguila, Nizar/AGN-5929-2022
CR Allili MS, 2007, PATTERN RECOGN LETT, V28, P1946, DOI 10.1016/j.patrec.2007.05.002
   Allili MS, 2010, IEEE T CIRC SYST VID, V20, P1373, DOI 10.1109/TCSVT.2010.2077483
   Allili MS, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2898125
   [Anonymous], 1992, Statistical Science, DOI DOI 10.1214/SS/1177011143
   Athitsos V, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P10, DOI 10.1109/IVL.1997.629715
   Bagenstoss PM, 1999, IEEE T SIGNAL PROCES, V47, P3428, DOI 10.1109/78.806092
   Baggenstoss PM, 2000, INT C PATT RECOG, P763, DOI 10.1109/ICPR.2000.906186
   Baluja S, 1997, ARTIF INTELL, V97, P381, DOI 10.1016/S0004-3702(97)00065-9
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P727, DOI 10.1016/j.imavis.2006.05.015
   Bouguila N, 2007, IEEE T PATTERN ANAL, V29, P1716, DOI [10.1109/TPAMI.2007.1095, 10.1109/TPAMl.2007.1095]
   Bouguila N, 2012, EXPERT SYST APPL, V39, P5946, DOI 10.1016/j.eswa.2011.11.122
   Bouguila N, 2011, PATTERN RECOGN, V44, P1183, DOI 10.1016/j.patcog.2010.12.010
   Bouguila N, 2010, IEEE T NEURAL NETWOR, V21, P107, DOI 10.1109/TNN.2009.2034851
   Bouguila N, 2008, MACHINE LEARN SIGN P, P297, DOI 10.1109/MLSP.2008.4685496
   Boutemedjet S, 2009, IEEE T PATTERN ANAL, V31, P1429, DOI 10.1109/TPAMI.2008.155
   Cardie C, 2000, MACH LEARN, V41, P85, DOI 10.1023/A:1007665204628
   Chen W, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1123
   CLIFFORD P, 1993, J ROY STAT SOC B, V55, P53
   Cutzu F, 2005, COMPUT VIS IMAGE UND, V100, P249, DOI 10.1016/j.cviu.2004.12.002
   Cutzu F, 2003, PROC CVPR IEEE, P305
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   DRAPER D, 1995, J R STAT SOC B, V57, P45, DOI 10.1111/j.2517-6161.1995.tb02015.x
   Dunson DB, 2009, BIOMETRICAL J, V51, P273, DOI 10.1002/bimj.200800183
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Elguebaly T, 2011, LECT NOTES COMPUT SC, V6753, P201, DOI 10.1007/978-3-642-21593-3_21
   Elguebaly T, 2011, SIGNAL PROCESS, V91, P801, DOI 10.1016/j.sigpro.2010.08.014
   Elguebaly T, 2010, LECT NOTES ARTIF INT, V5998, P207, DOI 10.1007/978-3-642-12159-3_19
   ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069
   FARVARDIN N, 1984, IEEE T INFORM THEORY, V30, P485, DOI 10.1109/TIT.1984.1056920
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   GAO Z, 1995, IEEE SIGNAL PROC LET, V2, P197
   Gelfand AE, 2002, J COMPUT GRAPH STAT, V11, P289, DOI 10.1198/106186002760180518
   Ghosh J., 2003, Springer Series in Statistics
   Ghosh JK., 2006, An introduction to Bayesian analysis
   Godsill SJ, 1997, INT STAT REV, V65, P1
   Guglielmi A, 2002, J COMPUT GRAPH STAT, V11, P306, DOI 10.1198/106186002760180527
   Günsel B, 2005, IEEE IMAGE PROC, P2197
   Hammoud R, 2004, INT C PATT RECOG, P525, DOI 10.1109/ICPR.2004.1334289
   HEBERT TJ, 1992, IEEE T SIGNAL PROCES, V40, P2290, DOI 10.1109/78.157228
   HEBERT TJ, 1995, IEEE T IMAGE PROCESS, V4, P1084, DOI 10.1109/83.403415
   Hernández B, 2007, COMPUT VIS IMAGE UND, V106, P258, DOI 10.1016/j.cviu.2006.08.012
   Hoff PD, 2006, BAYESIAN ANAL, V1, P321, DOI 10.1214/06-BA111
   Huang J., 1999, IEEE COMPUT SOC C CO, V1, P541, DOI DOI 10.1109/CVPR.1999.786990.[25]S
   Hung WL, 2008, PATTERN RECOGN LETT, V29, P1317, DOI 10.1016/j.patrec.2008.02.003
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Khardon R, 1997, ARTIF INTELL, V97, P169, DOI 10.1016/S0004-3702(97)00044-1
   Konishi S, 2000, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.2000.855809
   Laptev I, 2009, IMAGE VISION COMPUT, V27, P535, DOI 10.1016/j.imavis.2008.08.010
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Levi K, 2004, PROC CVPR IEEE, P53
   Li YH, 2009, IEEE T PATTERN ANAL, V31, P953, DOI 10.1109/TPAMI.2008.261
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   MAUERSBERGER W, 1979, IEEE T INFORM THEORY, V25, P381, DOI 10.1109/TIT.1979.1056068
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Meignen S, 2006, IEEE T IMAGE PROCESS, V15, P1647, DOI 10.1109/TIP.2006.873455
   Mengersen KL, 1996, ANN STAT, V24, P101
   MILLER JH, 1972, IEEE T INFORM THEORY, V18, P241, DOI 10.1109/TIT.1972.1054787
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653
   Olague G, 2009, ADV PATTERN RECOGNIT, P213, DOI 10.1007/978-1-84800-277-7_10
   Palacios MB, 2006, J AM STAT ASSOC, V101, P604, DOI 10.1198/016214505000001195
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Prokoski F, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P5, DOI 10.1109/CVBVS.2000.855245
   Raftery AE, 1996, Markov Chain Monte Carlo in Practice, P115, DOI DOI 10.1007/978-1-4899-4485-6.1269
   Raja Y., 1998, PROC EUROPEAN C COMP, P460
   Rasmussen CE, 2000, ADV NEUR IN, V12, P554
   Regazzini E, 2002, ANN STAT, V30, P1376
   Robert C., 2007, BAYESIAN CHOICE DECI
   Roberts GO, 1999, J ROY STAT SOC B, V61, P643, DOI 10.1111/1467-9868.00198
   Rodriguez A, 2008, J AM STAT ASSOC, V103, P1131, DOI 10.1198/016214508000000553
   ROSENTHAL JS, 1995, J AM STAT ASSOC, V90, P558, DOI 10.2307/2291067
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   RUE H, 1995, J AM STAT ASSOC, V90, P900, DOI 10.2307/2291324
   Sefidpour A, 2012, EXPERT SYST APPL, V39, P8993, DOI 10.1016/j.eswa.2012.02.024
   Socolinsky DA, 2001, PROC CVPR IEEE, P527
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Stoica P, 2004, IEEE SIGNAL PROC MAG, V21, P36, DOI 10.1109/MSP.2004.1311138
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Trujillo L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P14
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   Vidal-Naquet M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P281
   Wallraven C, 2009, COMPUT GRAPH-UK, V33, P484, DOI 10.1016/j.cag.2009.04.003
   Wang JP, 1998, IEEE T PATTERN ANAL, V20, P619, DOI 10.1109/34.683775
   Watanabe S., 1985, PATTERN RECOGN
   Wei HL, 2007, IEEE T PATTERN ANAL, V29, P162, DOI 10.1109/TPAMI.2007.250607
   WILD P, 1993, J ROY STAT SOC C-APP, V42, P701
   Zhang HM, 2006, IMAGE VISION COMPUT, V24, P327, DOI 10.1016/j.imavis.2005.11.010
   ZHANG J, 1990, IEEE T PATTERN ANAL, V12, P1009, DOI 10.1109/34.58873
NR 99
TC 9
Z9 9
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1199
EP 1212
DI 10.1016/j.jvcir.2012.08.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300004
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Qi, F
   Shi, GM
   Lu, YH
AF Wu, Jinjian
   Qi, Fei
   Shi, Guangming
   Lu, Yongheng
TI Non-local spatial redundancy reduction for bottom-up saliency estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Redundancy reduction; Image structure; Self-similarity; Bottom-up visual
   saliency; Visual attention; Non-local; Entropy; Human visual system
ID SACCADIC EYE-MOVEMENTS; VISUAL-ATTENTION; OBJECT; MODEL
AB In this paper we present a redundancy reduction based approach for computational bottom-up visual saliency estimation. In contrast to conventional methods, our approach determines the saliency by filtering out redundant contents instead of measuring their significance. To analyze the redundancy of self-repeating spatial structures, we propose a non-local self-similarity based procedure. The result redundancy coefficient is used to compensate the Shannon entropy, which is based on statistics of pixel intensities, to generate the bottom-up saliency map of the visual input. Experimental results on three publicly available databases demonstrate that the proposed model is highly consistent with the subjective visual attention. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Wu, Jinjian; Qi, Fei; Shi, Guangming; Lu, Yongheng] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Shi, GM (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM gmshi@xidian.edu.cn
RI Qi, Fei/G-3978-2013; Wu, Jinjian/GQH-0222-2022
OI Qi, Fei/0000-0002-2161-1551; 
FU National Natural Science Foundation of China [60805012, 61033004,
   61070138, 61100155]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant Nos. 60805012, 61033004, 61070138, and 61100155.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexander SK, 2008, LECT NOTES COMPUT SC, V5112, P192, DOI 10.1007/978-3-540-69812-8_19
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53
   BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236
   Boiman O, 2005, IEEE I CONF COMP VIS, P462
   Borji A, 2010, IMAGE VISION COMPUT, V28, P1130, DOI 10.1016/j.imavis.2009.10.006
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   FINDLAY JM, 1980, PERCEPTION, V9, P7, DOI 10.1068/p090007
   Gao D., 2004, ADV NEURAL INFO PROC
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Guiasu S., 1971, Reports on Mathematical Physics, V2, P165, DOI 10.1016/0034-4877(71)90002-4
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   HUTCHINSON JE, 1981, INDIANA U MATH J, V30, P713, DOI 10.1512/iumj.1981.30.30055
   Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Itti L., 2000, THESIS CALTECH PASAD
   Itti Laurent, 2005, P576, DOI 10.1016/B978-012375731-9/50098-7
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kastner S, 2000, ANNU REV NEUROSCI, V23, P315, DOI 10.1146/annurev.neuro.23.1.315
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krieger G, 2000, SPATIAL VISION, V13, P201, DOI 10.1163/156856800741216
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Lee JS, 2011, J VIS COMMUN IMAGE R, V22, P704, DOI 10.1016/j.jvcir.2010.11.002
   Lee S, 2010, PATTERN RECOGN, V43, P1116, DOI 10.1016/j.patcog.2009.07.014
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Liu Tie, 2007, P IEEE C COMP VIS PA
   Maver J, 2010, IEEE T PATTERN ANAL, V32, P1211, DOI 10.1109/TPAMI.2009.105
   Niebur E., 1997, COMPUTATIONAL ARCHIT
   Peters R. J, 2005, J VISION, V5, P692
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Shao L, 2006, J VIS COMMUN IMAGE R, V17, P1256, DOI 10.1016/j.jvcir.2006.08.002
   Sun YR, 2003, ARTIF INTELL, V146, P77, DOI 10.1016/S0004-3702(02)00399-5
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   van de Weijer J, 2005, IEEE T PATTERN ANAL, V27, P625, DOI 10.1109/TPAMI.2005.75
   Yarbus A. L., 1967, Eye Movements and Vision
   You J., 2009, Proceedings of the 17th ACM International Conference on Multimedia (ACM MM), P561
   You JY, 2011, IEEE T MULTIMEDIA, V13, P1269, DOI 10.1109/TMM.2011.2172591
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
NR 49
TC 22
Z9 22
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1158
EP 1166
DI 10.1016/j.jvcir.2012.07.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900017
DA 2024-07-18
ER

PT J
AU Zheng, YP
   Yu, ZW
   You, JN
   Sarem, M
AF Zheng, Yunping
   Yu, Zhiwen
   You, Jane
   Sarem, Mudar
TI A novel gray image representation using overlapping rectangular NAM and
   extended shading approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gray image representation; Overlapping rectangular NAM (ORNAM); Extended
   Gouraud shading; S-Tree Coding (STC); Spatial- and DCT-based (SDCT);
   Subpattern; Homogenous block; Coordinate data compression procedure
ID COMPRESSION; TREE
AB In this paper, inspired by the idea of overlapping rectangular region coding of binary images, we extend the SDS design, which is based on overlapping representation from binary images to gray images based on the non-symmetry and anti-packing model (NAM). A novel gray image representation is proposed by using the overlapping rectangular NAM (RNAM) and the extended Gouraud shading approach, which is called ORNAM representation. Also, we present an ORNAM representation algorithm of gray images. The encoding and the decoding of the proposed algorithm can be performed in O(n log n) time and O(n) time, respectively, where n denotes the number of pixels in a gray image. The wrong decoding problem of the hybrid matrix R for the overlapping RNAM representation of gray images is solved by using the horizontal, vertical, and isolated matrices, i.e., H, V and I, respectively, which are used to identify the vertex types. Also, we put forward four criteria of anti-packing homogeneous blocks. In addition, by redefining a codeword set for the three vertices symbols, we also propose a new coordinate data compression procedure for coding the coordinates of all non-zone elements in the three matrices H, V and I. By taking some idiomatic standard gray images in the field of image processing as typical test objects, and by comparing our proposed ORNAM representation with the conventional S-Tree Coding (STC) representation, the experimental results in this paper show that the former has higher compression ratio and less number of homogeneous blocks than the latter whereas maintaining a satisfactory image quality, and therefore it is a better method to represent gray images. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Zheng, Yunping; Yu, Zhiwen] S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [You, Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
   [Sarem, Mudar] Huazhong Univ Sci & Technol, Sch Software Engn, Wuhan 430074, Hubei, Peoples R China.
C3 South China University of Technology; Hong Kong Polytechnic University;
   Huazhong University of Science & Technology
RP Zheng, YP (corresponding author), S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM zhengyp@scut.edu.cn; zhwyu@scut.edu.cn; csyjia@comp.polyu.edu.hk;
   mudar@hust.edu.cn
OI You, Jane/0000-0002-8181-4836
FU National Natural Science Foundation of China [61003174, 60973085];
   Foundation for Distinguished Young Talents in Higher Education of
   Guangdong of China [LYM11015]; Natural Science Foundation of Guangdong
   Province of China [S2011040005815, S2011010000264, 10451064101004233];
   program for New Century Excellent Talents in University [NCET-11-0165];
   Fundamental Research Funds for the Central Universities of China
   [2011ZM0074, 2012ZZ0062]; Research Fund for the Doctoral Program of
   Higher Education of China [20120172120036, 20100172120031]; Hong Kong
   Government under its GRF scheme [5341/08E, 5366/09E]; Hong Kong
   Polytechnic University Postdoctoral Fellowship [G-YX5D]
FX We thank the anonymous reviewers and editors for their valuable comments
   on improving this paper. The work was partially supported by Grants from
   the National Natural Science Foundation of China (Nos. 61003174 and
   60973085), a Grant from the Foundation for Distinguished Young Talents
   in Higher Education of Guangdong of China (No. LYM11015), a Grant from
   the Natural Science Foundation of Guangdong Province of China (Nos.
   S2011040005815, S2011010000264, No. 10451064101004233), a Grant from
   program for New Century Excellent Talents in University (No.
   NCET-11-0165), a Grant from the Fundamental Research Funds for the
   Central Universities of China (No. 2011ZM0074 and 2012ZZ0062), a grant
   from the Research Fund for the Doctoral Program of Higher Education of
   China. (Nos. 20120172120036, No. 20100172120031), the grants from Hong
   Kong Government under its GRF scheme (5341/08E and 5366/09E) and the
   Hong Kong Polytechnic University Postdoctoral Fellowship (G-YX5D).
CR CHEN CB, 2009, CHINESE J ELECTRON, V18, P89
   Chen SK, 2006, IEEE T KNOWL DATA EN, V18, P784, DOI 10.1109/TKDE.2006.86
   Chung KL, 2000, IEEE T COMMUN, V48, P748, DOI 10.1109/26.843184
   Chung KL, 2005, PATTERN RECOGN, V38, P2578, DOI 10.1016/j.patcog.2005.04.004
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Distasi R, 1997, IEEE T COMMUN, V45, P1095, DOI 10.1109/26.623074
   Foley J.D., 1990, Computer graphics: Principles and practice
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Gong ML, 2004, PATTERN RECOGN, V37, P1723, DOI 10.1016/j.patcog.2004.02.004
   Gurumoorthy KS, 2010, IEEE T IMAGE PROCESS, V19, P322, DOI 10.1109/TIP.2009.2034991
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Jeng JH, 2009, IEEE T IMAGE PROCESS, V18, P995, DOI 10.1109/TIP.2009.2013080
   JONGE WD, 1994, CVGIP-IMAG UNDERSTAN, V59, P265
   Chung KL, 2006, J VIS COMMUN IMAGE R, V17, P1209, DOI 10.1016/j.jvcir.2006.01.002
   Laferté JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777
   MOHAMED SA, 1995, IEEE T COMMUN, V43, P1888, DOI 10.1109/26.387415
   OUKSEL MA, 1992, CVGIP-GRAPH MODEL IM, V54, P75, DOI 10.1016/1049-9652(92)90035-V
   Qiao Y, 2009, IEEE T IMAGE PROCESS, V18, P2153, DOI 10.1109/TIP.2009.2026623
   Quddus A, 1999, PATTERN RECOGN LETT, V20, P81, DOI 10.1016/S0167-8655(98)00118-4
   Samet H., 1990, The Design and Analysis of Spatial Data Structures
   Sarkar D, 1996, PATTERN RECOGN LETT, V17, P839, DOI 10.1016/0167-8655(96)00045-1
   TAMMINEN M, 1984, COMPUT VISION GRAPH, V28, P44, DOI 10.1016/0734-189X(84)90138-5
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wright, 1990, IMAGE COMPRESSION DC
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zahir Saif., 2005, Canadian Conference on Electrical and Computer Engineering, P281
   ZENG B, 1993, IEEE T COMMUN, V41, P1436, DOI 10.1109/26.237877
   Zheng YP, 2011, FRONT COMPUT SCI CHI, V5, P57, DOI 10.1007/s11704-010-0337-3
NR 30
TC 12
Z9 14
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 972
EP 983
DI 10.1016/j.jvcir.2012.06.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900002
DA 2024-07-18
ER

PT J
AU Kang, LW
   Lu, CS
   Lin, CY
AF Kang, Li-Wei
   Lu, Chun-Shien
   Lin, Chih-Yang
TI Low-complexity video coding via power-rate-distortion optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hash; Low-complexity video coding; Motion estimation; Rate-distortion;
   Power-rate-distortion optimization; Multiview video coding; Wireless
   multimedia sensor networks; Low-power and power-aware video coding
ID IMAGE COMPRESSION; COMMUNICATION; DESIGN
AB Wireless multimedia sensor networks (WMSNs) have been potentially applicable for several emerging applications. The resources, i.e., power and bandwidth available to visual sensors in a WMSN are, however, very limited. Hence, it is important but challenging to achieve efficient resource allocation and optimal video data compression while maximizing the overall network lifetime. In this paper, a power-rate-distortion (PRD) optimized resource-scalable low-complexity multiview video encoding scheme is proposed. In our video encoder, both the temporal and interview information can be exploited based on the comparisons of extracted media hashes without performing motion and disparity estimations, which are known to be time-consuming. We present a PRD model to characterize the relationship between the available resources and the RD performance of our encoder. More specifically, an RD function in terms of the percentages for different coding modes of blocks and the target bit rate under the available resource constraints is derived for optimal coding mode decision. The major goal here is to design a PRD model to optimize a "motion estimation-free" low-complexity video encoder for applications with resource-limited devices, instead of designing a general-purpose video codec to compete compression performance against current compression standards (e.g., H.264/AVC). Analytic results verify the accuracy of our PRD model, which can provide a theoretical guideline for performance optimization under limited resource constraints. Simulation results on joint RD performance and power consumption (measured in terms of encoding time) demonstrate the applicability of our video coding scheme for WMSNs. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Lin, Chih-Yang] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Kang, Li-Wei; Lu, Chun-Shien] Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan.
C3 Asia University Taiwan; Academia Sinica - Taiwan
RP Lin, CY (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, 500 Lioufeng Rd, Taichung 41354, Taiwan.
EM andrewlin@asia.edu.tw
RI Lin, Chih-Yang/HOF-2583-2023
OI Lin, Chih-Yang/0000-0002-0401-8473
FU National Science Council, Taiwan [NSC 100-2218-E-001-007-MY3, NSC
   100-2811-E-001-005, NSC 100-2221-E-468-021]
FX This work was supported by National Science Council, Taiwan, under
   Grants NSC 100-2218-E-001-007-MY3, NSC 100-2811-E-001-005, and NSC
   100-2221-E-468-021.
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   [Anonymous], 2009, THESIS BRUNEL U UK
   ARTIGAS X, 2007, P INT C SIGN PROC MU
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   Burd TD, 1996, J VLSI SIG PROC SYST, V13, P203, DOI 10.1007/BF01130406
   Chow KY, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/95076
   Dufaux F, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/508167
   Feng WC, 2005, ACM T MULTIM COMPUT, V1
   Guo X, 2008, IEEE T CIRC SYST VID, V18, P713, DOI 10.1109/TCSVT.2008.920970
   Guo X, 2006, IEEE T CIRC SYST VID, V16, P1527, DOI 10.1109/TCSVT.2006.885724
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   He ZH, 2008, IEEE T CIRC SYST VID, V18, P596, DOI 10.1109/TCSVT.2008.918802
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P590, DOI 10.1109/TCSVT.2006.873154
   Lian CJ, 2007, IEEE CIRC SYST MAG, V7, P26, DOI 10.1109/MCAS.2007.4299440
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Merkle P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1717, DOI 10.1109/ICME.2006.262881
   *MITS EL RES LAB, MERL MULT VID SEQ
   Morbee M., 2007, P IEEE 3DTV C MAY, P1
   Ouaret M, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/591915
   Phan KT, 2009, IEEE T VEH TECHNOL, V58, P3640, DOI 10.1109/TVT.2009.2013235
   Shafique Muhammad, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P350, DOI 10.1109/PCS.2010.5702506
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Sun K., 2006, P ACM C COMP COMM SE
   Tseng PC, 2005, P IEEE, V93, P184, DOI 10.1109/JPROC.2004.839622
   Turaga DS, 2005, IEEE T CIRC SYST VID, V15, P982, DOI 10.1109/TCSVT.2005.852399
   van der Schaar M, 2005, IEEE T MULTIMEDIA, V7, P471, DOI 10.1109/TMM.2005.846790
   Wang W, 2008, IEEE T MULTIMEDIA, V10, P1169, DOI 10.1109/TMM.2008.2001354
   Wiegand T, 2007, IEEE SIGNAL PROC MAG, V24, P148, DOI 10.1109/MSP.2007.323282
   Wu HM, 2005, COMPUT COMMUN, V28, P1658, DOI 10.1016/j.comcom.2005.02.018
   Wu M, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/70481
   Xu XZ, 2008, IEEE T CIRC SYST VID, V18, P285, DOI 10.1109/TCSVT.2008.918122
   Yeo C, 2010, IEEE T IMAGE PROCESS, V19, P995, DOI 10.1109/TIP.2009.2036715
   Yuan WH, 2006, IEEE T MOBILE COMPUT, V5, P799, DOI 10.1109/TMC.2006.98
NR 36
TC 5
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 569
EP 585
DI 10.1016/j.jvcir.2012.02.001
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800014
DA 2024-07-18
ER

PT J
AU Simone, G
   Pedersen, M
   Hardeberg, JY
AF Simone, Gabriele
   Pedersen, Marius
   Hardeberg, Jon Yngve
TI Measuring perceptual contrast in digital images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Perceived contrast; Local measure; Multilevel analysis; Difference of
   Gaussians; Regions-of-Interest; Saliency maps; Psychophysical
   experiment; Observers correlation
ID INFORMATION
AB In this paper we present a novel method to measure perceptual contrast in digital images. We start from a previous measure of contrast developed by Rizzi et al. [26], which presents a multilevel analysis. In the first part of the work the study is aimed mainly at investigating the contribution of the chromatic channels and whether a more complex neighborhood calculation can improve this previous measure of contrast. Following this, we analyze in detail the contribution of each level developing a weighted multilevel framework. Finally, we perform an investigation of Regions-of-Interest in combination with our measure of contrast. In order to evaluate the performance of our approach, we have carried out a psychophysical experiment in a controlled environment and performed extensive statistical tests. Results show an improvement in correlation between measured contrast and observers perceived contrast when the variance of the three color channels separately is used as weighting parameters for local contrast maps. Using Regions-of-Interest as weighting maps does not improve the ability of contrast measures to predict perceived contrast in digital images. This suggests that Regions-of-Interest cannot be used to improve contrast measures, as contrast is an intrinsic factor and it is judged by the global impression of the image. This indicates that further work on contrast measures should account for the global impression of the image while presenting the local information. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Simone, Gabriele; Pedersen, Marius; Hardeberg, Jon Yngve] Gjovik Univ Coll, Norwegian Color Res Lab, Fac Comp Sci & Media Technol, N-2802 Gjovik, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Simone, G (corresponding author), Gjovik Univ Coll, Norwegian Color Res Lab, Fac Comp Sci & Media Technol, POB 191, N-2802 Gjovik, Norway.
EM gabriele.simone@hig.no
RI Pedersen, Marius/AFT-7128-2022
OI Simone, Gabriele/0000-0002-7914-4693
CR ADELSON EH, 1984, RCA ENG, V29
   Ahumada A. J., 1998, SID INT
   [Anonymous], KENDALLS ADV THEORY
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   [Anonymous], THESIS GJOVIK U COLL
   [Anonymous], 1927, STUDIES OPTICS
   BABCOCK JS, 2000, THESIS ROCHESTER I T
   Bai J, 2006, IEICE T FUND ELECTR, VE89A, P2955, DOI 10.1093/ietfec/e89-a.11.2955
   Biiring H., 2004, 2 EUR C COL GRAPH IM, P459
   Boccignone G, 2001, IEEE T PATTERN ANAL, V23, P207, DOI 10.1109/34.908970
   BURKHARDT DA, 1984, J OPT SOC AM A, V1, P309, DOI 10.1364/JOSAA.1.000309
   Calabria AJ, 2003, J IMAGING SCI TECHN, V47, P494
   *CIE, 2004, TECHN REP COL
   CIE, 2004, 1562004 CIE
   de Ridder H., 1992, HUMAN VISION VIAUAL, V1666, P16
   Ferraro M, 2004, REAL-TIME IMAGING, V10, P229, DOI 10.1016/j.rti.2004.05.004
   Gregory GK, 1983, US Patent No., Patent No. [4, 1983,371, 516, 4]
   Henderson JM, 2003, PERCEPT PSYCHOPHYS, V65, P725, DOI 10.3758/BF03194809
   HESS RF, 1983, PROC R SOC SER B-BIO, V217, P309, DOI 10.1098/rspb.1983.0012
   HOLM J, 2006, 14 COL IM C IS T SID, P62
   KINGSMITH PE, 1975, J PHYSIOL-LONDON, V249, P519, DOI 10.1113/jphysiol.1975.sp011028
   Pedersen M., CGIV 2008 4 EUR C CO, P120
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Ponomarenko N., 2008, COLOR IMAGE DATABASE, P403
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Rizzi A., 2008, CGIV 2008 4 EUROPEAN, P249
   Rizzi A., 2004, CGIV 2004 2 EUR C CO
   Simone G., 2009, HUMAN VISION ELEC 14, V7240, p72400Q
   Simone G, 2009, LECT NOTES COMPUT SC, V5575, P597, DOI 10.1007/978-3-642-02230-2_61
   Tadmor Y, 2000, VISION RES, V40, P3145, DOI 10.1016/S0042-6989(00)00166-8
   Tremeau A, 2000, CIS P, P11
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   WHITTLE P, 1986, VISION RES, V26, P1677, DOI 10.1016/0042-6989(86)90055-6
NR 33
TC 53
Z9 56
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 491
EP 506
DI 10.1016/j.jvcir.2012.01.008
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ho, TC
   Zeng, B
AF Ho, Tsz-Chun
   Zeng, Bing
TI Image super-resolution by curve fitting in the threshold decomposition
   domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Up-scaling; Interpolation; Boundary extraction; Edge
   detection; Curve fitting; Threshold decomposition; Binary images
AB A new curve-fitting scheme is proposed in this paper to produce super-resolution images from a single low-resolution source image. The most unique feature of this method is that the threshold decomposition is performed on the given source image to obtain multiple binary images so that the curve-fitting applied on each resulted binary image can be made very efficient and accurate, thus allowing us to focus on tiny objects and thin structures so as to achieve rather nice visual results even when a large up-scaling factor is used. Two novel techniques are further proposed to improve the visual quality: (1) a spreading technique (applied on some significant pixels detected in each threshold decomposed binary image) is used to remove ladder-like false edges that often appear visually in super-resolution images, and (2) an edge correction (guided by the edge information extracted from the original source image) is used to sharpen all inherent edges. Our results are compared with those achieved by using the state-of-arts techniques, showing the ability of our algorithm to achieve a better visual quality in smooth areas as well as for sharp edges and small objects. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Ho, Tsz-Chun; Zeng, Bing] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Zeng, B (corresponding author), Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
EM eezeng@ust.hk
RI cai, bo/G-1491-2010
FU Government of Hong Kong SAR
FX This work has been partly supported by a RGC research grant from the
   Government of Hong Kong SAR. The authors would like to thank Dr. Jian
   Sun from Microsoft Research Asia for providing the GPP results included
   in Figs. 18 and 19.
CR Atkins CB, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P864, DOI 10.1109/ICIP.2001.958257
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Battiato S, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P572, DOI 10.1109/ICIAP.2003.1234111
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chetverikov D, 2003, LECT NOTES COMPUT SC, V2756, P746
   Dai S., 2007, Computer Vision and Pattern Recognition, P1
   Dai SY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1039
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Khan M., 2007, APPROXIMATION DATA U
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   LIU C, 2001, P IEEE C COMP VIS PA, P433
   LUKIN A, 2006, IMAGE INTERPOLATION
   Morse BS, 2001, PROC CVPR IEEE, P333
   MORSE BS, 1998, P IEEE INT C IM PROC
   Muresan DD, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P373, DOI 10.1109/ICIP.2002.1038983
   NAYAR SK, 2007, ACM SIGGRAPH 2007 CO
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   SHIH FYC, 1989, IEEE T PATTERN ANAL, V11, P31, DOI 10.1109/34.23111
   Staelin C., 2003, HPL200326R1
   Sun J, 2003, PROC CVPR IEEE, P729
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   TAPPEN MF, 2003, P 2003 INT WORKSH ST
   Yin LJ, 2005, COMPUT GRAPH-UK, V29, P946, DOI 10.1016/j.cag.2005.09.011
NR 26
TC 5
Z9 6
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 208
EP 221
DI 10.1016/j.jvcir.2011.10.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100020
DA 2024-07-18
ER

PT J
AU Krishnamoorthi, R
   Devi, SS
AF Krishnamoorthi, R.
   Devi, S. Sathiya
TI A multiresolution approach for rotation invariant texture image
   retrieval with orthogonal polynomials model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Texture image retrieval; Orthogonal polynomials; Rotation invariant;
   Gabor wavelet; Contourlet Transform; Multiresolution; Feature
   extraction; Canberra distance
ID CLASSIFICATION; TRANSFORM; FEATURES
AB In this paper, a simple and an efficient Content Based Image Retrieval which is based on orthogonal polynomials model is presented. This model is built with a set of carefully chosen orthogonal polynomials and is used to extract the low level texture features present in the image under analysis. The orthogonal polynomials model coefficients are reordered into multiresolution subband like structure. Simple statistical and perceptual properties are derived from the subband coefficients to represent the texture features and these features form a feature vector. The efficiency of the proposed feature vector extraction for texture image retrieval is experimented on the standard Brodatz and MIT's VisTex texture database images with the Canberra distance measure. The proposed method is compared with other existing retrieval schemes such as Discrete Cosine Transformation (DCT) based multiresolution subbands, Gabor wavelet and Contourlet Transform based retrieval schemes and is found to outperform the existing schemes with less computational cost. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Krishnamoorthi, R.; Devi, S. Sathiya] Anna Univ, Dept Comp Sci & Engn, Vis Lab, Thiruchirappalli, Tamil Nadu, India.
C3 Anna University
RP Krishnamoorthi, R (corresponding author), Anna Univ, Dept Comp Sci & Engn, Vis Lab, Thiruchirappalli, Tamil Nadu, India.
EM rkrish26@hotmail.com; sathyadevi_s@yahoo.com
RI cai, bo/G-1491-2010
OI Ramasamy, Krishnamoorthy/0000-0003-1823-5855; Shanmugam, Sathiya
   Devi/0000-0001-9789-1863
FU All India Council for Technical Education (AICTE), New Delhi, India
   [8023/BOR/RID/RPS-127/2008-09]
FX This work was sponsored by All India Council for Technical Education
   (AICTE), New Delhi, India under the scheme "AICTE-RPS (Research
   Promotion Scheme)" with the grant no: F. No.:
   8023/BOR/RID/RPS-127/2008-09.
CR Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Battiato S, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P524, DOI 10.1109/ICIAP.2003.1234103
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   Cui PL, 2006, PATTERN RECOGN LETT, V27, P408, DOI 10.1016/j.patrec.2005.09.001
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   FOUNTAIN S, 1998, P BMVC 98, V1, P266
   Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Jian MW, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P369, DOI 10.1109/SNPD.2007.94
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Krishnamoorthi R, 2007, PATTERN RECOGN LETT, V28, P771, DOI 10.1016/j.patrec.2006.10.009
   Krishnamoorthi R, 2009, IMAGE VISION COMPUT, V27, P999, DOI 10.1016/j.imavis.2008.08.006
   Krishnamoorthi R, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P490, DOI 10.1109/ICICS.1997.647146
   LO HS, 2004, IEEE INT C IM PROC I, V1, P227
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   Milanese R, 1999, J VIS COMMUN IMAGE R, V10, P186, DOI 10.1006/jvci.1999.0411
   Muneeswaran K, 2005, PATTERN RECOGN, V38, P1495, DOI 10.1016/j.patcog.2005.03.021
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Pun CM, 2003, COMPUT VIS IMAGE UND, V89, P24, DOI 10.1016/S1077-3142(03)00012-2
   RAO CS, 2007, ICGST GVIP J, V7, P9
   Smith JohnR., 1997, Querying by color regions using VisualSEEk content-based visual query system, P23
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tzagkarakis G, 2006, IEEE T IMAGE PROCESS, V15, P2702, DOI 10.1109/TIP.2006.877356
   Zhang DS, 2000, P 1 IEEE PAC RIM C M, P1139
   Zhang JG, 2002, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2002.1048450
NR 29
TC 18
Z9 19
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 18
EP 30
DI 10.1016/j.jvcir.2011.07.011
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100003
DA 2024-07-18
ER

PT J
AU Shi, BL
   Huang, LH
   Pang, ZF
AF Shi, Baoli
   Huang, Lihong
   Pang, Zhi-Feng
TI Fast algorithm for multiplicative noise removal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiplicative noise; Anisotropic total variation; Maximum a posteriori;
   Convex function; Alternating minimization algorithm; Proximal operator;
   Gamma distribution; Newton method
ID ANISOTROPIC DIFFUSION; IMAGES
AB In this work, we consider a variational restoration model for multiplicative noise removal problem. By using a maximum a posteriori estimator, we propose a strictly convex objective functional whose minimizer corresponds to the denoised image we want to recover. We incorporate the anisotropic total variation regularization in the objective functional in order to preserve the edges well. A fast alternating minimization algorithm is established to find the minimizer of the objective functional efficiently. We also give the convergence of this minimization algorithm. A broad range of numerical results are given to prove the effectiveness of our proposed model. Crown Copyright (C) 2011 Published by Elsevier Inc. All rights reserved.
C1 [Shi, Baoli; Huang, Lihong] Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
   [Pang, Zhi-Feng] Hunan Univ, Coll Math & Informat Sci, Kaifeng 475004, Hunan, Peoples R China.
   [Huang, Lihong] Hunan Womens Univ, Changsha 410000, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Huang, LH (corresponding author), Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
EM shibaoli1983@163.com; lhhuang@hnu.edu.cn; zhifengpang@163.com
RI Huang, Li/IUQ-0909-2023; , zhifengpang/AAE-6852-2020
OI Pang, Zhi-Feng/0000-0001-6824-3509
FU 973 Program [2009CB326202]; National Natural Science Foundation of China
   [11071060, 60835004]; Higher Educational Institutions of Hunan Province
   [XJT2008-244]
FX Research supported by 973 Program (2009CB326202), National Natural
   Science Foundation of China (11071060, 60835004), and Aid program for
   Science and Technology Innovative Research Team in Higher Educational
   Institutions of Hunan Province (XJT2008-244).
CR Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Jia RQ, 2010, ADV COMPUT MATH, V33, P231, DOI 10.1007/s10444-009-9128-5
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   KRISSION K, 2004, ANISTROPIC DIFFUSION
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Le T., 2003, 0352 UCLA
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   MOREAU JJ, 1962, CR HEBD ACAD SCI, V255, P2897
   Ogier A, 2004, LECT NOTES COMPUT SC, V3216, P70
   OPTIAL Z, 1967, B AM MATH SOC, V73, P591
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
NR 17
TC 13
Z9 13
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 126
EP 133
DI 10.1016/j.jvcir.2011.08.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100012
DA 2024-07-18
ER

PT J
AU Chen, KT
   Lin, KH
   Kuo, YH
   Wu, YL
   Hsu, WH
AF Chen, Kuan-Ting
   Lin, Kuan-Hung
   Kuo, Yin-Hsi
   Wu, Yi-Lun
   Hsu, Winston H.
TI Boosting image object retrieval and indexing by automatically discovered
   pseudo-objects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Object retrieval; Pseudo-object; Visual word; Local
   feature; Bundle feature; Indexing; Large-scale
AB State-of-the-art object retrieval systems are mostly based on the bag-of-visual-words representation which encodes local appearance information of an image in a feature vector. An image object search is performed by comparing query object's feature vector with those for database images. However, a database image vector generally carries mixed information of the entire image which may contain multiple objects and background. Search quality is degraded by such noisy (or diluted) feature vectors. To tackle this problem, we propose a novel representation, pseudo-objects - a subset of proximate feature points with its own feature vector to represent a local area, to approximate candidate objects in database images. In this paper, we investigate effective methods (e.g., grid, G-means, and GMM-BIC) to estimate pseudo-objects. Additionally, we also confirm that the pseudo-objects can significantly benefit inverted-file indexing both in accuracy and efficiency. Experimenting over two consumer photo benchmarks, we demonstrate that the proposed method significantly outperforms other state-of-the-art object retrieval and indexing algorithms. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Chen, Kuan-Ting; Hsu, Winston H.] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10764, Taiwan.
   [Lin, Kuan-Hung; Kuo, Yin-Hsi; Wu, Yi-Lun; Hsu, Winston H.] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Hsu, WH (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10764, Taiwan.
EM winston@csie.ntu.edu.tw
RI lin, ke/GZM-8300-2022
CR [Anonymous], 2007, ICCV
   [Anonymous], 2008, C COMP VIS PATT REC
   [Anonymous], 2007, CVPR
   [Anonymous], 2006, SIGGRAPH
   [Anonymous], CVPR
   [Anonymous], 2004, SOCG
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], 2009, CVPR
   [Anonymous], 2003, ICCV
   Barroso LA, 2003, IEEE MICRO, V23, P22, DOI 10.1109/MM.2003.1196112
   CHUM O, 2004, ACCV
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Hamerly G., 2003, Neural Information Processing Systems (NIPS)
   Ke Y., 2004, ACM MULT
   KUO YH, 2009, ACM MULT
   LI Y, 2005, ACM MULT
   LIAO WS, 2008, ACM SIGIR
   LIN KH, 2009, INT C IM PROC ICIP C
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MATAS J, 2002, P BRIT MACH VIS C LO
   MCDONALD K, 2005, CIVR SING
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SMITH JR, 1996, ACM MULT
   Yang Y.-H., 2008, ACM MULT
   YEH T, 2008, ACM MULT
   ZHANG S, 2009, ACM MULT
   Zheng Y, 2008, CVPR, P1
   Zobel J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132956.1132959
NR 33
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 815
EP 825
DI 10.1016/j.jvcir.2010.06.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500006
DA 2024-07-18
ER

PT J
AU Chang, CH
   Hsieh, KY
   Chiang, MC
   Wu, JL
AF Chang, Chia-Hu
   Hsieh, Kuei-Yi
   Chiang, Ming-Che
   Wu, Ja-Ling
TI Virtual spotlighted advertising for tennis videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tennis video analysis; Visual intrusiveness; Sports video advertising;
   Image advertising; Virtual advertising; Foveation model; Virtual product
   placement; Gestalt effect; Ad-blindness effect; Subliminal perception
ID SYSTEM
AB How to effectively and less-intrusively deliver the advertising message by spatially replacing regions with advertisements in a period of exposure time for sports videos has been known as a challenging problem. The size, placement locations, and the representation of advertisement are the critical factors that have significant impact on both the recognition effectiveness and the perceived intrusiveness. In this paper, we take advertising theory, psychology, and computational aesthetics into account to develop a novel virtual advertising mechanism, called virtual spotlighted advertising (ViSA), for tennis videos. We utilize the extraneous visual acuity of viewers while watching the attractive object, such that they are not much disturbed from the progress of the game, and at the same time, the inserted advertisement can effectively deliver its message across to them. We propose a framework and realize an exemplary system to serve ViSA. The system automatically detects the candidate insertion points in both temporal and spatial domains and estimates the most effective region for visual communication. Then, the harmonically re-colored advertisements with foveation model based non-uniform transparency, are projected onto the court. The evaluation results demonstrate the effectiveness of the proposed ViSA in terms of recall and recognition. Moreover, the induced visual intrusiveness is limited by the proposed innovative representation style. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Chang, Chia-Hu; Wu, Ja-Ling] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
   [Hsieh, Kuei-Yi; Chiang, Ming-Che; Wu, Ja-Ling] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Chang, CH (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, 1,Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.
EM chchang@cmlab.csie.ntu.edu.tw
OI WU, JA-LING/0000-0002-3631-1551; Chang, Chia-Hu/0000-0003-3056-8134
FU National Science Council of R.O.C. [NSC 97-2622-E-002-010-CC2]
FX This work was partially published in the ACM International Conference on
   Multimedia (MM), 2008 [1]. This work was partially supported by the
   National Science Council of R.O.C. under Grants NSC
   97-2622-E-002-010-CC2.
CR Aaker DavidA., 1996, BUILDING STRONG BRAN
   [Anonymous], P ACM INT C MULT
   [Anonymous], P 11 ACM INT C MULT
   [Anonymous], 2008, P 16 ACM INT C MULT, DOI DOI 10.1145/1459359.1459410
   Barry T.E., 1990, INT J ADVERT, V9, P121, DOI [DOI 10.1080/02650487.1990.11107138, 10.1080/02650487.1990.11107138]
   BRADLEY DR, 1977, AM J PSYCHOL, V90, P253, DOI 10.2307/1422047
   Broyles SJ, 2006, J CONSUM AFF, V40, P392, DOI 10.1111/j.1745-6606.2006.00063.x
   Bruce V., 1996, Visual Perception, physiology, psychology and ecology
   Changsheng Xu, 2009, Journal of Multimedia, V4, P69
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Ekin A, 2003, IEEE IMAGE PROC, P21
   Farin D, 2004, PROC SPIE, V5307, P80
   Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   HOYER WD, 1990, J CONSUM RES, V17, P141, DOI 10.1086/208544
   Hua XS, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P1, DOI 10.1109/MMSP.2008.4665039
   Li HR, 2002, J ADVERTISING, V31, P37, DOI 10.1080/00913367.2002.10673665
   LIAO WS, 2008, P ACM SIGIR C RES DE, P767
   Lim J, 2008, MULTIMED TOOLS APPL, V36, P11, DOI 10.1007/s11042-006-0079-2
   Liu T, 2005, PROG SAFETY SCI TECH, V5, P837
   Luo NT, 2008, IEEE INT C NETW SENS, P1500
   Mei T., 2008, P 16 ACM INT C MULT, P439, DOI [https://doi.org/10.1145/1459359.1459418, DOI 10.1145/1459359.1459418]
   Mei Tao., 2007, Proceedings of the 15th International Conference on Multimedia, P1075
   PARKER GR, 1992, I CHANGE DISCRETION
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   SCHAEFER RM, 1987, MINER ELECTROL METAB, V13, P1
   Sheikh HR, 2003, REAL-TIME IMAGING, V9, P27, DOI 10.1016/S1077-2014(02)00116-X
   SMITH KH, 1994, J APPL PSYCHOL, V79, P866, DOI 10.1037/0021-9010.79.6.866
   Tien MC, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1477, DOI 10.1109/ICME.2008.4607725
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   Tokumaru M, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P378, DOI 10.1109/FUZZ.2002.1005020
   TSAI M, 2007, J MANAGE, V24, P3
   WAN K, 2003, P 11 ACM INT C MULT, P468, DOI DOI 10.1145/957013.957116
   Wan KW, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1893, DOI 10.1109/ICME.2006.262925
   Wan XF, 2004, BMC EVOL BIOL, V4, DOI 10.1186/1471-2148-4-19
   Wang J.R., 2004, Proceedings of the Pan-Sydney area workshop on Visual information processing, VIP '05, P87
   Xiong SM, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P33, DOI 10.1109/ICMLC.2008.4620374
   Xu CS, 2004, LECT NOTES COMPUT SC, V3332, P264
   YU X, 2008, COMPUTER VISION IMAG, P837
   Yu XG, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P526
   ZHANG J, 1993, MULTIMEDIA SYSTEMS, V1, P10
NR 42
TC 13
Z9 17
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 595
EP 612
DI 10.1016/j.jvcir.2010.03.006
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 650DO
UT WOS:000281829400001
DA 2024-07-18
ER

PT J
AU Zhang, H
   Zhou, J
   Li, J
AF Zhang, Hui
   Zhou, Jin
   Li, Jun
TI M2FEC: An effective FEC based multi-path transmission scheme for
   interactive multimedia communication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive multimedia application; Delay sensitive; Overlay routing;
   Multi-path algorithm; Path diversity; FEC; Error-resilient coding;
   Rate-distortion; Video quality
AB The oncoming prosperity of interactive multimedia application triggers significant challenges to current best-effort Internet due to such application's stringent delay, loss and bandwidth requirements, and Internet's unpredictable dynamics. Multi-path transmission and error-resilient coding are two promising approaches to alleviate these problems. This paper attempts to introduce error-resilient coding into multi-path transmission to better trade off between multi-path bandwidth resource consumption and reliable media quality. We propose a model for multi-paths interactive multimedia transmission and develop M2FEC-a FEC based transmission scheme which maximizes the overall quality at the client under various constraints based on the proposed model. Numerical simulation and PlanetLab experiments demonstrate the effectiveness and practicability of M2FEC in theory and in empiricism, respectively. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Zhang, Hui] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Zhang, Hui; Zhou, Jin; Li, Jun] Tsinghua Univ, Res Inst Informat Technol, Beijing 100084, Peoples R China.
   [Li, Jun] Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University; Tsinghua University
RP Zhang, H (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
EM zhanghui04@mails.tsinghua.edu.cn; zhoujin@mail.tsinghua.edu.cn;
   junl@mail.tsinghua.edu.cn
FU NEC Laboratories China
FX This work is sponsored by NEC Laboratories China. The authors thank Dr.
   Yong Xia of NEC and all the members of Security Lab RITT, Tsinghua
   University for their valuable discussions and advice.
CR [Anonymous], 2001, P 18 ACM S OP SYST P
   ASHMAWI W, 2001, P ACM SIGCOMM
   BEGEN AC, 2005, P EURASIP SIGN IM CO
   BETTAHAR H, 2001, P IEEE S COMP COMM
   BOVY CJ, 2002, P PASS ACT MEAS WORK, P26
   CLARK D, 1992, P COMM ARCH PROT
   DAI M, 2006, IEEE T MULTIMEDIA
   DAI M, 2003, P ACM NOSSDAV
   FEI T, 2006, P IEEE INFOCOM 06
   GOYAL VK, 2001, IEEE SIGNAL PROCESSI
   GUMMADI KP, 2004, P 6 USENIX S OP SYST
   HE Z, 2002, IEEE T CIRCUITS SYST
   *ITU T, 2000, G114 ITUT
   JAIN M, 2008, COMPUTER NETWORKS
   Kunz T, 2007, IEEE CONF WIREL MOB
   LEE SJ, 2008, P IEEE INFOCOM 08
   LIU Z, 2007, P SIGCOMM WORKSH
   NELAKUDITI S, 2004, COMPUTER NETWROKS
   NGUYEN T, 2003, P IEEE INFOCOM 03
   Rosen E., 2001, RFC3031
   SALAMATIAN K, 2001, P PERF EV REV
   Savage Stefan., 1999, P ACM SIGCOMM
   TANG L, J COMMUNICA IN PRESS
   TAO S, 2005, P IEEE INFOCOM 05
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   WU M, 2006, P IEEE C INF SCI SYS
   YAJNIK M, 1999, P INFOCOM 99
   YAJNIK M, 1996, P IEEE GLOB INT C
   ZHANG H, 2006, P ICCCN 06
   ZHUANG X, 2007, P 4 ANN IEEE CONS CO
NR 30
TC 2
Z9 5
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 120
EP 128
DI 10.1016/j.jvcir.2009.07.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800006
DA 2024-07-18
ER

PT J
AU Pnevmatikakis, A
   Polymenakos, L
AF Pnevmatikakis, Aristodemos
   Polymenakos, Lazaros
TI Subclass linear discriminant analysis for video-based face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video-based face recognition; Subclass linear discriminant analysis;
   Facial image processing
AB We present a novel subclass Linear Discriminant Analysis algorithm for feature extraction that copes with the severe pose, expression and illumination changes present in faces extracted from far-field video streams with subjects unconstrained in their motion and uncooperative to the system. Our novelty lies on the efficient automatic generation of subclasses from the gallery faces, by exploiting their different visual appearance and not constrained by their numbers per class. The proposed feature extraction algorithm is integrated in our complete face recognition system, with modules for preprocessing, classification, and decision fusion. We demonstrate the capability of the new algorithm to automatically generate discriminable subclasses and the resulting improved classification accuracy on a challenging video-based dataset, comprising low quality and resolution faces, as well as large variations in visual appearance. Our results indicate superior recognition rate compared to any systems in the CLEAR 2007 evaluation, running on that dataset. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Pnevmatikakis, Aristodemos] Athens Informat Technol, Auton & Grid Comp, Athens 19002, Greece.
RP Pnevmatikakis, A (corresponding author), Athens Informat Technol, Auton & Grid Comp, 0-8Km Markopoulou Ave, Athens 19002, Greece.
EM apne@ait.edu.gr; lcp@ait.edu.gr
OI Pnevmatikakis, Aristodemos/0000-0002-9623-6354
FU European Union
FX This work has been partly sponsored by the European Union, under the FP7
   Specific Targeted Research Project My-e-Director 2012 (Real-Time
   Context-Aware and Personalized Media Streaming Environments for Large
   Scale Broadcasting Applications).
CR Aggarwal G, 2004, INT C PATT RECOG, P175, DOI 10.1109/ICPR.2004.1333732
   [Anonymous], 1990, STAT PATTERN RECOGNI
   [Anonymous], P 4 IEEE INT C AUT F
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   EKENEL HK, 2007, CLEAR 07 EV CAMP WOR, P256
   Gorodnichy DO, 2003, LECT NOTES COMPUT SC, V2688, P505
   Hastie T, 1996, J ROY STAT SOC B, V58, P155
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Lee KC, 2003, PROC CVPR IEEE, P313
   Li SZ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P455
   Li YM, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P40, DOI 10.1109/RATFG.2001.938908
   LIU X, 2003, IEEE P COMP VIS PATT, V1, P340
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384
   Mostefa D, 2007, LANG RESOUR EVAL, V41, P389, DOI 10.1007/s10579-007-9054-4
   Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15
   Pnevmatikakis A., 2007, Face Recognition, P467
   Raytchev B, 2003, COMPUT VIS IMAGE UND, V91, P22, DOI 10.1016/S1077-3142(03)00074-2
   Stiefelhagen R, 2007, LECT NOTES COMPUT SC, V4122, P1
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   WAIBEL A, 2004, P 5 INT WORKSH IM AN, P175
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Xie CY, 2004, LECT NOTES COMPUT SC, V3072, P102
   Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525, DOI 10.1109/TPAMI.2004.1265868
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172
NR 26
TC 10
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 543
EP 551
DI 10.1016/j.jvcir.2009.08.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400005
DA 2024-07-18
ER

PT J
AU Khan, JI
   Guo, Z
AF Khan, Javed I.
   Guo, Zhong
TI Fast perceptual region tracking with coding-depth sensitive access for
   stream transcoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE perceptual encoding; video transcoding; content aware streaming
AB Object-based bit allocation can result in significant improvement in the perceptual quality of extremely compressed video. However, real-time video object detection in large format high fidelity video is computationally daunting. Most algorithms begin with extensive use of classical bit analysis, and thus remain computationally heavy. Based on some recent results in human visual perception, in this paper, we present an experimental visual region tracking algorithm particularly designed for perceptual stream transcoding. This exploits the cue order observed in human visual perception to achieve very high computation speed as well as tracking efficiency. Rather than begin processing from pixel level or using any pixel level processing at all, it employs high level motion cue and block shape cue analysis to identify signatures of various relative movements between object of interest, scene background and the camera on the motion vector set, and from there it identifies objects. It then uses predictive filters to track the regions. The result is a fast yet highly effective perceptual region tracking algorithm that can operate in stream rate and track regions of perceptually significant object despite camera movements such as zoom, panning and translation. The technique is not specific to any special class of objects. We have implemented this algorithm in a live ISO-13818/MPEG-2 perceptual transcoder. In this paper, we share the performance of this implementation. This fast object-aware video rate transcoder is particularly Suitable for live streaming and can convert a regular stream into a perceptually coded video stream. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Khan, Javed I.; Guo, Zhong] Kent State Univ, Dept Comp Sci, Media Commun & Networking Res Lab, Kent, OH 44242 USA.
C3 University System of Ohio; Kent State University; Kent State University
   Salem; Kent State University Kent
RP Khan, JI (corresponding author), Kent State Univ, Dept Comp Sci, Media Commun & Networking Res Lab, 233 MSB, Kent, OH 44242 USA.
EM javed@kent.edu; zguo@kent.edu
RI Khan, Javed/AAJ-3455-2021; Guo, Zhong/JXM-5797-2024
OI Guo, Zhong/0000-0001-6275-1270
FU DARPA Research [F30602-99-1-0515]
FX This research has been supported by the DARPA Research Grant
   F30602-99-1-0515.
CR Abd El-Azim S, 2002, 2002 IEEE PROCEEDINGS OF THE NINETEENTH NATIONAL RADIO SCIENCE CONFERENCE, VOLS 1 AND 2, P427, DOI 10.1109/NRSC.2002.1022651
   Abrams RA, 2005, PERCEPT PSYCHOPHYS, V67, P219, DOI 10.3758/BF03206486
   ACHANTA R, 2002, P IEEE INT C MULT EX, V2, P61
   Aizawa K., 1989, Signal Processing: Image Communication, V1, P139, DOI 10.1016/0923-5965(89)90006-4
   [Anonymous], 1996, 138182 ISOIEC
   Assunçao PAA, 1998, IEEE T CIRC SYST VID, V8, P953, DOI 10.1109/76.736724
   Brown R., 2012, Introduction to Random Signals and Applied Kalman Filtering With MATLAB Exercises, V4th
   Carmi R., 2006, Proceedings. ETRA 2006. Symposium on Eye Tracking Research and Applications, P11, DOI 10.1145/1117309.1117313
   CASAS JR, 1994, IEEE T CIRC SYST VID, V4, P317, DOI 10.1109/76.305876
   CHONG U, 1996, SPIE, V2825, P901
   DARSAN P, 2000, 20001001 KENT STAT U
   DESILVA LC, 1994, ICA SSP P, V5, P421
   Foxlin E, 1996, P IEEE VIRT REAL ANN, P185, DOI 10.1109/VRAIS.1996.490527
   Franconeri SL, 2005, PSYCHOL SCI, V16, P275, DOI 10.1111/j.0956-7976.2005.01528.x
   GERALD K, 2001, ACM MULTIMEDIA 2001, P41
   GERTJAN K, 1996, SIGNAL PROCESS-IMAGE, V8, P481
   GUO Z, TR20060501 KENT STAT
   Hariharakrishan K, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P65
   Haskell B.G., 1997, DIGITAL VIDEO INTRO
   HOTTER M, 1988, SIGNAL PROCESS, V15, P315, DOI 10.1016/0165-1684(88)90021-7
   Huang CL, 2004, INT C PATT RECOG, P364, DOI 10.1109/ICPR.2004.1333778
   KHAN JI, 2001, TR20010101 KENT STAT
   KHAN JI, 2002, P DARPA ACT NETW C E
   KHAN JI, 1996, P INT C HUM ASP ADV, P183
   KHAN JI, 2001, INT C APPL INF AI 20, P655
   KIM JR, 2003, P JOINT C 4 INT C IN, V2, P729
   MINAMI T, PICT COD S CAMBR MA, P202
   NGO CW, 2001, ACM MULTIMEDIA, P51
   NIKLAS B, 2000, P ACM MULT 2000 WORK, P75
   OLEG K, 2004, P INT C COMP GRAPH I, P441
   OLEG K, 2004, ACM INT C MULT ACM M, P220
   Ozer IB, 2002, IEEE T MULTIMEDIA, V4, P283, DOI 10.1109/TMM.2002.1017740
   Park SM, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P748
   ROB K, 2000, ISOIECJTC1SC29WG11
   SEO KD, 1998, SPIE, V3528
   WANG R, 2000, IEEE INT S CIRC SYST
   Yantis S, 1999, J EXP PSYCHOL HUMAN, V25, P661, DOI 10.1037/0096-1523.25.3.661
   Youn J, 1999, IEEE T MULTIMEDIA, V1, P30, DOI 10.1109/6046.748169
   Youn JN, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P243, DOI 10.1145/319463.319616
NR 39
TC 0
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2008
VL 19
IS 6
BP 355
EP 371
DI 10.1016/j.jvcir.2008.01.005
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 343KS
UT WOS:000258853100002
DA 2024-07-18
ER

PT J
AU Zeng, WJ
AF Zeng, WJ
TI Adaptive spatial-temporal error concealment with embedded side
   information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error concealment; adaptive error concealment; data embedding; data
   hiding; side information
AB Error concealment (EC) is an important technique to recover the lost/damaged video data in transmitting video over error prone networks such as the Internet or wireless networks. Different EC strategies have their strength and weakness for different scenarios. Therefore an adaptive EC approach is desired. However, it is generally difficult for the decoder to figure out which strategy works the best for a specific case. This paper proposes to use data embedding to convey the necessary high level side information in it standard compliant way to help improve the decoder's EC performance. We show that the EC "mode" information (i.e., whether spatial EC or temporal EC should be used) is critical for a lightweight adaptive spatial-temporal EC approach. Experiments show that with such side information embedded in the standard compressed bitstream, significant quality improvement can be achieved in recovering the lost video packets. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
C3 University of Missouri System; University of Missouri Columbia
RP Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
EM zengw@missouri.edu
CR BORMANN C, 1998, RFC2429 IETF
   Chen TPC, 2002, WIREL COMMUN MOB COM, V2, P607, DOI 10.1002/wcm.83
   *ITU T, 2002, H264 ITUT
   JUNG KH, 1994, P SOC PHOTO-OPT INS, V2308, P1466, DOI 10.1117/12.185905
   LAM WM, 1993, P ICASSP, V5, P417
   SUN HF, 1995, IEEE T IMAGE PROCESS, V4, P470, DOI 10.1109/83.370675
   WANG Y, 1991, P SOC PHOTO-OPT INS, V1605, P667, DOI 10.1117/12.50300
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WATSON AB, 1993, DIGITAL DISPLAY, V4, P202
   WEGNER S, 1999, PACK VID WORKSH
   YIN P, 2001, P IEEE INT C AC SPEE
   ZENG W, 1997, THESIS PRINCETON U
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
NR 13
TC 3
Z9 4
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 499
EP 511
DI 10.1016/j.jvcir.2004.11.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600007
DA 2024-07-18
ER

PT J
AU Qiu, GP
AF Qiu, GP
TI Embedded colour image coding for content-based retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE segmentation-based image coding; vector quantization; linage coding;
   colour imaging; content-based indexing; image retrieval; image database
ID COMPRESSION; RECOGNITION
AB We present an image coding method explicitly designed for easy content access, i.e., content-based image retrieval. Based on a number of well-studied conventional image coding methods, namely segmentation-based image coding (SBIC), vector quantization (VQ), and a recently developed coloured pattern appearance model (CPAM), we have developed an image coding method with a compressed stream from which effective image content descriptors can be derived with very little computation. A colour image is first segmented adaptively into homogeneous regions of various sizes. Each region is then decomposed into three channels according to the CPAM and VQ is employed to represent the chromatic and achromatic spatial patterns efficiently. The image content descriptors are the joint probability distributions of the segmented region sizes and their achromatic and chromatic spatial patterns' VQ codebook indices. From image indexing and content-based retrieval perspective, this work can be regarded as a method effectively exploiting/employing image coding technologies to develop novel and effective image descriptors for content-based image retrieval. We have applied the newly developed image content descriptor to content-based image retrieval from a large colour photo image database. Experimental results demonstrate that the new method is comparable to state of the art methods.. such as colour correlogram and the latest MPEG7 colour structure descriptor in content-based image retrieval. (C) 2003 Elsevier Inc. All rights reserved.
C1 Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
C3 University of Nottingham
RP Qiu, GP (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
EM qiu@cs.nott.ac.uk
OI Qiu, Guoping/0000-0002-5877-5648
CR AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R
   CARSON C, P INT C VIS INF SYS
   *CCIR, 1990, 6012 CCIR
   CHANG SF, P ICIP, P314
   Ebrahimi T, 1998, P IEEE, V86, P1109, DOI 10.1109/5.687832
   FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390
   Gersho A., VECTOR QUANTIZATION
   HUANG J, P CVPR, P762
   *IEEE, 1996, IEEE T IM PROC, V5
   *ISO IEC JTC1 SC29, 2001, MPEG7 FCD
   Kaiser PeterK., HUMAN COLOR VISION
   KOHONEN T, SELFORGANIZATION ASS
   KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   PICARD RW, 1994, MIT MEDIA LAB TR, V295
   POIRSON A, J OPT SOC AM A, V10, P2458
   Pratt W. K., DIGITAL IMAGE PROCES
   Qiu G., 2001, VISUAL COMMUNICATION
   QIU G, PATTERN RECOGN, V35, P1675
   QIU G, 2001, IEEE WORKSH MULT SIG
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Seales WB, 1998, IMAGE VISION COMPUT, V16, P337, DOI 10.1016/S0262-8856(97)00072-3
   SWAIN MJ, INT J COMPUT VIS, V7, P11
   VAISEY J, 1992, IEEE T SIGNAL PROCES, V40, P2040, DOI 10.1109/78.150005
NR 25
TC 14
Z9 16
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2004
VL 15
IS 4
BP 507
EP 521
DI 10.1016/j.jvcir.2003.11.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 868OZ
UT WOS:000224924200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cheng, SC
   Hsia, SC
AF Cheng, SC
   Hsia, SC
TI Fast algorithms for color image processing by principal component
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE vector order statistics; covariance matrix; eigenvalue; color image
   processing
ID ORDER-STATISTICS; COMPRESSION; OPERATORS
AB This paper discusses a new approach for ordering color vectors by principal component analysis. A color image is represented by a vector field and the color vectors in an n by n pixel window are ordered according to the projection scores obtained by projecting each color vector within the window on the principal axis. We subtract each color vector in a window from the color vector of the central pixel before constructing the corresponding covariance matrix. For the purpose of computation efficiency, a fast approximation of the principal axis is also proposed. By applying the vector order statistics, various applications of color image processing, such as color image sharpening, color image compression, and color edge detection are also proposed in this paper. Therefore, the proposed color vector ordering method can be,used as a tool for color image processing. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
C3 National Kaohsiung University of Science & Technology
RP Cheng, SC (corresponding author), Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, 1 Univ Rd, Kaohsiung 824, Taiwan.
CR [Anonymous], 1982, Digital Picture Processing
   David H.A., 1980, Order Statistics, Vsecond
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   JAIN AK, 1991, FUNDAMENTALS DIGITAL
   KURITA T, 1993, IEEE T COMMUN, V41, P1270, DOI 10.1109/26.237840
   LEE HC, 1991, IEEE T SIGNAL PROCES, V39, P1181, DOI 10.1109/78.80971
   MACHUCA R, 1983, IEEE T PATTERN ANAL, V5, P318
   PAPADOPOULOS CK, 1990, IEEE T ACOUST SPEECH, V38, P1424, DOI 10.1109/29.57577
   Pei SC, 1999, IEEE T IMAGE PROCESS, V8, P614, DOI 10.1109/83.760310
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   SARKAR S, 1986, COMPUT VISION GRAPH, V36, P1
   Scharcanski J, 1997, IEEE T CIRC SYST VID, V7, P397, DOI 10.1109/76.564116
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   WU YY, 1992, IEEE J SEL AREA COMM, V10, P952, DOI 10.1109/49.139000
   Yang CK, 1997, IEEE T COMMUN, V45, P1513, DOI 10.1109/26.650223
   YANG CK, 1995, SIGNAL PROCESS, V45, P397, DOI 10.1016/0165-1684(95)00066-M
   ZENZO SD, 1986, COMPUT VISION GRAPH, V33, P116
NR 17
TC 22
Z9 23
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2003
VL 14
IS 2
BP 184
EP 203
DI 10.1016/S1047-3203(03)00024-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 680AJ
UT WOS:000182953900006
DA 2024-07-18
ER

PT J
AU Liu, S
   Kuo, CCJ
   Kim, J
AF Liu, S
   Kuo, CCJ
   Kim, J
TI Hybrid global-local motion compensated frame interpolation for low bit
   rate video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE global-local motion compensation; foreground background segmentation;
   frame interpolation; affine/perspective motion model
AB A hybrid global-local motion compensated frame interpolation (HMCI) scheme for low bit rate video coding is proposed in this paper. Different from most other global-local motion compensation algorithms, which were performed at the encoder end, the proposed scheme works solely on the decoded video stream. Thus, it can be applied to any MCP (motion compensated prediction) based standard coders without bit stream syntax modification. Along with the proposed HMCI scheme, a motion-based foreground-background segmentation method is presented. Traditional intensity-based segmentation methods can only segment moving objects from still background. In contrast, the proposed approach can segment foreground objects from both moving and still background by exploiting information carried by block-based motion vectors. Both the six-parameter affine or the eight-parameter perspective models can be applied to the foreground-background segmentation and the moving background reconstruction; while the six-parameter affine model with triangular patch warping is adopted to reconstruct the foreground blocks due to its low complexity. Experiments show that the proposed HMCI scheme achieves higher subjective (visual) quality compared to the conventional block-based frame interpolation without global motion compensation, where artifacts in moving backgrounds are significantly reduced. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
   Kwangju Inst Sci & Technol, Dept Informat & Commun, Kwangju 500712, South Korea.
C3 University of Southern California; University of Southern California;
   Gwangju Institute of Science & Technology (GIST)
RP Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
EM shanl@sipi.usc.edu; cckuo@sipi.usc.edu; jongwon@kjist.ac.kr
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035; , Shan/0000-0002-1442-1207
CR [Anonymous], 1992, NUMERICAL RECIPES C
   Chen YK, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P622, DOI 10.1109/MMSP.1998.739050
   CHU CT, 1997, IEEE P INT S CIRC SY
   GALLANT M, 1998, UBCS H 263PLUS PUBLI
   HEISING G, 1997, IEEE INT C IM PROC, V1, P275
   Jozawa H, 1997, IEEE T CIRC SYST VID, V7, P75, DOI 10.1109/76.554419
   Kuo TY, 1998, P SOC PHOTO-OPT INS, V3460, P277, DOI 10.1117/12.323181
   Liu S, 2000, PROC SPIE, V4115, P203, DOI 10.1117/12.411544
   MOSCHENI F, 1995, IEEE P ICASSP, V4, P2261
   MUSMANN HG, 1985, P IEEE, V73, P523, DOI 10.1109/PROC.1985.13183
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Tsuhan Chen, 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P591, DOI 10.1109/ICIP.1995.537548
   Zhang K, 1996, INT CONF ACOUST SPEE, P1978, DOI 10.1109/ICASSP.1996.544841
NR 14
TC 20
Z9 54
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2003
VL 14
IS 1
BP 61
EP 79
DI 10.1016/S1047-3203(02)00011-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 665TZ
UT WOS:000182138500004
DA 2024-07-18
ER

PT J
AU Pan, H
   Tian, QH
   Li, SW
   Miao, WL
AF Pan, Hao
   Tian, Qiuhong
   Li, Saiwei
   Miao, Weilun
TI Action recognition method based on lightweight network and rough-fine
   keyframe extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Keyframe extract; Action recognition; 3DCNN; Attention mechanism
AB To address the issues of large number of parameters and low recognition accuracy of action recognition networks, we propose an effective action recognition method based on lightweight network and rough-fine keyframe extraction. The method consists of three modules. The first module proposes a keyframe extraction network based on grayscale and feature descriptors, and employs a rough-fine idea to extract video keyframe. It reduces the redundancy of keyframe and enhances their ability to express action semantics. The second module introduces an attention-based feature extraction network, which combines decoupling ideas with attention mechanisms to enhance the accuracy of the action recognition network, while significantly reducing the network parameters. The third module is an improved attention module which optimizes the representation of local information. Finally, addition of the residual module fuses feature information between different convolutional layers. Experiments on two different datasets show that the number of parameters in the proposed method is only 6.4M. On publicly available datasets of HMDB51 and UCF101, the method achieves recognition accuracy of 75.69% and 93.18% without pre-training, respectively. The proposed method is valid and feasible on multiple public datasets.
C1 [Pan, Hao; Tian, Qiuhong; Li, Saiwei; Miao, Weilun] Zhejiang Sci Tech Univ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang Sci-Tech University
RP Tian, QH (corresponding author), Zhejiang Sci Tech Univ, Hangzhou 310018, Zhejiang, Peoples R China.
EM tianqiuhong@zstu.edu.cn
CR Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen B, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031707
   Chen B, 2022, IET IMAGE PROCESS, V16, P3097, DOI 10.1049/ipr2.12541
   Chen Junyu, 2021, Journal of Physics: Conference Series, V2025
   Diba A, 2017, Arxiv, DOI arXiv:1711.08200
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang YK, 2020, IEEE ACCESS, V8, P45753, DOI 10.1109/ACCESS.2020.2978223
   Indhumathi C, 2022, INT J IMAGE GRAPH, V22, DOI 10.1142/S0219467822500516
   Jin W., 2021, High Technol. Lett., V27, P163, DOI [10.3772/j.issn.1006-6748.2021.02.007,02, DOI 10.3772/J.ISSN.1006-6748.2021.02.007,02]
   Khan NS, 2021, WIRELESS PERS COMMUN, V120, P1593, DOI 10.1007/s11277-021-08525-w
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li H, 2023, SIGNAL IMAGE VIDEO P, V17, P57, DOI 10.1007/s11760-022-02203-5
   Luqman H, 2022, IEEE ACCESS, V10, P93785, DOI 10.1109/ACCESS.2022.3204110
   Mnih V, 2014, ADV NEUR IN, V27
   Nandini HM, 2022, J KING SAUD UNIV-COM, V34, P4537, DOI 10.1016/j.jksuci.2020.10.031
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Omi K, 2022, IEICE T INF SYST, VE105D, P2119, DOI 10.1587/transinf.2022EDP7058
   Qiu S, 2022, INFORM FUSION, V80, P241, DOI 10.1016/j.inffus.2021.11.006
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Sahoo SP, 2021, IEEE TETCI, V5, P813, DOI 10.1109/TETCI.2020.3014367
   Sharma V, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2093705
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun ZH, 2023, IEEE T PATTERN ANAL, V45, P3200, DOI 10.1109/TPAMI.2022.3183112
   Tang YC, 2023, ENG STRUCT, V274, DOI 10.1016/j.engstruct.2022.115158
   Tran D, 2017, Arxiv, DOI [arXiv:1708.05038, DOI 10.48550/ARXIV.1708.05038]
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu FY, 2023, COMPUT ELECTRON AGR, V209, DOI 10.1016/j.compag.2023.107827
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang G, 2022, MULTIMED TOOLS APPL, V81, P9875, DOI 10.1007/s11042-022-11937-w
   Yang HM, 2021, SIGNAL IMAGE VIDEO P, V15, P617, DOI 10.1007/s11760-020-01783-4
   Yu LC, 2018, PEER PEER NETW APPL, V11, P1141, DOI 10.1007/s12083-017-0567-3
   Yuan Y, 2022, MULTIMEDIA SYST, V28, P387, DOI 10.1007/s00530-021-00777-7
   Zhang SB, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041476
NR 41
TC 0
Z9 0
U1 2
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103959
DI 10.1016/j.jvcir.2023.103959
EA OCT 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y9KQ5
UT WOS:001108379700001
DA 2024-07-18
ER

PT J
AU Alphonse, AS
   Abinaya, S
   Abirami, S
AF Alphonse, A. Sherly
   Abinaya, S.
   Abirami, S.
TI Alibaba and forty thieves algorithm and novel Prioritized Prewitt
   Pattern (PPP)-based convolutional neural network (CNN) using
   hyperspherically compressed weights for facial emotion recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Optimization; CNN; Weights; Emotion; Hyperparameters
ID EXPRESSION RECOGNITION; IMAGE
AB The visual representations created using the self-distillation paradigm of Bootstrap Your Emotion Latent (BYEL) are empirically found to be less evenly distributed than those created using proposed technique. This proposed work promotes the compression of weights on a hypersphere by minimizing the hyperspherical energy of network weights using a novel method of optimizing manifolds through Riemannian metrics and the Conjugate gradient technique. The proposed work demonstrates how regularising the networks of the BYEL architecture reduces the hyperspherical energy of neurons by directly optimising a measure of uniformity alongside the standard loss. This leads to more uniformly distributed representation and better performance for downstream tasks. The Alibaba and Forty Thieves Algorithm-based Optimization (AFTAO) methodology is used to select the most precise collection of hyperparameters for a novel Prioritized Prewitt Pattern (PPP)-based Convolutional Neural Network (CNN) that results in a higher accuracy for all the six datasets used for facial emotion recognition.
C1 [Alphonse, A. Sherly; Abinaya, S.; Abirami, S.] Vellore Inst Technol, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Alphonse, AS (corresponding author), Vellore Inst Technol, Chennai, India.
EM sherly.a@vit.ac.in
RI S, Abirami/KTI-8099-2024
CR Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Akhand MAH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091036
   Alphonse AS, 2017, J VIS COMMUN IMAGE R, V49, P459, DOI 10.1016/j.jvcir.2017.10.008
   [Anonymous], 2018, arXiv
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Balochian S, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12011-1
   Boumal N, 2014, J MACH LEARN RES, V15, P1455
   Braik M, 2023, NEURAL COMPUT APPL, V35, P6153, DOI 10.1007/s00521-022-08015-5
   Braik M, 2022, NEURAL COMPUT APPL, V34, P409, DOI 10.1007/s00521-021-06392-x
   Chen T, 2020, PR MACH LEARN RES, V119
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Chu WS, 2017, IEEE INT CONF AUTOMA, P25, DOI 10.1109/FG.2017.13
   Cui YD, 2020, IFAC PAPERSONLINE, V53, P650, DOI 10.1016/j.ifacol.2021.04.155
   Dhall A., 2014, ACM ICMI 2014
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   Giannopoulos P., Advances in hybridization of intelligent methods 2018, P1
   Graves A., 2008, P INT WORKSH COGN TE, P56
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Hamester D, 2015, IEEE IJCNN
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jain DK, 2020, PATTERN RECOGN LETT, V139, P157, DOI 10.1016/j.patrec.2017.06.025
   Jaiswal A, 2020, 2020 INT C EM TECHN, P1
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Köppen M, 2001, IEEE T EVOLUT COMPUT, V5, P295, DOI 10.1109/4235.930318
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu YY, 2021, INFORM SCIENCES, V578, P195, DOI 10.1016/j.ins.2021.07.034
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Marazzato R, 2009, Arxiv, DOI arXiv:0910.4637
   Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1
   Mellouk W., 2020, Procedia Computer Science, V175, P689, DOI [DOI 10.1016/J.PROCS.2020.07.101, 10.1016/j.procs.2020.07.101]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pranav E, 2020, INT CONF ADVAN COMPU, P317, DOI [10.1109/icaccs48705.2020.9074302, 10.1109/ICACCS48705.2020.9074302]
   Rai R, 2023, ARCH COMPUT METHOD E, V30, P3791, DOI 10.1007/s11831-023-09923-y
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Sun X, 2020, INFORM SCIENCES, V522, P35, DOI 10.1016/j.ins.2020.02.047
   Valstar MF, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, pJ65
   Wang W., 2019, A fine-grained facial expression database for end-to-end multi-pose facial expression recognition
   Wang Y, 2016, INT J COMPUT INTELL, V15, DOI 10.1142/S1469026816500115
   Wolpert David H., 1997, IEEE Trans. Evol. Comput., V1
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao R, 2021, INT C PATT RECOG, P4412, DOI 10.1109/ICPR48806.2021.9413000
   Zheng H, 2020, INFORM SCIENCES, V533, P60, DOI 10.1016/j.ins.2020.04.041
   Zhong L, 2019, IEEE INT CONF AUTOMA, P270
NR 54
TC 1
Z9 1
U1 2
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103948
DI 10.1016/j.jvcir.2023.103948
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X3ZN7
UT WOS:001097871400001
DA 2024-07-18
ER

PT J
AU Huang, XF
   Zhou, FT
   Niu, WH
   Li, TC
   Lu, Y
   Zhou, Y
   Yin, HB
   Yan, CG
AF Huang, Xiaofeng
   Zhou, Fangtao
   Niu, Weihong
   Li, Tianci
   Lu, Yu
   Zhou, Yang
   Yin, Haibing
   Yan, Chenggang
TI Multi-stage affine motion estimation fast algorithm for versatile video
   coding using decision tree
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Affine motion estimation; Versatile video coding; Inter-mode decision;
   Decision tree; Fast algorithm
ID CU PARTITION
AB Affine motion estimation (AME) which is newly introduced in versatile video coding (VVC) plays a significant role in the bit-rate reduction for rotation and zooming scenes. However, it brings the complexity extremely increased. In this paper, a fast AME algorithm is designed to cope with the high-complexity problem. Three crucial stages are involved in the fast algorithm, which is the optimal inter-mode decision based on the coding unit (CU) partition, the fast algorithm in affine motion search (AMS), and the fast inter-mode decision based on a decision tree. Specifically, the optimal inter-mode will be determined straightforwardly when the parent CU is checked whether it is translational motion estimation (TME). Then, three fast algorithms are made in AMS, which are early termination based on control point motion vector (CPMV), early termination of the iteration process, and fast fine granularity CPMV search. Finally, the optimal inter-mode is predicted using a decision tree based on eight essential features. Experimental results show that the proposed algorithm achieves 10.20% and 10.33% encoding time-saving on average under Low Delay B (LDB) and Random Access (RA) configuration, while the BD-Rate loss is only 0.12% and 0.14%, respectively.
C1 [Huang, Xiaofeng; Zhou, Fangtao; Niu, Weihong; Li, Tianci; Lu, Yu; Zhou, Yang; Yin, Haibing; Yan, Chenggang] Hangzhou Dianzi Univ, Sch Commun Engn, 2 St, Hangzhou 310018, Peoples R China.
   [Huang, Xiaofeng] Peking Univ, Adv Inst Informat Technol, Hangzhou 311215, Peoples R China.
C3 Hangzhou Dianzi University; Peking University
RP Yin, HB (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, 2 St, Hangzhou 310018, Peoples R China.
EM yhb@hdu.edu.cn
OI huang, xiaofeng/0000-0002-8479-6960
FU National Key Ramp;D Program of China [2021ZD0109800]; National Natural
   Science Foundation of China [61901150, 61931008, 61972123]; Zhejiang
   Provincial Natural Science Foundation of China [LY21F020021]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2021ZD0109800, by the National Natural Science Foundation of
   China under Grant 61901150, 61931008, and 61972123, and in part by the
   Zhejiang Provincial Natural Science Foundation of China under grant
   LY21F020021.
CR Abdallah Bouthaina, 2022, 2022 IEEE 21st international Ccnference on Sciences and Techniques of Automatic Control and Computer Engineering (STA), P331, DOI 10.1109/STA56120.2022.10018992
   Badry E, 2017, IEEE GLOB CONF SIG, P151, DOI 10.1109/GlobalSIP.2017.8308622
   Barnett T., 2018, P AM EMEAR CISC KNOW, P1
   Benjamin B., 2020, Doc. JVET-T2001
   Bjontegaard G, 2001, VCEGM33
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Choi K, 2020, IEEE SIGNAL PROC MAG, V37, P160, DOI 10.1109/MSP.2020.2971765
   Ciou Y.-S., 2022, P IEEE INT C CONS EL, P471
   Dong XC, 2022, IEEE T MULTIMEDIA, V24, P400, DOI 10.1109/TMM.2021.3052348
   Duarte A, 2022, IEEE INT SYMP CIRC S, P1958, DOI 10.1109/ISCAS48785.2022.9937973
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Jia-Kai Liu, 2019, 2019 IEEE 8th Global Conference on Consumer Electronics (GCCE), P354, DOI 10.1109/GCCE46687.2019.9015477
   Jianle C, 2020, Doc. JVET-S2002
   Jung S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111243
   Kim TS, 2018, IEEE T CIRC SYST VID, V28, P3398, DOI 10.1109/TCSVT.2017.2759245
   Kulupana G, 2021, PICT COD SYMP, P26, DOI 10.1109/PCS50896.2021.9477461
   Lee Alex, 2013, 2013 International Conference on ICT Convergence (ICTC), P502, DOI 10.1109/ICTC.2013.6675406
   Li L, 2018, IEEE T CIRC SYST VID, V28, P1934, DOI 10.1109/TCSVT.2017.2699919
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Lin S., 2015, Affine Transform Prediction for Next Generation Video Coding
   Liu HW, 2021, IEEE I C VI COM I PR, DOI 10.1109/VCIP53242.2021.9675409
   Liu Z, 2022, IEEE DATA COMPR CONF, P468, DOI 10.1109/DCC52660.2022.00079
   Pakdaman F, 2020, IEEE IMAGE PROC, P3134, DOI 10.1109/ICIP40778.2020.9190983
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P7518, DOI 10.1109/TCSVT.2022.3188991
   Pan ZQ, 2022, IEEE T IMAGE PROCESS, V31, P1613, DOI 10.1109/TIP.2022.3144892
   Pan ZQ, 2021, IEEE SIGNAL PROC LET, V28, P1260, DOI 10.1109/LSP.2021.3086692
   Park SH, 2019, IEEE ACCESS, V7, P158075, DOI 10.1109/ACCESS.2019.2950388
   Ren WZ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071143
   Shen LQ, 2022, IEEE INT WORKSH MULT, DOI 10.1109/MMSP55362.2022.9949302
   Siqueira I, 2020, IEEE LAT AMER SYMP
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Tech G, 2021, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP42928.2021.9506360
   Wang M, 2021, IEEE T IMAGE PROCESS, V30, P2378, DOI 10.1109/TIP.2021.3051460
   Wang ZM, 2022, 2022 11TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS (ICCCAS 2022), P237, DOI 10.1109/ICCCAS55266.2022.9825469
   Wu SL, 2022, IEEE T CIRC SYST VID, V32, P5638, DOI 10.1109/TCSVT.2022.3146061
   Xiang L., 2020, Doc. JVET-T2020
   Xiaohan Guan, 2021, 2021 International Conference on Digital Society and Intelligent Systems (DSInS), P371, DOI 10.1109/DSInS54396.2021.9670606
   Xu M, 2005, REMOTE SENS ENVIRON, V97, P322, DOI 10.1016/j.rse.2005.05.008
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yeo Woon-Ha, 2021, Journal of Multimedia Information System, V8, P147
   Zhang QW, 2020, IEEE ACCESS, V8, P203516, DOI 10.1109/ACCESS.2020.3036858
   Zhang SS, 2022, IEEE INT SYM BROADB, DOI 10.1109/BMSB55706.2022.9828663
   Zhang Ziheng, 2022, 2022 IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR), P84, DOI 10.1109/MIPR54900.2022.00022
   Zhao JC, 2022, IEEE ACCESS, V10, P100337, DOI 10.1109/ACCESS.2022.3208135
NR 47
TC 1
Z9 1
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103910
DI 10.1016/j.jvcir.2023.103910
EA AUG 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S2GK0
UT WOS:001069401900001
DA 2024-07-18
ER

PT J
AU Patel, S
   Vaish, A
AF Patel, Saumya
   Vaish, Ankita
TI An efficient optimization of measurement matrix for compressive sensing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Measurement matrix; Optimization; Compressive sensing; Sparsity
ID PROJECTION MATRIX; ALGORITHM
AB Compressive sensing (CS) is a new paradigm for signal acquisition and reconstruction, which can reconstruct the signal at less than the Nyquist sampling rate. The sampling of the signal occurs through a measurement matrix (MM); thus, MM generation is significant in the context of the CS framework. In this paper, an optimization algorithm is introduced for the generation of the MM of CS based on Restricted Isometric Property (RIP) mandates that eigenvalues of the sensing matrix fall within an interval also minimizes the mutual coherence of the sensing matrix (i.e. the product of the MM and sparsifying matrix). A novel gradient-based iterative optimization method is used to reduce the eigenvalues of the sensing matrix by SVD decomposition. Meanwhile, the proposed algorithm can also reduce the operational complexity. Experimental results and analysis prove that the optimized MM reduces the maximum mutual and average mutual coherence between the MM and the sparsifying basis, which shows the effectiveness of the proposed algorithm over some state-of-art works.
C1 [Patel, Saumya; Vaish, Ankita] Banaras Hindu Univ, Varanasi, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU)
RP Patel, S (corresponding author), Banaras Hindu Univ, Varanasi, Uttar Pradesh, India.
EM saumyapatel5@gmail.com
RI PATEL, SAUMYA/KQU-8641-2024
OI PATEL, SAUMYA/0000-0002-8692-7194
CR Abolghasemi V, 2012, SIGNAL PROCESS, V92, P999, DOI 10.1016/j.sigpro.2011.10.012
   Bandeira AS, 2013, IEEE T INFORM THEORY, V59, P3448, DOI 10.1109/TIT.2013.2248414
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Elad M, 2007, IEEE T SIGNAL PROCES, V55, P5695, DOI 10.1109/TSP.2007.900760
   Entezari R, 2017, AEU-INT J ELECTRON C, V82, P321, DOI 10.1016/j.aeue.2017.09.015
   Hong T, 2016, SIGNAL PROCESS, V125, P9, DOI 10.1016/j.sigpro.2015.12.015
   Johnson DH., 2006, SCHOLARPEDIA, V1, P2088, DOI [DOI 10.4249/SCHOLARPEDIA.2088, 10.4249/scholarpedia.2088]
   Lu WZ, 2018, IEEE T SIGNAL PROCES, V66, P77, DOI 10.1109/TSP.2017.2757915
   Lu WZ, 2015, IEEE SIGNAL PROC LET, V22, P1074, DOI 10.1109/LSP.2014.2385813
   Nouasria H, 2022, SIGNAL IMAGE VIDEO P, V16, P2279, DOI 10.1007/s11760-022-02193-4
   Pan JF, 2018, IET IMAGE PROCESS, V12, P1773, DOI 10.1049/iet-ipr.2017.0888
   Pan JF, 2016, CIRC SYST SIGNAL PR, V35, P837, DOI 10.1007/s00034-015-0107-4
   Peng JY, 2020, MED PHYS, V47, P1907, DOI 10.1002/mp.14010
   Tropp JA, 2005, IEEE T INFORM THEORY, V51, P188, DOI 10.1109/TIT.2004.839492
   Xu JX, 2011, ERGOD THEOR DYN SYST, V31, P599, DOI 10.1017/S0143385709001114
   Xu QR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041229
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 22
TC 0
Z9 0
U1 5
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103904
DI 10.1016/j.jvcir.2023.103904
EA AUG 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P8BR6
UT WOS:001052874600001
DA 2024-07-18
ER

PT J
AU Hermesa, N
   Bigalkea, A
   Heinricha, MP
AF Hermesa, Niklas
   Bigalkea, Alexander
   Heinricha, Mattias P.
TI Point cloud-based scene flow estimation on realistically deformable
   objects: A benchmark of deep learning-based methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene flow estimation; 3D; Point clouds; Computer vision; Deep learning;
   Convolutional neural networks
AB Flow estimation on 3D point clouds is a challenging problem in the field of computer vision, which has great significance in many areas, such as autonomous driving and human interaction applications. Within the last years, the field of motion analysis has made great progress. The evaluation of the existing approaches mostly focuses on scenarios where objects are affected by rigid transformations. However, in many application areas such as gesture recognition or pose tracking, the detection of shape changes is essential and breaking them down to local rigid transformations is accompanied by loss of information. One component of ou r contributions is that we specifically prepared existing datasets for scene flow estimation on deformable objects. Additionally, we benchmark existing methods and analyze their behavior on various subtasks. The results show that already close to 80% of correct correspondences can be found on synthetic hand data, while only around 50% are found on real hand data. Our experimental validation and analysis help to build an understanding of new possibilities in broader areas. Furthermore, they should help to inspir e possible further research directions.
C1 [Hermesa, Niklas; Bigalkea, Alexander; Heinricha, Mattias P.] Lubeck Univ, Inst Med Informat, Lubeck, Germany.
   [Hermesa, Niklas] Gestigon GmbH, D-23562 Lubeck, Germany.
C3 University of Lubeck
RP Hermesa, N (corresponding author), Lubeck Univ, Inst Med Informat, Lubeck, Germany.
EM n.hermes@student.uni-luebeck.de
CR Ao S, 2021, PROC CVPR IEEE, P11748, DOI 10.1109/CVPR46437.2021.01158
   Battrawy R, 2019, Arxiv, DOI arXiv:1910.14453
   Behl A., 2018, Pointflownet: Learning representations for 3d scene flow estimation from point clouds, DOI DOI arXiv:1806.02170.v3
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bhatnagar Bharat Lal, 2020, Advances in Neural Information Processing Systems, V33, P12909
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Chen MY, 2019, OPT LASER ENG, V122, P170, DOI 10.1016/j.optlaseng.2019.06.011
   Chizat L, 2017, Arxiv, DOI [arXiv:1607.05816, DOI 10.48550/ARXIV.1607.05816]
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cuturi M., 2013, ADV NEURAL INFORM PR, P2292, DOI DOI 10.48550/ARXIV.1306.0895
   Deng BL, 2022, COMPUT GRAPH FORUM, V41, P559, DOI 10.1111/cgf.14502
   Ding LH, 2022, LECT NOTES COMPUT SC, V13699, P213, DOI 10.1007/978-3-031-19842-7_13
   Fan HH, 2019, Arxiv, DOI arXiv:1910.08287
   Feng WQ, 2021, PROC CVPR IEEE, P10292, DOI 10.1109/CVPR46437.2021.01016
   Gojcic Z, 2021, Arxiv, DOI arXiv:2102.08945
   Gu XD, 2022, PROC CVPR IEEE, P8206, DOI 10.1109/CVPR52688.2022.00804
   Gu XY, 2019, PROC CVPR IEEE, P3249, DOI 10.1109/CVPR.2019.00337
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hur J, 2021, PROC CVPR IEEE, P2683, DOI 10.1109/CVPR46437.2021.00271
   Hur Junhwa, 2020, P IEEE CVF C COMP VI, P7396
   Jin Z., 2022, DEFORMATION CORRSEP, P7223, DOI [10.1109/CVPR52688.2022.00709, DOI 10.1109/CVPR52688.2022.00709]
   Kingma D, 2014, C LEARNING REPRESENT, P12
   Kittenplon Y, 2021, Arxiv, DOI arXiv:2011.10147
   Lenz P, 2011, IEEE INT VEH SYM, P926, DOI 10.1109/IVS.2011.5940558
   Li RB, 2021, PROC CVPR IEEE, P364, DOI 10.1109/CVPR46437.2021.00043
   Li Y., 2021, IEEE INT C COMPUTER
   Li Y, 2022, PROC CVPR IEEE, P5544, DOI 10.1109/CVPR52688.2022.00547
   Li YL, 2019, Arxiv, DOI [arXiv:1902.05399, 10.48550/ARXIV.1902.05399, DOI 10.48550/ARXIV.1902.05399]
   Lin GC, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106107
   Liu XY, 2019, IEEE I CONF COMP VIS, P9245, DOI 10.1109/ICCV.2019.00934
   Liu XY, 2019, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2019.00062
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Maretic H.P., 2019, P 33 INT C NEURAL IN
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, ISPRS ANN PHOTO REM, VII-3, P427, DOI 10.5194/isprsannals-II-3-W5-427-2015
   Menze M, 2018, ISPRS J PHOTOGRAMM, V140, P60, DOI 10.1016/j.isprsjprs.2017.09.013
   Min YC, 2020, PROC CVPR IEEE, P5760, DOI 10.1109/CVPR42600.2020.00580
   Monga V, 2021, IEEE SIGNAL PROC MAG, V38, P18, DOI 10.1109/MSP.2020.3016905
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Owoyemi J, 2018, IEEE INT CONF ROBOT, P5929, DOI 10.1109/ICRA.2018.8460910
   Poiesi F, 2023, IEEE T PATTERN ANAL, V45, P3979, DOI 10.1109/TPAMI.2022.3175371
   Puy Gilles, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P527, DOI 10.1007/978-3-030-58604-1_32
   Qi CR, 2017, Arxiv, DOI [arXiv:1706.02413, DOI 10.48550/ARXIV.1706.02413]
   Sarode V, 2019, Arxiv, DOI arXiv:1908.07906
   Shen Z., 2021, Accurate Point Cloud Registration with Robust Optimal Transport
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Tishchenko I, 2020, Arxiv, DOI [arXiv:2009.10467, DOI 10.48550/ARXIV.2009.10467, 10.48550/ARXIV.2009.10467]
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Vayer T, 2019, PR MACH LEARN RES, V97
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Wang GM, 2022, LECT NOTES COMPUT SC, V13693, P38, DOI 10.1007/978-3-031-19827-4_3
   Wang HY, 2021, PROC CVPR IEEE, P14168, DOI 10.1109/CVPR46437.2021.01395
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wei Y, 2021, PROC CVPR IEEE, P6950, DOI 10.1109/CVPR46437.2021.00688
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu Wenxuan, 2020, EUROPEAN C COMPUTER, P88
   Xu J, 2017, PROC CVPR IEEE, P5807, DOI 10.1109/CVPR.2017.615
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 61
TC 0
Z9 0
U1 3
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103893
DI 10.1016/j.jvcir.2023.103893
EA JUL 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O9EN8
UT WOS:001046779700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wan, B
   Zhou, XF
   Zhu, B
   Xiao, M
   Sun, YQ
   Zheng, BL
   Zhang, JY
   Yan, CG
AF Wan, Bin
   Zhou, Xiaofei
   Zhu, Bin
   Xiao, Mang
   Sun, Yaoqi
   Zheng, Bolun
   Zhang, Jiyong
   Yan, Chenggang
TI CANet: Context-aware Aggregation Network for Salient Object Detection of
   Surface Defects*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Defect detection; Salient object detection; Weighted convolution
   pyramid; Cascaded fusion structure
ID NEURAL-NETWORK; INSPECTION; ATTENTION; PATTERNS; MODEL
AB Surface defect detection has become more and more important in the industrial manufacture and engineering application in recent years. However, due to the lack of overall perception and interaction among features layers, lots of computer vision-based detection methods cannot grab the complete details of defects when dealing with complex scenes, such as low contrast and irregular shape. Therefore, in this paper, we propose a Context-aware Aggregation Network (CANet) to accurately pop-out the defects, where we focus on the mining of context cues and the fusion of multiple context features. To be specific, embarking on the multi-level deep features extracted by encoder, we first deploy a sufficient exploration to dig the context information by deploying the weighted convolution pyramid (WCP) module, which extracts multi-scale context features, transfers the information flow between different resolution features, and fuses the features with same resolution. By this way, we can obtain the effective context pyramid features. Then, the decoder deploys the weighted context attention (WCA) module to filter the irrelevant information from context features and employs the cascaded fusion structure (CFS) to aggregate the multiple context cues in a hierarchical way. Following this way, the generated high-quality saliency maps can highlight the defects accurately and completely. Extensive experiments are performed on four public datasets, and the results firmly prove the effectiveness and superiority of the proposed CANet under different evaluation metrics.
C1 [Wan, Bin; Zhou, Xiaofei; Sun, Yaoqi; Zheng, Bolun; Zhang, Jiyong; Yan, Chenggang] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
   [Zhu, Bin] Huzhou Univ, Huzhou 313000, Peoples R China.
   [Xiao, Mang] Zhejiang Univ, Sir Run Run Shaw Hosp, Dept Otolaryngol Head & Neck Surg, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Huzhou University; Zhejiang University
RP Zhou, XF (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
EM wanbinxueshu@icloud.com; zxforchid@outlook.com; 227342978@qq.com;
   joelxm@zju.edu.cn; syq@hdu.edu.cn; blzheng@hdu.edu.cn;
   jzhang@hdu.edu.cn; cgyan@hdu.edu.cn
FU National Key Research and Development Program of China [2020YFB1406604];
   Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK229909299001-009, GK219909299001-407]; National Natural Science
   Foundation of China [62271180, 62171002, 61901145, U21B2024, 61931008,
   62071415, 61972123, 62001146]; Zhejiang Province Nature Science
   Foundation of China [LR17F030006, LY19F030022, LZ22F020003]; Hangzhou
   Dianzi University (HDU); China Electronics Corporation DATA (CECDATA)
   Joint Re-search Center of Big Data Technologies [KYH063120009]; 111
   Project [D17019]
FX This work was supported by the National Key Research and Devel-opment
   Program of China under Grants 2020YFB1406604; the Fun-damental Research
   Funds for the Provincial Universities of Zhejiang under Grants
   GK229909299001-009; the National Natural Science Foundation of China
   under Grants 62271180, 62171002, 61901145, U21B2024, 61931008, 62071415,
   61972123, 62001146; the Zhejiang Province Nature Science Foundation of
   China under Grants LR17F030006, LY19F030022, LZ22F020003; the Hangzhou
   Dianzi University (HDU) and the China Electronics Corporation DATA
   (CECDATA) Joint Research Center of Big Data Technologies under Grants
   KYH063120009; the 111 Project under Grants D17019; and the Fundamental
   Research Funds for the Provincial Universities of Zhejiang under Grants
   GK219909299001-407.
CR Bissi L, 2013, J VIS COMMUN IMAGE R, V24, P838, DOI 10.1016/j.jvcir.2013.05.011
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen FC, 2018, IEEE T IND ELECTRON, V65, P4392, DOI 10.1109/TIE.2017.2764844
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Chen YT, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103776
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Chen YT, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02778-2
   Chen Z, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01370-7
   Cheng X, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3040485
   Dong HW, 2020, IEEE T IND INFORM, V16, P7448, DOI 10.1109/TII.2019.2958826
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Ghorai S, 2013, IEEE T INSTRUM MEAS, V62, P612, DOI 10.1109/TIM.2012.2218677
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2020, IEEE T INSTRUM MEAS, V69, P1493, DOI 10.1109/TIM.2019.2915404
   Hinton Geoffrey., 2012, NEURAL NETWORKS MACH, V6e, page, P13
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu Y., 2010, J. Pattern Recognit. Res., V5, P140, DOI 10.13176/11.167
   Huang YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3047190
   Huang YB, 2020, VISUAL COMPUT, V36, P85, DOI 10.1007/s00371-018-1588-5
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li GY, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3145483
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu FF, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P610, DOI 10.1109/KAM.2008.29
   Liu N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4702, DOI 10.1109/ICCV48922.2021.00468
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Nakazawa T, 2019, IEEE T SEMICONDUCT M, V32, P250, DOI 10.1109/TSM.2019.2897690
   Ni XF, 2022, IEEE T IND INFORM, V18, P1694, DOI 10.1109/TII.2021.3085848
   Paszke A, 2019, ADV NEUR IN, V32
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song GR, 2020, IEEE T INSTRUM MEAS, V69, P9709, DOI 10.1109/TIM.2020.3002277
   Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002
   Sun YA, 2020, IEEE T EVOLUT COMPUT, V24, P394, DOI 10.1109/TEVC.2019.2916183
   Wang CJ, 2020, IEEE T IND INFORM, V16, P2667, DOI 10.1109/TII.2019.2945362
   Wang Q, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103260
   Wang XL, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P917, DOI 10.1109/ICTIS.2017.8047878
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wieler Matthias, 2007, P DAGM S
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xia RL, 2022, J KING SAUD UNIV-COM, V34, P6008, DOI 10.1016/j.jksuci.2022.02.004
   Yang F, 2020, IEEE T INTELL TRANSP, V21, P1525, DOI 10.1109/TITS.2019.2910595
   Yous H, 2019, J VIS COMMUN IMAGE R, V59, P486, DOI 10.1016/j.jvcir.2019.02.005
   Zhang DF, 2021, IEEE T IND INFORM, V17, P6731, DOI 10.1109/TII.2020.3045196
   Zhang DF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3040890
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhong JP, 2019, IEEE T INSTRUM MEAS, V68, P2849, DOI 10.1109/TIM.2018.2871353
   Zhou J, 2006, OPT ENG, V45, DOI 10.1117/1.2172917
   Zhou XF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3132082
   Zhou XF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3091312
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 63
TC 2
Z9 2
U1 3
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103820
DI 10.1016/j.jvcir.2023.103820
EA APR 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F0SL2
UT WOS:000979530300001
DA 2024-07-18
ER

PT J
AU Yuan, MR
   Zhang, HX
   Liu, DM
   Wang, L
   Liu, L
AF Yuan, Mengru
   Zhang, Huaxiang
   Liu, Dongmei
   Wang, Lin
   Liu, Li
TI Semantic-embedding Guided Graph Network for cross-modal retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-modal retrieval; Graph convolution network; Adversarial network;
   Graph aggregation network
AB Many methods focus on aligning image regions with the corresponding text fragments, and ignore that images contain fragments that cannot be expressed by texts. To fully express the information of images and prevent the performance degradation caused by fine-grained information deviating from the core meaning of images, we propose Semantic-embedding Guided Graph Network (SGGN) for cross-modal retrieval. It learns the detail representations of each modality, with an integrated semantic information, by guiding local fragments to capture the internal correlation of cross-modal data and effectively convey the information. To further bridge the semantic gap between different modalities, SGGN uses adversarial network to play a game, and uses graph aggregation network to absorb complementary information of neighbor samples. We evaluate our approach on two datasets. Our method (based on R@10) achieves 97.2% on Flickr30k dataset. On MS-COCO dataset, it reaches 99.2% using 1K test set and 92.0% using 5K test set.
C1 [Yuan, Mengru; Zhang, Huaxiang; Liu, Dongmei; Wang, Lin; Liu, Li] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong Provin, Peoples R China.
   [Zhang, Huaxiang] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong Provin, Peoples R China.
C3 Shandong Normal University; Shandong Jiaotong University
RP Zhang, HX; Liu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong Provin, Peoples R China.
EM huaxzhang@hotmail.com; liuli_790209@163.com
FU National Natural Science Foundation of China [62176144, U1836216,
   62076153]; Shandong, China [ZR2019Z D03]; Taishan Scholar Project of
   Shandong Province, China [ts20190924]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 62176144, U1836216, 62076153) , the major
   fundamental research project of Shandong, China (No. ZR2019Z D03) , and
   the Taishan Scholar Project of Shandong Province, China (No. ts20190924)
   .
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chen Ran, 2022, ARXIV
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Diao HW, 2021, Arxiv, DOI arXiv:2101.01368
   Dong XF, 2022, IEEE T CIRC SYST VID, V32, P1634, DOI 10.1109/TCSVT.2021.3075242
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hu ZB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P789
   Huang Y, 2017, PROC CVPR IEEE, P7254, DOI 10.1109/CVPR.2017.767
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Ji Z., 2021, arXiv
   Ji Z, 2022, IEEE T CYBERNETICS, V52, P1086, DOI 10.1109/TCYB.2020.2985716
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1063, DOI 10.1145/3178876.3186005
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Que Y, 2023, ENG STRUCT, V277, DOI 10.1016/j.engstruct.2022.115406
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Song Y, 2019, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2019.00208
   Tang YC, 2023, ENG STRUCT, V274, DOI 10.1016/j.engstruct.2022.115158
   Tang YC, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118573
   Tang YC, 2022, STRUCTURES, V37, P426, DOI 10.1016/j.istruc.2021.12.055
   van den Berg R, 2017, Arxiv, DOI arXiv:1706.02263
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wang SJ, 2020, IEEE WINT CONF APPL, P1497, DOI 10.1109/WACV45572.2020.9093614
   Wang Y., 2019, arXiv
   Wang ZH, 2019, IEEE I CONF COMP VIS, P5763, DOI 10.1109/ICCV.2019.00586
   Wu J, 2022, IEEE T CIRC SYST VID, V32, P388, DOI 10.1109/TCSVT.2021.3060713
   Xie D, 2020, IEEE T IMAGE PROCESS, V29, P3626, DOI 10.1109/TIP.2020.2963957
   Xu RQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P982
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Yongzhi Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12783, DOI 10.1109/CVPR42600.2020.01280
   Yu MY, 2017, IEEE T NEUR NET LEAR, V28, P2899, DOI 10.1109/TNNLS.2016.2609463
   Zhang J, 2022, MULTIMED TOOLS APPL, V81, P12005, DOI 10.1007/s11042-020-10466-8
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
NR 47
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103807
DI 10.1016/j.jvcir.2023.103807
EA MAR 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C1LC4
UT WOS:000959607500001
DA 2024-07-18
ER

PT J
AU Wang, YN
   Zhang, ZB
AF Wang, Yongnian
   Zhang, Zhibin
TI Global attention retinex network for low light image enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low light image enhancement; Retinex; Global attention; Channel
   attention
AB Most low-light image enhancement methods only adjust the brightness, contrast and noise reduction of low -light images, making it difficult to recover the lost information in darker areas of the image, and even cause color distortion and blurring. To solve the above problems, a global attention-based Retinex network (GARN) for low-light image enhancement is proposed in this paper. We propose a novel global attention module which computes multiple dimensional information in the channel attention module to help facilitate inference learning. Then the global attention module is embedded into different layers of the network to extract richer shallow texture features and deep semantic features. This means that the rich features are more conducive to learning the mapping relationship between low-light images to normal-light images, so that the detail recovery of dark regions is enhanced in low-light images. We also collected a low/normal light image dataset with multiple scenes, in which the images paired as training set can succeed to be applied to low-light image enhancement under different lighting conditions. Experimental results on publicly available datasets show that our method has better effectiveness and generality than the state-of-the-art methods in terms of evaluations metrics such as PSNR, SSIM, NIQE, Entropy.
C1 [Zhang, Zhibin] Inner Mongolia Univ, Sch Comp Sci, Hohhot 010021, Peoples R China.
   Inner Mongolia Univ, Sch Comp Sci, Key Lab Wireless Networks & Mobile Comp, Hohhot 010021, Peoples R China.
C3 Inner Mongolia University; Inner Mongolia University
RP Zhang, ZB (corresponding author), Inner Mongolia Univ, Sch Comp Sci, Hohhot 010021, Peoples R China.
EM cszhibin@imu.edu.cn
RI zhang, zhibin/IQS-5892-2023
OI Wang, Yongnian/0009-0002-3240-9911; zhang, zhibin/0000-0002-7754-0385
FU Major Special Project of the Inner Mongolia Autonomous Region; National
   Natural Science Foundation of China [2021SZD0043, 31760345]
FX Acknowledgments This study is fully supported by the Major Special
   Project of the Inner Mongolia Autonomous Region and the National Natural
   Science Foundation of China (No. 2021SZD0043; No. 31760345) .
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Atoum Y, 2020, IEEE COMPUT SOC CONF, P2130, DOI 10.1109/CVPRW50498.2020.00261
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chen J., 2022, MULTIMEDIA TOOLS APP, P1
   Fan MH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2317, DOI 10.1145/3394171.3413757
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao Hu, 2021, 2021 International Conference on Electronic Information Engineering and Computer Science (EIECS), P612, DOI 10.1109/EIECS53707.2021.9587939
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin YY, 2022, LECT NOTES COMPUT SC, V13697, P404, DOI 10.1007/978-3-031-19836-6_23
   Ko S, 2022, IEEE SIGNAL PROC LET, V29, P289, DOI 10.1109/LSP.2021.3134943
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liu Y., 2021, arXiv, DOI DOI 10.48550/ARXIV.2112.05561
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Pramanik A, 2022, IEEE TETCI, V6, P171, DOI 10.1109/TETCI.2020.3041019
   Shen L, 2017, Arxiv, DOI arXiv:1711.02488
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118
   Wang XH, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13335-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Wei Q, 2017, METHODS MOL BIOL, V1611, P1, DOI 10.1007/978-1-4939-7015-5_1
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu WH, 2022, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR52688.2022.00581
   Ying ZQ, 2017, Arxiv, DOI arXiv:1711.00591
   Zhang X, 2021, IEEE ACCESS, V9, P50939, DOI 10.1109/ACCESS.2021.3068534
   Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhu A, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR INDUSTRIES (AI4I 2020), P1, DOI 10.1109/AI4I49448.2020.00007
NR 36
TC 4
Z9 4
U1 6
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103795
DI 10.1016/j.jvcir.2023.103795
EA MAR 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C4PZ5
UT WOS:000961765300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, QF
AF li, Qifan
TI Denoising image by matrix factorization in U-shaped convolutional neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Matrix factorization; Convolution network; Image
   restoration
ID SPARSE; REPRESENTATION
AB Image denoising requires both spatial details and global contextualized information to recover a clean version from the deteriorative one. Previous deep convolution networks usually focus on modeling the local feature and stacked convolution blocks to expand the receptive field, which can catch the long-distance dependencies. However, contrary to the expectation, the extracted local feature incapacity recovers the global details by traditional convolution while the stacked blocks hinder the information flow. To tackle these issues, we introduce the Matrix Factorization Denoising Module (MD) to model the interrelationship between the global context aggregating process and the reconstructed process to attain the context details. Besides, we redesign a new basic block to ease the information flow and maintain the network performance. In addition, we conceive the Feature Fusion Module (FFU) to fuse the information from the different sources. Inspired by the multi-stage progressive restoration architecture, we adopt two-stage convolution branches progressively reconstructing the denoised image. In this paper, we propose an original and efficient neural convolution network dubbed MFU. Experimental results on various image denoising datasets: SIDD, DND, and synthetic Gaussian noise datasets show that our MFU can produce comparable visual quality and accuracy results with state-of-the-art methods.
C1 [li, Qifan] Fudan Univ, Dept Comp Sci, SonghuRd 2005, Shanghai 200082, Peoples R China.
C3 Fudan University
RP Li, QF (corresponding author), Fudan Univ, Dept Comp Sci, SonghuRd 2005, Shanghai 200082, Peoples R China.
EM qfli20@fudan.edu.cn
CR Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Benesty J, 2010, INT CONF ACOUST SPEE, P205, DOI 10.1109/ICASSP.2010.5496033
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cheng S, 2021, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR46437.2021.00486
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3099, DOI 10.1145/2556288.2557011
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Eriksson A, 2012, IEEE T PATTERN ANAL, V34, P1681, DOI 10.1109/TPAMI.2012.116
   Geng ZY, 2021, Arxiv, DOI arXiv:2109.04553
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu RS, 2012, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2012.6247726
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov Ilya, 2016, arXiv
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mao XJ, 2016, ADV NEUR IN, V29
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Plötz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Trigeorgis G, 2017, IEEE T PATTERN ANAL, V39, P417, DOI 10.1109/TPAMI.2016.2554555
   Udell M, 2016, FOUND TRENDS MACH LE, V9, P2, DOI 10.1561/2200000055
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZD, 2021, Arxiv, DOI arXiv:2106.03106
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3203
   Yi BL, 2019, IEEE T IND INFORM, V15, P4591, DOI 10.1109/TII.2019.2893714
   Yue ZS, 2019, ADV NEUR IN, V32
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zamir SW, 2020, PROC CVPR IEEE, P2693, DOI 10.1109/CVPR42600.2020.00277
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhang L, 2017, IEEE SIGNAL PROC MAG, V34, P172, DOI 10.1109/MSP.2017.2717489
NR 53
TC 1
Z9 1
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103729
DI 10.1016/j.jvcir.2022.103729
EA DEC 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7L9BN
UT WOS:000906253300001
DA 2024-07-18
ER

PT J
AU Kuo, CCJ
   Madni, AM
AF Kuo, C. -C. Jay
   Madni, Azad M.
TI Green learning: Introduction, examples and outlook?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Machine learning; Green learning; Trust learning; Deep learning
ID IMAGE QUALITY ASSESSMENT; SELECTION; NETWORKS; MODEL
AB Rapid advances in artificial intelligence (AI) in the last decade have been largely built upon the wide applications of deep learning (DL). However, the high carbon footprint yielded by larger and larger DL networks has become a concern for sustainability. Furthermore, DL decision mechanism is somewhat obscure in that it can only be verified by test data. Green learning (GL) is being proposed as an alternative paradigm to address these concerns. GL is characterized by low carbon footprints, lightweight model, low computational complexity, and logical transparency. It offers energy-efficient solutions in cloud centers as well as mobile/edge devices. GL also provides a more transparent, logical decision-making process which is essential to gaining people's trust. Several statistical tools such as unsupervised representation learning, supervised feature learning, and supervised decision learning, have been developed to achieve this goal in recent years. We have seen a few successful GL examples with performance comparable with state-of-the-art DL solutions. This paper introduces the key characteristics of GL, its demonstrated applications, and future outlook.
C1 [Kuo, C. -C. Jay; Madni, Azad M.] Univ Southern Calif, Los Angeles, CA 90007 USA.
C3 University of Southern California
RP Kuo, CCJ (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
CR [Anonymous], 2018, ICLR 18
   [Anonymous], 2015, ARTIF INTELL RES, DOI DOI 10.5430/AIR.V4N2P22
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fu HY, 2022, Arxiv, DOI arXiv:2208.07023
   Fu Hongyu, 2022, ARXIV
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ge X, 2022, Arxiv, DOI arXiv:2207.05324
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Goodfellow I., 2014, P ADV NEUR INF PROC, P2672
   Granot N, 2022, P IEEECVF C COMPUTER, P13460
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Nguyen HH, 2019, Arxiv, DOI arXiv:1906.06876
   Nguyen HH, 2019, Arxiv, DOI arXiv:1910.12467
   Hamilton WL, 2017, ADV NEUR IN, V30
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoefler T., 2021, J. Mach. Learn Res, V22, P1
   Hoefler T, 2021, J MACH LEARN RES, V23
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hoshen Y, 2019, PROC CVPR IEEE, P5804, DOI 10.1109/CVPR.2019.00596
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Q, 2020, Arxiv, DOI [arXiv:2010.13993, DOI 10.48550/ARXIV.2010.13993]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Johnson A.E., 1997, Spin-images: a representation for 3-D surface matching, DOI 10.1.1.71.4190
   Kadam P., 2021, ARXIV
   Kadam P, 2022, Arxiv, DOI arXiv:2202.07843
   Kadam P, 2022, IEEE T IMAGE PROCESS, V31, P2710, DOI 10.1109/TIP.2022.3160609
   Kadam P, 2020, IEEE I C VI COM I PR, P5, DOI 10.1109/vcip49819.2020.9301874
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Khan S., 2021, ARXIV210101169
   Khan S., 2021, Transformers in vision: A survey
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Kipf T. N., 2016, arXiv preprint arXiv:1609.02907
   Klicpera J., 2018, P INT C LEARN REPR
   Klicpera Johannes, 2018, INT C LEARNING REPRE
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo CCJ, 2018, J VIS COMMUN IMAGE R, V50, P237, DOI 10.1016/j.jvcir.2017.11.023
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Kuo CCJ, 2019, J VIS COMMUN IMAGE R, V60, P346, DOI 10.1016/j.jvcir.2019.03.010
   Lannelongue L, 2021, ADV SCI, V8, DOI 10.1002/advs.202100707
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei XJ, 2021, APSIPA TRANS SIGNAL, V10, DOI 10.1017/ATSIP.2021.15
   Lei XJ, 2020, ASIAPAC SIGN INFO PR, P1698
   Lei Xuejing, 2022, ARXIV
   Li D, 2020, 2020 16TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2020), P298, DOI 10.1109/CIS52066.2020.00070
   Li K, 2018, Arxiv, DOI arXiv:1809.09087
   Li QM, 2019, PROC CVPR IEEE, P9574, DOI 10.1109/CVPR.2019.00981
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Li Qimai, 2019, PROC CVPR IEEE, P9582, DOI DOI 10.1109/CVPR.2019.00981
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Li Yuezun, 2019, IEEE C COMPUTER VISI
   Li Z., 2018, NETFLIX TECH BLOG
   Lin HH, 2019, INT WORK QUAL MULTIM
   Lin RY, 2021, IEEE SIGNAL PROC LET, V28, P1813, DOI 10.1109/LSP.2021.3103130
   Lin Ruiyuan, 2022, IEEE T NEUR NET LEAR
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu S., 2021, 3D Point cloud analysis
   Liu XF, 2021, Arxiv, DOI arXiv:2101.05131
   Loh WY, 2011, WIRES DATA MIN KNOWL, V1, P14, DOI 10.1002/widm.8
   Louizos C, 2017, ADV NEUR IN, V30
   Ma Y, 2022, FRONT INFORM TECH EL, V23, P1298, DOI 10.1631/FITEE.2200297
   MADNI AM, 1982, IEEE T SYST MAN CYB, V12, P504, DOI 10.1109/TSMC.1982.4308855
   Madni Azad M., 1985, APPL ARTIF INTELL, P279
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Mahdisoltani F., 2014, P 7 BIENN C INN DAT
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   Mei ZX, 2022, Arxiv, DOI arXiv:2206.14400
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Murshed MGS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3469029
   Nie FP, 2010, NEURAL COMPUT APPL, V19, P549, DOI 10.1007/s00521-009-0305-8
   Northcutt CG, 2021, Arxiv, DOI arXiv:2103.14749
   Oymak Samet, 2021, INT C MACHINE LEARNI, P8291
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Poursabzi-Sangdeh F, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445315
   Nguyen DQ, 2018, Arxiv, DOI arXiv:1712.02121
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Rouhsedaghat Mozhdeh, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P169, DOI 10.1007/978-3-030-68793-9_12
   Rouhsedaghat M, 2021, PATTERN RECOGN LETT, V149, P193, DOI 10.1016/j.patrec.2021.05.009
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salehinejad H, 2018, Arxiv, DOI arXiv:1801.01078
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Scheffe H., 1959, ANAL VARIANCE
   Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831
   Seferbekov Selim, 2020, PRIZE WINNING SOLUTI
   Sharir O, 2020, Arxiv, DOI [arXiv:2004.08900, DOI 10.48550/ARXIV.2004.08900, 10.48550/arXiv.2004.08900]
   Sheikhpour R, 2017, PATTERN RECOGN, V64, P141, DOI 10.1016/j.patcog.2016.11.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K., 2020, ADV NEURAL INFORM PR
   Solorio-Fernández S, 2020, ARTIF INTELL REV, V53, P907, DOI 10.1007/s10462-019-09682-y
   Soltanolkotabi M, 2019, IEEE T INFORM THEORY, V65, P742, DOI 10.1109/TIT.2018.2854560
   Song ZX, 2023, IEEE T NEUR NET LEAR, V34, P8174, DOI 10.1109/TNNLS.2022.3155478
   Strubell E, 2019, Arxiv, DOI [arXiv:1906.02243, 10.48550/arXiv.1906.02243]
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Su YH, 2019, NEUROCOMPUTING, V356, P151, DOI 10.1016/j.neucom.2019.04.044
   Su Yuanhang, 2022, APSIPA T SIGNAL INF, V11
   Sun ZQ, 2019, Arxiv, DOI arXiv:1902.10197
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Toutanova K., 2015, P 3 WORKSH CONT VECT, P57, DOI [10.18653/v1/W15-4007, DOI 10.18653/V1/W15-4007]
   Tseng TW, 2020, IEEE ACCESS, V8, P143962, DOI 10.1109/ACCESS.2020.3014307
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan Sheng, 2021, ADV NEURAL INF PROCE, V34
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang Jinyan, 2022, NEURAL NETWORKS
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Yue, 2019, Adv. Neural Inf. Process. Syst., P8814
   Wang YC, 2022, Arxiv, DOI arXiv:2208.09137
   Wang YC, 2022, PATTERN RECOGN LETT, V157, P104, DOI 10.1016/j.patrec.2022.04.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei CW, 2022, Arxiv, DOI arXiv:2206.10029
   Wei Chengwei, 2022, PATTERN RECOGN LETT
   Wei Chengwei, 2022, P IEEE C MULTIMEDIA
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wright J., 2022, High-dimensional data analysis with low-dimensional models: Principles, computation, and applications
   Wu C. -J., 2022, Proceedings of Machine Learning and Systems, V4, P795, DOI DOI 10.48550/ARXIV.2111.00364
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie T, 2022, Arxiv, DOI arXiv:2204.08646
   Xie Tian, 2022, IEEE T NEUR NET LEAR
   Xu H, 2017, ASIAPAC SIGN INFO PR, P1052, DOI 10.1109/APSIPA.2017.8282184
   Xu J., 2021, arXiv
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Yang XH, 2019, IEEE ACCESS, V7, P123788, DOI 10.1109/ACCESS.2019.2938900
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yang Y., 2022, arXiv
   Yang YJ, 2022, Arxiv, DOI arXiv:2203.11924
   Yang YJ, 2022, Arxiv, DOI arXiv:2206.09061
   Yang YJ, 2021, ASIAPAC SIGN INFO PR, P1475
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Yuezun Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3204, DOI 10.1109/CVPR42600.2020.00327
   Zadrozny B., 2004, INT C MACH LEARN ICM, DOI 10.1145/1015330.1015425
   Zeng DL, 2021, Arxiv, DOI arXiv:2101.10531
   Zeng Hanqing, 2021, ADV NEURAL INF PROCE, V34
   Zeng H, 2018, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2018.8451285
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang KT, 2019, IEEE IMAGE PROC, P4419, DOI [10.1109/icip.2019.8803556, 10.1109/ICIP.2019.8803556]
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang M., 2020, ARXIV
   Zhang M, 2021, Arxiv, DOI arXiv:2109.11835
   Zhang M, 2020, IEEE I C VI COM I PR, P144, DOI 10.1109/vcip49819.2020.9301786
   Zhang M, 2020, IEEE T MULTIMEDIA, V22, P1744, DOI 10.1109/TMM.2019.2963592
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XF, 2021, IEEE T CIRC SYST VID, V31, P3352, DOI 10.1109/TCSVT.2020.3041639
   Zhang XF, 2020, IEEE T IMAGE PROCESS, V29, P9292, DOI 10.1109/TIP.2020.3025203
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhao Z, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8918995
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
   Zhu Y, 2022, INT CONF ACOUST SPEE, P8947, DOI 10.1109/ICASSP43922.2022.9747901
   Zhu YS, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1516, DOI 10.1145/3488560.3498437
   Zou Z., 2019, arXiv
NR 178
TC 15
Z9 15
U1 7
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103685
DI 10.1016/j.jvcir.2022.103685
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200003
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Zhang, JQ
   Fang, ZG
   Yu, L
AF Zhang, Jiaqi
   Fang, Zhigao
   Yu, Lu
TI A no-reference perceptual image quality assessment database for learned
   image codecs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Learning-based image compression; Generated
   image compression
ID SIMILARITY
AB The drastic growth of research in image compression, especially deep learning-based image compression techniques, poses new challenges to objective image quality assessment (IQA). Typical artifacts encountered in the emerging image codecs are significantly different from that produced by traditional block-based codecs, leading to inapplicability of the existing objective IQA algorithms. Towards advancing the development of objective IQA algorithms for recent compression artifacts, we built a learning-based compressed image quality assessment (LCIQA) database involving traditional block-based image codecs, hybrid neural network based image codecs, convolutional neural network based and generative adversarial network (GAN) based end-to-end optimized image coding approaches. Our study confirms the statistical difference and human perception difference between reconstructions of learned compression and traditional block-based compression. We propose a two-step deep learning model for learning-based compressed image quality assessment. Extensive experiments on LCIQA database demonstrate that our proposed model performs better than other counterparts on learning-based compressed images, especially on GAN compressed images, and achieves competitive performance to the state-of-the-art IQA metrics on traditional compressed images.
C1 [Yu, Lu] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
   Zhejiang Prov Key Lab Informat Proc Commun & Netwo, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Yu, L (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
EM yul@zju.edu.cn
RI Zhang, Jiaqi/JCO-6818-2023
FU National Natural Science Founda-tion of China [62071427, U21B2004]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Grant 62071427 and U21B2004.
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Agustsson Eirikur, 2017, IEEE CVF C COMP VIS, P126, DOI DOI 10.1109/CVPRW.2017.150
   [Anonymous], 1994, 181994 EG SMPTE, P1
   [Anonymous], 2019, 85 JPEG M
   [Anonymous], 1999, KODAK PHOTOCD DATASE
   [Anonymous], 2012, B SERIES METHODOLOGY, P500
   Ascenso J, 2021, PROC SPIE, V11353, DOI 10.1117/12.2555368
   Balle J., 2018, INT C LEARN REPR ICL, P1
   Ballé J, 2016, PICT COD SYMP, DOI 10.1109/pcs.2016.7906310
   Blau Y, 2019, PR MACH LEARN RES, V97
   Bond-Taylor S, 2022, IEEE T PATTERN ANAL, V44, P7327, DOI 10.1109/TPAMI.2021.3116668
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bossen Frank, 2020, JVETS0003
   Bross B., 2020, JVET-S2001
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cui WX, 2017, IEEE DATA COMPR CONF, P436, DOI 10.1109/DCC.2017.53
   Deng J., 2009, IEEE C COMP VIS PATT
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Fabrice Bellard, 2018, BPG IMAGE FORMAT
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Ghadiyaram D, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P946, DOI 10.1109/GlobalSIP.2014.7032260
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu Jinjin, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P633, DOI 10.1007/978-3-030-58621-8_37
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   ITU-T RECOMMENDATION P., 1999, SUBJ VID QUAL ASS ME
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kingma D. P., 2014, arXiv
   Ko H, 2020, IEEE T IMAGE PROCESS, V29, P5964, DOI 10.1109/TIP.2020.2987180
   Larson E.C., 2009, IMAGE QUAL SYST PERF, P270, DOI DOI 10.1117/12.810071
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li JW, 2020, IEEE T IMAGE PROCESS, V29, P8842, DOI 10.1109/TIP.2020.3020389
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Lin HH, 2019, INT WORK QUAL MULTIM
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mentzer F., 2020, P ADV NEUR INF PROC, V33
   Minnen D, 2018, ADV NEUR IN, V31
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nafchi HZ, 2016, IEEE ACCESS, V4, P5579, DOI 10.1109/ACCESS.2016.2604042
   Pan D, 2018, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2018.00667
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rippel O, 2017, PR MACH LEARN RES, V70
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Theis L., 2017, ICLR
   Tschannen M, 2018, ADV NEUR IN, V31
   VANDIJK AM, 1995, P SOC PHOTO-OPT INS, V2451, P90, DOI 10.1117/12.201231
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang XS, 2018, IEEE IMAGE PROC, P390, DOI 10.1109/ICIP.2018.8451694
   Zhao SJ, 2017, Arxiv, DOI [arXiv:1702.08658, 10.48550/arXiv.1702.08658]
   Zhao X, 2020, PROC SPIE, V11510, DOI 10.1117/12.2570003
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
NR 70
TC 2
Z9 2
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103617
DI 10.1016/j.jvcir.2022.103617
EA AUG 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2FV
UT WOS:000859982300004
DA 2024-07-18
ER

PT J
AU Tariq, J
   Ijaz, A
   Armghan, A
   Rahman, H
   Ali, H
   Alenezi, F
AF Tariq, Junaid
   Ijaz, Amir
   Armghan, Ammar
   Rahman, Hameedur
   Ali, Hashim
   Alenezi, Fayadh
TI HEVC?s intra mode process expedited using Histogram of Oriented
   Gradients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Histogram of Oriented Gradients; HEVC; Intra mode; Fast Encoding
ID DISTORTION COST ESTIMATION; DECISION; PREDICTION; SELECTION; ALGORITHM
AB The brute-force behavior of High Efficiency Video Coding (HEVC) is the biggest hurdle in the communication of multimedia content. Therefore, two novel methods will be presented here to expedite the intra mode decision process of HEVC. In the first algorithm, the feasibility of Histogram of Oriented Gradients (HOG) for early intra mode decision is presented by using statistical evidence. Then, HOG of the current block and 35 intra predictions are obtained. The intra-prediction that gives the least sum of absolute difference (SAD) with the HOG of the current block is selected as the termination point. In the second algorithm, the difference between the Hardmard-cost of intra modes is modeled to achieve fast intra mode decision. The proposed algorithms accelerated the encoding process of the HEVC by 5% and 35.57%, while their Bjontegaard Delta Bit Rate (BD-BR) is 1.09% and 1.61%, respectively.
C1 [Tariq, Junaid] Natl Univ Modern Languages, Dept Comp Sci, Rawalpindi, Pakistan.
   [Ijaz, Amir] HITEC Univ, Dept Comp Engn, Taxila, Pakistan.
   [Armghan, Ammar; Alenezi, Fayadh] Jouf Univ, Dept Elect Engn, Sakaka, Saudi Arabia.
   [Rahman, Hameedur] Air Univ, Dept Creat Technol, Islamabad, Pakistan.
   [Ali, Hashim] Pak Austria Fachhsch, Dept IT & CS, Haripur, Pakistan.
C3 NITEC University; Al Jouf University; Air University Islamabad
RP Tariq, J (corresponding author), Natl Univ Modern Languages, Dept Comp Sci, Rawalpindi, Pakistan.
EM jtariq2-c@my.cityu.edu.hk; amirijaz@live.com; aarmghan@ju.edu.sa;
   rhameedur@mail.au.edu.pk; hashim.ali@fecid.paf-iast.edu.pk;
   fshenezi@ju.edu.sa
RI Ali, Hashim/D-6880-2016; Rahman, Hameedur/HSE-8425-2023; Rahman,
   Hameedur/GPW-6712-2022; Rahman, Hameedur/AAK-6179-2021; Alenezi,
   Fayadh/ABB-4871-2021; Armghan, Ammar/ABA-9560-2021
OI Ali, Hashim/0000-0001-6116-5616; Rahman, Hameedur/0000-0001-8892-9911;
   Alenezi, Fayadh/0000-0002-4099-1254; Armghan, Ammar/0000-0002-9062-7493
CR [Anonymous], 2001, Q6SG16 ITUT
   [Anonymous], 2017, MULTIMED TOOLS APPL, DOI DOI 10.1057/S41278-017-0070-Z
   Armghan A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151839
   Bossen Frank., 2011, Joint Collaborative Team on Video Coding (JCT-VC), JCTVC-F900
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Cristina OC, 2016, 2016 12TH IEEE INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS (ISETC'16), P277, DOI 10.1109/ISETC.2016.7781111
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   frauhofer, 2020, HEVC TEST MOD
   Gwon D, 2019, KSII T INTERNET INF, V13, P385, DOI 10.3837/tiis.2019.01.022
   Hao Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P568, DOI 10.1007/978-3-642-34778-8_53
   Hosseini E, 2019, MULTIMED TOOLS APPL, V78, P11607, DOI 10.1007/s11042-018-6713-y
   Hu Q, 2016, IEEE INT SYM BROADB
   Huang B, 2020, IEEE T CIRC SYST VID, V30, P795, DOI 10.1109/TCSVT.2019.2893396
   Kuanar Shiba, 2019, Circuits Syst Signal Process, P1
   Liao KY, 2010, IEEE T CIRC SYST VID, V20, P38, DOI 10.1109/TCSVT.2009.2026946
   Tariq J, 2022, CMC-COMPUT MATER CON, V70, P3903, DOI 10.32604/cmc.2022.019541
   Tariq J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10090985
   Tariq J, 2021, MULTIMED TOOLS APPL, V80, P21449, DOI 10.1007/s11042-021-10677-7
   Tariq J, 2020, MULTIMED TOOLS APPL, V79, P20299, DOI 10.1007/s11042-020-08915-5
   Tariq J, 2020, VISUAL COMPUT, V36, P1603, DOI 10.1007/s00371-019-01764-w
   Tariq J, 2021, CIRC SYST SIGNAL PR, V40, P418, DOI 10.1007/s00034-020-01482-y
   Tariq J, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102766
   Tariq J, 2019, MULTIMED TOOLS APPL, V78, P31533, DOI 10.1007/s11042-019-07989-0
   Tariq J, 2019, MULTIMED TOOLS APPL, V78, P16783, DOI 10.1007/s11042-018-7111-1
   Tariq J, 2018, J VIS COMMUN IMAGE R, V51, P1, DOI 10.1016/j.jvcir.2017.12.008
   Tian R, 2019, MULTIMED TOOLS APPL, V78, P289, DOI 10.1007/s11042-018-6001-x
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Yan ZG, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P45, DOI 10.1145/3317640.3317645
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang JL, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1018, DOI [10.1109/itnec48623.2020.9084653, 10.1109/ITNEC48623.2020.9084653]
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
   Zhu J, 2013, IEEE IMAGE PROC, P1977, DOI 10.1109/ICIP.2013.6738407
NR 35
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103594
DI 10.1016/j.jvcir.2022.103594
EA AUG 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4H2GN
UT WOS:000849699300001
DA 2024-07-18
ER

PT J
AU Lang, WX
   Sun, H
   Xu, C
   Liu, NZ
   Zhou, HY
AF Lang, Wenxi
   Sun, Han
   Xu, Can
   Liu, Ningzhong
   Zhou, Huiyu
TI Discriminative feature mining hashing for fine-grained image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained image retrieval; Attention drop; Attention re-sample; Deep
   hashing
ID BINARY-CODES
AB With the development of multimedia technology, fine-grained image retrieval has gradually become a new hot topic in computer vision, while its accuracy and speed are limited due to the low discriminative high-dimensional real-valued embedding. To solve this problem, we propose an end-to-end framework named DFMH (Discriminative Feature Mining Hashing), which consists of the DFEM (Discriminative Feature Extracting Module) and SHCM (Semantic Hash Coding Module). Specifically, DFEM explores more discriminative local regions by attention drop and obtains finer local feature expression by attention re-sample. SHCM generates high-quality hash codes by combining the quantization loss and bit balance loss. Validated by extensive experiments and ablation studies, our method consistently outperforms both the state-of-the-art generic retrieval methods as well as fine-grained retrieval methods on three datasets, including CUB Birds, Stanford Dogs and Stanford Cars.
C1 [Lang, Wenxi; Sun, Han; Liu, Ningzhong] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Lang, Wenxi; Sun, Han; Liu, Ningzhong] MIIT Key Lab Pattern Anal & Machine Intelligence, Nanjing 211106, Peoples R China.
   [Xu, Can] Nanjing Univ Sci & Technol, Coll Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Zhou, Huiyu] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Science & Technology; University of Leicester
RP Sun, H (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM sunhan@nuaa.edu.cn
RI Li, Hang/ABA-3237-2021; Sun, Han/AGP-5382-2022; Zhou, Huiyu/O-2692-2014
OI Li, Hang/0000-0002-9179-3741; Sun, Han/0000-0002-2208-6672; Zhou,
   Huiyu/0000-0003-1634-9840; Xu, Can/0000-0001-5374-3818
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2009, NIPS
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   CAKIR F, 2018, P EUR C COMP VIS ECC, P332
   Cao G, 2021, P 2021 IEEE INT C MU, P1
   Cao Y, 2018, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2018.00134
   Cao Y, 2016, AAAI CONF ARTIF INTE, P3457
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Chen JX, 2017, PROC CVPR IEEE, P5330, DOI 10.1109/CVPR.2017.566
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   D'Innocente A, 2021, IEEE COMPUT SOC CONF, P3905, DOI 10.1109/CVPRW53098.2021.00435
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gu SM, 2013, INT CONF MACH LEARN, P108, DOI 10.1109/ICMLC.2013.6890453
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu T, 2019, Arxiv, DOI [arXiv:1901.09891, DOI 10.48550/ARXIV.1901.09891]
   Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342
   Jin S, 2020, IEEE T IMAGE PROCESS, V29, P5336, DOI 10.1109/TIP.2020.2971105
   Khosla A., 2013, Novel dataset for fine-grained image categorization
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lei Ma, 2021, 2021 6th International Conference on Communication, Image and Signal Processing (CCISP), P155, DOI 10.1109/CCISP52774.2021.9639255
   Li WJ, 2016, Arxiv, DOI arXiv:1511.03855
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Ma L, 2020, IEEE SIGNAL PROC LET, V27, P2129, DOI 10.1109/LSP.2020.3039755
   Ma L, 2021, NEUROCOMPUTING, V443, P85, DOI 10.1016/j.neucom.2021.02.057
   Ma L, 2020, NEUROCOMPUTING, V380, P115, DOI 10.1016/j.neucom.2019.11.009
   Ma L, 2018, NEUROCOMPUTING, V312, P49, DOI 10.1016/j.neucom.2018.05.052
   Ma L, 2017, IEEE T MULTIMEDIA, V19, P2545, DOI 10.1109/TMM.2017.2703089
   Ma L, 2017, J VIS COMMUN IMAGE R, V44, P29, DOI 10.1016/j.jvcir.2017.01.014
   Ma L, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Pang C, 2017, IEEE IMAGE PROC, P2896, DOI 10.1109/ICIP.2017.8296812
   Quan Cui, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P189, DOI 10.1007/978-3-030-58580-8_12
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Sun H, 2020, IEEE ACCESS, V8, P26199, DOI 10.1109/ACCESS.2020.2970223
   Talreja V, 2018, IEEE GLOB CONF SIG, P564, DOI 10.1109/GlobalSIP.2018.8646467
   Vedaldi A., 2013, Technical report
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wu ZZ, 2021, INFORM SCIENCES, V572, P404, DOI 10.1016/j.ins.2021.04.078
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Yang YF, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P114, DOI 10.1145/3323873.3325015
   Zeng ZY, 2024, Arxiv, DOI arXiv:2109.05206
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zheng XW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1226
   Zheng XW, 2019, AAAI CONF ARTIF INTE, P9291
   Zhong GQ, 2016, IEEE IJCNN, P2236, DOI 10.1109/IJCNN.2016.7727476
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
NR 59
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103592
DI 10.1016/j.jvcir.2022.103592
EA JUL 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4U2UR
UT WOS:000858655700004
DA 2024-07-18
ER

PT J
AU Li, DW
   Li, YM
   Sun, HM
   Yu, L
AF Li, Daowen
   Li, Yingming
   Sun, Heming
   Yu, Lu
TI Deep image compression based on multi-scale deformable convolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deepimagecompression; Multi-scaledeformableconvolution; Spatialattention
AB Deep image compression efficiency has been improved in the past years. However, to fully exploit context information for compressing image objects of different scales and shapes, more adaptive geometric structure of inputs should be considered. In this paper, we novelly introduce deformable convolution and its spatial attention extension into deep image compression task to fully exploit the context information. Specifically, a novel deep image compression network with Multi-Scale Deformable Convolution and Spatial Attention, named MS-DCSA, is proposed to better extract compact and efficient latent representation as well as reconstruct higher-quality images. First, multi-scale deformable convolution is presented to provide multi-scale receptive fields for learning spatial sampling offsets in deformable operations. Subsequently, multi-scale deformable spatial attention module is developed to generate attention masks to re-weight extracted features according to their importance. In addition, the multi-scale deformable convolution is applied to design delicate up/down sampling modules. Extensive experiments demonstrate that the proposed MS-DCSA network achieves improved performance on both PSNR and MS-SSIM quality metrics, compared to conventional as well as competing deep image compression methods.
C1 [Li, Daowen; Li, Yingming; Sun, Heming; Yu, Lu] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
   [Li, Daowen; Li, Yingming; Yu, Lu] Zhejiang Prov Key Lab Informat Proc Commun & Netwo, Hangzhou, Peoples R China.
   [Sun, Heming] Waseda Res Inst Sci & Engn, Tokyo, Japan.
   [Sun, Heming] JST, PRESTO, 4-1-8 Honcho, Kawaguchi, Saitama, Japan.
C3 Zhejiang University; Waseda University; Japan Science & Technology
   Agency (JST)
RP Yu, L (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
EM lidaowen@zju.edu.cn; yingming@zju.edu.cn; hemingsun@aoni.waseda.jp;
   yul@zju.edu.cn
RI Heming, Sun/G-6882-2018
OI , Daowen/0000-0001-7805-9967
FU National Natural Science Founda-tion of China [62071427, U21B2004]; Key
   Research and Development Program of Zhejiang Province, China
   [2021C01119]
FX Acknowledgment This work was supported by the National Natural Science
   Founda-tion of China under Grant 62071427 and U21B2004, and Key Research
   and Development Program of Zhejiang Province, China under Grant
   2021C01119.
CR [Anonymous], 1999, Kodak lossless true color image database
   [Anonymous], 2018, BPG IMAGE FORMAT
   [Anonymous], 2020, JPEG2000 OFFICIAL SO
   [Anonymous], 2014, HIGH EFFICIENCY VIDE
   [Anonymous], 2020, VTM REFERENCE SOFTWA
   Asuni N, 2014, P SMART TOOLS APPS G, P63, DOI DOI 10.2312/STAG.20141242
   Balle Johannes, 2018, INT C LEARNING REPRE
   Bjontegarrd G., 2001, SG16Q6VCEG ITUT
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Budagavi M., 2014, PROC INT C HIGH EFFI, P141
   Chen T, 2021, IEEE T IMAGE PROCESS, V30, P3179, DOI 10.1109/TIP.2021.3058615
   Cheng XH, 2020, AAAI CONF ARTIF INTE, V34, P10607
   Cheng Z., 2020, P IEEECVF C COMPUTER, P126
   Cheng Z., 2019, P IEEE CVF C COMP VI
   Cheng ZX, 2021, IEEE COMPUT SOC CONF, P1895, DOI 10.1109/CVPRW53098.2021.00213
   Clark Alex, 2015, Pillow (pil fork) documentation
   Cui Z., 2021, PROC IEEECVF C COMPU, P10532
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dumas T, 2020, IEEE T IMAGE PROCESS, V29, P679, DOI 10.1109/TIP.2019.2934565
   Fu C.-M., 2011, PROC IEEE 13 INT WOR, P1
   Fu J., 2021, 2021 IEEE INT S CIRC, P1
   Guo Z., 2020, ARXIV PREPRINT ARXIV
   Guo ZY, 2020, IEEE COMPUT SOC CONF, P520, DOI 10.1109/CVPRW50498.2020.00066
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YY, 2020, AAAI CONF ARTIF INTE, V34, P11013
   Huang HY, 2021, IEEE T CIRC SYST VID, V31, P2100, DOI 10.1109/TCSVT.2020.3018230
   Kingma D. P., 2014, arXiv
   Ladune T, 2020, INT CONF ACOUST SPEE, P2168, DOI [10.1109/ICASSP40776.2020.9053997, 10.1109/icassp40776.2020.9053997]
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee J., 2019, P 7 INT C LEARN REP
   Lee J., 2019, P IEEECVF C COMPUTER
   Li D., 2019, IEEE INT SYMP CIRC S, P1
   Li Mu, 2021, IEEE T NEUR NET LEAR
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Liu H., 2019, P IEEECVF C COMPUTER
   Liu H., 2018, P IEEE C COMP VIS PA
   Liu HTD, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322953
   Liu WX, 2019, IEEE T IMAGE PROCESS, V28, P3766, DOI 10.1109/TIP.2019.2902784
   Ma C., ARXIV PREPRINT ARXIV
   Ma Y, 2021, IEEE COMPUT SOC CONF, P1936, DOI 10.1109/CVPRW53098.2021.00221
   Mentzer F., 2020, PROC NEURIPS 20, V33
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Minnen D, 2020, IEEE IMAGE PROC, P3339, DOI [10.1109/icip40778.2020.9190935, 10.1109/ICIP40778.2020.9190935]
   Minnen D, 2018, ADV NEUR IN, V31
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Pate Y, 2021, IEEE WINT CONF APPL, P227, DOI 10.1109/WACV48630.2021.00027
   Rabbani Majid., 2002, J ELECTRON IMAGING, V11
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schiopu I, 2020, IEEE T CIRC SYST VID, V30, P1816, DOI 10.1109/TCSVT.2019.2940092
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Sun HM, 2020, IEEE I C VI COM I PR, P21, DOI 10.1109/vcip49819.2020.9301842
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Tsai CY, 2013, IEEE J-STSP, V7, P934, DOI 10.1109/JSTSP.2013.2271974
   van den Oord A, 2016, ADV NEUR IN, V29
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang X., 2019, P IEEECVF C COMPUTER
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZX, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103226
   Wen S., 2019, CVPR WORKSH
   Xu J., 2020, P IEEECVF C COMPUTER, P130
   Yang JY, 2020, IEEE COMPUT SOC CONF, P575, DOI 10.1109/CVPRW50498.2020.00078
   Yilmaz M.A., 2021, 2021 IEEE INT C IMAG, P3732
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P1500, DOI 10.1109/LSP.2020.3013518
   Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang SF, 2020, IEEE T CIRC SYST VID, V30, P1888, DOI 10.1109/TCSVT.2019.2938192
   Zhao CH, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3084203
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
   Zhong ZS, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P467
   Zhou L., 2019, P IEEECVF C COMPUTER
   Zhu LW, 2021, IEEE T CIRC SYST VID, V31, P3168, DOI 10.1109/TCSVT.2020.3035356
NR 73
TC 7
Z9 7
U1 5
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103573
DI 10.1016/j.jvcir.2022.103573
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3C7GN
UT WOS:000828788400003
DA 2024-07-18
ER

PT J
AU Chen, GP
   Gao, ZS
   Zhou, B
   Zuo, CL
AF Chen, Gongping
   Gao, Zhisheng
   Zhou, Bin
   Zuo, Chenglin
TI Optimization and regularization of complex task decomposition for blind
   removal of multi-factor degradation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Complex task; Decomposition regularization; Convolutional neural
   network; Atmospheric turbulence; Blind restoration
AB Most existing image restoration methods based on deep neural networks are developed for images which only degraded by a single degradation mode and imaging under an ideal condition. They cannot be directly used to restore the images degraded by multi-factor coupling. A complex task decomposition regularization optimization strategy (TDROS) is proposed to solve the problem. The restoration of images degraded by multi factor coupling is a complex task that can be solved by separating these multiple factors, that is, breaking the complex task into numbers of simpler tasks to make the entire complex problem be overcome more easily. Motivated by this idea, the TDROS decomposes the complex task of image restoration into two sub-task: the potential task constrained by regularization and the main task for reconstructing high-definition images. In TDROS, the front of the neural network is focused on the restoration of images degraded by additive noise, while the other part of the network is focused mainly on the restoration of images degraded by blur. We applied the TDROS to an 11-layer convolutional neural network (CNN) and compared it with initial CNNs from the aspects of restoration accuracy and generalization ability. Based on these results, we used TDROS to design a novel network model for the restoration of atmospheric turbulence-degraded images. The experimental results demonstrate that the proposed TDROS can improve the generalization ability of the existing network more effectively than current popular methods, offering a better solution for the problem of severely degraded image restoration. Moreover, the TDROS concept provides a flexible framework for low-level visual complex tasks and can be easily incorporated into existing CNNs.
C1 [Chen, Gongping; Gao, Zhisheng; Zhou, Bin] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
   [Zuo, Chenglin] China Aerodynam Res & Dev Ctr, Low Speed Aerodynam Inst, Mianyang 621000, Sichuan, Peoples R China.
C3 Xihua University
RP Gao, ZS (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.; Zuo, CL (corresponding author), China Aerodynam Res & Dev Ctr, Low Speed Aerodynam Inst, Mianyang 621000, Sichuan, Peoples R China.
EM gzs_xihua@mail.xhu.edu.cn; zuochenglin@cardc.cn
RI Gongping, Chen/GZH-2842-2022
OI Gongping, Chen/0000-0002-3031-5308
FU Key scientific re-search fund of Xihua University, China [Z17134];
   Sichuan science and technology program, China [2020YFG0188, 2021YFG0022]
FX Acknowledgments This work has been partially supported by the Key
   scientific re-search fund of Xihua University, China (Grant No: Z17134)
   , Sichuan science and technology program, China (Grant No: 2020YFG0188,
   2021YFG0022) .
CR Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, P192, DOI 10.1016/0885-064X(90)90006-Y
   Cortés-Osorio JA, 2019, IEEE T INSTRUM MEAS, V68, P4038, DOI 10.1109/TIM.2018.2882261
   Bai Y., 2019, IEEE T CIRC SYST VID
   Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704
   Cao L., 2014, CHIN OPT, V7, P68
   Carbillet M, 2013, EAS PUBLICATIONS, V59, P59, DOI 10.1051/eas/1359004
   Carreira-Perpiñán MA, 2014, JMLR WORKSH CONF PRO, V33, P10
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chang Y, 2020, IEEE T CYBERNETICS, V50, P4558, DOI 10.1109/TCYB.2020.2983102
   Chang-li W., 2014, ACTA OPT SIN, V34
   Cho S, 2017, IEEE I CONF COMP VIS, P4818, DOI 10.1109/ICCV.2017.515
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang XY, 2020, IEEE T CYBERNETICS, V50, P997, DOI 10.1109/TCYB.2018.2876511
   Gal R, 2014, PATTERN RECOGN LETT, V48, P8, DOI 10.1016/j.patrec.2014.04.007
   Gao ZS, 2018, NEUROCOMPUTING, V313, P295, DOI 10.1016/j.neucom.2018.06.009
   Guo J, 2017, PROC CVPR IEEE, P4867, DOI 10.1109/CVPR.2017.517
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3034967
   HRADI M, 2015, BRIT MACH VIS C
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Le L, 2018, ADV NEUR IN, V31
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Liu JP, 2020, IEEE T INSTRUM MEAS, V69, P9618, DOI 10.1109/TIM.2020.3006629
   Liu TL, 2017, IEEE T PATTERN ANAL, V39, P227, DOI 10.1109/TPAMI.2016.2544314
   Loshchilov Ilya, 2018, Decoupled Weight Decay Regularization
   Maheshwari M., 2016, Int. J. Comput. Sci. Commun. Netw., V6, P198
   Mao XJ, 2016, ADV NEUR IN, V29
   Maurer A., 2013, PMLR, P55
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Ng A.Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435
   Pan JS, 2018, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2018.00324
   Ranzato M., 2008, P 25 INT C MACH LEAR, P792, DOI DOI 10.1145/1390156.1390256
   Sajid M, 2015, 2015 SYMPOSIUM ON RECENT ADVANCES IN ELECTRICAL ENGINEERING (RAEE)
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Sha L., 2019, IEEE T CIRC SYST VID
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soni V, 2013, IET SIGNAL PROCESS, V7, P720, DOI 10.1049/iet-spr.2013.0139
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   [谭海鹏 Tan Haipeng], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P386
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wipf D, 2014, J MACH LEARN RES, V15, P3595
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yu K, 2018, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2018.00259
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang J, 2017, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2017.555
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713
   Zhu X., 2011, 2011 IEEE INT C COMP, P1
   Zhu X, 2013, IEEE T PATTERN ANAL, V35, P157, DOI 10.1109/TPAMI.2012.82
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 58
TC 2
Z9 2
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103384
DI 10.1016/j.jvcir.2021.103384
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z2GF
UT WOS:000790895000002
DA 2024-07-18
ER

PT J
AU Dias, W
   Andaló, F
   Padilha, R
   Bertocco, G
   Almeida, W
   Costa, P
   Rocha, A
AF Dias, William
   Andalo, Fernanda
   Padilha, Rafael
   Bertocco, Gabriel
   Almeida, Waldir
   Costa, Paula
   Rocha, Anderson
TI Cross-dataset emotion recognition from facial expressions through
   convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Emotion recognition; Facial analysis; Cross-dataset evaluation; Deep
   learning
ID INTENSITY ESTIMATION; 3D; DATABASE
AB The face is the window to the soul. This is what the 19th-century French doctor Duchenne de Boulogne thought. Using electric shocks to stimulate muscular contractions and induce bizarre-looking expressions, he wanted to understand how muscles produce facial expressions and reveal the most hidden human emotions. Two centuries later, this research field remains very active. We see automatic systems for recognizing emotion and facial expression being applied in medicine, security and surveillance systems, advertising and marketing, among others. However, there are still fundamental questions that scientists are trying to answer when analyzing a person's emotional state from their facial expressions. Is it possible to reliably infer someone's internal state based only on their facial muscles' movements? Is there a universal facial setting to express basic emotions such as anger, disgust, fear, happiness, sadness, and surprise? In this research, we seek to address some of these questions through convolutional neural networks. Unlike most studies in the prior art, we are particularly interested in examining whether characteristics learned from one group of people can be generalized to predict another's emotions successfully. In this sense, we adopt a cross-dataset evaluation protocol to assess the performance of the proposed methods. Our baseline is a custom-tailored model initially used in face recognition to categorize emotion. By applying data visualization techniques, we improve our baseline model, deriving two other methods. The first method aims to direct the network's attention to regions of the face considered important in the literature but ignored by the baseline model, using patches to hide random parts of the facial image so that the network can learn discriminative characteristics in different regions. The second method explores a loss function that generates data representations in high-dimensional spaces so that examples of the same emotion class are close and examples of different classes are distant. Finally, we investigate the complementarity between these two methods, proposing a late-fusion technique that combines their outputs through the multiplication of probabilities. We compare our results to an extensive list of works evaluated in the same adopted datasets. In all of them, when compared to works that followed an intra-dataset protocol, our methods present competitive numbers. Under a cross-dataset protocol, we achieve state-of-the-art results, outperforming even commercial off-the-shelf solutions from well-known tech companies.
C1 [Dias, William; Andalo, Fernanda; Padilha, Rafael; Bertocco, Gabriel; Almeida, Waldir; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, Recod Ai, Artificial Intelligence Lab, BR-13083852 Campinas, SP, Brazil.
   [Costa, Paula] Univ Estadual Campinas, Sch Elect Engn & Comp Engn, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas; Universidade Estadual de Campinas
RP Rocha, A (corresponding author), Univ Estadual Campinas, Inst Comp, Recod Ai, Artificial Intelligence Lab, BR-13083852 Campinas, SP, Brazil.
EM anderson.rocha@ic.unicamp.br
RI Rocha, Anderson/KHU-9621-2024; Padilha, Rafael Soares/AAG-7246-2020;
   Andaló, Fernanda/K-6663-2012; Costa, Paula/J-4072-2013
OI Padilha, Rafael Soares/0000-0003-1944-5475; Andaló,
   Fernanda/0000-0002-5243-0921; Costa, Paula/0000-0002-1534-5744; Almeida,
   Waldir/0000-0002-5848-5560
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Ahmed HA, 2016, INT J ADV COMPUT SC, V7, P101
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   [Anonymous], 2010, IEEE CVPR 10 WORKSHO
   [Anonymous], 2014, ARXIV14117923
   da Silva Neto H., 2018, WORKSH VIS COMP, P190
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dolan RJ, 2002, SCIENCE, V298, P1191, DOI 10.1126/science.1076358
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   EmotiW, 2020, EMOTION RECOGNITION
   FERA, 2017, FACIAL EXPRESSION RE
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Guo YY, 2022, IEEE T KNOWL DATA EN, V34, P3740, DOI 10.1109/TKDE.2020.3034613
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heaven D, 2020, NATURE, V578, P502, DOI 10.1038/d41586-020-00507-5
   Howard A. G., 2017, PREPRINT
   Hu HF, 2019, IEEE T IMAGE PROCESS, V28, P739, DOI 10.1109/TIP.2018.2860898
   Islam B, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCEMENT IN ELECTRICAL AND ELECTRONIC ENGINEERING (ICAEEE)
   Jiabei Zeng, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11217), P227, DOI 10.1007/978-3-030-01261-8_14
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kim S, 2020, PROC CVPR IEEE, P3235, DOI 10.1109/CVPR42600.2020.00330
   King DE, 2009, J MACH LEARN RES, V10, P1755
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Koujan MR, 2020, IEEE INT CONF AUTOMA, P16, DOI 10.1109/FG47880.2020.00048
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li HB, 2017, IEEE T MULTIMEDIA, V19, P2816, DOI 10.1109/TMM.2017.2713408
   Li SM, 2020, J MATER SCI, V55, P6551, DOI 10.1007/s10853-020-04464-2
   Liu XF, 2017, IEEE COMPUT SOC CONF, P522, DOI 10.1109/CVPRW.2017.79
   LoBue V., 2015, DATABRARY
   Lobue V, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01532
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Lv Yanpeng., 2011, Proceedings of the Third International Conference on Internet Multimedia Computing and Service - ICIMCS'11, page, P170, DOI DOI 10.1145/2043674.2043723
   Magyar Jan, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P109, DOI 10.1109/DISA.2018.8490628
   Mavani V, 2017, IEEE INT CONF COMP V, P2783, DOI 10.1109/ICCVW.2017.327
   da Silva FAM, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023015
   Nagpal S, 2019, IEEE COMPUT SOC CONF, P236, DOI 10.1109/CVPRW.2019.00033
   Padilha R, 2020, INT CONF ACOUST SPEE, P2972, DOI [10.1109/ICASSP40776.2020.9054120, 10.1109/icassp40776.2020.9054120]
   Parkhi O.M., 2015, BRIT MACHINE VISION
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Rhue L., 2018, SSRN ELECT J
   Ruiz-Garcia A, 2017, IEEE IJCNN, P1586, DOI 10.1109/IJCNN.2017.7966040
   Ruiz-Garcia A, 2016, LECT NOTES COMPUT SC, V9887, P38, DOI 10.1007/978-3-319-44781-0_5
   Sadeghi H, 2019, J VIS COMMUN IMAGE R, V62, P152, DOI 10.1016/j.jvcir.2019.05.004
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shin M, 2016, IEEE ROMAN, P724, DOI 10.1109/ROMAN.2016.7745199
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Sun WY, 2017, NEUROCOMPUTING, V267, P385, DOI 10.1016/j.neucom.2017.06.050
   TAHA B, 2019, P IEEE CAN C EL COMP, P1
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   TechCrunch, 2016, SMIL FAC FAC ACQ EM
   TechCrunch, 2016, APPL DIV DEEP ART IN
   Tong Y, 2007, PATTERN RECOGN, V40, P3195, DOI 10.1016/j.patcog.2007.02.021
   Wan SH, 2014, PATTERN RECOGN, V47, P1859, DOI 10.1016/j.patcog.2013.11.025
   Wang SF, 2013, IEEE T AFFECT COMPUT, V4, P34, DOI 10.1109/T-AFFC.2012.32
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Witherow MeganA., 2019, Applications of Machine Learning, V11139, P275
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wong K, 2009, SCI AM, V301, P94
   Yaddaden Y, 2018, EXPERT SYST APPL, V112, P173, DOI 10.1016/j.eswa.2018.06.033
   Yan HB, 2018, PATTERN RECOGN, V75, P33, DOI 10.1016/j.patcog.2017.02.031
   Yosinski J, 2014, ADV NEUR IN, V27
   Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang Y, 2015, EXPERT SYST APPL, V42, P1446, DOI 10.1016/j.eswa.2014.08.042
   Zheng Z., 2019, Human-computer interaction. Recognition and interaction technologies, P201
   Zhou YQ, 2017, IEEE IJCNN, P2031
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 77
TC 11
Z9 11
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103395
DI 10.1016/j.jvcir.2021.103395
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400005
DA 2024-07-18
ER

PT J
AU Li, ZZ
   Yang, XY
   Shen, KQ
   Jiang, FZ
   Jiang, J
   Ren, HW
   Li, YX
AF Li, Zhengze
   Yang, Xiaoyuan
   Shen, Kangqing
   Jiang, Fazhen
   Jiang, Jin
   Ren, Huwei
   Li, Yixiao
TI PSGU: Parametric self-circulation gating unit for deep neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Neural network; Activation function; PSGU; Initialization
AB Activation functions are of great importance for the performance and training of deep neural networks. Highperformance activation function is expected to effectively prevent the gradient from vanishing and help network converge. This paper provides a novel smooth activation function, called Parameterized Self-circulating Gating Unit (PSGU), aiming to train an adaptive activation function to improve the performance of deep networks. Compared with other works, we propose and study the self-circulation gating property of activation function, and analyze its influence on the signal transmission in network by controlling the flow of information. Specifically, we theoretically analyze and propose the initialization based on PSGU, which adequately explores the properties in neighborhood of the origin. Finally, the proposed activation function and initialization are compared with other methods on commonly-used network architectures, the achieved performances of using PSGU alone or combining with our proposed initialization are over par with the state of the art.
C1 [Li, Zhengze; Yang, Xiaoyuan; Shen, Kangqing; Jiang, Fazhen; Jiang, Jin; Ren, Huwei; Li, Yixiao] Beihang Univ, Sch Math Sci, Beijing, Peoples R China.
C3 Beihang University
RP Yang, XY (corresponding author), Beihang Univ, Sch Math Sci, Beijing, Peoples R China.
EM lizz0317@163.com; xiaoyuanyang@vip.163.com; shenkqtx@163.com;
   fazhenjiang@163.com; jiangjin1246@163.com; 13031016060@163.com;
   18335310648@163.com
RI lu, kai/KBB-4008-2024
FU National Natural Science Foundation of China [61671002]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61671002.
CR [Anonymous], 1997, NEURAL COMPUT
   Apicella A, 2021, NEURAL NETWORKS, V138, P14, DOI 10.1016/j.neunet.2021.01.026
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D., 2020, ARXIV PREPRINT ARXIV
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S., 2017, P 31 INT C NEUR INF, P1942
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Y, 2018, NEUROCOMPUTING, V301, P11, DOI 10.1016/j.neucom.2018.01.084
   Lin M., 2014, P 2014 INT C LEARN R
   Maas Andrew L, 2013, P INT C MACH LEARN A, V30, P3
   Maguolo G, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114048
   Mercioni MA, 2020, INT SYMP ELEC TELECO, P32, DOI 10.1109/isetc50328.2020.9301084
   Misra D., 2019, ARXIV190808681
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Netzer Y., 2011, ADV NEURAL INF PROCE, P1
   Ramachandran P., 2018, ICLR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tavakoli M, 2021, NEURAL NETWORKS, V140, P1, DOI 10.1016/j.neunet.2021.02.023
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Varshney M, 2021, SIGNAL IMAGE VIDEO P, V15, P1323, DOI 10.1007/s11760-021-01863-z
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu YB, 2020, IEEE ACCESS, V8, P72727, DOI 10.1109/ACCESS.2020.2987829
   Zheng BY, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P125, DOI 10.1109/ICCCS49078.2020.9118471
NR 37
TC 0
Z9 0
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103294
DI 10.1016/j.jvcir.2021.103294
EA AUG 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600006
DA 2024-07-18
ER

PT J
AU Tan, X
   Li, ZW
   Liang, QK
   Sun, W
   Wang, YN
   Zhang, D
AF Tan, Xu
   Li, Zhengwei
   Liang, Qiaokang
   Sun, Wei
   Wang, Yaonan
   Zhang, Dan
TI Sequence-tracker: Multiple object tracking with sequence features in
   severe occlusion scene
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Sequence features; Severe occlusion scene;
   Sequence-tracker
AB Multiple object tracking is one of the most fundamental tasks in computer vision, and it is still very challenging for real-world applications due to its severe occlusion and motion blur. Most of the existing methods solve these multiple object tracking issues by performing data association based on the deep features of the detections in consecutive frames, which only contain the spatial information of the detected objects. Therefore, the inaccuracy of data association would easily occur, especially in the severe occlusion scenes. In this paper, a novel multiple object tracking model named sequence-tracker (STracker) has been proposed, which combines both the temporal and spatial features to perform data association. We trained a sequence feature extraction network based on video pedestrian re-identification offline, fused the obtained sequence features with the depth features of the previous frame, and then implemented the Hungarian algorithm for data association. Experiments have been carried out to validate the effectiveness of the proposed algorithm and the corresponding results indicates that it can significantly improve the trajectory quality of our dataset in this paper. Remarkably, for the public detector results from MOT official website, the proposed algorithm can achieve up to 57.2% MOTA and 50.9% IDF1 on the MOT17 dataset.
C1 [Tan, Xu; Liang, Qiaokang; Sun, Wei; Wang, Yaonan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
   [Tan, Xu; Liang, Qiaokang; Sun, Wei; Wang, Yaonan] Natl Engn Lab Robot Vis Percept & Control, Changsha 410082, Peoples R China.
   [Li, Zhengwei] Univ Alberta, Dept Mech Engn, Edmonton, AB T6G 2E1, Canada.
   [Zhang, Dan] York Univ, Dept Mech Engn, Toronto, ON M3J 1P3, Canada.
C3 Hunan University; University of Alberta; York University - Canada
RP Liang, QK (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.; Liang, QK (corresponding author), Natl Engn Lab Robot Vis Percept & Control, Changsha 410082, Peoples R China.
EM qiaokang@hnu.edu.cn
RI Liang, Qiaokang/D-5406-2012; Zhang, Dan/AFA-2608-2022
OI Zhang, Dan/0000-0002-7295-4837; Liang, qiaokang/0000-0002-5504-9966
FU National Natural Science Foundation of China [NSFC 62073129]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC 62073129) .
CR Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884
   Bochkovskiy A., 2020, PREPRINT
   Chen LJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS), P1, DOI [10.1109/ICSRS.2018.8688869, 10.1109/ICSRS.2018.00009]
   Chen L, 2019, IEEE SIGNAL PROC LET, V26, P1613, DOI 10.1109/LSP.2019.2940922
   Chen L, 2017, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2017.8296360
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Fleuret, 2016, ARXIV161200604
   Guo S., 2021, ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Lan L, 2018, IEEE T IMAGE PROCESS, V27, P4585, DOI 10.1109/TIP.2018.2843129
   Leal-Taix L., 2015, MOTCHALLENGE 2015 BE
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CH, 2020, IEEE T CYBERNETICS, V50, P1726, DOI 10.1109/TCYB.2018.2884007
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Ma LQ, 2019, LECT NOTES COMPUT SC, V11362, P612, DOI 10.1007/978-3-030-20890-5_39
   Matsukawa T, 2014, INT C PATT RECOG, P3975, DOI 10.1109/ICPR.2014.681
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Song GL, 2018, AAAI CONF ARTIF INTE, P7347
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang JH, 2018, IEEE SIGNAL PROC LET, V25, P1725, DOI 10.1109/LSP.2018.2872403
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wang Z, 2019, EUROPEAN C COMPUTER
   Wei B, 2018, COMPUT ENG APPL, V2018, P14
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xiang J., 2018, ARXIV PREPRINT ARXIV
   Xinqian Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P228, DOI 10.1007/978-3-030-58536-5_14
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
NR 39
TC 1
Z9 1
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103250
DI 10.1016/j.jvcir.2021.103250
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800011
DA 2024-07-18
ER

PT J
AU Bahrami, M
   Pourahmadi, M
   Vafaei, A
   Shayesteh, MR
AF Bahrami, Maedeh
   Pourahmadi, Majid
   Vafaei, Abbas
   Shayesteh, Mohammad Reza
TI A comparative study between single and multi-frame anomaly detection and
   localization in recorded video streams
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomaly detection; Deep learning; Convolutional autoencoder; Image
   reconstruction
ID SURVEILLANCE; BEHAVIOR
AB Video anomaly detection is usually studied by considering the spatial and temporal contexts. This paper focuses first on spatial context and shows that it can be a fast real-time solution. In the first part of this work there are two main contributions: employing a new deep network for reconstruction and introducing a new regularity scoring function. The new deep architecture is based on pyramid of input images and compared to UNet, the proposed architecture boosts AUC by 15% and the new regularity scoring function is based on SSIM. The second part employs a multiframe approach to distinguish temporal behavior anomalies. The second approach enhances the results by 7% compared to spatial anomaly detection. Comparing the two approaches, if computing power is limited and real time anomaly detection is looked for, single frame detection is preferred while multi frame analysis offers a much wider possibility of anomaly detection.
C1 [Bahrami, Maedeh; Pourahmadi, Majid; Shayesteh, Mohammad Reza] Islamic Azad Univ, Yazd Branch, Dept Elect Engn, Yazd 8915813135, Iran.
   [Vafaei, Abbas] Isfahan Univ, Fac Comp Engn, Esfahan 8174673441, Iran.
C3 Islamic Azad University; University of Isfahan
RP Pourahmadi, M (corresponding author), Islamic Azad Univ, Yazd Branch, Dept Elect Engn, Yazd 8915813135, Iran.
EM pourahmadi@iauyazd.ac.ir
RI Shayesteh, Mohammad Reza/AAO-6891-2021
OI Bahrami, Maedeh/0000-0003-3959-6190
CR Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Almasi R, 2020, BIOMED OPT EXPRESS, V11, P3455, DOI 10.1364/BOE.395784
   Amraee S, 2018, MULTIMED TOOLS APPL, V77, P14767, DOI 10.1007/s11042-017-5061-7
   [Anonymous], 1980, IDENTIFICATION OUTLI
   Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Doshi K., 2020, P IEEE CVF C COMP VI, P254
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Gunale KG, 2018, J IMAGING, V4, DOI 10.3390/jimaging4060079
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Horikawa T, 2019, SCI DATA, V6, DOI 10.1038/sdata.2019.12
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pang Guansong, 2020, IEEE C COMP VIS PATT
   Piza EL, 2019, CRIMINOL PUBLIC POL, V18, P135, DOI 10.1111/1745-9133.12419
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2017, MACH VISION APPL, V28, P965, DOI 10.1007/s00138-017-0869-8
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wang H., 2017, On the Origin of Deep Learning
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu CY, 2020, PROC CVPR IEEE, P150, DOI 10.1109/CVPR42600.2020.00023
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu D., 2015, arXiv preprint arXiv:1510.01553
   Xu M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163337
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
   Zhu HH, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2018), P49, DOI 10.1145/3301506.3301510
NR 48
TC 3
Z9 3
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103232
DI 10.1016/j.jvcir.2021.103232
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800006
DA 2024-07-18
ER

PT J
AU Wang, X
   Chang, CC
   Lin, CC
   Chang, CC
AF Wang, Xu
   Chang, Ching-Chun
   Lin, Chia-Chen
   Chang, Chin-Chen
TI Privacy-preserving reversible data hiding based on quad-tree block
   encoding and integer wavelet transform*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Encrypted images; Quad-tree partition; IWT
ID ENCRYPTED IMAGES; SCHEME
AB Applications on the cloud server have matured, and protecting the privacy of the content owner has attracted more attention. Privacy-Preserving Reversible data hiding (PP-RDH) is an efficient technique for embedding additional data into an encrypted image. In this paper, we propose a privacy-preserving reversible data hiding scheme using the quad-tree partition and Integer Wavelet Transform (IWT) techniques. Our scheme focuses on improving the embedding rate and quality of the recovered image when a 2 x 2-sized, block-based image encryption method is applied to ensure relative higher security. On this basis, the IWT technique transforms the encrypted image, and coefficients in three high frequency subbands are converted into 8-bit binary system. Then, the quad-tree partition technique encodes each 8 x 8-sized coefficient block, since there are many zeroes in the front bit planes. The experimental results indicated that our proposed scheme significantly improved the embedding rate, and guaranteed lossless image recovery and data extraction.
C1 [Wang, Xu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Ching-Chun] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
C3 Feng Chia University; University of Warwick; National Chin-Yi University
   of Technology; Providence University - Taiwan
RP Chang, CC (corresponding author), Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
EM xu.wang.phd@gmail.com; c.c.chang@warwickgrad.net;
   ally.cclin@ncut.edu.tw; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; 王, 旭/JAX-6722-2023; Chang,
   Ching-Chun/AGG-3857-2022; 王, 旭/GPX-0697-2022
OI Lin, Chia-Chen/0000-0003-4480-7351
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., Image database of BOWS-2.
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   MARKAS T, 1992, INFORM PROCESS MANAG, V28, P707, DOI 10.1016/0306-4573(92)90063-6
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Shiu PF, 2019, SIGNAL PROCESS-IMAGE, V74, P64, DOI 10.1016/j.image.2019.01.003
   SPANN M, 1985, PATTERN RECOGN, V18, P257, DOI 10.1016/0031-3203(85)90051-2
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2021, INFORM SCIENCES, V567, P375, DOI 10.1016/j.ins.2021.02.079
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang W, 2019, J REAL-TIME IMAGE PR, V16, P697, DOI 10.1007/s11554-018-0811-y
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 44
TC 11
Z9 11
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103203
DI 10.1016/j.jvcir.2021.103203
EA JUL 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100009
DA 2024-07-18
ER

PT J
AU Dharanya, V
   Raj, ANJ
   Gopi, VP
AF Dharanya, V.
   Raj, Alex Noel Joseph
   Gopi, Varun P.
TI Facial Expression Recognition through person-wise regeneration of
   expressions using Auxiliary Classifier Generative Adversarial Network
   (AC-GAN) based model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial Expression Recognition (FER); Subject dependence; Conditional
   GAN(CGAN); Auxiliary Classifier GAN(ACGAN); U-Net; Capsule
   Network(capsuleNet)
AB Recently, Facial Expression Recognition (FER) has gained much attention in the research area for its various applications. In the facial expression recognition task, subject-dependent issue is predominant when a smallscale database is used for training the system. The proposed Auxiliary Classifier Generative Adversarial Network (AC-GAN) based model regenerates ten expressions (angry, contempt, disgust, embarrassment, fear, joy, neutral, pride, sad, surprise) from input face image and recognizes its expression. To alleviate the subject dependence issue, we train the model person-wise and generate all the above expressions for a person and allow the discriminator to classify the expressions. The generator of our model uses U-Net Architecture, and the discriminator uses Capsule Networks for improved feature extraction. The model has been evaluated on the ADFES-BIV dataset yielding an overall classification accuracy of 93.4%. We also compared our model with the existing methods by evaluating our model on commonly used datasets like CK+, KDEF.
C1 [Dharanya, V.; Gopi, Varun P.] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli, Tamil Nadu, India.
   [Raj, Alex Noel Joseph] Shantou Univ, Coll Engn, Dept Elect Engn, Key Lab Digital Signal & Image Proc Guangdong Pro, Shantou, Peoples R China.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Shantou University
RP Raj, ANJ (corresponding author), Shantou Univ, Coll Engn, Dept Elect Engn, Key Lab Digital Signal & Image Proc Guangdong Pro, Shantou, Peoples R China.
EM jalexnoel@stu.edu.cn
RI P Gopi, Varun/S-3943-2019
OI P Gopi, Varun/0000-0001-5593-3949; Joseph Raj, Alex
   Noel/0000-0003-1505-3159
FU Scientific Research Grant of Shantou University, China [NTF17016]
FX This research was financially supported by the Scientific Research Grant
   of Shantou University, China, Grant No: NTF17016.
CR Alhussein M, 2016, CLUSTER COMPUT, V19, P99, DOI 10.1007/s10586-016-0535-3
   [Anonymous], 1998, KAROLINSKA DIRECTED
   [Anonymous], CORR
   [Anonymous], 2021, AIIDE
   Baddar W.J., 2018, ARXIV181106937
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fan XJ, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102659
   Fengchun Q., 2018, CORR
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hong Y., 2017, CORR
   Hsu SC, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P1, DOI [10.1109/PLASMA.2017.8496316, 10.1109/IRC.2017.12]
   Islam B., 2018, HIGH PERFORMANCE FAC
   Li HB, 2017, IEEE T MULTIMEDIA, V19, P2816, DOI 10.1109/TMM.2017.2713408
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu YY, 2018, IEEE INT CONF AUTOMA, P458, DOI 10.1109/FG.2018.00074
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mehrabian A., 2017, Communication theory, P193
   Melinte DO, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082393
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Ngo QT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092639
   Sabour S, 2017, ADV NEUR IN, V30
   Samadiani N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081863
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Ul Haq I, 2019, COMPLEXITY, DOI 10.1155/2019/3581419
   Wingenbach TSH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147112
   Yan K., 2010, TOTAL VARIATION MODE, DOI [10.1109/CISP.2010.5647075, DOI 10.1109/CISP.2010.5647075]
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yang HY, 2018, IEEE INT CONF AUTOMA, P294, DOI 10.1109/FG.2018.00050
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
NR 31
TC 20
Z9 23
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103110
DI 10.1016/j.jvcir.2021.103110
EA APR 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700010
DA 2024-07-18
ER

PT J
AU Li, CY
   Li, G
AF Li, Chunyu
   Li, Gang
TI Learning multiple instance deep representation for objects tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Convolutional networks; Multiple Instance Learning
ID VISUAL TRACKING
AB Object tracking has been widely used in various intelligent systems, such as pedestrian tracking, autonomous vehicles. To solve the problem that appearance changes and occlusion may lead to poor tracking performance, we propose a multiple instance learning (MIL) based method for object tracking. To achieve this task, we first manually label the first several frames of video stream in image level, which can indicate that whether a target object in the video stream. Then, we leverage a pre-trained convolutional neural network that has rich prior information to extract deep representation of target object. Since the location of the same object in adjacent frames is similar, we introduce a particle filter to predict the location of target object within a specific region. Comprehensive experiments have shown the effectiveness of our proposed method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Chunyu; Li, Gang] Anyang Inst Technol, Coll Comp Sci & Engn, Anyang 455000, Henan, Peoples R China.
C3 Anyang Institute of Technology
RP Li, CY (corresponding author), Anyang Inst Technol, Coll Comp Sci & Engn, Anyang 455000, Henan, Peoples R China.
EM chunyuli_ayit@outlook.com
RI L, Chun/HKW-1738-2023
CR Anderson C.H., 1985, CHANGE DETECTION TRA
   [Anonymous], PETS04 SURVEILLANCE
   [Anonymous], 2017, P IEEE C COMPUTER VI
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Chauhan A.K., 2013, International Journal of Advanced Research in Computer Science and Software Engineering, V3
   Dang T, 2002, IEEE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P112, DOI 10.1109/ITSC.2002.1041198
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Hess R, 2009, PROC CVPR IEEE, P240, DOI 10.1109/CVPRW.2009.5206801
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Nguyen KD, 2019, J VIS COMMUN IMAGE R, V60, P206, DOI 10.1016/j.jvcir.2019.02.020
   Kim Z., 2008, CVPR, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CC, 2022, IEEE T AFFECT COMPUT, V13, P729, DOI 10.1109/TAFFC.2019.2954394
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Maron O, 1998, ADV NEUR IN, V10, P570
   Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wildes R.P., 1994, SYSTEM AUTOMATED IRI
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
NR 30
TC 4
Z9 4
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102737
DI 10.1016/j.jvcir.2019.102737
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900027
DA 2024-07-18
ER

PT J
AU Verma, P
   Srivastava, R
AF Verma, Pratishtha
   Srivastava, Rajeev
TI Three stage deep network for 3D human pose reconstruction by exploiting
   spatial and temporal data via its 2D pose
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human Pose Estimation (HPE); Human Pose Reconstruction (HPR); Frame
   Specific Pose Estimation (FSPE); Multi-Stage Cascaded Feature Connection
   (MSCFC); Feature Residual Connection (FRC)
AB 3D Human Pose Reconstruction (HPR) is a challenging task due to less availability of 3D ground truth data and projection ambiguity. To address these limitations, we propose a three-stage deep network having the workflow of 2D Human Pose Estimation (HPE) followed by 3D HPR; which utilizes the proposed Frame Specific Pose Estimation (FSPE), Multi-Stage Cascaded Feature Connection (MSCFC) and Feature Residual Connection (FRC) Sub-level Strategies. In the first stage, the FSPE concept with the MSCFC strategy has been used for 2D HPE. In the second stage, the basic deep learning concepts like convolution, batch normalization, ReLU, and dropout have been utilized with the FRC Strategy for spatial 3D reconstruction. In the last stage, LSTM deep architecture has been used for temporal refinement. The effectiveness of the technique has been demonstrated on MPII, Human3.6M, and HumanEva-I datasets. From the experiments, it has been observed that the proposed method gives competitive results to the recent state-of-the-art techniques.
C1 [Verma, Pratishtha; Srivastava, Rajeev] Indian Inst Technol BHU, Comp Sci & Engn Dept, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Verma, P (corresponding author), Indian Inst Technol BHU, Comp Sci & Engn Dept, Varanasi 221005, Uttar Pradesh, India.
EM pratishthaver.rs.cse17@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556; Verma,
   Pratishtha/0000-0003-1571-392X
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agarwal A, 2004, PROC CVPR IEEE, P882
   [Anonymous], 2016, BMVC
   Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64
   Bo LF, 2008, PROC CVPR IEEE, P1833
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Chen XP, 2019, PROC CVPR IEEE, P10887, DOI 10.1109/CVPR.2019.01115
   Chen Yun-Chun., 2019, IEEE Transactions on Pattern Analysis and Machine Intelligence in press
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Fan B, 2019, IEEE T IMAGE PROCESS, V28, P4774, DOI 10.1109/TIP.2019.2909640
   Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44
   Habibie I, 2019, PROC CVPR IEEE, P10897, DOI 10.1109/CVPR.2019.01116
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500
   Katircioglu I, 2018, INT J COMPUT VISION, V126, P1326, DOI 10.1007/s11263-018-1066-6
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Lin MD, 2017, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2017.588
   Liu D, 2019, IEEE WINT CONF APPL, P1004, DOI 10.1109/WACV.2019.00112
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Perez-Sala X, 2017, INT J COMPUT VISION, V121, P327, DOI 10.1007/s11263-016-0938-x
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tekin B., 2015, ARXIV150408200, V2, P6
   Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Wang J, 2019, IEEE I CONF COMP VIS, P7770, DOI 10.1109/ICCV.2019.00786
   Wang KZ, 2020, IEEE T PATTERN ANAL, V42, P1069, DOI 10.1109/TPAMI.2019.2892452
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Zhang X., 2019, PATTERN RECOGNIT LET
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
NR 45
TC 3
Z9 3
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102866
DI 10.1016/j.jvcir.2020.102866
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000006
DA 2024-07-18
ER

PT J
AU Xiong, LJ
   Zhang, DL
   Zhang, Y
AF Xiong, Leijin
   Zhang, Dingli
   Zhang, Yu
TI Water leakage image recognition of shield tunnel via learning deep
   feature representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shield tunnel; Water leakage; Deep learning; Image recognition
ID OBJECT DETECTION; CONSTRUCTION
AB With the development of urban metro, the research on structural diseases of shield tunnels has been becoming a hot research topic, especially the leakage water diseases. Deep learning-based algorithms have shown impressive performance in image processing domain, such as image classification, image recognition or image retrieval. In this paper, we propose a novel image recognition algorithm for water leakage diseases of shield tunnels based on deep learning algorithm. Water leakage images are classified into six categories, each of which are extracted deep representation for image recognition. We compare our method with Otsu algorithm (OA), Region Growing Algorithm (RGA), and Watershed Algorithm (WA) to show the effectiveness of our proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xiong, Leijin; Zhang, Dingli; Zhang, Yu] Beijing Jiaotong Univ, Key Lab Urban Underground Engn, Minist Educ, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Zhang, DL (corresponding author), Beijing Jiaotong Univ, Key Lab Urban Underground Engn, Minist Educ, Beijing 100044, Peoples R China.
EM 12115286@bjtu.edu.cn; dlzhang@bjtu.edu.cn; 16115279@bjtu.edu.cn
RI ZHOU, yf/IAO-5497-2023
FU National Key R&D Program of China [2017YFC0805401]
FX The authors gratefully acknowledge the financial support by the National
   Key R&D Program of China under Grant 2017YFC0805401.
CR [Anonymous], 2017, J VIS COMMUN IMAGE R
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Du SM, 2016, IEEE AUTOTESTCON
   Fang Q, 2015, TUNN UNDERGR SP TECH, V45, P128, DOI 10.1016/j.tust.2014.10.001
   Fang Q, 2012, TUNN UNDERGR SP TECH, V29, P10, DOI 10.1016/j.tust.2011.12.007
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Li X., 2010, LEAK DETECTION MUNIC
   Makantasis K, 2015, INT C INTELL COMP CO, P335, DOI 10.1109/ICCP.2015.7312681
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Protopapadakis E., 2015, INT S VIS COMP
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Terao Y, 2008, PROC SPIE, V6932, DOI 10.1117/12.775968
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   XU ML, 2016, ACM T GRAPHIC, V35, P6, DOI DOI 10.1145/2980179.2982425
   Yin X., 2016, MECH ENG CONTROL SYS
   Zhang XY, 2016, IEEE CONF COMPUT
   Zhang Y, 2020, TUNN UNDERGR SP TECH, V96, DOI 10.1016/j.tust.2019.103182
NR 24
TC 22
Z9 25
U1 24
U2 151
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102708
DI 10.1016/j.jvcir.2019.102708
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900016
DA 2024-07-18
ER

PT J
AU Razzaghi, P
   Abbasi, K
   Bayat, P
AF Razzaghi, Parvin
   Abbasi, Karim
   Bayat, Pegah
TI Learning spatial hierarchies of high-level features in deep neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Perceptual grouping; Modified Guided Co-occurrence Block (mGCoB);
   Map-wise Fully Connected Block (MFC); Spatial hierarchies of high-level
   features
AB This paper addresses a new approach to learn perceptual grouping of the extracted features of the convolutional neural network (CNN) to represent the structure contained in the image. In CNN, the spatial hierarchies between the high-level features are not taken into account. To do so, the perceptual grouping of features is utilized. To consider the intra-relationship between feature maps, modified Guided Co-occurrence Block (mGCoB) is proposed. This block preserves the joint co-occurrence of two features in the spatial domain and it prevents the co-adaptation. Also, to preserve the interrelationship in each feature map, the principle of common region grouping is utilized which states that the features which are located in the same feature map tend to be grouped together. To consider it, an MFC block is proposed. To evaluate the proposed approach, it is applied to some known semantic segmentation and image classification datasets that achieve superior performance. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Razzaghi, Parvin; Bayat, Pegah] Inst Adv Studies Basic Sci IASBS, Dept Comp Sci & Informat Technol, Artificial Intelligence Lab, Zanjan, Iran.
   [Razzaghi, Parvin] Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
   [Abbasi, Karim] Univ Tehran, Inst Biochem & Biophys, Lab Syst Biol & Bioinformat LBB, Tehran, Iran.
C3 Institute for Advanced Studies in Basic Sciences (IASBS); University of
   Tehran
RP Razzaghi, P (corresponding author), Inst Adv Studies Basic Sci IASBS, Dept Comp Sci & Informat Technol, Artificial Intelligence Lab, Zanjan, Iran.
EM p.razzaghi@iasbs.ac.ir
RI Razzaghi, Parvin/AAE-2348-2022; Abbasi, Karim/AAE-1063-2022
OI Razzaghi, Parvin/0000-0002-7031-4609; Abbasi, Karim/0000-0003-2135-8864
FU Institute for Research in Fundamental Sciences (IPM)
FX Parvin Razzaghi has received research grants from the Institute for
   Research in Fundamental Sciences (IPM). Pegah Bayat and Karim Abbasi
   declare no conflict of interest.
CR Aliniya P, 2018, PATTERN RECOGN, V84, P165, DOI 10.1016/j.patcog.2018.07.013
   [Anonymous], 2015, PROC CVPR IEEE
   Brooks Joseph L, 2015, Traditional and New Principles of Perceptual Grouping
   Chatfield K., ARXIV14053
   Dai J., 2017, CORR, V1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2014, PR MACH LEARN RES, V32
   Felzenszwalb P. F., 2009, PAMI, V32, P1627, DOI [DOI 10.1109/TPAMI.2009.167, 10.1109/TPAMI.2009.167]
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Goodfellow IJ, 2013, ARXIV13024389
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G. E., 2012, 12070580 ARXIV
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jevnisek RJ, 2017, PROC CVPR IEEE, P3816, DOI 10.1109/CVPR.2017.406
   Jin XX, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901353
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson Gustav, 2016, ARXIV160507648
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu W., 2015, ARXIV150604579
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mottaghi R, 2012, PROC CVPR IEEE, P3116, DOI 10.1109/CVPR.2012.6248044
   Palmer SE, 2007, PERCEPT PSYCHOPHYS, V69, P68, DOI 10.3758/BF03194454
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Sabour Sara, 2017, Advances in Neural Information Processing Systems, P3856
   Sharma A., 2014, NIPS
   Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377, DOI DOI 10.48550/ARXIV.1505.00387
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
NR 39
TC 8
Z9 8
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102817
DI 10.1016/j.jvcir.2020.102817
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900022
DA 2024-07-18
ER

PT J
AU Lyu, WJ
   Lu, W
   Ma, M
AF Lyu, Wenjing
   Lu, Wei
   Ma, Ming
TI No-reference quality metric for contrast-distorted image based on
   gradient domain and HSV space
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image forensics; No-reference image quality assessment; Contrast
   distortion; Gradient domain; HSV color space
ID NATURAL SCENE
AB Image quality assessment (IQA) plays an important role in digital image forensics. Due to the occurrence of contrast distortion during image acquisition and manipulation, IQA for contrast is a major issue. And it is vital for benchmarking and optimizing the image tampering detection and contrast-enhancement algorithms. In this paper, a new no-reference/blind image quality assessment (IQA) metric is proposed for evaluating image contrast. This research seeks for the inter-relationship between contrast distortion and visual perception quality. The comprehensive quality metric is obtained by combining local binary pattern (LBP) descriptor on gradient domain with color moment on HSV color space. And a prediction model is trained with support vector regression (SVR). Extensive analysis and cross validation are performed on four contrast relevant image databases, which validates the superiority of our proposed blind technique over state-of-the-art no-reference IQA methods. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Lyu, Wenjing; Lu, Wei; Ma, Ming] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Peoples R China.
EM lvwj@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   maming3@mail2.sysu.edu.cn
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; Key Areas R&D
   Program of Guangdong [2019B010136002]; Key Scientific Research Program
   of Guangzhou [201804020068]; Natural Science Foundation of Guangdong
   [2016A030313350]; Special Funds for Science and Technology Development
   of Guangdong [2016KZ010103]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Key Areas R&D Program of Guangdong (No.
   2019B010136002), the Key Scientific Research Program of Guangzhou (No.
   201804020068), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103).
CR [Anonymous], 2020, SIGNAL PROCESS
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Bai YQ, 2019, SIGNAL PROCESS, V161, P248, DOI 10.1016/j.sigpro.2019.03.013
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gao Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107284
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Gvozden G, 2018, J VIS COMMUN IMAGE R, V50, P145, DOI 10.1016/j.jvcir.2017.11.017
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Jen T.-C., 2005, P IEEE INT C IM PROC, V1, P913
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P918, DOI 10.1109/LSP.2014.2320743
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Min XK, 2018, SIGNAL PROCESS, V145, P127, DOI 10.1016/j.sigpro.2017.10.025
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Peng F, 2019, IEEE T RELIAB, V68, P342, DOI 10.1109/TR.2018.2869303
   Peng F, 2019, COMPUT SECUR, V82, P173, DOI 10.1016/j.cose.2018.12.015
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Peng F, 2014, DIGIT INVEST, V11, P111, DOI 10.1016/j.diin.2014.04.002
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Saha A, 2016, SIGNAL PROCESS, V128, P186, DOI 10.1016/j.sigpro.2016.03.026
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Sun W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1228, DOI 10.1109/ICASSP.2018.8461581
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P16, DOI 10.1016/j.image.2016.05.008
   Xiao HM, 2019, J VIS COMMUN IMAGE R, V59, P52, DOI 10.1016/j.jvcir.2018.12.048
   Yang GY, 2017, IEEE ACCESS, V5, P23146, DOI 10.1109/ACCESS.2017.2764126
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhang LB, 2017, J VIS COMMUN IMAGE R, V48, P471, DOI 10.1016/j.jvcir.2016.12.013
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhou Y, 2019, J VIS COMMUN IMAGE R, V60, P158, DOI 10.1016/j.jvcir.2019.02.028
NR 43
TC 18
Z9 20
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2020
VL 69
AR 102797
DI 10.1016/j.jvcir.2020.102797
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LZ3UM
UT WOS:000541153600004
DA 2024-07-18
ER

PT J
AU Cao, Y
   Ji, HB
   Zhang, WB
   Xue, F
AF Cao, Yi
   Ji, Hongbing
   Zhang, Wenbo
   Xue, Fei
TI Visual tracking via dynamic weighting with pyramid-redetection based
   Siamese networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Siamese networks; Dynamic weighting; Residual
   structure; Convolutional neural networks; Pyramid-redetection
ID OBJECT TRACKING
AB Siamese network based similarity-learning algorithm is currently a significant branch of visual tracking. However, most of existing deep Siamese networks depend much on the offline-trained knowledge and always assume the same importance for different prediction views. In this paper, we first introduce a dynamic weighting module in Siamese framework, which could make the offline-trained network adapt to the current circumstance well and weight predictive response maps discriminatively. The thought stems from the basis that different maps have different predictive preference, which should not be treated equally. Secondly, in order to focus more on the accurate preference, we then introduce the residual structure to form the residual dynamic weighting module. Thirdly, we construct a simple online pyramidredetection module to avoid local search and also consider the global viewpoint. Extensive experiments on both short-term and long-term tracking demonstrate that the proposed tracker possesses the competitive tracking performance over many mainstream state-of-the-art trackers. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Cao, Yi; Ji, Hongbing; Zhang, Wenbo; Xue, Fei] Xidian Univ, Sch Elect Engn, POB 229, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Ji, HB (corresponding author), Xidian Univ, Sch Elect Engn, POB 229, Xian 710071, Shaanxi, Peoples R China.
EM hbji@xidian.edu.cn
RI Zhang, Wenbo/IQS-6801-2023
FU National Natural Science Foundation of China [61501357]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016JQ6080]
FX This work was supported by the National Natural Science Foundation of
   China under grant No. 61501357 and Natural Science Basic Research Plan
   in Shaanxi Province of China under grant No. 2016JQ6080. The authors
   want to thank Prof. Shahram Shirani from McMaster University for his
   suggestion on improving the paper.
CR [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2016, CVPR
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], 2012, CoRR
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bai B, 2018, NEUROCOMPUTING, V286, P109, DOI 10.1016/j.neucom.2018.01.068
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P1327, DOI 10.1109/TIP.2016.2520358
   Cheng K, 2021, IEEE T BIG DATA, V7, P689, DOI 10.1109/TBDATA.2017.2707552
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Grabner H., 2006, BMVC, P47
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji ZJ, 2018, J VIS COMMUN IMAGE R, V55, P354, DOI 10.1016/j.jvcir.2018.06.017
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Kristan M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P98, DOI 10.1109/ICCVW.2013.20
   Li GJ, 2018, J VIS COMMUN IMAGE R, V56, P92, DOI 10.1016/j.jvcir.2018.09.004
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Parkhi O., 2015, 2015 BRIT MACH VIS C
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song HH, 2017, ELECTRON LETT, V53, P20, DOI 10.1049/el.2016.3011
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang MN, 2017, PROCEEDINGS OF THE 2017 IEEE-APS TOPICAL CONFERENCE ON ANTENNAS AND PROPAGATION IN WIRELESS COMMUNICATIONS (APWC), P21, DOI 10.1109/APWC.2017.8062230
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang TY, 2017, IEEE INT CONF COMP V, P2010, DOI 10.1109/ICCVW.2017.235
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zheng WW, 2018, J VIS COMMUN IMAGE R, V55, P688, DOI 10.1016/j.jvcir.2018.08.004
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu G., 2015, 2015 BRIT MACH VIS C
   Zhu Z., 2018, ARXIV180806048
NR 68
TC 4
Z9 4
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102635
DI 10.1016/j.jvcir.2019.102635
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700004
DA 2024-07-18
ER

PT J
AU Li, ZY
AF Li, Zhenyu
TI Application research of digital image technology in graphic design
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image technology; Digital image; Graphic design; Image
   adjustment
ID OPTIMIZATION
AB With the development of the information age and the popularity of Internet computer technology, the application field of digital image technology has been further expanded. Digital image technology can not only buy the interchange of the current picture scene, the image adjustment, but also change the color texture of the image and the shape of the main body of the picture. The application of digital technology and imaging in graphic design has become an inevitable trend, and they play an invaluable role in graphic design. Graphic design is designed to meet the growing cultural needs of people, and it is clear that high standards of digital technology and imaging are not lacking. The development of graphic design is inseparable from the promotion of digital image technology, and there is a close relationship between the two. In the context of the rapid development of the current society, people's needs are increasing, and how to meet the visual needs of the social population has become a top priority. This paper takes the relationship between digital image technology and graphic design as the starting point, discusses the processing criteria of digital image technology in graphic design, and provides reference for relevant researchers. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Zhenyu] Gansu Univ Polit Sci & Law, Art Coll, Lanzhou, Gansu, Peoples R China.
C3 Gansu University of Political Science & Law
RP Li, ZY (corresponding author), Gansu Univ Polit Sci & Law, Art Coll, Lanzhou, Gansu, Peoples R China.
EM lzy6493@gsli.edu.cn
RI li, zy/HZM-1892-2023
CR Aghaei M., 2015, EV BAS CONTR COMM SI, P1, DOI DOI 10.1109/EBCCSP.2015.7300708
   Barbedo JGA, 2016, TROP PLANT PATHOL, V41, P210, DOI 10.1007/s40858-016-0090-8
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Neto EC, 2015, IEEE LAT AM T, V13, P272, DOI 10.1109/TLA.2015.7040658
   Chen SJ, 2016, ROCK MECH ROCK ENG, V49, P855, DOI 10.1007/s00603-015-0795-x
   Chrysafi AP, 2017, INT J THERM SCI, V116, P242, DOI 10.1016/j.ijthermalsci.2017.02.017
   Di Mauro D, 2019, J VIS COMMUN IMAGE R, V62, P234, DOI 10.1016/j.jvcir.2019.05.015
   Garcia I, 2015, COMPUT APPL ENG EDUC, V23, P92, DOI 10.1002/cae.21581
   Juno D.L.B.R., 2015, MECH SYST SIG PROCES, V54-55, P394
   Kalafi EY, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1376-z
   Khan MB, 2015, ADV EXP MED BIOL, V823, P227, DOI 10.1007/978-3-319-10984-8_13
   Lakkis S, 2015, SENSOR ACTUAT B-CHEM, V207, P321, DOI 10.1016/j.snb.2014.09.103
   Leow L.K., 2015, BMC BIOINF S18, V16, P54
   Mazhir S.N., 2017, INT C SIGN PROC, P2
   Moon K.H., 2015, KSCE J CIV ENG, V19, P1
   Oliveira PC, 2016, COMPUT ELECTRON AGR, V124, P289, DOI 10.1016/j.compag.2016.04.020
   Pizurica A, 2015, IEEE SIGNAL PROC MAG, V32, P112, DOI 10.1109/MSP.2015.2411753
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Robertson S, 2018, TRANSL RES, V194, P19, DOI 10.1016/j.trsl.2017.10.010
   Samarasinghe S., 2015, SILVA FENNICA, V38, P267
   Szmaja W., 2015, PHYS STATUS SOLIDI A, V194, P315
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wigianto R., 2015, BIOMED MAT RES, V34, P177
   Yang Y, 2015, J MATER PROCESS TECH, V226, P85, DOI 10.1016/j.jmatprotec.2015.07.001
   Yao JN, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/3/035003
NR 25
TC 8
Z9 8
U1 5
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102689
DI 10.1016/j.jvcir.2019.102689
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700027
DA 2024-07-18
ER

PT J
AU Song, WL
   Li, LN
   Ren, ZH
AF Song, Wuli
   Li, Linna
   Ren, Zihui
TI Ultrasonic image processing based on fusion super-resolution
   reconstruction of familiar models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Ultrasonic image; Super-resolution; Coefficient representation; Multi
   feature fusion
ID OBJECT DETECTION; DIFFUSION; SELECTION
AB Ultrasound image technology is to measure the energy and time of arrival of the reflected echo after the pulse acoustic signal is sent out by the ultrasonic wave. Usually, the distance between the ultrasonic source and the reflector is measured. Super-resolution image reconstruction aims to recover high-resolution images from one or more low-resolution images. Super-resolution image reconstruction is a software approach to solve the problem of low-resolution images by overcoming the limitations of hardware. In this paper, an image super-resolution reconstruction method based on sparse representation model and multi-feature fusion is proposed. Sparse dictionary is used to learn and reconstruct the luminance details of ultrasonic images, and edge interpolation is used to improve the edge clarity. Experimental results show that the proposed method is superior to Bicubic interpolation, SCSR and JOR in PSNR, and is 0.35 dB higher than RAISR. On the FSIM index, this method is also slightly better than other comparison methods, which can get better reconstruction results. Visual effects and numerical evaluation results of reconstructed images are better than several comparison methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Song, Wuli; Ren, Zihui] China Univ Min & Technol, Xuzhou, Jiangsu, Peoples R China.
   [Song, Wuli] Shandong First Med Univ & Shandong Acad Med Sci, Tai An, Shandong, Peoples R China.
   [Li, Linna] Shandong Agr Univ, Tai An, Shandong, Peoples R China.
C3 China University of Mining & Technology; Shandong First Medical
   University & Shandong Academy of Medical Sciences; Shandong Agricultural
   University
RP Song, WL (corresponding author), China Univ Min & Technol Xuzhou, 1 Univ Rd, Xuzhou, Jiangsu, Peoples R China.
EM wlsong@sdfmu.edu.cn; lnl@sdau.edu.cn
RI li, li/HII-4157-2022
FU Natural Fund Project of Shandong Province [ZR2016FLO5]
FX This work was supported by Natural Fund Project of Shandong Province
   (No. ZR2016FLO5).
CR Adamo F, 2013, MEASUREMENT, V46, P2447, DOI 10.1016/j.measurement.2013.04.064
   Ahmad T., 2012, J COMMUN, V7
   Al Mamun Md, 2019, J VIS COMMUN IMAGE R, V59
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Andria G, 2013, IEEE INT SYM MED MEA, P49, DOI 10.1109/MeMeA.2013.6549704
   [Anonymous], 2015, IEEE T SMART GRID PP
   Bätz M, 2015, IEEE IMAGE PROC, P58, DOI 10.1109/ICIP.2015.7350759
   Chen W, 2012, IEEE SYS MAN CYBERN, P35, DOI 10.1109/ICSMC.2012.6377673
   Chu J., 2012, GRADIENT BASED ADAPT, P1027
   de Fontes FPX, 2011, J REAL-TIME IMAGE PR, V6, P15, DOI 10.1007/s11554-010-0158-5
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Jung C, 2014, SIGNAL PROCESS-IMAGE, V29, P1211, DOI 10.1016/j.image.2014.08.002
   Mu S., 2015, J HARBIN I TECHNOLOG
   Murali S, 2012, INT J COMPUTER APPL
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Olfa M., 2015, IM PROC APPL SYST C, P1
   Raj VNP, 2012, INT J COMPUT APPL, V56, P44, DOI DOI 10.5120/8963-3171
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Scherrer B, 2012, MED IMAGE ANAL, V16, P1465, DOI 10.1016/j.media.2012.05.003
   Shang L, 2017, NEUROCOMPUTING, V228, P37, DOI 10.1016/j.neucom.2016.09.090
   Srinivas M., 2015, 2015 21 NATL C COMMU, P1
   Turek JS, 2015, INT CONF ACOUST SPEE, P793, DOI 10.1109/ICASSP.2015.7178078
   Veatch SL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031457
   Wang GD, 2014, BIOMED SIGNAL PROCES, V13, P212, DOI 10.1016/j.bspc.2014.05.005
   WANG Y, 2017, ACTA OPT SIN, V37
   Wen QN, 2013, J NANOSCI NANOTECHNO, V13, P666, DOI 10.1166/jnn.2013.6861
   Wu H., 2015, MEAS SCI TECHNOL, P26
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Yin M.I., 2015, COMPUT ENG
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhou F, 2012, IEEE T IMAGE PROCESS, V21, P3312, DOI 10.1109/TIP.2012.2189576
NR 37
TC 1
Z9 1
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102633
DI 10.1016/j.jvcir.2019.102633
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600024
DA 2024-07-18
ER

PT J
AU Li, WJ
   He, W
   Ou, XF
   Hu, WJ
   Wu, JH
   Zhang, GY
AF Li, Wujing
   He, Wei
   Ou, Xianfeng
   Hu, Wenjing
   Wu, Jianhui
   Zhang, Guoyun
TI Fast combination filtering based on weighted fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Filter; Linear combination; Multi-scale; Edge preserving
ID BILATERAL FILTER; TONE REPRODUCTION; APPROXIMATION; DIFFUSION; EFFICIENT
AB This paper presents a fast filter based on a modified Lee filter. The smoothing operation in the proposed filter is a linear combination of the center pixel value and the average of pixel values in a window. Based on the new definitions of edge and noise, the local gradient mean is introduced to compute the coefficient of the linear combination. Besides, a multi-scale method is employed to smooth the pixel values near edges. The main advantage of the proposed filter is its computational cost. In addition to some point operations, only several mean filters are taken in this filter. No matter how large the window size is, the time complexity is O(N) (N is the pixel number). Experimental results have shown that the proposed filter can effectively smooth images while keeping edges well, thus can be widely used in computer vision and image processing. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Wujing; He, Wei; Ou, Xianfeng; Wu, Jianhui] Hunan Inst Sci & Technol, Sch Informat Sci & Technol, Yueyang, Peoples R China.
   [Li, Wujing; Ou, Xianfeng; Hu, Wenjing; Wu, Jianhui; Zhang, Guoyun] Hunan Inst Sci & Technol, Key Lab Optimizat & Control Complex Syst, Yueyang, Peoples R China.
C3 Hunan Institute of Science & Technology; Hunan Institute of Science &
   Technology
RP Wu, JH (corresponding author), Hunan Inst Sci & Technol, Sch Informat Sci & Technol, Yueyang, Peoples R China.
EM jhwu@hnist.edu.cn
RI Li, Wujing/GZL-9066-2022
OI Wu, Jianhui/0000-0002-7226-1619; Li, Wujing/0000-0002-7825-7805
FU Hunan Provincial Natural Science Foundation of China [2017JJ3099,
   20191140104]; Science and Technology Program of Hunan Province
   [2016TP1021]; Scientific Research Fund of Education Department of Hunan
   Province [188345]
FX This work was supported by the Hunan Provincial Natural Science
   Foundation of China under Grant 2017JJ3099 and 20191140104, the Science
   and Technology Program of Hunan Province under Grant 2016TP1021, and
   Scientific Research Fund of Education Department of Hunan Province under
   Grant 188345. We thank the reviewers for insightful comments.
CR [Anonymous], 2019, KODAK LOSSLESS TRUE
   Chen HT, 2005, PROC CVPR IEEE, P369
   Dai LQ, 2016, IEEE T IMAGE PROCESS, V25, P2657, DOI 10.1109/TIP.2016.2549701
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Kass M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778837
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Porikli F, 2008, PROC CVPR IEEE, P3895
   Rau R, 1997, IEEE T SIGNAL PROCES, V45, P468, DOI 10.1109/78.554310
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Shen J, 2002, SIGNAL PROCESS, V82, P1109, DOI 10.1016/S0165-1684(02)00243-8
   Song KC, 2016, J VIS COMMUN IMAGE R, V38, P487, DOI 10.1016/j.jvcir.2016.03.026
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Y, 2017, J VIS COMMUN IMAGE R, V43, P185, DOI 10.1016/j.jvcir.2017.01.005
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Xu Jun., 2018, Real-world noisy image denoising: A new benchmark
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
NR 29
TC 3
Z9 3
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 226
EP 233
DI 10.1016/j.jvcir.2019.05.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600021
DA 2024-07-18
ER

PT J
AU Li, N
   Zhang, Y
   Zhu, LW
   Luo, WH
   Kwong, S
AF Li, Na
   Zhang, Yun
   Zhu, Linwei
   Luo, Wenhan
   Kwong, Sam
TI Reinforcement learning based coding unit early termination algorithm for
   high efficiency video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Coding tree unit; Early termination; High efficiency video coding;
   Markov decision processing; Actor-critic; Reinforcement learning
ID DECISION; ALLOCATION; H.264/AVC
AB In this paper, we propose a Reinforcement Learning (RL) based Coding Unit (CU) early termination algorithm for High Efficiency Video Coding (HEVC). RL is utilized to learn a CU early termination classifier independent of depths for low complexity video coding. Firstly, we model the process of CU decision as a Markov Decision Process (MDP) according to the Markov property of CU decision. Secondly, based on the MDP, a CU early termination classifier independent of depths is learned from trajectories of CU decision across different depths with the end-to-end actor-critic RL algorithm. Finally, a CU decision early termination algorithm is introduced with the learned classifier, so as to reduce computational complexity of CU decision. We implement the proposed scheme with different neural network structures. Two different neural network structures are utilized in the implementation of RL based video encoder, which are evaluated to reduce video coding complexity by 34.34% and 43.33%. With regard to Bjontegaard delta peak signal-to-noise ratio and Bjontegaard delta bit rate, the results are -0.033 dB and 0.85%, -0.099 dB and 2.56% respectively on average under low delay B main configuration, when compared with the HEVC test model version 16.5. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Na; Zhang, Yun; Zhu, Linwei] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Luo, Wenhan] Tencent AI Lab, Shenzhen, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Tencent; City University of Hong Kong; City University of Hong
   Kong; Shenzhen Research Institute, City University of Hong Kong
RP Zhang, Y (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM na.li1@siat.ac.cn; yun.zhang@siat.ac.cn; lw.zhu@siat.ac.cn;
   whluo.china@gmail.com; cssamk@cityu.edu.hk
RI Zhang, Yun/V-7261-2019; Luo, Wenhan/GZL-0535-2022; Kwong,
   Sam/C-9319-2012
OI Zhang, Yun/0000-0001-9457-7801; Kwong, Sam/0000-0001-7484-7261; Luo,
   Wenhan/0000-0002-5697-4168; , linwei/0000-0002-9385-9054
FU National Natural Science Foundation of China [61471348, 61871372,
   61672443]; Guangdong Natural Science Foundation for Distinguished Young
   Scholar [2016A030306022]; Shenzhen Science and Technology Development
   Project [JCYJ20170811160212033]; Shenzhen International Collaborative
   Research Project [GJHZ20170314155404913]; Key Project for Guangdong
   Provincial Science and Technology Development [2017B010110014]; Free
   Application Fund of Natural Science Foundation of Guangdong Province
   [2018A0303130126]; RGC General Research Fund (GRF) [9042322, 9042489,
   CityU 11200116, 11206317]; Guangdong International Science and
   Technology Cooperative Research Project [2018A050506063]; Membership of
   Youth Innovation Promotion Association, Chinese Academy of Sciences
   [2018392]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61471348, 61871372, 61672443, in part by
   Guangdong Natural Science Foundation for Distinguished Young Scholar
   under Grant 2016A030306022, in part by Shenzhen Science and Technology
   Development Project under Grant JCYJ20170811160212033 and Shenzhen
   International Collaborative Research Project under Grant
   GJHZ20170314155404913, in part by the Key Project for Guangdong
   Provincial Science and Technology Development under Grant
   2017B010110014, in part by Free Application Fund of Natural Science
   Foundation of Guangdong Province under Grant 2018A0303130126, in part by
   RGC General Research Fund (GRF) 9042322, 9042489 (CityU 11200116,
   11206317), in part by Guangdong International Science and Technology
   Cooperative Research Project under Grant 2018A050506063, in part by
   Membership of Youth Innovation Promotion Association, Chinese Academy of
   Sciences under Grant 2018392.
CR Ahn Y. J., 2017, J REAL-TIME IMAGE PR, P1
   Bertsekas D.P., 2012, DYNAMIC PROGRAMMING, VII
   Bjentegaard G., 2001, 15 M AUST TEX US APR
   Chen HM, 2016, IEEE T IMAGE PROCESS, V25, P3671, DOI 10.1109/TIP.2016.2573585
   Chung CH, 2017, I S INTELL SIG PROC, P570, DOI 10.1109/ISPACS.2017.8266543
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Duanmu F, 2016, IEEE J EM SEL TOP C, V6, P517, DOI 10.1109/JETCAS.2016.2597698
   Duanmu F, 2015, IEEE IMAGE PROC, P4972, DOI 10.1109/ICIP.2015.7351753
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Heller P, 2017, WOODHEAD PUBL SER EN, P1, DOI 10.1016/B978-0-08-100447-0.00001-8
   Jung SH, 2016, IEEE T CIRC SYST VID, V26, P1846, DOI 10.1109/TCSVT.2015.2473303
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim J, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P261, DOI 10.1109/ICCE.2012.6161857
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   ORTEGA A, 1994, IEEE T IMAGE PROCESS, V3, P26, DOI 10.1109/83.265978
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Si J, 2001, IEEE T NEURAL NETWOR, V12, P264, DOI 10.1109/72.914523
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sutton RS, 2016, Reinforcement Learning: An Introduction
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Zhang Y, 2018, IEEE T CIRC SYST VID, V28, P3208, DOI 10.1109/TCSVT.2017.2747659
   Zhang Y, 2015, IEEE T IND INFORM, V11, P1492, DOI 10.1109/TII.2015.2491646
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhang Y, 2012, IEEE T BROADCAST, V58, P10, DOI 10.1109/TBC.2011.2174282
   Zhu LW, 2018, IEEE T BROADCAST, V64, P681, DOI 10.1109/TBC.2017.2762470
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
   Zhu LW, 2016, J VIS COMMUN IMAGE R, V38, P824, DOI 10.1016/j.jvcir.2016.04.020
   Zupancic I, 2016, IEEE T MULTIMEDIA, V18, P1677, DOI 10.1109/TMM.2016.2579505
NR 31
TC 16
Z9 17
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 276
EP 286
DI 10.1016/j.jvcir.2019.02.021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000030
DA 2024-07-18
ER

PT J
AU Chen, F
   Li, B
   Li, L
AF Chen, Feng
   Li, Bo
   Li, Liang
TI 3D object retrieval with graph-based collaborative feature learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D Object retrieval; Collaborative feature learning; Hypergraph
   learning; Bipartite graph matching
ID MODEL RETRIEVAL; HAUSDORFF DISTANCE; RECOGNITION; SEARCH;
   CLASSIFICATION; IMAGES
AB 3D object retrieval has attractive extensive research focus in recent years. Among various schemes, view based 3D object retrieval is regarded as a promising direction. In this paper, we present a novel view-based 3D object retrieval framework, which is deployed over a graph-based collaborative learning scheme to intelligently fuse multiple features. In particular, we introduce a hypergraph based collaborative feature learning scheme to fuse complement descriptors from both the contour and the interior region of 3D object effectively. Then, the view-based 3D object retrieval is done via a greedy bipartite graph matching algorithm, which achieves highly accurate and efficient 3D object matching. With the above bipartite graph matching and feature concatenation, significant performance improvement is achieved in the 3D object retrieval task, on either widely-used benchmark datasets or open competitions like SHREC15 challenge. In both evaluations, the proposed graph-based collaborative feature learning scheme has beaten a serial of existing approaches and state-of-the-art schemes. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chen, Feng; Li, Bo; Li, Liang] State Grid Zhejiang Elect Vehicle Serv Co Ltd, Hangzhou, Zhejiang, Peoples R China.
RP Chen, F (corresponding author), State Grid Zhejiang Elect Vehicle Serv Co Ltd, Hangzhou, Zhejiang, Peoples R China.
EM 13705817924@139.com
CR [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 2003, INT J IMAGE GRAPH
   [Anonymous], 2015, SHREC 15 TRACK 3D OB
   [Anonymous], 2000, P KDD WORKSHOP TEXT
   [Anonymous], VIEW BASED 3 D OBJEC
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377
   Blum M, 2012, IEEE INT CONF ROBOT, P1298, DOI 10.1109/ICRA.2012.6225188
   Bracewell R., 1965, The Fourier Transform and Its Applications
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chang CY, 2012, IEEE T IND ELECTRON, V59, P1640, DOI 10.1109/TIE.2011.2163916
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cheng YH, 2014, INT C PATT RECOG, P2377, DOI 10.1109/ICPR.2014.412
   Chowdhury Ananda S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2456, DOI 10.1109/ICPR.2010.601
   Coates A., 2011, P 14 INT C ART INT S, V15, P215
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Gao Y., 2015, 3D OBJECT RETRIEVAL
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu WS, 2013, IEEE T IND ELECTRON, V60, P4673, DOI 10.1109/TIE.2012.2208440
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   Kuhn Harold W, 1955, NAV RES LOG, V2, P83, DOI [10.1002/nav.20053, DOI 10.1002/NAV.20053, DOI 10.1002/NAV.3800020109]
   LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4
   Leibe B., 2003, 2003 IEEE COMP VIS P
   Li WJ, 2008, IEEE T IMAGE PROCESS, V17, P2236, DOI 10.1109/TIP.2008.2003404
   Lin C, 2014, NEUROCOMPUTING, V123, P424, DOI 10.1016/j.neucom.2013.08.004
   Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu K, 2014, INFORM SCIENCES, V281, P703, DOI 10.1016/j.ins.2014.03.079
   Mahmoudi S, 2002, INT C PATT RECOG, P457, DOI 10.1109/ICPR.2002.1048337
   Makadia A, 2010, INT J COMPUT VISION, V89, P193, DOI 10.1007/s11263-009-0280-7
   Ohbuchi R., 2008, P IEEE C SHAP MOD AP, P1
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Stejic Z, 2003, IEEE T IND ELECTRON, V50, P839, DOI 10.1109/TIE.2003.817497
   Takeguchi T, 2005, IEEE T IND ELECTRON, V52, P1041, DOI 10.1109/TIE.2005.851660
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   XIAO WS, 1993, GRAPH THEORY ITS ALG
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang YB, 2007, IEEE T SYST MAN CY C, V37, P1081, DOI 10.1109/TSMCC.2007.905756
NR 54
TC 4
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 261
EP 268
DI 10.1016/j.jvcir.2018.11.046
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100026
DA 2024-07-18
ER

PT J
AU Du, HS
   Li, GD
   Wang, S
   Zhang, F
AF Du, Haishun
   Li, Guodong
   Wang, Sheng
   Zhang, Fan
TI Discriminant locality preserving projections based on <i>L</i>_2,p-norm
   for image feature extraction and recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discriminant locality preserving projections; L-2,L-p-norm; Subspace
   learning; Feature extraction; Image recognition
ID PRINCIPAL COMPONENT ANALYSIS; FACE RECOGNITION; DIMENSIONALITY
   REDUCTION; FRAMEWORK; EIGENFACES; REGRESSION; ALGORITHM; SELECTION
AB Conventional discriminant locality preserving projections (DLPP) is sensitive to outliers because the formulation of its objective function is based on L-2-norm. Not only that, the learned features by DLPP are linear combinations of all the original features. So, it is hard to know which features play an important role in feature extraction, and the learned features often contain irrelevant information. In this paper, we propose a robust version of DLPP based on L-2,L-p-norm with 0 < p < 1, termed DLPP-L-2,L-p, for image feature extraction and recognition. DLPP-L-2,L-p learns an optimal projection matrix by maximizing the L-2,L-p-norm-based locality preserving between-class dispersion and minimizing the L-2,L-p-norm-based locality preserving within-class dispersion simultaneously. Furthermore, by imposing an L-2,L-p-norm penalty on the projection matrix to achieve row-sparsity, DLPP-L-2,L-p can discard irrelevant features and transform relevant features simultaneously. Experimental results on several image datasets demonstrate the effectiveness and robustness of DLPP-L-2,L-p. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Du, Haishun; Li, Guodong; Wang, Sheng; Zhang, Fan] Henan Univ, Sch Comp & Informat Engn, Kaifeng, Peoples R China.
C3 Henan University
RP Wang, S (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng, Peoples R China.
EM wangsheng1910@163.com
OI Du, Haishun/0000-0003-0883-8118
FU NSFC-Henan Talent Jointly Training Foundation of China [U1504621];
   Science and Technology Development Project of Henan Province
   [172102210185]; Key Science Research Project of Higher Education of
   Henan Province [18A120001]
FX This work is supported in part by the NSFC-Henan Talent Jointly Training
   Foundation of China (No. U1504621), the Science and Technology
   Development Project of Henan Province (No. 172102210185), and the Key
   Science Research Project of Higher Education of Henan Province (No.
   18A120001).
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 1998, AR FACE DATABASE
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2007, 0749 U MASS
   [Anonymous], 1996, Tech. Rep. CUCS-006-96
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Chen H., 2005, P 2005 IEEE COMP SOC
   Chen YD, 2018, IEEE T MULTIMEDIA, V20, P3212, DOI 10.1109/TMM.2018.2834867
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   He L., 2018, DYNAMIC FEATURE LEAR, P7054
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4
   KRZANOWSKI WJ, 1987, J R STAT SOC C-APPL, V36, P22
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Kwak N, 2014, IEEE T CYBERNETICS, V44, P594, DOI 10.1109/TCYB.2013.2262936
   Lai ZH, 2017, IEEE T CYBERNETICS, V47, P3733, DOI 10.1109/TCYB.2016.2578642
   Li CN, 2015, NEURAL NETWORKS, V65, P92, DOI 10.1016/j.neunet.2015.01.003
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li S., 2017, IEEE T NEURAL NETWOR, V27, P2160
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu F., 2018, DISENTANGLING FEATUR, P5216
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu Y, 2018, PROC CVPR IEEE, P2080, DOI 10.1109/CVPR.2018.00222
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Oh JH, 2013, PATTERN RECOGN LETT, V34, P679, DOI 10.1016/j.patrec.2013.01.016
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi XS, 2015, IEEE T IMAGE PROCESS, V24, P1341, DOI 10.1109/TIP.2015.2405474
   Shi XS, 2014, PATTERN RECOGN, V47, P2447, DOI 10.1016/j.patcog.2014.01.007
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang LP, 2014, COMPUT OPTIM APPL, V58, P409, DOI 10.1007/s10589-014-9648-x
   Wen J, 2019, IEEE T CYBERNETICS, V49, P1279, DOI 10.1109/TCYB.2018.2799862
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wong WK, 2017, IEEE T IMAGE PROCESS, V26, P2905, DOI 10.1109/TIP.2017.2691543
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xie LF, 2018, IEEE T IMAGE PROCESS, V27, P5261, DOI 10.1109/TIP.2018.2855426
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zhang MX, 2016, NEUROCOMPUTING, V195, P104, DOI 10.1016/j.neucom.2015.08.111
   Zhong FJ, 2014, IEEE T NEUR NET LEAR, V25, P2065, DOI 10.1109/TNNLS.2014.2303798
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 53
TC 11
Z9 12
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 166
EP 177
DI 10.1016/j.jvcir.2018.11.037
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100018
DA 2024-07-18
ER

PT J
AU Yang, T
   Cappelle, C
   Ruichek, Y
   El Bagdouri, M
AF Yang, Tao
   Cappelle, Cindy
   Ruichek, Yassine
   El Bagdouri, Mohammed
TI Online multi-object tracking combining optical flow and compressive
   tracking in Markov decision process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-object tracking; Markov decision process;
   Tracking-learning-detection; Compressive sensing features
ID NETWORK-FLOW
AB Effective features are important for visual tracking, and efficiency also needs to be considered especially for multi-object tracking. Thanks to the simplicity, we think compressive sensing features are suitable for this task. In this paper, we use compressive sensing features to improve the Markov decision process (MDP) multi-object tracking framework. First, we design a single object tracker which uses the compressive tracking to correct the optical flow tracking and apply this tracker into the MDP tracking framework. The appearance model constructed during compressive tracking also helps for data association. In order to validate our method, we firstly test the designed single object tracker with a common dataset. Then, we test our multi-object tracking method for vehicle tracking. Finally, we analyze and test our approach in the multi-object tracking (MOT) benchmark for pedestrian tracking. The results show our approach performs superiorly against several state-of-the-art online multi-object trackers. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yang, Tao; Cappelle, Cindy; Ruichek, Yassine; El Bagdouri, Mohammed] Univ Bourgogne Franche Comte, Le2i EA7508, CNRS, Arts & Metiers,UTBM, F-90010 Belfort, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Bourgogne; Universite de Technologie de Belfort-Montbeliard (UTBM);
   Universite de Franche-Comte
RP Yang, T; Cappelle, C; Ruichek, Y (corresponding author), Univ Bourgogne Franche Comte, Le2i EA7508, CNRS, Arts & Metiers,UTBM, F-90010 Belfort, France.
EM tao.yang@utbm.fr; cindy.cappelle@utbm.fr; yassine.ruichek@utbm.fr
RI Ruichek, Yassine/GRX-3627-2022; CAPPELLE, Cindy/AID-6674-2022
OI CAPPELLE, Cindy/0000-0002-3756-2336; Yang, Tao/0000-0003-3729-4359;
   RUICHEK, Yassine/0000-0003-4795-8569
FU China Scholarship Council
FX The authors gratefully acknowledge financial support from China
   Scholarship Council.
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Ahuja Ravindra K., 2017, Network Flows: Theory, Algorithms, and Applications
   [Anonymous], 2017, 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)
   [Anonymous], COMP VIS ECCV 2016 W
   [Anonymous], MULTICUT FORMULATION
   [Anonymous], 2016, IJCAI
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2018, CVPR WORKSHOPS
   [Anonymous], 2016, MEX INT C ART INT
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Barbu T, 2014, COMPUT ELECTR ENG, V40, P1072, DOI 10.1016/j.compeleceng.2013.12.004
   Bingham E., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P245, DOI 10.1145/502512.502546
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Butt AA, 2013, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2013.241
   Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266
   Eiselein V, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P325, DOI 10.1109/AVSS.2012.59
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Ju J, 2017, J OPT SOC AM A, V34, P280, DOI 10.1364/JOSAA.34.000280
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kieritz H, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P122, DOI 10.1109/AVSS.2016.7738059
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lan L, 2018, IEEE T IMAGE PROCESS, V27, P4585, DOI 10.1109/TIP.2018.2843129
   Leal-Taix L., 2015, MOTCHALLENGE 2015 BE
   Li P., 2006, P ACM SIGKDD INT C K, P287
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Maksai A, 2016, PROC CVPR IEEE, P972, DOI 10.1109/CVPR.2016.111
   Milan A., MOT16: A Benchmark for Multi-Object Tracking
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48
   Türetken E, 2017, IEEE T MED IMAGING, V36, P942, DOI 10.1109/TMI.2016.2640859
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu J, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P523, DOI 10.1109/DCABES.2010.112
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu YX, 2015, VISUAL COMPUT, V31, P471, DOI 10.1007/s00371-014-0942-5
   Wu Z, 2011, PROC CVPR IEEE, P1185, DOI 10.1109/CVPR.2011.5995515
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Zhang HY, 2013, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2013.379
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
NR 47
TC 16
Z9 17
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 178
EP 186
DI 10.1016/j.jvcir.2018.11.034
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100019
DA 2024-07-18
ER

PT J
AU Cai, HY
   Ma, HD
   Li, LY
   Zhang, LM
AF Cai, Haoyang
   Ma, Haodong
   Li, Linyu
   Zhang, Luming
TI Can modified minimax win in Pearl's game?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Minimax algorithm; Modified Minimax algorithm; Pearl's game
AB Minimax algorithm is widely used for adversarial searching. It is commonly believed that searching depth and winning chance has a positive correlation, but Dana S. Nau pointed out in his 1982 research that in Pearl's game, pathology occurs. Minimax shows a decrease of winning chance as searching depth increases. Our research proposes a possible way to fix the pathology by taking the opponent's strategy into consideration in some specific cases. The experiment proves that the accumulation of incorrect predictions at least partially causes the pathology. Our modified version of Minimax successfully overcomes the pathology and continues to present the power of Minimax in Pearl's game. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Cai, Haoyang] Hangzhou Foreign Languages Sch, 12 Grade, Hangzhou, Zhejiang, Peoples R China.
   [Ma, Haodong] Zhengzhou Foreign Languages Sch, 12 Grade, Zhengzhou, Henan, Peoples R China.
   [Li, Linyu] Bishop Hendricken High Sch, 12 Grade, Warwick, RI USA.
   [Zhang, Luming] Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Cai, HY (corresponding author), Hangzhou Foreign Languages Sch, 12 Grade, Hangzhou, Zhejiang, Peoples R China.
EM haoyangcai@126.com
RI SUN, Ye/KBC-8159-2024; zhang, lu/GRO-2969-2022; Lei, Ming/JAD-1050-2023
CR NAU DS, 1982, ARTIF INTELL, V19, P257, DOI 10.1016/0004-3702(82)90002-9
   NAU DS, 1982, ARTIF INTELL, V18, P53, DOI 10.1016/0004-3702(82)90010-8
   NAU DS, 1983, ARTIF INTELL, V21, P221, DOI 10.1016/S0004-3702(83)80011-3
NR 3
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 23
EP 27
DI 10.1016/j.jvcir.2018.10.011
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400003
DA 2024-07-18
ER

PT J
AU Jian, MW
   Zhao, RX
   Sun, X
   Luo, HJ
   Zhang, WY
   Zhang, HX
   Dong, JY
   Yin, YL
   Lam, KM
AF Jian, Muwei
   Zhao, Runxia
   Sun, Xin
   Luo, Hanjiang
   Zhang, Wenyin
   Zhang, Huaxiang
   Dong, Junyu
   Yin, Yilong
   Lam, Kin-Man
TI Saliency detection based on background seeds by object proposals and
   extended random walk
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Object proposals; Background seeds; Extended random
   walk
ID ATTENTION; OPTIMIZATION; CONTRAST; SPARSE; MODEL
AB Recently, many graph-based algorithms are applied in the research of saliency detection, which use the border of an image as a background query. This frequently leads to undesired errors and retrieval outputs when the boundaries of the salient objects concerned touch, or connect with, the image's border. In this paper, a novel bottom-up saliency-detection algorithm is proposed to tackle and overcome the above issue. First, we utilize object proposals to collect the background seeds reliably. Then, the Extended Random Walk (ERW) algorithm is adopted to propagate the prior background labels to the rest of the pixels in an image. Finally, we refine the saliency map by taking both the textural and structure-information into consideration simultaneously. Experiments on publicly available data sets show that our proposed method achieves competitive results against the state-of-the-art approaches. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Jian, Muwei; Zhao, Runxia; Sun, Xin; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Luo, Hanjiang] Shandong Univ Sci & Technol, Sch Comp Sci & Technol, Qingdao, Peoples R China.
   [Zhang, Wenyin] Linyi Univ, Sch Informat Sci & Engn, Linyi, Peoples R China.
   [Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Yin, Yilong] Shandong Univ, Sch Software Engn, Jinan 250101, Shandong, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Shandong University of Finance & Economics; Ocean University of China;
   Shandong University of Science & Technology; Linyi University; Shandong
   Normal University; Shandong University; Hong Kong Polytechnic University
RP Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM jianmuweihk@163.com
RI Sun, Xin/ADH-1623-2022; Jian, Muwei/Q-8319-2018
OI Sun, Xin/0000-0003-1870-9037; Jian, Muwei/0000-0002-4249-2264; Luo,
   Hanjiang/0000-0001-6796-9658
FU National Natural Science Foundation of China (NSFC) [61601427, 61602229,
   61771230, 61573219]; Natural Science Foundation of Shandong Province
   [ZR2016FM40]; Shandong Provincial Key Research and Development Program
   of China [2017CXGC0701, 2017CXGC1504]; Fostering Project of Dominant
   Discipline and Talent Team of Shandong Province Higher Education
   Institutions
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61601427, 61602229, 61771230, 61573219); Natural Science
   Foundation of Shandong Province (ZR2016FM40); Shandong Provincial Key
   Research and Development Program of China (2017CXGC0701, 2017CXGC1504);
   Fostering Project of Dominant Discipline and Talent Team of Shandong
   Province Higher Education Institutions.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Aytekin CÇ, 2017, PATTERN RECOGN, V64, P159, DOI 10.1016/j.patcog.2016.11.005
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen SH, 2016, PATTERN RECOGN, V60, P2, DOI 10.1016/j.patcog.2016.05.016
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian M., 2018, AS PAC SIGN INF PROC
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2019, PATTERN RECOGN LETT, V127, P37, DOI 10.1016/j.patrec.2018.08.022
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Kong YQ, 2016, LECT NOTES COMPUT SC, V9910, P583, DOI 10.1007/978-3-319-46466-4_35
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li JX, 2018, PATTERN RECOGN LETT, V107, P114, DOI 10.1016/j.patrec.2017.08.014
   Li X, 2018, PATTERN RECOGN LETT, V101, P29, DOI 10.1016/j.patrec.2017.11.006
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li Y, 2010, LECT NOTES COMPUT SC, V6313, P790
   Liu AN, 2018, SIGNAL PROCESS, V152, P206, DOI 10.1016/j.sigpro.2018.06.001
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xi T, 2017, IEEE T IMAGE PROCESS, V26, P3425, DOI 10.1109/TIP.2016.2631900
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yan XY, 2017, J VIS COMMUN IMAGE R, V48, P224, DOI 10.1016/j.jvcir.2017.06.013
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhang CQ, 2015, PATTERN RECOGN LETT, V63, P66, DOI 10.1016/j.patrec.2015.06.012
   Zhang J, 2018, IEEE SIGNAL PROC LET, V25, P333, DOI 10.1109/LSP.2017.2748604
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 69
TC 15
Z9 16
U1 3
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 202
EP 211
DI 10.1016/j.jvcir.2018.11.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400024
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhu, XL
   Feng, XC
   Wang, WW
   Jia, XX
   Zhang, R
   He, RQ
   Xu, C
AF Zhu, Xiaolong
   Feng, Xiangchu
   Wang, Weiwei
   Jia, Xixi
   Zhang, Rui
   He, Ruiqiang
   Xu, Chen
TI HCLR: A hybrid clustering and low-rank regularization-based method for
   photon-limited image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Low rank; Poisson denoising; Newton's method
AB A photon-limited image can be represented as a pixel matrix limited by the relatively small number of collected photons. The image can also be seen as being contaminated by Poisson noise because the total number of photons follows the Poisson distribution. Through exploitation of the inherent properties of observation combined with application of a denoising method, an image can be significantly restored. In this paper, a hybrid clustering and low-rank regularization-based model (HCLR) is proposed based on the essential features of patch clustering and noise. An efficient Newton-type method is designed to optimize this biconvex problem. Experimental results demonstrate that HCLR achieves competitive denoising performance, especially for high noise levels, compared with state-of-the-art Poisson denoising algorithms. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhu, Xiaolong; Feng, Xiangchu; Wang, Weiwei; Jia, Xixi; Zhang, Rui; He, Ruiqiang] Xidian Univ, Sch Math & Stat, Xian 710071, Shaanxi, Peoples R China.
   [Xu, Chen] Shenzhen Univ, Shenzhen 518060, Guangdong, Peoples R China.
C3 Xidian University; Shenzhen University
RP Feng, XC (corresponding author), Xidian Univ, Sch Math & Stat, Xian 710071, Shaanxi, Peoples R China.
EM xcfeng@mail.xidian.edu.cn
RI Zhang, Yanchao/JMB-7717-2023; Zhu, Xiaolong/ACE-6241-2022; wang,
   weiwei/AAI-2245-2020; wu, yi/JEP-1581-2023
OI Zhu, Xiaolong/0000-0002-7350-2592; Wang, Weiwei/0000-0002-6985-2784
FU National Natural Science Foundation of China [61472303, 61271294,
   61772389]; Fundamental Research Funds for the Central Universities of
   China [NSIY21]; HD Video & R Platform for Intelligent Analysis and
   Processing of the Guangdong Engineering Technology Research Center of
   Colleges and University of China [GCZX-A1409]
FX The authors would like to thank the National Natural Science Foundation
   of China (Grants 61472303, 61271294, 61772389), the Fundamental Research
   Funds for the Central Universities of China (Grant NSIY21) and the HD
   Video & R Platform for Intelligent Analysis and Processing of the
   Guangdong Engineering Technology Research Center of Colleges and
   University of China (Grant GCZX-A1409) for supporting this research
   work.
CR [Anonymous], 2012, 2012 IEEE 27 CONV EL
   [Anonymous], PATTERN ANAL MACHINE
   [Anonymous], 2002, THESIS STANFORD U
   [Anonymous], FISZ TRANSFORMAT
   [Anonymous], P SPIE
   [Anonymous], 2006, A theoretical introduction to numerical analysis
   ANSCOMBE FJ, 1948, BIOMETRIKA, V35, P246, DOI 10.2307/2332343
   Boulanger J, 2010, IEEE T MED IMAGING, V29, P442, DOI 10.1109/TMI.2009.2033991
   Chan RH, 2007, INT J COMPUT MATH, V84, P1183, DOI 10.1080/00207160701450390
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.25
   Dong WS, 2012, ASIAPAC SIGN INFO PR
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Fisz M., 1955, Colloquium Mathematicum, V3, P138, DOI DOI 10.4064/CM-3-2-138-146
   Gil-Rodrigo E, 2011, IEEE IMAGE PROC, P1385, DOI 10.1109/ICIP.2011.6115697
   Giryes R, 2014, IEEE T IMAGE PROCESS, V23, P5057, DOI 10.1109/TIP.2014.2362057
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y
   Lebrun M, 2012, ACTA NUMER, V21, P475, DOI 10.1017/S0962492912000062
   Liu Hao., 2017, IEEE Trans. Circuits Syst. Video Technol.
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   Salmon J, 2012, INT CONF ACOUST SPEE, P1109, DOI 10.1109/ICASSP.2012.6288081
   Salmon J, 2014, J MATH IMAGING VIS, V48, P279, DOI 10.1007/s10851-013-0435-6
   Srebro N, 2005, LECT NOTES COMPUT SC, V3559, P545, DOI 10.1007/11503415_37
   Zhang XQ, 2012, J SCI COMPUT, V50, P519, DOI 10.1007/s10915-011-9533-z
NR 29
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 61
EP 68
DI 10.1016/j.jvcir.2018.10.015
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400008
DA 2024-07-18
ER

PT J
AU Wang, P
   Liu, FL
   Yang, CF
   Luo, XY
AF Wang, Ping
   Liu, Fenlin
   Yang, Chunfang
   Luo, Xiangyang
TI Blind forensics of image gamma transformation and its application in
   splicing detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind forensics; Gamma transformation; Manipulation detection; Splicing;
   Tampered area location
ID DOUBLE JPEG COMPRESSION; DIGITAL IMAGES; QUANTIZATION MATRIX
AB Image forensics technology based on image manipulation detection has aroused great interest of researchers in recent decades. By revealing the traces of image manipulations, it could contribute to the location of tampered areas. This paper addresses the detection of image gamma transformation and its application in image splicing detection. A 5-dimensional feature vector is constructed based on the effects of gamma transformation on the histogram, and then Support Vector Machine (SVM) is trained to detect gamma transformation. For splicing tampered area locating, the investigated image is divided into overlapping blocks based on the sliding window, and then each pixel gets a probability of being gamma transformed according to the detection results in image blocks, based on which the tampered area is located. The experimental results validate the effectiveness of the proposed method when no post-operations are applied. Meanwhile, the proposed method is robust to the attack of rank filtering.
C1 [Wang, Ping; Liu, Fenlin; Yang, Chunfang; Luo, Xiangyang] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Liu, FL (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM liufenlin@vip.sina.com
OI Wang, Ping/0000-0002-5849-810X
FU National Natural Science Foundation of China [61302159, 61379151,
   61272489, 61602508, 61772549, U1636219, U1736214]; National Key R&D
   Program of China [2016YFB0801303, 2016QY01W0105]; Key Technologies R&D
   Program of Henan Province [162102210032]; Key Science and Technology
   Research Project of Henan Province [152102210005]; Plan For Scientific
   Innovation Talent of Henan Province [2018JR0018]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61302159, 61379151, 61272489, 61602508,
   61772549, U1636219, and U1736214), the National Key R&D Program of China
   (Nos. 2016YFB0801303 and 2016QY01W0105), the Key Technologies R&D
   Program of Henan Province (No. 162102210032), the Key Science and
   Technology Research Project of Henan Province (No. 152102210005), and
   the Plan For Scientific Innovation Talent of Henan Province (No.
   2018JR0018).
CR Barni M, 2013, INT J DIGIT CRIME FO, V5, P35, DOI 10.4018/jdcf.2013070103
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Birajdar GK, 2014, AEU-INT J ELECTRON C, V68, P644, DOI 10.1016/j.aeue.2014.01.013
   Cao G., 2010, Journal of Information Hiding and Multimedia Signal Processing, V1, P20
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P25
   Cao G, 2010, IEEE IMAGE PROC, P2097, DOI 10.1109/ICIP.2010.5652701
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Hsiao DY, 2005, INT WORK SYS APPR D, P264, DOI 10.1109/SADFE.2005.8
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Liu GJ, 2013, MATH COMPUT MODEL, V57, P2647, DOI 10.1016/j.mcm.2011.06.026
   Liu QZ, 2017, PATTERN RECOGN, V65, P35, DOI 10.1016/j.patcog.2016.12.010
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Rhee KH, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053039
   Sarkar A, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P107
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1698, DOI 10.1109/ICASSP.2010.5495488
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Valera J., 2013, 2013 INT WORKSH BIOM, P1
   Wattanachote K, 2015, IEEE T INF FOREN SEC, V10, P2477, DOI 10.1109/TIFS.2015.2464776
   Wei JD, 2014, PATTERN RECOGN LETT, V36, P100, DOI 10.1016/j.patrec.2013.09.026
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhou LN, 2007, LECT NOTES ARTIF INT, V4496, P990
NR 35
TC 14
Z9 14
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 80
EP 90
DI 10.1016/j.jvcir.2018.05.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100008
DA 2024-07-18
ER

PT J
AU Kang, M
   Jung, M
   Kang, M
AF Kang, Myeongmin
   Jung, Miyoun
   Kang, Myungjoo
TI Rician denoising and deblurring using sparse representation prior and
   nonconvex total variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rician denoising; Deblurring; Sparse representation; Dictionary
   learning; Nonconvex total variation; Penalty method; Alternating
   minimization method
ID NOISE REMOVAL; K-SVD; IMAGE; ALGORITHM; OPTIMIZATION; MINIMIZATION;
   RESTORATION; TRANSFORM; EFFICIENT; RECOVERY
AB We propose a sparse representation based model to restore an image corrupted by blurring and Rician noise. Our model is composed of a nonconvex data-fidelity term and two regularization terms involving a sparse representation prior and a nonconvex total variation. The sparse representation prior, using image patches, provides restored images with well-preserved repeated patterns and small details, whereas the non-convex total variation enables the preservation of edges. Moreover, the regularization terms are mutually complementary in removing artifacts. To realize our nonconvex model, we adopt the penalty method and the alternating minimization method. The K-SVD algorithm is utilized for learning dictionaries. Numerical experiments demonstrate that the proposed model is superior to state-of-the-art models, in terms of visual quality and certain image quality measurements.
C1 [Kang, Myeongmin; Kang, Myungjoo] Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
   [Jung, Miyoun] Hankuk Univ Foreign Studies, Dept Math, Yongin, South Korea.
C3 Seoul National University (SNU); Hankuk University Foreign Studies
RP Kang, M (corresponding author), Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
EM wjdjr1@snu.ac.kr; mjung@hufs.ac.kr; mkang@snu.ac.kr
OI Kang, Myeongmin/0000-0003-1693-1582; Jung, Miyoun/0000-0001-7370-6651
FU National Research Foundation of Korea [2016R1C1B1009808,
   2015R1A5A1009350, 2017R1A2A1A17069644, 2017R1A2B1005363]; IITP-MSIT
   [B0717-16-0107]; Hankuk University of Foreign Studies Research Fund
FX Myeongmin Kang was supported by the National Research Foundation of
   Korea (2016R1C1B1009808). Myungjoo Kang was supported by the National
   Research Foundation of Korea (2015R1A5A1009350, 2017R1A2A1A17069644) and
   IITP-MSIT (B0717-16-0107). Miyoun Jung was supported by Hankuk
   University of Foreign Studies Research Fund and the National Research
   Foundation of Korea (2017R1A2B1005363).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aja-Fernandez Santiago, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4815
   [Anonymous], 2006, MATH PROBLEMS IMAGE
   [Anonymous], IMAGE PROCESSING ANA
   [Anonymous], 9756 UCLA CAM
   Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1
   Basu S, 2006, LECT NOTES COMPUT SC, V4190, P117
   BUCKLEY MJ, 1994, BIOMETRIKA, V81, P247, DOI 10.2307/2336955
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chan RH, 2010, IEEE T IMAGE PROCESS, V19, P1731, DOI 10.1109/TIP.2010.2045148
   Chen LY, 2015, J MATH IMAGING VIS, V53, P92, DOI 10.1007/s10851-014-0551-y
   Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Courant R., 1994, LECT NOTES PURE APPL, P1
   Csiszar I., 1984, STATISTICS DECISIO S, V1, P205
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Debnath A, 2013, INT J COMPUT APPL, V81, P7
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dong YQ, 2011, J MATH IMAGING VIS, V40, P82, DOI 10.1007/s10851-010-0248-9
   Donoho D., 2005, AUST NZ IND APPL MAT, V46, P29
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4
   Fletcher R., 1983, Math. Program. State Art, P87
   Foi A, 2011, I S BIOMED IMAGING, P1809, DOI 10.1109/ISBI.2011.5872758
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Getreuer Pascal, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P686
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Kang M, 2015, J VIS COMMUN IMAGE R, V32, P180, DOI 10.1016/j.jvcir.2015.08.006
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Li Y, 2016, APPL OPTICS, V55, P1814, DOI 10.1364/AO.55.001814
   Liu RW, 2014, MAGN RESON IMAGING, V32, P702, DOI 10.1016/j.mri.2014.03.004
   LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605
   Ma LY, 2013, SIAM J IMAGING SCI, V6, P2258, DOI 10.1137/120866452
   Ma LY, 2013, IEEE T MED IMAGING, V32, P1277, DOI 10.1109/TMI.2013.2255883
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Manjón JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003
   Martín A, 2017, J MATH IMAGING VIS, V57, P202, DOI 10.1007/s10851-016-0675-3
   Martín A, 2013, LECT NOTES COMPUT SC, V7950, P581, DOI 10.1007/978-3-642-39094-4_66
   Nesterov Y., 2004, INTRO LECT CONVEX OP, V87
   Ng MK, 1999, SIAM J SCI COMPUT, V21, P851, DOI 10.1137/S1064827598341384
   Nikolova M., IEEE T IMAGE PROCESS, P19
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Ochs P, 2015, SIAM J IMAGING SCI, V8, P331, DOI 10.1137/140971518
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Robini MC, 2007, IEEE T IMAGE PROCESS, V16, P2576, DOI 10.1109/TIP.2007.904975
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sun WY, 2003, J COMPUT MATH, V21, P451
   Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189
   Tristán-Vega A, 2012, COMPUT METH PROG BIO, V105, P131, DOI 10.1016/j.cmpb.2011.07.014
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
NR 61
TC 11
Z9 11
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 80
EP 99
DI 10.1016/j.jvcir.2018.04.010
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800008
DA 2024-07-18
ER

PT J
AU Silva, MM
   Ramos, WLS
   Chamone, FC
   Ferreira, JPK
   Campos, MFM
   Nascimento, ER
AF Silva, Michel M.
   Ramos, Washington L. S.
   Chamone, Felipe C.
   Ferreira, Joao P. K.
   Campos, Mario F. M.
   Nascimento, Erickson R.
TI Making a long story short: A multi-importance fast-forwarding egocentric
   videos with the emphasis on relevant objects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic information; First-person video; Fast-forward; Egocentric
   stabilization
AB The emergence of low-cost high-quality personal wearable cameras combined with the increasing storage capacity of video-sharing websites have evoked a growing interest in first-person videos, since most videos are composed of long-running unedited streams which are usually tedious and unpleasant to watch. State-of-the-art semantic fast-forward methods currently face the challenge of providing an adequate balance between smoothness in visual flow and the emphasis on the relevant parts. In this work, we present the Multi-Importance Fast-Forward (MIFF), a fully automatic methodology to fast-forward egocentric videos facing these challenges. The dilemma of defining what is the semantic information of a video is addressed by a learning process based on the preferences of the user. Results show that the proposed method keeps over 3 times more semantic content than the state-of-the-art fast-forward. Finally, we discuss the need of a particular video stabilization technique for fast-forward egocentric videos(1).
C1 [Silva, Michel M.; Ramos, Washington L. S.; Chamone, Felipe C.; Ferreira, Joao P. K.; Campos, Mario F. M.; Nascimento, Erickson R.] Ave Pres Antonio Carlos 6627, Belo Horizonte, MG, Brazil.
RP Silva, MM (corresponding author), Ave Pres Antonio Carlos 6627, Belo Horizonte, MG, Brazil.
EM michelms@dcc.ufmg.br; washington.ramos@dcc.ufmg.br; cadar@dcc.ufmg.br;
   joaoklock@dcc.ufmg.br; mario@dcc.ufmg.br; erickson@dcc.ufmg.br
RI Nascimento, Erickson R./G-5374-2014; de Souza Ramos, Washington
   Luis/AAH-7330-2019; Campos, Mario/AAU-1799-2020; de Souza Ramos,
   Washington Luis/JBJ-7614-2023; Campos, Mario/C-4647-2013
OI Nascimento, Erickson R./0000-0003-2973-2232; Chamone, Felipe
   Cadar/0000-0003-1707-5984; Campos, Mario/0000-0002-8336-9190; Klock
   Ferreira, Joao Pedro/0000-0002-4445-9847; Silva,
   Michel/0000-0002-2499-9619; Ramos, Washington/0000-0002-0411-8677
FU CAPES; CNPq; FAPEMIG; Petrobras
FX The authors would like to thank the agencies CAPES, CNPq, FAPEMIG, and
   Petrobras for funding different parts of this work.
CR [Anonymous], TECHNOLOGY HYPERLAPS
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], IEEE T MULTIM
   [Anonymous], CORR
   [Anonymous], IEEE T HUMAN MACH SY
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C IM PROC O
   [Anonymous], IEEE INT CONF MULT
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 1995, 1995 IEEE INT C
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Gemmell J., 2002, P 10 ACM INT C MULTI, P235, DOI DOI 10.1145/641007.641053
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Higuch K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6536, DOI 10.1145/3025453.3025821
   Joshi N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766954
   Kopf J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601195
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Lin YL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P443, DOI 10.1109/ICCVW.2015.65
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Marvaniya S, 2016, IEEE IMAGE PROC, P176, DOI 10.1109/ICIP.2016.7532342
   Melo Silva Michel, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P557, DOI 10.1007/978-3-319-46604-0_40
   Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Poleg Y, 2015, PROC CVPR IEEE, P4768, DOI 10.1109/CVPR.2015.7299109
   Poleg Y, 2014, PROC CVPR IEEE, P2537, DOI 10.1109/CVPR.2014.325
   Ramos WLS, 2016, IEEE IMAGE PROC, P3334, DOI 10.1109/ICIP.2016.7532977
   Song XL, 2016, ENC BET EAST WEST, P1, DOI 10.1007/978-3-662-47056-5_1
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Xiong B, 2015, IEEE I CONF COMP VIS, P4525, DOI 10.1109/ICCV.2015.514
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhou BL, 2014, ADV NEUR IN, V27
NR 32
TC 8
Z9 8
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 55
EP 64
DI 10.1016/j.jvcir.2018.02.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, LB
   Peng, F
   Qin, L
   Long, M
AF Zhang, Le-Bing
   Peng, Fei
   Qin, Le
   Long, Min
TI Face spoofing detection based on color texture Markov feature and
   support vector machine recursive feature elimination
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face anti-spoofing; Color texture Markov feature; Adjacent facial pixels
   discrepancy; SVM-RFE
ID RECOGNITION; ATTACKS; IMAGE
AB Aiming to counterstrike face spoofing attacks such as photo attacks and video attacks, a face spoofing detection scheme based on color texture Markov feature (CTMF) and support vector machine recursive feature elimination (SVM-RFE) is proposed. In this paper, the adjacent facial pixels discrepancy between the real and the fake face is analyzed, and texture information between the color channels is fully considered. Firstly, the directional difference filter is used to capture the facial texture difference between the real and the fake face, which can be regarded as low-level features of CTMF. Then, the facial texture difference is modeled by the Markov process to form a high-level representation of the low-level features. Meanwhile, the mutual information of facial texture between the color channels, which is ignored in the previous literature, is investigated. In addition, SVM-RFE is utilized to reduce the feature dimension and makes it suitable for real-time detection. Experiments on four public benchmark databases indicate that the proposed scheme can effectively resist photo and video spoofing attacks in face recognition.
C1 [Zhang, Le-Bing; Peng, Fei; Qin, Le] Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410112, Hunan, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM zhanglebing@hnu.edu.cn; eepengf@gmail.com; qinle@hnu.edu.cn;
   caslongm@gmail.com
RI Zhang, Le-Bing/AHA-1060-2022; Long, Min/AGW-6059-2022; Bueno, Regis
   Cortez/AAG-3852-2020; Peng, Fei/H-6951-2017
OI Bueno, Regis Cortez/0000-0002-2923-4930; Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [61572182, 61370225]; Hunan
   Provincial Natural Science Foundation of China [15JJ2007]
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant Nos. 61572182, 61370225), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No. 15JJ2007).
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Anjos Andre, 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], 2014, LEARN CONVOLUTIONAL
   [Anonymous], ENCY BIOMETR
   [Anonymous], ISO IEC JTC 1 SC 3 1
   [Anonymous], 2013, 2013 INT C BIOMETRIC, DOI DOI 10.1109/ICB.2013.6612968
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], PSDK ACQUIRED GOOGLE
   [Anonymous], COLOR IMAGE PROCESSI
   [Anonymous], IEEE INT C AUT FAC G
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Bharadwaj Samarth., 2014, Face anti-spoofing via motion magnification and multifeature videolet aggregation
   Biggio B, 2017, IEEE T PATTERN ANAL, V39, P561, DOI 10.1109/TPAMI.2016.2558154
   Boulkenafet Z, 2016, INT CONF BIOMETR
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chao Zhu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3065, DOI 10.1109/ICPR.2010.751
   Chingovska Ivana, 2012, BIOSIG
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Ding X., 2017, IEEE T VEH TECHNOL, P1
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Jinggang Huang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P541, DOI 10.1109/CVPR.1999.786990
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Li Y, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1558, DOI 10.1145/2810103.2813612
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Menotti David, 2015, IEEE Transactions on Information Forensics and Security, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peng F., 2017, MULTIMEDIA TOOLS APP, P1
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Sun XD, 2016, INT C PATT RECOG, P4262, DOI 10.1109/ICPR.2016.7900303
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007
   Yang JS, 2013, IEEE GLOB COMM CONF, P1, DOI 10.1109/GLOCOM.2013.6831038
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 49
TC 50
Z9 53
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 56
EP 69
DI 10.1016/j.jvcir.2018.01.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500006
DA 2024-07-18
ER

PT J
AU Lu, X
   Martin, GR
AF Lu, Xin
   Martin, Graham R.
TI Improved macroblock level rate control for the spatially scalable
   extension of H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interlayer prediction; MAD prediction; Rate control; Scalable video
   coding
ID RATE CONTROL SCHEME; COMMUNICATION; SCALABILITY; NETWORKS
AB An improved rate control algorithm, designed for scalable video coders incorporating interlayer prediction, is proposed. Firstly, a Rate Distortion (RD) model for interlayer prediction involving the spatial enhancement layers is devised. An optimised Mean Absolute Difference (MAD) prediction model for the spatial enhancement layers that considers both the MAD from the spatial base layer in the same frame and the MAD from the corresponding macroblock in previous frames is also proposed. Simulation results show that the resulting algorithm produces accurate rate control with an average bit rate error of less than 0.26%. Compared with the JVT-W043 default rate control algorithm of the JSVM, the proposed algorithm improves the average PSNR by up to 0.53 dB or reduces the bit rate by an average of 10.95%. Furthermore, the proposed algorithm can be combined with the existing rate control scheme for H.264/AVC, resulting in further improvements. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Lu, Xin] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Martin, Graham R.] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
C3 Harbin Institute of Technology; University of Warwick
RP Lu, X (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM Xin@hit.edu.cn; G.R.Martin@warwick.ac.uk
OI Lu, Xin/0000-0001-6470-8022
FU National Natural Science Foundation of China (NSFC) [61401123,
   61501146]; Fundamental Research Funds for the Central Universities
   [HIT.NSRIF.201617]; Harbin Science and Technology Bureau [2014RFQXJ166]
FX This work has been supported by the National Natural Science Foundation
   of China (NSFC) under Projects Nos. 61401123 and 61501146, the
   Fundamental Research Funds for the Central Universities under Grant No.
   HIT.NSRIF.201617, and the Harbin Science and Technology Bureau under
   Project No. 2014RFQXJ166.
CR [Anonymous], 2010, 14496MPEG4 ISOIEC 10
   Bjolntegaard G., 2001, CALCULATION AVERAGE
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   DURRETT R., 2010, PROBABILITY THEORY E
   Gardos T., 1997, VIDEO CODEC TEST MOD
   Hu H, 2013, IEEE T MULTIMEDIA, V15, P1638, DOI 10.1109/TMM.2013.2266092
   Hu S., IEEE T CIRC SYST VID, V21
   Hu SD, 2012, IEEE T IND ELECTRON, V59, P1673, DOI 10.1109/TIE.2011.2157282
   Kelly FP, 1998, J OPER RES SOC, V49, P237, DOI 10.2307/3010473
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Leontaris A., 2007, Rate control for the joint scalable 638 video model (jsvm)
   Li XA, 2011, IEEE T BROADCAST, V57, P66, DOI 10.1109/TBC.2010.2082370
   Li Z., 2003, P JOINT VID TEAM JVT
   Lie Xu., 2007, IEEE Power engineering society general meeting, P1
   Liu JY, 2010, IEEE T CIRC SYST VID, V20, P967, DOI 10.1109/TCSVT.2010.2045924
   Liu Y, 2007, IEEE INT SYMP CIRC S, P1746, DOI 10.1109/ISCAS.2007.378009
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P116, DOI 10.1109/TCSVT.2007.903325
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   MA S, 2003, PROPOSED DRAFT ADAPT
   MA SW, 2002, PROPOSED DRAFT DESCR
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Mansour H, 2011, IEEE T MULTIMEDIA, V13, P165, DOI 10.1109/TMM.2010.2099648
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Sanz-Rodríguez S, 2012, IEEE T CIRC SYST VID, V22, P1199, DOI 10.1109/TCSVT.2012.2198089
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Test Model Editing Committee, 1993, MPEG 2 VID TEST MOD
   V. Group, 1997, MPEG 4 VID VER MOD V
   Wien M., 2005, TESTING CONDITIONS S
   Xu L, 2005, PROC SPIE, V5960, P525, DOI 10.1117/12.631424
   Zhang R, 2010, IEEE T IMAGE PROCESS, V19, P2947, DOI 10.1109/TIP.2010.2051624
NR 31
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 205
EP 223
DI 10.1016/j.jvcir.2017.05.014
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700017
DA 2024-07-18
ER

PT J
AU Huang, X
   Sogaard, J
   Forchhammer, S
AF Huang, Xin
   Sogaard, Jacob
   Forchhammer, Soren
TI No-reference pixel based video quality assessment for HEVC decoded video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC analysis; No-reference; Video quality assessment; Machine learning;
   Elastic net
ID REFERENCE PSNR ESTIMATION; INFORMATION
AB This paper proposes a No-Reference (NR) Video Quality Assessment (VQA) method for videos subject to the distortion given by the High Efficiency Video Coding (HEVC) scheme. The assessment is performed without access to the bitstream. The proposed analysis is based on the transform coefficients estimated from the decoded video pixels, which is used to estimate the level of quantization. The information from this analysis is exploited to assess the video quality. HEVC transform coefficients are modeled with a joint-Cauchy probability density function in the proposed method. To generate VQA features the quantization step used in the Intra coding is estimated. We map the obtained HEVC features using an Elastic Net to predict subjective video quality scores, Mean Opinion Scores (MOS). The performance is verified on a dataset consisting of HEVC coded 4 K UHD (resolution equal to 3840 x 2160) video sequences at different bitrates and spanning a wide range of content. The results show that the quality scores computed by the proposed method are highly correlated with the mean subjective assessments. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Huang, Xin; Sogaard, Jacob; Forchhammer, Soren] Tech Univ Denmark, DTU Photon, Orsteds Plads 343, DK-2800 Lyngby, Denmark.
C3 Technical University of Denmark
RP Forchhammer, S (corresponding author), Tech Univ Denmark, DTU Photon, Orsteds Plads 343, DK-2800 Lyngby, Denmark.
EM jsog@fotonik.dtu.dk; sofo@fotonik.dtu.dk
OI Forchhammer, Soren/0000-0002-6698-8870
FU SVCF Grant from the Cisco University Research Program Fund [117983]
FX This work was supported in part by SVCF Grant 117983 from the Cisco
   University Research Program Fund.
CR Altunbasak Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P177
   [Anonymous], 2010, P 2 ACM WORKSHOP MUL
   [Anonymous], SG16 ITUT
   Bae SH, 2013, IEEE T BROADCAST, V59, P209, DOI 10.1109/TBC.2013.2247171
   Bi J., 2003, Journal of Machine Learning Research, V3, P1229, DOI 10.1162/153244303322753643
   Brandao T, 2010, IEEE T CIRC SYST VID, V20, P1437, DOI 10.1109/TCSVT.2010.2077474
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   Forchhammer S, 2011, J VIS COMMUN IMAGE R, V22, P313, DOI 10.1016/j.jvcir.2011.01.006
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Huang X., 2015, IEEE INT C VIS COMM
   International Telecommunication Union (ITU), 1999, ITU T REC P 910 SUBJ
   Jiang QP, 2015, J VIS COMMUN IMAGE R, V33, P123, DOI 10.1016/j.jvcir.2015.09.009
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Le Callet P, 2006, IEEE T NEURAL NETWOR, V17, P1316, DOI 10.1109/TNN.2006.879766
   Lee B, 2013, IEEE T BROADCAST, V59, P20, DOI 10.1109/TBC.2012.2226533
   Li YM, 2016, IEEE T CIRC SYST VID, V26, P1044, DOI 10.1109/TCSVT.2015.2430711
   Lin TL, 2015, J VIS COMMUN IMAGE R, V32, P257, DOI 10.1016/j.jvcir.2015.03.008
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Na T, 2014, IEEE T CIRC SYST VID, V24, P320, DOI 10.1109/TCSVT.2013.2255425
   Narwaria M, 2012, IEEE T MULTIMEDIA, V14, P525, DOI 10.1109/TMM.2012.2190589
   Oelbaum Tobias, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1265
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shahid M, 2015, INT WORK QUAL MULTIM
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sjostrand K., 2012, J STAT SOFTWARE
   Sogaard J., 2015, IEEE INT WORKSH QUAL
   Sogaard J, 2015, IEEE T CIRC SYST VID, V25, P1637, DOI 10.1109/TCSVT.2015.2397207
   Sogaard J, 2013, PICT COD SYMP, P161, DOI 10.1109/PCS.2013.6737708
   Song L., 2013, IEEE INT WORKSH QUAL
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tubaro S., 2012, IEEE INT C AC SPEECH
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Wallendael G. V., 2012, IEEE INT WORKSH QUAL
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Wu QB, 2015, IEEE IMAGE PROC, P339, DOI 10.1109/ICIP.2015.7350816
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yang Peng, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2517, DOI 10.1109/ICIP.2011.6116174
   Zhang F, 2014, J VIS COMMUN IMAGE R, V25, P542, DOI 10.1016/j.jvcir.2013.11.011
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhu KF, 2015, IEEE T CIRC SYST VID, V25, P533, DOI 10.1109/TCSVT.2014.2363737
   Zhu KF, 2013, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2013.6738011
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 52
TC 16
Z9 16
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 173
EP 184
DI 10.1016/j.jvcir.2017.01.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400017
DA 2024-07-18
ER

PT J
AU Srivastava, P
   Khare, A
AF Srivastava, Prashant
   Khare, Ashish
TI Integration of wavelet transform, Local Binary Patterns and moments for
   content-based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Discrete wavelet transform; Local Binary Pattern;
   Legendre moments
ID FEATURES; REPRESENTATION; DESCRIPTOR; COLOR; SHAPE
AB The proliferation of large number of images has made it necessary to develop systems for indexing and organizing images for easy access. This has made Content-Based Image Retrieval (CBIR) an important area of research in Computer Vision. This paper proposes a combination of features in multiresolution analysis framework for image retrieval. In this work, the concept of multiresolution analysis has been exploited through the use of wavelet transform. This paper combines Local Binary Pattern (LBP) with Legendre Moments at multiple resolutions of wavelet decomposition of image. First, LBP codes of Discrete Wavelet Transform (DWT) coefficients of images are computed to extract texture feature from image. The Legendre Moments of these LBP codes are then computed to extract shape feature from texture feature for constructing feature vectors. These feature vectors are used to search and retrieve visually similar images from large database. The proposed method has been tested on five benchmark datasets, namely, Corel-1K, Olivia-2688, Corel-5K, Corel-10K, and GHIM-10K, and performance of the proposed method has been measured in terms of precision and recall. The expetimental results demonstrate that the proposed method outperforms some of the other state-of-the-art methods in terms of precision and recall. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Srivastava, Prashant; Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
C3 University of Allahabad
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
EM prashantjk087@gmail.com; ashishkhare@hotmail.com
RI Srivastava, Prashant/V-5825-2019; Khare, Ashish/D-4566-2012
OI Srivastava, Prashant/0000-0002-5812-2022
CR Agarwal M, 2012, INT J MULTIMED INF R, V1, P129, DOI 10.1007/s13735-012-0005-5
   Feng L, 2015, J VIS COMMUN IMAGE R, V33, P104, DOI 10.1016/j.jvcir.2015.09.002
   Forsyth D., 2002, Computer Vision: A Modern Approach
   Fu X, 2006, INT C PATT RECOG, P417
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Huang J., 2001, US Patent, Patent No. [6,246,790, 6246790]
   Khare M, 2015, SIGNAL IMAGE VIDEO P, V9, P635, DOI 10.1007/s11760-013-0496-4
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2015, AER ADV ENG RES, V22, P838
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Long F., 2003, MULTIMEDIA INF RETRI
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nigam S, 2015, MULTIMED TOOLS APPL, V74, P7037, DOI 10.1007/s11042-014-1951-0
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   Srivastava P, 2014, 2 INT C CONT AW SYST, P228, DOI DOI 10.1007/978-3-319-05939-6_23
   Srivastava P, 2014, INT CONF CONTR AUTO, P159, DOI 10.1109/ICCAIS.2014.7020550
   Srivastava P, 2014, MOBILE NETW APPL, V19, P618, DOI 10.1007/s11036-014-0526-7
   Suhasini P. S., 2009, Journal of Theoretical and Applied Information Technology, V6, P116
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M., 2015, NEUROCOMPUTING
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2012, MYCOPATHOLOGIA, V173, P295, DOI 10.1007/s11046-011-9484-9
   Wu Y., 2009, 2 INT C IM SIGN PROC
   Xia Y, 2013, LECT NOTES COMPUT SC, V8210, P423, DOI 10.1007/978-3-319-02750-0_45
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang C., 2014, ELECTRON LETT, V50, P367
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zhang M, 2014, J VIS COMMUN IMAGE R, V25, P1574, DOI 10.1016/j.jvcir.2014.06.016
NR 40
TC 58
Z9 58
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 78
EP 103
DI 10.1016/j.jvcir.2016.11.008
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200007
DA 2024-07-18
ER

PT J
AU Pan, ZQ
   Jin, P
   Lei, JJ
   Zhang, Y
   Sun, XM
   Kwong, S
AF Pan, Zhaoqing
   Jin, Peng
   Lei, Jianjun
   Zhang, Yun
   Sun, Xingming
   Kwong, Sam
TI Fast reference frame selection based on content similarity for low
   complexity HEVC encoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reference frame; Prediction unit; Early termination; HEVC; Video coding
ID MOTION ESTIMATION; MODE DECISION; CODING EFFICIENCY
AB The high efficiency video coding (HEVC) is the state-of-the-art video coding standard, which achieves about 50% bit rate saving while maintaining the same visual quality as compared to the H.264/AVC. This achieved coding efficiency benefits from a set of advanced coding tools, such as the multiple reference frames (MRF) based interframe prediction, which efficiently improves the coding efficiency of the HEVC encoder, while it also increases heavy computation into the HEVC encoder. The high encoding complexity becomes a bottleneck for the high definition videos and HEVC encoder to be widely used in real-time and low power multimedia applications. In this paper, we propose a content similarity based fast reference frame selection algorithm for reducing the computational complexity of the multiple reference frames based interframe prediction. Based the large content similarity between the parent prediction unit (Inter_2N x 2N) and the children prediction units (Inter_2N x N, Inter_N x 2N, Inter N x N, Inter_2N x nU, Inter 2N x nD, Inter_nL x 2N, and Inter_nR x 2N), the reference frame selection information of the children prediction units are obtained by learning the results of their parent prediction unit. Experimental results show that the proposed algorithm can reduce about 54.29% and 43.46% MRF encoding time saving for the low-delay-main and random-access-main coding structures, respectively, while the rate distortion performance degradation is negligible. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pan, Zhaoqing; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Jin, Peng; Lei, Jianjun] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Nanjing University of Information Science & Technology; Tianjin
   University; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS; City University of Hong Kong
RP Lei, JJ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM zqpan3-c@my.cityu.edu.hk; qustjinpeng@163.com; jjlei@tju.edu.cn;
   yun.zhang@siat.ac.cn; sunnudt@163.com; cssamk@cityu.edu.hk
RI Zhang, Yun/V-7261-2019; Lei, Jianjun/P-2539-2018; Sun,
   Xingming/AAD-1866-2019; Jin, Peng/IAP-3718-2023; Kwong, Sam/C-9319-2012
OI Zhang, Yun/0000-0001-9457-7801; Jin, Peng/0000-0002-4440-5240; Kwong,
   Sam/0000-0001-7484-7261
FU National Natural Science Foundation of China [61501246, 61271324,
   61471348, 61232016]; Natural Science Foundation of Jiangsu Province of
   China [BK20150930]; Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China [15KJB510019]; Natural Science
   Foundation of Hebei Province of China [F2015202311]; Project through the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions; Startup Foundation for Introducing Talent of Nanjing
   University of Information Science and Technology [2015r012]; Guangdong
   Natural Science Funds for Distinguished Young Scholar [2016A030306022]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61501246, Grant 61271324, Grant
   61471348, Grant 61232016, in part by the Natural Science Foundation of
   Jiangsu Province of China under Grant BK20150930, in part by the Natural
   Science Foundation of the Jiangsu Higher Education Institutions of China
   under Grant 15KJB510019, in part by the Natural Science Foundation of
   Hebei Province of China under Grant F2015202311, in part by the Project
   through the Priority Academic Program Development of Jiangsu Higher
   Education Institutions, in part by the Startup Foundation for
   Introducing Talent of Nanjing University of Information Science and
   Technology under Grant 2015r012, in part by the Guangdong Natural
   Science Funds for Distinguished Young Scholar under Grant
   2016A030306022.
CR [Anonymous], 2014, SCI WORLD J, DOI [DOI 10.1155/2014/305452, DOI 10.4174/ASTR.2014.86.4.199.]]
   [Anonymous], P ICIP
   [Anonymous], JCTVCN1010 ITUTISOIE
   [Anonymous], JCTVCJ1100 ITUTISOIE
   [Anonymous], JCTVCD600 ITUTISOIEC
   [Anonymous], 2001, ITU T VCEG M AUST TE
   Chen JW, 2013, J VIS COMMUN IMAGE R, V24, P1443, DOI 10.1016/j.jvcir.2013.10.003
   Chen MJ, 2006, IEEE T MULTIMEDIA, V8, P478, DOI 10.1109/TMM.2006.870739
   Hanhart P, 2014, J VIS COMMUN IMAGE R, V25, P555, DOI 10.1016/j.jvcir.2013.11.008
   Jun D, 2010, IEEE T CIRC SYST VID, V20, P1156, DOI 10.1109/TCSVT.2010.2057016
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Lei JJ, 2015, IEEE T IND INFORM, V11, P978, DOI 10.1109/TII.2015.2446769
   Liu ZY, 2008, IEEE T CIRC SYST VID, V18, P620, DOI 10.1109/TCSVT.2008.918844
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2016, IET IMAGE PROCESS, V10, P9, DOI 10.1049/iet-ipr.2014.1018
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Su YP, 2006, IEEE T CIRC SYST VID, V16, P447, DOI 10.1109/TCSVT.2006.869970
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wang HL, 2014, J VIS COMMUN IMAGE R, V25, P1784, DOI 10.1016/j.jvcir.2014.08.007
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang Y, 2011, IEEE T BROADCAST, V57, P15, DOI 10.1109/TBC.2010.2082670
NR 27
TC 87
Z9 91
U1 0
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 516
EP 524
DI 10.1016/j.jvcir.2016.07.018
PN B
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600010
DA 2024-07-18
ER

PT J
AU Tamrakar, D
   Khanna, P
AF Tamrakar, Deepti
   Khanna, Pritee
TI Kernel discriminant analysis of Block-wise Gaussian Derivative Phase
   Pattern Histogram for palmprint recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Region of Interest; Gaussian derivative filter; Kernel discriminant
   analysis; Multispectral palmprint; Score level fusion
ID PALM-PRINT RECOGNITION; LEVEL FUSION; GRAY-SCALE; IDENTIFICATION;
   VERIFICATION; EXTRACTION; WAVELET; REPRESENTATION; ALGORITHM; SELECTION
AB This paper presents an efficient palmprint recognition technique for palmprints collected with visible as well as multispectral imaging system. ROI extraction is a challenging task for palmprint captured in unconstrained environment. ROI extracted by gaps between fingers and width of palm makes system rotation and translation invariant. Approximation ROI obtained by First-level decomposition of ROI using Haar wavelet reduces computational overhead as well as noise. Phase quantization of AROI by Gaussian derivative filter gives Gaussian derivative phase pattern image and its block-wise histograms are concatenated to form a single vector referred as BGDPPH descriptor. Dimension reduction is performed by increasing discrimination between genuine and impostor scores using chi-RBF kernel discriminant analysis (KDA). Weighted score level fusion of spectral palmprints on Fisher criterion improves recognition rate. Robustness of the proposed BGDPPH descriptor against blur and noise is evaluated on four gray scale and two multispectral palmprint databases collected through touch-based and touch-less acquisition devices. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tamrakar, Deepti; Khanna, Pritee] Pandit Dwarka Prasad Mishra Indian Inst Informat, Design & Mfg, Dumna Airport Rd,PO Khamaria, Jabalpur 482005, Madhya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Khanna, P (corresponding author), Pandit Dwarka Prasad Mishra Indian Inst Informat, Design & Mfg, Dumna Airport Rd,PO Khamaria, Jabalpur 482005, Madhya Pradesh, India.
EM pkhanna@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019; Tamrakar, Deepti/G-7861-2019
OI Khanna, Pritee/0000-0003-0518-2133; Tamrakar, Deepti/0000-0002-4591-2156
CR [Anonymous], 1999, IEEE SIGN PROC SOC W
   Badrinath GS, 2012, FUTURE GENER COMP SY, V28, P287, DOI 10.1016/j.future.2010.11.029
   Bin Mansoor A, 2011, J NETW COMPUT APPL, V34, P159, DOI 10.1016/j.jnca.2010.08.004
   Bouchemha A, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043005
   Cui JR, 2013, OPTIK, V124, P3067, DOI 10.1016/j.ijleo.2012.09.030
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Guo ZH, 2012, IEEE T INF FOREN SEC, V7, P1094, DOI 10.1109/TIFS.2012.2189206
   Guo ZH, 2010, IEEE IMAGE PROC, P4521, DOI 10.1109/ICIP.2010.5653119
   Guo ZH, 2011, PATTERN RECOGN LETT, V32, P120, DOI 10.1016/j.patrec.2010.09.026
   Han D., 2008, 9 INT C SIGN PROC, P2074
   Hanmandlu M, 2011, PATTERN RECOGN LETT, V32, P1843, DOI 10.1016/j.patrec.2011.06.029
   Hong DF, 2015, NEUROCOMPUTING, V151, P511, DOI 10.1016/j.neucom.2014.09.013
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Imtiaz H, 2013, COMPUT ELECTR ENG, V39, P1114, DOI 10.1016/j.compeleceng.2013.01.006
   Imtiaz H, 2013, DIGIT SIGNAL PROCESS, V23, P244, DOI 10.1016/j.dsp.2012.06.016
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Jia W, 2014, IEEE T SYST MAN CY-S, V44, P385, DOI 10.1109/TSMC.2013.2258010
   Jinyu Guo, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1909, DOI 10.1109/CISP.2010.5647597
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Kumar A., IIT DELHI TOUCHLESS
   Laadjel M, 2015, NEUROCOMPUTING, V152, P179, DOI 10.1016/j.neucom.2014.11.005
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Michael GKO, 2012, J VIS COMMUN IMAGE R, V23, P1068, DOI 10.1016/j.jvcir.2012.07.004
   Mu MR, 2011, NEUROCOMPUTING, V74, P3351, DOI 10.1016/j.neucom.2011.05.026
   Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan X, 2009, NEUROCOMPUTING, V72, P2040, DOI 10.1016/j.neucom.2008.11.019
   Raghavendra R, 2014, PATTERN RECOGN, V47, P2205, DOI 10.1016/j.patcog.2013.12.011
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sun Z., 2005, CASIA PALMPRINT DATA
   Tamrakar D., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P20, DOI 10.1109/CICN.2010.15
   Tamrakar D., 2014, 9 INT C IND INF SYST, P1
   Tamrakar D, 2015, PROCEDIA COMPUT SCI, V54, P491, DOI 10.1016/j.procs.2015.06.056
   Wang X, 2012, KNOWL-BASED SYST, V27, P451, DOI 10.1016/j.knosys.2011.10.008
   Xiao X., 2010, Power Electronics, Drives and Energy Systems (PEDES) 2010 Power India, 2010 Joint International Conference on, P1
   Ying T.T. Hao, 2007, CASIA MS PALMPRINTV1
   Yue F, 2009, PATTERN RECOGN, V42, P2841, DOI 10.1016/j.patcog.2009.03.015
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D., POLYU PALMPR DAT
   Zhang D., 2011, POLYU MULTISPECTRAL
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang SW, 2013, OPTIK, V124, P5434, DOI 10.1016/j.ijleo.2013.03.133
   Zuo WM, 2011, PATTERN RECOGN, V44, P964, DOI 10.1016/j.patcog.2010.09.017
   Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909
NR 51
TC 26
Z9 27
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 432
EP 448
DI 10.1016/j.jvcir.2016.07.008
PN B
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600004
DA 2024-07-18
ER

PT J
AU Xiong, TS
   Huang, YY
   Gou, JP
   Hu, JR
AF Xiong, Taisong
   Huang, Yuanyuan
   Gou, Jianping
   Hu, Jinrong
TI A unified Bayesian mixture model framework via spatial information for
   grayscale image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatially variant finite mixture model; Bayesian framework; Gaussian
   distribution; Student's t-distribution; Grayscale image segmentation;
   Expectation-maximization algorithm
AB Because of the Student-t distribution owning heavier tailed than the Gaussian distribution, under a Bayesian framework, a spatially variant finite mixture model with Student's t-distribution component function is proposed for grayscale image segmentation. To avoid additional computational step and improve the efficiency of the proposed model, a representation of contextual mixing proportion is adopted. Secondly, the spatial information of the pixels is closely related to the Gaussian distribution of their neighborhood system. Thirdly, the inherent relationship between the Gaussian distribution and the Student's t-distribution is adopted to optimize the unknown parameters of the proposed model, which simplifies the inference process and makes the proposed model to be easily implemented. Comprehensive experiments on synthetic noise images, simulated medical images and real-world grayscale images are presented to illustrate the superior performance of the proposed model in terms of the visual and quantitative comparison. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xiong, Taisong; Huang, Yuanyuan] Chengdu Univ Informat Technol, Chengdu 610225, Sichuan, Peoples R China.
   [Xiong, Taisong; Huang, Yuanyuan] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Gou, Jianping] JiangSu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Hu, Jinrong] Xihua Univ, Sch Comp & Soft Engn, Chengdu 610039, Peoples R China.
C3 Chengdu University of Information Technology; University of Electronic
   Science & Technology of China; Jiangsu University; Xihua University
RP Huang, YY (corresponding author), Chengdu Univ Informat Technol, Chengdu 610225, Sichuan, Peoples R China.; Huang, YY (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
EM iyyhuang@hotmail.com
RI Gou, Jianping/JQX-2453-2023
OI Gou, Jianping/0000-0003-1413-0693
FU National Nature Science Foundation of China [61502208, 61303126];
   Applied Basic Research Program of Sichuan Province [2014JY0168];
   Foundation of Chengdu University of Information Technology [KYTZ201426]
FX The authors would like to thank the anonymous reviewers for their
   thorough and valuable comments and suggestions, which greatly helped to
   improve both the technical content and the presentation quality of this
   paper. This work was supported by National Nature Science Foundation of
   China under Grant No. 61502208 and 61303126, and the Applied Basic
   Research Program of Sichuan Province (No. 2014JY0168), and Foundation of
   Chengdu University of Information Technology (No. KYTZ201426).
CR [Anonymous], EM ALGORITHM EXTENSI
   Aubert-Broche B, 2006, IEEE T MED IMAGING, V25, P1410, DOI 10.1109/TMI.2006.883453
   Aubert-Broche B, 2006, NEUROIMAGE, V32, P138, DOI 10.1016/j.neuroimage.2006.03.052
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Chatzis SP, 2008, IEEE T SIGNAL PROCES, V56, P949, DOI 10.1109/TSP.2007.907912
   Chatzis SP, 2011, PATTERN RECOGN, V44, P295, DOI 10.1016/j.patcog.2010.09.001
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Constantinopoulos C, 2006, IEEE T PATTERN ANAL, V28, P1013, DOI 10.1109/TPAMI.2006.111
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Diplaros A, 2007, IEEE T NEURAL NETWOR, V18, P798, DOI 10.1109/TNN.2007.891190
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Han J, 2012, MOR KAUF D, P1
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li S. Z., 2009, Markov random field modeling in image analysis
   Luenberger DG, 2016, INT SER OPER RES MAN, V228, P1, DOI 10.1007/978-3-319-18842-3
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Nguyen TM, 2010, IEEE T NEURAL NETWOR, V21, P1326, DOI 10.1109/TNN.2010.2054109
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Nikou C, 2010, IEEE T IMAGE PROCESS, V19, P2278, DOI 10.1109/TIP.2010.2047903
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   Sfikas G, 2007, IEEE IMAGE PROC, P273
   Sfikas G, 2010, J MATH IMAGING VIS, V36, P91, DOI 10.1007/s10851-009-0174-x
   Svensén M, 2005, NEUROCOMPUTING, V64, P235, DOI 10.1016/j.neucom.2004.11.018
   Nguyen TM, 2013, EVOL SYST-GER, V4, P171, DOI 10.1007/s12530-012-9066-1
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Nguyen TM, 2012, IEEE T SYST MAN CY B, V42, P193, DOI 10.1109/TSMCB.2011.2161284
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001
   Xiong TS, 2014, MULTIMED TOOLS APPL, V72, P167, DOI 10.1007/s11042-012-1336-1
   Xiong TS, 2014, NEURAL COMPUT APPL, V24, P1269, DOI 10.1007/s00521-013-1358-2
   Yuan J., 2010, ECCV
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
NR 41
TC 4
Z9 4
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 345
EP 356
DI 10.1016/j.jvcir.2016.07.004
PN A
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500030
DA 2024-07-18
ER

PT J
AU Coleman, S
   Scotney, B
   Gardiner, B
AF Coleman, Sonya
   Scotney, Bryan
   Gardiner, Bryan
TI Tri-directional gradient operators for hexagonal image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hexagonal image processing; Scalable operator; Tri-directional operator;
   Gradient operator
ID EDGE-DETECTION; DESIGN
AB Image processing has traditionally involved the use of square operators on regular rectangular image lattices. For many years the concept of using hexagonal pixels for image capture has been investigated, and several advantages of such an approach have been highlighted. We present a design procedure for hexagonal gradient operators, developed within the finite element framework, for use on hexagonal pixel based images. In order to evaluate the approach, we generate pseudo hexagonal images via resizing and resampling of rectangular images. This approach also allows us to present results visually without the use of hexagonal lattice capture or display hardware. We provide comparative results with existing gradient operators, both rectangular and hexagonal. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Coleman, Sonya; Gardiner, Bryan] Univ Ulster, Magee BT48 7JL, Londonderry, North Ireland.
   [Scotney, Bryan] Univ Ulster, Coleraine BT52 1SA, Londonderry, North Ireland.
C3 Ulster University; Ulster University
RP Gardiner, B (corresponding author), Univ Ulster, Magee BT48 7JL, Londonderry, North Ireland.
EM sa.coleman@ulster.ac.uk; bw.scotney@ulster.ac.uk;
   b.gardiner@ulster.ac.uk
OI Coleman, Sonya/0000-0002-4676-7640; Gardiner, Bryan/0000-0001-5642-6850
CR ALLEN J D., 2003, Filter banks for images on hexagonal grid
   Ando S, 2000, IEEE T PATTERN ANAL, V22, P252, DOI 10.1109/34.841757
   [Anonymous], COMP VIS PATT REC 19, DOI [10.1109/CVPR.1999.784624, DOI 10.1109/CVPR.1999.784624]
   BALAKRISHNAN M, 1993, OPT ENG, V32, P1430, DOI 10.1117/12.141686
   Coleman SA, 2004, INT C PATT RECOG, P700, DOI 10.1109/ICPR.2004.1334275
   CURCIO CA, 1990, J COMP NEUROL, V292, P497, DOI 10.1002/cne.902920402
   Davies E. R., 1984, Image and Vision Computing, V2, P134, DOI 10.1016/0262-8856(84)90049-0
   Gardiner B., 2011, 14 INT MACH VIS IM P, P102
   He X., 2005, P 1 INT C INFORM COM, V2005, P52, DOI DOI 10.1109/ICICT.2005.1598543
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Huang CH, 2007, IEEE T CIRCUITS-I, V54, P35, DOI 10.1109/TCSI.2006.887975
   Jiang QT, 2008, IEEE T SIGNAL PROCES, V56, P5861, DOI 10.1109/TSP.2008.2006157
   KITCHEN LJ, 1989, COMPUT VISION GRAPH, V47, P243, DOI 10.1016/S0734-189X(89)80009-X
   Knaup M., 2007, IEEE Med. Imaging Conf. Rec, VM13-277, P2074
   Lau DL, 2006, IEEE T IMAGE PROCESS, V15, P1270, DOI 10.1109/TIP.2005.864160
   Middleton L, 2001, IMAGE VISION COMPUT, V19, P1071, DOI 10.1016/S0262-8856(01)00067-1
   Middleton L., 2005, Hexagonal Image Processing: A Practical Approach
   Paplinski AP, 1998, IEEE T IMAGE PROCESS, V7, P611, DOI 10.1109/83.663510
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Qiang W.J., 2007, INT J INFORM SYST SC, V3, P492
   Scotney BW, 2007, PATTERN RECOGN, V40, P1451, DOI 10.1016/j.patcog.2006.10.020
   Shima T, 2010, IEEE T PATTERN ANAL, V32, P961, DOI 10.1109/TPAMI.2009.99
   Shimonomura K, 2007, IEEE INT CONF ROBOT, P4867, DOI 10.1109/ROBOT.2007.364229
   Shirazi SKG, 2009, COMPUT VIS IMAGE UND, V113, P556, DOI 10.1016/j.cviu.2009.01.001
   STAUNTON RC, 1989, IMAGE VISION COMPUT, V7, P162, DOI 10.1016/0262-8856(89)90040-1
   Thiem J., 2000, ICPR, P3449
   Vitulli R, 2002, INT GEOSCI REMOTE SE, P979, DOI 10.1109/IGARSS.2002.1025749
   Wu Q, 2004, PDPTA '04: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOLS 1-3, P399
   Wu Q, 2005, INT CONF ACOUST SPEE, P713
   Wu Q, 2004, INT C PAR DISTR PROC, P339
   WUTHRICH CA, 1991, CVGIP-GRAPH MODEL IM, V53, P324, DOI 10.1016/1049-9652(91)90036-J
NR 31
TC 10
Z9 10
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 614
EP 626
DI 10.1016/j.jvcir.2016.04.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100053
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dutta, T
   Gupta, HP
AF Dutta, Tanima
   Gupta, Hari Prabhat
TI A robust watermarking framework for High Efficiency Video Coding (HEVC)
   - Encoded video with blind extraction process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind extraction; Compressed domain; Copyright protection; Digital
   video; High Efficiency Video Coding (HEVC); Key extraction; Robust
   watermarking; Security
ID H.264/AVC; SCHEME
AB Digital watermarking is an efficient and promising means for copyright protection of multimedia objects. Digital videos are stored and transmitted in a compressed format, which has drawn a great deal of attention in compressed domain watermarking for video. The embedding and extraction of watermark bits in compressed domain, therefore does not require complete decoding and re-encoding of the compressed video. There have been several compression standards for video. High Efficiency Video Coding (HEVC), a successor to H.264 Advanced Video Coding (AVC), is the latest standard for video compression with high compression efficiency. In this paper, we propose a robust watermarking framework with a blind extraction process for HEVC encoded video. A readable watermark is embedded invisibly in 4 x 4 intra predicted blocks of the HEVC encoded video. Our watermarking framework enforces security by exploring the spatio-temporal characteristics of the compressed video and a random key for selection of embedding regions. We also analyze the strengths of different compressed domain features of HEVC encoded video for implementing the embedding algorithm. Experimental results demonstrate that the proposed work restrict the increase in video bit rate and degradation of perceptual quality. The proposed framework can also survive filtering, compressions, and noise additions maintaining good quality and robustness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Dutta, Tanima; Gupta, Hari Prabhat] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Dutta, T (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
RI Dutta, Tanima/N-7222-2015; GUPTA, HARI PRABHAT/AAC-1727-2021
OI GUPTA, HARI PRABHAT/0000-0003-3207-1340
CR [Anonymous], 2015, DATABASE IMAGES VIDE
   [Anonymous], P IEEE INT S BROADB
   [Anonymous], 2012, HEVC REFERENCE SOFTW
   Boho A, 2013, IEEE SIGNAL PROC MAG, V30, P97, DOI 10.1109/MSP.2012.2230220
   DUTTA T, 2013, NAT C COMM NCC, P1
   Dutta T, 2013, MULT EXP ICME 2013 I, P1, DOI DOI 10.1109/ICME.2013.6607430
   Dutta T., 2014, THESIS INDIAN I TECH
   Esen E, 2011, IEEE T CIRC SYST VID, V21, P1130, DOI 10.1109/TCSVT.2011.2134770
   Furht B., 2003, Handbook of video databases: design and applications
   Gui Feng, 2011, Proceedings of the 2011 International Conference on Anti-Counterfeiting, Security and Identification (2011 ASID), P73, DOI 10.1109/ASID.2011.5967419
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Li J, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344439
   Lu CS, 2007, IEEE T CIRC SYST VID, V17, P454, DOI 10.1109/TCSVT.2006.888837
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2005, IEEE IMAGE PROC, P1229
   Noorkami M., 2007, THESIS GEORGIA I TEC
   Noorkami M, 2008, IEEE T INF FOREN SEC, V3, P441, DOI 10.1109/TIFS.2008.923825
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ogawa K, 2015, I SYMP CONSUM ELECTR, P102, DOI 10.1109/ICCE.2015.7066337
   Qiu G, 2004, INT C PATT RECOG, P865
   Salomon D., 2010, ENG GUIDE AUTOMATED
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Watson A.B., 1993, DCT QUANTIZATION MAT, P202
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang J, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P46
NR 30
TC 42
Z9 48
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 29
EP 44
DI 10.1016/j.jvcir.2015.12.007
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100004
DA 2024-07-18
ER

PT J
AU Jia, TT
   Shi, YY
   Zhu, YG
   Wang, L
AF Jia, Tongtong
   Shi, Yuying
   Zhu, Yonggui
   Wang, Lei
TI An image restoration model combining mixed
   <i>L</i><SUP>1</SUP>/<i>L</i><SUP>2</SUP> fidelity terms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; L-1 and L-2 fidelity terms; TV; Split-Bregman; Mixed
   noise
ID MUMFORD-SHAH MODEL; ROBUST ALGORITHM; MINIMIZATION; NONSMOOTH
AB Image restoration is a common problem in visual process. In this paper, a modified minimization model is presented, which combines the L-1 and L-2 fidelity terms with a combined quadratic L-2 and TV regularizer just as the regularizer of Cai et al. (2013). The combined regularizer has the priorities of preserving desirable edges and ensuring several kinds of noises can be removed clearly. Split-Bregman algorithm is efficiently employed to solve this model and convergence analysis is also discussed. Moreover, we extend the proposed model and algorithm for image restoration involving blurry images and color images. Experimental results show that our proposed model and algorithm have good performance both in visual and ISNR values for different kinds of blurs and noises including mixed noise. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Jia, Tongtong; Shi, Yuying; Wang, Lei] North China Elect Power Univ, Dept Math & Phys, Wuhan, Peoples R China.
   [Zhu, Yonggui] Commun Univ China, Sch Sci, Wuhan, Peoples R China.
C3 North China Electric Power University; Communication University of China
RP Shi, YY (corresponding author), North China Elect Power Univ, Dept Math & Phys, Wuhan, Peoples R China.
EM jttncepu@163.com; yyshi@amss.ac.cn; ygzhu@cuc.edu.cn;
   wanglei2239@126.com
RI yuan, lin/JDW-7387-2023
FU NSFC [11271126, 11571325]; Fundamental Research Funds for the Central
   Universities [2014ZZD10]
FX The research is partially supported by NSFC (Nos. 11271126, 11571325)
   and the Fundamental Research Funds for the Central Universities (No.
   2014ZZD10). The authors are indebted to Professor Tieyong Zeng from Hong
   Kong Baptist University for sharing the code.
CR Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179
   [Anonymous], IMAGE PROCESSING ANA
   Babacan S., 2007, IEEE INT C IM PROC, V1
   Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gilboa G., 2002, IEEE T IMAGE PROCESS, V26, P1020
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   He C., 2014, MATH PROBL ENG
   Hintermüller M, 2013, SIAM J IMAGING SCI, V6, P2134, DOI 10.1137/120894130
   Huang YM, 2013, SIAM J SCI COMPUT, V35, pA2856, DOI 10.1137/120898693
   Ito K, 1999, RAIRO-MATH MODEL NUM, V33, P1
   Kärkkäinen T, 2000, J OPTIMIZ THEORY APP, V106, P61, DOI 10.1023/A:1004655007088
   Kärkkäinen T, 2000, J OPTIMIZ THEORY APP, V106, P81, DOI 10.1023/A:1004607123926
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Liu JJ, 2014, J COMPUT ANAL APPL, V17, P524
   Liu RT, 2008, IEEE IMAGE PROC, P505, DOI 10.1109/ICIP.2008.4711802
   Liu XW, 2010, J MATH ANAL APPL, V372, P486, DOI 10.1016/j.jmaa.2010.07.013
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shi YY, 2015, INVERSE PROBL IMAG, V9, P551, DOI 10.3934/ipi.2015.9.551
   Shi YY, 2013, J APPL MATH, DOI 10.1155/2013/797239
   Wang LL, 2012, LECT NOTES COMPUT SC, V6667, P291, DOI 10.1007/978-3-642-24785-9_25
   Wang S, 2014, COMMUN NONLINEAR SCI, V19, P617, DOI 10.1016/j.cnsns.2013.07.004
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Xu J, 2008, ACTA MATH APPL SIN-E, V24, P681, DOI 10.1007/s10255-007-7120-8
   Xu Y, 2013, J APPL MATH, DOI 10.1155/2013/238561
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
NR 41
TC 21
Z9 22
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 461
EP 473
DI 10.1016/j.jvcir.2016.03.022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100040
DA 2024-07-18
ER

PT J
AU Hou, YE
   Ye, P
AF Hou, Yueen
   Ye, Ping
TI Robust residual error consistent tracker with ranking mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Sparse representation; Particle filter; Residual error;
   Ranking; Alignment-pooling; Objective function; Target
ID VISUAL TRACKING
AB In the paper, we propose a novel structural local sparse representation based residual error consistent ranking tracker. In our tracker, candidate targets are linearly combined by using the structural local sparse appearance model. To encourage temporal consistency, a residual error consistency term is designed to constraint the objective function of sparse representation. Based on the objective function, the similarity information is extracted from both coefficients and residual errors of sparse coding. For extracting similarity information from coefficients, the alignment-pooling algorithm is applied to obtain pooled features. For extracting similarity information from residual errors, we develop a residual error score. For different natures of residual error scores and pooled features, a ranking mechanism is proposed to fuse them. The dictionary updating scheme uses the ranking results of the predicted targets to determine which of them are collected for updating. Our tracker performs favorably against 6 state-of-the-art trackers on 18 challenging sequences. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hou, Yueen] Jiaying Univ, Sch Comp, Meizhou, Peoples R China.
   [Ye, Ping] Jiaying Univ, Auditing Dept, Meizhou, Peoples R China.
C3 Jiaying University; Jiaying University
RP Hou, YE (corresponding author), Jiaying Univ, Sch Comp, Meizhou, Peoples R China.
EM houyueen@jyu.edu.cn
FU National Natural Science Foundation of China [61304084]; Innovation and
   Strong School Project of JiaYing University [CQX036]; Natural Science
   Foundation of Guangdong [2014A030307038]; Natural Science Foundation of
   Fujian Province of China [2014J05078]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61304084), by the Innovation and Strong School Project
   of JiaYing University (Grant No. CQX036), by the Natural Science
   Foundation of Guangdong (Grant No. 2014A030307038) and by the Natural
   Science Foundation of Fujian Province of China (Grant No. 2014J05078).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nummiaro K., 2003, IMAGE VISION COMPUT, V257, P1563
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Tianxiang Bai, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P79, DOI 10.1109/ROBIO.2012.6490947
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P3296, DOI 10.1109/TIP.2012.2190085
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 30
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 56
EP 68
DI 10.1016/j.jvcir.2016.01.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200005
DA 2024-07-18
ER

PT J
AU Wang, S
   Lu, JF
   Gu, XJ
   Shen, CH
   Xia, R
   Yang, JY
AF Wang, Sheng
   Lu, Jianfeng
   Gu, Xingjian
   Shen, Chunhua
   Xia, Rui
   Yang, Jingyu
TI Canonical principal angles correlation analysis for two-view data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Canonical correlation analysis; Feature fusion; Unpaired data; Manifold
   regularization; Mutual subspace method; Orthogonal projection; Pattern
   recognition; Handwritten recognition
ID DIMENSIONALITY REDUCTION; FEATURE FUSION; RECOGNITION; FRAMEWORK
AB Canonical correlation analysis (CCA) is a popular method that has been widely used in information fusion. However, CCA requires that the data from two views must be paired, which is hard to satisfy in the real applications, moreover, it only considers the correlated information of the paired data. Thus, it cannot be used when there are only a little paired data or no paired data. In this paper, we propose a novel method named Canonical Principal Angles Correlation Analysis (CPACA) which does not need paired data during training stage. It makes classic CCA escape from the limitation of paired information. Its objective function can be constructed as follows: First, the correlation of two views is represented by the similarity between two subspace spanned by the principal components, which makes CPACA favorably compare with CCA in the case of limited paired data; Second, in order to increase the discriminative information of CPACA, we utilize manifold regularization to exploit the geometry of the marginal distribution. To optimize the objective function, we propose a new method to calculate the projected vectors. The experimental results show that the performance of CPACA is superior to that of traditional CCA and its variants. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Sheng; Lu, Jianfeng; Gu, Xingjian; Xia, Rui; Yang, Jingyu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
C3 Nanjing University of Science & Technology; University of Adelaide
RP Lu, JF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM lujf@njust.edu.cn
RI Yang, Jing/HZJ-2451-2023; jing, yang/JDV-8487-2023
OI Wang, Sheng/0000-0001-6652-960X
FU Jiangsu Natural Science Foundation [BK20131351]; National Natural
   Science Foundation of China (NSFC) [61233011, 91220301]; NFSC & Henan
   Talent Jointly Training Foundation of China [U1504621]; 111 Project
   [B13022]; Fundamental Research Funds for the Central Universities
   [NUST-30920130121004]; Key Scientific Research Project of Universities
   in Henan Province, China [15A413009]
FX The authors would like to thank the referees for their comments. This
   work is supported in part by Jiangsu Natural Science Foundation (Project
   No. BK20131351), by the National Natural Science Foundation of China
   (NSFC) (Project Nos. 61233011 and 91220301), by the NFSC & Henan Talent
   Jointly Training Foundation of China (No. U1504621), by the 111 Project
   (No. B13022), by the Fundamental Research Funds for the Central
   Universities (No. NUST-30920130121004), by the Key Scientific Research
   Project of Universities in Henan Province, China (No. 15A413009).
CR [Anonymous], INT C PATT REC ICPR
   [Anonymous], THESIS NANJING U AER
   [Anonymous], NEURAL PROCESS LETT
   [Anonymous], 2008, TECHNICAL REPORT
   [Anonymous], 28 AAAI C ART INT
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662
   Blaschko MB, 2008, LECT NOTES ARTIF INT, V5211, P133, DOI 10.1007/978-3-540-87479-9_27
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008
   Chen Y, 2013, NEURAL NETWORKS, V42, P28, DOI 10.1016/j.neunet.2013.01.009
   Dasarathy Belur V., 1994, DECISION FUSION, V1994
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208
   Fukui K, 2005, SPRINGER TRAC ADV RO, V15, P192
   Georghiades A., 1997, Yale face database
   Gu JJ, 2011, IEEE T WIREL COMMUN, V10, P2841, DOI 10.1109/TWC.2011.070511.100270
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2006, LECT NOTES COMPUT SC, V3953, P251
   Kimura Akisato, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2933, DOI 10.1109/ICPR.2010.719
   Kroemer O, 2011, IEEE T ROBOT, V27, P545, DOI 10.1109/TRO.2011.2121130
   Lampert CH, 2010, LECT NOTES COMPUT SC, V6312, P566, DOI 10.1007/978-3-642-15552-9_41
   LeCun J, 1999, MNIST DATASET HANDWR
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183
   Lou Z, 1999, PATTERN ANAL APPL, V2, P228, DOI 10.1007/s100440050031
   McFee B, 2011, J MACH LEARN RES, V12, P491
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Satoh S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P163, DOI 10.1109/AFGR.2000.840629
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen XB, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P151
   Su Y, 2012, IEEE T IMAGE PROCESS, V21, P1381, DOI 10.1109/TIP.2011.2169972
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tingkai Sun, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P95, DOI 10.1109/CSIE.2009.794
   van Breukelen M, 1998, KYBERNETIKA, V34, P381
   Wang F, 2009, PATTERN RECOGN, V42, P2863, DOI 10.1016/j.patcog.2009.04.015
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang JA, 2011, PATTERN RECOGN, V44, P1387, DOI 10.1016/j.patcog.2011.01.009
   Yuan YH, 2014, PATTERN RECOGN, V47, P1411, DOI 10.1016/j.patcog.2013.09.009
   Zhou XD, 2013, NEURAL PROCESS LETT, V37, P335, DOI 10.1007/s11063-012-9251-z
NR 49
TC 10
Z9 10
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 209
EP 219
DI 10.1016/j.jvcir.2015.12.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600019
DA 2024-07-18
ER

PT J
AU Yang, B
   Yu, HM
   Xie, Y
AF Yang, Bai
   Yu, Huimin
   Xie, Yi
TI Cooperative object search and segmentation in Internet images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cosegmentation; Segmentation; Object search; Region matching;
   Combinatorial optimization; Structural properties; Iterative
   segmentation; Hierarchical search
ID WINNER DETERMINATION; COSEGMENTATION; RECOGNITION
AB We propose a combined approach for object search and segmentation in realistic Internet image collections. According to a query object, our goal is to locate and segment out those objects of interest. Our approach mainly includes two modules: the hierarchical discriminative region matching method and the iterative object segmentation algorithm. The hierarchical matching method is proposed to perform a hierarchical search to localize the seed-regions for segmentation. Then the iterative segmentation algorithm searches the optimal solution for the final segmentation, with the constraints from structural properties and seed-regions. These two modules work cooperatively because the seed-regions serve as constraints for segmentation and are also verified by segmentation results. Unlike existing search and segmentation approaches, our method produces accurate segmentation results and ignores noise images (images not containing the object of interest). The experimental results validate the advantages of our method on several benchmark datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yang, Bai; Yu, Huimin; Xie, Yi] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yu, Huimin] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Yu, HM (corresponding author), Zhejiang Univ, Inst Informat & Commun Engn, Dept Informat Sci & Elect Engn, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM yangbai@zju.edu.cn; yhm2005@zju.edu.cn; yixie@zju.edu.cn
FU NSFC [61471321]; National Key Basic Research Project of China (973
   Program) [2012CB316400]
FX This work was supported by NSFC under Grant No. 61471321 and a National
   Key Basic Research Project of China (973 Program No. 2012CB316400).
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 7 IEEE INT S MULT
   [Anonymous], 2004, P 2004WORKSHOP STAT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x
   Bhardwaj A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1321
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Cour T, 2005, PROC CVPR IEEE, P1124
   Cui J., 2008, Proc. of the IEEE Conference on Computer Vision and Pattern Recognition CVPR, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Lampert C. H., 2008, IEEE C COMPUTER VISI, P1
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Maji S., 2008, IEEE C COMPUTER VISI, P1
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Russakovsky O, 2010, PROC CVPR IEEE, P1070, DOI 10.1109/CVPR.2010.5540097
   Sandholm T, 2005, MANAGE SCI, V51, P374, DOI 10.1287/mnsc.1040.0336
   Sandholm T, 2003, ARTIF INTELL, V145, P33, DOI 10.1016/S0004-3702(03)00015-8
   Schnitman Y, 2006, LECT NOTES COMPUT SC, V3852, P373
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34
   Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2011.5995545
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang L, 2014, IEEE T IMAGE PROCESS, V23, P4070, DOI 10.1109/TIP.2014.2339196
   Wu JJ, 2014, PROC CVPR IEEE, P256, DOI 10.1109/CVPR.2014.40
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
NR 43
TC 0
Z9 0
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 179
EP 192
DI 10.1016/j.jvcir.2015.09.011
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700017
DA 2024-07-18
ER

PT J
AU Yang, Y
   Zhang, WS
   Xie, Y
AF Yang, Yang
   Zhang, Wensheng
   Xie, Yuan
TI Image automatic annotation via multi-view deep representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image annotation; Stacked auto-encoder; Imbalance learning; Multi-view
   learning; Image features; Semantic gap; Deep learning; Multi-labeling
ID EFFICIENT
AB The performance of text-based image retrieval is highly dependent on the tedious and inefficient manual work. For the purpose of realizing image keywords generated automatically, extensive work has been done in the area of image annotation. However, how to treat image diverse keywords and choose appropriate features are still two difficult problems. To address this challenge, we propose the multi-view stacked auto-encoder (MVSAE) framework to establish the correlations between the low-level visual features and high-level semantic information. In this paper, a new method, which incorporates the keyword frequencies and log-entropy, is presented to address the imbalanced distribution of keywords. In order to utilize the complementarities among diverse visual descriptors, we tactfully apply multi-view learning to search for the label-specific features. Thereafter, the image keywords are finally produced by appropriate features. Conducting extensive experiments on three popular data sets, we demonstrate that our proposed framework can achieve effective and favorable performance for image annotation. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yang, Yang; Zhang, Wensheng; Xie, Yuan] Univ Chinese Acad Sci, Inst Automat, Shanghai, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhang, WS (corresponding author), Univ Chinese Acad Sci, Inst Automat, Shanghai, Peoples R China.
RI yongbei, Zhu/L-7015-2016
OI yang, yang/0000-0002-1895-7906
CR [Anonymous], 2010, P ICML
   [Anonymous], 2012, INT C MACH LEARN WOR
   [Anonymous], 2006, P 2006 IEEE COMPUTER, DOI DOI 10.1109/CVPR.2006.167
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chen A., 2013, ICML, P1274
   Cusano C, 2004, PROC SPIE, V5304, P330
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng ZY, 2013, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2013.203
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu JW, 2013, PATTERN RECOGN, V46, P936, DOI 10.1016/j.patcog.2012.09.010
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Kukar M, 1998, ECAI 1998: 13TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P445
   Lavrenko V., 2003, NIPS
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WY, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P326
   Luo Y, 2013, IEEE T NEUR NET LEAR, V24, P709, DOI 10.1109/TNNLS.2013.2238682
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Saffari A, 2010, LECT NOTES COMPUT SC, V6313, P776
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204
NR 38
TC 22
Z9 27
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 368
EP 377
DI 10.1016/j.jvcir.2015.10.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700033
DA 2024-07-18
ER

PT J
AU Xu, LF
   Zeng, LY
   Duan, HP
AF Xu, Linfeng
   Zeng, Liaoyuan
   Duan, Huiping
TI An effective vector model for global-contrast-based saliency detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention; Saliency model; Global contrast; Vector model; Feature
   vector; Weighted mean vector; Chromatic double opponency; Similarity
   distribution
ID VISUAL-ATTENTION; SEGMENTATION; OBJECTS
AB The saliency detection methods based on global contrast can generate full-resolution saliency map with uniformly highlighted regions and defined boundaries. For the images consisting of large salient objects, the use of unweighted sum of the color distances in the existing global-contrast-based methods may result in the detection of the background instead of the outstanding objects. In this paper, we propose a new global-contrast-based saliency detection method, called LRSW method, by deriving a new vector model which uses the weighted mean vector and contains the features of CIELAB color, chromatic double opponency, and similarity distribution. By using the vector model, the proposed method can significantly increase the detection precision and suppress the background in the saliency map, especially for large salient objects. The experimental results on the MSRA benchmark images show the effectiveness of the proposed method which outperforms the existing methods on visual saliency detection in terms of precision and recall. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Xu, Linfeng; Zeng, Liaoyuan; Duan, Huiping] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Xu, LF (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM lfxu@uestc.edu.cn; lyzeng@uestc.edu.cn; huipingduan@uestc.edu.cn
RI Xu, Linfeng/HME-1913-2023
OI Xu, Linfeng/0000-0002-9934-0958
FU National High Technology Research and Development Program of China (863
   Program) [2012AA011503]; China Scholarship Council (CSC); Program for
   Science and Technology Innovative Research Team for Young Scholars in
   Sichuan Province, China [2014TD0006]; OATF; UESTC
FX This work was partially supported by National High Technology Research
   and Development Program of China (863 Program, No. 2012AA011503), the
   China Scholarship Council (CSC), the Program for Science and Technology
   Innovative Research Team for Young Scholars in Sichuan Province, China
   (No. 2014TD0006), and the Project-sponsored by OATF, UESTC.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Boyer KL, 2002, COMPUT VIS IMAGE UND, V88, P152, DOI 10.1006/cviu.2002.0973
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Forsyth D., 2011, Computer Vision: A Modern Approach
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guttmann M, 2011, COMPUT VIS IMAGE UND, V115, P1662, DOI 10.1016/j.cviu.2011.05.010
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Kim YS, 1998, IMAGE VISION COMPUT, V16, P931, DOI 10.1016/S0262-8856(98)00060-2
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Li HL, 2013, SIGNAL PROCESS-IMAGE, V28, P55, DOI 10.1016/j.image.2012.10.004
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li HL, 2011, IEEE T CIRC SYST VID, V21, P1571, DOI 10.1109/TCSVT.2011.2129150
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Ndjiki-Nya P, 2012, SIGNAL PROCESS-IMAGE, V27, P579, DOI 10.1016/j.image.2012.01.003
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Walther D, 2005, COMPUT VIS IMAGE UND, V100, P41, DOI 10.1016/j.cviu.2004.09.004
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 33
TC 19
Z9 19
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 64
EP 74
DI 10.1016/j.jvcir.2015.03.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900006
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Xiong, RQ
   Ma, SW
   Li, G
   Gao, W
AF Zhang, Xinfeng
   Xiong, Ruiqin
   Ma, Siwei
   Li, Ge
   Gao, Wen
TI Video super-resolution with registration-reliability regulation and
   adaptive total variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Registration reliability; Regularization; Total
   variation; Nonlocal similarity; Structure tensor; Interpolation; Optical
   flow
ID IMAGE SUPERRESOLUTION; SUPER RESOLUTION; INTERPOLATION; ALGORITHM
AB In super-resolution that constructs a high-resolution (HR) image from a set of low-resolution (LR) reference images, it is crucial to align the LR reference images in order to efficiently exploit the pixels therein. However, due to the existence of complex local motion, ideal registration is difficult to acquire. In this paper, we present a robust video super-resolution scheme with registration-reliability regulation and content adaptive total variation regularization, which make the scheme resilient to registration failures. In order to handle ill-registered pixels, we propose a registration-reliability regulated data-fidelity term, which assigns smaller weights to the pixels with larger locally-averaged registration residuals. In addition, a content adaptive total variation based on structure tensor, which is used to estimate image local structures, is proposed to regularize the super-resolved images. The structure tensor is derived not only from the gradients of local patches but also the nonlocal similar patches. Experimental results show that the proposed scheme can remarkably improve both the objective and subjective quality of the video super-resolution results. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Xinfeng] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Xiong, Ruiqin; Ma, Siwei; Gao, Wen] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
   [Li, Ge] Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen 518005, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Peking University; Peking University
RP Xiong, RQ (corresponding author), Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
EM xfzhang@jdl.ac.cn; rqxiong@pku.edu.cn; swma@pku.edu.cn;
   gli@pkusz.edu.cn; wgao@pku.edu.cn
RI Zhang, Xinfeng/X-8148-2019
FU National Science Foundation of China [61322106, 61370114]; National
   Basic Research Program of China (973 Program) [2015CB351800]
FX This work was supported in part by the National Science Foundation of
   China (61322106, 61370114) and National Basic Research Program of China
   (973 Program, 2015CB351800).
CR [Anonymous], 2001, INTEL CORPORATION
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Doré V, 2011, IMAGE VISION COMPUT, V29, P730, DOI 10.1016/j.imavis.2011.07.007
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   He H, 2006, IEEE T IMAGE PROCESS, V15, P592, DOI 10.1109/TIP.2005.860599
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Izadpanahi S, 2013, SIGNAL PROCESS, V93, P2076, DOI 10.1016/j.sigpro.2013.01.006
   Izadpanahi S., 2012, MULTIFRAME SUPER RES, P1
   Kanaev AV, 2013, OPT EXPRESS, V21, P19850, DOI 10.1364/OE.21.019850
   Katsaggelos A.K., 2007, Synth. Lectures Image, Video, Multimedia Process., V1, P1
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Mitzel D, 2009, LECT NOTES COMPUT SC, V5748, P432, DOI 10.1007/978-3-642-03798-6_44
   Omer O., 2008, P SPIE C VIS COMM IM, V1, P275
   Omer OA, 2009, INT CONF ACOUST SPEE, P833, DOI 10.1109/ICASSP.2009.4959713
   Omer OA, 2009, LECT NOTES COMPUT SC, V5414, P944, DOI 10.1007/978-3-540-92957-4_82
   Rasti P, 2014, SIG PROCESS COMMUN, P552, DOI 10.1109/SIU.2014.6830288
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Takeda H, 2008, IEEE IMAGE PROC, P637, DOI 10.1109/ICIP.2008.4711835
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   van de Weijer J, 2001, IEEE T PATTERN ANAL, V23, P1035, DOI 10.1109/34.955116
   Volz S, 2011, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2011.6126359
   Wang Y., 2010, J SCI COMPUT, V45, P272
   Xinfeng Zhang, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P574, DOI 10.1109/PCS.2010.5702567
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan QQ, 2013, IEEE T IMAGE PROCESS, V22, P2327, DOI 10.1109/TIP.2013.2251648
   Zhang X., P IEEE PAC RIM C INT
   Zhang X., 2010, SPIE C VIS COMM IM P
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 31
TC 10
Z9 11
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 181
EP 190
DI 10.1016/j.jvcir.2015.04.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900016
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Jiang, SJF
   Lin, CY
   Suei, PL
   Chang, MKC
AF Yeh, Chia-Hung
   Jiang, Shu-Jhen Fan
   Lin, Chih-Yang
   Suei, Pei-Lun
   Chang, Min-Kuan C.
TI A new intra prediction with adaptive template matching through finite
   state machine
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intra prediction; H.264/AVC; High Efficiency Video Coding; Finite state
   machine; Motion estimation; Video coding; Side-match vector
   quantization; Codebook
ID VECTOR QUANTIZATION; MOTION ESTIMATION; COMPRESSION; DEBLOCKING;
   ALGORITHM
AB This paper presents a new approach that aims to improve the performance of the intra block coding of H.264/AVC and HEVC by using a finite state machine. Based on the high correlations between a frame's neighboring blocks, the finite state machine is employed at both the encoder and decoder to reduce the number of bits required for intra encoding, improving the coding performance of videos. With the matching adaptive template, a better prediction block is found. Through the proposed extra intra prediction modes, the number of bits required to encode a block is reduced significantly, and thus a better intra coding performance is achieved. In addition, an early termination is proposed to speed-up the coding performance. Experimental results show that with the proposed method, the bit rate can be reduced 11% on average when compared to H.264/AVC and 4% on average when compared to HEVC. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yeh, Chia-Hung; Jiang, Shu-Jhen Fan] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.
   [Lin, Chih-Yang] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 413, Taiwan.
   [Lin, Chih-Yang] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
   [Suei, Pei-Lun] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan.
   [Chang, Min-Kuan C.] Natl Chung Hsing Univ, Grad Inst Commun Engn, Taichung 402, Taiwan.
C3 National Sun Yat Sen University; Asia University Taiwan; China Medical
   University Taiwan; China Medical University Hospital - Taiwan; Academia
   Sinica - Taiwan; National Chung Hsing University
RP Lin, CY (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung 413, Taiwan.
RI Lin, Chih-Yang/HOF-2583-2023; Chang, Min-Kuan/AAM-4077-2020
OI Lin, Chih-Yang/0000-0002-0401-8473; Chang, Min-Kuan/0000-0002-0979-0892
FU National Science Council [NSC101-2221-E-110-093-MY2,
   NSC102-2221-E-110-032-MY3]
FX This work was supported in part by the National Science Council under
   the Grants NSC101-2221-E-110-093-MY2 and NSC102-2221-E-110-032-MY3. Our
   thanks to Chia-Shiu Wu for executing the program on the test data in our
   preliminary work; his timely assistance is greatly appreciated.
CR [Anonymous], JVTC151
   Bjontegaard G., 2001, ITU T Q 6 SG 16 VCEG
   FOSTER J, 1985, IEEE T INFORM THEORY, V31, P348, DOI 10.1109/TIT.1985.1057035
   Gu ZY, 2012, IEEE T IMAGE PROCESS, V21, P4106, DOI 10.1109/TIP.2012.2197630
   Jia J, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P49, DOI 10.1109/MUE.2009.20
   Kumwilaisak W, 2011, J VIS COMMUN IMAGE R, V22, P164, DOI 10.1016/j.jvcir.2010.12.002
   Kuo CJ, 2000, IEEE T CIRC SYST VID, V10, P813, DOI 10.1109/76.856459
   Lan CL, 2010, IEEE IMAGE PROC, P1221, DOI 10.1109/ICIP.2010.5652427
   Liu D, 2012, J VIS COMMUN IMAGE R, V23, P100, DOI 10.1016/j.jvcir.2011.09.001
   Nasrabadi N, 1994, COMMUN IEEE T, V42, P2145
   Shen M.Y., 1988, J VIS COMMUN IMAGE R, V9, P2
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Tan TK, 2007, CONSUM COMM NETWORK, P405, DOI 10.1109/CCNC.2007.86
   Wang LP, 2009, IEEE INT CON MULTI, P165, DOI 10.1109/ICME.2009.5202462
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu C.-S., 2010, P SPIE VIS COMMUN IM, V7744
   Yang CC, 2010, IEEE T CIRC SYST VID, V20, P1150, DOI 10.1109/TCSVT.2010.2056953
   Yeh CH, 2012, IET IMAGE PROCESS, V6, P534, DOI 10.1049/iet-ipr.2010.0545
   Yeh CH, 2004, OPT ENG, V43, P363, DOI 10.1117/1.1633777
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Zhang K, 2009, IEEE INT SYMP CIRC S, P2814, DOI 10.1109/ISCAS.2009.5118387
   Zhang P., 2004, P IEEE ICME JUN, V1, P419
NR 22
TC 4
Z9 4
U1 0
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 33
EP 45
DI 10.1016/j.jvcir.2015.01.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100004
DA 2024-07-18
ER

PT J
AU Guruvareddiar, P
   Joseph, BK
AF Guruvareddiar, Palanivel
   Joseph, Biju K.
TI Comparative study of frame-compatible stereo 3D services and a novel
   method for spatial interleaving using HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; HEVC; Stereoscopic 3D; MVC; SVC-TS; Multiview video coding;
   In-loop filters; 3D video coding standards
AB There are a number of ways to realize frame-compatible stereo 3D services, which includes the spatial and temporal interleaving based methods. We first present the detailed analysis of these methods with respect to compression efficiency, backward compatibility and the ability to re-use existing infrastructure. Simulations have been set up to benchmark the Rate-Distortion (R-D) performance of these options with the state-of-the-art Multiview Video Coding (MVC) and results show that temporal interleaving based method performs better when compared to spatial interleaving in both H.264/AVC as well as in HEVC compression schemes, with MVC still outperforms both the methods. In the case of the spatial interleaving method using HEVC, we propose to encapsulate the two views in different tiles with filters turned off across the tile boundary. Simulation results show that the proposed method, when compared to "no-tiles" case, improves decoder performance by approximately 50% with no reduction in R-D performance. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Guruvareddiar, Palanivel; Joseph, Biju K.] TATA ELXSI Ltd, Bangalore 560048, Karnataka, India.
C3 Tata Sons; Tata Elxsi
RP Guruvareddiar, P (corresponding author), TATA ELXSI Ltd, Whitefield Rd, Bangalore 560048, Karnataka, India.
EM palanivelg@ieee.org
CR [Anonymous], TITLE ERROR
   Bjontegaard G, 2001, ITU T SG16 Q6 DOCUME
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chen Ying, 2012, JCT2 VC DOCUMENT JCT
   Chi C.C., 2012, JCT VC DOCUMENT JCTV
   Digital Video Broadcasting (DVB), FRAME COMPATIBLE PIA
   Fuldseth Arild, 2011, JCT VC DOCUMENT JCTV
   Hong D., 2007, JVT DOCUMENT JVT W06
   Jesus Sampedro, 2008, U.S. Patent Application, Patent No. [12/109,695, 12109695]
   Kondrad L, 2009, IEEE INT SYM BROADB, P71
   Nakagami Ohji, 2012, JCT VC DOCUMENT
   Nakagami Ohji, 2012, TERUHIKO SUZUKI ON S
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Ozcan Erdem, 2013, 2013 23rd International Conference on Field Programmable Logic and Applications (FPL 2013), P1, DOI 10.1109/FPL.2013.6645602
   Sullivan Gary J., 2010, STUDY GROUP 16
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang Ye-Kui, 2012, JCT VC DOCUMENT JCTV
   Yang Xiaofeng, 2012, JCT VC DOCUMENT JCTV
   Zhou M., 2012, JCT VC DOCUMENT JCTV
   Zhu JY, 2013, IEEE IMAGE PROC, P1967, DOI 10.1109/ICIP.2013.6738405
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 21
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 200
EP 209
DI 10.1016/j.jvcir.2014.11.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000018
DA 2024-07-18
ER

PT J
AU Zhang, K
   Sheng, YH
   Lv, HY
AF Zhang, Ka
   Sheng, Yehua
   Lv, Haiyang
TI Stereo matching cost computation based on nonsubsampled contourlet
   transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo image matching; Nonsubsampled contourlet transform; Feature
   vector; Weighted matching cost; Matching accuracy
ID POINT CLOUDS; REGISTRATION; IMAGES; ROBUST
AB A new matching cost computation method based on nonsubsampled contourlet transform (NSCT) for stereo image matching is proposed in this paper. Firstly, stereo image is decomposed into high frequency sub-band images at different scales and along different directions by NSCT. Secondly, by utilizing coefficients in high frequency domain and grayscales in RGB color space, the computation model of weighted matching cost between two pixels is designed based on the gestalt laws. Lastly, two types of experiments are carried out with standard stereopairs in the Middlebury benchmark. One of the experiments is to confirm optimum values of NSCT scale and direction parameters, and the other is to compare proposed matching cost with nine known matching costs. Experimental results show that the optimum values of scale and direction parameters are respectively 2 and 3, and the matching accuracy of the proposed matching cost is twice higher than that of traditional NCC cost. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Ka; Sheng, Yehua; Lv, Haiyang] Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Ka; Sheng, Yehua] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Ka; Sheng, Yehua] Nanjing Normal Univ, Key Lab Police Geog Informat Technol, Minist Publ Secur, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing Normal University; Ministry of Public Security (China); Nanjing
   Normal University
RP Zhang, K (corresponding author), Nanjing Normal Univ, Key Lab Virtual Geog Environm, 1 WenYuan Rd, Nanjing, Jiangsu, Peoples R China.
EM zhangka81@126.com; shengyehua@njnu.edu.cn; lvhaiyang368@163.com
OI Zhang, Ka/0000-0002-3277-580X
FU National Natural Science Foundation of China [40901200, 41101377,
   41271383, 41171321]; National Science and Technology Support Project of
   China [2012BAH35B02]; Momentous Science Foundation of Jiangsu province
   [11KJA420001]; Surveying and Mapping Research Foundation of Jiangsu
   province [JSCHKY201011]; Priority Academic Program Development of
   Jiangsu Higher Education Institutions
FX This work was supported by National Natural Science Foundation of China
   under the grant number 40901200, 41101377, 41271383 and 41171321,
   National Science and Technology Support Project of China under the grant
   number 2012BAH35B02, Momentous Science Foundation of Jiangsu province
   under the grant number 11KJA420001, and Surveying and Mapping Research
   Foundation of Jiangsu province under the grant number of JSCHKY201011,
   the Priority Academic Program Development of Jiangsu Higher Education
   Institutions.
CR Ambrosch K, 2010, COMPUT VIS IMAGE UND, V114, P1303, DOI 10.1016/j.cviu.2010.07.008
   [Anonymous], P IEEE C COMP VIS PA
   Binaghi E, 2004, PATTERN RECOGN LETT, V25, P1743, DOI 10.1016/j.patrec.2004.07.001
   Cheng LA, 2008, IEEE GEOSCI REMOTE S, V5, P246, DOI 10.1109/LGRS.2008.915599
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   El-Etriby S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1807, DOI 10.1109/ISIE.2007.4374880
   Gerke M, 2014, ISPRS J PHOTOGRAMM, V87, P78, DOI 10.1016/j.isprsjprs.2013.10.011
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Kim YS, 2008, PATTERN RECOGN, V41, P3356, DOI 10.1016/j.patcog.2008.04.017
   Leberl F, 2010, PHOTOGRAMM ENG REM S, V76, P1123, DOI 10.14358/PERS.76.10.1123
   Manap N.A., 2012, J TELECOMMUN ELECT C, V4, P51
   Nalpantidis L, 2010, ROBOT AUTON SYST, V58, P457, DOI 10.1016/j.robot.2010.02.002
   Nalpantidis L, 2010, IMAGE VISION COMPUT, V28, P940, DOI 10.1016/j.imavis.2009.11.011
   Paclík P, 2006, IEEE T INTELL TRANSP, V7, P309, DOI 10.1109/TITS.2006.880627
   Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510
   Samadi M., 2013, ADV INTELL SYST COMP, V209, P281
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Yang HC, 2012, IEEE GEOSCI REMOTE S, V9, P783, DOI 10.1109/LGRS.2011.2181485
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang W., 2010, J VISION COMMUN IMAG, V21
   Zhou XZ, 2012, IEEE IMAGE PROC, P2989, DOI 10.1109/ICIP.2012.6467528
NR 24
TC 9
Z9 10
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 275
EP 283
DI 10.1016/j.jvcir.2014.10.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000025
DA 2024-07-18
ER

PT J
AU Yan, CC
   Huang, L
   Wei, ZQ
   Nie, J
   Chen, BC
   Zhang, YP
AF Yan, Chenggang Clarence
   Huang, Lei
   Wei, Zhiqiang
   Nie, Jie
   Chen, Bochuan
   Zhang, Yingping
TI Finding suits in images of people in unconstrained environments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Suits detection; Photo ranking; People search; Clothing style; Color
   feature; Shape feature; Statistical feature; Understanding image of
   people
ID PARALLEL FRAMEWORK; DEBLOCKING FILTER; DECISION; HEVC
AB Clothing style analysis is a critical step for understanding images of people. To automatically identify the style of clothing that people wear is a challenging task due to various poses of person and large variations for even the same clothing category. Suit as one of the clothing style is a key element in many important activities. In this paper, we propose a novel suits detection method for images of people in unconstrained environments. In order to cope with various human poses, human pose estimation is incorporated. By analyzing the style of clothing, we propose the color features, shape features and statistical features for suits detection. Experiments with four popular classifiers have been conducted to demonstrate that the proposed features are effective and robust. Comparative experiments with Bag of Words (BoW) method demonstrate that the proposed features are superior to BoW which is a popular method for object detection. The proposed method has achieved promising performance over our dataset, which is a challenging web image set with various human poses and diverse styles of clothing. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yan, Chenggang Clarence] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Yan, Chenggang Clarence] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Huang, Lei; Wei, Zhiqiang] Ocean Univ China, Sch Informat Sci & Engn, Qingdao, Peoples R China.
   [Nie, Jie] Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
   [Chen, Bochuan; Zhang, Yingping] State Grid Informat & Commun Co Hunan EPC, Changsha, Hunan, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Tsinghua University; Ocean University of China; Tsinghua University
RP Huang, L (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao, Peoples R China.
EM ithuanglei@gmail.com
RI Nie, Jie/ABG-9228-2021
OI Nie, Jie/0000-0003-4952-7666
FU Fundamental Research Funds for the Central Universities [201413021];
   National Nature Science Foundation of China [61202208]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities under Grant 201413021; by the National Nature Science
   Foundation of China under Grant 61202208.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P ACM INT C MULT NEW
   [Anonymous], 2006, P CVPR, DOI 10.1109/CVPR.2006.81
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Breiman L., 2001, Mach. Learn., V45, P5
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   El Khoury E., 2010, PROC INT C MULTIMEDI, P295
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gallagher AC., 2008, PROC IEEE C COMPUTER, P1
   Gallagher AndrewC., 2009, IPSJ Transactions on Computer Vision and Applications, V1, P115
   Huang L, 2012, LECT NOTES COMPUT SC, V7131, P485
   Jammalamadaka N, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.88
   Kohavi R, 1995, LECT NOTES ARTIF INT, V912, P174
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Ramanan D., 2007, Advances in Neural Information Processing Systems, V19, P1129
   Song Y, 2006, LECT NOTES COMPUT SC, V3953, P382, DOI 10.1007/11744078_30
   Sprague N, 2002, INT C PATT RECOG, P585, DOI 10.1109/ICPR.2002.1048007
   Tian YL, 2010, LECT NOTES COMPUT SC, V6180, P324, DOI 10.1007/978-3-642-14100-3_48
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang Xianwang., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P1353
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhang W, 2010, IEEE IMAGE PROC, P4593, DOI 10.1109/ICIP.2010.5651704
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
NR 30
TC 0
Z9 1
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1588
EP 1594
DI 10.1016/j.jvcir.2014.07.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100009
DA 2024-07-18
ER

PT J
AU Han, QL
   Zhang, RQ
   Cham, WK
   Liu, Y
AF Han, Qinglong
   Zhang, Renqi
   Cham, Wai-Kuen
   Liu, Yu
TI Quadtree-based non-local Kuan's filtering in video compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Artifacts; Non-local Kuan's filter; Quadtree; Residual
   transform coefficients; Quantization constraint sets; H.264/AVC; HEVC
ID QUANTIZATION NOISE; IMAGES
AB Transform coding has been widely used in video coding standards, such as H.264 advanced video coding (H.264/AVC) and high efficiency video coding (HEVC). But the coded video sequences suffer from annoying coding artifacts, such as blocking and ringing artifacts. In this paper, we propose the quadtree-based non-local Kuan's (QNLK) filter to suppress the quantization noise optimally and improve the objective and subjective quality of the reconstructed frame simultaneously. The proposed filter takes advantage of the non-local Kuan's (NLK) filter to restore the quantized signal in transform domain. Restored coefficients are then projected onto designed quantization constraint sets (QCS). Quadtree-based signaling strategy is used at the end of QNLK for adaptive filtering on/off control. Experimental results of QNLK show that the proposed method achieves significant objective coding gain and visual quality improvement, compared with both H.264/AVC high profile and HEVC. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Han, Qinglong; Zhang, Renqi; Cham, Wai-Kuen] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
   [Liu, Yu] Hong Kong Appl Sci & Technol Res Inst ASTRI, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Hong Kong Applied Science & Technology
   Research Institute Company Limited (ASTRI)
RP Han, QL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM qlhan@ee.cuhk.edu.hk; rqzhang@ee.cuhk.edu.hk; wkcham@ee.cuhk.edu.hk;
   yliu@ieee.org
RI Han, Qing-Long/B-6635-2013; han, qing/KCZ-0174-2024; Zhang,
   Renqi/AHE-3861-2022
OI Han, Qing-Long/0000-0002-7207-0716; 
CR [Anonymous], 2001, ITU T VCEG M
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2011, ITU T VCEG KTA REFER
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chujoh T., 2008, ITU T SG16 CONTR C40
   Chujoh T., 2008, VCEG AI18 BERL
   Chujoh T., 2009, ITU T SG16 CONTR C18
   Dong J., 2012, IEEE T CIRCUITS SYST, V22, P1697
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P2967, DOI 10.1109/TIP.2006.877498
   Gunturk BK, 2004, IEEE T IMAGE PROCESS, V13, P33, DOI 10.1109/TIP.2003.819221
   JCT-VC, 2012, JCTVC J1100 STOCKH S
   Kim I., 2009, IEEE T CIRCUITS SYST, V19, P1462
   Krattenthaler W., 2008, IEEE INT C IM PROC G
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   SULLIVAN GJ, 1994, IEEE T IMAGE PROCESS, V3, P327, DOI 10.1109/83.287030
   Tsai CY, 2013, IEEE J-STSP, V7, P934, DOI 10.1109/JSTSP.2013.2271974
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Widrow B, 1996, IEEE T INSTRUM MEAS, V45, P353, DOI 10.1109/19.492748
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 24
TC 9
Z9 11
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1044
EP 1055
DI 10.1016/j.jvcir.2014.03.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200031
DA 2024-07-18
ER

PT J
AU Liu, Y
   Chen, LY
   Wang, HM
   Jiang, LL
   Zhang, Y
   Zhao, JF
   Wang, PY
   Zhao, YC
   Song, YC
AF Liu, Yu
   Chen, Lingyu
   Wang, Heming
   Jiang, Lanlan
   Zhang, Yi
   Zhao, Jiafei
   Wang, Payong
   Zhao, Yuechao
   Song, Yongchen
TI An improved differential box-counting method to estimate fractal
   dimensions of gray-level images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Differential box-counting method (DBC); Fractal dimension; Gray-level
   images; Grid box size; Synthetic images; Over-counting; Texture images;
   Under-counting
ID SEGMENTATION
AB The differential box-counting (DBC) method is one of the frequently used techniques to estimate the fractal dimension (FD) of a 2D gray-level image. This paper presents an improved DBC method based on the original one for improvement of the accuracy. By adopting the modifying box-counting mechanism, shifting box blocks in (x, y) plane and selecting appropriate grid box sizes, it can solve the two kinds of problems which the DBC has: over-counting boxes along z direction and under-counting boxes just at the border of two neighboring box blocks where there is a sharp gray-level abruption exits. The experiments using two sets of synthetic images and one set of real natural texture images demonstrate that the improved DBC method can solve the two kinds of problems perfectly, simultaneously, and can outperform other DBC methods in the accuracy. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Liu, Yu; Chen, Lingyu; Wang, Heming; Jiang, Lanlan; Zhang, Yi; Zhao, Jiafei; Wang, Payong; Zhao, Yuechao; Song, Yongchen] Dalian Univ Technol, Key Lab Ocean Energy Utilizat & Energy Conservat, Minisny Educ, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Song, YC (corresponding author), Dalian Univ Technol, Key Lab Ocean Energy Utilizat & Energy Conservat, Minisny Educ, Dalian 116024, Peoples R China.
EM songyc@dlut.edu.cn
RI Wang, Heming/N-6430-2019; Mohanty, Nandan/W-7339-2018; Liu,
   Yu/AAD-4123-2019; Jiang, lanlan/AFT-7446-2022; Song,
   Yongchen/HCH-9817-2022
OI Wang, Heming/0000-0003-3487-0912; Liu, Yu/0000-0002-6003-9121; Jiang,
   lanlan/0000-0001-5300-6332; 
FU National Natural Science Foundation of China [51106019, 51006016];
   National High Technology Research and Development of China (863) Program
   [2009AA63400]; National Basic Research Program of China (973) Program
   [2011CB707300]; Fundamental Research Funds for the Central Universities
FX This study has been supported by the National Natural Science Foundation
   of China (Grant Nos. 51106019 and 51006016), the National High
   Technology Research and Development of China (863) Program (Grant No.
   2009AA63400), and the National Basic Research Program of China (973)
   Program (Grant No. 2011CB707300). It has been also supported by the
   Fundamental Research Funds for the Central Universities.
CR Asvestas P, 1998, J VIS COMMUN IMAGE R, V9, P392, DOI 10.1006/jvci.1998.0394
   Barnsley MF., 1993, Fractals Everywhere
   Bisoi AK, 2001, PATTERN RECOGN LETT, V22, P631, DOI 10.1016/S0167-8655(00)00132-X
   Biswas MK, 1998, PATTERN RECOGN LETT, V19, P309, DOI 10.1016/S0167-8655(98)00002-6
   Brodatz P., 1966, Texture: A Photographic Album for Artists and Designers
   Buczkowski S, 1998, PATTERN RECOGN, V31, P411, DOI 10.1016/S0031-3203(97)00054-X
   Chen WS, 2003, OPT ENG, V42, P2452, DOI 10.1117/1.1585061
   CLARKE KC, 1986, COMPUT GEOSCI, V12, P713, DOI 10.1016/0098-3004(86)90047-6
   GAGNEPAIN JJ, 1986, WEAR, V109, P119, DOI 10.1016/0043-1648(86)90257-7
   JIN XC, 1995, PATTERN RECOGN LETT, V16, P457, DOI 10.1016/0167-8655(94)00119-N
   KAPLAN LM, 1995, J VIS COMMUN IMAGE R, V6, P387, DOI 10.1006/jvci.1995.1032
   KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8
   KELLER JM, 1987, IEEE T PATTERN ANAL, V9, P621, DOI 10.1109/TPAMI.1987.4767956
   Lopes R, 2009, MED IMAGE ANAL, V13, P634, DOI 10.1016/j.media.2009.05.003
   Mandelbrot B. B., 1982, The fractal geometry of nature, P468, DOI DOI 10.1002/ESP3290080415
   Peitgen H. O., 1992, CHAOS FRACTALS NEW F
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   SARKAR N, 1995, SIGNAL PROCESS, V42, P181, DOI 10.1016/0165-1684(94)00126-K
   SARKAR N, 1992, PATTERN RECOGN, V25, P1035, DOI 10.1016/0031-3203(92)90066-R
   Soille P, 1996, J VIS COMMUN IMAGE R, V7, P217, DOI 10.1006/jvci.1996.0020
   Voss R., 1986, RANDOM FRACTALS CHAR
   Wang E, 2014, TECTONICS, V33, P686, DOI 10.1002/2013TC003337
NR 24
TC 97
Z9 107
U1 8
U2 73
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1102
EP 1111
DI 10.1016/j.jvcir.2014.03.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200036
DA 2024-07-18
ER

PT J
AU Namane, A
   Guessoum, A
   Soubari, EH
   Meyrueis, P
AF Namane, A.
   Guessoum, A.
   Soubari, E. H.
   Meyrueis, P.
TI CSM neural network for degraded printed character optical recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Component; Complementary similarity measure; Degraded printed
   characters; Hamming net; Competitive neural network; OCR; Character
   recognition; CSM net; Combination method
AB In pattern recognition applications, the classification power of a system can be improved by combining several classifiers. Obviously performance of the system cannot be improved if the individual classifiers make all the same mistakes, thus it is important to use different features and different structures in the individual classifiers. In this context, we propose a two subnets neural network called CSM net. The first subnet, or similarity layer, is operating as a similarity measure neural network; it is based on the complementary similarity measure method (CSM). The second subnet is a competitive neural network (CNN) based on the winner takes all algorithm (WTA) that is used for the classification. In the proposed neural architecture, the statistical CSM method is analyzed, and implemented in the form of a feed forward neural network, it is named "similarity measure neural network" (SMNN). We show that the resulting SMNN synaptic weights are modified versions of the model patterns used in the training set, and that they can be considered as a memory network. We introduce a relative distance data calculated from the SMNN output, and we use it as a quality measurement tool of the degraded characters, what makes the SMNN classifier very powerful, and very well-suited for features rejections. This relative distance is used by the SMNN and compared to a first rejection threshold to accept, or reject, the incoming characters. In order to guarantee a higher recognition and reliability rates for the cascaded method, the SMNN is combined with a second subnet based on the WTA for classification using a second specific rejection threshold. These two submits combination (CSM net) boost the performance of the SMNN classifier. This is resulting in a robust multiple classifiers that can be used for setting the entire rejection threshold. The experimental results that we introduce are related to the proposed method, but the tests are introduced with various impulse noise levels, as well as the tests with broken and manually corrupted characters, and characters with various levels of additive Gaussian noise. The experiments show the effective ability of the model to yield relevant and robust recognition on poor quality printed checks, and show that the CSM net outperforms the previous works, both in efficiency and accuracy. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Namane, A.; Guessoum, A.] Univ Saad Dahlab Blida, Fac Technol, Dept Elect, LAb Traitement Signal & Image LATSI, Blida, Algeria.
   [Soubari, E. H.; Meyrueis, P.] Univ Strasbourg, Lab Sci Ingenieur Informat & Imagerie, ICUBE, E Phot Grp, Strasbourg, France.
C3 Universite Saad Dahlab de Blida; Universites de Strasbourg
   Etablissements Associes; Universite de Strasbourg
RP Namane, A (corresponding author), Univ Saad Dahlab Blida, Fac Technol, Dept Elect, LAb Traitement Signal & Image LATSI, Blida, Algeria.
EM a_namane@hotmail.com
CR AVIITZHAK HI, 1995, IEEE T PATTERN ANAL, V17, P218, DOI 10.1109/34.368165
   Babu R., 2010, P SPIE, V7546, P754
   Dimauro G, 1997, INT J PATTERN RECOGN, V11, P467, DOI 10.1142/S0218001497000214
   Francesconi E., 2001, International Journal on Document Analysis and Recognition, V3, P160, DOI 10.1007/PL00013556
   Gorski N., 2001, International Journal on Document Analysis and Recognition, V3, P196, DOI 10.1007/PL00013561
   Gupta A. K., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P38, DOI 10.1109/CSNT.2011.15
   Hobby JD, 1997, PROC INT CONF DOC, P394, DOI 10.1109/ICDAR.1997.619877
   Huiqun Deng, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P581, DOI 10.1109/ICDAR.2009.144
   Kim J, 2011, J POWER SOURCES, V196, P2227, DOI 10.1016/j.jpowsour.2010.08.119
   Likforman-Sulem L, 2008, PATTERN RECOGN, V41, P3092, DOI 10.1016/j.patcog.2008.03.022
   Likforman-Sulem L, 2011, IMAGE VISION COMPUT, V29, P351, DOI 10.1016/j.imavis.2011.01.001
   Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]
   Liu HS, 1999, P SOC PHOTO-OPT INS, V3651, P41, DOI 10.1117/12.335820
   Namane A., 2010, IEEE 9 INT C CYB INT, P1
   Namane A., 2007, 9 INT S SIGN PROC IT, P1
   Namane A, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P207
   Namane A, 2006, OPT ENG, V45, DOI 10.1117/1.2345056
   Niblack W., 1986, An Introduction to Digital Image Processing
   Penz H, 2001, P SOC PHOTO-OPT INS, V4303, P127, DOI 10.1117/12.424946
   Sawaki M, 1998, IEEE T PATTERN ANAL, V20, P1103, DOI 10.1109/34.722625
   Tan CL, 2002, IEEE T PATTERN ANAL, V24, P838, DOI 10.1109/TPAMI.2002.1008389
   Tonazzini A., 2004, International Journal on Document Analysis and Recognition, V6, P236, DOI 10.1007/s10032-003-0115-y
   van der Smagt P. P., 1990, Proceedings. The Third International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems (IEA/AIE 90), P1037, DOI 10.1145/98894.99119
   Yanikoglu B. A., 2000, International Journal on Document Analysis and Recognition, V3, P34, DOI 10.1007/PL00013553
NR 24
TC 7
Z9 9
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1171
EP 1186
DI 10.1016/j.jvcir.2014.04.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200043
DA 2024-07-18
ER

PT J
AU Zilly, F
   Riechert, C
   Muller, M
   Eisert, P
   Sikora, T
   Kauff, P
AF Zilly, Frederik
   Riechert, Christian
   Mueller, Marcus
   Eisert, Peter
   Sikora, Thomas
   Kauff, Peter
TI Real-time generation of multi-view video plus depth content using mixed
   narrow and wide baseline
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-TV; Depth image based rendering DIBR; Depth estimation; Multi-view
   video plus depth; MVD4; Real-time; Multi-camera rectification
ID DISPLAY; SYSTEM
AB Content production for stereoscopic 3D-TV displays has become mature in the past years while huge progress has also been achieved in the improvement of the image quality of glasses-free auto-stereoscopic displays and light-field displays. Concerning the latter two display families, the content production workflow is less elaborated and more complex, as the number of required views not only differs considerably but is also likely to increase in the near future. As a co-existence of all 3D display families can be expected for the next years, one aims to establish an efficient content production workflow which yields to high quality content for all 3D-TV displays.
   Against this background we present a real-time capable multi-view video plus depth (MVD) content production workflow based on a four-camera rig with mixed narrow and wide baseline. Results show the suitability of the approach to simultaneously produce high quality MVD4 and native stereoscopic 3D content. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zilly, Frederik] IIS, Fraunhofer Inst Integrated Circuits, Erlangen, Germany.
   [Riechert, Christian; Mueller, Marcus; Eisert, Peter; Kauff, Peter] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, Berlin, Germany.
   [Zilly, Frederik; Sikora, Thomas] Tech Univ Berlin, Berlin, Germany.
C3 Fraunhofer Gesellschaft; Fraunhofer Gesellschaft; Technical University
   of Berlin
RP Zilly, F (corresponding author), IIS, Fraunhofer Inst Integrated Circuits, Erlangen, Germany.
EM frederik.zilly@iis.fraunhofer.de
RI Eisert, Peter/AAX-7968-2020
OI Eisert, Peter/0000-0001-8378-4805
CR [Anonymous], 3DTV CON 2011 16 18
   [Anonymous], 3D MOVIE MAKING STER
   [Anonymous], P 2 INT C IMM TEL IM
   [Anonymous], P SPIE STEREOSCOPIC
   [Anonymous], P EUR C VIS MED PROD
   [Anonymous], P PICT COD S PCS 200
   [Anonymous], 3D TV C TRUE VIS CAP
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 2008, WORKSH MULT MULT SEN
   [Anonymous], 3DTV C TRUE VIS CAPT
   [Anonymous], P VIIP 03 BEN SPAIN
   [Anonymous], 3D TV 3D CINEMA TOOL
   [Anonymous], P IAWIT 2010 JAN
   [Anonymous], SMPTE J JUN
   [Anonymous], 3DTV C JUN 2010
   [Anonymous], RECENT ACTIVITIES 3D
   [Anonymous], P 3D SYST APPL MAY
   [Anonymous], SPIE
   [Anonymous], C VIS MED PROD CVMP
   [Anonymous], P ICIP SPEC SESS IM
   [Anonymous], P 10 EUR C COMP VI 1
   Atzpadin N, 2004, IEEE T CIRC SYST VID, V14, P321, DOI 10.1109/TCSVT.2004.823391
   Bartczak B, 2011, IEEE T BROADCAST, V57, P477, DOI 10.1109/TBC.2011.2120790
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Chen CH, 2008, INT C PATT RECOG, P1814
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   Fehn C, 2003, CONF REC ASILOMAR C, P1529
   Forstmann S., 2004, IEEE CVPR WORKSHOP R, P29
   Grau O, 2011, IEEE T BROADCAST, V57, P408, DOI 10.1109/TBC.2011.2126350
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239453
   Kovacs PeterTamas., 2012, ACM SIGGRAPH 2012 Emerging Technologies, SIGGRAPH '12, p1:1
   Marton F., 2011, 3DTV C TRUE VIS CAPT, P1, DOI DOI 10.1109/3DTV.2011.5877176
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Mueller M., 2010, 3DTV C TRUE VISION C, P1
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Solh M., 2011, IEEE International Conference on Multimedia and Expo (ICME), P1
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Zhang Qi., 2011, P 5 INT WORKSHOP LAR, P1
   Zilly F, 2011, P IEEE, V99, P590, DOI 10.1109/JPROC.2010.2095810
   Zilly M. Muller, 2013, in3D-TV in System With Depth-Image-Based Rendering: Ar-chitectures, Techniques and Challenges, P39
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 48
TC 13
Z9 13
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 632
EP 648
DI 10.1016/j.jvcir.2013.07.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500004
DA 2024-07-18
ER

PT J
AU Song, YQ
AF Song, Yuqing
TI Computation of level lines of 4-/8-connectedness
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Level line; Jordan boundary; Level set; Image representation; Level line
   tree; Square grid; Connectedness; Topdown algorithm
ID IMAGE
AB We present a topdown algorithm to compute level line trees of 4-/8-connectedness. As a boundary of a level set component, a level line of an image is a Jordan boundary of intensity value on instant interior greater/less than on instant exterior. The interior of a Jordan boundary assumes 4-connectedness and the exterior 8-connectedness, or the inverse. All level lines form a tree structure. The running time of the algorithm is O(n + t), where n is the size of the input image and t is the total length of all level lines. The efficiency of the algorithm is illustrated by experiments. (C) 2013 Elsevier Inc. All rights reserved.
C1 Tianjin Univ Technol & Educ, Tianjin 300222, Peoples R China.
C3 Tianjin University of Technology & Education
RP Song, YQ (corresponding author), Tianjin Univ Technol & Educ, 1310 Dagu South Rd, Tianjin 300222, Peoples R China.
EM yqsong7@hotmail.com
FU Natural Science Foundation of China [61070112, 61070116]
FX This paper is partially supported by Natural Science Foundation of China
   under contracts No. 61070112 and No. 61070116.
CR Ballester C, 2007, J MATH IMAGING VIS, V27, P5, DOI 10.1007/s10851-006-7252-0
   Caselles V, 2008, POSITIVITY, V12, P55, DOI 10.1007/s11117-007-2150-2
   Dibos F, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P179, DOI 10.1109/VLSM.2001.938897
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Ferraro M., IEEE T PATTERN ANAL, V21
   Herman GT., 1998, Geometry of digital spaces
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   MONASSE P, 2000, THESIS U PARIS DAUPH
   NEWMAN MHA, 1951, ELEMENTS TOPOLOGY PL
   Parot V, 2012, MAGN RESON MED, V68, P17, DOI 10.1002/mrm.23190
   Song YQ, 2007, IEEE T IMAGE PROCESS, V16, P2107, DOI 10.1109/TIP.2007.899616
   Song YQ, 2011, IEEE T IMAGE PROCESS, V20, P2722, DOI 10.1109/TIP.2011.2142317
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   [No title captured]
NR 17
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 435
EP 444
DI 10.1016/j.jvcir.2013.12.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300019
DA 2024-07-18
ER

PT J
AU Hulik, R
   Spanel, M
   Smrz, P
   Materna, Z
AF Hulik, Rostislav
   Spanel, Michal
   Smrz, Pavel
   Materna, Zdenek
TI Continuous plane detection in point-cloud data based on 3D Hough
   Transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D sensor; Point cloud; Hough Transform; Plane detection; PCL
   library; RANSAC; Computer vision; Shape extraction
ID LINES
AB This paper deals with shape extraction from depth images (point clouds) in the context of modern robotic vision systems. It presents various optimizations of the 3D Hough Transform used for plane extraction from point cloud data. Presented enhancements of standard methods address problems related to noisy data, high memory requirements for the parameter space and computational complexity of point accumulations. The realised robust plane detector benefits from a continuous point cloud stream generated by a depth sensor over time. It is used for iterative refinements of the results. The system is compared to a state-of-the-art RANSAC-based plane detector from the Point Cloud Library (PCL). Experimental results show that it overcomes the PCL alternative in the stability of plane detection and in the number of negative detections. This advantage is crucial for robotic applications, e.g., when a robot approaches a wall, it can be consistently recognized. The paper concludes with a discussion of further promising optimisation that will be implemented as a future step. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hulik, Rostislav; Spanel, Michal; Smrz, Pavel; Materna, Zdenek] Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4Innovat, Brno 61266, Czech Republic.
C3 Brno University of Technology
RP Hulik, R (corresponding author), Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4Innovat, Bozetechova 2, Brno 61266, Czech Republic.
EM ihulik@fit.vutbr.cz; spanel@fit.vutbr.cz; smrz@fit.vutbr.cz;
   imaterna@fit.vutbr.cz
RI Spanel, Michal/G-9639-2016; Materna, Zdeněk/AAC-9572-2019; Smrz,
   Pavel/A-4763-2016
OI Materna, Zdeněk/0000-0001-5798-5435; Spanel, Michal/0000-0003-0193-684X;
   Smrz, Pavel/0000-0002-5638-1362
FU European Community's 7th Framework Artemis JU grant [100233, 247772];
   European Regional Development Fund in the IT4Innovations Centre of
   Excellence project [CZ.1.05/1.1.00/02.00 70]
FX This work was supported by the European Community's 7th Framework
   Artemis JU grant agreement no. 100233 (R3-COP), grant no. 247772 (SRS)
   and European Regional Development Fund in the IT4Innovations Centre of
   Excellence project (CZ.1.05/1.1.00/02.00 70).
CR BALLARD DH, 1987, GEN HOUGH TRANSFORM, P714
   Borrmann D, 2011, 3D RES, V2, DOI 10.1007/3DRes.02(2011)3
   BOX GEP, 1958, ANN MATH STAT, V29, P610, DOI 10.1214/aoms/1177706645
   Chen TC, 2001, REAL-TIME IMAGING, V7, P473, DOI 10.1006/rtim.2001.0233
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   DESCHAUD JE, 2010, 3DPVT 10
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   FISCHLER MA, 1987, COMMUN ACM, P726
   Han B, 2011, J VIS COMMUN IMAGE R, V22, P421, DOI 10.1016/j.jvcir.2011.03.006
   Heracles M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5717, DOI 10.1109/IROS.2009.5353932
   Holz D., 2011, P 15 ROBOCUP INT S I
   HULIK MSP, 2012, IEEE RSJ INT C INT R
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   KLVIINEN H, 1994, P 3 EUR C COMP VIS E, P351
   Mochizuki Y, 2009, J VIS COMMUN IMAGE R, V20, P242, DOI 10.1016/j.jvcir.2009.01.004
   Poppinga J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3378, DOI 10.1109/IROS.2008.4650729
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Tarsha-Kurdi F., 2007, INT ARCH PHOTOGRAMME, V36, P407
   XU L, 1993, CVGIP-IMAG UNDERSTAN, V57, P131, DOI 10.1006/ciun.1993.1009
NR 19
TC 79
Z9 95
U1 4
U2 56
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 86
EP 97
DI 10.1016/j.jvcir.2013.04.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900009
DA 2024-07-18
ER

PT J
AU Raveaux, R
   Burie, JC
   Ogier, JM
AF Raveaux, Romain
   Burie, Jean-Christophe
   Ogier, Jean-Marc
TI Structured representations in a content based image retrieval context
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content image representation; Graph-Based Representation; Structural
   pattern recognition; Graph matching; Image features; Bag of Words; Image
   retrieval; Query by example
ID EDIT DISTANCE; RECOGNITION; ASSIGNMENT; ALGORITHMS; KERNELS; TREES
AB Here, we propose an automatic system to annotate and retrieve images. We assume that regions in an image can be described using a vocabulary of blobs. Blobs are generated from image features using clustering. Features are locally extracted on regions to capture Color, Texture and Shape information. Regions are processed by an efficient segmentation algorithm. Images are structured into a region adjacency graph to consider spatial relationships between regions. This representation is used to perform a similarity search into an image set. Hence, the user can express his need by giving a query image, and thereafter receiving as a result all similar images. Our graph based approach is benchmarked to conventional Bag of Words methods. Results tend to reveal a good behavior in classification of our graph based solution on two publicly available databases. Experiments illustrate that a structural approach requires a smaller vocabulary size to reach its best performance. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Raveaux, Romain] Univ Tours, LI Lab, Tours, France.
   [Burie, Jean-Christophe; Ogier, Jean-Marc] Univ La Rochelle, Lab L3I, La Rochelle, France.
C3 Universite de Tours; La Rochelle Universite
RP Raveaux, R (corresponding author), Univ Tours, LI Lab, Av Jean Portalis, Tours, France.
EM romain.raveaux@univ-tours.fr
CR Aiello M, 2004, INFORM SCIENCES, V167, P147, DOI 10.1016/j.ins.2003.05.015
   Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], STRUCTURE BASED SIMI
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], CUCS00696
   [Anonymous], HUMAN MACHINE VISION
   [Anonymous], ACM 86
   [Anonymous], INT S MULT INF PROC
   [Anonymous], AUTOMATIC IMAGE ANNO
   [Anonymous], ACM MULT C
   [Anonymous], P 4 ACM INT C MULT
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], IEEE CVPR 2004 WORKS
   [Anonymous], 1 INT FOR MULT IM PR
   [Anonymous], P 21 INT C MACH LEAR
   [Anonymous], SKETCH SYMB REC US Z
   [Anonymous], BLOBWORLD SYSTEM REG
   [Anonymous], LIGHTWEIGHT SIFT IMP
   [Anonymous], P 21 INT C MACH LEAR
   [Anonymous], 2007, BRIDGING GAP GRAPH E
   [Anonymous], MULTIMEDIA INFORM RE
   [Anonymous], 5 INT WORKSH WEB DAT
   [Anonymous], 2000, DISTINCTIVE IMAGE FE
   [Anonymous], J MULTIMEDIA TOOLS A
   [Anonymous], ACM MULT C
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], J VISUAL COMMUNICATI
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Berretti S, 2003, IEEE T MULTIMEDIA, V5, P52, DOI 10.1109/TMM.2002.802833
   Bonabeau E, 2002, INFORM SCIENCES, V143, P159, DOI 10.1016/S0020-0255(02)00191-3
   Borgwardt K. M., 2005, ICDM, DOI DOI 10.1109/ICDM.2005.132
   Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3
   Burl MC, 1996, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.1996.517078
   Chang CC, 1998, J SYST SOFTWARE, V44, P73, DOI 10.1016/S0164-1212(98)10044-4
   CHANG SK, 1984, IEEE T PATTERN ANAL, V6, P475, DOI 10.1109/TPAMI.1984.4767552
   Cox M. F., MULTIDIMENSIONAL SCA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R., 2006, ACM COMPUT SURV, V39, P2007
   DeMarsicoi M, 1997, IMAGE VISION COMPUT, V15, P119, DOI 10.1016/S0262-8856(96)01114-6
   Duygulu P., 2002, ECCV, P349, DOI DOI 10.1007/3-540-47979-17
   Eakins J. P., 2001, Lectures on Information Retrieval. Third European Summer-School, ESSIR 2000. Revised Lectures (Lecture Notes in Computer Science Vol.1980), P111
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fergus R, 2003, PROC CVPR IEEE, P264
   Finch AM, 1997, PATTERN RECOGN, V30, P123, DOI 10.1016/S0031-3203(96)00060-X
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Guru DS, 2001, PATTERN RECOGN LETT, V22, P999, DOI 10.1016/S0167-8655(01)00043-5
   HADDON JF, 1993, ELECTRON COMMUN ENG, V5, P71, DOI 10.1049/ecej:19930013
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang PW, 2004, IEEE T KNOWL DATA EN, V16, P1486, DOI 10.1109/TKDE.2004.92
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Mahé P, 2005, J CHEM INF MODEL, V45, P939, DOI 10.1021/ci050039t
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Nowak E., Computer Vision-ECCV 2006Anonymous 2006
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Petrakis EGM, 2002, IMAGE VISION COMPUT, V20, P59, DOI 10.1016/S0262-8856(01)00077-4
   Petrakis EGM, 2002, IEEE T KNOWL DATA EN, V14, P979, DOI 10.1109/TKDE.2002.1033768
   Raveaux R, 2011, COMPUT VIS IMAGE UND, V115, P905, DOI 10.1016/j.cviu.2010.12.015
   Raveaux R, 2010, PATTERN RECOGN LETT, V31, P394, DOI 10.1016/j.patrec.2009.10.011
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Sethi IK, 2001, P SOC PHOTO-OPT INS, V4384, P279, DOI 10.1117/12.421083
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Smith G, 1997, PATTERN RECOGN LETT, V18, P1495, DOI 10.1016/S0167-8655(97)00132-3
   Sriram R, 1996, IEEE T IMAGE PROCESS, V5, P1382, DOI 10.1109/83.535852
   Suard F, 2006, LECT NOTES COMPUT SC, V4142, P23
   Valveny E, 2004, LECT NOTES COMPUT SC, V3088, P368
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Wang JTL, 2002, PATTERN RECOGN, V35, P473, DOI 10.1016/S0031-3203(01)00055-3
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Williams C.K.I., PASCAL VISUAL OBJECT
   ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082
   ZHANG KZ, 1992, INFORM PROCESS LETT, V42, P133, DOI 10.1016/0020-0190(92)90136-J
   Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866
NR 84
TC 25
Z9 25
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1252
EP 1268
DI 10.1016/j.jvcir.2013.08.010
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Agarwal, C
   Mishra, A
   Sharma, A
AF Agarwal, Charu
   Mishra, Anurag
   Sharma, Arpita
TI Gray-scale image watermarking using GA-BPN hybrid network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image watermarking; Human visual system; GA-BPN; Hybrid
   intelligent system; Robustness; Discrete wavelet domain;
   Peak-signal-to-noise ratio; Normalized cross-correlation
AB In this paper, a novel watermarking scheme is proposed by embedding a binary watermark into gray-scale images using a hybrid GA-BPN intelligent network. HVS characteristics of the images in DCT domain are used to obtain a sequence of weighting factor from a GA-BPN. This weighting factor is used to embed and extract the watermark from the image in DWT domain. The GA-BPN is trained by 27 inference rules that includes three input HVS parameters namely luminance sensitivity, edge sensitivity computed using threshold and contrast sensitivity computed using variance. The robustness of the embedding scheme is examined by executing seven different image processing attacks. Visual quality of signed images before and after the attacks is examined by PSNR. The extracted watermarks from signed and attacked images show a high degree of similarity with the embedded content. Overall, the algorithm is robust against selected attacks and is well optimized. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Agarwal, Charu] Univ Delhi, Dept Comp Sci, Delhi 110007, India.
   [Mishra, Anurag] Univ Delhi, Deendayal Upadhyay Coll, Dept Elect, Delhi 110007, India.
   [Sharma, Arpita] Univ Delhi, Deendayal Upadhyay Coll, Dept Comp Sci, Delhi 110007, India.
C3 University of Delhi; University of Delhi; University of Delhi
RP Agarwal, C (corresponding author), Univ Delhi, Dept Comp Sci, Delhi 110007, India.
EM agarwalcharu2@rediffmail.com; anurag_cse2003@yahoo.com;
   arpt1_mishra1@yahoo.com
RI Mishra, Anurag/Y-3426-2019; Agarwal, Charu/HTM-4123-2023
OI Mishra, Anurag/0000-0003-3881-7182
CR Abraham A, 2005, STUD FUZZ SOFT COMP, V173, P159
   Agarwal C, 2011, CAN CON EL COMP EN, P822, DOI 10.1109/CCECE.2011.6030570
   Agarwal Charu, 2010, IEEE 6 INT C INT INF, P102
   Bansal Ashish, 2005, J THEOR APPL INF TEC, V4, P663
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fuller R., 1999, ADV SOFT COMPUTING S
   Gonzalez RC, 2005, DIGITAL IMAGE PROCES, P406
   Huang S, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5985, DOI 10.1109/WCICA.2008.4594557
   Jacobsen Hans-Arno, 1998, IEEE WORLD C COMP IN, V1, P709
   Kaewkamnerd N, 2000, ELECTRON LETT, V36, P312, DOI 10.1049/el:20000269
   Lou Der-Chyuan, 2008, J CCIT, V37, P151
   Mei Shi-chun, 2002, 9 INT C NEUR INF PRO, V5, P2430
   Melin P, 2007, NAFIPS 2007 - 2007 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P582, DOI 10.1109/NAFIPS.2007.383905
   Motwani Mukesh C., 2009, INT C IM PROC COMP V, P321
   Rajasekaran S., 1996, 4 INT C ADV COMP BAN, P73
   Saraju P., 1999, ACM MULTIMEDIA, V2, P49
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   [No title captured]
NR 18
TC 52
Z9 52
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1135
EP 1146
DI 10.1016/j.jvcir.2013.07.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700037
DA 2024-07-18
ER

PT J
AU Besiris, D
   Zigouris, E
AF Besiris, D.
   Zigouris, E.
TI Dictionary-based color image retrieval using multiset theory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image retrieval; Data compression; Dictionary; Kolmogorov
   complexity; Multiset theory; Similarity metric; Normalized Multiset
   Distance; Image compression
ID TEXTURE; SCHEME
AB Dictionaries have recently attracted a great deal of interest as a new powerful representation scheme that can describe the visual content of an image. Most existing approaches nevertheless, neglect dictionary statistics. In this work, we explore the linguistic and statistical properties of dictionaries in an image retrieval task, representing the dictionary as a multiset. This is extracted by means of the LZW data compressor which encodes the visual patterns of an image. For this reason the image is first quantized and then transformed into a 1D string of characters. Based on the multiset notion we also introduce the Normalized Multiset Distance (NMD), as a new dictionary-based dissimilarity measure which enables the user to retrieve images with similar content to a given query. Experimental results demonstrate a significant improvement in retrieval performance compared to related dictionary-based techniques or to several other image indexing methods that utilize classical low-level image features. (C) 2013 Published by Elsevier Inc.
C1 [Besiris, D.; Zigouris, E.] Univ Patras, Dept Phys, Elect Lab, Rion 26500, Greece.
C3 University of Patras
RP Besiris, D (corresponding author), Univ Patras, Dept Phys, Elect Lab, Rion 26500, Greece.
EM dbes@upaqtras.gr; ez@physics.upatras.gr
CR [Anonymous], 2006, IEEE COMPUTER
   [Anonymous], 19 IS T SPIE S EL IM
   [Anonymous], CLUSTERING IMAGES US
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Apostolico A, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P13, DOI 10.1109/DCC.2008.105
   Bar J.Z., 2003, COMP GRAPH FORUM EUR, V22, P349, DOI [10.1111/1467-8659.00682, DOI 10.1111/1467-8659.00682]
   Basavaraja S.V., 2008, P SPPRA 08 5 IASTED
   Blizard WD., 1991, Modern Logic, V1, P319
   Bratko A, 2006, J MACH LEARN RES, V7, P2673
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Castelli V., 2002, IMAGE DATABASES SEAR, DOI [https://doi.org/10.1002/0471224634, DOI 10.1002/0471224634]
   Cerra D, 2012, J VIS COMMUN IMAGE R, V23, P293, DOI 10.1016/j.jvcir.2011.10.009
   Cerra D, 2010, IEEE GEOSCI REMOTE S, V7, P8, DOI 10.1109/LGRS.2009.2020349
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Cilibrasi R, 2004, COMPUT MUSIC J, V28, P49, DOI 10.1162/0148926042728449
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   *COR CORP, COR STOCK PHOT LIB
   Evans S., 2007, P MIL COMM C MILCOM, P1, DOI [10.1109/MILCOM.2007.4455304, DOI 10.1109/MILC0M.2007.4455304]
   Gonde A.B., 2010, P 7 IND C COMP VIS G, P359, DOI [10.1145/1924559.1924607, DOI 10.1145/1924559.1924607]
   Hagenauer J, 2004, 2004 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P55
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Kavitha C., 2011, Int. J. Eng. Sci. Technol. (IJEST), V3, P1060
   Keogh E. J., 2004, KDD, P206, DOI [DOI 10.1145/1014052.1014077, 10.1145/1014052.1014077]
   Kolmogorov A. N., 1968, International Journal of Computer Mathematics, V2, P157, DOI 10.1080/00207166808803030
   Lan Y., 2005, P 2 INT C VIS VID GR, P173
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149
   Li M, 2006, LECT NOTES ARTIF INT, V3918, P704
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Macedonas A, 2008, J VIS COMMUN IMAGE R, V19, P464, DOI 10.1016/j.jvcir.2008.06.006
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mortensen J, 2009, COMM COM INF SC, V61, P106
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PICARD RW, 1995, MULTIMEDIA SYST, V3, P3, DOI 10.1007/BF01236575
   Reddy P. V. N., 2011, Journal of Theoretical and Applied Information Technology, V28, P95
   Richard G, 2008, INT J WEB GRID SERV, V4, P136, DOI 10.1504/IJWGS.2008.018500
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Syropoulos A, 2001, LECT NOTES COMPUT SC, V2235, P347
   Theoharatos C, 2005, IEEE T KNOWL DATA EN, V17, P808, DOI 10.1109/TKDE.2005.85
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Watanabe T, 2002, IEEE T PATTERN ANAL, V24, P579, DOI 10.1109/34.1000234
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
NR 47
TC 10
Z9 12
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1155
EP 1167
DI 10.1016/j.jvcir.2013.07.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700039
DA 2024-07-18
ER

PT J
AU Liu, HM
   Wang, ZH
AF Liu, Hongmin
   Wang, Zhiheng
TI Geometric property based ellipse detection method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Ellipse detection; Inner product; Distance distribution; Symmetry center
   location; Shape detection; Circle detection; Ellipse foci location;
   Geometric property
ID RANDOMIZED HOUGH TRANSFORM; ROBUST ELLIPSE; CURVES; SURFACES;
   CONSTRAINT; SYMMETRY; VISION; IMAGES; CIRCLE; EDGE
AB In this paper a simple but effective and robust ellipse detection method based on geometric property is developed, which mainly utilizes the following two aspects of ellipse geometric information:
   (1) Points on ellipse contour are position-symmetric and the gradient vectors of one pair of symmetric points are parallel or anti-parallel, the fact of which can be used for ellipse center location. In this part, the inner product in mathematics is introduced to evaluate the extent of parallelism of two gradient vectors, and then two concepts, inner product symmetrical energy (IPSE) and inner product consistent energy (IPCE), is defined to compute the probability of a position as a symmetric center.
   (2) The sum of distances of one contour point far from ellipse's two foci is a constant. For two given positions, by computing the distribution of the sum of distances we can validate if they are the correct positions of ellipse foci. Furthermore, ellipse's semi-major axis can be also estimated from distance distribution on the positions of ellipse foci. After determining the center, foci and semi-major axis of an ellipse candidate, other parameters can be easily deduced by resolving the elliptic equation directly.
   Compared with existing methods, the proposed method detects the ellipse using the geometric properties directly while avoiding the complicated application of the ellipse parameter space or fitting step, and it is simple, effective and robust. In addition, the ideas proposed in this paper can be extended for other features extraction, such as general symmetry center location and other shapes detection, and extensive experiments show the good availability of the proposed ideas. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Liu, Hongmin; Wang, Zhiheng] Henan Polytech Univ, Sch Comp Sci & Tech, Jiaozuo 454000, Peoples R China.
C3 Henan Polytechnic University
RP Wang, ZH (corresponding author), Henan Polytech Univ, Sch Comp Sci & Tech, Jiaozuo 454000, Peoples R China.
EM hongminliu@hpu.edu.cn; wzhenry@eyou.com
OI Liu, Hongmin/0000-0001-9834-4087
FU National Natural Science Foundation of China [61201395, 61005033,
   61272394]; Program for Science & Technology Innovation Talents in
   Universities of Henan Province [13HASTIT039]
FX This work is supported by the National Natural Science Foundation of
   China (61201395, 61005033 and 61272394) and Program for Science &
   Technology Innovation Talents in Universities of Henan Province
   (13HASTIT039). The authors thank Dr. Zhi-Yong Liu of Key Laboratory of
   Complex Systems and Intelligence Science, Institute of Automation,
   Chinese Academy of Science for providing the source program of his
   method kindly. The authors are also grateful for the valuable and
   constructive comments from the reviewers.
CR Aguado AS, 1996, PATTERN RECOGN, V29, P369, DOI 10.1016/0031-3203(94)00096-4
   Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237
   Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen KC, 2011, EXPERT SYST APPL, V38, P7622, DOI 10.1016/j.eswa.2010.12.098
   Chia AYS, 2011, IEEE T IMAGE PROCESS, V20, P1991, DOI 10.1109/TIP.2010.2099127
   Chojnacki W, 2004, IEEE T PATTERN ANAL, V26, P264, DOI 10.1109/TPAMI.2004.1262197
   Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   HO CT, 1995, PATTERN RECOGN, V28, P117, DOI 10.1016/0031-3203(94)00077-Y
   KALVIAINEN H, 1995, IMAGE VISION COMPUT, V13, P239, DOI 10.1016/0262-8856(95)99713-B
   Kim E., 2002, P INT C INF TECHN AP, P357
   Kiryati N, 2000, PATTERN RECOGN LETT, V21, P1157, DOI 10.1016/S0167-8655(00)00077-5
   Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375
   Lei YW, 1999, PATTERN RECOGN LETT, V20, P41, DOI 10.1016/S0167-8655(98)00127-5
   Liu ZY, 2009, PATTERN RECOGN, V42, P2421, DOI 10.1016/j.patcog.2009.01.028
   Lu W, 2008, PATTERN RECOGN, V41, P1268, DOI 10.1016/j.patcog.2007.09.006
   Mai F, 2008, PATTERN RECOGN, V41, P2512, DOI 10.1016/j.patcog.2008.01.027
   McLaughlin RA, 1998, PATTERN RECOGN LETT, V19, P299, DOI 10.1016/S0167-8655(98)00010-5
   Pietrowcew A, 2003, OPTO-ELECTRON REV, V11, P247
   Prasad DK, 2012, PATTERN RECOGN, V45, P3204, DOI 10.1016/j.patcog.2012.02.014
   Qiao Y, 2004, PATTERN RECOGN, V37, P755, DOI 10.1016/j.patcog.2003.08.008
   Qiao Y, 2007, PATTERN RECOGN, V40, P1990, DOI 10.1016/j.patcog.2006.10.009
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Toennies K, 2002, INT C PATT RECOG, P1053, DOI 10.1109/ICPR.2002.1048486
   Wu FC, 2010, PATTERN RECOGN, V43, P3273, DOI 10.1016/j.patcog.2010.05.001
   Xie YH, 2002, INT C PATT RECOG, P957, DOI 10.1109/ICPR.2002.1048464
   Xie YD, 2010, IEICE T INF SYST, VE93D, P611, DOI 10.1587/transinf.E93.D.611
   Yu JQ, 2012, PATTERN RECOGN LETT, V33, P492, DOI 10.1016/j.patrec.2011.11.025
   Zhang SC, 2005, PATTERN RECOGN, V38, P273, DOI 10.1016/j.patcog.2004.03.014
NR 31
TC 5
Z9 6
U1 1
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1075
EP 1086
DI 10.1016/j.jvcir.2013.07.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700031
DA 2024-07-18
ER

PT J
AU Serir, A
   Beghdadi, A
   Kerouh, F
AF Serir, A.
   Beghdadi, A.
   Kerouh, F.
TI No-reference blur image quality measure based on multiplicative
   multiresolution decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blur; Contrast; Image quality; Multi-resolution analysis; MMD; Intrinsic
   information analysis; Support Vector Machine; Features extraction
ID BLIND
AB A new approach for analyzing the blur effect on real images is proposed. This approach is based on the Multiplicative Multi-resolution Decomposition MMD. From MMD image-content analysis, a blind image quality measure dedicated to blur is then derived. The proposed measure has been applied on Gaussian-blurred and JPEG2000-compressed images from the LIVE, TID and IVC databases. The performance of the proposed measure is evaluated and compared with some referenced image quality metrics. The experimental results measured in terms of correlation with the subjective assessment of the images, demonstrate the efficiency of the proposed image quality measure in predicting the amount of blur. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Serir, A.; Kerouh, F.] USTHB, LTIR, Fac Elect & Informat, Algiers, Algeria.
   [Beghdadi, A.] Univ Paris 13, L2TI, F-93430 Villetaneuse, France.
C3 University Science & Technology Houari Boumediene; Universite Paris 13
RP Serir, A (corresponding author), USTHB, LTIR, Fac Elect & Informat, Algiers, Algeria.
EM aserir@usthb.dz
RI Beghdadi, Azeddine/ABF-9801-2022; SERIR, Amina/AIE-7078-2022; Kerouh,
   Fatma/AAD-3555-2019; guang, Yu/B-9006-2008
OI Beghdadi, Azeddine/0000-0002-5595-0615; SERIR,
   Amina/0000-0001-7716-1273; , Fatma/0000-0001-5833-1265
CR Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   [Anonymous], 2006, MODERN IMAGE QUALITY
   Beghdadi A, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P485, DOI 10.1109/ISSPA.2003.1224745
   Beghdadi A, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/80537
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Chen MJ, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-3
   Chetouani A., 2011, PCM IEEE PAC RIM C M, P1185
   Choi Min Goo, 2009, ENG TECHNOLOGY, V50, P163
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Ferzli R, 2005, IEEE IMAGE PROC, P1157
   Ferzli R, 2006, IEEE IMAGE PROC, P2949, DOI 10.1109/ICIP.2006.312925
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   FIRESTONE L, 1991, CYTOMETRY, V12, P195, DOI 10.1002/cyto.990120302
   Hassen R., 2010, P IEEE INT C AC SPEE
   Hu H., 2006, P IEEE INT C IM PROC
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Karam LJ, 2009, IEEE J-STSP, V3, P189, DOI 10.1109/JSTSP.2009.2015485
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Marichal X., 1999, P IEEE INT C IM PROC, V3, P386
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   NILL NB, 1992, OPT ENG, V31, P813, DOI 10.1117/12.56114
   Ong EP, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P469, DOI 10.1109/ISSPA.2003.1224741
   Pentland A., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P256, DOI 10.1109/CVPR.1989.37858
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Saad MA, 2010, IEEE IMAGE PROC, P313, DOI 10.1109/ICIP.2010.5653349
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Serir A., 2003, IEEE ISSPIT DARMST A
   Serir A., 2004, IEEE INT C IM PROC O, P24
   Sheikh H.R., Live Image Quality Assessment Database
   Sheikh H.R., 2005, IEEE Transactions on Image Processing, V14
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Souidene W, 2009, IEEE T IMAGE PROCESS, V18, P1487, DOI 10.1109/TIP.2009.2018566
   VAIDYANATHAN PP, 1990, P IEEE, V78, P56, DOI 10.1109/5.52200
   Varadarajan S, 2008, IEEE IMAGE PROC, P401, DOI 10.1109/ICIP.2008.4711776
   VETTERLI M, 1987, IEEE T ACOUSTICS SPE, V35
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 41
TC 16
Z9 22
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 911
EP 925
DI 10.1016/j.jvcir.2013.06.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700016
DA 2024-07-18
ER

PT J
AU Zheng, DC
   Han, M
AF Zheng, Danchen
   Han, Min
TI Shape retrieval and recognition based on fuzzy histogram
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape matching; Uniform fuzzy partition; Fuzzy histogram;
   Classical-histogram-based descriptor; Fuzzy-histogram-based descriptor;
   Fuzzy shape context; Inner-distance fuzzy shape context; Locally
   constrained matching
ID REPRESENTATION; DISTANCE; SIMILARITY; FEATURES
AB Shape representation and shape matching are significant topics in computer and human vision. In this paper, fuzzy histogram model with a uniform fuzzy partition is introduced instead of the classical histogram model, and two fuzzy-histogram-based descriptors are proposed: fuzzy shape context (FSC) and inner-distance fuzzy shape context (IDFSC). Compared with classical-histogram-based descriptors, FSC and IDFSC provide more accurate descriptions of samples distributions in log-polar space. Based on fuzzy-histogram-based descriptors, a novel shape matching framework named locally constrained matching (LCM) is proposed for computing the dissimilarity between shapes, and the rotation invariant problem of descriptors can be properly settled. Experimental results on a variety of shape databases show that shape retrieval and recognition results can be effectively achieved by using the proposed method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zheng, Danchen; Han, Min] Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Peoples R China.
C3 Dalian University of Technology
RP Han, M (corresponding author), Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Peoples R China.
EM minhan@dlut.edu.cn
FU National Nature Science Foundation of China [61074096]; National High
   Technology Research and Development Program of China (863 Program)
   [2007AA04Z158]; National Key Technology R&D Program of China
   [2006BAB14B05]; National Basic Research Program of China (973 Program)
   [2006CB403405]
FX This research is supported by the project (61074096) of the National
   Nature Science Foundation of China, the project (2007AA04Z158) of the
   National High Technology Research and Development Program of China (863
   Program), the project (2006BAB14B05) of the National Key Technology R&D
   Program of China and the project (2006CB403405) of the National Basic
   Research Program of China (973 Program).
CR Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098
   Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   DOULAMIS A, 2001, IEEE INT C MULT EXP, P893
   Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448
   Felzenszwalb PF, 2007, PROC CVPR IEEE, P367
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Haasdonk B, 2004, INT C PATT RECOG, P769, DOI 10.1109/ICPR.2004.1334372
   Haasdonk B, 2002, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2002.1048439
   Keysers D, 2000, INT C PATT RECOG, P38, DOI 10.1109/ICPR.2000.906014
   Keysers D., IEEE T PATTERN ANAL, V29
   Kholgade N, 2009, LECT NOTES COMPUT SC, V5876, P357, DOI 10.1007/978-3-642-10520-3_33
   Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655
   Latecki LJ, 2002, PATTERN RECOGN, V35, P15, DOI 10.1016/S0031-3203(01)00039-5
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Loquin K, 2008, STAT PROBABIL LETT, V78, P1863, DOI 10.1016/j.spl.2008.01.053
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mcneill G., 2006, IEEE COMPUTER SOC C, V1, P885
   McNeill G, 2006, IEEE IMAGE PROC, P937, DOI 10.1109/ICIP.2006.312629
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   Roman Rangel E., 2010, Int. J. Comput. Vis, V90, P1
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   Shi YG, 2007, NEUROIMAGE, V37, P792, DOI 10.1016/j.neuroimage.2007.05.016
   Simard P., 1993, EFFICIENT PATTERN RE
   Super BJ, 2006, INT J PATTERN RECOGN, V20, P1117, DOI 10.1142/S0218001406005174
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   van den Berg J, 2004, INT J APPROX REASON, V35, P291, DOI 10.1016/j.ijar.2003.08.007
   Werman M., IEEE T PATTERN ANAL, V17
   Xiao D, 2010, COMPUT MED IMAG GRAP, V34, P321, DOI 10.1016/j.compmedimag.2009.12.003
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 52
TC 2
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1009
EP 1019
DI 10.1016/j.jvcir.2013.06.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700025
DA 2024-07-18
ER

PT J
AU Falomir, Z
   Museros, L
   Gonzalez-Abril, L
   Velasco-Morente, F
AF Falomir, Zoe
   Museros, Lledo
   Gonzalez-Abril, Luis
   Velasco-Morente, Francisco
TI Measures of similarity between qualitative descriptions of shape, colour
   and size applied to mosaic assembling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Qualitative shape; Qualitative colour; Qualitative size; Conceptual
   neighbourhood diagram; Interval distance; Similarity measure; Mosaic
   assembling; Trencadis
AB A computational approach for obtaining a similarity measure between qualitative descriptions of shape, colour and size of objects within digital images is presented. According to the definition of the qualitative features, the similarity values determined are based on conceptual neighbourhood diagrams or interval distances. An approximate matching algorithm between object descriptions is defined and applied to tile mosaic assembling and results of previous approaches are improved. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Falomir, Zoe] Univ Bremen, Informat FB3, Cognit Syst CoSy, D-28359 Bremen, Germany.
   [Falomir, Zoe; Museros, Lledo] Univ Jaume 1, Engn & Comp Sci Dept, Escola Tecnol & Ciencies Expt, E-12071 Castellon de La Plana, Spain.
   [Gonzalez-Abril, Luis; Velasco-Morente, Francisco] Univ Seville, Appl Econ Dept 1, Fac Ciencias Econ, E-41018 Seville, Spain.
C3 University of Bremen; Universitat Jaume I; University of Sevilla
RP Falomir, Z (corresponding author), Univ Bremen, Informat FB3, Cognit Syst CoSy, Enrique Schmidt Str 5, D-28359 Bremen, Germany.
EM zfalomir@informatik.uni-bremen.de; museros@uji.es; luisgon@us.es;
   velasco@us.es
RI Museros, Lledó/AAO-5549-2021; Falomir, Zoe/L-4639-2014; Velasco-Morente,
   Francisco/E-6301-2010; Gonzalez Abril, Luis/E-6323-2010
OI Falomir, Zoe/0000-0002-6398-8488; Velasco-Morente,
   Francisco/0000-0002-9585-1208; Gonzalez Abril, Luis/0000-0002-2532-0946;
   Museros, Lledo/0000-0001-5521-2666
FU Universitat Jaume I (Fons del Pla Estrategic); Zentrale
   Forschungsforderung der Universitat Bremen under the project name
   "Providing human-understandable qualitative and semantic descriptions";
   Spanish Ministry of Science and Innovation under project ARTEMISA
   [TIN2009-14378-C02-01]
FX This work has been partially supported by Universitat Jaume I (Fons del
   Pla Estrategic de 2011/2012), by the Zentrale Forschungsforderung der
   Universitat Bremen under the project name "Providing
   human-understandable qualitative and semantic descriptions", and by the
   Spanish Ministry of Science and Innovation under project ARTEMISA
   (TIN2009-14378-C02-01).
CR Bai X, 2008, PATTERN RECOGN, V41, P2189, DOI [10.1016/i.patcog.2007.12.016, 10.1016/j.patcog.2007.12.016]
   Bechthold M., 2012, GERONTECHNOLOGY, V11, P360
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cayiroglu I, 2012, ROBOT CIM-INT MANUF, V28, P583, DOI 10.1016/j.rcim.2012.02.008
   Chailloux C, 2011, IEEE J OCEANIC ENG, V36, P627, DOI 10.1109/JOE.2011.2141850
   Cochran W.G., 1977, Sampling techniques, V3rd ed.
   Falomir Z., 2011, QUALITATIVE DISTANCE
   Falomir Z., 2008, P SPAT TEMP REAS WOR
   Falomir Z, 2010, FRONT ARTIF INTEL AP, V220, P281, DOI 10.3233/978-1-60750-643-0-281
   Falomir Z, 2009, FRONT ARTIF INTEL AP, V202, P318, DOI 10.3233/978-1-60750-061-2-318
   Falomir Z, 2012, COMPUT VIS IMAGE UND, V116, P698, DOI 10.1016/j.cviu.2012.01.007
   FREKSA C, 1991, DECISION SUPPORT SYSTEMS AND QUALITATIVE REASONING, P181
   Gonzalez Abril L., 2004, INTELL ARTIF, V8, P111, DOI [10.4114/ia.v8i23.798, DOI 10.4114/IA.V8I23.798]
   Gottfried B, 2008, COMPUT VIS IMAGE UND, V110, P117, DOI 10.1016/j.cviu.2007.05.002
   Griffin LD, 2001, COLOR RES APPL, V26, P151, DOI 10.1002/1520-6378(200104)26:2<151::AID-COL1006>3.0.CO;2-G
   Kaya B, 2005, IND ROBOT, V32, P388, DOI 10.1108/01439910510614655
   KOSIBA DA, 1994, INT C PATT RECOG, P616, DOI 10.1109/ICPR.1994.576377
   Kuijpers B., 2006, GIS 06, P11, DOI [10.1145/1183471.1183475, DOI 10.1145/1183471.1183475]
   Liang H, 2006, INT C PATT RECOG, P476
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Macrini D., 2008, CVPR
   MORI G, 2001, CVPR, V1, P723
   Museros L, 2004, FR ART INT, V110, P858
   Museros L., 2006, THESIS U JAUME 1 CAS
   Museros L., 2007, 2007 IEEE RSJ INT C
   Museros L., 2011, J INTELL MANUF, V22, P1, DOI [10.1007/s10845-011-0524-6, DOI 10.1007/S10845-011-0524-6]
   Navon R, 2000, AUTOMAT CONSTR, V10, P113, DOI 10.1016/S0926-5805(99)00044-8
   Oral A, 2004, ROBOTICA, V22, P235, DOI 10.1017/S0263574703005484
   Oral A, 2009, ROBOT CIM-INT MANUF, V25, P589, DOI 10.1016/j.rcim.2008.04.003
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Sarifuddin M., 2005, Proc. of ACM SIGIR 2005 Workshop on Multimedia Information Retrieval (MMIR 2005), P1
   Schuldt A, 2006, LECT NOTES COMPUT SC, V4071, P261
   Seaborn M, 2005, PATTERN RECOGN, V38, P165, DOI 10.1016/j.patcog.2004.05.001
   Sebastian TB, 2002, LECT NOTES COMPUT SC, V2352, P731
   Steger C., 1996, Technical report FGBV-96-05
   Super BJ, 2004, PATTERN RECOGN LETT, V25, P217, DOI 10.1016/j.patrec.2003.10.003
   Yao FH, 2003, PATTERN RECOGN LETT, V24, P1819, DOI 10.1016/S0167-8655(03)00006-0
NR 37
TC 12
Z9 12
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 388
EP 396
DI 10.1016/j.jvcir.2013.01.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200015
OA Green Published
DA 2024-07-18
ER

PT J
AU Barzigar, N
   Roozgard, A
   Cheng, S
   Verma, P
AF Barzigar, Nafise
   Roozgard, Aminmohammad
   Cheng, Samuel
   Verma, Pramode
TI SCoBeP: Dense image registration using sparse coding and belief
   propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dense image registration; Sparse coding; Belief propagation; Middlebury
   data set
AB Image registration as a basic task in image processing has been studied widely in the literature. It is an important preprocessing step in various applications such as medical imaging, super resolution, and remote sensing. In this paper, we proposed a novel dense registration method based on sparse coding and belief propagation. We used image blocks as features, and then we employed sparse coding to find a set of candidate points. To select optimum matches, belief propagation was subsequently applied on these candidate points. Experimental results show that the proposed approach is able to robustly register scenes and is competitive as compared to high accuracy optical flow Brox et al. (2004) [1], and SIFT flow Liu et al. [2]. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Barzigar, Nafise; Roozgard, Aminmohammad; Cheng, Samuel; Verma, Pramode] Univ Oklahoma, Dept Elect & Comp Engn, Tulsa, OK 74135 USA.
C3 University of Oklahoma System; University of Oklahoma - Tulsa
RP Barzigar, N (corresponding author), Univ Oklahoma, Dept Elect & Comp Engn, Tulsa, OK 74135 USA.
EM Barzigar@ou.edu
OI Cheng, Samuel/0000-0002-5439-1137
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482
   [Anonymous], P INT C IM PROC
   [Anonymous], MIDDLEBURY STEREO VI
   [Anonymous], ECCV
   Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Barzigar N., 2012, IEEE AS C SIGN SYST
   Belhumeur P., 2002, 1992 IEEE COMP SOC C, P506
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Buehler C., 2002, COMP VIS ECCV 2002, P1
   Cheng S, 2009, INT CONF ACOUST SPEE, P2909, DOI 10.1109/ICASSP.2009.4960232
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dai W., 2008, SUBSPACE PURSUIT COM
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Delong A, 2010, PROC CVPR IEEE, P2173, DOI 10.1109/CVPR.2010.5539897
   Enqvist O, 2009, IEEE I CONF COMP VIS, P1295, DOI 10.1109/ICCV.2009.5459319
   Felzenszwalb P., 2011, IEEE T PATTERN ANAL, P1
   Gales G, 2010, LECT NOTES COMPUT SC, V6454, P182, DOI 10.1007/978-3-642-17274-8_18
   Glocker B, 2008, MED IMAGE ANAL, V12, P731, DOI 10.1016/j.media.2008.03.006
   Guo Da-bo, 2009, Acta Electronica Sinica, V37, P1516
   Kang L., 2011, IEEE T MULTIMEDIA, P1
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Liu C., THESIS MIT
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Maleh R., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P77
   Mattoccia S, 2007, LECT NOTES COMPUT SC, V4844, P517
   McLauchlan PF, 2002, IMAGE VISION COMPUT, V20, P751, DOI 10.1016/S0262-8856(02)00064-1
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Miyazaki D, 2010, LECT NOTES COMPUT SC, V5994, P234
   Pang Y., 2011, NEUROCOMPUTING
   Pang Y., 2011, IEEE T SYST MAN CY B, P1
   Pang YW, 2011, SIGNAL PROCESS, V91, P773, DOI 10.1016/j.sigpro.2010.08.010
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Papadakis N, 2010, J MATH IMAGING VIS, V38, P70, DOI 10.1007/s10851-010-0212-8
   Pock T, 2007, LECT NOTES COMPUT SC, V4792, P511
   Psota Eric T., 2011, Proceedings of the 2011 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV 2011), P271
   Quist M., 2010, Medical Image Computing and Computer-Assisted Intervention MICCAI2001, volume 2208 of Lecture Notes in Computer Science, V2208, P573
   Roozgard A., 2012, 34 ANN IEEE INT C EN
   Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   Strecha C., 2006, IEEE Conference on Computer Vision and Pattern Recognition, V2, P2394
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tang TWH, 2007, LECT NOTES COMPUT SC, V4791, P916
   Tell D., 2002, THESIS KTH STOCKHOLM
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Xiong W, 2009, IEEE T PATTERN ANAL, V31, P428, DOI 10.1109/TPAMI.2008.98
   Yang D, 2008, PHYS MED BIOL, V53, P6143, DOI 10.1088/0031-9155/53/21/017
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Zhang QA, 2010, LECT NOTES COMPUT SC, V6474, P255, DOI 10.1007/978-3-642-17688-3_25
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 61
TC 8
Z9 8
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 137
EP 147
DI 10.1016/j.jvcir.2012.08.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000007
DA 2024-07-18
ER

PT J
AU Lu, SY
   Zhang, J
   Wang, ZY
   Feng, DD
AF Lu, Shiyang
   Zhang, Jian
   Wang, Zhiyong
   Feng, David Dagan
TI Fast human action classification and VOI localization with enhanced
   sparse coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action classification; Localization; Sparse coding; Volume of
   Interest (VOI)
AB Sparse coding which encodes the natural visual signal into a sparse space for visual codebook generation and feature quantization, has been successfully utilized for many image classification applications. However, it has been seldom explored for many video analysis tasks. In particular, the increased complexity in characterizing the visual patterns of diverse human actions with both the spatial and temporal variations imposes more challenges to the conventional sparse coding scheme. In this paper, we propose an enhanced sparse coding scheme through learning discriminative dictionary and optimizing the local pooling strategy. Localizing when and where a specific action happens in realistic videos is another challenging task. By utilizing the sparse coding based representations of human actions, this paper further presents a novel coarse-to-fine framework to localize the Volumes of Interest (VOIs) for the actions. Firstly, local visual features are transformed into the sparse signal domain through our enhanced sparse coding scheme. Secondly, in order to avoid exhaustive scan of entire videos for the VOI localization, we extend the Spatial Pyramid Matching into temporal domain, namely Spatial Temporal Pyramid Matching, to obtain the VOI candidates. Finally, a multi-level branch-and-bound approach is developed to refine the VOI candidates. The proposed framework is also able to avoid prohibitive computations in local similarity matching (e.g., nearest neighbors voting). Experimental results on both two popular benchmark datasets (KTH and YouTube UCF) and the widely used localization dataset (MSR) demonstrate that our approach reduces computational cost significantly while maintaining comparable classification accuracy to that of the state-of-the-art methods. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Lu, Shiyang; Wang, Zhiyong; Feng, David Dagan] Univ Sydney, Sydney, NSW 2006, Australia.
   [Zhang, Jian] Univ Technol Sydney, Sydney, NSW 2007, Australia.
C3 University of Sydney; University of Technology Sydney
RP Lu, SY (corresponding author), Univ Sydney, Sydney, NSW 2006, Australia.
EM shiyang@it.usyd.edu.au
OI Zhang, Jian/0000-0002-7240-3541; Wang, Zhiyong/0000-0002-8043-0312;
   Feng, Dagan/0000-0002-3381-214X
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Boureau Y., 2010, P ITN C MACH LEARN I
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Derpanis KG, 2010, PROC CVPR IEEE, P1990, DOI 10.1109/CVPR.2010.5539874
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hamker FH, 2004, NEUROCOMPUTING, V56, P329, DOI 10.1016/j.neucom.2003.09.006
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee H., 2007, ADV NEURAL INFORM PR, P801, DOI DOI 10.7551/MITPRESS/7503.003.0105
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Niebles JC, 2007, PROC CVPR IEEE, P1235
   Ramirez I., 2010, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2010.5539964, 10.1109/CVPR.2010.5539964]
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418
   Yan Zhu, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P660, DOI 10.1007/978-3-642-19309-5_51
   Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Yu G, 2011, PROC CVPR IEEE, P865, DOI 10.1109/CVPR.2011.5995488
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
NR 35
TC 5
Z9 5
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 127
EP 136
DI 10.1016/j.jvcir.2012.07.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000006
DA 2024-07-18
ER

PT J
AU Gao, DH
   Wu, XL
   Shi, GM
   Zhang, L
AF Gao, Dahua
   Wu, Xiaolin
   Shi, Guangming
   Zhang, Lei
TI Color demosaicking with an image formation model and adaptive PCA
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color demosaicking; Image formation model; Principal component analysis;
   Sparsity; Color filter array; Digital cameras; Zipper effect; Sparse
   representation
ID ALGORITHMS; CAMERAS
AB Color demosaicking is an ill-posed inverse problem of image restoration. The performance of a color demosaicking algorithm depends on how thoroughly it can exploit domain knowledge to confine the solution space for the underlying true color image. We propose an l(1) minimization technique for color demosaicking that exploits spectral and spatial sparse representations of natural images jointly. The spectral sparse representation is derived from a physical image formation model; the spatial sparse representation is based on a windowed adaptive principal component analysis. In some of most challenging cases of color demosaicking, the new technique outperforms many existing techniques by a large margin in PSNR and achieves higher visual quality. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Gao, Dahua; Wu, Xiaolin; Shi, Guangming] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Gao, Dahua] AF Engn Univ, Sch Sci, Xian, Peoples R China.
   [Wu, Xiaolin] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
   [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
C3 Xidian University; Air Force Engineering University; McMaster
   University; Hong Kong Polytechnic University
RP Gao, DH (corresponding author), Xidian Univ, Sch Elect Engn, 2 S Taibai Rd,Box 134, Xian 710071, Shaanxi, Peoples R China.
EM gaodahua@gmail.com
RI Zhang, Lei/P-8881-2014
OI Zhang, Lei/0000-0002-2078-4215; Gao, Dahua/0000-0002-0900-0483
FU National Science Foundation of China [61003148, 60902031, 61070138,
   61072104, 61033004]
FX This work was supported in part by the National Science Foundation of
   China under Grants 61003148, 60902031, 61070138, 61072104, and 61033004.
CR Angel E., 2003, INTERACTIVE COMPUTER
   Bayer E. B., 1976, Patent No. [U. S. Patent, 3,971,065, 3971065]
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Chang LL, 2004, IEEE T CONSUM ELECTR, V50, P355, DOI 10.1109/TCE.2004.1277885
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Comninos P., 2006, MATH COMPUTER PROGRA, DOI DOI 10.1007/978-1-84628-292-8
   Ferradans S, 2009, IEEE T IMAGE PROCESS, V18, P665, DOI 10.1109/TIP.2008.2010204
   Foley J. D., 1994, Introduction to Computer Graphics", V55
   Fukunaga K., 1991, INTRO STAT PATTERN R, V2nd
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Hamilton J. F., U.S. patent, Patent No. [5, 629-734, 5629734]
   Heiss-Czedik D, 2009, J VIS COMMUN IMAGE R, V20, P389, DOI 10.1016/j.jvcir.2009.04.003
   Hirakawa K, 2005, IEEE T IMAGE PROCESS, V14, P360, DOI 10.1109/TIP.2004.838691
   Leung B, 2011, IEEE T IMAGE PROCESS, V20, P1885, DOI 10.1109/TIP.2011.2107524
   Li X, 2008, PROC SPIE, V6822, DOI 10.1117/12.766768
   Lu WM, 2003, IEEE T IMAGE PROCESS, V12, P1194, DOI 10.1109/TIP.2003.816004
   Malvar H. S., 2004, ICASSP 04, V3, P17
   Menon D., 2008, THESIS U PADOVA
   Omer O. A., 2007, INT C INF COMM SIGN, P1
   Saito T., 2009, P IEEE INT C IM PROC, pC1625
   Saito T., 2008, P SPIE ELECT IMAGING, V6817
   Wu XL, 2004, IEEE T IMAGE PROCESS, V13, P1263, DOI 10.1109/TIP.2004.832920
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zhang F, 2009, IEEE T IMAGE PROCESS, V18, P2706, DOI 10.1109/TIP.2009.2029987
NR 24
TC 17
Z9 17
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1019
EP 1030
DI 10.1016/j.jvcir.2012.06.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900006
DA 2024-07-18
ER

PT J
AU Liu, QG
   Wang, SS
   Luo, JH
   Zhu, YM
   Ye, M
AF Liu, Qiegen
   Wang, Shanshan
   Luo, Jianhua
   Zhu, Yuemin
   Ye, Meng
TI An augmented Lagrangian approach to general dictionary learning for
   image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Dictionary learning; Augmented Lagrangian;
   Bregman iterative method; Accelerated technique; Iteratively Reweighted
   Norm; Gaussian noise removal; Impulse noise removal
ID ITERATIVE REGULARIZATION; THRESHOLDING ALGORITHM; SPARSE; RECONSTRUCTION
AB This paper presents an augmented Lagrangian (AL) based method for designing of overcomplete dictionaries for sparse representation with general l(q)-data fidelity term (q <= 2). In the proposed method, the dictionary is updated via a simple gradient descent method after each inner minimization step of the AL scheme. Besides, a modified Iterated Shrinkage/Thresholding Algorithm is employed to accelerate the sparse coding stage of the algorithm. We reveal that the dictionary update strategy of the proposed method is different from most of existing methods because the learned dictionaries become more and more complex regularly. An advantage of the iterated refinement methodology is that it makes the method less dependent on the initial dictionary. Experimental results on real image for Gaussian noise removal (q = 2) and impulse noise removal (q = 1) consistently demonstrate that the proposed approach can efficiently remove the noise while maintaining high image quality. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Liu, Qiegen; Wang, Shanshan; Luo, Jianhua] Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200240, Peoples R China.
   [Zhu, Yuemin] Univ Lyon 1, CREATIS, CNRS UMR 5220, INSA Lyon,Inserm U630, F-69365 Lyon, France.
   [Ye, Meng] Shanghai Jiao Tong Univ, Dept Math, Shanghai 200240, Peoples R China.
   [Liu, Qiegen] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
   [Luo, Jianhua] Shanghai Jiao Tong Univ, Coll Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Centre National de la Recherche
   Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences
   (INSIS); Institut National de la Sante et de la Recherche Medicale
   (Inserm); Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1; Shanghai Jiao Tong University;
   Nanchang University; Shanghai Jiao Tong University
RP Luo, JH (corresponding author), Shanghai Jiao Tong Univ, Coll Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
EM jhluo@sjtu.edu.cn
RI Shi, Yaolin/JXN-8322-2024; Luo, jian/HGE-7331-2022; Wang,
   Shanshan/T-6972-2017; Zhu, Yuemin/K-7292-2014
OI Wang, Shanshan/0000-0002-0575-6523; Zhu, Yuemin/0000-0001-6814-1449
FU High Technology Research Development Plan (863 plan) of PR China
   [2006AA020805]; NSFC of China [30670574]; Shanghai International
   Cooperation Grant [06SR07109]; Region Rhone-Alpes of France; French ANR
   [ANR-859 09-BLAN-0372-01]; National Natural Science Foundation of China
   [61141007]; Chinese NSFC [30911130364]
FX This work was partly supported by High Technology Research Development
   Plan (863 plan) of PR China under 2006AA020805, the NSFC of China under
   30670574, Shanghai International Cooperation Grant under 06SR07109,
   Region Rhone-Alpes of France under the project Mira Recherche 2008, the
   joint project of Chinese NSFC (under 30911130364) and French ANR 2009
   (under ANR-859 09-BLAN-0372-01), and the National Natural Science
   Foundation of China under Nos. 61141007.
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aharon M, 2008, SIAM J IMAGING SCI, V1, P228, DOI 10.1137/07070156X
   [Anonymous], 2008, TECHNION
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], TECHNICAL REPORT
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bertsekas D. P., 1982, REINFORCEMENT LEARNI
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger M, 2005, LECT NOTES COMPUT SC, V3752, P25
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dobigeon N, 2010, IEEE T SIGNAL PROCES, V58, P2675, DOI 10.1109/TSP.2010.2041594
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   ENGAN K, 1999, P ISCS
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Granai L., 2005, P WORKSH SIGN PROC A
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Liu QG, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-58
   Liu QG, 2012, J VIS COMMUN IMAGE R, V23, P182, DOI 10.1016/j.jvcir.2011.09.008
   Mairal J., 2009, P ICCV
   Mairal J., 2009, Online dictionary learning for sparse coding
   Malgouyres F, 2009, INT J COMPUT VISION, V83, P294, DOI 10.1007/s11263-009-0227-z
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251
   Rodriguez P., 2008, P 4 IEEE AND TECHN C
   Rodríguez P, 2009, IEEE T IMAGE PROCESS, V18, P322, DOI 10.1109/TIP.2008.2008420
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Takeda H, 2006, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2006.312573
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JJ, 2007, IEEE T IMAGE PROCESS, V16, P534, DOI 10.1109/TIP.2006.888335
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zhou M., 2009, Neural Information Processing Systems (NIPS)
NR 38
TC 24
Z9 27
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 753
EP 766
DI 10.1016/j.jvcir.2012.04.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400007
DA 2024-07-18
ER

PT J
AU Li, GR
   Huang, QM
   Pang, JBA
   Jiang, SQ
   Qin, L
AF Li, Guorong
   Huang, Qingming
   Pang, Junbiao
   Jiang, Shuqiang
   Qin, Lei
TI Online selection of the best <i>k</i>-feature subset for object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Feature subset selection; Feature selection; Feature
   subset tree; Conditional entropy; Greedy search algorithm; Particle
   filter; Online selection
AB In this paper, we propose a new feature subset evaluation method for feature selection in object tracking. According to the fact that a feature which is useless by itself could become a good one when it is used together with some other features, we propose to evaluate feature subsets as a whole for object tracking instead of scoring each feature individually and find out the most distinguishable subset for tracking. In the paper, we use a special tree to formalize the feature subset space. Then conditional entropy is used to evaluating feature subset and a simple but efficient greedy search algorithm is developed to search this tree to obtain the optimal k-feature subset quickly. Furthermore, our online k-feature subset selection method is integrated into particle filter for robust tracking. Extensive experiments demonstrate that k-feature subset selected by our method is more discriminative and thus can improve tracking performance considerably. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Li, Guorong; Huang, Qingming] Chinese Acad Sci, Grad Univ, Beijing 100190, Peoples R China.
   [Huang, Qingming; Pang, Junbiao; Jiang, Shuqiang; Qin, Lei] Chinese Acad Sci, Inst Comput Tech, Key Lab Intell Info Proc, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Li, GR (corresponding author), Chinese Acad Sci, Grad Univ, Beijing 100190, Peoples R China.
EM grli@jdl.ac.cn
RI Li, Guorong/AAG-1594-2020; Huang, Qingming/GLR-3473-2022
OI Huang, Qingming/0000-0002-3025-7099
FU National Basic Research Program of China (973 Program) [2009CB320906];
   National Natural Science Foundation of China [61025011, 61035001,
   61133003, 61003165]; Beijing Natural Science Foundation [4111003]
FX This work was supported in part by National Basic Research Program of
   China (973 Program): 2009CB320906, in part by National Natural Science
   Foundation of China: 61025011, 61035001, 61133003 and 61003165, and in
   part by Beijing Natural Science Foundation: 4111003.
CR [Anonymous], CAVIAR TEST CASE SCE
   [Anonymous], 2005, IEEE INT WORKSH PERF
   Chen X., 2007, P 24 INT C MACH LEAR, P153, DOI DOI 10.1145/1273496.1273516
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Grabner H., 2006, BMVC, P47
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Huber Marco F., 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P181, DOI 10.1109/MFI.2008.4648062
   Jiang D., INFORM THEORY CODING, P77
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Liang W., 2007, IEEE INT C IM PROC, V3, P369
   LIU X., 2007, INT C COMPUTER VISIO, P1
   Pearl J., 1984, Heuristics: Intelligent Search Strategies for Computer Problem Solving
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Tu J., 2009, MACHINE VISION APPL
   Wang JY, 2005, PROC CVPR IEEE, P1037
NR 15
TC 8
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 254
EP 263
DI 10.1016/j.jvcir.2011.11.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900003
DA 2024-07-18
ER

PT J
AU Luong, H
   Goossens, B
   Pizurica, A
   Philips, W
AF Luong, Hiep
   Goossens, Bart
   Pizurica, Aleksandra
   Philips, Wilfried
TI Total least square kernel regression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kernel regression; Total least square; Super-resolution; Orthogonal
   distance regression; Image fusion; Gauss-Newton; Non-uniform resampling;
   Registration error
ID SUPERRESOLUTION; RECONSTRUCTION
AB In this paper, we study the problem of robust image fusion in the context of multi-frame super-resolution. Given multiple aligned noisy low-resolution images, image fusion produces a new image on a high-resolution grid. Recently, kernel regression is presented as a powerful image fusion technique. However, in the presence of registration errors, the performance of kernel regression is quite poor. Therefore, we present a new kernel regression method that takes these registration errors into account. Instead of the ordinary least square metric, we employ the total least square metric, which allows for spatial perturbations of the image samples. We show in our experiments that our method is more robust to noise and/or registration errors compared to the traditional kernel regression algorithm. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Luong, Hiep; Goossens, Bart; Pizurica, Aleksandra; Philips, Wilfried] Univ Ghent, IBBT, Dept Telecommun & Informat Syst, B-9000 Ghent, Belgium.
C3 Ghent University
RP Luong, H (corresponding author), Univ Ghent, IBBT, Dept Telecommun & Informat Syst, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM hiep.luong@telin.ugent.be
RI Goossens, Bart/H-4772-2018; Pizurica, Aleksandra/AAG-4687-2021;
   Pizurica, Aleksandra/ISU-9519-2023; Luong, Hiep/HKN-4631-2023; Luong,
   Hiep Quang/AAA-7371-2020
OI Pizurica, Aleksandra/0000-0002-9322-4999; Pizurica,
   Aleksandra/0000-0002-9322-4999; Luong, Hiep Quang/0000-0002-6246-5538
CR Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], P IEEE INT C IM PROC
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Fruchter AS, 2002, PUBL ASTRON SOC PAC, V114, P144, DOI 10.1086/338393
   GERCHBERG RW, 1974, OPT ACTA, V21, P709, DOI 10.1080/713818946
   Glasbey CA, 1998, J APPL STAT, V25, P155, DOI 10.1080/02664769823151
   Knutsson H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P515, DOI 10.1109/CVPR.1993.341081
   Markovsky I, 2007, SIGNAL PROCESS, V87, P2283, DOI 10.1016/j.sigpro.2007.04.004
   Nadaraya E.A., 1964, Theory of Probability and Its Applications, V61, P405, DOI [10.1137/1109020, DOI 10.1137/1109020]
   Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891
   PAPOULIS A, 1975, IEEE T CIRCUITS SYST, V22, P735, DOI 10.1109/TCS.1975.1084118
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   PELEG S, 1987, PATTERN RECOGN LETT, V5, P223, DOI 10.1016/0167-8655(87)90067-5
   Pham TQ, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/83268
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Unser M, 2000, P IEEE, V88, P569, DOI 10.1109/5.843002
   van Wijk C, 2004, LECT NOTES COMPUT SC, V3216, P200
NR 18
TC 5
Z9 5
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 94
EP 99
DI 10.1016/j.jvcir.2011.09.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100009
OA Green Published
DA 2024-07-18
ER

PT J
AU Ding, WP
   Xiong, RQ
   Shi, YH
   Kong, DH
   Yin, BC
AF Ding, Wenpeng
   Xiong, Ruiqin
   Shi, Yunhui
   Kong, Dehui
   Yin, Baocai
TI Fast mode dependent directional transform via butterfly-style transform
   and integer lifting steps
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DCT; KLT; Lifting; Structured matrix; Integer transform; Video coding;
   H.264/AVC; Fast transform
ID DISCRETE COSINE TRANSFORM; ALGORITHM
AB Mode dependent directional transform (MDDT) can improve the coding efficiency of H.264/AVC but it also brings high computation complexity. In this paper we present a new design for implementing fast MDDT transform through integer lifting steps. We first approximate the optimal MDDT by a proper transform matrix that can be implemented with butterfly-style operation. We further factorize the butterfly-style transform into a series of integer lifting steps to eliminate the need of multiplications. Experimental results show that the proposed fast MDDT can significantly reduce the computation complexity while introducing negligible loss in the coding efficiency. Due to the merit of integer lifting steps, the proposed fast MDDT is reversible and can be implemented on hardware very easily. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Ding, Wenpeng; Shi, Yunhui; Kong, Dehui; Yin, Baocai] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
   [Xiong, Ruiqin] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
C3 Beijing University of Technology; Peking University
RP Ding, WP (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
EM wpding@gmail.com
FU NSFC [61003182, 61033004, 60825203, 60973056, U0935004]; National Key
   Basic Research Program of China (973 Program) [2011CB302703]; BJNSF
   [4112007, 4102009]
FX The authors would like to thank the reviewers and editors for reviewing
   this paper and their helpful comments. The authors thank Dr. Feng Wu and
   Dr. Jizheng Xu for many helpful discussions. This paper is supported by
   NSFC (No. 61003182, 61033004, 60825203, 60973056, U0935004), National
   Key Basic Research Program of China (973 Program) (2011CB302703), BJNSF
   (4112007, 4102009).
CR [Anonymous], KTA SOFTWARE
   [Anonymous], VCEG 13 M AUST TEX U
   BJONTEGAARD G, 2007, VCEG 31 MARR MA 15 1
   Bjontegaard G., 2008, VCEG 35 M BERL GERM
   Budagavi M., 2010, VCEGAM20 ITUT
   CVETKOVIC Z, 1992, IEEE T SIGNAL PROCES, V40, P2083, DOI 10.1109/78.150010
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   HOU HS, 1987, IEEE T ACOUST SPEECH, V35, P1455
   *ISO IEC JTC1 SC 2, 2009, MPEG VIS
   Kok CW, 1997, IEEE T SIGNAL PROCES, V45, P757, DOI 10.1109/78.558495
   Liang J, 2001, IEEE T SIGNAL PROCES, V49, P3032, DOI 10.1109/78.969511
   N11113, 2010, JOINT COLL TEAM VID
   Vaidyanathan P. P., 1993, MULTIRATE SYSTEMS FI
   Ye Y., 2007, VCEGAG11 ITUT
   YE Y, ICIP2008, P2116
NR 15
TC 2
Z9 2
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 721
EP 726
DI 10.1016/j.jvcir.2011.01.007
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200005
DA 2024-07-18
ER

PT J
AU Zhao, TS
   Wang, HL
   Kwong, S
   Kuo, CCJ
   Halang, WA
AF Zhao, Tiesong
   Wang, Hanli
   Kwong, Sam
   Kuo, C. -C. Jay
   Halang, Wolfgang A.
TI Hierarchical B-picture mode decision in H.264/SVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; Scalable video coding; Temporal scalability; Hierarchical
   B-picture prediction structure; Mode decision; Mode classification;
   All-zero macroblock detection; Neighboring prediction
ID INTERMODE DECISION; ALGORITHM
AB To enable robust video transmission over heterogeneous networks, the hierarchical B-picture prediction structure is employed in the state-of-the-art video coding standard H.264/SVC, aiming to produce scalable bitstreams with various frame rates. However, the exhaustive mode decision process with the hierarchical B-picture structure increases the computational complexity of H.264/SVC encoding dramatically. In this paper, a fast mode decision algorithm is proposed to speed up H.264/SVC encoding with the hierarchical B-picture structure, which is achieved by utilizing macroblock (MB) features, correlation of temporal-spatial neighboring MBs, and the discrepant characteristics of hierarchical layers. Extensive experimental results demonstrate that the proposed algorithm is able to reduce the encoding time of H.264/SVC significantly for video sequences with a wide range of resolutions, and meanwhile the video quality and compression ratio are well preserved. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Wang, Hanli] Tongji Univ, Dept Comp Sci & Technol, Minist Educ, Shanghai 200092, Peoples R China.
   [Wang, Hanli] Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.
   [Zhao, Tiesong; Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Kuo, C. -C. Jay] Univ So Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
   [Halang, Wolfgang A.] Univ Hagen, Fac Math & Comp Sci, D-58084 Hagen, Germany.
C3 Tongji University; Tongji University; City University of Hong Kong;
   University of Southern California; University of Southern California;
   Fern University Hagen
RP Wang, HL (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Minist Educ, Shanghai 200092, Peoples R China.
EM ztiesong2@student.cityu.edu.hk; hanliwang@tongji.edu.cn;
   cssamk@cityu.edu.hk; cckuo@sipi.usc.edu;
   wolfgang.halang@fernuni-hagen.de
RI Wang, Hanli/K-5717-2019; Kwong, Sam/C-9319-2012; Halang, Wolfgang
   A./O-3573-2016; Wang, Hanli/G-5111-2014; Kuo, C.-C. Jay/A-7110-2011
OI Wang, Hanli/0000-0002-9999-4871; Kwong, Sam/0000-0001-7484-7261; Wang,
   Hanli/0000-0002-9999-4871; Kuo, C.-C. Jay/0000-0001-9474-5035
FU Hong Kong Research Grants Council [9041353, CityU 115408, 9041495, CityU
   115109]; Germany Alexander von Humboldt Research Fellowship; Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning; Program for New Century Excellent
   Talents in University of China [NCET-10-0634]; Shanghai Pujiang Program;
   Science and Technology Commission of Shanghai Municipality
   [10DJ1400300]; National Basic Research Program (973 Program) of China
   [2010CB328101]
FX This work was supported in part by the Hong Kong Research Grants Council
   General Research Fund, under Projects 9041353 (CityU 115408) and 9041495
   (CityU 115109), the Germany Alexander von Humboldt Research Fellowship,
   the Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning, the Program for New Century
   Excellent Talents in University of China under Grant NCET-10-0634, the
   Shanghai Pujiang Program, the 2010 Innovation Action Plan of Science and
   Technology Commission of Shanghai Municipality under Grant 10DJ1400300,
   and the National Basic Research Program (973 Program) of China under
   Grant 2010CB328101.
CR BJONTEGAARD G, 2001, VCEGM33, V4
   Hamamoto T., 2009, ICIC EXPRESS LETT, V3, P1179
   *ISO, 2005, 14496102005E ISOIEC, V3
   Kim JH, 2008, J VIS COMMUN IMAGE R, V19, P175, DOI 10.1016/j.jvcir.2007.09.001
   LEE B, 2008, P SPIE VISUAL COMMUN
   Li H, 2006, IEEE T CIRC SYST VID, V16, P889, DOI 10.1109/TCSVT.2006.877404
   Lin HC, 2009, IEEE IMAGE PROC, P3425, DOI 10.1109/ICIP.2009.5413868
   Liu Z, 2009, IEEE T CIRC SYST VID, V19, P128, DOI 10.1109/TCSVT.2008.2005804
   Paul M, 2009, IEEE T MULTIMEDIA, V11, P581, DOI 10.1109/TMM.2009.2017610
   REICHEL J, 2007, JVTX202, V7
   Ri SH, 2009, IEEE T CIRC SYST VID, V19, P302, DOI 10.1109/TCSVT.2008.2009257
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   Wang HL, 2007, IEEE T MULTIMEDIA, V9, P882, DOI 10.1109/TMM.2007.893345
   WIEGAND T, 2007, JVTX201, V7
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Zeng HQ, 2009, IEEE T CIRC SYST VID, V19, P491, DOI 10.1109/TCSVT.2009.2014014
   Zhao TS, 2010, IEEE T CIRC SYST VID, V20, P697, DOI 10.1109/TCSVT.2010.2045812
NR 17
TC 2
Z9 3
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 627
EP 633
DI 10.1016/j.jvcir.2011.07.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800005
DA 2024-07-18
ER

PT J
AU Sánchez-Nielsen, E
   Hernández-Tejera, M
AF Sanchez-Nielsen, Elena
   Hernandez-Tejera, Mario
TI Heuristic algorithm for visual tracking of deformable objects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Real-time visual tracking; Heuristic tracking algorithm; Template
   matching; Template updating; Template tracking; Heuristic search; Target
   motion; Kullback-Leibler
ID REGISTRATION
AB Many vision problems require fast and accurate tracking of objects in dynamic scenes. These problems can be formulated as exploration problems and thus can be expressed as a search into a state space based approach. However, these problems are hard to solve because they involve search through a space of transformations corresponding to all the possible motion and deformation. In this paper, we propose a heuristic algorithm through the space of transformations for computing target 2D motion. Three features are combined in order to compute efficient motion: (1) a quality of function match based on a holistic similarity measurement, (2) Kullback-Leibler measure as heuristic to guide the search process and (3) incorporation of target dynamics into the search process for computing the most promising search alternatives. Once 2D motion has been calculated, the result value of the quality of function match computed is used with the purpose of verifying template updates. A template will be updated only when the target object has evolved to a transformed shape dissimilar with respect to the actual shape. Also, a short-term memory subsystem is included with the purpose of recovering previous views of the target object. The paper includes experimental evaluations with video streams that illustrate the efficiency and suitability for real-time vision based tasks in unrestricted environments. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Sanchez-Nielsen, Elena] Univ La Laguna, Dept Stat Operat Res & Comp Sci, San Cristobal la Laguna 38271, Spain.
   [Hernandez-Tejera, Mario] Univ Campus Tafira, Inst Intelligent Syst & Numer Applicat Engn, Gran Canaria 35017, Spain.
C3 Universidad de la Laguna
RP Sánchez-Nielsen, E (corresponding author), Univ La Laguna, Dept Stat Operat Res & Comp Sci, San Cristobal la Laguna 38271, Spain.
EM enielsen@ull.es; mhernandez@iusiani.ulpgc.es
RI Sánchez-Nielsen, Elena/HTT-2627-2023; Hernandez-Tejera, Francisco
   Mario/L-2679-2017
OI Sánchez-Nielsen, Elena/0000-0003-2114-4137; Hernandez-Tejera, Francisco
   Mario/0000-0001-9717-8048
FU Spanish Government; Canary Islands Autonomous Government [TIN2004-07087,
   PI2003/165]
FX This work has been supported by the Spanish Government and Canary
   Islands Autonomous Government under the Projects TIN2004-07087 and
   PI2003/165.
CR Aloimonos Y., 1993, Active perception
   BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bar-Shalom Yaakov., 1993, ESTIMATION TRACKING
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Brown Christopher, 1995, 534 U ROCH COMP SCI
   Burschka D., 2001, SPIE P MOBILE ROBOTS, P114
   CAMPANI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P90, DOI 10.1016/1049-9660(92)90088-K
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cham T., 1999, IEEE COMPUTER VISION, VII, P219
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Ferrari V, 2001, PROC CVPR IEEE, P226
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kervrann C, 1998, GRAPH MODEL IM PROC, V60, P173, DOI 10.1006/gmip.1998.0469
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Kullback S., 1968, INFORM THEORY STAT
   Lange C, 2003, LECT NOTES ARTIF INT, V2915, P132
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Nielsen ES, 2000, FR ART INT, V56, P164
   PAGLIERONI DW, 1992, CVGIP-GRAPH MODEL IM, V54, P56, DOI 10.1016/1049-9652(92)90034-U
   Parra R., 1999, LECT NOTES COMPUTER, V1542
   Pearl J., 1984, Heuristics: Intelligent Search Strategies for Computer Problem Solving
   Pentland A, 2000, COMMUN ACM, V43, P35, DOI 10.1145/330534.330536
   Rehg J. M., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P35, DOI 10.1007/BFb0028333
   Reynolds J., 1998, THESIS AUSTR NATL U
   Rucklidge W., 1996, Lecture Notes in Computer Science, V1173
   Schlegel C., 1999, LECT NOTES COMPUTER, V1542
   Spengler M, 2003, MACH VISION APPL, V14, P50, DOI 10.1007/s00138-002-0095-9
   Turk M, 2004, COMMUN ACM, V47, P61, DOI 10.1145/962081.962107
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008
NR 40
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 465
EP 478
DI 10.1016/j.jvcir.2011.05.005
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000002
DA 2024-07-18
ER

PT J
AU Pugeault, N
   Krüger, N
AF Pugeault, Nicolas
   Krueger, Norbert
TI Temporal accumulation of oriented visual features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object model building; Visual representation; Feature tracking; Temporal
   filtering; Unscented Kalman filtering; Edge features; Multiple
   hypotheses tracking; Structure from motion
ID SIMULTANEOUS LOCALIZATION; TRACKING; TRANSFORMATION; FILTERS; NUMBER
AB In this paper we present a framework for accumulating on-line a model of a moving object (e.g., when manipulated by a robot). The proposed scheme is based on Bayesian filtering of local features, filtering jointly position, orientation and appearance information. The work presented here is novel in two aspects: first, we use an estimation mechanism that updates iteratively not only geometrical information, but also appearance information. Second, we propose a probabilistic version of the classical n-scan criterion that allows us to select which features are preserved and which are discarded, while making use of the available uncertainty model.
   The accumulated representations have been used in three different contexts: pose estimation, robotic grasping, and driver assistance scenario. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Pugeault, Nicolas] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
   [Krueger, Norbert] Univ So Denmark, Maersk Mc Kinney Moller Inst, DK-5230 Odense, Denmark.
C3 University of Surrey; University of Southern Denmark
RP Pugeault, N (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM n.pugeault@surrey.ac.uk; norbert@mmmi.sdu.dk
RI Pugeault, Nicolas/JGC-8673-2023; Pugeault, Nicolas/I-1873-2015;
   Pugeault, Nicolas/AAF-9768-2019; Kruger, Norbert/P-6315-2015
OI Pugeault, Nicolas/0000-0002-3455-6280; Pugeault,
   Nicolas/0000-0002-3455-6280; Kruger, Norbert/0000-0002-3931-116X
FU European Project PACOPLUS [IST-FP6-IP-027657]
FX This research was funded by the European Project PACOPLUS
   (IST-FP6-IP-027657).
CR [Anonymous], [No title captured]
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 1853, Lectures on Quaternions
   [Anonymous], IEEE T AUTOMATIC CON
   [Anonymous], SIGGRAPH 85
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BOESMAN B, 2009, P VMV 2009, P127
   DAVISON A, 2005, P INT C COMP VIS ICC, V1, P66
   Detry R, 2009, IEEE T PATTERN ANAL, V31, P1790, DOI 10.1109/TPAMI.2009.64
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   GU YL, 1987, IEEE T ROBOTIC AUTOM, V3, P615
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Jahne B., 2002, DIGITAL IMAGE PROCES
   Julier S, 2000, IEEE T AUTOMAT CONTR, V45, P477, DOI 10.1109/9.847726
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P39
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247
   Kraft D, 2008, INT J HUM ROBOT, V5, P247, DOI 10.1142/S021984360800139X
   Kraft D, 2009, LECT NOTES COMPUT SC, V5815, P235, DOI 10.1007/978-3-642-04667-4_24
   KRUGER N, 2004, INTERDISCIPLINARY J, V1, P417
   Lemaire T, 2007, INT J COMPUT VISION, V74, P343, DOI 10.1007/s11263-007-0042-3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mouragnon E, 2006, IEEE INT CONF ROBOT, P3055, DOI 10.1109/ROBOT.2006.1642166
   Nistér D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y
   Pilz F, 2009, LECT NOTES COMPUT SC, V5604, P280, DOI 10.1007/978-3-642-03061-1_14
   Popovic M, 2010, ROBOT AUTON SYST, V58, P551, DOI 10.1016/j.robot.2010.01.003
   PUGEAULT N, 20076 U SO DENM MAER
   PUGEAULT N, 2008, P INT C COMP VIS THE
   PUGEAULT N, 2010, INT J HUM ROBOT, V7, P1
   PUGEAULT N, 2006, P IEEE SYST MAN CYB
   PUGEAULT N, 2010, P INT C COMP VIS THE
   PUGEAULT N, 2008, THESIS G AUGUST U GO
   Shevlin F, 1998, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1998.711236
   SIMONSEN K, 2009, 5 INT S VIS COMP LEC
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   van der Merwe R., 2000, 380 CUEDFINFENGTR CA
   van der Merwe R., 2001, ADV NEURAL INFORM PR, V13
   YANG AT, 1964, ASME, P300
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
NR 44
TC 3
Z9 3
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 153
EP 163
DI 10.1016/j.jvcir.2010.12.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600005
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Lee, SW
   Kuo, CCJ
AF Lee, Szu-Wei
   Kuo, C. -C. Jay
TI H.264/AVC entropy decoder complexity analysis and its applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; CAVLC/UVLC; Decoding complexity model; Rate-distortion
   optimization (RDO); Decoding complexity control; High bit rate video;
   Rate, distortion, and decoding complexity optimization; Bit rate and
   complexity analysis
ID VIDEO
AB Context-based adaptive variable length coding (CAVLC) and universal variable length coding (UVLC) are two entropy coding tools that are supported in all profiles of H.264/AVC coders. In this paper, we investigate the relationship between the bit rate and the CAVLC/UVLC decoding complexity. This relationship can help the encoder choose the best coding parameter to yield the best tradeoff between the rate, distortion, and the decoding complexity performance. A practical application of CAVLC/UVLC decoding complexity reduction is also discussed. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lee, Szu-Wei] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   Univ So Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Lee, SW (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM swli@ms14.hinet.net; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   BJONTEGARRD G, 2002, JVT
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   *INT, INTELR 64 IA 32 ARCH
   intel, Intel VTune performance analyzer
   *JOINT VID TEAM, H264 JM94 REF COD
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee S.W., THESIS U SO CALIFORN
   Lee SW, 2008, IEEE INT SYMP CIRC S, P1616
   Lee SW, 2007, PROC SPIE, V6696, DOI 10.1117/12.730962
   Lee SW, 2010, IEEE T CIRC SYST VID, V20, P706, DOI 10.1109/TCSVT.2010.2045913
   Li ZG, 2004, IEEE IMAGE PROC, P745
   Lin HY, 2008, IEEE T MULTIMEDIA, V10, P31, DOI 10.1109/TMM.2007.911299
   LINDROTH T, 2006, IEEE INT WORKSH MULT
   Ma Z., 2008, IEEE INT C IM PROC I
   RAY A, 2004, PICT COD S PCS 2004
   SHEN G, 2005, IEEE T CIRCUITS SYST, V5, P685
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 20
TC 6
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 61
EP 72
DI 10.1016/j.jvcir.2010.10.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300006
DA 2024-07-18
ER

PT J
AU Liao, X
   Wen, QY
   Zhang, J
AF Liao, Xin
   Wen, Qiao-yan
   Zhang, Jie
TI A steganographic method for digital images with four-pixel differencing
   and modified LSB substitution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Four-pixel differencing; Modified LSB substitution; Data
   hiding; Pixel-value differencing; Error block; Embedding capacity;
   Imperceptible
ID HIDING DATA; INFORMATION; SCHEME
AB To improve the embedding capacity and provide an imperceptible visual quality, a novel steganographic method based on four-pixel differencing and modified least significant bit (LSB) substitution is presented. The average difference value of a four-pixel block is exploited to classify the block as a smooth area or an edge area. Secret data are hidden into each pixel by the k-bit modified LSB substitution method, where k is decided by the level which the average difference value falls into. Readjustment will be executed to guarantee the same level that the average difference value belongs to before and after embedding, and to minimize the perceptual distortion. By proving that the readjusting procedure works, a theoretical proof is given to justify our method succeeded in embedding and extracting. Our experimental results have shown that the proposed method not only has an acceptable image quality but also provides a large embedding capacity. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Liao, Xin; Wen, Qiao-yan] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Zhang, Jie] Beijing Univ Posts & Telecommun, Sch Sci, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Liao, X (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
EM liaoxinbupt@gmail.com
RI Liao, Xin/ITT-1021-2023; Liao, Xin/X-2736-2018
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [60873191, 60903152,
   60821001]; Beijing Natural Science Foundation [4072020]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 60873191, 60903152, 60821001), Beijing Natural Science
   Foundation (Grant No. 4072020).
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Highland HJ, 1997, COMPUT SECUR, V16, P369, DOI 10.1016/S0167-4048(97)82243-2
   Jung KH, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P355, DOI 10.1109/ICHIT.2008.279
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Park YR, 2005, LECT NOTES COMPUT SC, V3612, P962
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang SJ, 2005, APPL MATH COMPUT, V164, P99, DOI 10.1016/j.amc.2004.04.059
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang C.H., 2006, P INT COMP S TAIP TA, P831
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
NR 18
TC 121
Z9 126
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 1
EP 8
DI 10.1016/j.jvcir.2010.08.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300001
DA 2024-07-18
ER

PT J
AU Rahman, MM
   Bhattacharya, P
   Desai, BC
AF Rahman, Md. Mahmudur
   Bhattacharya, Prabir
   Desai, Bipin C.
TI A unified image retrieval framework on local visual and semantic
   concept-based feature spaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Learning methods; Classification;
   Self-organizing map; Support vector machine; Relevance feedback;
   Similarity fusion
ID CLASSIFICATION
AB This paper presents a learning-based unified image retrieval framework to represent images in local visual and semantic concept-based feature spaces. In this framework, a visual concept vocabulary (codebook) is automatically constructed by utilizing self-organizing map (SOM) and statistical models are built for local semantic concepts using probabilistic multi-class support vector machine (SVM). Based on these constructions, the images are represented in correlation and spatial relationship-enhanced concept feature spaces by exploiting the topology preserving local neighborhood structure of the codebook, local concept correlation statistics, and spatial relationships in individual encoded images. Finally, the features are unified by a dynamically weighted linear combination of similarity matching scheme based on the relevance feedback information. The feature weights are calculated by considering both the precision and the rank order information of the top retrieved relevant images of each representation, which adapts itself to individual searches to produce effective results. The experimental results on a photographic database of natural scenes and a bio-medical database of different imaging modalities and body parts demonstrate the effectiveness of the proposed framework. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Rahman, Md. Mahmudur; Desai, Bipin C.] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3H 2G7, Canada.
   [Bhattacharya, Prabir] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ H3H 2G7, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Rahman, MM (corresponding author), Concordia Univ, Dept Comp Sci & Software Engn, Sir George Williams Campus,1515 St Catherine W,EV, Montreal, PQ H3H 2G7, Canada.
EM mah_rahm@cs.concordia.ca
RI Rahman, Md Mahmudur/AAL-3192-2020; cai, bo/G-1491-2010
OI Rahman, Md Mahmudur/0000-0003-0405-9088; 
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   IDEAS; Canada Research Chair; SRTC Concordia University
FX This work was supported by Natural Sciences and Engineering Research
   Council of Canada (NSERC), IDEAS, Canada Research Chair and SRTC
   Concordia University grants. We thank the CLEF [35,36] organizers for
   making the database available for the experiments and C. C. Chang and
   C.J. Lin for the LIBSVM software tool [37] that is utilized for the
   SVM-related experiments.
CR Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   GRUBINGER M, 2006, INT WORKSH ONTOIMAGE, P1323
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Kohonen T., 1997, Self-Organizing Maps
   Laaksonen J, 2002, IEEE T NEURAL NETWOR, V13, P841, DOI 10.1109/TNN.2002.1021885
   LIM JH, 2000, P ACM MULTIMEDIA 200, P407
   MUELLER H, 2006, P LNCS, V4730, P595
   NIBLACK W, P SPIE 93 STOR RETR, P173
   Picard RW, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P777, DOI 10.1109/ICIP.1996.561018
   Rahman MM, 2006, INT DATABASE ENG APP, P201
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   TOWN C, 2000, 200014 ATT RES
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Vesanto J., 1999, Intelligent Data Analysis, V3, P111, DOI 10.1016/S1088-467X(99)00013-X
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   VOGT CC, 1993, INFORM RETRIEVAL, V1, P151
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Yates R. B., 1999, MODERN INFORM RETRIE
   Yen GG, 2005, IEEE IJCNN, P1587
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   ZHU L, 2000, P ACM MULT 2000 LOS, P157
NR 36
TC 14
Z9 16
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2009
VL 20
IS 7
BP 450
EP 462
DI 10.1016/j.jvcir.2009.06.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 559DJ
UT WOS:000274800800002
DA 2024-07-18
ER

PT J
AU Yu, XG
   Li, LY
   Leong, HW
AF Yu, Xinguo
   Li, Liyuan
   Leong, Hon Wai
TI Interactive broadcast services for live soccer video based on instant
   semantics acquisition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive broadcast service; Sports video; Semantic gamelog; Instant
   semantics acquisition; Live event alert; Gamelog translation; On-the-fly
   language selection; Clock time recognition
ID SPORTS VIDEO
AB This paper presents a system for providing interactive broadcast services for live soccer video that is based on instant semantics acquisition. Currently, we have implemented two such interactive services: live event alert and on-the-fly language selection. The live event alert service has a small time lag of about 30 s for a short video clip to reach its final viewer and at most 1.5 min for a long clip of the live event. The on-the-fly language selection service allows users to choose their preferred contents and preferred language. The motivation for this work is that such interactive services will greatly increase the value of live soccer video. Currently, similar systems attempt to derive semantics of a soccer game from gamelog in freestyle text format and low-level features of the video, which is a challenging task. In this paper, we tackle this challenge with a combination of both gamelog input tool and targeted algorithm proposed in this paper. Our system is powered by our proposed semantic gamelog input tool that facilitates fast and accurate input of a semantic gamelog that contains basic semantic information of atomic events. When an interesting event occurs, our system performs boundary detection of these events by combining features extracted from the video with additional information from the semantic gamelog. This additional information facilitates our system to achieve accurate and very fast boundary detection of these events to support our live event alert service. Our system also implements a gamelog translation machine which translates the semantic gamelog (encoded in a game-specific code) into any natural language, provided that there is a configuration file for that language. Combining our gamelog translation machine with existing text-to-speech technology, we provide the on-the-fly language selection service. (Currently, our system supports English, Chinese, and Malay). (C) 2008 Elsevier Inc. All rights reserved.
C1 [Yu, Xinguo; Li, Liyuan] Inst Infocomm Res, Singapore 138632, Singapore.
   [Leong, Hon Wai] Natl Univ Singapore, Dept Comp Sci, Singapore 117590, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); National University of Singapore
RP Yu, XG (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis S Tower, Singapore 138632, Singapore.
EM xinguo@i2r.a-star.edu.sg; lyli@i2r.a-star.edu.sg;
   leonghw@comp.nus.edu.sg
RI Leong, Wai/G-6642-2013
OI leong, wai yie/0000-0002-5389-1121
CR Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   Bolle RM, 1998, IBM J RES DEV, V42, P233, DOI 10.1147/rd.422.0233
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Chang SF, 2002, IEEE MULTIMEDIA, V9, P6, DOI 10.1109/93.998041
   Chen SC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P265, DOI 10.1109/ICME.2004.1394176
   Chong-Wah N., 2001, INT J IMAGE GRAPH, V1, P445
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   GONG Y, 1995, 2 INT C MULT COMP SY, P167
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li BX, 2004, J VIS COMMUN IMAGE R, V15, P393, DOI 10.1016/j.jvcir.2004.04.006
   LI Y, 2006, ICASSP 2, P653
   LI Y, 2006, ICPR, V4, P128
   Pan H, 2002, INT CONF ACOUST SPEE, P3385
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Pingali GS, 2002, IEEE T MULTIMEDIA, V4, P269, DOI 10.1109/TMM.2002.1017739
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   TOVINKERE V, 2001, ICME, P1040
   WAN K, 2005, ICME
   WANG HL, 2000, CHIN ANIM QUANRANTIN, V17, P36
   WANG J, 2004, ACM MM 04, P32
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Xiong ZY, 2003, IEEE IMAGE PROC, P5
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   XU H, 2004, MIR
   XU H, 2005, ICME
   Xu M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P333
   XU M, 2003, ICASSP, P189
   YANG YQ, 2004, INT C MACH LEARN CYB, V6, P3759
   YEW D, 1995, ACCV, P499
   Yu X., 2008, CIVRO8, P495
   YU X, 2008, ICPR08
NR 32
TC 9
Z9 9
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 117
EP 130
DI 10.1016/j.jvcir.2008.12.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800006
DA 2024-07-18
ER

PT J
AU Schmugge, SJ
   Zaffar, MA
   Tsap, LV
   Shin, MC
AF Schmugge, Stephen J.
   Zaffar, M. Adeel
   Tsap, Leonid V.
   Shin, Min C.
TI Task-based evaluation of skin detection for communication and perceptual
   interfaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE skin detection; hand detection; empirical evaluation
ID FACE DETECTION; COLOR; RECOGNITION; HAND; SEGMENTATION; GESTURES; MODEL
AB Skin detection is frequently used as the first step for the tasks of face and gesture recognition in perceptual interfaces for human-computer interaction and communication. Thus, it is important for the researchers using skin detection to choose the optimal method for their specific task. In this paper, we propose a novel method of measuring the performance of skin detection for a task. We have created an evaluation framework for the task of hand detection and executed this assessment using a large dataset containing 17 million pixels from 225 images taken under various conditions. The parameter set of the skin detection has been trained extensively. Five colorspace transformations with and without the illuminance component coupled with two color modeling approaches have been evaluated. The results indicate that the best performance is achieved by transforming to SCT colorspace, using the illuminance component, and modeling the distribution with the histogram approach. Some conclusions such as the SCT colorspace being one of the best colorspaces are consistent with our previous work, while findings such as the YUV colorspace performing well in this work when it was one of the worst in our previous work are different. This indicates that the performance measured at the pixel-level might not be the ultimate indicator for the performance at the task-level of hand detection. We believe that the users of skin detection will find our task-based results to be more relevant than the traditional pixel-level results. However, we acknowledge that an evaluation is limited by its specific dataset and evaluation protocols. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Schmugge, Stephen J.; Zaffar, M. Adeel; Shin, Min C.] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Tsap, Leonid V.] Lawrence Livermore Natl Lab, Syst Res Grp, Adv Communicat & Signal Process Grp, Livermore, CA 94551 USA.
C3 University of North Carolina; University of North Carolina Charlotte;
   United States Department of Energy (DOE); Lawrence Livermore National
   Laboratory
RP Shin, MC (corresponding author), Univ N Carolina, Dept Comp Sci, 9201 Univ City Blvd, Charlotte, NC 28223 USA.
EM sischmug@unec.edu; mazaffar@uncc.edu; tsap@llnl.gov; mcshin@uncc.edu
OI Zaffar, Muhammad Adeel/0000-0002-9986-9149
CR Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   Brand J, 2000, INT C PATT RECOG, P1056, DOI 10.1109/ICPR.2000.905653
   BRETZNER L, 2002, 5 IEEE INT C AUT FAC
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fritsch J, 2002, IEEE ROMAN 2002, PROCEEDINGS, P337, DOI 10.1109/ROMAN.2002.1045645
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Greenspan H, 2001, PATTERN RECOGN LETT, V22, P1525, DOI 10.1016/S0167-8655(01)00086-1
   Hadid A, 2002, INT C PATT RECOG, P196, DOI 10.1109/ICPR.2002.1047431
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   HUNKE M, 1994, 28 AS C SIGN SYST CO
   Jayaram S, 2004, PROC CVPR IEEE, P813
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Marcel S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P456, DOI 10.1109/AFGR.2000.840674
   McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1
   Phung SL, 2002, IEEE IMAGE PROC, P289
   POWELL MW, 1999, P IEEE WORKSH PHOT M, P21
   Poynton CharlesA., 1996, TECHNICAL INTRO DIGI
   RAJA Y, 1998, EUR C COMP VIS JUN
   Sato Y, 2001, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2001.913773
   SCHMUGGE SJ, 2007, COMPUTER VISION IMAG
   Shin MC, 2004, PATTERN RECOGN, V37, P1011, DOI 10.1016/j.patcog.2003.11.007
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Soriano M, 2000, INT C PATT RECOG, P839, DOI 10.1109/ICPR.2000.905542
   SRISUK S, 2002, 5 IEEE INT C AUT FAC, P291
   STORRING M, 2001, ROBOTICS AUTONOMOUS, P131
   Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   YANG J, 1998, ACCV, P687
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
   Zhu YX, 2002, COMPUT VIS IMAGE UND, V85, P189, DOI 10.1006/cviu.2002.0967
NR 33
TC 9
Z9 9
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2007
VL 18
IS 6
BP 487
EP 495
DI 10.1016/j.jvcir.2007.04.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 243NA
UT WOS:000251803400003
DA 2024-07-18
ER

PT J
AU Chang, CC
   Wu, WC
   Hu, YC
AF Chang, Chin-Chen
   Wu, Wen-Chuan
   Hu, Yu-Chen
TI Lossless recovery of a VQ index table with embedded secret data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE data hiding; reversible embedding; vector quantization; data clustering
AB This paper proposes a reversible data embedding scheme based on a VQ image compression technique which emphasizes that the original VQ compressed codes can be recovered after data extraction. In this proposed scheme, a VQ codebook, which had already been clustered into three groups, was adopted to achieve secret concealment and data recovery. In order to embed more secret data, the concepts of frequency clustering and trio extension were also introduced. Experimental results showed that the proposed scheme with the lossless recovery facility could work well. (c) 2006 Elsevier Inc. All rights reserved.
C1 Providence Univ, Dept Comp Sci & Informat Engn, Taichung 433, Taiwan.
   Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 Providence University - Taiwan; Feng Chia University; National Chung
   Cheng University
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Engn, Taichung 433, Taiwan.
EM ccc@cs.ccu.edu.tw; wenn@cs.ccu.edu.tw; ychu@pu.edu.tw
RI Hui, Yu/JOZ-3598-2023; Hu, Yu-Chen/AAT-5264-2020; Chang,
   Ching-Chun/JAN-6210-2023; Wu, Wenchuan/H-6751-2019
OI Hu, Yu-Chen/0000-0002-5055-3645; Wu, Wenchuan/0000-0002-5020-5165
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P947
   Chang CC, 2005, IEICE T INF SYST, VE88D, P2159, DOI 10.1093/ietisy/e88-d.9.2159
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Du WC, 2003, IEE P-VIS IMAGE SIGN, V150, P233, DOI 10.1049/ip-vis:20030525
   Jo M, 2002, IEICE T INF SYST, VE85D, P1054
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lu ZM, 2000, ELECTRON LETT, V36, P303, DOI 10.1049/el:20000309
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai CL, 2004, 38TH ANNUAL 2004 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P226
   Tsai CL, 2005, PATTERN RECOGN, V38, P1993, DOI 10.1016/j.patcog.2005.03.001
   Tseng HW, 2004, INFORMATICA-LITHUAN, V15, P127
   Wu HC, 2004, FUND INFORM, V63, P89
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
NR 15
TC 49
Z9 50
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 207
EP 216
DI 10.1016/j.jvcir.2006.11.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300002
DA 2024-07-18
ER

PT J
AU Lotfallah, O
   Panchanathan, S
AF Lotfallah, Osama
   Panchanathan, Sethuraman
TI Network performance analysis of advanced video coding schemes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE advanced; video coding; error resilience; video streaming; FGS; PFGS;
   router queue; jitter
ID H.264/AVC
AB Advanced video coding schemes, currently under investigation, provide greater bandwidth efficiency than existing schemes. However, the network resources required by these advanced-coded video streams have not yet been fully investigated. In this paper, we present a network performance analysis of recent video coding schemes, such as H.264 coding and PFGS coding. The robustness of these coding schemes to channel losses is evaluated using video sequences containing various motion activity levels. Simulation results showed that H.264 streams require larger buffering at the decoder, to overcome the higher delay variations seen over lossy packet networks. PFGS streams were found to produce reconstruction qualities superior to FGS streams, if the maximum rate of the enhancement layer is selected based on the receiver capabilities. This paper also proposes a framework for quality monitoring of the reconstructed video, after transmission over lossy packet networks and application of appropriate error concealment techniques. The proposed framework is flexible enough to be used with any structure of frame types, and any :level of motion activities in the underlying video sequence. (c) 2005 Elsevier Inc. All rights reserved.
C1 Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
   Arizona State Univ, Dept Elect Engn, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe; Arizona State
   University; Arizona State University-Tempe
RP Panchanathan, S (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
EM Osama.Lotfallah@asu.edu; Panch@asu.edu
CR Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   Feamster N., 2002, 12 INT PACK VID WORK
   Flierl M, 2003, IEEE T CIRC SYST VID, V13, P587, DOI 10.1109/TCSVT.2003.814963
   HE YW, P ISCAS 2002, V4, P548
   HEMAMI S, 2002, P ICIP SEP, P721
   International Organization for Standardization/International Electrotechnical Commission (ISO/IEC), 2001, 1449622001 ISOIEC
   ITO MR, 2002, 8 INT C COMM SYST, V1, P497
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   LIANG YJ, 2003, ICASSP 03 HONG KONG
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu JC, 2003, IEEE MULTIMEDIA, V10, P22, DOI 10.1109/MMUL.2003.1167919
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Ribas-Corbera J, 2003, IEEE T CIRC SYST VID, V13, P674, DOI 10.1109/TCSVT.2003.814965
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wedi T, 2003, IEEE T CIRC SYST VID, V13, P577, DOI 10.1109/TCSVT.2003.815171
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   WENGER S, 1999, Q15I16R1 ITU TEL
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wien M, 2003, IEEE T CIRC SYST VID, V13, P604, DOI 10.1109/TCSVT.2003.815380
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
   Zhang ZL, 1999, IEEE INFOCOM SER, P472, DOI 10.1109/INFCOM.1999.751380
NR 27
TC 1
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 467
EP 489
DI 10.1016/j.jvcir.2005.04.007
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000015
DA 2024-07-18
ER

PT J
AU Chen, DY
   Lee, SY
   Liao, HYM
AF Chen, DY
   Lee, SY
   Liao, HYM
TI Robust video sequence retrieval using a novel object-based T2D-histogram
   descriptor
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE motion activity; spatio-temporal feature description; video sequence
   matching; discrete cosine transform; video similarity measure
AB Due to the tremendous growth in the number of digital videos, the development of video retrieval algorithms that can perform efficient and effective retrieval task is indispensable. In this paper, we propose a high-level motion activity descriptor, object-based transformed 2D-histogram (T2D-histogram), which exploits both spatial and temporal features to characterize video sequences in a semantics-based manner. The discrete cosine transform (DCT) is applied to convert the object-based 2D-histogram sequences from the time domain to the frequency domain. Using this transform, the original high-dimensional time domain features used to represent successive frames are significantly reduced to a set of low-dimensional features in frequency domain. The energy concentration property of DCT allows us to use only a few DCT coefficients to effectively capture the variations of moving objects. Having the efficient scheme for video representation, one can perform video retrieval in an accurate and efficient way. (c) 2004 Elsevier Inc. All rights reserved.
C1 Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
   Acad Sinica, Inst Sci Informat, Taipei 11529, Taiwan.
C3 National Yang Ming Chiao Tung University; Academia Sinica - Taiwan
RP Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, 1001 Ta Hsueh Rd, Hsinchu, Taiwan.
EM dychen@csie.netu.edu.tw; sylee@csie.nctu.edu.tw; liao@iis.sinica.edu.tw
RI Liao, Hong-Yuan Mark/AAQ-5514-2021
CR Aghbari Z, 1998, NINTH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P102, DOI 10.1109/DEXA.1998.707387
   Agnihotri L, 2000, LECT NOTES COMPUT SC, V1929, P62
   [Anonymous], 1977, DISCRETE TIME SIGNAL
   Chen DY, 2002, LECT NOTES COMPUT SC, V2532, P319
   CHEN DY, 2001, P IEEE PCM, P110
   CHEUNG SS, 2001, P IEEE INT C IM PROC, V2, P649
   Divakaran A, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P287, DOI 10.1109/ICIP.2000.899359
   *ISO IEC, 1998, JTC1SC29WG11N2466 IS
   *ISO IEC, 2001, JTC1SC29WG11N4547 IS
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   LEE SY, 2001, P 3 INT C INF COMM S
   LIN T, 2001, P IEEE INT C IM PROC, V2, P592
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mohan R, 1998, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.1998.679686
   PEKER KA, 2000, P IEEE INT C IM PROC, V2, P801
   Roach M, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P146, DOI 10.1109/ISIMP.2001.925353
   Shi Y.Q., 2000, IMAGE PROC SER
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   TANG YP, 2000, IEEE T CIRCUITS SYST, V10, P133
   Wang R, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P33, DOI 10.1109/MMSP.2001.962708
   Wang R, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P21, DOI 10.1109/ISCAS.2000.857353
   Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338
   ZHAO L, 2001, P IEEE INT C AC SPEE, V3, P1625
NR 23
TC 6
Z9 6
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2005
VL 16
IS 2
BP 212
EP 232
DI 10.1016/j.jvcir.2004.08.003
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 915VY
UT WOS:000228340700005
DA 2024-07-18
ER

PT J
AU Poon, WF
   Lo, KT
   Feng, J
AF Poon, WF
   Lo, KT
   Feng, J
TI A hierarchical video-on-demand system with double-rate batching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID ARCHITECTURE; DESIGN
AB In this paper, a two-tier hierarchical network architecture is exploited to provide true video-on-demand (VoD) services using double-rate (DR) batching in multicast environment. In the proposed system, new customers will be grouped together by the local server with the DR batching scheme and then be served by the multicast backbone network. Two scheduling policies are developed to serve customers at the local batching servers. The results show that the hierarchical VoD system can greatly reduce the resources requirement compared with the centralized approach. In addition, in order to secure the multicast channels for the new multicast groups, the backbone channel reservation algorithm that is similar to the look-ahead scheme [Multimedia Systems 3 (1995) 137] is proposed. If there are 100 videos and 500 backbone multicast channels, the system is able to support 0.2 requests/s with less than 7% admission blocking probability. (C) 2004 Elsevier Inc. All rights reserved.
C1 Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Hong Kong, Hong Kong, Peoples R China.
   City Univ Hong Kong, Dept Comp Engn & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; City University of Hong Kong
RP Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Hong Kong, Hong Kong, Peoples R China.
EM enktlo@polyu.edu.hk
RI Lo, Kwok Tung KT/O-2143-2013
CR Carter SW, 1997, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND NETWORKS, PROCEEDINGS, P200, DOI 10.1109/ICCCN.1997.623313
   Chan SHG, 2001, IEEE ACM T NETWORK, V9, P125, DOI 10.1109/90.917070
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   EAGER D, 2000, P IS T SPIE C MULT C
   EAGER D, 2000, PERFGORMANCE EVALUAT
   FENG WC, 1997, THESIS OHIO STATE U
   Golubchik L, 1996, MULTIMEDIA SYST, V4, P140, DOI 10.1007/s005300050019
   Guo Y., 2002, P IEEE INT C COMM, V4, P2607
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Lai YC, 1997, IEEE T BROADCAST, V43, P145, DOI 10.1109/11.598363
   Li VOK, 1996, IEEE J SEL AREA COMM, V14, P1099, DOI 10.1109/49.508281
   Onvural R.O., 1995, ASYNCHRONOUS TRANSFE, VSecond
   Poon WF, 2000, ELECTRON LETT, V36, P1329, DOI 10.1049/el:20000926
   Poon WF, 2001, J NETW COMPUT APPL, V24, P229, DOI 10.1006/jnca.2001.0130
   SINCOSKIE WD, 1991, COMPUT NETWORKS ISDN, V22, P155, DOI 10.1016/0169-7552(91)90007-Y
   Wang B, 2002, IEEE INFOCOM SER, P1726, DOI 10.1109/INFCOM.2002.1019426
   YU PS, 1995, MULTIMEDIA SYST, V3, P137, DOI 10.1007/BF02176235
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
   ZIPF G, 1994, HUMAN BEHAV PRINCIPL
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2005
VL 16
IS 1
BP 1
EP 18
DI 10.1016/j.jvcir.2004.01.002
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 885SN
UT WOS:000226177300001
DA 2024-07-18
ER

PT J
AU Tan, SH
   Chen, H
   Zhu, SH
AF Tan, Shaohan
   Chen, Hui
   Zhu, Songhao
TI CTFCD: Channel transformer based on full convolutional decoder for
   single image deraining
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deraining; Full convolutional decoder; Channel transformer
AB Although convolutional neural network and visual transformer have been successfully applied in various field of computer vision, there is little work combining them to construct an efficient network model to solve image deraining tasks. Convolutional neural network is utilized to extract the features from each region, while visual transformer is utilized to extract the context information between local features. Due to the limitations in computational resources and processing time, it is difficult for visual transformer to process high-resolution images, which hinders the application of visual transformer in devices with limited hardware resources. The purpose of this article is to utilize the advantages of to design a lightweight encoder-decoder network for realtime image deraining. Firstly, a novel channel Transformer module is designed to obtain global contextual information, where deep separable convolution is utilized to extract multi-scale local features and a Transformer encoder is constructed by stacking Transformer modules. Secondly, a decoder based on a fully convolution is designed to adopt mask attention and inverted bottleneck convolution to achieve progressive feature fusion and feature reconstruction, which significantly reduces computational complexity and memory requirement. A large number of experimental results have verified that the proposed method has superior performance compared with other state-of-the art methods, while the computational cost and parameter quantity are much smaller than those of similar methods.
C1 [Tan, Shaohan; Chen, Hui; Zhu, Songhao] Nanjing Univ Posts & Telecommun, Coll Automat & Artificial Intelligence, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat & Artificial Intelligence, Nanjing, Peoples R China.
EM zhush@njupt.edu.cn
CR Chang Y, 2017, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2017.191
   Chen CH, 2021, PROC CVPR IEEE, P7738, DOI 10.1109/CVPR46437.2021.00765
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen X, 2023, PROC CVPR IEEE, P5896, DOI 10.1109/CVPR52729.2023.00571
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fu XY, 2021, AAAI CONF ARTIF INTE, V35, P1352
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Gao H., 2023, CoRR abs/ 2302.09554.
   Han K, 2021, ADV NEUR IN
   Jiang Kui, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P827, DOI 10.1145/3503161.3547760
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y., 2022, CoRR abs/ 2303.00748.
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Wang H, 2020, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR42600.2020.00317
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Woo S, 2023, PROC CVPR IEEE, P16133, DOI 10.1109/CVPR52729.2023.01548
   Xianhui Zheng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P258, DOI 10.1007/978-3-642-42051-1_33
   Xiao J, 2023, IEEE T PATTERN ANAL, V45, P12978, DOI 10.1109/TPAMI.2022.3183612
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhu H., 2020, IEEE C MULTIMEDIA EX, P1
NR 36
TC 0
Z9 0
U1 10
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 103992
DI 10.1016/j.jvcir.2023.103992
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD1Z9
UT WOS:001130016000001
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Song, KC
   Cui, WQ
   Ren, H
   Yan, YH
AF Zhao, Ying
   Song, Kechen
   Cui, Wenqi
   Ren, Hang
   Yan, Yunhui
TI MFS enhanced SAM: Achieving superior performance in bimodal few-shot
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Segment anything; Few-shot segmentation; RGB-T SAM; Gated prediction
   selection
AB Recently, Segment Anything Model (SAM) has become popular in computer vision field because of its powerful image segmentation ability and high interactivity of various prompts, which opens a new era of large vision foundation models. But is SAM really omnipotent? In this letter, we establish a comprehensive bimodal few-shot segmentation indoor dataset VT-840-5i, and compare SAM with eight state-of-the-art few-shot segmentation (FSS) methods on two benchmark datasets. Qualitative and quantitative experiment results show that although SAM is very effective in general object segmentation, it still has room for improvement in some challenging scenarios. Therefore, we introduce thermal infrared auxiliary information into the segmentation task and provide multiple fusion strategies (MFS) for readers to choose the most suitable approach for the specific task. Finally, we discuss several potential research trends about SAM in the future. Our test results are available at: https://github. com/VDT-2048/Bi-SAM.
C1 [Song, Kechen] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Liaoning, Peoples R China.
   Northeastern Univ, Natl Frontiers Sci Ctr Ind Intelligence & Syst Opt, Shenyang 110819, Peoples R China.
   Northeastern Univ, Key Lab Data Analyt & Optimizat Smart Ind, Minist Educ, Shenyang, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   Northeastern University - China
RP Song, KC (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Liaoning, Peoples R China.
EM songkc@me.neu.edu.cn
RI Song, Kechen/T-1896-2019
OI Song, Kechen/0000-0002-7636-3460
CR Bao YQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103306
   Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]
   Brown T., 2020, Advances in Neural Information Processing Systems, V33, P1877, DOI [DOI 10.48550/ARXIV.2005.14165, DOI 10.5555/3495724.3495883]
   Chen GB, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102720
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding BY, 2018, J VIS COMMUN IMAGE R, V52, P170, DOI 10.1016/j.jvcir.2018.02.012
   Fang ZY, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2023.103754
   Feng MZ, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102881
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   He B, 2014, J VIS COMMUN IMAGE R, V25, P1031, DOI 10.1016/j.jvcir.2014.03.002
   Hu CF, 2023, Arxiv, DOI [arXiv:2304.08506, DOI 10.48550/ARXIV.2304.08506]
   Ji GP, 2023, Arxiv, DOI [arXiv:2304.06022, DOI 10.48550/ARXIV.2304.06022, 10.1007/s11432-023-3881-x, DOI 10.1007/S11432-023-3881-X]
   Ji W, 2023, Arxiv, DOI [arXiv:2304.05750, DOI 10.48550/ARXIV.2304.05750, 10.1007/s11633-023-1385-0]
   Jiang CX, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103192
   Kang D, 2022, PROC CVPR IEEE, P9969, DOI 10.1109/CVPR52688.2022.00974
   Kirillov A, 2023, Arxiv, DOI arXiv:2304.02643
   Li G, 2021, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR46437.2021.00823
   Liu HW, 2014, J VIS COMMUN IMAGE R, V25, P709, DOI 10.1016/j.jvcir.2013.03.012
   Min J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6921, DOI 10.1109/ICCV48922.2021.00686
   OpenAI, 2023, Introducing ChatGPT
   Ouyang L., 2022, ADV NEURAL INFORM PR, V35, P27730, DOI 10.48550/ARXIV.2203.02155
   Shaban A, 2017, Arxiv, DOI [arXiv:1709.03410, DOI 10.48550/ARXIV.1709.03410]
   Shen QH, 2023, Arxiv, DOI arXiv:2304.10261
   Song KC, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23146612
   Song KC, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105919
   Song KC, 2023, IEEE T CIRC SYST VID, V33, P3104, DOI 10.1109/TCSVT.2022.3233131
   Tian ZT, 2022, IEEE T PATTERN ANAL, V44, P1050, DOI 10.1109/TPAMI.2020.3013717
   Touvron H, 2023, Arxiv, DOI arXiv:2302.13971
   Tu ZZ, 2022, Arxiv, DOI arXiv:2007.03262
   Tu ZZ, 2020, IEEE T MULTIMEDIA, V22, P160, DOI 10.1109/TMM.2019.2924578
   Wang G., 2018, CHINESE C IMAGE GRAP, P359
   Wu JD, 2023, Arxiv, DOI arXiv:2304.12620
   Xie GS, 2021, PROC CVPR IEEE, P5471, DOI 10.1109/CVPR46437.2021.00543
   Xu G, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103727
   Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhao Y, 2023, IEEE T CIRCUITS-II, V70, P4266, DOI 10.1109/TCSII.2023.3278941
NR 37
TC 1
Z9 1
U1 4
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103946
DI 10.1016/j.jvcir.2023.103946
EA SEP 2023
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X1BL4
UT WOS:001095869400001
DA 2024-07-18
ER

PT J
AU Zouari, S
   Masmoudi, A
AF Zouari, Sonia
   Masmoudi, Atef
TI Dictionary-based histogram packing technique for lossless image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lossless image compression; Sparse histogram; Histogram packing;
   histogram sparseness; JPEG-2000; JPEG-LS; JPEG-XL
ID COMPRESSION; ALGORITHM
AB This paper proposes a dictionary-based histogram packing technique for lossless image compression. It is used to improve the performance of the state-of-the-art lossless image compression standards and methods when compressing sparse and locally sparse histogram images. The proposed method leverages inter-block correlations and similarities not only within the neighborhood but also across the entire image, thereby effectively reducing the block boundary artifacts commonly observed in block-based histogram packing techniques. To achieve this, a dictionary is employed to represent highly correlated blocks using a key that captures the union of their active symbol sets. Experimental results have demonstrated that the proposed method, when applied to sparse and locally sparse histogram images, enhances the performance of various state-of-the-art lossless image compression techniques. Notably, improvements were observed in standards and methods such as JPEG-2000, JPEG-LS, JPEG-XL, PNG, and CALIC.
C1 [Zouari, Sonia] Univ Sfax, Natl Engn Sch Sfax, Lab Elect & Technol Informat, Sfax, Tunisia.
   [Masmoudi, Atef] King Khalid Univ, Coll Comp Sci, Abha, Saudi Arabia.
C3 Universite de Sfax; Faculty of Sciences Sfax; Ecole Nationale
   dIngenieurs de Sfax (ENIS); King Khalid University
RP Masmoudi, A (corresponding author), King Khalid Univ, Coll Comp Sci, Abha, Saudi Arabia.
EM sonia.zouari@ieee.org; amasmoudi@kku.edu.sa
RI MASMOUDI, Atef/A-3258-2012
FU Deanship of Scientific Research at King Khalid University [RGP2/171/44]
FX Acknowledgments The authors extend their appreciation to the Deanship of
   Scientific Research at King Khalid University for funding this work
   through large group Research Project under grant number RGP2/171/44.
CR [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   Ausbeck PJ, 2000, P IEEE, V88, P1779, DOI 10.1109/5.892713
   Chaoui S, 2018, INT J SIGNAL IMAGING, V11, P85
   Ferreira PJSG, 2002, IEEE SIGNAL PROC LET, V9, P259, DOI 10.1109/LSP.2002.803018
   Firsching M., 2019, APPL DIGITAL IMAGE P, P11137
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Iwahashi M, 2012, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.2012.6288143
   Jallouli S, 2020, INT J SIGNAL IMAGING, V12, P28, DOI 10.1504/IJSISE.2020.113562
   Jallouli S, 2018, LECT NOTES COMPUT SC, V10884, P63, DOI 10.1007/978-3-319-94211-7_8
   Jallouli S, 2017, EUR SIGNAL PR CONF, P1912, DOI 10.23919/EUSIPCO.2017.8081542
   Masmoudi A, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.063001
   Masmoudi A, 2015, MULTIMED TOOLS APPL, V74, P10605, DOI 10.1007/s11042-014-2195-8
   Masmoudi A, 2015, SIGNAL IMAGE VIDEO P, V9, P1021, DOI 10.1007/s11760-013-0531-5
   Minewaki S, 2019, MULTIMED TOOLS APPL, V78, P27, DOI 10.1007/s11042-017-5082-2
   Odaka T, 2014, IEICE T FUND ELECTR, VE97A, P2181, DOI 10.1587/transfun.E97.A.2181
   Pinho AJ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P341
   Pinho AJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P633, DOI 10.1109/ICME.2002.1035861
   Starosolski R, 2015, COMM COM INF SC, V521, P363, DOI 10.1007/978-3-319-18422-7_32
   Watanabe O, 2018, Arxiv, DOI arXiv:1808.00956
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
NR 21
TC 0
Z9 0
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103894
DI 10.1016/j.jvcir.2023.103894
EA JUL 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O8ZA3
UT WOS:001046634500001
DA 2024-07-18
ER

PT J
AU Zhu, H
   Chen, ZZ
   Liu, S
AF Zhu, Han
   Chen, Zhenzhong
   Liu, Shan
TI Learning knowledge representation with meta knowledge distillation for
   single image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Knowledge distillation; Single image super-resolution; Representation of
   knowledge; Meta learning; Texture-aware dynamic kernel
ID NETWORKS
AB Although the deep CNN-based super-resolution methods have achieved outstanding performance, their memory cost and computational complexity severely limit their practical employment. Knowledge distillation (KD), which can efficiently transfer knowledge from a cumbersome network (teacher) to a compact network (student), has demonstrated its advantages in some computer vision applications. The representation of knowledge is vital for knowledge transferring and student learning, which is generally defined in hand-crafted manners or uses the intermediate features directly. In this paper, we propose a model-agnostic meta knowledge distillation method under the teacher-student architecture for the single image super-resolution task. It provides a more flexible and accurate way to help teachers transmit knowledge in accordance with the abilities of students via knowledge representation networks (KRNets) with learnable parameters. Specifically, the texture-aware dynamic kernels are generated from local information to decompose the distillation problem into texture-wise supervision for further promoting the recovery quality of high-frequency details. In addition, the KRNets are optimized in a meta-learning manner to ensure the knowledge transferring and the student learning are beneficial to improving the reconstructed quality of the student. Experiments conducted on various single image super-resolution datasets demonstrate that our proposed method outperforms existing defined knowledge representation-related distillation methods and can help super-resolution algorithms achieve better reconstruction quality without introducing any extra inference complexity.
C1 [Zhu, Han; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Liu, Shan] Tencent, Palo Alto, CA 94306 USA.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM zzchen@whu.edu.cn
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn S, 2019, PROC CVPR IEEE, P9155, DOI 10.1109/CVPR.2019.00938
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Benlin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P694, DOI 10.1007/978-3-030-58568-6_41
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bian CL, 2021, IEEE T IMAGE PROCESS, V30, P2963, DOI 10.1109/TIP.2021.3056895
   Cai JR, 2019, IEEE I CONF COMP VIS, P3086, DOI 10.1109/ICCV.2019.00318
   Cai Q, 2022, IEEE T IMAGE PROCESS, V31, P2375, DOI 10.1109/TIP.2022.3154614
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Flennerhag S., 2018, INT C LEARNING REPRE
   Gu JJ, 2021, PROC CVPR IEEE, P9195, DOI 10.1109/CVPR46437.2021.00908
   He ZB, 2020, IEEE IMAGE PROC, P518, DOI [10.1109/icip40778.2020.9190917, 10.1109/ICIP40778.2020.9190917]
   Hegde S, 2020, INT CONF ACOUST SPEE, P3247, DOI [10.1109/ICASSP40776.2020.9054157, 10.1109/icassp40776.2020.9054157]
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang Q, 2021, IEEE IMAGE PROC, P1814, DOI 10.1109/ICIP42928.2021.9506517
   Huixia Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P564, DOI 10.1007/978-3-030-58595-2_34
   Jang Y, 2019, PR MACH LEARN RES, V97
   Jiang QP, 2022, IEEE T IMAGE PROCESS, V31, P2279, DOI 10.1109/TIP.2022.3154588
   Jiao JN, 2018, AAAI CONF ARTIF INTE, P6967
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Komodakis N, 2017, P ICLR
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li XW, 2021, IEEE T IMAGE PROCESS, V30, P4735, DOI 10.1109/TIP.2021.3066051
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin S., 2022, CVPR, p10 915
   Liu L., 2021, INT C COMPUT VIS, P8271
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P5573, DOI 10.1109/TIP.2021.3086590
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Loshchilov I., 2017, P INT C LEARN REPR
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Qing Liu, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P3661, DOI 10.1109/ICCV.2019.00376
   Romero A., 2015, INT C LEARNING REPRE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun WJ, 2022, IEEE T IMAGE PROCESS, V31, P1490, DOI 10.1109/TIP.2022.3142999
   Tian Yonglong, 2020, INT C LEARN REPR ICL
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang Y., 2021, IJCAI, P1122
   Wonkyung Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P465, DOI 10.1007/978-3-030-58586-0_28
   Wu ZY, 2022, IEEE T IMAGE PROCESS, V31, P6649, DOI 10.1109/TIP.2022.3214332
   Xudong Lin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P701, DOI 10.1007/978-3-030-58523-5_41
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Yu X, 2018, PROC CVPR IEEE, P908, DOI 10.1109/CVPR.2018.00101
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L., 2022, P IEEECVF C COMPUTER, p12 464
   Zhang Y., 2021, P IEEECVF C COMPUTER, P7852
   Zhang YL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4258, DOI 10.1109/ICCV48922.2021.00424
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zheng HT, 2018, LECT NOTES COMPUT SC, V11210, P87, DOI 10.1007/978-3-030-01231-1_6
   Zhou WCS, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7037
NR 62
TC 2
Z9 2
U1 6
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103874
DI 10.1016/j.jvcir.2023.103874
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N0XQ8
UT WOS:001034351300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khezerlou, F
   Baradarani, A
   Balafar, MA
AF Khezerlou, F.
   Baradarani, A.
   Balafar, M. A.
TI A convolutional autoencoder model with weighted multi-scale attention
   modules for 3D skeleton-based action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Motion trajectories; 3DPo-CDP descriptor;
   Change direction patterns; Pose features; Convolutional autoencoder;
   Weighted multi-scale attention; WMS block
ID REPRESENTATION; FEATURES; DESCRIPTOR; NETWORKS
AB The 3D skeleton sequences of action can be recognized based on series of meaningful movements including changes in the direction and geometry features of the body pose. In this paper, we introduce the 3DPo-CDP descriptor, which incorporates the change direction patterns of body joints and pose features in a unified deep structure to learn more adequate features for the action recognition problem. To this end, two types of features are extracted. First, Change Direction Patterns (CDPs) are extracted by following the important points of motion trajectories where a significant change of direction has occurred using two filtering phases. The CDPs capture the global features which are invariant to noise and insignificant temporal dynamics of joints. Second, Pose Features are employed to learn the intrinsic connectivity relationships of adjacent limbs and the variance distances of body joints from representative joints to concentrate on key-frames and informative joints. The complementary features of CDPs and 3D pose, which are transformed into images, are combined in a unified representation and fed into a new convolutional autoencoder. Unlike conventional convolutional autoencoders that focus on frames, high-level discriminative features of spatiotemporal relationships of whole body joints are extracted by introducing weighted multi-scale channel and spatial attention modules. In this paper, we show that adjacent and non-adjacent neighbors can be effectively used to compute different weights for extracting cross-interaction channels and multi-scale spatial relationships of the current pixel. The extracted features are combined with the wavelet representation of statistical body information and then classified with a multi-class SVM classifier. The experimental results demonstrate the effectiveness of the augmented 3DPo-CDP descriptor using an attentional convolution autoencoder structure on five challenging 3D action recognition datasets.
C1 [Khezerlou, F.; Baradarani, A.; Balafar, M. A.] Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
C3 University of Tabriz
RP Khezerlou, F (corresponding author), Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
EM khezerlou@tabrizu.ac.ir; baradar@tabrizu.ac.ir; balafarila@tabrizu.ac.ir
RI Khezerlou, Fatemeh/HSG-1497-2023
CR Agahian S, 2020, ENG SCI TECHNOL, V23, P196, DOI 10.1016/j.jestch.2019.04.014
   Agahian S, 2019, VISUAL COMPUT, V35, P591, DOI 10.1007/s00371-018-1489-7
   Baradarani A., 2010, PATTERN RECOGN, P151
   Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300
   Boujebli M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111888
   Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Cai L., 2020, NONLINEAR DYNAM, P1
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Cavazza J, 2019, PATTERN RECOGN, V93, P25, DOI 10.1016/j.patcog.2019.03.031
   Chaolong L., 2018, P 32 AAAI C ARTIFICI
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Dhiman C, 2019, Arxiv, DOI arXiv:1912.00576
   Ding WW, 2016, SIGNAL PROCESS-IMAGE, V42, P109, DOI 10.1016/j.image.2016.01.010
   Ding WW, 2015, COMM COM INF SC, V546, P12, DOI 10.1007/978-3-662-48558-3_2
   Ding WW, 2015, J VIS COMMUN IMAGE R, V26, P329, DOI 10.1016/j.jvcir.2014.10.009
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2016, IEEE T IMAGE PROCESS, V25, P3010, DOI 10.1109/TIP.2016.2552404
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   El-Ghaish HA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P343, DOI 10.5220/0006625703430350
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Elmadany NE, 2019, IEEE T MULTIMEDIA, V21, P1317, DOI 10.1109/TMM.2018.2875510
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Ghojogh B, 2018, IEEE SENS J, V18, P1612, DOI 10.1109/JSEN.2017.2784425
   Giannakeris P, 2020, LECT NOTES COMPUT SC, V11962, P601, DOI 10.1007/978-3-030-37734-2_49
   Guo Y, 2018, PATTERN RECOGN, V76, P137, DOI 10.1016/j.patcog.2017.10.034
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussein, 2013, INT JOINT C ART INT
   Huynh-The T., 2019, IEEE T IND INFORM
   Jiang XB, 2016, MULTIMED TOOLS APPL, V75, P11019, DOI 10.1007/s11042-015-2829-5
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Kerola T, 2017, COMPUT VIS IMAGE UND, V154, P108, DOI 10.1016/j.cviu.2016.10.004
   Kim S, 2019, IEEE WINT CONF APPL, P61, DOI 10.1109/WACV.2019.00014
   Kiruba K, 2019, COGN SYST RES, V58, P71, DOI 10.1016/j.cogsys.2019.03.001
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li B, 2017, Arxiv, DOI arXiv:1704.05645
   Li B, 2018, MULTIMED TOOLS APPL, V77, P22901, DOI 10.1007/s11042-018-5642-0
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P4800, DOI 10.1109/TNNLS.2021.3061115
   Li C, 2018, Arxiv, DOI arXiv:1804.06055
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li YS, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107293
   Liu J., 2020, NEUROCOMPUTING, V385
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, IEEE IMAGE PROC, P3670, DOI 10.1109/ICIP.2017.8296967
   Liu MY, 2017, IEEE INT CON MULTI, P901, DOI 10.1109/ICME.2017.8019313
   Liu TT, 2019, INT J SOC ROBOT, V11, P219, DOI 10.1007/s12369-018-0498-z
   Luvizon DC, 2017, PATTERN RECOGN LETT, V99, P13, DOI 10.1016/j.patrec.2017.02.001
   Mazzia V, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108487
   McNally W, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P49, DOI 10.1109/CRV.2019.00015
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mendapara P, 2010, IEEE INT CON MULTI, P1409, DOI 10.1109/ICME.2010.5583171
   Minhas R, 2010, NEUROCOMPUTING, V73, P1906, DOI 10.1016/j.neucom.2010.01.020
   Mohammadzade H, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102691
   Muhammad K, 2021, FUTURE GENER COMP SY, V125, P820, DOI 10.1016/j.future.2021.06.045
   Naveenkumar M, 2020, LEARNING REPRESENTAT
   Ng W., 2021, IEEE T NEUR NET LEAR
   Nie Q., 2019, IEEE T IMAGE PROCESS
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Padilla-L¢pez JR, 2015, Arxiv, DOI arXiv:1407.7390
   Paoletti G, 2021, INT C PATT RECOG, P6035, DOI 10.1109/ICPR48806.2021.9412060
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Qing Zhang, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11857), P26, DOI 10.1007/978-3-030-31654-9_3
   Rahimi S, 2019, SIGNAL IMAGE VIDEO P, V13, P271, DOI 10.1007/s11760-018-1354-1
   Ramírez I, 2020, NEUROCOMPUTING, V379, P64, DOI 10.1016/j.neucom.2019.09.101
   Rani SS, 2021, MATER TODAY-PROC, V37, P3164, DOI 10.1016/j.matpr.2020.09.052
   Rhif M, 2018, INT C PATT RECOG, P3427, DOI 10.1109/ICPR.2018.8546027
   Salih AA, 2016, PATTERN RECOGN LETT, V83, P32, DOI 10.1016/j.patrec.2016.05.032
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Si CY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107511
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Song SJ, 2018, IEEE T IMAGE PROCESS, V27, P3459, DOI 10.1109/TIP.2018.2818328
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Santos ACSE, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420400017
   Sun B, 2019, MULTIMED TOOLS APPL, V78, P6329, DOI 10.1007/s11042-018-6370-1
   Tabejamaat M., 2020, INT J PATTERN RECOGN
   Tao LL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P303, DOI 10.1109/ICCVW.2015.48
   Thien HT, 2020, INFORM SCIENCES, V513, P112, DOI 10.1016/j.ins.2019.10.047
   Thien HT, 2018, INFORM SCIENCES, V444, P20, DOI 10.1016/j.ins.2018.02.042
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang JJ, 2022, APPL INTELL, V52, P1362, DOI 10.1007/s10489-021-02496-y
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang QL, 2020, Arxiv, DOI arXiv:1910.03151
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Wei P, 2017, IEEE T PATTERN ANAL, V39, P1165, DOI 10.1109/TPAMI.2016.2574712
   Weng J., 2018, IEEE T CIRC SYST VID
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu ZZ, 2020, Arxiv, DOI arXiv:2003.05684
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xie CY, 2018, Arxiv, DOI arXiv:1804.08254
   Yao H., 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1
   Yin B., 2019, IEEE INT JOINT C NEU, P1
   Zhang B., 2019, IEEE T CIRCUITS-II, VII
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhao R, 2019, PROC CVPR IEEE, P7725, DOI 10.1109/CVPR.2019.00792
   Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147
   Zhi Liu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457931
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
   Zhu AC, 2020, NEUROCOMPUTING, V414, P90, DOI 10.1016/j.neucom.2020.07.068
   Zhu KJ, 2020, IEEE T MULTIMEDIA, V22, P2977, DOI 10.1109/TMM.2019.2962304
NR 117
TC 3
Z9 3
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103781
DI 10.1016/j.jvcir.2023.103781
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9P6YW
UT WOS:000944429400001
DA 2024-07-18
ER

PT J
AU Niu, WJ
   Zhao, YK
   Yu, ZY
   Liu, Y
   Gong, Y
AF Niu, Wenjie
   Zhao, Yuankun
   Yu, Zhiyan
   Liu, Yu
   Gong, Yu
TI Research on a face recognition algorithm based on 3D face data and 2D
   face image matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D face recognition; Depth image; Deep learning; Data enhancement
ID DEEP
AB Under the condition of weak light or no light, the recognition accuracy of the mature 2D face recognition technology decreases sharply. In this paper, a face recognition algorithm based on the matching of 3D face data and 2D face images is proposed. Firstly, 3D face data is reconstructed from the 2D face in the database based on the 3DMM algorithm, and the face depth image is obtained through orthogonal projection. Then, the average curvature map of the face depth image is used to enhance the data of the depth image. Finally, an improved residual neural network based on the depth image and curvature is designed to compare the scanned face with the face in the database. The method proposed in this paper is tested on the 3D face data in three public face datasets (Texas 3DFRD, FRGC v2.0, and Lock3DFace), and the recognition accuracy is 84.25%, 83.39%, and 78.24%, respectively.
C1 [Niu, Wenjie; Zhao, Yuankun; Yu, Zhiyan; Liu, Yu; Gong, Yu] China Univ Petr, Sch Mech & Elect Engn, Shandong 266580, Peoples R China.
C3 China University of Petroleum
RP Niu, WJ (corresponding author), China Univ Petr, Sch Mech & Elect Engn, Shandong 266580, Peoples R China.
EM zhaoyuankun95@163.com
RI Niu, Wen-jie/M-3342-2019
OI Niu, Wen-jie/0000-0002-1386-8621
CR Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   [Anonymous], 2014, PROC BRIT MACHINE VI
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V., 2002, IT+TI Informationstechnik und Technische Informatik, V44, P295, DOI 10.1524/itit.2002.44.6.295
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Cai Y, 2019, NEUROCOMPUTING, V363, P375, DOI 10.1016/j.neucom.2019.07.047
   Cai Y, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/678973
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   Danelakis A, 2016, PATTERN RECOGN, V52, P174, DOI 10.1016/j.patcog.2015.10.012
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gilani SZ, 2017, PATTERN RECOGN, V69, P238, DOI 10.1016/j.patcog.2017.04.013
   Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huber Patrik, 2016, P 11 INT JOINT C COM, DOI DOI 10.5220/0005669500790086
   Jiang L, 2020, IEEE T PATTERN ANAL, V42, P2552, DOI 10.1109/TPAMI.2019.2919284
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Lee YH, 2004, IEEE IMAGE PROC, P1429
   Li HB, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P234, DOI 10.1109/BTAS.2017.8272703
   Liu F, 2020, IEEE T PATTERN ANAL, V42, P664, DOI 10.1109/TPAMI.2018.2885995
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Mangijaosingh S., 2013, INT J COMPUTER APPL, V59, P13
   Mu GD, 2019, PROC CVPR IEEE, P5766, DOI 10.1109/CVPR.2019.00592
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun Y, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang H.L., 2010, J INFORM COMPUTATION, V7, P2
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   [王晓华 Wang Xiaohua], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1473
   Wu X, 2015, ARXIV PREPRINT ARXIV, V8
   [杨恢先 Yang Huixian], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P1493
   Yanga Y, 2018, ARXIV
   Zhang J., 2016, International Conference on Biometrics, P1
   Zhou H, 2020, PROC CVPR IEEE, P5910, DOI 10.1109/CVPR42600.2020.00595
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 58
TC 5
Z9 6
U1 5
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103757
DI 10.1016/j.jvcir.2023.103757
EA JAN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G7TZ3
UT WOS:000991150900001
DA 2024-07-18
ER

PT J
AU Chen, XY
   Kan, SC
   Zhang, FH
   Cen, YG
   Zhang, LN
   Zhang, DM
AF Chen, Xiaoyu
   Kan, Shichao
   Zhang, Fanghui
   Cen, Yigang
   Zhang, Linna
   Zhang, Damin
TI Multiscale spatial temporal attention graph convolution network for
   skeleton-based anomaly behavior detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiscale spatial temporal graph; Spatial attention graph convolution;
   Skeleton-based anomaly behavior detection
ID NEURAL-NETWORKS
AB Anomaly behavior detection plays a significant role in emergencies such as robbery. Although a lot of works have been proposed to deal with this problem, the performance in real applications is still relatively low. Here, to detect abnormal human behavior in videos, we propose a multiscale spatial temporal attention graph convolution network (MSTA-GCN) to capture and cluster the features of the human skeleton. First, based on the human skeleton graph, a multiscale spatial temporal attention graph convolution block (MSTA-GCB) is built which contains multiscale graphs in temporal and spatial dimensions. MSTA-GCB can simulate the motion relations of human body components at different scales where each scale corresponds to different granularity of annotation levels on the human skeleton. Then, static, globally-learned and attention-based adjacency matrices in the graph convolution module are proposed to capture hierarchical representation. Finally, extensive experiments are carried out on the ShanghaiTech Campus and CUHK Avenue datasets, the final results of the frame-level AUC/EER are 0.759/0.311 and 0.876/0.192, respectively. Moreover, the frame-level AUC is 0.768 for the human-related ShanghaiTech subset. These results show that our MSTA-GCN outperforms most of methods in video anomaly detection and we have obtained a new state-of-the-art performance in skeleton-based anomaly behavior detection.
C1 [Chen, Xiaoyu; Zhang, Fanghui; Cen, Yigang] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Chen, Xiaoyu; Zhang, Fanghui; Cen, Yigang] Beijing Key Lab Adv Informat Sci & Network Technol, Beijing 100044, Peoples R China.
   [Kan, Shichao] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Zhang, Linna] Guizhou Univ, Coll Mech Engn, Guiyang 550025, Guizhou, Peoples R China.
   [Zhang, Damin] Guizhou Univ, Coll Big Data & Informat Engn, Guiyang 550025, Guizhou, Peoples R China.
C3 Beijing Jiaotong University; Central South University; Guizhou
   University; Guizhou University
RP Cen, YG (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM ygcen@bjtu.edu.cn
RI Cen, Yigang/AAC-1999-2019
OI Chen, Xiaoyu/0000-0002-7673-265X; Zhang, Damin/0009-0003-0924-9590
FU National Key R&D Program of China [2021YFE0110500]; National Natural
   Science Foundation of China [62202499, 61872034, 62062021, 62011530042];
   Beijing Municipal Natural Science Foundation, China [4202055]; Guizhou
   Provincial Science and Technology Department, China [[2021] 4023]
FX This work was supported by the National Key R&D Program of China [grant
   number 2021YFE0110500]; the National Natural Science Foundation of China
   [grant numbers 62202499, 61872034, 62062021, and 62011530042]; the
   Beijing Municipal Natural Science Foundation, China [grant number
   4202055] and the central guiding local funding project of Guizhou
   Provincial Science and Technology Department, China [grant number [2021]
   4023].
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   [Anonymous], 2018, P EUR C COMP VIS
   Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525
   Cao Z., 2017, P IEEE C COMP VIS PA, P7291
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cui QJ, 2020, PROC CVPR IEEE, P6518, DOI 10.1109/CVPR42600.2020.00655
   Doshi K, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107865
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fang ZW, 2021, IEEE T MULTIMEDIA, V23, P4106, DOI 10.1109/TMM.2020.3037538
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Kingma D. P., 2014, arXiv
   Li MS, 2021, IEEE T IMAGE PROCESS, V30, P7760, DOI 10.1109/TIP.2021.3108708
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu Y, 2022, IEEE T CIRCUITS-II, V69, P2498, DOI 10.1109/TCSII.2022.3161049
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Markovitz Amir, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10536, DOI 10.1109/CVPR42600.2020.01055
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Medel JR, 2016, Arxiv, DOI arXiv:1612.00390
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Tabassum S, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1256
   Wu P, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107515
   Xie JY, 2016, PR MACH LEARN RES, V48
   Xu D, 2015, Arxiv, DOI [arXiv:1510.01553, DOI 10.48550/ARXIV.1510.01553]
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Yiwei Lu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P125, DOI 10.1007/978-3-030-58558-7_8
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zhang CX, 2019, AAAI CONF ARTIF INTE, P1409
   Zhang XK, 2020, IEEE T NEUR NET LEAR, V31, P3047, DOI 10.1109/TNNLS.2019.2935173
   Zhang Y., 2022, ACM Trans. Multim. Comput. Commun. Appl.
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhang Y, 2020, IEEE MULTIMEDIA, V27, P23, DOI 10.1109/MMUL.2020.2999445
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zong B., 2018, INT C LEARNING REPRE, P1
NR 49
TC 4
Z9 4
U1 5
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103707
DI 10.1016/j.jvcir.2022.103707
EA DEC 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200006
DA 2024-07-18
ER

PT J
AU Li, YY
   Zhang, HX
   Liu, L
AF Li, Yueying
   Zhang, Huaxiang
   Liu, Li
TI HCFN: Hierarchical cross-modal shared feature network for
   visible-infrared person re-identification?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visible-infrared person re-identification; Feature extraction; Deep
   learning; Hierarchical attention mechanism
AB Compared with traditional visible-visible person re-identification, the modality discrepancy between visible and infrared images makes person re-identification more challenging. Existing methods rely on learning efficient transformation mechanisms in paired images to reduce the modality gap, which inevitably introduces noise. To get rid of these limitations, we propose a Hierarchical Cross-modal shared Feature Network (HCFN) to mine modality-shared and modality-specific information. Since infrared images lack color and other information, we construct an Intra-modal Feature Extraction Module (IFEM) to learn the content information and reduce the difference between visible and infrared images. In order to reduce the heterogeneous division, we apply a Cross-modal Graph Interaction Module (CGIM) to align and narrow the set-level distance of the inter-modal images. By jointly learning two modules, our method can achieve 66.44% Rank-1 on SYSU-MM01 dataset and 74.81% Rank-1 on RegDB datasets, respectively, which is superior compared with the state-of-the-art methods. In addition, ablation experiments demonstrate that HCFN is at least 4.9% better than the baseline network.
C1 [Li, Yueying; Zhang, Huaxiang; Liu, Li] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Jiaotong University
RP Zhang, HX; Liu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@hotmail.com; liuli_790209@163.com
FU National Natural Science Foundation of China [U1836216, 62176144,
   62076153]; major fundamental research project of Shandong, China
   [ZR2019ZD03]; Taishan Scholar Project of Shandong Province, China
   [ts20190924]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. U1836216, 62176144, 62076153), the major
   fundamental research project of Shandong, China (No. ZR2019ZD03), and
   the Taishan Scholar Project of Shandong Province, China (No.
   ts20190924).
CR [Anonymous], 2016, IEEE C COMP VIS PATT
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Cai X, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106772
   Chen F, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106939
   Cheng ZY, 2020, PROC CVPR IEEE, P2602, DOI 10.1109/CVPR42600.2020.00268
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Hao Y, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107533
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang Pan, 2021, Martin Luther and the Third Enlightenment Series No. 4 The Interaction between Martin Luther's Finnish School and Chinese Contexts, P1
   Huang YK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P365, DOI 10.1145/3343031.3350994
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li S, 2020, INT J COMPUT VISION, V128, P2936, DOI 10.1007/s11263-020-01349-4
   Li YY, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107281
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Ling YG, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P889, DOI 10.1145/3394171.3413821
   Liu JC, 2022, APPL INTELL, V52, P2423, DOI 10.1007/s10489-021-02548-3
   Liu Q, 2022, APPL INTELL, V52, P547, DOI 10.1007/s10489-021-02390-7
   Mang Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P229, DOI 10.1007/978-3-030-58520-4_14
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Qi MB, 2021, MULTIMED TOOLS APPL, V80, P17645, DOI 10.1007/s11042-020-10431-5
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang YZ, 2020, NEURAL NETWORKS, V124, P223, DOI 10.1016/j.neunet.2020.01.012
   Velickovic P, 2017, ARXIV
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GA, 2020, NEURAL NETWORKS, V128, P294, DOI 10.1016/j.neunet.2020.05.008
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yang WX, 2019, NEUROCOMPUTING, V340, P125, DOI 10.1016/j.neucom.2019.02.042
   Ye HR, 2021, IEEE T IMAGE PROCESS, V30, P1583, DOI 10.1109/TIP.2020.3045261
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Yuan BW, 2022, MULTIMEDIA SYST, V28, P749, DOI 10.1007/s00530-021-00872-9
   Zeng ZL, 2020, IEEE T MULTIMEDIA, V22, P3064, DOI 10.1109/TMM.2020.2969782
   Zhang GQ, 2021, IEEE T IMAGE PROCESS, V30, P8913, DOI 10.1109/TIP.2021.3120054
   Zhang HJ, 2020, IEEE ACCESS, V8, P83685, DOI 10.1109/ACCESS.2020.2991838
   Zhang JJ, 2021, NEUROCOMPUTING, V452, P137, DOI 10.1016/j.neucom.2021.04.080
   Zhang P, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104118
   Zhang SS, 2021, INT J COMPUT VISION, V129, P1875, DOI 10.1007/s11263-021-01461-z
   Zhang SZ, 2021, IEEE T IMAGE PROCESS, V30, P8861, DOI 10.1109/TIP.2021.3120881
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhao X, 2020, IEEE SYS MAN CYBERN, P3154, DOI [10.1109/smc42975.2020.9283157, 10.1109/SMC42975.2020.9283157]
   Zheng WS, 2022, INT J COMPUT VISION, V130, P136, DOI 10.1007/s11263-021-01518-z
   Zhou SR, 2020, PATTERN RECOGN LETT, V138, P617, DOI 10.1016/j.patrec.2020.09.009
   Zhu ZQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103303
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 51
TC 1
Z9 1
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103689
DI 10.1016/j.jvcir.2022.103689
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600001
DA 2024-07-18
ER

PT J
AU Li, QY
   Xie, XM
   Zhang, J
   Shi, GM
AF Li, Qiyue
   Xie, Xuemei
   Zhang, Jin
   Shi, Guangming
TI Language-guided graph parsing attention network for human-object
   interaction recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human-object interaction; Language-guided; Graph parsing attention
   network; Word embedding
ID AFFORDANCES
AB This paper focuses on the task of human-object interaction (HOI) recognition, which aims to classify the interaction between human and objects. It is a challenging task partially due to the extremely imbalanced data among classes. To solve this problem, we propose a language-guided graph parsing attention network (LG-GPAN) that makes use of the word distribution in language to guide the classification in vision. We first associate each HOI class name with a word embedding vector in language and then all the vectors can construct a language space specified for HOI recognition. Simultaneously, the visual feature is extracted from the inputs via the proposed graph parsing attention network (GPAN) for better visual representation. The visual feature is then transformed into the linguistic one in language space. Finally, the output score is obtained via measuring the distance between the linguistic feature and the word embedding of classes in language space. Experimental results on the popular CAD-120 and V-COCO datasets validate our design choice and demonstrate its superior performance in comparison to the state-of-the-art.
C1 [Li, Qiyue; Xie, Xuemei; Zhang, Jin; Shi, Guangming] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Xie, XM (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
EM xmxie@mail.xidian.edu.cn
RI Li, Qiyue/GON-3433-2022
OI Li, Qiyue/0000-0002-7990-0671
FU National Key R & D Program of China; National Natural Science Foundation
   of China; Guangdong Provincial Key Field Research and Development Plan
   Project;  [2020AAA0109301];  [61836008];  [2021B0101400002]
FX This work was supported by National Key R & D Program of China (No.
   2020AAA0109301) , National Natural Science Foundation of China (No.
   61836008) , Guangdong Provincial Key Field Research and Development Plan
   Project (No. 2021B0 101410002) and Guangdong Provincial Key Field
   Research and Development Plan Project (No. 2021B0101400002) .
CR Baldassano C, 2017, CEREB CORTEX, V27, P2276, DOI 10.1093/cercor/bhw077
   Byrd J, 2019, PR MACH LEARN RES, V97
   Cao KD, 2019, ADV NEUR IN, V32
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chen Y., 2020, P EUROPEAN C COMPUTE, P136, DOI 10.1007/978-3-030-58542-6_9
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Dong-Jin Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P718, DOI 10.1007/978-3-030-58589-1_43
   Gao C., 2018, ARXIV
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Gupta S, 2015, Arxiv, DOI arXiv:1505.04474
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Thekumparampil KK, 2018, Arxiv, DOI arXiv:1803.03735
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Lee JB, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3363574
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Liang Weixin, 2021, arXiv
   Liao WT, 2019, IEEE COMPUT SOC CONF, P444, DOI 10.1109/CVPRW.2019.00058
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Liu C., 2020, CVPR, P10840
   Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Narasimhan M., 2021, ADV NEURAL INF PROCE, V34
   Ng SC, 2017, PROCEDIA COMPUT SCI, V111, P113, DOI 10.1016/j.procs.2017.06.017
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Prest A, 2013, IEEE T PATTERN ANAL, V35, P835, DOI 10.1109/TPAMI.2012.175
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Qian XF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P84, DOI 10.1145/3343031.3351058
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Sayer N., 2014, Patent No. [XP055260798, 055260798]
   Shang XD, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P279, DOI 10.1145/3323873.3325056
   Sunkesula SPR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P691, DOI 10.1145/3394171.3413778
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Velickovic Petar, 2018, INT C LEARN REPR
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   Xu BJ, 2019, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2019.00212
   Xu BJ, 2020, IEEE T MULTIMEDIA, V22, P1423, DOI 10.1109/TMM.2019.2943753
   Xu J, 2020, IEEE SYMP COMP COMMU, P703, DOI 10.1109/iscc50000.2020.9219587
NR 49
TC 1
Z9 1
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103640
DI 10.1016/j.jvcir.2022.103640
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5M4GW
UT WOS:000871056800002
DA 2024-07-18
ER

PT J
AU Aslam, N
   Rai, PK
   Kolekar, MH
AF Aslam, Nazia
   Rai, Prateek Kumar
   Kolekar, Maheshkumar H.
TI A3N: Attention-based adversarial autoencoder network for detecting
   anomalies in video sequence
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomaly detection; Attention mechanism; Adversarial autoencoder;
   Generative adversarial network
ID ABNORMAL EVENT DETECTION; DEEP NEURAL-NETWORKS; LOCALIZATION; HISTOGRAMS
AB This paper presents a novel attention-based adversarial autoencoder network (A3N) that consists of a twostream decoder to detect abnormal events in video sequences. The first stream of the decoder is a reconstructive model responsible for recreating the input frame sequence. However, the second stream is a future predictive model used to predict the future frame sequence through adversarial learning. A global attention mechanism is employed at the decoder side that helps to decode the encoded sequences effectively. The training of A3N is carried out on normal video data. The attention-based reconstructive model is used during the inference stage to compute the anomaly score. A3N delivers a considerable average speed of 0.0227 s (similar to 44 fps) for detecting anomalies in the testing phase on used datasets. Several experiments and ablation analyses have been performed on UCSD Pedestrian, CUHK Avenue and ShanghaiTech datasets to validate the efficiency of the proposed model.
C1 [Aslam, Nazia; Rai, Prateek Kumar; Kolekar, Maheshkumar H.] Indian Inst Technol Patna, Dept Elect Engn, Video Surveillance Lab, Bihta 801106, India.
C3 Indian Institute of Technology (IIT) - Patna
RP Aslam, N (corresponding author), Indian Inst Technol Patna, Dept Elect Engn, Video Surveillance Lab, Bihta 801106, India.
EM n.aslam921@gmail.com; raipkiitp@gmail.com; mahesh@iitp.ac.in
RI Aslam, Nazia/AGZ-4243-2022
OI Aslam, Nazia/0000-0002-8381-9702
CR Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Asad M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103047
   Aslam N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1071, DOI 10.1109/ICCSP.2017.8286540
   Bhattacharya S, 2017, 2017 INTERNATIONAL CONFERENCE ON ALGORITHMS, METHODOLOGY, MODELS AND APPLICATIONS IN EMERGING TECHNOLOGIES (ICAMMAET), DOI 10.1109/CNS.2017.8228635
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen TY, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104340
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Fang ZW, 2021, IEEE T MULTIMEDIA, V23, P4106, DOI 10.1109/TMM.2020.3037538
   Feng XY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5546, DOI 10.1145/3474085.3475693
   Georgescu MI, 2021, PROC CVPR IEEE, P12737, DOI 10.1109/CVPR46437.2021.01255
   Ghosal D, 2018, INTERSPEECH, P2087
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hou JL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8771, DOI 10.1109/ICCV48922.2021.00867
   Huang C, 2023, IEEE T NEUR NET LEAR, V34, P9389, DOI 10.1109/TNNLS.2022.3159538
   Huang C, 2022, IEEE T IND INFORM, V18, P5171, DOI 10.1109/TII.2021.3122801
   Huang C, 2022, IEEE T CYBERNETICS, V52, P13834, DOI 10.1109/TCYB.2021.3127716
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kingma D. P., 2014, arXiv
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Lin WY, 2021, Arxiv, DOI arXiv:2005.04490
   Lin WY, 2020, IEEE MULTIMEDIA, V27, P12, DOI 10.1109/MMUL.2020.2990863
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu YQ, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102767
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mathieu M, 2016, Arxiv, DOI arXiv:1511.05440
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Purwanto D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P173, DOI 10.1109/ICCV48922.2021.00024
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Medel JR, 2016, Arxiv, DOI arXiv:1612.00390
   Sabokrou M, 2019, LECT NOTES COMPUT SC, V11366, P488, DOI 10.1007/978-3-030-20876-9_31
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Song H, 2020, IEEE T MULTIMEDIA, V22, P2138, DOI 10.1109/TMM.2019.2950530
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tian Y, 2021, Arxiv, DOI arXiv:2101.10030
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang L, 2018, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2018.8451070
   Wang X, 2018, INT CONF SIGN PROCES, P474, DOI 10.1109/ICSP.2018.8652354
   Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Yang ZW, 2021, IEEE ACCESS, V9, P107842, DOI 10.1109/ACCESS.2021.3100678
   Yang ZY, 2022, IEEE T NEUR NET LEAR, V33, P2324, DOI 10.1109/TNNLS.2021.3132928
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Yu G, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P583, DOI 10.1145/3394171.3413973
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zaheer Muhammad Zaigham, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P358, DOI 10.1007/978-3-030-58542-6_22
   Zaheer MZ, 2020, IEEE SIGNAL PROC LET, V27, P1705, DOI 10.1109/LSP.2020.3025688
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang JG, 2019, IEEE IMAGE PROC, P4030, DOI [10.1109/ICIP.2019.8803657, 10.1109/icip.2019.8803657]
   Zhang J, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104337
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhao Y, 2016, IEEE IMAGE PROC, P3354, DOI 10.1109/ICIP.2016.7532981
   Zheng L, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4419
   Zhou JT, 2020, IEEE T CIRC SYST VID, V30, P4639, DOI 10.1109/TCSVT.2019.2962229
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 77
TC 15
Z9 15
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103598
DI 10.1016/j.jvcir.2022.103598
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4U2UR
UT WOS:000858655700006
DA 2024-07-18
ER

PT J
AU He, SH
   Xu, DW
   Yang, L
   Liu, Y
AF He, Songhan
   Xu, Dawen
   Yang, Lin
   Liu, Yong
TI HEVC video information hiding scheme based on adaptive double-layer
   embedding strategy*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive video information hiding; HEVC; PU partition mode; STC;
   Double-layer embedding
ID CODING HEVC
AB High Efficiency Video Coding (HEVC) is well-known as an internationally popular video coding standard, and HEVC-based steganography has received increasing attention. In this paper, a new adaptive HEVC video information hiding method based on Prediction Unit (PU) partition mode and double-layer embedding strategy is proposed. Double-layer embedding is a method to complete the first-layer embedding using the mapping rules of PU partition mode, and to perform the second-layer embedding after the first-layer embedding. The cost assignment function designed in this paper can accurately evaluate the second-layer data embedding distortion. The frame position, motion properties and block size of PU are taken into consideration for the second-layer data embedding, and the syndrome-trellis codes (STCs) are used to minimize the embedding distortion. Experimental results show that the proposed adaptive double-layer embedding algorithm has better embedding efficiency and less embedding distortion in most cases.
C1 [He, Songhan; Yang, Lin] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [He, Songhan; Xu, Dawen; Yang, Lin; Liu, Yong] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315211, Peoples R China.
C3 Ningbo University; Ningbo University of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315211, Peoples R China.
EM dawenxu@126.com
RI he, songhan/KVY-0154-2024
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [62071267, 61771270];
   Zhejiang Provincial Natural Science Foundation of China [LR20F020001]
FX Acknowledgements This work is supported by the National Natural Science
   Foundation of China (62071267, 61771270) , Zhejiang Provincial Natural
   Science Foundation of China (LR20F020001) .
CR Burbeck C., 1989, J OPT SOC AM, V70, P1121
   Chang P. C., 2013, 2013 FUTURE NETWORK, P1
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen YL, 2021, IEEE T DEPEND SECURE, V18, P1320, DOI 10.1109/TDSC.2019.2932983
   Chen Yongna, 2017, Journal of Computer Applications, V37, P2806, DOI 10.11772/j.issn.1001-9081.2017.10.2806
   Cui YH, 2020, IEEE INT CONF COMM, DOI 10.1109/iccworkshops49005.2020.9145384
   Dong Y, 2023, IEEE T DEPEND SECURE, V20, P769, DOI 10.1109/TDSC.2022.3144139
   Dong Y, 2023, IEEE T MULTIMEDIA, V25, P2698, DOI 10.1109/TMM.2022.3150180
   Dong Y, 2017, LECT NOTES COMPUT SC, V10431, P149, DOI 10.1007/978-3-319-64185-0_12
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, PROC SPIE, V7541, DOI 10.1117/12.838002
   Jia XQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2720, DOI 10.1109/ICASSP39728.2021.9413728
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P6459, DOI 10.1007/s11042-018-6320-y
   Mengyuan Guo, 2020, Digital Forensics and Watermarking. 18th International Workshop, IWDW 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12022), P293, DOI 10.1007/978-3-030-43575-2_25
   [盛琪 Sheng Qi], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P433
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   [王家骥 Wang Jiaji], 2015, [光电子·激光, Journal of Optoelectronics·Laser], V26, P942
   [王家骥 Wang Jiaji], 2014, [光电子·激光, Journal of Optoelectronics·Laser], V25, P1578
   Xie WC, 2018, LECT NOTES COMPUT SC, V11066, P252, DOI 10.1007/978-3-030-00015-8_22
   Xu DW, 2019, IEEE ACCESS, V7, P66028, DOI 10.1109/ACCESS.2019.2916484
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Yang YY, 2019, MULTIMED TOOLS APPL, V78, P8423, DOI 10.1007/s11042-018-6859-7
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
NR 26
TC 8
Z9 9
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103549
DI 10.1016/j.jvcir.2022.103549
EA JUN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H5UY
UT WOS:000814360600002
DA 2024-07-18
ER

PT J
AU Chen, YC
   Horng, G
AF Chen, Yu-Chi
   Horng, Gwoboa
TI Cheating in (halftone-secret) visual cryptography: Analysis of blind
   authentication schemes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Human vision system; Binocular cheating; Cheating
   prevention; Security
ID GRAY-LEVEL IMAGES; PREVENTION SCHEME; CONTRAST
AB In visual cryptography (VC), cheating is an important security concern where dishonest participants will fool honest ones and make them accept a fake secret by providing fake shares. Share and blind authentications are two categories of cheating prevention, and the last one relies on the inherent robust of shares against cheating attacks. In the previous studies, cheating in VC only focuses on operating a 'pixel block' instead of a region of adjacent pixels. However, the well-known advantage of VC is to decode the secret image by using the human vision system (HVS), so it leads to a natural issue to reconsider cheating a region. In this paper, we formally address the binocular cheating attack (BCA) for a region to augment effectiveness of original cheating for a block. Finally, we demonstrate how to realize BCA by presenting non-trivial techniques against some blind authentication schemes, and further obtain implausible results. The BCA can also be applied to halftone secret.
C1 [Chen, Yu-Chi] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan 320, Taiwan.
   [Horng, Gwoboa] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 Yuan Ze University; National Chung Hsing University
RP Chen, YC (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan 320, Taiwan.
EM wycchen@saturn.yzu.edu.tw
OI Chen, Yu-Chi/0000-0002-5577-0016
FU Ministry of Science and Technology of Taiwan [106-2218-E-155-008-MY3,
   109-2628-E-155-001-MY3]
FX Acknowledgments This work was supported in part by the Ministry of
   Science and Technology of Taiwan (Nos. 106-2218-E-155-008-MY3 and
   109-2628-E-155-001-MY3) . The authors would like to thank the anonymous
   reviewers for their comments that helped to improve the presentation of
   the paper, and acknowledge Enago for editing this manuscript. In
   particular, we thank Gwoboa Horng (NCHU) for initial discussions of this
   work and his contributions on cheating in visual cryptography.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Chang CC, 2002, PATTERN RECOGN LETT, V23, P931, DOI 10.1016/S0167-8655(02)00023-5
   Chang CC, 2009, IEEE T INF FOREN SEC, V4, P790, DOI 10.1109/TIFS.2009.2034203
   Chen J, 2009, IMAGING SCI J, V57, P101, DOI 10.1179/174313108X384656
   Chen YC, 2013, DIGIT SIGNAL PROCESS, V23, P1496, DOI 10.1016/j.dsp.2013.05.014
   Chen YC, 2012, J VIS COMMUN IMAGE R, V23, P1225, DOI 10.1016/j.jvcir.2012.08.006
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   De Prisco R, 2010, COMPUT J, V53, P1485, DOI 10.1093/comjnl/bxp068
   Dehkordi M.H., 2008, AUSTRAL J BASIC APPL, V2, P1239
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Lu S, 2011, J COMB OPTIM, V21, P47, DOI 10.1007/s10878-009-9241-x
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Naor M., 1997, Security Protocols. International Workshop Proceedings, P197
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Ren YW, 2017, IET INFORM SECUR, V11, P211, DOI 10.1049/iet-ifs.2016.0126
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Shyu SJ, 2012, IEEE T CIRC SYST VID, V22, P769, DOI 10.1109/TCSVT.2011.2180769
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Tsai DS, 2014, MULTIMED TOOLS APPL, V70, P1825, DOI 10.1007/s11042-012-1206-x
   Wang CC, 2000, IEICE T FUND ELECTR, VE83A, P1589
   Wang RZ, 2009, IEEE SIGNAL PROC LET, V16, P659, DOI 10.1109/LSP.2009.2021334
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2018, J VIS COMMUN IMAGE R, V55, P660, DOI 10.1016/j.jvcir.2018.07.012
   Yang CN, 2016, THEOR COMPUT SCI, V609, P143, DOI 10.1016/j.tcs.2015.09.016
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2010, OPT COMMUN, V283, P4949, DOI 10.1016/j.optcom.2010.07.051
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 44
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103489
DI 10.1016/j.jvcir.2022.103489
EA APR 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600007
DA 2024-07-18
ER

PT J
AU Weng, SW
   Zhou, Y
   Zhang, TC
AF Weng, Shaowei
   Zhou, Ye
   Zhang, Tiancong
TI Adaptive reversible data hiding for JPEG images with multiple
   two-dimensional histograms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Multiple histograms; Two-dimensional histogram;
   Rate-distortion model
ID EXPANSION; BITSTREAM
AB Joint photographic experts group (JPEG) can provide good quality with small file size but also eliminate extensively the redundancies of images. Therefore, hiding data into JPEG images in terms of maintaining high visual quality at small file sizes has been a great challenge for researchers. In this paper, an adaptive reversible data hiding method for JPEG images containing multiple two-dimensional (2D) histograms is proposed. Adaptability is mainly reflected in three aspects. The first one is to preferentially select sharper histograms for data embedding after K histograms are established by constructing the kth (k epsilon {1, 2, ... , K}) histogram using the kth non-zero alternating current (AC) coefficient of all the quantized discrete cosine transform blocks. On the other hand, to fully exploit the strong correlation between coefficients of one histogram, the smoothness of each coefficient is estimated by a block smoothness estimator so that a sharply-distributed 2D-histogram is constructed by combining two coefficients with similar smoothness into a pair. The pair corresponding to low complexity is selected priorly for data embedding, leading to high embedding performance while maintaining low file size. Besides, we design multiple embedding strategies to adaptively select the embedding strategy for each 2D histogram. Experimental results demonstrate that the proposed method can achieve higher rate-distortion performance which maintaining lower file storage space, compared with previous studies.
C1 [Weng, Shaowei; Zhang, Tiancong] Fujian Univ Technol, Sch Elect, Elect Engn & Phys, Fuzhou 350118, Peoples R China.
   [Zhou, Ye] Fujian Univ Technol, Sch Comp Sci & Math, Fuzhou 350118, Peoples R China.
C3 Fujian University of Technology; Fujian University of Technology
RP Zhang, TC (corresponding author), Fujian Univ Technol, Sch Elect, Elect Engn & Phys, Fuzhou 350118, Peoples R China.
EM kushentian@163.com
RI tian'cong, zhang/IQU-9892-2023
OI tian'cong, zhang/0000-0002-5343-6233
FU National NSF of China [61872095, 61571139, 61872128]; International
   Scientific and Technological Cooperation of Guangdong Province
   [2019A050513012]; Open Project Program of Shenzhen Key Laboratory of
   Media Security [ML-2018-03]; Fujian Science Fund for Distinguished Young
   Scholars [2020J06043]
FX Acknowledgments This work was supported in part by the National NSF of
   China under Grant 61872095, Grant 61571139, Grant 61872128, in part
   International Scientific and Technological Cooperation of Guangdong
   Province under Grant 2019A050513012, in part by the Open Project Program
   of Shenzhen Key Laboratory of Media Security under Grant ML-2018-03, in
   part by Fujian Science Fund for Distinguished Young Scholars under Grant
   2020J06043.
CR Barton J. M., 1997, U.S. Patent, Patent No. 5646997
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chen KJ, 2021, IEEE T CIRC SYST VID, V31, P3942, DOI 10.1109/TCSVT.2020.3044186
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Du Y, 2022, IEEE T DEPEND SECURE, V19, P1420, DOI 10.1109/TDSC.2020.3013326
   Efimushkina T., 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P94
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   He JH, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107647
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Li N, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107476
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qiu YQ, 2021, IEEE T CIRC SYST VID, V31, P1380, DOI 10.1109/TCSVT.2020.3006494
   Qiu YQ, 2018, J VIS COMMUN IMAGE R, V52, P86, DOI 10.1016/j.jvcir.2018.02.005
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sakai H., 2008, P INT S INF THEOR IT, P1
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   sipi, 1977, USC SIPI IMAGE DATAB
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Weng SW, 2021, INFORM SCIENCES, V549, P13, DOI 10.1016/j.ins.2020.10.063
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu Y., 2011, Visual Communications and Image Processing (VCIP), P1
   Xiao MY, 2021, IEEE SIGNAL PROC LET, V28, P1620, DOI 10.1109/LSP.2021.3101424
   Xiao MY, 2021, IEEE T CIRC SYST VID, V31, P2535, DOI 10.1109/TCSVT.2020.3027391
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Xuan GR, 2019, J INF SECUR APPL, V45, P1, DOI 10.1016/j.jisa.2018.12.007
   Yin ZX, 2020, IEEE T CIRC SYST VID, V30, P2343, DOI 10.1109/TCSVT.2020.2969463
NR 38
TC 5
Z9 6
U1 1
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103487
DI 10.1016/j.jvcir.2022.103487
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600008
DA 2024-07-18
ER

PT J
AU Ding, WW
   Zhou, GH
   Ding, CY
   Li, G
   Liu, K
AF Ding, Wenwen
   Zhou, GuangHui
   Ding, ChongYang
   Li, Guang
   Liu, Kai
TI Graph-based relational reasoning in a latent space for skeleton-based
   action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Graph neural networks; Graph convolutional network;
   Message passing; Spatio-temporal graph; Grassmannian geometry
AB Motivated by the powerful capability of deep neural networks in feature learning, a new graph-based neural network is proposed to learn local and global relational information on skeleton sequences represented as spatio-temporal graphs (STGs). The pipeline of our network architecture consists of three main stages. As the first stage, spatial-temporal sub-graphs (sub-STGs) are projected into a latent space in which every point is represented as a linear subspace. The second stage is based on message passing to acquire the localized correlated features of the nodes in the latent space. The third stage relies on graph convolutional networks (GCNs) to reason the long-range spatio-temporal dependencies through a graph representation of the latent space. Finally, the average pooling layer and the softmax classifier are then employed to predict the action categories based on the extracted local and global correlations. We validate our model in terms of action recognition using three challenging datasets: the NTU RGB+D, Kinetics Motion, and SBU Kinect Interaction datasets. The experimental results demonstrate the effectiveness of our approach and show that our proposed model outperforms the state-of-the-art methods.
C1 [Ding, Wenwen; Zhou, GuangHui] Huaibei Normal Univ, Sch Math Sci, Huaibei, Anhui, Peoples R China.
   [Ding, ChongYang; Li, Guang; Liu, Kai] Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
C3 Huaibei Normal University; Xidian University
RP Liu, K (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
EM dww2048@163.com; 163zgh@163.com; dingcy@stu.xidian.edu.cn;
   liguang1980@stu.xidian.edu.cn; kailiu@xidian.edu.cn
RI wang, yu/IUQ-6654-2023; liu, jianyang/JXL-6273-2024; Liu,
   Kai/IST-6808-2023
FU National Natural Science Foundation of China [62171342]; Nature Science
   Foun-dation of Anhui Province [1908085MF186]; Key Natural Science
   Foundation of the Anhui Higher Education Institutions of China
   [KJ2018A0384, KJ2019A0589]; Major Nat-ural Science Foundation of the
   Anhui Higher Education Institutions of China [KJ2020ZD008]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China (Grant No. 62171342) , the Nature Science
   Foun-dation of Anhui Province (Grant No. 1908085MF186) , the Key Natural
   Science Foundation of the Anhui Higher Education Institutions of China
   (Grant No. KJ2018A0384 and No. KJ2019A0589) , and the Major Nat-ural
   Science Foundation of the Anhui Higher Education Institutions of China
   (Grant No. KJ2020ZD008) .
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Borzeshi EZ, 2013, IEEE SIGNAL PROC LET, V20, P1207, DOI 10.1109/LSP.2013.2284196
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Ding WW, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2019.115776
   Ding WW, 2018, PATTERN RECOGN, V77, P75, DOI 10.1016/j.patcog.2017.12.004
   Ding WW, 2015, J VIS COMMUN IMAGE R, V26, P329, DOI 10.1016/j.jvcir.2014.10.009
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Gao X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P601, DOI 10.1145/3343031.3351170
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Harandi MT, 2014, LECT NOTES COMPUT SC, V8690, P17, DOI 10.1007/978-3-319-10605-2_2
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZW, 2018, AAAI CONF ARTIF INTE, P3279
   Huang ZW, 2017, AAAI CONF ARTIF INTE, P2036
   Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137
   Huynh-The T., 2019, INFORM SCIENTIST
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji X., 2021, KNOWL-BASED SYST
   Kay W., 2017, ARXIV170506950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kipf TN, 2016, ARXIV
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li CL, 2018, AAAI CONF ARTIF INTE, P3482
   Li M.M., 2020, CENTRALITY GRAPH CON
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li Q., 2018, AAAI, V32, DOI [https://doi.org/10.1609/aaai.v32i1.11604, DOI 10.1109/IFETC.2018.8583886]
   Li W, 2017, IEEE I CONF COMP VIS, P1453, DOI 10.1109/ICCV.2017.161
   Li WB, 2015, IEEE I CONF COMP VIS, P4444, DOI 10.1109/ICCV.2015.505
   Liu J., 2017, ARXIV PREPRINT ARXIV
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Nguyen XS, 2019, PROC CVPR IEEE, P12028, DOI 10.1109/CVPR.2019.01231
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Schlichtkrull Michael, 2018, PROC EUR SEMANTIC WE, P593
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YQ, 2016, NEUROCOMPUTING, V174, P988, DOI 10.1016/j.neucom.2015.10.035
   Wen YH, 2019, AAAI CONF ARTIF INTE, P8989
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Ying R, 2018, ADV NEUR IN, V31
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3111
   Zhang Y., 2018, ABS180507694 CORR
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou Jie, 2018, arXiv preprint arXiv:1812.08434
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 71
TC 2
Z9 2
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103410
DI 10.1016/j.jvcir.2021.103410
EA FEB 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800005
DA 2024-07-18
ER

PT J
AU Chen, J
   Wang, YJ
   Yan, XH
   Wang, JY
   Li, LL
AF Chen, Jia
   Wang, Yongjie
   Yan, Xuehu
   Wang, Jiayu
   Li, Longlong
TI Visual secret sharing scheme with (n,n) threshold based on WeChat Mini
   Program codes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; WeChat Mini Program codes; Error correction;
   Access control
ID CRYPTOGRAPHY
AB With the widespread use of WeChat Mini Programs, their security has attracted more and more attention. The WeChat Mini Program can be accessed by scanning a WeChat Mini Program code. We should protect the code thus to protect the Mini Program. In this paper, based on studying the function in each pattern of WeChat Mini Program codes, a visual secret sharing (VSS) scheme for WeChat Mini Program codes (MPCVSS) with (n, n)(n >= 4) threshold is proposed to control and identify the users of Mini Program. MPCVSS combines the error-correcting characteristic of WeChat Mini Program codes with the theory of VSS. A secret WeChat Mini Program code is shared into n shared codes slightly modified from n cover codes. Each shared code is a valid code that can be scanned and decoded correctly. The secret code can be recovered by XORing n shares. The recovered code can be decoded as the same secret Mini Program. Theoretical analysis and experiments show that the proposed VSS scheme is practical and feasible.
C1 [Chen, Jia; Wang, Yongjie; Yan, Xuehu; Wang, Jiayu; Li, Longlong] Natl Univ Def Technol, 460 Huangshan Rd, Hefei 230037, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, YJ; Yan, XH (corresponding author), Natl Univ Def Technol, 460 Huangshan Rd, Hefei 230037, Peoples R China.
EM w_yong_j@189.cn; publictiger@126.com
OI wang, yongjie/0000-0003-2055-3799; Jia, Chen/0000-0002-8049-4893; Li,
   Longlong/0000-0001-7390-3647
FU Program of the National University of Defense Technology, China
   [61602491]; National Natural Science Founda-tion of China
FX Acknowledgments This work is funded by the Program of the National
   University of Defense Technology, China and the National Natural Science
   Founda-tion of China (Number: 61602491) . The authors are thankful to
   the reviewers for their professional comments and suggestions to improve
   the manuscript.
CR Aladdin Institute, 2021, AL I WHIT PAP INT DE
   Alipay, 2021, DEV DOC AL MIN PROGR
   [Anonymous], 2019, MINIAPP STANDARDIZAT
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Baidu, 2021, DEV DOC BAID SMARTPR
   Beimel Amos, 2011, Coding and Cryptology. Proceedings of the Third International Workshop, IWCC 2011, P11, DOI 10.1007/978-3-642-20901-7_2
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Jia C., 2021, SECUR COMMUN NETW, V2021
   Liu YJ, 2018, MULTIMED TOOLS APPL, V77, P25295, DOI 10.1007/s11042-018-5785-z
   Luo H, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P431, DOI 10.1109/ISDA.2008.37
   MIGNOTTE M, 1983, LECT NOTES COMPUT SC, V149, P371
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Song Wan, 2016, 2016 12th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN). Proceedings, P374, DOI 10.1109/MSN.2016.068
   Tan LD, 2020, ADV INTELL SYST, V895, P619, DOI 10.1007/978-3-030-16946-6_50
   Wan S, 2020, MULTIMED TOOLS APPL, V79, P2789, DOI 10.1007/s11042-019-08246-0
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Yan XH, 2021, IEEE T CIRC SYST VID, V31, P2896, DOI 10.1109/TCSVT.2020.3025527
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
   Yan XH, 2018, MULTIMED TOOLS APPL, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yan XH, 2017, INT J DIGIT CRIME FO, V9, P45, DOI 10.4018/IJDCF.2017040105
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yan XH, 2014, LECT NOTES COMPUT SC, V8836, P620, DOI 10.1007/978-3-319-12643-2_75
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 27
TC 2
Z9 2
U1 46
U2 112
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103409
DI 10.1016/j.jvcir.2021.103409
EA JAN 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0V1MU
UT WOS:000788110200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, SH
   Kang, X
   Liu, FS
   Nie, XS
   Liu, XB
AF Wang, Shaohua
   Kang, Xiao
   Liu, Fasheng
   Nie, Xiushan
   Liu, Xingbo
TI Discrete hashing with triple supervision learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE ANN search; Discrete hashing; Triple supervision
ID ALGORITHMS
AB In recent years, discrete supervised hashing methods have attracted increasing attention because of their high retrieval efficiency and precision. However, in these methods, some effective semantic information is typically neglected, which means that all the information is not sufficiently utilized. Moreover, these methods often only decompose the first-order features of the original data, ignoring the more fine-grained higher-order features. To address these problems, we propose a supervised hashing learning method called discrete hashing with triple supervision learning (DHTSL). Specifically, we integrate three aspects of semantic information into this method: (1) the bidirectional mapping of semantic labels; (2) pairwise similarity relations; (3) second-order features from the original data. We also design a discrete optimization method to solve the proposed objective function. Moreover, an out-of-sample extension strategy that can better maintain the independence and balance of hash codes is employed to improve retrieval performance. Extensive experiments on three widely used datasets demonstrate its superior performance.
C1 [Wang, Shaohua; Liu, Fasheng] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao, Shandong, Peoples R China.
   [Kang, Xiao] Shandong Univ, Sch Software, Jinan, Shandong, Peoples R China.
   [Nie, Xiushan; Liu, Xingbo] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University;
   Shandong Jianzhu University
RP Liu, XB (corresponding author), Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
EM sclxb@mail.sdu.edu.cn
RI Yu, Xiaohan/KCK-5462-2024; Wang, Shaohua/S-8094-2017
OI Wang, Shaohua/0000-0001-9599-3698
FU National Natural Science Foundation of China [61876098, 61671274,
   61573219]; National Key R&D Program of China [2018YFC0830100,
   2018YFC0830102]; special funds for distinguished professors of Shandong
   Jianzhu University, China
FX This work was supported in part by the National Natural Science
   Foundation of China (61876098, 61671274, 61573219), National Key R&D
   Program of China (2018YFC0830100, 2018YFC0830102) and special funds for
   distinguished professors of Shandong Jianzhu University, China.
CR Attouch H, 2013, MATH PROGRAM, V137, P91, DOI 10.1007/s10107-011-0484-9
   Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Dai Q, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1247, DOI 10.1145/2964284.2964331
   Dasgupta A., 2011, P 17 ACM SIGKDD INT, P1073
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824
   Ge LW, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102577
   Golub G. H., 2009, MATRIX COMPUTATIONS
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Gui J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1485, DOI 10.1145/3219819.3219955
   Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475
   Gui J, 2018, IEEE T NEUR NET LEAR, V29, P608, DOI 10.1109/TNNLS.2016.2636870
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jia W, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102908
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Kong WH, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P45, DOI 10.1145/2348283.2348293
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lai ZH, 2018, IEEE T IMAGE PROCESS, V27, P6147, DOI 10.1109/TIP.2018.2867956
   Lin GS, 2015, IEEE T PATTERN ANAL, V37, P2317, DOI 10.1109/TPAMI.2015.2404776
   Liu Q., 2016, PROC INT JOINT C ART, P1788
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XB, 2021, IEEE T CIRC SYST VID, V31, P3655, DOI 10.1109/TCSVT.2020.3040863
   Liu XB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3031
   Liu XB, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P871, DOI 10.1145/3357384.3357915
   Liu XB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1561, DOI 10.1145/3343031.3351091
   Liu XB, 2020, IEEE T IMAGE PROCESS, V29, P4254, DOI 10.1109/TIP.2020.2970577
   Liu XB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1662, DOI 10.1145/3240508.3240683
   Liu XB, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1678, DOI 10.1109/ICASSP.2018.8462454
   Luo X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1603, DOI 10.1145/3178876.3186072
   Luo X, 2018, ACM/SIGIR PROCEEDINGS 2018, P735, DOI 10.1145/3209978.3210035
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Ma C., 2017, PATTERN RECOGNIT LET
   Ma CY, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/iscas.2019.8702499
   Nie XS, 2021, IEEE T CIRC SYST VID, V31, P3669, DOI 10.1109/TCSVT.2020.3042972
   Shen FM, 2019, IEEE T IMAGE PROCESS, V28, P3662, DOI 10.1109/TIP.2019.2899987
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340
   Tian D., 2021, IEEE T CYBERN
   Tu B, 2021, IEEE GEOSCI REMOTE S, V18, P861, DOI 10.1109/LGRS.2020.2988124
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang XF, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103124
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Wu DY, 2019, PROC CVPR IEEE, P9061, DOI 10.1109/CVPR.2019.00928
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yuan X, 2021, PATTERN RECOGN LETT, V145, P247, DOI 10.1016/j.patrec.2021.02.016
   Zhang WQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3274, DOI 10.1145/3394171.3414028
   Zhang XN, 2019, PATTERN RECOGN LETT, V125, P677, DOI 10.1016/j.patrec.2019.07.010
   Zhao S, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P763, DOI 10.1145/3394171.3414033
   Zhi J., 2020, 2019 12 INT C IM SIG
   Zhu YX, 2019, IEEE SIGNAL PROC LET, V26, P395, DOI 10.1109/LSP.2019.2892233
NR 56
TC 2
Z9 2
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103355
DI 10.1016/j.jvcir.2021.103355
EA OCT 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700001
DA 2024-07-18
ER

PT J
AU Guan, QX
   Chen, HF
   Zhang, WM
   Yu, NH
AF Guan, Qingxiao
   Chen, Hefeng
   Zhang, Weiming
   Yu, Nenghai
TI Improving UNIWARD distortion function via isotropic construction and
   hierarchical merging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Distortion; UNIWARD
ID STEGANALYSIS; STEGANOGRAPHY
AB Distortion function is designed for evaluating the cost of modifications in adaptive steganography. UNIWARD is a successful and popular distortion scheme which achieves high performance both for spatial and JPEG images. In this paper, we analyze the UNIWARD scheme with some empirical rules of distortion function designation. Based on that we propose our scheme to improve UNIWARD distortion. In our scheme, we focus on the symmetric characteristic of UNIWARD, and suggest that not only use original wavelet filters but also their flippings to calculate sub-models of UNIWARD distortion to maintain its isotropic properties. Moreover, we design several schemes to merge sub-models, which could maintain its invariance regard to flipping or rotation and improve its security against steganalysis detection. Experimental results show our revised UNIWARD achieves better performance for spatial and JPEG image in comparison with original UNIWARD.
C1 [Guan, Qingxiao; Chen, Hefeng] Jimei Univ, Comp Engn Coll, Xiamen 361021, Peoples R China.
   [Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
C3 Jimei University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Chen, HF (corresponding author), Jimei Univ, Comp Engn Coll, Xiamen 361021, Peoples R China.; Zhang, WM (corresponding author), Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
EM chenhf@jmu.edu.cn; zhangwm@ustc.edu.cn
RI guan, qingxiao/AAE-5163-2022
OI Chen, Hefeng/0000-0002-7272-0563
CR Bas P, P 13 INT WORKSH INF, P59
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Cogranne R., 2020, IH MMSEC 2020 PROC 2, P161, DOI DOI 10.1145/3369412.3395075
   Cogranne R, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360896
   Cogranne R, 2015, IEEE INT WORKS INFOR
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Feng GR, 2020, IEEE T CIRC SYST VID, V30, P376, DOI 10.1109/TCSVT.2019.2891778
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jin ZY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107455
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2014, IEEE T INF FOREN SEC, V9, P752, DOI 10.1109/TIFS.2014.2309054
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Li FY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107454
   Lu W, 2021, IEEE T CIRC SYST VID, V31, P2909, DOI 10.1109/TCSVT.2020.3027843
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Pevny T, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P109, DOI 10.1145/3206004.3206015
   Sedighi V, 2016, IS T ELECT IMAGING M, P14
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Song XF, 2017, MULTIMED TOOLS APPL, V76, P26391, DOI 10.1007/s11042-016-4157-9
   Su WK, 2018, IEEE T CIRC SYST VID, V28, P3545, DOI 10.1109/TCSVT.2018.2865537
   Wang P, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107422
   Wang ZC, 2018, IEEE ACCESS, V6, P74917, DOI 10.1109/ACCESS.2018.2884198
   Xia C, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P55, DOI 10.1145/3082031.3083243
   Yin ZX, 2021, IEEE T SIGNAL INF PR, V7, P336, DOI 10.1109/TSIPN.2021.3081373
   Yousfi Y, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360897
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhang Y, 2020, IEEE T CIRC SYST VID, V30, P2750, DOI 10.1109/TCSVT.2019.2923980
   Zhao ZZ, 2019, IEEE T INF FOREN SEC, V14, P1843, DOI 10.1109/TIFS.2018.2885438
   Zhou WB, 2019, IET IMAGE PROCESS, V13, P24, DOI 10.1049/iet-ipr.2018.5401
   Zhou WB, 2017, IEEE T INF FOREN SEC, V12, P2654, DOI 10.1109/TIFS.2017.2718480
NR 41
TC 0
Z9 0
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103333
DI 10.1016/j.jvcir.2021.103333
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700003
DA 2024-07-18
ER

PT J
AU Wang, ZX
   Ding, GG
   Han, JG
   Li, F
AF Wang, Zixi
   Ding, Guiguang
   Han, Jungong
   Li, Fan
TI Deep image compression with multi-stage representation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep image compression; Multi-stage representation; Data-dependent
   probability model; Convolutional neural network
AB While deep learning-based image compression methods have shown impressive coding performance, most existing methods are still in the mire of two limitations: (1) unpredictable compression efficiency gain when adopting convolutional neural networks with different depths, and (2) lack of an accurate model to estimate the entropy during the training process. To address these two problems, in this paper, a deep multi-stage representation based image compression (MSRIC) method is proposed. Owing to this architecture, the detail information of shallow stages and the compact information of deep stages can be utilized for image reconstruction. Furthermore, a data-dependent channel-wised factorized probability model (DCFPM) is adopted to increase the accuracy of entropy estimation. Experimental results indicate that the proposed method guarantees better perceptual performance at a wide range of bit-rates. Also, ablation studies are carried out to validate the above mentioned technologies.
C1 [Wang, Zixi; Li, Fan] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
   [Ding, Guiguang] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Han, Jungong] Aberystwyth Univ, Comp Sci Dept, Aberystwyth SY23 3FL, Dyfed, Wales.
C3 Xi'an Jiaotong University; Tsinghua University; Aberystwyth University
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
EM lifan@mail.xjtu.edu.cn
RI Han, Jungong/ABE-6812-2020; Ding, Guiguang/KIL-3528-2024; Wang,
   Zixi/KEI-0077-2024; Wang, Zixi/JMP-7296-2023
FU National Sci-ence Foundation of China [62071369]; Key Research and
   Development Program of Shaanxi Province, China [2020KW-009]
FX This research work was supported in part by the National Sci-ence
   Foundation of China (62071369) , and the Key Research and Development
   Program of Shaanxi Province, China (2020KW-009) .
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Akbari M, 2019, INT CONF ACOUST SPEE, P2042, DOI [10.1109/icassp.2019.8683541, 10.1109/ICASSP.2019.8683541]
   Balle J., 2017, INT C LEARN REPR
   Balle J., 2018, TENSORFLOW COMPRESSI
   Balle J, 2018, ICLR
   Ballé J, 2018, PICT COD SYMP, P248, DOI 10.1109/PCS.2018.8456272
   Begaint J., 2020, CompressAI: a PyTorch library and evaluation platform for end-to-end compression research
   Campos Joaquim, 2019, P IEEE C COMP VIS PA
   Cheng Z., 2020, ARXIV200101568
   Cheng ZX, 2020, IEEE T MULTIMEDIA, V22, P860, DOI 10.1109/TMM.2019.2938345
   Cheng ZX, 2018, PICT COD SYMP, P253, DOI 10.1109/PCS.2018.8456308
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dufaux F, 2009, IEEE SIGNAL PROC MAG, V26, P195, DOI 10.1109/MSP.2009.934187
   Dumas T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1188, DOI 10.1109/ICASSP.2018.8462263
   Huang C., 2019, P IEEE INT C VIS COM
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Kingma D. P., 2014, arXiv
   Li M., 2020, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2020.2983926, DOI 10.1109/TPAMI.2020.2983926]
   Ma Z, 2019, P IEEE C COMP VIS PA, P3
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Theis L., 2017, ICLR
   Toderici G., 2016, P INT C LEARN REPR I
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Zhou LC, 2018, IEEE COMPUT SOC CONF, P192, DOI 10.1109/CVPRW.2018.00034
NR 27
TC 4
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103226
DI 10.1016/j.jvcir.2021.103226
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900004
DA 2024-07-18
ER

PT J
AU Naveed, H
   Jafri, F
   Javed, K
   Babri, HA
AF Naveed, Humza
   Jafri, Fareed
   Javed, Kashif
   Babri, Haroon Atique
TI Driver activity recognition by learning spatiotemporal features of pose
   and human object interaction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Driver activity recognition; Feature extraction; Spatiotemporal
   features; Driver activity recognition dataset
ID DRIVING POSTURES; INTELLIGENT VEHICLES; CONTOURLET TRANSFORM
AB Detecting hazardous activity during driving can be useful in curbing roadside accidents. Existing techniques utilizing image based features for encoding such activity can sometimes misclassify crucial scenarios. One particular work by Zhao et al. (2013 [1], 2013 [2], 2011 [3]) suggests an image based feature set that encodes the driver's pose, which is categorized into one of four activities. We bring more clarity in understanding the activity by proposing a richer, video based feature set that adeptly exploits spatiotemporal information of the driver. Our feature set encodes the driver's pose, crucial variations in pose and interactions with objects within the vehicle. The feature set is tested on our newly created dataset since the ones used in literature are not publicly available. Our proposed feature set captures a larger number of activities and using standard classifiers and benchmarks it has shown significant improvements over the existing ones.
C1 [Naveed, Humza; Jafri, Fareed; Javed, Kashif; Babri, Haroon Atique] Univ Engn & Technol, Lahore, Pakistan.
C3 University of Engineering & Technology Lahore
RP Naveed, H; Jafri, F (corresponding author), Univ Engn & Technol, Lahore, Pakistan.
EM humza_naveed@yahoo.com; fjafri3@gatech.edu; kashif.javed@uet.edu.pk;
   babri@uet.edu.pk
CR Abouelnaga Y., 2017, ARXIV PREPRINT ARXIV
   Alotaibi M, 2020, SIGNAL IMAGE VIDEO P, V14, P617, DOI 10.1007/s11760-019-01589-z
   Chaaraoui AA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P91, DOI 10.1109/ICCVW.2013.19
   [Anonymous], 2016, STATE FARMS DISTRACT
   [Anonymous], 2004, WORLD HLTH ORG
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Baheti B, 2018, IEEE COMPUT SOC CONF, P1145, DOI 10.1109/CVPRW.2018.00150
   Behera A., 2018, P GERM C PATT REC, P298
   Breiman L., 2001, Mach. Learn., V45, P5
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen JC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061908
   Cheng SY, 2007, COMPUT VIS IMAGE UND, V106, P245, DOI 10.1016/j.cviu.2006.08.010
   Chihang Zhao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P926, DOI 10.1109/ICIG.2011.184
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chung J, 2016, ARXIV PREPRINT ARXIV
   Cuong Tran, 2009, 2009 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2009), P97, DOI 10.1109/ICVES.2009.5400235
   Dong YC, 2011, IEEE T INTELL TRANSP, V12, P596, DOI 10.1109/TITS.2010.2092770
   Tran D, 2018, IET INTELL TRANSP SY, V12, P1210, DOI 10.1049/iet-its.2018.5172
   El Khatib A, 2019, IEEE T INTELL TRANSP
   Eraqi HM, 2019, J ADV TRANSPORT, DOI 10.1155/2019/4125865
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hssayeni M. D., 2017, Electronic Imaging, V2017, P20, DOI 10.imawm-162
   Hu YC, 2019, MACH VISION APPL, V30, P851, DOI 10.1007/s00138-018-0994-z
   Huang C., 2020, IEEE ACCESS, V8
   Koesdwiady A, 2017, LECT NOTES COMPUT SC, V10317, P11, DOI 10.1007/978-3-319-59876-5_2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Celaya-Padilla JM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9152962
   Mase JM, 2020, I C INF COMM TECH CO, P1, DOI 10.1109/ICTC49870.2020.9289588
   Masood S., 2018, PATTERN RECOGN LETT
   Murphy-Chutorian E, 2008, IEEE INT VEH SYM, P1174
   Naveed H, 2019, INT J MACH LEARN CYB, V10, P2329, DOI 10.1007/s13042-018-0870-1
   Ohn-Bar E, 2014, INT C PATT RECOG, P660, DOI 10.1109/ICPR.2014.124
   Okon OD, 2017, LECT NOTES ARTIF INT, V10459, P170, DOI 10.1007/978-3-319-66471-2_19
   Park S, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P644
   Pasupa K, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE)
   Pedregosa F, 2011, J. Mach. Learn. Res., V12, P2825
   Ranney T.A., 2001, Technical report
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Rish I., 2001, IJCAI 2001 WORKSH EM, P41
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tran C, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P446, DOI 10.1109/ISM.2009.89
   Veeraraghavan H., 2005, 2005 IEEE Intelligent Transportation Systems Conference (ITSC), P580
   W.H. Organization, 2019, WORLD HLTH STAT 2019
   Xing Y, 2019, IEEE T VEH TECHNOL, V68, P5379, DOI 10.1109/TVT.2019.2908425
   Xing Y, 2019, IEEE T VEH TECHNOL, V68, P4377, DOI 10.1109/TVT.2019.2903299
   Yan C, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416500105
   Yan C, 2016, IET COMPUT VIS, V10, P103, DOI 10.1049/iet-cvi.2015.0175
   Yan C, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P83, DOI 10.1109/CISP.2014.7003754
   Zhang B., 2010, INT J INTELL COMPUT
   Zhao CH, 2012, IET INTELL TRANSP SY, V6, P161, DOI 10.1049/iet-its.2011.0116
   Zhao CH, 2014, J INTELL FUZZY SYST, V27, P2011, DOI 10.3233/IFS-141167
   Zhao CH, 2013, J INTELL ROBOT SYST, V72, P483, DOI 10.1007/s10846-012-9797-z
   Zhao CH, 2012, ENG APPL ARTIF INTEL, V25, P1677, DOI 10.1016/j.engappai.2012.09.018
   Zhao CHH, 2013, NEURAL COMPUT APPL, V22, pS175, DOI 10.1007/s00521-012-1057-4
   Zhao Y, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7316954
NR 59
TC 4
Z9 5
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103135
DI 10.1016/j.jvcir.2021.103135
EA APR 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200005
DA 2024-07-18
ER

PT J
AU Wang, H
   Wu, H
   Hu, Q
   Chi, JN
   Yu, XS
   Wu, CD
AF Wang, Huan
   Wu, Hao
   Hu, Qian
   Chi, Jianning
   Yu, Xiaosheng
   Wu, Chengdong
TI Underwater image super-resolution using multi-stage information
   distillation networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image; Super-resolution; Visually-guided underwater robots;
   Convolutional neural network
ID QUALITY ASSESSMENT; INTERPOLATION
AB Recently, single image super-resolution (SISR) has been widely applied in the fields of underwater robot vision and obtained remarkable performance. However, most current methods generally suffered from the problem of a heavy burden on computational resources with large model sizes, which limited their real-world underwater robotic applications. In this paper, we introduce and tackle the super resolution (SR) problem for underwater robot vision and provide an efficient solution for near real-time applications. We present a novel lightweight multi-stage information distillation network, named MSIDN, for better balancing performance against applicability, which aggregates the local distilled features from different stages for more powerful feature representation. Moreover, a novel recursive residual feature distillation (RRFD) module is constructed to progressively extract useful features with a modest number of parameters in each stage. We also propose a channel interaction & distillation (CI&D) module that employs channel split operation on the preceding features to produce two-part features and utilizes the inter channel-wise interaction information between them to generate the distilled features, which can effectively extract the useful information of current stage without extra parameters. Besides, we present USR-2K dataset, a collection of over 1.6K samples for large-scale underwater image SR training, and a testset with an additional 400 samples for benchmark evaluation. Extensive experiments on several standard benchmark datasets show that the proposed MSIDN can provide state-of-the-art or even better performance in both quantitative and qualitative measurements.
C1 [Wang, Huan; Hu, Qian; Chi, Jianning; Yu, Xiaosheng; Wu, Chengdong] Northeastern Univ, 195 Chuangxin Rd, Shenyang, Peoples R China.
   [Wu, Hao] Univ Sydney, Sydney, NSW 2006, Australia.
C3 Northeastern University - China; University of Sydney
RP Wu, CD (corresponding author), Northeastern Univ, 195 Chuangxin Rd, Shenyang, Peoples R China.
EM wanghuan_neu@126.com; hawu1598@uni.sydney.edu.au; huqian_neu@126.com;
   chijianning@mail.neu.edu.cn; yuxiaosheng@mail.neu.edu.cn;
   wuchengdong@mail.neu.edu.cn
RI Wu, Chengdong/IST-5302-2023; Chi, Jianning/GQQ-4099-2022
OI Chi, Jianning/0000-0002-9748-5619
FU National Natural Science Foundation of China [U20A20197, 61973063,
   U1713216, 61901098, 61971118]; Liaoning Key Research and Development
   Project, China [2020JH2/10100040]; China Postdoctoral Science Foundation
   [2020M670778]; Northeastern University Postdoctoral Research Fund,
   Australia [20200308]; Scientific Research Foundation of Liaoning
   Provincial Education Department, China [LT2020002]; Fundamental Research
   Fund for the Central Universities of China [N2026005, N181602014,
   N2026004, N2026006, N2026001, N2011001]
FX The authors would like to thank Xingrui Wu, Haopeng Zhang, and Changqing
   Ma for helpful discussions and fruitful feedback along the way. This
   work was supported in part by the National Natural Science Foundation of
   China under Grant nos. U20A20197, 61973063, U1713216, 61901098,
   61971118, Liaoning Key Research and Development Project, China
   2020JH2/10100040, the China Postdoctoral Science Foundation 2020M670778,
   the Northeastern University Postdoctoral Research Fund, Australia
   20200308, the Scientific Research Foundation of Liaoning Provincial
   Education Department, China LT2020002, and the Fundamental Research Fund
   for the Central Universities of China N2026005, N181602014, N2026004,
   N2026006, N2026001, N2011001.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   [Anonymous], 2016, P C C WORKSH NEUR IN
   Anwar S., 2019, ARXIV190612021
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bingham B, 2010, J FIELD ROBOT, V27, P702, DOI 10.1002/rob.20350
   Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Chen YZ, 2012, PROC SPIE, V8332, DOI 10.1117/12.918997
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gradetsky V, 2020, STUD SYST DECIS CONT, V272, P65, DOI 10.1007/978-3-030-37841-7_6
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Islam MJ, 2020, IEEE INT CONF ROBOT, P900, DOI [10.1109/ICRA40945.2020.9197213, 10.1109/icra40945.2020.9197213]
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li J, 2018, PROC EUR C COMPUT VI, V11212, P517, DOI 10.1007/978-3-030-01237-3_32
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Luo P., 2020, ROBOTICS SCI SYSTEMS, DOI [10.15607/rss.2020.xvi.018, DOI 10.15607/RSS.2020.XVI.018]
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Ma XY, 2020, IEEE ACCESS, V8, P84316, DOI 10.1109/ACCESS.2020.2988483
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Menandro PS, 2020, GEOSCIENCES, V10, DOI 10.3390/geosciences10070273
   Mishra D, 2016, NEUROCOMPUTING, V202, P49, DOI 10.1016/j.neucom.2016.04.013
   Ni KS, 2009, IEEE T IMAGE PROCESS, V18, P1976, DOI 10.1109/TIP.2009.2023706
   Rummer JL, 2020, CORAL REEFS, V39, P1215, DOI 10.1007/s00338-020-01972-0
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Singh A., 2020, INT J ELECT COMPUT E, V10, pPP3014, DOI [10.11591/ijece.v10i3, DOI 10.11591/IJECE.V10I3]
   Sonderby C. K., 2016, ARXIV161004490
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2018, IEEE COMPUT SOC CONF, P965, DOI 10.1109/CVPRW.2018.00130
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Zhihao, 2019, IEEE PHOTONICS J, DOI DOI 10.1109/JPHOT.2020.3019059
   Wei SF, 2018, SUSTAIN CITIES SOC, V37, P358, DOI 10.1016/j.scs.2017.11.012
   Xu Y, 2019, IEEE T IMAGE PROCESS, V28, P3034, DOI 10.1109/TIP.2019.2893530
   Yu YF, 2007, OPT ENG, V46, DOI 10.1117/1.2802169
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang YD, 2010, 2010 INTERNATIONAL CONFERENCE ON EDUCATION AND SPORTS EDUCATION, VOL II, P287
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 59
TC 6
Z9 6
U1 3
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103136
DI 10.1016/j.jvcir.2021.103136
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200001
DA 2024-07-18
ER

PT J
AU Sharma, K
   Rameshan, R
AF Sharma, Krishan
   Rameshan, Renu
TI Distance based kernels for video tensors on product of Riemannian matrix
   manifolds
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video tensor; Product manifold geometry; Sparse representation;
   Grassmann manifold; SPD manifold; Riemannian manifold; Kernel methods
ID GESTURE RECOGNITION; REPRESENTATION; GEOMETRY; SEQUENCES
AB In this paper, we explore the inherent geometry of video tensors by modeling them as points in product of Riemannian matrix manifolds. A video tensor is decomposed into three modes (factors) using matrix unfolding operation and each mode is represented as a point in a product space of Grassmannian and symmetric positive definite (SPD) matrix manifold. Hence a video is represented as a point in the Cartesian product of three such product spaces. Being a manifold valued (non-Euclidean) representation, application of several state-of-the-art Euclidean machine learning algorithms lead to inferior results. To overcome this, we propose positive definite kernels which map the points from product manifold space to Hilbert space. The proposed kernel functions implicitly make use of geodesic distance on product manifold to obtain a similarity measure and generate a kernel-gram matrix. In addition, we generate a discriminative feature representation for each manifold valued point using kernel-gram matrix diagonalization. Classification is performed in a sparse framework. The proposed methodology is tested over three publicly available datasets for hand gesture, traffic signal and sign language recognition. Experimentation performed over these datasets show that the proposed methodology is powerful in terms of classification accuracy in comparison with the state-of-the-art methods.
C1 [Sharma, Krishan; Rameshan, Renu] Indian Inst Technol Mandi, Sch Comp & Elect Engn, Kamand 175005, Himachal Prades, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Mandi
RP Sharma, K (corresponding author), Indian Inst Technol Mandi, Sch Comp & Elect Engn, Kamand 175005, Himachal Prades, India.
EM krishans@vehant.com
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Berg C., 1984, HARMONIC ANAL SEMIGR
   Bilinski Piotr, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P61, DOI 10.1007/978-3-642-23968-7_7
   Bonnabel S, 2009, SIAM J MATRIX ANAL A, V31, P1055, DOI 10.1137/080731347
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Datta Ankur, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1034, DOI 10.1109/ICCVW.2009.5457588
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Faraki M, 2015, IET COMPUT VIS, V9, P331, DOI 10.1049/iet-cvi.2014.0018
   Golts A, 2016, IEEE J-STSP, V10, P726, DOI 10.1109/JSTSP.2016.2555241
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005
   Harandi M, 2015, IEEE I CONF COMP VIS, P4112, DOI 10.1109/ICCV.2015.468
   Harandi M, 2015, INT J COMPUT VISION, V114, P113, DOI 10.1007/s11263-015-0833-x
   Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16
   Huang ZW, 2018, IEEE T CIRC SYST VID, V28, P2513, DOI 10.1109/TCSVT.2017.2729660
   Huang ZW, 2017, AAAI CONF ARTIF INTE, P2036
   Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137
   Huang ZW, 2015, PR MACH LEARN RES, V37, P720
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Jing PG, 2019, SIGNAL PROCESS, V156, P62, DOI 10.1016/j.sigpro.2018.10.018
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kong Y, 2016, COMPUT VIS IMAGE UND, V144, P14, DOI 10.1016/j.cviu.2015.10.001
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Lee JE, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0171
   Li PH, 2017, IEEE T PATTERN ANAL, V39, P803, DOI 10.1109/TPAMI.2016.2560816
   Li RN, 2010, PROC CVPR IEEE, P2038, DOI 10.1109/CVPR.2010.5539880
   Liang CW, 2016, IEEE INT SYM MULTIM, P261, DOI [10.1109/ISM.2016.32, 10.1109/ISM.2016.0058]
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Lui YM, 2012, J MACH LEARN RES, V13, P3297
   Lui YM, 2012, IEEE T CIRC SYST VID, V22, P930, DOI 10.1109/TCSVT.2011.2181452
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Ma Y., 1998, P C MATH THEOR NETW
   ONeill B., 1983, Pure and Applied Mathematics, V103
   Qiu Q, 2011, IEEE I CONF COMP VIS, P707, DOI 10.1109/ICCV.2011.6126307
   Rodolà E, 2019, COMPUT GRAPH FORUM, V38, P678, DOI 10.1111/cgf.13598
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shaji A, 2008, INT C PATT RECOG, P3555
   Sharma K, 2019, INT CONF ACOUST SPEE, P3437, DOI 10.1109/ICASSP.2019.8682898
   Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8
   Tong YL, 1984, Lecture Notes-Monograph Series, P68, DOI DOI 10.1214/LNMS/1215465631
   Turaga P, 2010, INT CONF ACOUST SPEE, P946, DOI 10.1109/ICASSP.2010.5495292
   Turaga P, 2009, PROC CVPR IEEE, P2427
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang BY, 2017, IEEE T CIRC SYST VID, V27, P554, DOI 10.1109/TCSVT.2016.2609760
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P4001, DOI 10.1007/s11042-017-5173-0
   Zhang L, 2018, IEEE T CIRC SYST VID, V28, P2562, DOI 10.1109/TCSVT.2017.2721108
   Zhang L, 2019, IEEE T IMAGE PROCESS, V28, P205, DOI 10.1109/TIP.2018.2866688
   Zhang XK, 2016, PROC CVPR IEEE, P4498, DOI 10.1109/CVPR.2016.487
NR 63
TC 1
Z9 1
U1 3
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103045
DI 10.1016/j.jvcir.2021.103045
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600004
DA 2024-07-18
ER

PT J
AU Irfan, MA
   Magli, E
AF Irfan, Muhammad Abeer
   Magli, Enrico
TI Exploiting color for graph-based 3D point cloud denoising*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Point cloud denoising; Color denoising; Convex optimization; Tikhonov
   regularization; Total variation; Graph signal processing
ID GEOMETRY; CLASSIFICATION
AB A point cloud is a representation of a 3D scene as a discrete collection of geometry plus other attributes such as color, normal, transparency associated with each point. The traditional acquisition process of a 3D point cloud, e. g. using depth information acquired directly by active sensors or indirectly from multi-viewpoint images, suffers from a significant amount of noise. Hence, the problem of point cloud denoising has recently received a lot of attention. However, most existing techniques attempt to denoise only the geometry of each point, based on the geometry information of the neighboring points; there are very few works at all considering the problem of denoising the color attributes of a point cloud. In this paper, we move beyond the state of the art and we propose a novel technique employing graph-based optimization, taking advantage of the correlation between geometry and color, and using it as a powerful tool for several different tasks, i.e. color denoising, geometry denoising, and combined geometry and color denoising. The proposed method is based on the notion that the correct location of a point also depends on the color attribute and not only the geometry of the neighboring points, and the correct color also depends on the geometry of the neighbors. The proposed method constructs a suitable k-NN graph from geometry and color and applies graph-based convex optimization to obtain the denoised point cloud. Extensive simulation results on both real-world and synthetic point clouds show that the proposed denoising technique outperforms state-of-the-art methods using both subjective and objective quality metrics.
C1 [Irfan, Muhammad Abeer; Magli, Enrico] Politecn Torino, Dept Elect & Telecommun, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Irfan, MA (corresponding author), Politecn Torino, Dept Elect & Telecommun, I-10129 Turin, Italy.
EM abeer.irfan@polito.it
RI irfan, muhammad/JAD-1451-2023
OI irfan, muhammad/0000-0002-9885-9547; Irfan, Muhammad
   Abeer/0000-0003-3442-0727
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730
   Cheung G, 2018, P IEEE, V106, P907, DOI 10.1109/JPROC.2018.2799702
   Chung F. R. K., 1997, AM MATH SOC, V92, DOI DOI 10.1090/CBMS/092
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Couprie C, 2013, SIAM J IMAGING SCI, V6, P1246, DOI 10.1137/120895068
   Dal Mutto C, 2012, IEEE J-STSP, V6, P505, DOI 10.1109/JSTSP.2012.2194474
   Das R, 2016, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, INTELLIGENT CONTROL AND ENERGY SYSTEMS (ICPEICES 2016)
   Deutsch S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2786, DOI 10.1109/ICASSP.2018.8462113
   Deutsch S, 2016, INT CONF ACOUST SPEE, P4673, DOI 10.1109/ICASSP.2016.7472563
   Dinesh C, 2018, IEEE INT WORKSH MULT
   Eberly D., 1999, DISTANCE POINT TRIAN
   Fliegel K., 2019, 3D VISUAL CONTENT CR, P299
   Gao X, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Gatti A, 2013, J GEODESY, V87, P15, DOI 10.1007/s00190-012-0574-3
   Girardeau-Montaut Daniel., 2016, Cloudcompare
   Guennebaud G, 2008, COMPUT GRAPH FORUM, V27, P653, DOI 10.1111/j.1467-8659.2008.01163.x
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   Han XF, 2017, SIGNAL PROCESS-IMAGE, V57, P103, DOI 10.1016/j.image.2017.05.009
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Huang WM, 2009, THIRD INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING, P574, DOI 10.1109/WGEC.2009.139
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Jinlei Z., 2015, P IEEE INT C SIGN PR, P1
   Kamal K, 2018, INT J PAVEMENT ENG, V19, P565, DOI 10.1080/10298436.2016.1187730
   Le Turnier P., 2020, INT J MOL SCI, V26, p1415.
   Levin D, 2004, MATH VISUAL, P37
   Li QN, 2018, VISUAL COMPUT, V34, P229, DOI 10.1007/s00371-016-1330-0
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Liu YJ, 2012, VISUAL COMPUT, V28, P75, DOI 10.1007/s00371-011-0605-8
   Lu J, 2015, CHIN CONTR CONF, P3707, DOI 10.1109/ChiCC.2015.7260213
   Mattei E, 2017, COMPUT GRAPH FORUM, V36, P123, DOI 10.1111/cgf.13068
   Matti EK, 2014, PHOTOGRAMM FERNERKUN, P161, DOI 10.1127/1432-8364/2014/0216
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pang JH, 2017, IEEE T IMAGE PROCESS, V26, P1770, DOI 10.1109/TIP.2017.2651400
   Perraudin N., 2014, ARXIV PREPRINT ARXIV
   Perraudin N., 2014, ARXIV PREPRINT ARXIV
   Rosman G, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12139
   Rusu RB, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3197
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Schoenenberger Y., 2015, 3DTV C TRUE VIS CAPT, P1, DOI DOI 10.1109/3DTV.2015.7169366
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Siena FL, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0905-x
   SLATER D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P563, DOI 10.1109/ICCV.1995.466889
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Tan DJ, 2018, INT J COMPUT VISION, V126, P158, DOI 10.1007/s11263-017-0988-8
   Thanou D, 2016, IEEE T IMAGE PROCESS, V25, P1765, DOI 10.1109/TIP.2016.2529506
   Tulvan C., 2016, JTC1SC29WG11 ISO IEC
   Verdoja F, 2017, IEEE INT CON MULTI, P1285, DOI 10.1109/ICME.2017.8019382
   Wang J., 2012, Geometric structure of high-dimensional data and dimensionality reduction
   Yang X., 2017, 2017 IEEE INT C INF, P1
   Zhan Q., 2009, LASER SCANNING, V38, P155
   Zheng YL, 2017, VISUAL COMPUT, V33, P857, DOI 10.1007/s00371-017-1391-8
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386
NR 58
TC 10
Z9 12
U1 3
U2 44
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103027
DI 10.1016/j.jvcir.2021.103027
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BY
UT WOS:000633494500001
DA 2024-07-18
ER

PT J
AU Wu, GX
   Li, YC
AF Wu, Guixian
   Li, Yuancheng
TI Non-maximum suppression for object detection based on the chaotic whale
   optimization algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Post-processing step; Object detection; Non-maximum suppression
AB Non-maximum suppression (NMS) as a post-processing step for object detection is mainly used to remove redundant bounding boxes in the object and plays a vital role in many detectors. Its positioning accuracy mainly depends on the bounding box with the highest score, and this strategy is difficult to eliminate the false positive. In order to solve the problem, this paper regards the post-processing step as a combinatorial optimization problem and combines the chaotic whale optimization algorithm and non-maximum suppression. The chaotic search method is used to generate an initial combinatorial solution, and the whale optimization algorithm is discretized to create an updated combinatorial strategy. Under the guidance of the fitness function, the optimal combination is searched. In addition, the method of difference set area (DSA) is proposed to optimize the final detection result. The experiment uses the current mainstream framework Faster R-CNN as the detector on PASCAL VOC2012, COCO2017 and the Warships datasets. The experimental results show that the proposed method can significantly improve the average precision (AP) of detectors compared with the most advanced methods.
C1 [Wu, Guixian; Li, Yuancheng] North China Elect Power Univ, Sch Control & Comp Engn, Beijing 102206, Peoples R China.
C3 North China Electric Power University
RP Li, YC (corresponding author), North China Elect Power Univ, Sch Control & Comp Engn, Beijing 102206, Peoples R China.
EM yuancheng@ncepu.cn
RI Li, yuancheng/IUO-3866-2023
OI Li, Yuancheng/0000-0001-8074-7259
CR Abdel-Basset M, 2018, FUTURE GENER COMP SY, V85, P129, DOI 10.1016/j.future.2018.03.020
   Ali IM, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100607
   [Anonymous], 2018, APPL INTELL
   Ben Ali A, 2020, INFORM SCIENCES, V512, P880, DOI 10.1016/j.ins.2019.10.026
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen C, 2019, IEEE ACCESS, V7, P104848, DOI 10.1109/ACCESS.2019.2930939
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Jiang LF, 2020, MULTIMED TOOLS APPL, V79, P4277, DOI 10.1007/s11042-018-6806-7
   Koulinas G, 2014, INFORM SCIENCES, V277, P680, DOI 10.1016/j.ins.2014.02.155
   Lin CZ, 2019, IEEE T CIRC SYST VID, V29, P3608, DOI 10.1109/TCSVT.2018.2883558
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu WC, 2018, IEEE GEOSCI REMOTE S, V15, P937, DOI 10.1109/LGRS.2018.2813094
   Lorenz EN, 2005, J ATMOS SCI, V62, P1574, DOI 10.1175/JAS3430.1
   Min WD, 2019, IET COMPUT VIS, V13, P165, DOI 10.1049/iet-cvi.2018.5586
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Neto LB, 2017, IEEE T HUM-MACH SYST, V47, P52, DOI 10.1109/THMS.2016.2604367
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Qiu SH, 2018, REMOTE SENS LETT, V9, P237, DOI 10.1080/2150704X.2017.1415473
   Qiu SH, 2017, IEEE J-STARS, V10, P1909, DOI 10.1109/JSTARS.2017.2655098
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song YN, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.05.005
   Tian DP, 2018, SWARM EVOL COMPUT, V41, P49, DOI 10.1016/j.swevo.2018.01.011
   Trivedi I.N., 2018, ADV COMPUTER COMPUTA, P53, DOI [10.1007/978-981-10-3773-3_6, DOI 10.1007/978-981-10-3773-3_6]
   Wang YC, 2016, INT J COMPUT SCI NET, V16, P21
   Xu XL, 2018, SOFT COMPUT, V22, P783, DOI 10.1007/s00500-016-2383-8
   Yang ML, 2019, NEUROCOMPUTING, V330, P48, DOI 10.1016/j.neucom.2018.10.075
   Yu L., 2019, CoRR
   Zhang SM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060631
   Zhang WC, 2015, ISPRS J PHOTOGRAMM, V99, P30, DOI 10.1016/j.isprsjprs.2014.10.007
   Zhang YZ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010027
   Zhao Y, 2020, IEEE T IMAGE PROCESS, V29, P1591, DOI 10.1109/TIP.2019.2942686
NR 38
TC 11
Z9 12
U1 2
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102985
DI 10.1016/j.jvcir.2020.102985
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OM
UT WOS:000613151000005
DA 2024-07-18
ER

PT J
AU Cui, R
   Hua, G
   Wu, JR
AF Cui, Ran
   Hua, Gang
   Wu, Jingran
TI AP-GAN: Predicting skeletal activity to improve early activity
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Early activity recognition; Activity prediction; Skeleton; GAN
ID CNN FEATURES; MODELS
AB Early activity recognition is a classification task before the completion of activity. The study of early activity recognition is beneficial to avoid serious result. Previous studies have focused on extracting effective activity features and modeling for quick and accurate classification. It is challenging because of lack of available information. In order to get a firm basis for judgment, this paper adds an activity prediction module prior to recognition module. The main task of the module is to predict subsequent motions according to observed motions. To avoid motion blur, the structure of GAN (Generative Adversarial Networks) is used to generate the predicted motions. Compared with the traditional deep learning model, dilated neural network has advantages in large-span spatiotemporal feature modeling. The dilated RNN (Recurrent Neural Networks) and CNN (Convolutional Neural Networks) are introduced to the recognition module. In order to make the activity prediction and recognition modules work together, this paper designs and introduces a hard class mining mechanism to improve the learning ability of hard class samples. The proposed method is validated on four skeletal activity datasets and achieves state-of-the-art accuracy.
C1 [Cui, Ran; Hua, Gang] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221008, Jiangsu, Peoples R China.
   [Cui, Ran; Wu, Jingran] China Univ Min & Technol, Xuhai Coll, Xuzhou 221008, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Hua, G (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221008, Jiangsu, Peoples R China.
EM ghua@cumt.edu.cn
RI Cui, Ran/JXL-5894-2024
FU National Natural Science Foundation of China [51574232]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [18KJB510049]; China University IndustryUniversity-Research Innovation
   Fund [2019ITA04013]
FX This work was supported in part by the National Natural Science
   Foundation of China [grant number 51574232], by the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China [grant
   number 18KJB510049] and by the China University
   IndustryUniversity-Research Innovation Fund [grant number 2019ITA04013].
CR Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Chang S., 2017, Dilated Recurrent Neural Networks
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Cui R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043050
   Davis JW, 2006, IMAGE VISION COMPUT, V24, P455, DOI 10.1016/j.imavis.2006.01.012
   Ding ZH, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P610, DOI 10.1109/QRS-C.2017.134
   Du Y., 2015, 3 IAPR AS C PATT REC, DOI DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hussein, 2013, INT JOINT C ART INT
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kolahi SS, 2013, IEEE SYMP COMP COMMU
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liu FY, 2015, PATTERN RECOGN, V48, P2983, DOI 10.1016/j.patcog.2015.04.019
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu T, 2016, IEEE IMAGE PROC, P2871, DOI 10.1109/ICIP.2016.7532884
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Ma M, 2018, PATTERN RECOGN, V76, P506, DOI 10.1016/j.patcog.2017.11.026
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Matsumoto K, 2017, IEEE INT C DAT MIN W
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Streuber S, 2011, EXP BRAIN RES, V214, P273, DOI 10.1007/s00221-011-2830-9
   Subetha T, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Verfaillie K, 2002, VIS COGN, V9, P217, DOI 10.1080/13506280143000403
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 49
TC 6
Z9 6
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102923
DI 10.1016/j.jvcir.2020.102923
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200007
DA 2024-07-18
ER

PT J
AU Babu, GH
   Venkatram, N
AF Babu, G. Harish
   Venkatram, N.
TI A survey on analysis and implementation of state-of-the-art haze removal
   techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Opalescent; Image dehazing; Image restoration; Computational time;
   Machine learning; Deep learning; Hardware implementation
ID UNDERWATER IMAGE-ENHANCEMENT; FAST SINGLE IMAGE; ALGORITHM; VISION; FOG;
   RESTORATION; VISIBILITY; WEATHER; FUSION; CONSTRAINT
AB Haze is a poor-quality state described by the opalescent appearance of the atmosphere which reduces the visibility. It is caused by high concentrations of atmospheric air pollutants, such as dust, smoke and other particles that scatter and absorb sunlight. The poor visibility can result in the failure of multiple computer vision applications such as smart transport systems, image processing, object detection, surveillance etc. One of the major issues in the field of image processing is the restoration of images that are corrupted due to different degradations. Typically, the images or videos captured in the outside environment have low contrast, colour fade and restricted visibility due to suspended particles of the atmosphere that directly influence the image quality. This can cause difficulty in identifying the objects in the captured hazy images or frames. To address this problem, several image dehazing techniques have been developed in the literature, each of which has its own advantages and limitations, but effective image restoration remains a challenging task. In recent times, various learning (Machine learning & Deep learning) based methods greatly condensed the drawbacks of manual design of haze related features and reduces the difficulty in efficient restoration of images with less computational time and cost. The current state-of-the-art methods for haze free images, mainly from the last decade, are thoroughly examined in this survey. Moreover, this paper systematically summarizes the hardware implementations of various haze removal methods in real time. It is with the hope that this current survey acts as a reference for researchers in this scientific area and to provide a direction for future improvements based on current achievements.
C1 [Babu, G. Harish] Koneru Laskshmaiah Educ Fdn, Dept Elect & Commun Engn, Guntur, Andhra Pradesh, India.
   [Venkatram, N.] Koneru Laskshmaiah Educ Fdn, Dept Elect & Comp Engn, Guntur, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Babu, GH (corresponding author), Koneru Laskshmaiah Educ Fdn, Dept Elect & Commun Engn, Guntur, Andhra Pradesh, India.
EM harish.sidhu12@gmail.com; venkatram@kluniversity.in
RI GADE, Dr HARISH BABU/AAU-8202-2020
OI GADE, Dr HARISH BABU/0000-0001-7496-5946
CR Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   Ancuti C. O., 2018, IEEE C COMP VIS PATT
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti CO, 2010, IEEE IMAGE PROC, P3541, DOI 10.1109/ICIP.2010.5651263
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Ancuti Cosmin, 2019, IEEE INT C IM PROC
   [Anonymous], 2015, INT J CURRENT ENG TE
   [Anonymous], 2013, INT J ENG RES TECHNO
   [Anonymous], 2017, P INT C INT SYST MET
   [Anonymous], 2019, IEEE T COMPUT IMAG, DOI DOI 10.1186/S40792-019-0740-4
   [Anonymous], 2012, ASIAN C COMPUTER VIS
   [Anonymous], 2016, SIGNAL IMAGE VIDEO P
   [Anonymous], 2015, INT J MULTIMEDIA UBI
   [Anonymous], 2017, VISUAL COMPUTER
   [Anonymous], 2016, EUR C COMP VIS
   [Anonymous], 2015, J LATEX CLASS FILES
   [Anonymous], 2012, OPEN J APPL SCI
   [Anonymous], 2016, INT J COMPUTER APPL, DOI DOI 10.1002/APP.43974
   Ansari A, 2017, IET SIGNAL PROCESS, V11, P95, DOI 10.1049/iet-spr.2016.0141
   Ansari H, 2019, INT CONF INF COMMUN, P113, DOI [10.1109/icict47744.2019.9001953, 10.1109/ICICT47744.2019.9001953]
   Bai LT, 2015, PROCEDIA ENGINEER, V99, P244, DOI 10.1016/j.proeng.2014.12.532
   Bhusari Titiksha N., 2016, INT J ELECT ELECT DA, V4
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Bisen Lipakshee, INT J MODERN TRENDS
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Cantor A., 1977, IEEE J QUANTUM ELECT, V14, P698
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chacon-Murguia MI, 2012, IEEE T IND ELECTRON, V59, P3286, DOI 10.1109/TIE.2011.2106093
   Chaudhry AM, 2018, IEEE GEOSCI REMOTE S, V15, P932, DOI 10.1109/LGRS.2018.2814016
   Chen BH, 2016, J DISP TECHNOL, V12, P753, DOI 10.1109/JDT.2016.2518646
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chengtao C, 2015, CHIN CONT DECIS CONF, P3964, DOI 10.1109/CCDC.2015.7162616
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   COMM ASSAM, 2018, ACIVS
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   Diaz-Ramirez Victor H., 2017, J REAL TIME IMAGE PR
   Ding Meng, 2013, Science China Information Sciences, V56, DOI 10.1007/s11432-012-4566-y
   Ding S, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2836350
   Ding Yanfu Zhang Li, 2017, IEEE INT C IM PROC
   Eattal R., 2011, ACM TOG, V34, P13
   El Khoury J, 2018, J IMAGING SCI TECHN, V62, DOI 10.2352/J.ImagingSci.Technol.2018.62.1.010503
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Faming Fang, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P219, DOI 10.1109/IASP.2010.5476126
   Fan X, 2016, IEEE T CIRCUIT SYSTE, P1
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   fleuret P., 2014, P EUR C COMP VIS, V17, P32
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Galdran A, 2015, SIAM J IMAGING SCI, V8, P1519, DOI 10.1137/15M1008889
   Ghani ASA, 2017, COMPUT ELECTRON AGR, V141, P181, DOI 10.1016/j.compag.2017.07.021
   GUAN L, 1995, J ELECTRON IMAGING, V4, P407, DOI 10.1117/12.217268
   Guo F, 2016, INFORM PROCESS LETT, V116, P595, DOI 10.1016/j.ipl.2016.04.013
   Guo JM, 2017, IEEE T IMAGE PROCESS, V26, P4217, DOI 10.1109/TIP.2017.2706526
   Halmaoui H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2057, DOI 10.1109/ICCVW.2011.6130501
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   He RJ, 2015, ELECTRON LETT, V51, P1776, DOI 10.1049/el.2015.0707
   He Shengfeng, 2010, IEEE T CIRCUITS SYST, P3541
   He Shengfeng, 2015, IEEE T CIRCUITS SYST
   He X., 2011, FAST ALGORITHM IMAGE, P119
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Huang SY, 2018, IEEE ACCESS, V6, P53907, DOI 10.1109/ACCESS.2018.2871123
   Hung CL, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P581, DOI 10.1109/SNPD.2016.7515962
   Jeong S, 2013, IEEE ICCE, P376, DOI 10.1109/ICCE.2013.6486936
   Jiang G, 2015, J MOD OPTIC, V62, P536, DOI 10.1080/09500340.2014.991358
   Kaufman YJ, 1997, J GEOPHYS RES-ATMOS, V102, P16815, DOI 10.1029/97JD01496
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Kumari A, 2015, AEU-INT J ELECTRON C, V69, P43, DOI 10.1016/j.aeue.2015.09.001
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Li JF, 2015, NEUROCOMPUTING, V156, P1, DOI 10.1016/j.neucom.2015.01.026
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Liao B, 2018, COMPUT GRAPH-UK, V70, P242, DOI 10.1016/j.cag.2017.07.016
   Liu PJ, 2019, IEEE T IMAGE PROCESS, V28, P2212, DOI 10.1109/TIP.2018.2823424
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Liu Z, 2019, IEEE SIGNAL PROC LET, V26, P833, DOI 10.1109/LSP.2019.2910403
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P132
   Lv X, 2010, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL SYMPOSIUM ON STRUCTURAL ENGINEERING, VOL I AND II, P600
   Ma ZL, 2016, NEUROCOMPUTING, V173, P1257, DOI 10.1016/j.neucom.2015.08.084
   Mayuri V., 2016, INT J COMPUTER SCI M, V5, P96
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Meng D, 2015, OPTIK, V126, P3522, DOI 10.1016/j.ijleo.2015.08.220
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173443
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Park Y, 2018, IEEE ACCESS, V6, P10003, DOI 10.1109/ACCESS.2018.2806378
   Poonam Dr, 2017, INT RES J ENG TECHNO, V04
   Protas É, 2019, IEEE T NEUR NET LEAR, V30, P2231, DOI 10.1109/TNNLS.2018.2881194
   Qiaoling Liu, 2011, 2011 International Conference on Multimedia Technology, P467
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Riaz I, 2016, IET COMPUT VIS, V10, P817, DOI 10.1049/iet-cvi.2015.0451
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   Rong Z, 2014, OPTIK, V125, P3064, DOI 10.1016/j.ijleo.2013.12.077
   Sahu V, 2015, INT J RECENT INNOVAT, V3, P85
   Sandeep M., 2014, INT J RES STUD COMPU, V1, P44
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Seivi N. Tamil, 2018, 2018 2 INT C GREEN C
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shiau YH, 2019, IEEE T CIRC SYST VID, V29, P238, DOI 10.1109/TCSVT.2017.2777140
   Shiau YH, 2013, IEEE T CIRC SYST VID, V23, P1369, DOI 10.1109/TCSVT.2013.2243650
   Shrivastava A, 2013, INT J ADV RES COMPUT, V3, P423
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P9595, DOI 10.1007/s11042-017-5321-6
   Singh Dilbag, 2018, ARCH COMPUTATIONAL M
   Singh H, 2017, TRIBOL LETT, V65, DOI 10.1007/s11249-017-0861-5
   Son CH, 2018, IEEE T CIRC SYST VID, V28, P3111, DOI 10.1109/TCSVT.2017.2748150
   Sun W, 2013, OPTIK, V124, P4770, DOI 10.1016/j.ijleo.2013.01.097
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tang X, 2017, IEEE GEOSCI REMOTE S, V14, P242, DOI 10.1109/LGRS.2016.2636819
   Tao SY, 2012, OPT EXPRESS, V20, P16584, DOI 10.1364/OE.20.016584
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Tiwari Ritesh, INT J RECENT TRENDS
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Tupe S., 2017, INT J ADV RES INNOVA, V3
   Vasamsetti S, 2017, OCEAN ENG, V141, P88, DOI 10.1016/j.oceaneng.2017.06.012
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Wang D, 2015, IET COMPUT VIS, V9, P950, DOI 10.1049/iet-cvi.2015.0063
   Wang J., 2015, P 7 INT C INT MULT C, P19
   Wang P, 2019, IEEE T CONSUM ELECTR, V65, P47, DOI 10.1109/TCE.2018.2884794
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   Wang WC, 2017, IEEE-CAA J AUTOMATIC, V4, P410, DOI 10.1109/JAS.2017.7510532
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang XC, 2014, COMPUT VIS IMAGE UND, V119, P102, DOI 10.1016/j.cviu.2013.11.010
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wang Z, 2014, COMPUT ELECTR ENG, V40, P785, DOI 10.1016/j.compeleceng.2013.06.009
   Wang Z, 2018, IET COMPUT VIS, V12, P393, DOI 10.1049/iet-cvi.2017.0318
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Xi Qiao, 2017, Information Processing in Agriculture, V4, P206, DOI 10.1016/j.inpa.2017.06.001
   Xue YG, 2013, COMM COM INF SC, V207, P99
   Yang Y, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2952843
   Yin WY, 2014, IEEE T MULTIMEDIA, V16, P184, DOI 10.1109/TMM.2013.2283468
   Yoon SM, 2016, IMAGING SCI J, V64, P82, DOI 10.1080/13682199.2015.1133010
   You SD, 2013, PROC CVPR IEEE, P1035, DOI 10.1109/CVPR.2013.138
   Yu T, 2015, IET IMAGE PROCESS, V9, P725, DOI 10.1049/iet-ipr.2015.0087
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   Zhang B, 2017, IEEE T VLSI SYST, V25, P1188, DOI 10.1109/TVLSI.2016.2622404
   Zhang J, 2014, J REAL-TIME IMAGE PR, V9, P661, DOI 10.1007/s11554-012-0244-y
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhang Yu, 2018, IEEE SIGNAL PROCESS, V25
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhao XT, 2018, IET IMAGE PROCESS, V12, P88, DOI 10.1049/iet-ipr.2017.0060
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YB, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P248, DOI 10.1109/CISP.2014.7003786
NR 167
TC 24
Z9 24
U1 2
U2 62
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102912
DI 10.1016/j.jveir.2020.102912
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400021
DA 2024-07-18
ER

PT J
AU Cai, H
   Wang, MJ
   Mao, WD
   Gong, ML
AF Cai, Hao
   Wang, Mingjie
   Mao, Wendong
   Gong, Minglun
TI No-reference image sharpness assessment based on discrepancy measures of
   structural degradation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image sharpness assessment; Structural degradation; No-reference;
   Orientation selectivity mechanism
ID BLIND QUALITY ASSESSMENT; ORIENTATION SELECTIVITY; BLUR ASSESSMENT;
   STATISTICS; RESTORATION; VARIABILITY; STRENGTH; DATABASE; PATTERN
AB The discrepancy between an image and its "reblurred" version indicates the extent of blur in the image. This paper presents a novel no-reference image sharpness evaluator leveraging the discrepancy measures of structural degradation in both the spatial and wavelet domains. Specifically, local structural degradation of an input image is characterized by the discrepancy measures of orientation selectivity-based visual patterns and log-Gabor filter responses between the image and its corresponding reblurred version respectively. Considering the influence of viewing distance on image quality, the global sharpness discrepancy is measured through inter-resolution self-similarities. Finally, the computed discrepancies are utilized as sharpness-aware features and then a support vector regressor is employed to map the feature vectors into quality scores. The performance of the proposed method is evaluated on six public image quality databases, including two real blurred image databases. Experimental results demonstrate that our proposed method achieves state-of-the-art performances across all these databases. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Cai, Hao; Wang, Mingjie; Mao, Wendong; Gong, Minglun] Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
   [Cai, Hao; Wang, Mingjie; Gong, Minglun] Univ Guelph, Sch Comp Sci, Guelph, ON N1G 2W1, Canada.
   [Cai, Hao] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 1H9, Canada.
C3 Memorial University Newfoundland; University of Guelph; University of
   Alberta
RP Wang, MJ (corresponding author), Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
EM mingjiew@mun.ca
RI Cai, Hao/HPH-5544-2023; wang, ming/HPC-6329-2023; Gong,
   Minglun/AAU-3103-2020
OI Gong, Minglun/0000-0001-5820-5381
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council of Canada (NSERC).
CR ALBRIGHT TD, 1984, J NEUROPHYSIOL, V52, P1106, DOI 10.1152/jn.1984.52.6.1106
   [Anonymous], 2015, J INF HIDING MULTIME
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Barros W, 2018, J VIS COMMUN IMAGE R, V55, P363, DOI 10.1016/j.jvcir.2018.06.018
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Cai H, 2019, J VIS COMMUN IMAGE R, V61, P250, DOI 10.1016/j.jvcir.2019.04.006
   Cai H, 2019, SIGNAL PROCESS-IMAGE, V71, P88, DOI 10.1016/j.image.2018.11.003
   CAMPBELL FW, 1966, J PHYSIOL-LONDON, V187, P437, DOI 10.1113/jphysiol.1966.sp008101
   Chaurasia V, 2016, J VIS COMMUN IMAGE R, V41, P87, DOI 10.1016/j.jvcir.2016.09.008
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Dhara BC, 2012, J VIS COMMUN IMAGE R, V23, P313, DOI 10.1016/j.jvcir.2011.11.005
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Field DJ, 1997, VISION RES, V37, P3367, DOI 10.1016/S0042-6989(97)00181-8
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gu K, 2020, IEEE T BROADCAST, V66, P127, DOI 10.1109/TBC.2019.2906768
   Gu K, 2015, IEEE T BROADCAST, V61, P520, DOI 10.1109/TBC.2015.2459851
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Hansel D, 2012, J NEUROSCI, V32, P4049, DOI 10.1523/JNEUROSCI.6284-11.2012
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hosseini MS, 2019, IEEE T IMAGE PROCESS, V28, P4510, DOI 10.1109/TIP.2019.2906582
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kim J, 2019, IEEE T NEUR NET LEAR, V30, P11, DOI 10.1109/TNNLS.2018.2829819
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee S, 2012, SIGNAL PROCESS-IMAGE, V27, P31, DOI 10.1016/j.image.2011.08.002
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu LX, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115654
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2017, IEEE IMAGE PROC, P3150, DOI 10.1109/ICIP.2017.8296863
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Wu JJ, 2015, IEEE T IMAGE PROCESS, V24, P4602, DOI 10.1109/TIP.2015.2460467
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Xue HZ, 2019, J VIS COMMUN IMAGE R, V59, P204, DOI 10.1016/j.jvcir.2019.01.014
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Yan B, 2019, IEEE T MULTIMEDIA, V21, P2603, DOI 10.1109/TMM.2019.2904879
   Yang S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1383, DOI 10.1145/3343031.3350990
   Yu SD, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176632
   Yu SD, 2017, LECT NOTES COMPUT SC, V10116, P50, DOI 10.1007/978-3-319-54407-6_4
   Yuan SY, 2019, J VIS COMMUN IMAGE R, V59, P33, DOI 10.1016/j.jvcir.2018.12.043
   Yue GH, 2017, J VIS COMMUN IMAGE R, V49, P382, DOI 10.1016/j.jvcir.2017.09.011
   Zhan YB, 2018, IEEE T MULTIMEDIA, V20, P1796, DOI 10.1109/TMM.2017.2780770
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang YL, 2013, J THERM SCI, V22, P1, DOI 10.1007/s11630-013-0584-3
   Zhao PP, 2015, IEICE T INF SYST, VE98D, P1613, DOI 10.1587/transinf.2015EDL8041
NR 77
TC 6
Z9 6
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102861
DI 10.1016/j.jvcir.2020.102861
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000002
DA 2024-07-18
ER

PT J
AU Condori, MAT
   Cappabianco, FAM
   Falcao, AX
   Miranda, PAV
AF Condori, Marcos A. T.
   Cappabianco, Fabio A. M.
   Falcao, Alexandre X.
   Miranda, Paulo A., V
TI An extension of the differential image foresting transform and its
   application to superpixel generation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image foresting transform; Superpixels; Differential image foresting
   transform
ID OPTIMUM-PATH FOREST; SEGMENTATION; SKELETONS
AB The Image Foresting Transform (IFT) is a graph-based framework to develop image operators based on optimum connectivity between a root set and the remaining nodes, according to a given path-cost function. Its applications involve a variety of tasks, such as segmentation, boundary tracking, skeletonization, filtering, among others. The Differential Image Foresting Transform (DIFT) allows multiple IFT executions for different root sets and a same monotonically incremental path-cost function, making the processing time proportional to the number of modified nodes. In this paper, we extend the DIFT algorithm for non monotonically incremental functions with root-based increases. This proposed extension, called Generalized DIFT (GDIFT), has been successfully used as the core part of some modern superpixels methods with state-of-the-art results. Experimental results show considerable efficiency gains over the sequential flow of IFTs for the generation of superpixels, also avoiding inconsistencies in image segmentation, which could occur with the regular DIFT algorithm. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Condori, Marcos A. T.; Miranda, Paulo A., V] Univ Sao Paulo, Inst Math & Stat, Sao Paulo, SP, Brazil.
   [Cappabianco, Fabio A. M.] Univ Fed Sao Paulo, Inst Ciencia & Tecnol, Sao Jose Dos Campos, SP, Brazil.
   [Falcao, Alexandre X.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
C3 Universidade de Sao Paulo; Universidade Federal de Sao Paulo (UNIFESP);
   Universidade Estadual de Campinas
RP Condori, MAT; Miranda, PAV (corresponding author), Univ Sao Paulo, Inst Math & Stat, Sao Paulo, SP, Brazil.
EM mtejadac@vision.ime.usp.br; cappabianco@unifesp.br;
   afalcao@ic.unicamp.br; pmiranda@vision.ime.usp.br
RI Miranda, Paulo A V/C-2342-2012; Falcão, Alexandre X/F-8361-2012
OI Falcão, Alexandre X/0000-0002-2914-5380; Tejada Condori, Marcos
   Ademir/0000-0002-4737-4240
FU CNPq [308985/2015-0, 313554/2018-8, 486083/2013-6, 303808/2018-7,
   486988/2013-9, 166631/2018-3, 465446/2014-0, FINEP 1266/13]; Sao Paulo
   Research Foundation (FAPESP) [2011/50761-2, 2016/21591-5, 2014/50937-1];
   NAP eScience - PRP - USP; Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior (CAPES) [001, 88887.136422/2017-00]; FAPESP Thematic
   Research Project [2014/12236-1]
FX The authors would like to thank CNPq (308985/2015-0, 313554/2018-8,
   486083/2013-6, 303808/2018-7, 486988/2013-9, 166631/2018-3,
   465446/2014-0, FINEP 1266/13), Sao Paulo Research Foundation (FAPESP
   2011/50761-2, 2016/21591-5, 2014/50937-1), NAP eScience - PRP - USP, and
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES) -
   Finance Code 001 for funding (88887.136422/2017-00). This research is
   also part of the FAPESP Thematic Research Project (proc. 2014/12236-1).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexandre EB, 2015, SIBGRAPI, P337, DOI 10.1109/SIBGRAPI.2015.20
   [Anonymous], THESIS
   Belem Felipe, 2018, P IB C PATT REC, P334
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cappabianco FAM, 2012, COMPUT VIS IMAGE UND, V116, P1047, DOI 10.1016/j.cviu.2012.06.002
   Leon LMC, 2017, SIBGRAPI, P79, DOI 10.1109/SIBGRAPI.2017.17
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Ciesielski KC, 2018, J MATH IMAGING VIS, V60, P1025, DOI 10.1007/s10851-018-0793-1
   Condori MAT, 2017, SIBGRAPI, P7, DOI 10.1109/SIBGRAPI.2017.8
   Condori MAT, 2017, LECT NOTES COMPUT SC, V10225, P95, DOI 10.1007/978-3-319-57240-6_8
   Duan L, 2015, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2015.7298931
   Falcao A, 2017, COMPUT VIS PATT REC, P43, DOI 10.1016/B978-0-08-101291-8.00003-1
   Falcao AX, 2004, IEEE T MED IMAGING, V23, P1100, DOI 10.1109/TMI.2004.829335
   Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076
   Falcao AX, 2001, PROC SPIE, V4322, P468, DOI 10.1117/12.431120
   Falcao AX, 2002, PATTERN RECOGN, V35, P1571, DOI 10.1016/S0031-3203(01)00148-0
   Falcao AX, 2000, IEEE T MED IMAGING, V19, P55, DOI 10.1109/42.832960
   FRIEZE A, 1977, OPER RES QUART, V28, P339, DOI 10.2307/3009189
   Galvao FL, 2018, SIBGRAPI, P408, DOI 10.1109/SIBGRAPI.2018.00059
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Lotufo RA, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P146, DOI 10.1109/SIBGRA.2002.1167137
   Machairas V, 2015, IEEE T IMAGE PROCESS, V24, P3707, DOI 10.1109/TIP.2015.2451011
   Mansilla Lucy A. C., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P147, DOI 10.1109/SIBGRAPI.2013.29
   Mansilla LAC, 2016, IEEE IMAGE PROC, P2554, DOI 10.1109/ICIP.2016.7532820
   Mansilla LAC, 2013, INT CONF DIGIT SIG
   Mansilla LAC, 2013, LECT NOTES COMPUT SC, V8047, P572, DOI 10.1007/978-3-642-40261-6_69
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Miranda PAV, 2014, IEEE T IMAGE PROCESS, V23, P389, DOI 10.1109/TIP.2013.2288867
   Miranda PAV, 2012, IEEE T IMAGE PROCESS, V21, P3042, DOI 10.1109/TIP.2012.2188034
   Miranda PAV, 2009, J MATH IMAGING VIS, V35, P128, DOI 10.1007/s10851-009-0159-9
   Tavares ACM, 2017, LECT NOTES COMPUT SC, V10225, P119, DOI 10.1007/978-3-319-57240-6_10
   Perkins L., 2010, Proceedings of AIIDE, P168
   Rocha LM, 2009, INT J IMAG SYST TECH, V19, P50, DOI 10.1002/ima.20191
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Silva DJ, 2016, IEEE IMAGE PROC, P3738, DOI 10.1109/ICIP.2016.7533058
   Strand R, 2013, COMPUT VIS IMAGE UND, V117, P429, DOI 10.1016/j.cviu.2012.10.011
   Vargas-Muñoz JE, 2019, IEEE T IMAGE PROCESS, V28, P3477, DOI 10.1109/TIP.2019.2897941
NR 39
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102748
DI 10.1016/j.jvcir.2019.102748
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900030
DA 2024-07-18
ER

PT J
AU Li, YG
   Zhang, MY
   Hu, L
   Li, J
   Wang, DQ
AF Li, Yeguang
   Zhang, Mingyuan
   Hu, Liang
   Li, Jun
   Wang, Deqing
TI Candidate region correlation for video action detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Action detection; Region correlation; Self-attention
   mechanism
ID RECOGNITION
AB The rapid development of deep learning has prompted the development of video action detection technology. However, the accuracy of current video action detection algorithms can be improved further. Previous work has improved feature extraction by optimizing the network structure. In addition, the features of the candidate regions have been optimized by changing the representation of the regions. Although these methods have achieved promising results, they fail to consider the correlation among different candidate regions, generating uninformative (even redundant) candidate regions, and thus usually decrease the detection performance in practice. To address this problem, in this paper we propose a self attention mechanism for candidate regions, which can help pursue the most informative regions. We obtain the region correlation by simultaneously determining the spatial and temporal correlation among different candidate regions. In addition, we focus on how to apply the correlation to optimize the original candidate region features and improve video action detection accuracy. The experimental results show the promising improvement achieved by our method over the state-of-the-art solutions. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Yeguang; Hu, Liang] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Mingyuan; Li, Jun; Wang, Deqing] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Li, Yeguang] Changchun Univ Technol, Sch Econ & Management, Jilin, Jilin, Peoples R China.
C3 Jilin University; Beihang University
RP Wang, DQ (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
EM dqwang@buaa.edu.cn
RI Li, Jun/HJH-3122-2023
CR [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2007, INT S NEUR NETW
   [Anonymous], 2014, ECCV WORKSH
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   Diba A., 2018, EUR C COMP VIS
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao Z., 2019, ASS ADV ARTIFICIAL I
   Gleason J., 2019, 2019 IEEE WINT C APP
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hou R., 2017, BRIT MACH VIS C
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang J., 2017, ARXIV170607251
   Huang L, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107317
   Huang Yupan, 2019, ARXIV190407442
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li JW, 2019, LECT NOTES COMPUT SC, V11562, P3, DOI 10.1007/978-3-030-25543-5_1
   Li J, 2020, IEEE T MULTIMEDIA, V22, P2990, DOI 10.1109/TMM.2020.2965434
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu J, 2014, ACTION RECOGNITION L
   Luo Z., 2017, ARXIV1701018212
   Ma ZG, 2014, INT J COMPUT VISION, V109, P60, DOI 10.1007/s11263-014-0717-5
   Oneata D., 2013, LEAR SUBMISSION THUM
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ray Jamie, 2017, ABS171111248 CORR
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richard A, 2018, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2018.00627
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K, 2017, IEEE I CONF COMP VIS, P696, DOI 10.1109/ICCV.2017.82
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Limin., 2014, THUMOS14 Action Recognition Challenge
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie D, 2020, IEEE T IMAGE PROCESS, V29, P3626, DOI 10.1109/TIP.2020.2963957
   Xie Saining, 2017, ARXIV171204851, V1, P5
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu XL, 2020, IEEE T IND INFORM, V16, P6172, DOI 10.1109/TII.2019.2959258
   Yang K., 2017, ARXIV170803280
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 49
TC 0
Z9 0
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102818
DI 10.1016/j.jvcir.2020.102818
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400016
DA 2024-07-18
ER

PT J
AU Liu, C
   Wang, XF
AF Liu, Cheng
   Wang, Xiaofang
TI Quality-related English text classification based on recurrent neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Recurrent neural network; Text categorization; English categorization;
   Feature Word Categorization
AB With the rapid development of artificial intelligence technology, text categorization technology is becoming more and more mature. However, text categorization in real situations still faces various unconstrained conditions. English text is an important part of text information, it is also an important way for people to get information from abroad. How can everyone get the desired content from the massive data quickly and accurately, it has become a hot issue in current research. This paper improves the current text categorization algorithm based on English quality-related text categorization. The design and implementation of text categorization system are illustrated with an example of English quality related text categorization system, complete the research work of text categorization algorithm. The core work of this paper is to mine, classify and analyze large amounts of data in English text by using the method of combining cyclic neural network with quality. Finally, the essential features of high quality English texts are obtained. Traditional English text categorization algorithm if the amount of training data is large, it is easy to show some defects such as unclear feature items. In view of these problems, in order to improve the accuracy and flexibility of English text categorization, this paper proposes a quality related English text categorization method based on cyclic neural network. A mechanism combining attention is proposed to improve the problem of label disorder and make the structure of the model more flexible. The model proposed in this paper is compared and optimized. Experiments show that the accuracy of neural text classification based on quality classification can reach about 96%. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Cheng; Wang, Xiaofang] Jiangxi Univ Tradit Chinese Med, Sch Humanities, Nanchang, Jiangxi, Peoples R China.
C3 Jiangxi University of Traditional Chinese Medicine
RP Wang, XF (corresponding author), Jiangxi Univ Tradit Chinese Med, Sch Humanities, Nanchang, Jiangxi, Peoples R China.
EM 20040805@jxutcm.edu.cn
FU Humanities and Social Sciences Research Project for Jiangxi Colleges and
   Universities [YY162002]
FX This work was supported by the Humanities and Social Sciences Research
   Project for Jiangxi Colleges and Universities (No. YY162002).
CR [Anonymous], 2016, IOP C SER MAT SCI EN, V105
   Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Chen JY, 2020, NEURAL COMPUT APPL, V32, P10809, DOI 10.1007/s00521-018-3442-0
   Cheng PM, 2017, J DIGIT IMAGING, V30, P234, DOI 10.1007/s10278-016-9929-2
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Du Jian-hai, 2017, J COMPUTAT SCI
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Garro BA, 2016, APPL SOFT COMPUT, V38, P548, DOI 10.1016/j.asoc.2015.10.002
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang ML, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3052770
   Hughes M, 2017, STUD HEALTH TECHNOL, V235, P246, DOI 10.3233/978-1-61499-753-5-246
   Lahav O, 1996, MON NOT R ASTRON SOC, V283, P207, DOI 10.1093/mnras/283.1.207
   Luo Y, 2017, J BIOMED INFORM, V72, P85, DOI 10.1016/j.jbi.2017.07.006
   Ma L., 2017, J APPL REMOTE SENS, V11, P1
   Maksimenko VA, 2018, COMPLEXITY, DOI 10.1155/2018/9385947
   Mengjia X., 2017, PLOS COMPUT BIOL, V13
   Saloot MA, 2016, ARTIF INTELL REV, V46, P113, DOI 10.1007/s10462-016-9458-x
   Schirmer M, 2009, J GLACIOL, V55, P761, DOI 10.3189/002214309790152429
   Shoji D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26200-2
   Vinodhini G, 2016, J KING SAUD UNIV-COM, V28, P2, DOI 10.1016/j.jksuci.2014.03.024
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200491
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zhang MM, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042607
   Zhong YF, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.025006
NR 28
TC 8
Z9 8
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102724
DI 10.1016/j.jvcir.2019.102724
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900006
DA 2024-07-18
ER

PT J
AU Wang, HK
   Yu, L
   Yin, HB
   Li, TS
   Wang, SW
AF Wang, Hongkui
   Yu, Li
   Yin, Haibing
   Li, Tiansong
   Wang, Shengwei
TI An improved DCT-based JND estimation model considering multiple masking
   effects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DCT-based JND estimation model; Contrast masking; Disorderly concealment
   effect
ID JUST-NOTICEABLE-DISTORTION; DIFFERENCE; IMAGE; PROFILE; SCALE; EDGE
AB The just noticeable distortion (JND) in the contour and orderly regions is easy to be overestimated and that in the disorderly areas is usually underestimated. In order to estimate the JND threshold more accurately, this paper proposes an improved DCT-based JND estimation model considering multiple masking effects properly. The contributions of this paper are characterized by twofold. On the one hand, a mean absolute difference based (MAD-based) block classification method is developed at first to classify image blocks into plain, contour and texture types accurately and quickly. And the JND model for contrast masking effect (CM-JND) is constructed as a modulation factor based on the MAD of each block. On the other hand, we propose a distance-based disorder evaluation metric to measure the disorder intensity in block level. Then, the JND model for the disorderly concealment effect (DC-JND) is proposed based on our psychological experiment. Finally, the total JND estimation threshold is modeled by fusing the spatial contrast sensitivity function, the luminance adaptation effect, the CM and DC effects. Experimental results show that the proposed DCT-based JND estimation model outperforms existing models in performance and complexity. Specifically, the proposed model shows more tolerance for distortions, lower computational complexity with better perceptual quality than other JND models. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wang, Hongkui; Yu, Li; Li, Tiansong; Wang, Shengwei] Huazhong Univ Sci & Technol, Sch Electron Inf & Commun, Wuhan, Peoples R China.
   [Yin, Haibing] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou, Peoples R China.
C3 Huazhong University of Science & Technology; Hangzhou Dianzi University
RP Yu, L (corresponding author), Huazhong Univ Sci & Technol, Sch Electron Inf & Commun, Wuhan, Peoples R China.
EM hkwang@hust.edu.cn; hustlyu@hust.edu.cn; tiansongli@hust.edu.cn;
   kadinwang@hust.edu.cn
RI Wang, HK W/GQQ-8378-2022
FU NSFC [61871437, 61972123, 61572449]; Natural Science Foundation of Hubei
   Province of China [2019CFA022]; Key RD projects [2018YFC0830106]
FX This work was supported in part by the NSFC under Grant 61871437,
   61972123, 61572449; in part by the Natural Science Foundation of Hubei
   Province of China under Grant 2019CFA022; and the Key R&D projects under
   Grant 2018YFC0830106.
CR Ahumada A.J., 1992, HUMAN VISION VISUAL
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P3343, DOI 10.1109/TIP.2016.2568459
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P3227, DOI 10.1109/TIP.2014.2327808
   Bross B., 2018, P JOINT VIDEO EXPL T
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang C., 2017, SIGN INF PROC ASS SU
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Ma L, 2011, SIGNAL PROCESS-IMAGE, V26, P162, DOI 10.1016/j.image.2011.02.002
   Macknik SL, 1998, NAT NEUROSCI, V1, P144, DOI 10.1038/393
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Naccari M, 2011, IEEE T CIRC SYST VID, V21, P766, DOI 10.1109/TCSVT.2011.2130430
   Netravali A.N., 1988, DIGITAL PICTURES REP
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Ritschel T., 2008, ACM SIGGRAPH
   Shen D.F., 2003, P IEEE
   Wang HG, 2016, IEEE IMAGE PROC, P1509, DOI 10.1109/ICIP.2016.7532610
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Watson A.B., 1993, SID INT S, V24, P946
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wolfgang R., 2002, P IEEE, V87, P1108
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P4892, DOI 10.1109/TIP.2013.2279934
   Yang KF, 2014, IEEE T IMAGE PROCESS, V23, P5020, DOI 10.1109/TIP.2014.2361210
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
NR 41
TC 8
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102850
DI 10.1016/j.jvcir.2020.102850
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400001
DA 2024-07-18
ER

PT J
AU Wang, W
   Zhu, LQ
AF Wang, Wei
   Zhu, Liqiang
TI Structured feature sparsity training for convolutional neural network
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; CNN compression; Structured sparsity;
   Pruning criterion
AB Convolutional neural networks (CNNs) with large model size and computing operations are difficult to be deployed on embedded systems, such as smartphones or AI cameras. In this paper, we propose a novel structured pruning method, termed the structured feature sparsity training (SFST), to speed up the inference process and reduce the memory usage of CNNs. Unlike other existing pruning methods, which require multiple iterations of pruning and retraining to ensure stable performance, SFST only needs to fine-tune the pretrained model with additional regularization on the less important features and then prune them, no multiple pruning and retraining needed. SFST can be deployed to a variety of modern CNN architectures including VGGNet, ResNet and MobileNetv2. Experimental results on CIFAR, SVHN, ImageNet and MSTAR benchmark dataset demonstrate the effectiveness of our scheme, which achieves superior performance over the state-of-the-art methods.
C1 [Wang, Wei; Zhu, Liqiang] Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
   [Wang, Wei; Zhu, Liqiang] Beijing Jiaotong Univ, Key Lab Vehicle Adv Mfg Measuring & Control Techn, Minist Educ, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Zhu, LQ (corresponding author), Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
EM 16116336@bjtu.edu.cn; lqzhu@bjtu.edu.cn
RI Zhu, Li/JTT-9093-2023; xu, xuan/KHX-8344-2024; zhou, you/KBC-3567-2024;
   Huang, Liping/KIB-4430-2024; Zhao, YuHan/KIE-0813-2024
OI Wang, Wei/0000-0001-8855-2819
FU National Key Research and Development Program of China [2016YFB1200401]
FX This work is supported by the National Key Research and Development
   Program of China under Grant 2016YFB1200401.
CR [Anonymous], 2015, ARXIV150202551
   [Anonymous], 2016, NETWORK TRIMMING DAT
   [Anonymous], 2014, INT C LEARN REPR ICL
   [Anonymous], 2014, P BMVC
   [Anonymous], 2015, CoRR
   [Anonymous], 2018, INVERTED RESIDUALS L
   Ba LJ, 2014, ADV NEUR IN, V27
   Baker C, 2017, TLS-TIMES LIT SUPPL, P5
   Chen MJ, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102678
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Courbariaux M, 2015, ADV NEUR IN, V28
   Cun Y.L., 1989, Advances in neural information processing systems, V2, P598
   Denton E, 2014, ADV NEUR IN, V27
   Gong Y., 2014, COMPRESSING DEEP CON
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hashemi S., 2016, ARXIV161203940V1
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   Hassibi B., 1993, P ADV NEUR INF PROC, P164
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, MOBILENETS EFFICIENT
   Hubara I, 2018, J MACH LEARN RES, V18
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Keydel ER, 1996, P SOC PHOTO-OPT INS, V2757, P228, DOI 10.1117/12.242059
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280
   Li H., 2017, P ICLR
   Li Y, 2018, SIGNAL PROCESS-IMAGE, V64, P21, DOI 10.1016/j.image.2018.01.012
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo JH, 2019, IEEE T PATTERN ANAL, V41, P2525, DOI 10.1109/TPAMI.2018.2858232
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Malmgren-Hansen D, 2017, IEEE GEOSCI REMOTE S, V14, P1484, DOI 10.1109/LGRS.2017.2717486
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Pei JF, 2018, IEEE T GEOSCI REMOTE, V56, P2196, DOI 10.1109/TGRS.2017.2776357
   Real E., 2017, Large-scale evolution of image classifiers, V70, P2902
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen CC, 2019, AAAI CONF ARTIF INTE, P3068
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tisdall EKM, 2014, STUD CHILDHOOD YOUTH, P1
   Wang W, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102582
   Wang YH, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102647
   Wen W, 2016, ADV NEUR IN, V29
   Wen W, 2017, IEEE I CONF COMP VIS, P658, DOI 10.1109/ICCV.2017.78
   Ye JW, 2019, PROC CVPR IEEE, P2824, DOI 10.1109/CVPR.2019.00294
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhong CL, 2019, IEEE GEOSCI REMOTE S, V16, P412, DOI 10.1109/LGRS.2018.2876378
   Zhou K, 2016, DESTECH TRANS COMP
   Zoph B., 2017, 5 INT C LEARN REPR
NR 52
TC 7
Z9 7
U1 4
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102867
DI 10.1016/j.jvcir.2020.102867
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000001
DA 2024-07-18
ER

PT J
AU Zhao, F
   Huang, SW
   Long, RY
   Zhang, TT
   Na, SG
AF Zhao, Feng
   Huang, Shiwang
   Long, Renyan
   Zhang, Tiantian
   Na, Sang-Gyun
TI Perceptual visual quality assessment using deeply-learned gaze shifting
   kernel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Human visual system; SSIM
ID IMAGE; INFORMATION
AB Image quality assessment (IQA) is a useful technique in computer vision and machine intelligence. It is widely applied in image retrieval, image clustering and image recognition. IQA algorithms generally rely on human visual system (HVS), which can reflect how human perceive salient regions in the image. In this paper, we leverage both low-level features and high-level semantic features to select salient regions, which will be concatenated to form GSPs by the designed saliency-constraint algorithm to mimic human visual system. We design an enhanced IQA index based on the GSPs to calculate the simialrity between reference image and test image to achieve image quality assessment. Experiments demonstrate that our IQA method can achieve satisfactory performance. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Zhao, Feng; Long, Renyan; Zhang, Tiantian; Na, Sang-Gyun] Wonkwang Univ, Dept Business Adm, 460 Iksandae Ro, Iksan, Jeonbuk, South Korea.
   [Huang, Shiwang] Quanzhou Normal Univ, Engn Res Ctr Cloud Comp & Internet Things & E Com, 398 Donghai St, Quanzhou 362000, Peoples R China.
   [Long, Renyan] Xinyu Univ, Sch Econ & Management, 2666 Yangguang St, Xinyu 338004, Peoples R China.
C3 Wonkwang University; Quanzhou Normal University; Xinyu University
RP Na, SG (corresponding author), Wonkwang Univ, Dept Business Adm, 460 Iksandae Ro, Iksan, Jeonbuk, South Korea.
EM nsghy@wku.ac.kr
RI zhang, tiantian/AIE-2834-2022
FU Wonkwang University
FX This paper performance was supported by Wonkwang University in 2019.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 41 EUR WORKSH VIS IN
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dhar S., 2011, P CVPR
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Larson E C, 2009, Categorical Image Quality (CSIQ) database [EB/OL]
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Mai L., 2016, P CVPR
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Nishiyama M., 2009, P 17 ACM INT C MULTI, P669
   Nishiyama M, 2011, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2011.5995539
   Sheikh H.R., 2004, IMAGE AND VIDEO QUAL
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xin Lu, 2014, RAPID RATING PICTORI
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhen L, 2020, IEEE T SYST MAN CY-S, V50, P771, DOI 10.1109/TSMC.2017.2690444
NR 25
TC 1
Z9 1
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102701
DI 10.1016/j.jvcir.2019.102701
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900001
DA 2024-07-18
ER

PT J
AU Hou, GJ
   Li, JM
   Wang, GD
   Yang, H
   Huang, BX
   Pan, ZK
AF Hou, Guojia
   Li, Jingming
   Wang, Guodong
   Yang, Huan
   Huang, Baoxiang
   Pan, Zhenkuan
TI A novel dark channel prior guided variational framework for underwater
   image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image restoration; Dehazing and denoising; UTV; ADMM; UDCP
ID ENHANCEMENT; CONTRAST; TEXTURE; MODEL; RETINEX
AB Image captured underwater often suffers from low contrast, color distortion and noise problems, which is caused by absorbing and scattering before the light reaches the camera when traveling through water. Underwater image enhancement and restoration from a single image is known to be an ill-posed problem. To overcome these limitations, we establish an underwater total variation (UTV) model relying on underwater dark channel prior (UDCP), in which UDCP is used to estimate the transmission map. We design the data item and smooth item of the unified variational model based on the underwater image formation model. We further employ the alternating direction method of multipliers (ADMM) to accelerate the solving procedure. Numerical experiential results demonstrate that our underwater variational method obtains a good outcome on dehazing and denoising. Furthermore, compared with several other state-of-the-art algorithms, the proposed approach achieves better visual quality, which is illustrated by examples and statistics. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hou, Guojia; Li, Jingming; Wang, Guodong; Yang, Huan; Huang, Baoxiang; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Hou, GJ; Pan, ZK (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
EM hgjouc@126.com; zkpan@126.com
OI Baoxiang, Huang/0000-0002-0380-419X; Hou, Guojia/0000-0001-6509-6259
FU National Natural Science Foundation of China [61901240]; China
   Scholarship Council [201908370002]; Natural Science Foundation of
   Shandong Province, China [ZR2019BF042, ZR2019MF050]; China Postdoctoral
   Science Foundation [2017M612204]
FX The research work is partially supported by National Natural Science
   Foundation of China (No. 61901240), China Scholarship Council (No.
   201908370002), the Natural Science Foundation of Shandong Province,
   China (No. ZR2019BF042, ZR2019MF050), and the China Postdoctoral Science
   Foundation (No. 2017M612204). The first author also would like to thank
   Xin Zhao, Xinjie Li, and Jun Xie et al. as the observers for subjective
   test and Miao Yang for providing the source code of the UCIQE metric.
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], [No title captured]
   [Anonymous], P CAR M MAR BREST FR
   [Anonymous], UNDERWATER IMAGE ENH
   Boudhane M, 2016, J VIS COMMUN IMAGE R, V39, P226, DOI 10.1016/j.jvcir.2016.05.017
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Chuang MC, 2016, IEEE T IMAGE PROCESS, V25, P1862, DOI 10.1109/TIP.2016.2535342
   Ding YC, 2017, IEEE ACM T COMPUT BI, V14, P1366, DOI 10.1109/TCBB.2016.2591520
   Duan JM, 2015, J GLOBAL OPTIM, V62, P853, DOI 10.1007/s10898-015-0290-7
   Fang FM, 2014, SIAM J IMAGING SCI, V7, P969, DOI 10.1137/130919696
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Goldstein T, 2014, SIAM J IMAGING SCI, V7, P1588, DOI 10.1137/120896219
   Guojia Hou, 2017, IAENG International Journal of Computer Science, V44, P445
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hong DF, 2016, NEUROCOMPUTING, V174, P999, DOI 10.1016/j.neucom.2015.10.031
   Hong DF, 2015, NEUROCOMPUTING, V151, P511, DOI 10.1016/j.neucom.2014.09.013
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Hou GJ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051207
   Hou GJ, 2018, IET IMAGE PROCESS, V12, P292, DOI 10.1049/iet-ipr.2017.0359
   Hu HF, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2791517
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Ko S, 2017, SIGNAL PROCESS-IMAGE, V58, P99, DOI 10.1016/j.image.2017.06.016
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Liang JW, 2015, J MATH IMAGING VIS, V52, P345, DOI 10.1007/s10851-015-0568-x
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Lu JG, 2017, MULTIMED TOOLS APPL, V76, P10991, DOI 10.1007/s11042-016-3462-7
   Lu WQ, 2016, MATH METHOD APPL SCI, V39, P4208, DOI 10.1002/mma.3858
   Luan X, 2014, MAR TECHNOL SOC J, V48, P57, DOI 10.4031/MTSJ.48.3.8
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Nnolim UA, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023009
   Nomura K, 2018, IEEE SIGNAL PROC LET, V25, P893, DOI 10.1109/LSP.2018.2831630
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Pu YF, 2006, INT CONF SIGN PROCES, P1002
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tan L, 2018, APPL MATH MODEL, V61, P280, DOI 10.1016/j.apm.2018.04.017
   Wang GD, 2017, MULTIMED TOOLS APPL, V76, P24515, DOI 10.1007/s11042-016-4136-1
   Wang J, 2015, PHYS REV A, V92, DOI 10.1103/PhysRevA.92.033848
   Wang N, 2016, 2016 INTERNATIONAL CONFERENCE ON APPLIED MECHANICS, ELECTRONICS AND MECHATRONICS ENGINEERING (AMEME 2016), P116
   Wang N, 2017, IEEE ACCESS, V5, P18941, DOI 10.1109/ACCESS.2017.2753796
   Wang SQ, 2016, IEEE T MULTIMEDIA, V18, P219, DOI 10.1109/TMM.2015.2510326
   Wang Y, 2018, IEEE T CIRCUITS-I, V65, P992, DOI 10.1109/TCSI.2017.2751671
   Wang Z, 2018, IET COMPUT VIS, V12, P393, DOI 10.1049/iet-cvi.2017.0318
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Xu HT, 2014, IEEE T MULTIMEDIA, V16, P68, DOI 10.1109/TMM.2013.2283453
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zeng K, 2013, CONF REC ASILOMAR C, P1351, DOI 10.1109/ACSSC.2013.6810514
   Zhang MH, 2018, IEEE ACCESS, V6, P58634, DOI 10.1109/ACCESS.2018.2875344
   Zhang R, 2017, SIGNAL PROCESS-IMAGE, V58, P270, DOI 10.1016/j.image.2017.08.008
NR 62
TC 67
Z9 68
U1 7
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102732
DI 10.1016/j.jvcir.2019.102732
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200011
DA 2024-07-18
ER

PT J
AU Chen, MJ
   Han, XF
   Zhang, H
   Lin, GJ
   Kamruzzaman, MM
AF Chen, Mingju
   Han, Xiaofeng
   Zhang, Hua
   Lin, Guojun
   Kamruzzaman, M. M.
TI Quality-guided key frames selection from video stream based on object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; Key frame; Object detection; SIFT
   characteristics; Quality assessment model
ID KEYFRAME EXTRACTION; DESIGN; STATE
AB Object detection technique is widely applied in modern intelligent systems, such as pedestrian tracking, video surveillance. Key frames selection aims to select more informative frames and reduce amount of redundant information frames. Traditional methods leveraged SIFT feature, which have high key frame selection error rate. In this paper, we propose a novel key frames selection method based on object detection and image quality. Specifically, we first leverage object detector to detect object, such as pedestrian, vehicles. Then, each training frame will be assigned with a quality score, where frames contain objects have high quality score. Afterwards, we leverage CNN based AlexNet architecture for deep feature representation extraction. Our algorithm combines mutual information entropy and SURF image local features to extract key frames. Comprehensive experiments verify the feasibility of practicing the key frame extractor based on convolutional neural network by training the model, and conduct a quality assessment model study. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Mingju; Zhang, Hua] Southwest Univ Sci & Technol, Robot Technol Used Special Environm Key Lab Sichu, Mianyang 621010, Sichuan, Peoples R China.
   [Chen, Mingju; Lin, Guojun] Sichuan Univ Sci & Engn, Artificial Intelligence Key Lab Sichuan Prov, Zigong 643000, Peoples R China.
   [Han, Xiaofeng] Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao, Shandong, Peoples R China.
   [Kamruzzaman, M. M.] Jouf Univ, Dept Comp & Informat Sci, Sakaka, Al Jouf, Saudi Arabia.
C3 Southwest University of Science & Technology - China; Sichuan University
   of Science & Engineering; Shandong University of Science & Technology;
   Al Jouf University
RP Han, XF (corresponding author), Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao, Shandong, Peoples R China.
EM chenmingju@suse.edu.cn; hanxiaofeng@sdust.edu.cn; zzhh839@163.com;
   tiemujian123400@163.com; mmkamruzzaman@ju.edu.sa
RI Kamruzzaman, M.M./F-6702-2011; han, xiao/HDN-9782-2022
OI Kamruzzaman, M.M./0000-0001-8464-1523; 
FU Open Fund Project of the Artificial Intelligence Key Laboratory of
   Sichuan Province [2016RYY02]; Project of Sichuan Department of Science
   and Technology [2019YJ0476, 2018GZDZX0043]; Jouf University, Sakaka,
   Aljouf, KSA
FX This research was supported by the Open Fund Project of the Artificial
   Intelligence Key Laboratory of Sichuan Province (Grant no. 2016RYY02),
   the Project of Sichuan Department of Science and Technology (2019YJ0476,
   2018GZDZX0043) and Jouf University, Sakaka, Aljouf, KSA.
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2017, J ELECTR COMPUT ENG
   Cai Y., 2017, REMOTE SENS, P9
   Chaabouni S, 2019, J VIS COMMUN IMAGE R, V60, P79, DOI 10.1016/j.jvcir.2019.02.004
   Chasanis V.T., 2015, INT C SIGN PROC, P23
   Dang C, 2015, IEEE T IMAGE PROCESS, V24, P3742, DOI 10.1109/TIP.2015.2445572
   Ding SF, 2015, ARTIF INTELL REV, V43, P593, DOI 10.1007/s10462-013-9398-7
   Duan H, 2009, J SYST SOFTWARE, V82, P400, DOI 10.1016/j.jss.2008.07.007
   Gao Lin Gao Lin, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P121
   Ghoniemy T, 2018, IEEE IMAGE PROC, P236, DOI 10.1109/ICIP.2018.8451757
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Huang X, 2016, NEUROCOMPUTING, V218, P296, DOI 10.1016/j.neucom.2016.08.078
   Ioannidis A, 2016, PATTERN RECOGN LETT, V72, P52, DOI 10.1016/j.patrec.2016.01.027
   Ioannidis AI, 2014, INT C PATT RECOG, P3463, DOI 10.1109/ICPR.2014.596
   Jing Y, 2014, IEEE INT ULTRA SYM, P150, DOI 10.1109/ULTSYM.2014.0038
   Kumar N.S., 2015, UNDERWATER TECHNOL, P1
   Liu H, 2014, MATERIALS, V7, P1, DOI 10.3390/ma7010001
   Liu L, 2015, COMPUT GEOSCI-UK, V83, P27, DOI 10.1016/j.cageo.2015.06.017
   Luo X., 2014, IEEE INT C MULT EXP, P15
   Luo X., 2014, INT C MULT EXP, P23
   Meng FX, 2018, LITHOS, V302, P535, DOI 10.1016/j.lithos.2018.01.032
   Momin B.F., 2017, INT C ADV COMM CONTR
   Ning J., 2017, MIN MINER, V7
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Priya GGL, 2014, ECOL INFORM, V23, P107, DOI 10.1016/j.ecoinf.2013.09.003
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Schoeffmann K, 2015, MULTIMED TOOLS APPL, V74, P11187, DOI 10.1007/s11042-014-2224-7
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Sheng L, 2017, IEEE T NEUR NET LEAR, V28, P2382, DOI 10.1109/TNNLS.2016.2580601
   Song BY, 2017, COGN COMPUT, V9, P5, DOI 10.1007/s12559-016-9442-4
   Song X, 2016, SURF REV LETT, V23, DOI 10.1142/S0218625X16500475
   Sun HM, 2016, COMPUT GEOSCI-UK, V91, P98, DOI 10.1016/j.cageo.2016.03.012
   Thepade D.S., 2015, INT J COMPUT APPL, V111, P49
   Thepade S.D., 2014, INT C COMM SIGN PROC, P975
   Thepade SD, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P332, DOI 10.1109/IIC.2015.7150763
   Tian ZW, 2016, COMPUT GEOSCI-UK, V86, P15, DOI 10.1016/j.cageo.2015.10.002
   Wang H, 2013, INFORM SCIENCES, V223, P221, DOI 10.1016/j.ins.2012.08.027
   Wang JJ, 2014, J ZHEJIANG U-SCI C, V15, P383, DOI 10.1631/jzus.C1300289
   Wattanarachothai W., 2015, INT C IND NETW INT S, P336
   Xu FJ, 2018, HOLOCENE, V28, P455, DOI 10.1177/0959683617729445
   Yan B, 2013, MULTIMED TOOLS APPL, V67, P383, DOI 10.1007/s11042-011-0861-7
   Zhang YL, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/8950794
   Zhou XP, 2018, IEEE T KNOWL DATA EN, V30, P1178, DOI 10.1109/TKDE.2017.2784430
NR 43
TC 33
Z9 33
U1 3
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102678
DI 10.1016/j.jvcir.2019.102678
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700023
DA 2024-07-18
ER

PT J
AU Chen, YY
   Yu, M
   Jiang, GY
   Peng, ZJ
   Chen, F
AF Chen, Yeyao
   Yu, Mei
   Jiang, Gangyi
   Peng, Zongju
   Chen, Fen
TI End-to-end single image enhancement based on a dual network cascade
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single image enhancement; Convolutional neural network; Dual network
   cascade model; Exposure prediction; Exposure fusion
ID HIGH DYNAMIC-RANGE; QUALITY ASSESSMENT; FUSION
AB A single-exposure image may lose details because of the imaging dynamic range limitations of single camera sensor. Multi-image fusion techniques are often used to improve the image quality, but if there are moving objects in the scene, the fused images may result in ghost artifacts. In order to avoid this problem and enhance single-exposure images, this paper proposes a dual network cascade model for single image enhancement, including exposure prediction network and exposure fusion network. First, the exposure prediction network generates two under-/over-exposure images that differ from the input normal-exposure image so as to recover the lost details of the under-exposed/over-exposed regions. Then, the exposure fusion network fuses the input image and the generated under-/over-exposure images to generate the final enhanced image. The loss function constructed by a structural dissimilarity index is used to alleviate chessboard artifacts in the generated image. Further, through three-phase training, the model robustly generates enhanced images without any post-processing. The experimental results demonstrate that the proposed method can effectively improve the image contrast and reconstruct details of under-exposed/over-exposed regions in the original image. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Yeyao; Yu, Mei; Jiang, Gangyi; Peng, Zongju; Chen, Fen] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
   [Yu, Mei; Jiang, Gangyi] Nanjing Univ, Natl Key Lab Software New Technol, Nanjing, Jiangsu, Peoples R China.
C3 Ningbo University; Nanjing University
RP Yu, M; Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
EM jianggangyi@126.com
RI jiang, gang/KII-8233-2024; Peng, Zongju/AAA-2914-2020; Chen,
   Fen/ABG-7013-2021
OI Peng, Zongju/0000-0001-8286-538X; 
FU Natural Science Foundation of China [61671258, 61871247, 61671412,
   61620106012]; K.C. Wong Magna Fund of Ningbo University
FX This work was supported by the Natural Science Foundation of China under
   Grant Nos. 61671258, 61871247, 61671412 and 61620106012. It was also
   sponsored by the K.C. Wong Magna Fund of Ningbo University.
CR Akyüz AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276425
   [Anonymous], 2012, NEURIPS 2012
   Artusi A, 2017, IEEE SIGNAL PROC MAG, V34, P165, DOI 10.1109/MSP.2017.2716957
   Banterle F., 2006, P 4 INT C COMP GRAPH, P349
   Bashfordrogers T., 2018, COMPUTER GRAPHICS FO, V37
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Clevert D.-A., 2016, P 4 INT C LEARN REPR, P1
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Huo YQ, 2014, VISUAL COMPUT, V30, P507, DOI 10.1007/s00371-013-0875-4
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   John A, 2017, CRISIS, V38, P17, DOI 10.1027/0227-5910/a000410
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Li H, 2018, IEEE IMAGE PROC, P1723, DOI 10.1109/ICIP.2018.8451689
   Li H, 2018, COMPUT VIS IMAGE UND, V168, P37, DOI 10.1016/j.cviu.2017.11.001
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Liang Z., 2018, P IEEE C COMP VIS PA
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Park JS, 2018, IEEE ACCESS, V6, P10966, DOI 10.1109/ACCESS.2018.2797197
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Raveendranath A, 2016, INT CONF COMMUN SYST, P120, DOI 10.1109/CSN.2016.7823999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Shangzhe, 2018, EUR C COMP VIS ECCV
   Yang Xin, 2018, P IEEE C COMP VIS PA
   Zhang JS, 2017, IEEE I CONF COMP VIS, P4529, DOI 10.1109/ICCV.2017.484
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   2015, IEEE T IMAGE PROCESS, V24, P3086, DOI DOI 10.1109/TIP.2015.2436340
NR 42
TC 12
Z9 13
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 284
EP 295
DI 10.1016/j.jvcir.2019.04.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100029
DA 2024-07-18
ER

PT J
AU Huang, FH
   Yu, Y
   Feng, TH
AF Huang, Fenghua
   Yu, Ying
   Feng, Tinghao
TI Automatic extraction of urban impervious surfaces based on deep learning
   and multi-source remote sensing data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-source remote sensing data; Deep learning; Extraction of urban
   impervious surface; ELM classifier; Fuzzy C means clustering
AB The conventional methods of urban impervious surfaces extraction mainly use the shallow-layer machine learning algorithms based on the medium- or low-resolution remote sensing images, and always provide low accuracy and poor automation level because the potential of multi-source remote sensing data are not fully utilized and the low-level features are not effectively organized. In order to address this problem, a novel method (AEIDLMRS) is proposed to automatically extract impervious surfaces based on deep learning and multi-source remote sensing data. First, the multi-source remote sensing data consisting of LIDAR points cloud data, Landsat8 images and Pleiades-1A images are preprocessed, re-sampled and registered, and then the combined features of spectral, elevation and intensity from the multi-source data are denoised using the minimum noise fraction (MNF) method to generate some representative MNF features. A small number of reliable labelled samples are automatically extracted using the fuzzy C-means (FCM) clustering method based on the MNF features. Secondly, the convolutional neural network (CNN) is used to extract the representative features of the neighborhood windows of each pixel in the fused Pleiades-1A image through multi-layer convolution and pooling operations. Finally, the combined features of MNF features and CNN features are pre-learned via the deep belief network (DBN). The DBN parameters are globally optimized jointly using the Extreme Learning Machine (ELM) classifier on the top level and the small set of labelled samples extracted via FCM, and the urban impervious surfaces are distinguished from others based on the trained ELM classifier and morphological operations. Experiments are performed to compare the proposed method with other three related methods in three different experimental regions respectively. Experimental results demonstrate that AEIDLMRS has better accuracy and automation level than the others under relatively good efficiency, and it is more suitable for the extraction of complex urban impervious surfaces. (C) 2018 Published by Elsevier Inc.
C1 [Huang, Fenghua; Yu, Ying] Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Fenghua; Yu, Ying] Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
   [Feng, Tinghao] Univ N Carolina, Coll Comp & Informat, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Huang, FH (corresponding author), Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
EM fenghuait@sina.com; thfeng@uncc.edu
RI Feng, Tinghao/JWO-1400-2024
OI Feng, Tinghao/0000-0003-2765-2765
FU National Natural Science Foundation of China (NSFC) [41501451]; Program
   for New Century Excellent Talents in Fujian Province Universities
   [[2016]23]; Program for Outstanding Youth Scientific Research Talents in
   Fujian Province Universities [[2015]54]
FX This work was funded by the National Natural Science Foundation of China
   (NSFC, 41501451), the Program for New Century Excellent Talents in
   Fujian Province Universities (MinJiaoKe [2016]23) and the Program for
   Outstanding Youth Scientific Research Talents in Fujian Province
   Universities (MinJiaoKe [2015]54). The authors would like to thank Dr.
   Gang Chen and Dr. Yinan He in University of North Carolina at Charlotte
   for their assistance, suggestions, and discussions.
CR [Anonymous], GEOMATICS SPATIAL IN
   [Anonymous], J REMOTE SENS
   [Anonymous], J NEUROMUSCULAR DIS
   [Anonymous], 1981, ADV APPL PATTERN
   [Anonymous], 2014, Comput. Modern
   [Anonymous], TEXT MIN ALGORITHM B
   [Anonymous], COMPUT SCI A
   [Anonymous], 2013, ADV EARTH SCI
   [Anonymous], COMPUT ENG APPL
   [Anonymous], J REMOTE SENS
   [Anonymous], 2017, THESIS
   [Anonymous], INSTRUM TECHN SENS
   [Anonymous], J N CHINA U WATER RE
   [Anonymous], COMPUT APPL SOFTW
   [Anonymous], JOURNAL
   Arnold CL, 1996, J AM PLANN ASSOC, V62, P243, DOI 10.1080/01944369608975688
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Chen H. J., 2014, China Patent, Patent No. [201410039584.3, 2014100395843]
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hodgson ME, 2003, PHOTOGRAMM ENG REM S, V69, P973, DOI 10.14358/PERS.69.9.973
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   [李彩丽 LI Cai-li], 2009, [遥感信息, Remote Sensing Information], P36
   Li Xiaolong, 2014, Journal of Frontiers of Computer Science and Technology, V8, P305, DOI 10.3778/j.issn.1673-9418.1306023
   [吕启 Lu Qi], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P1911
   [孙志英 SUN ZhiYing], 2007, [地理科学, Scientia Geographica Sinica], V27, P837
   [王宇红 Wang Yuhong], 2016, [化工学报, CIESC Journal], V67, P5163
   [吴孟凡 Wu Mengfan], 2017, [遥感信息, Remote Sensing Information], V32, P79
   [夏俊士 XIA Junshi], 2011, [中国矿业大学学报. 自然科学版, Journal of China University of Mining & Technology], V40, P660
   [徐涵秋 Xu Hanqiu], 2005, [遥感学报, Journal of Remote Sensing], V9, P589
   Yin Bao-cai, 2015, Journal of Beijing University of Technology, V41, P48, DOI 10.11936/bjutxb2014100026
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
NR 40
TC 13
Z9 14
U1 0
U2 66
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 16
EP 27
DI 10.1016/j.jvcir.2018.12.051
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000002
DA 2024-07-18
ER

PT J
AU Zou, Y
   Zhang, G
   Liu, LA
AF Zou, Ying
   Zhang, Ge
   Liu, Leian
TI Research on image steganography analysis based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganalysis; Steganography; Feature learning; Deep learning;
   Convolutional neural network; Transfer learning; Multitask learning
ID OBJECT DETECTION
AB Although steganalysis has developed rapidly in recent years, it still faces many difficulties and challenges. Based on the theory of in-depth learning method and image-based general steganalysis, this paper makes a deep study of the hot and difficult problem of steganalysis feature expression, and tries to establish a new steganalysis paradigm from the idea of feature learning. The main contributions of this paper are as follows: 1. An innovative steganalysis paradigm based on in-depth learning is proposed. Based on the representative deep learning method CNN, the model is designed and adjusted according to the characteristics of steganalysis, which makes the proposed model more effective in capturing the statistical characteristics such as neighborhood correlation. 2. A steganalysis feature learning method based on global information constraints is proposed. Based on the previous research of steganalysis method based on CNN, this work focuses on the importance of global information in steganalysis feature expression. 3. A feature learning method for low embedding rate steganalysis is proposed. 4. A general steganalysis method for multi-class steganography is proposed. The ultimate goal of general steganalysis is to construct steganalysis detectors without distinguishing specific types of steganalysis algorithms. (C) 2019 Published by Elsevier Inc.
C1 [Zou, Ying; Liu, Leian] Zhongkai Univ Agr & Engn, Coll Informat Sci & Technol, 501,Zhongkai Rd, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Ge] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Zhang, Ge] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
C3 Zhongkai University of Agriculture & Engineering; Henan University;
   Henan University
RP Zhang, G (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
EM zouying@zhku.edu.cn; zhangge@henu.edu.cn; Ila@zhku.edu.cn
RI Zou, Ying/KLC-9380-2024
FU Science and Technology Planning Project of Guangdong Province
   [2017A070709012]; quality resource sharing course project "Computer
   Network" [133]; provincial-level characteristic specialty-"Network
   Engineering" and the provincial teaching team-"Teaching team of basic
   core course of computer major" [[2017]214]; Guangdong province-"Reform
   and practice of the training mode of network engineering talents based
   on the cooperation of school-school and school-enterprise" [180];
   university-level high-quality resource sharing course project-"Network
   Security Technology" and "Wireless Sensor Network and RFID Technology".
   And NSFC [61802114, 61802113]; Scientific Research Foundation of the
   Higher Education Institutions of Henan Province [18A520021, 18A120001];
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety (Nanjing University of Science and Technology) [30916014107]
FX This work was supported by the Science and Technology Planning Project
   of Guangdong Province under Grant (2017A070709012), the quality resource
   sharing course project "Computer Network" (Official document by
   Department of education of Guangdong province ([2015] no. 133)), the
   provincial-level characteristic specialty-"Network Engineering" and the
   provincial teaching team-"Teaching team of basic core course of computer
   major" (Official document by Department of education of Guangdong
   province ([2017]214)), 2018 higher education teaching reform project of
   Guangdong province-"Reform and practice of the training mode of network
   engineering talents based on the cooperation of school-school and
   school-enterprise" (Official document by Department of education of
   Guangdong province ([2018] no. 180)), and the university-level
   high-quality resource sharing course project-"Network Security
   Technology" and "Wireless Sensor Network and RFID Technology". And NSFC
   (No. 61802114, 61802113), Scientific Research Foundation of the Higher
   Education Institutions of Henan Province (18A520021, 18A120001), Project
   supported by the Jiangsu Key Laboratory of Image and Video Understanding
   for Social Safety (Nanjing University of Science and Technology No.
   30916014107).
CR Artz D, 2001, IEEE INTERNET COMPUT, V5, P75, DOI 10.1109/4236.935180
   Cachin Christian, 1998, INT WORKSH INF HID
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dumitrescu S, 2002, INT WORKSH INF HID
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hussain M., 2013, SURVEY IMAGE STEGANO
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 23
TC 16
Z9 18
U1 3
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 266
EP 275
DI 10.1016/j.jvcir.2019.02.034
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000029
DA 2024-07-18
ER

PT J
AU Baisa, NL
   Wallace, A
AF Baisa, Nathanael L.
   Wallace, Andrew
TI Development of a N-type GM-PHD filter for multiple target, multiple type
   visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Random finite sets; FISST; Multiple target filtering;
   PHD filter; N-type GM-PHD filter; Gaussian mixture; OSPA metric
ID DATA ASSOCIATION; MULTITARGET
AB We propose a new framework that extends the standard Probability Hypothesis Density (PHD) filter for multiple targets having N >= 2 different types based on Random Finite Set theory, taking into account not only background clutter, but also confusions among detections of different target types, which are in general different in character from background clutter. Under Gaussianity and linearity assumptions, our framework extends the existing Gaussian mixture (GM) implementation of the standard PHD filter to create a N-type GM-PHD filter. The methodology is applied to real video sequences by integrating object detectors' information into this filter for two scenarios. For both cases, Munkres's variant of the Hungarian assignment algorithm is used to associate tracked target identities between frames. This approach is evaluated and compared to both raw detection and independent GM-PHD filters using the Optimal Sub-pattern Assignment metric and discrimination rate. This shows the improved performance of our strategy on real video sequences. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Baisa, Nathanael L.; Wallace, Andrew] Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh, Midlothian, Scotland.
C3 Heriot Watt University
RP Baisa, NL (corresponding author), Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh, Midlothian, Scotland.
EM NBaisa@lincoln.ac.uk
OI Wallace, Andrew/0000-0003-4425-8591
FU Engineering and Physical Sciences Research Council (EPSRC) [EP/K009931];
   James Watt Scholarship; EPSRC [EP/K009931/1] Funding Source: UKRI
FX We would like to acknowledge the support of the Engineering and Physical
   Sciences Research Council (EPSRC), grant references EP/K009931 and a
   James Watt Scholarship. We would also like to thank Dr. Daniel Clark for
   sharing his expertise and understanding of RFS methodology.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2016, CVPR
   [Anonymous], 2013, PMLR
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], 2009, CVPR
   [Anonymous], 2014, Computer Vision in Sports
   Baisa N. L., 2017, P 12 INT C COMP VIS
   Baisa N. L., ARXIV170504757
   Baisa NL, 2018, J VIS COMMUN IMAGE R, V55, P464, DOI 10.1016/j.jvcir.2018.06.027
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   BOURGEOIS F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945
   Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107
   Cavallaro A, 2016, ONLINE MULTITARGET T
   Cham  T.-J., 1999, CVPR, P2239
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Dollar P, 2014, IEEE T PATTERN ANAL, V99, P14
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Leal-Taixe  L, IEEE C COMP VIS PATT
   Luo  W., ABS14097618 CORR
   Maggio E, 2008, IEEE T CIRC SYST VID, V18, P1016, DOI 10.1109/TCSVT.2008.928221
   Mahler R., 2014, ADV STAT MULTISOURCE
   Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119
   Matzka S, 2012, IEEE T INTELL TRANSP, V13, P859, DOI 10.1109/TITS.2011.2182610
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Ohn-Bar E, 2015, IEEE T INTELL TRANSP, V16, P2511, DOI 10.1109/TITS.2015.2409889
   Panta K, 2009, IEEE T AERO ELEC SYS, V45, P1003, DOI 10.1109/TAES.2009.5259179
   Pasha SA, 2009, IEEE T AERO ELEC SYS, V45, P919, DOI 10.1109/TAES.2009.5259174
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Rezatofighi SH, 2015, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2015.349
   Ristic B, 2012, IEEE T AERO ELEC SYS, V48, P1656, DOI 10.1109/TAES.2012.6178085
   Ristic B., 2010, Thirteenth Conference on Information Fusion, P1
   Romero-Cano V, 2016, INT J ROBOT RES, V35, P654, DOI 10.1177/0278364915583881
   Schindler K., ARXIV160300831CS
   Schuhmacher D, 2008, IEEE T SIGNAL PROCES, V56, P3447, DOI 10.1109/TSP.2008.920469
   Shin S, 2015, IEEE IC COMP COM NET
   Song  Y., 2016, IEEE IEIE INT C CONS
   Vo B.N., 2015, MULTITARGET TRACKING, P1
   Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190
   Vo BN, 2005, IEEE T AERO ELEC SYS, V41, P1224, DOI 10.1109/TAES.2005.1561884
   Yang W, 2014, INFORM FUSION, V18, P101, DOI 10.1016/j.inffus.2013.05.010
   Yang W, 2012, IEEE T AERO ELEC SYS, V48, P3594, DOI 10.1109/TAES.2012.6324744
   Zhou XL, 2014, IEEE T IND INFORM, V10, P1064, DOI 10.1109/TII.2013.2294156
NR 43
TC 25
Z9 28
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 257
EP 271
DI 10.1016/j.jvcir.2019.01.026
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600027
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cai, ZQ
   Chen, GC
   Xing, LN
   Yang, JH
   Tan, X
AF Cai, Zhaoquan
   Chen, Guangcai
   Xing, Lining
   Yang, Jinghui
   Tan, Xu
TI Evaluating hedge fund downside risk using a multi-objective neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Downside risk evaluation; Big data hedge fund; Multi-objective neural
   network
ID ALGORITHM; FRAMEWORK; MODEL
AB Predicting the downside risk of a hedge fund is the foundation of risk measurement. These predictions also provide conditions that can be used for designing and implementing risk prevention measures. Hence, this paper proposes a big data hedge fund downside risk evaluation model based on a multi objective neural network. First, two evaluation indexes are defined. Then, local search is applied to merge parent and descendant populations. Only those individuals from the Pareto front are optimized. Experimental results suggest that this model and method is feasible and valid. Specifically, the VaR model is unable to estimate the possible extreme risk of a hedge fund. In contrast, the CVaR model can accurately measure the risks under extreme market conditions. However, a combination of VaR and CVaR can help a fund manager avoid extreme risks to a hedge fund. (C) 2018 Published by Elsevier Inc.
C1 [Cai, Zhaoquan] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Guangdong, Peoples R China.
   [Chen, Guangcai] Huizhou Univ, Dept Informat Sci & Technol, Huizhou 516007, Peoples R China.
   [Xing, Lining; Yang, Jinghui] Shanghai Polytech Univ, Coll Engn, Shanghai 201209, Peoples R China.
   [Tan, Xu] Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen 518172, Peoples R China.
C3 Guangdong University of Technology; Huizhou University; Shanghai
   Polytechnic University; Shenzhen Institute of Information Technology
RP Yang, JH (corresponding author), Shanghai Polytech Univ, Coll Engn, Shanghai 201209, Peoples R China.; Tan, X (corresponding author), Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen 518172, Peoples R China.
EM jhyang@sspu.edu.cn; tanxu_nudt@yahoo.com
RI XING, Lining/GRO-1108-2022
FU National Natural Science Foundation of China [61773120, 51678239,
   61772225]; Foundation for Distinguished Young Talents in Higher
   Education of Guangdong, China [2015KQNCX153]; Science and Technology
   Program of Huizhou, China [2015B010002002]; Science and Technology
   Program of Huizhou [2016X0431046, 2016X0432047, 2016X0434049]
FX This paper is supported by the National Natural Science Foundation of
   China (Grant Nos. 61773120, 51678239, and 61772225). This research is
   also supported by the Foundation for Distinguished Young Talents in
   Higher Education of Guangdong, China, under Grant No. 2015KQNCX153,
   Science and Technology Program of Huizhou, China under Grant No.
   2015B010002002, and Science and Technology Program of Huizhou (Grant
   Nos. 2016X0431046, 2016X0432047, and 2016X0434049). We thank Kim
   Moravec, PhD, from Liwen Bianji, Edanz Editing China
   (www.liwenbianji.cnjac), for editing the English text of a draft of this
   manuscript.
CR Aloisio G, 1997, LECT NOTES COMPUT SC, V1225, P480, DOI 10.1007/BFb0031620
   Aloisio G, 1999, LECT NOTES COMPUT SC, V1593, P563
   Aloisio G, 2005, P 2005 ACM S APPL CO, P701
   [Anonymous], 2015, IEEE T PARALL DISTR, V25, P2126
   Bai GQ, 2012, RES J CHEM ENVIRON, V16, P43
   Barnhart DJ, 2009, J SPACECRAFT ROCKETS, V46, P469, DOI 10.2514/1.41639
   Belaqziz S, 2013, AGR WATER MANAGE, V119, P1, DOI 10.1016/j.agwat.2012.12.011
   CHEN YW, 2008, J SPACECRAFT TT C TE, V27, P1
   Doyne  T., 2007, P 5 RESP SPAC C
   Fei Lu, 2012, Proceedings of the 2012 International Conference on System Science and Engineering (ICSSE), P50, DOI 10.1109/ICSSE.2012.6257147
   Feng MW, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P295, DOI 10.1109/ISUC.2008.87
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Fukushima Y., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics (ICM), P439, DOI 10.1109/ICMECH.2011.5971326
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   He RJ, 2012, RES J CHEM ENVIRON, V16, P18
   Huang JD, 2008, PROC SPIE, V6932, DOI 10.1117/12.776089
   Hur-Diaz S., 2014, P 24 INT S SPAC FLIG
   Ip F, 2006, REMOTE SENS ENVIRON, V101, P463, DOI 10.1016/j.rse.2005.12.018
   Karamchand S. S, 2006, OPERATOR SCHEDULING
   Kim T, 2008, 2008 22ND INTERNATIONAL WORKSHOPS ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOLS 1-3, P662, DOI 10.1109/WAINA.2008.188
   Lee MFR, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P195, DOI 10.1109/iFuzzy.2013.6825435
   Li JF, 2012, DISASTER ADV, V5, P726
   Lian ZY, 2013, DISASTER ADV, V6, P330
   Lian ZY, 2012, DISASTER ADV, V5, P1346
   Lu F, 2014, IEEE INT C NETW SENS, P273, DOI 10.1109/ICNSC.2014.6819638
   Lu F, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P289, DOI 10.1109/ICInfA.2012.6246820
   Martin M., 1999, AIAA SPACE TECHNOLOG, P28
   Maruyama N, 2013, IEEE SYMP ART LIFE, P67, DOI 10.1109/ALIFE.2013.6602433
   O'Neill M. G., 2010, AIAA SPAC 2010 C EXP, P391
   Rodrigues P, 2014, NASA ESA CONF, P180, DOI 10.1109/AHS.2014.6880175
   Tang XF, 2014, SENSORS-BASEL, V14, P8513, DOI 10.3390/s140508513
   Tehranian S, 2006, J PARALLEL DISTR COM, V66, P403, DOI 10.1016/j.jpdc.2005.12.001
   Vladimirova T, 2008, AEROSP CONF PROC, P153
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Wu XF, 2008, PROCEEDINGS OF THE 2008 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, P424, DOI 10.1109/AHS.2008.55
   [向彪 XIANG Biao], 2008, [宇航学报, Journal of Chinese Society of Astronautics], V29, P1443
   Yao F, 2012, DISASTER ADV, V5, P1341
   Zhang WF, 2014, SOFTWARE PRACT EXPER, V44, P873, DOI 10.1002/spe.2229
   Zhang YH, 2016, CHINA COMMUN, V13, P16, DOI 10.1109/CC.2016.7559071
NR 39
TC 7
Z9 8
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 433
EP 438
DI 10.1016/j.jvcir.2018.11.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600046
DA 2024-07-18
ER

PT J
AU Ray, KS
   Chakraborty, S
AF Ray, Kumar S.
   Chakraborty, Soma
TI Object detection by spatio-temporal analysis and tracking of the
   detected objects in a video with variable background
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Variable background; Object detection; Gabor filter; Spatio-temporal
   analysis; Minimum Spanning Tree (MST); Object tracking; Linear
   Assignment Problem (LAP); Kalman filter; Occlusion
ID MOVING-OBJECTS; VISUAL TRACKING; SEGMENTATION; INTELLIGENCE; CAMERA;
   DESCRIPTORS; SUBTRACTION; FLUID
AB In this paper we propose a novel approach for detecting and tracking objects in videos captured by moving cameras without any additional sensor. In such a video both the background and foreground change in each frame of the image sequence; making the separation of actual moving object from the background a challenging task. In this work, moving objects are detected as clusters of spatio-temporal blobs generated by spatio-temporal analysis of the image sequence using a three-dimensional Gabor filter and merged using Minimum Spanning Tree. Problem of data association during tracking is solved by Linear Assignment Problem and occlusion is handled by the application of Kalman filter. The major advantage of the proposed method is that, it does not require initialization or training on sample data to perform. Our algorithm demonstrated very satisfactory state-of-the-art result on benchmark videos. The performance of the algorithm is equivalent or superior to some benchmark algorithms. (C) 2018 Published by Elsevier Inc.
C1 [Ray, Kumar S.; Chakraborty, Soma] Indian Stat Inst, 203 BT Rd, Kolkata 108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Chakraborty, S (corresponding author), Indian Stat Inst, 203 BT Rd, Kolkata 108, India.
EM ksray@isical.ac.in; soma.gchakraborty@gmail.com
CR Harbi N, 2015, NEUROCOMPUTING, V161, P56, DOI 10.1016/j.neucom.2014.11.072
   [Anonymous], 2014, ADV INTELLIGENT SYST
   [Anonymous], 1992, Combinatorial optimization
   Arvanitidou MG, 2013, SIGNAL PROCESS-IMAGE, V28, P1420, DOI 10.1016/j.image.2013.09.008
   Avola D., 2016, PATTERN RECOGN LETT
   Blair C, 2006, BEHAV BRAIN SCI, V29, P109
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   CATTELL RB, 1963, J EDUC PSYCHOL, V54, P1, DOI 10.1037/h0046743
   Cho HG, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P1035, DOI 10.1109/IVS.2012.6232264
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   Collins RT, 2012, PROC CVPR IEEE, P1744, DOI 10.1109/CVPR.2012.6247870
   Cormen T.H., 2009, INTRO ALGORITHMS
   Cui XY, 2012, LECT NOTES COMPUT SC, V7572, P612, DOI 10.1007/978-3-642-33718-5_44
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Ferone A, 2014, IEEE T SYST MAN CY-S, V44, P571, DOI 10.1109/TSMC.2013.2280121
   Fradi H, 2015, SIGNAL PROCESS-IMAGE, V31, P100, DOI 10.1016/j.image.2014.11.006
   Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035
   Ghosh A, 2012, IEEE T CIRC SYST VID, V22, P1127, DOI 10.1109/TCSVT.2012.2190476
   HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568
   Hou L, 2015, INT CONF ACOUST SPEE, P2249, DOI 10.1109/ICASSP.2015.7178371
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Javed S., 2017, P S APPL COMP APR, P89
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Khatoonabadi SH, 2013, IEEE T IMAGE PROCESS, V22, P300, DOI 10.1109/TIP.2012.2214049
   Kim SW, 2013, MACH VISION APPL, V24, P1015, DOI 10.1007/s00138-012-0448-y
   Kim S, 2016, IEEE T CIRC SYST VID, V26, P1407, DOI 10.1109/TCSVT.2015.2444711
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P1011, DOI 10.1109/TPAMI.2012.161
   Lian FL, 2013, IEEE T IND INFORM, V9, P172, DOI 10.1109/TII.2012.2209664
   Lim MK, 2014, INFORM SCIENCES, V283, P267, DOI 10.1016/j.ins.2014.01.003
   Lim T, 2012, PATTERN RECOGN, V45, P1696, DOI 10.1016/j.patcog.2011.10.018
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Minematsu T., 2015, FRONT COMP VIS FCV 2, DOI [10.1109/FCV.2015.7103752, DOI 10.1109/FCV.2015.7103752]
   Mishra Neeraj, 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P423, DOI 10.1007/978-3-642-45062-4_58
   Monma Y, 2015, IEEE IMTC P, P29, DOI 10.1109/I2MTC.2015.7151235
   Sabirin H, 2012, IEEE T MULTIMEDIA, V14, P657, DOI 10.1109/TMM.2012.2187777
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shi XC, 2013, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2013.309
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simpson AJR, 2015, ARXIV150900913
   Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wei Z, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1501, DOI 10.1109/ICME.2008.4607731
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107
   Xue GJ, 2012, PATTERN RECOGN LETT, V33, P1601, DOI 10.1016/j.patrec.2012.05.009
   Yi KM, 2013, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2013.9
   Yun KM, 2017, PATTERN RECOGN LETT, V88, P57, DOI 10.1016/j.patrec.2017.01.017
   Zamalieva D, 2014, LECT NOTES COMPUT SC, V8689, P803, DOI 10.1007/978-3-319-10590-1_52
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zheng AH, 2017, MULTIMED TOOLS APPL, V76, P11003, DOI 10.1007/s11042-016-3565-1
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 56
TC 27
Z9 27
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 662
EP 674
DI 10.1016/j.jvcir.2018.12.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100063
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, HH
   Xu, Y
   Huang, YJ
   Yang, Q
   Zhou, ZG
AF Huang, Honghe
   Xu, Yi
   Huang, Yanjie
   Yang, Qian
   Zhou, Zhiguo
TI Pedestrian tracking by learning deep features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pedestrian tracking; Convolutional neural networks; Optical flow
AB Pedestrian tracking technique is now widely used in many intelligent systems, such as video surveillance, security regions. But many methods suffer from illumination, human posture or human appendant. With the development of Convolutional Neural Networks (CNNs), deep feature can be learned. In this paper, training images will be divided into subregions to reduce the influence of human appendant such as bags. The remain regions are almost fixed regions. Then these fixed regions will be fed into our CNNs for learning deep features. In order to copy with different sizes of training images, an arbitrarily-sized pooling layer is developed in our CNN architecture. Then, these deeply-learned feature vector can be used in pedestrian recognition. In our work, optical flow is used for pedestrian tracking. Experimental results show our proposed method can achieve pedestrian tracking effectively. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Huang, Honghe; Xu, Yi; Huang, Yanjie; Yang, Qian; Zhou, Zhiguo] State Grid Quzhou Elect Power Supply Co, Quzhou, Zhejiang, Peoples R China.
RP Huang, HH (corresponding author), State Grid Quzhou Elect Power Supply Co, Quzhou, Zhejiang, Peoples R China.
RI Huang, YQ/JOK-7580-2023; huang, yan/GWM-4747-2022; Zhou,
   Zhiguo/S-4260-2018
OI Zhou, Zhiguo/0000-0003-4207-5759
CR [Anonymous], 2015, CHINA ENERGY REPORT
   [Anonymous], 2016, DEEP TRANSFER LEARNI
   [Anonymous], 2016, ARXIV161001708
   Antigny N., 2017, P 2017 INT C IND POS
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Elzein H, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P500, DOI 10.1109/IVS.2003.1212962
   Fernández-Caballero A, 2010, ROBOT AUTON SYST, V58, P1273, DOI 10.1016/j.robot.2010.06.002
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Kwak J. Y., 2017, IEEE T INTELL TRANSP, P1
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Walk S., 2010, CVPR 2010, DOI DOI 10.1109/CVPR.2010.5540102
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zeng XY, 2014, LECT NOTES COMPUT SC, V8691, P472, DOI 10.1007/978-3-319-10578-9_31
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
NR 23
TC 5
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 172
EP 175
DI 10.1016/j.jvcir.2018.11.001
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400020
DA 2024-07-18
ER

PT J
AU Wu, SL
   Chen, XM
   Fu, J
   Chen, ZB
AF Wu, Shilin
   Chen, Xiaoming
   Fu, Jun
   Chen, Zhibo
TI Efficient VR Video Representation and Quality Assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Virtual reality; Cinematic VR; lmmersive media; Video coding; Quality
   assessment
AB VR video is increasingly popular due to the recent advances in VR technology and hardware. The bulky size of VR video, however, impose new challenges in its storage and processing. In this paper, we focus on the research problems of VR video representation and objective quality assessment. Distinct from traditional 2D video, a VR video is displayed and represented in a form of spherical surface. For encoding purpose, a VR video frame needs to be projected to a 2D flat plane. Existing projection methods usually lead to much redundancy or significant violation in the correlation of neighbor pixels, which are not encoding friendly or are creating visible edge artifacts. To alleviate these problems, we propose in this paper our Quadrangle Affine Square Projection (QASP). QASP is a novel representation for VR video frames, which can reduce the redundant pixels over the traditional projections. In particular, all the inner pixels in QASP remain connected, i.e. the correlations between neighbors pixels are well maintained, which is a desirable feature for video encoding and edge-artifact-free viewing experience. Besides, we also investigated in predicting the optimal rotation angle for QASP frames for higher encoding efficiency. In addition to VR video representation, we also investigate in this paper accurate objective quality measurement for VR video. The traditional video quality measurements, e.g. PSNR, are not suitable to measure the quality of VR videos since they will take the redundant pixels into account. In this paper, we propose a new quality measurement for VR videos, named as Resized-PSNR (R-PSNR). With R-PSNR, only the "meaningful" pixels are considered for quality measurement while the redundant pixels are discarded. To evaluate QASP and R-PSNR, experiments are conducted based on standard VR video sequences. The experimental results show that the proposed projection method achieves noticeable improvement over traditional methods, and the proposed quality assessment method outperforms the traditional measurements in terms of consistency with subjective evaluation. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wu, Shilin; Chen, Xiaoming; Fu, Jun; Chen, Zhibo] Univ Sci & Technol China, CAS Key Lab Technol Geospotial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Chen, ZB (corresponding author), Univ Sci & Technol China, CAS Key Lab Technol Geospotial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
EM chenzhibo@ustc.edu.cn
RI Wu, Shilin/IWU-6689-2023; Chen, Zhibo/T-5349-2019
OI Chen, Zhibo/0000-0002-8525-5066; Chen, Xiaoming/0000-0002-7503-3021
FU National Program on Key Basic Research Projects (973 Program) of China
   [2015CB351803]; National Science Foundation of China (NSFC) [61571413,
   61632001, 61390514]
FX This work was supported in part by the National Program on Key Basic
   Research Projects (973 Program) of China under Grant 2015CB351803, and
   the National Science Foundation of China (NSFC) under Grant 61571413,
   61632001, 61390514.
CR Abbas A., 2017, WP3 ITUT SG16 JOINT
   [Anonymous], 2017, W16825 ISOIEC JTC1SC
   [Anonymous], 2016, N0004 IEEE 1857 9 WO
   Barr A. H., 1995, P 22 ANN C COMP GRAP
   Boyce J., 2017, P JOINT VID EXPL TEA
   Coban Muhammed, 2017, WP3 ITUT SG16 JOINT
   Fu CW, 2009, IEEE T MULTIMEDIA, V11, P634, DOI 10.1109/TMM.2009.2017626
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   He Y., 2017, WP3 ITUT SG16 JOINT
   Lin H.-C., 2017, WP3 ITUT SG16 JOINT
   Liu Yufan, 2016, M1003 IEEE 1857 9 WO
   Olivia Nemethova, 2004, COMMUNICATIONS INTER
   Ries Michal, 2005, 2005 1 INT C MULT SE
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Smolic A, 2004, IEEE T CIRC SYST VID, V14, P348, DOI 10.1109/TCSVT.2004.823395
   Snyder J.P., 1987, 1395 US GEOL SURV
   Snyder JP., 1993, FLATTENING EARTH 200
   Sreedhar K. K., 2017, WP3 ITUT SG16 JOINT
   Sun Y, 2016, J ORTHOP SURG RES, V11, DOI 10.1186/s13018-016-0391-0
   Van der Auwera Geert, 2017, WP3 ITUT SG16 JOINT
   Wang Y., 2016, 4 M IMM VIS CONT COD
   Wu Chengjia, 2017, 8 M IMM VIS CONT COD
   Ye Y., 2017, WP3 ITUT SG16 JOINT
   Yu M., 2015, 2015 IEEE INT S MIX
   Zakharchenko V., 2016, WP3 ITUT SG16 JOINT
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zakharchenko Vladyslav, 2017, WP3 ITUT SG16 JOINT
   Zhang C, 2017, REDOX BIOL, V11, P1, DOI 10.1016/j.redox.2016.10.019
   Zhou Minhua, 2017, WP3 ITUT SG16 JOINT
NR 29
TC 10
Z9 10
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 107
EP 117
DI 10.1016/j.jvcir.2018.10.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400014
DA 2024-07-18
ER

PT J
AU Zhang, GY
   Wang, JP
   Zhang, XF
   Fei, HY
   Tu, B
AF Zhang, Guoyun
   Wang, Jinping
   Zhang, Xiaofei
   Fei, Hongyan
   Tu, Bing
TI Adaptive total variation-based spectral-spatial feature extraction of
   hyperspectral image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral image classification; Principal component analysis;
   Adaptive total variation filtering; Extreme learning machine
ID CLASSIFICATION; RESOLUTION; FILTER
AB In this paper, a simple yet quite useful hyperspectral images (HSI) classification method based on adaptive total variation filtering (ATVF) is proposed. The proposed method consists of the following steps: First, the spectral dimension of the HSI is reduced with principal component analysis (PCA). Then, ATVF is employed to extract image features which not only reduces the noise in the image, but also effectively exploits spatial-spectral information. Therefore, it can provide an improved representation. Finally, the efficient extreme learning machine (ELM) with a very simple structure is used for classification. This paper analyzes the influence of different parameters of the ATVF and ELM algorithm on the classification performance in detail. Experiments are performed on three hyperspectral urban data sets. By comparing with other HSI classification methods and other different feature extraction methods, the proposed method based on the ATVF algorithm shows outstanding performance in terms of classification accuracy and computational efficiency when compared with other hyperspectral classification methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Guoyun; Wang, Jinping; Zhang, Xiaofei; Fei, Hongyan; Tu, Bing] Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang, Peoples R China.
C3 Hunan Institute of Science & Technology
RP Tu, B (corresponding author), Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang, Peoples R China.
EM tubing@hnist.edu.cn
RI xiaofei, zhang/AAK-4586-2020
OI xiaofei, zhang/0000-0001-5567-4326; Wang, Jinping/0000-0002-4157-8605
FU National Natural Science Foundation of China [51704115]; Key Laboratory
   Open Fund Project of Hunan Province University [17K040, 15K051]; Science
   and Technology Program of Hunan Province [2016TP1021]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 51704115, by the Key Laboratory Open
   Fund Project of Hunan Province University under Grant 17K040 and 15K051,
   and by the Science and Technology Program of Hunan Province under Grant
   2016TP1021.
CR Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Chen C, 2014, REMOTE SENS-BASEL, V6, P5795, DOI 10.3390/rs6065795
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Jackson Q, 2002, IEEE T GEOSCI REMOTE, V40, P2454, DOI 10.1109/TGRS.2002.805087
   Jia RQ, 2010, ADV COMPUT MATH, V33, P231, DOI 10.1007/s10444-009-9128-5
   Kang XD, 2017, IEEE T GEOSCI REMOTE, V55, P7140, DOI 10.1109/TGRS.2017.2743102
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P3742, DOI 10.1109/TGRS.2013.2275613
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Lampropoulos G. A., 2009, IEEE INT GEOSCI REMO, P262
   Lanthier Y., 2008, P IEEE INT GEOSC REM, V2, P585, DOI [10.1109/IGARSS.2008.4779060, DOI 10.1109/IGARSS.2008.4779060]
   Li W, 2011, IEEE GEOSCI REMOTE S, V8, P894, DOI 10.1109/LGRS.2011.2128854
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Liu H, 2010, MAGN RESON IMAGING, V28, P1485, DOI 10.1016/j.mri.2010.06.023
   Liu Wen, 2011, Application Research of Computers, V28, P4797, DOI 10.3969/j.issn.1001-3695.2011.12.107
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Prasad S, 2008, IEEE GEOSCI REMOTE S, V5, P625, DOI 10.1109/LGRS.2008.2001282
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Song B., 2003, THESIS
   Tarabalka Y, 2010, PATTERN RECOGN, V43, P2367, DOI 10.1016/j.patcog.2010.01.016
   Tarabalka Y, 2010, IEEE T GEOSCI REMOTE, V48, P4122, DOI 10.1109/TGRS.2010.2062526
   Tarabalka Y, 2010, IEEE T SYST MAN CY B, V40, P1267, DOI 10.1109/TSMCB.2009.2037132
   Tarabalka Y, 2009, IEEE T GEOSCI REMOTE, V47, P2973, DOI 10.1109/TGRS.2009.2016214
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P1573, DOI 10.1109/TGRS.2018.2867444
   Tu B, 2018, IEEE SIGNAL PROC LET, V25, P1520, DOI 10.1109/LSP.2018.2865687
   Tu B, 2018, IEEE GEOSCI REMOTE S, V15, P1417, DOI 10.1109/LGRS.2018.2842792
   Tu B, 2018, IEEE GEOSCI REMOTE S, V15, P340, DOI 10.1109/LGRS.2017.2787338
   Valero S, 2013, IEEE T IMAGE PROCESS, V22, P1430, DOI 10.1109/TIP.2012.2231687
   Villa A, 2011, IEEE T GEOSCI REMOTE, V49, P4865, DOI 10.1109/TGRS.2011.2153861
   Yang H, 1999, INT J REMOTE SENS, V20, P97, DOI 10.1080/014311699213622
   Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054
   Zhang HY, 2014, IEEE J-STARS, V7, P2056, DOI 10.1109/JSTARS.2013.2264720
   Zhao GZ, 2018, NEUROCOMPUTING, V316, P68, DOI 10.1016/j.neucom.2018.07.052
   Zhong P, 2010, IEEE T IMAGE PROCESS, V19, P1890, DOI 10.1109/TIP.2010.2045034
   Zhong YF, 2014, IEEE J-STARS, V7, P1314, DOI 10.1109/JSTARS.2013.2290296
NR 41
TC 10
Z9 10
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 150
EP 159
DI 10.1016/j.jvcir.2018.09.016
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500014
DA 2024-07-18
ER

PT J
AU Gregori, V
   Morillas, S
   Roig, B
   Sapena, A
AF Gregori, Valentin
   Morillas, Samuel
   Roig, Bernardino
   Sapena, Almanzor
TI Fuzzy averaging filter for impulse noise reduction in colour images with
   a correction step
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image filter; Correction step; Fuzzy filter; Impulse noise
ID SWITCHING MEDIAN FILTER; REMOVAL
AB In this paper we propose a fuzzy detection and reduction method for impulse noise in colour images. Detection is based on the fuzzyfication of a well-known statistic called ROD. The noise degrees obtained are used to reduce impulses by employing a fuzzy averaging between the input colour vector and a robust estimate of noise-free colour vector within the input neighbourhood. Fuzzy averaging has some advantages in terms of both noise reduction and detail preservation in front of detect and replace approaches because of threshold based decisions of the latter. However, robustness of the former is lower. We solve this problem by including a correction mechanism that checks the fuzzy noise degree of the output and replaces it with a robust colour vector either when noise has not been properly reduced or when a colour artefact has been introduced. We carry out a thorough study of the method parameter setting and give a convenient and robust setting. Experimental results show that our approach is very robust in front of four different types of impulse noise.
C1 [Gregori, Valentin; Roig, Bernardino; Sapena, Almanzor] Univ Politecn Valencia, Inst Invest Gest Integrada Zonas Costeras, Campus Gandia, Valencia, Spain.
   [Morillas, Samuel] Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Valencia, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP Morillas, S (corresponding author), Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Valencia, Spain.
EM smorillas@mat.upv.es
RI Roig, Bernardino/B-7833-2014; Sapena, Almanzor/H-5102-2015; Morillas,
   Samuel/H-2610-2015; Gregori, Valentin/B-8233-2014
OI Roig, Bernardino/0000-0002-9599-572X; Sapena,
   Almanzor/0000-0001-8473-6063; Morillas, Samuel/0000-0001-9262-6139;
   Gregori, Valentin/0000-0002-5983-6182
FU Ministry of Economy and Competitiveness of Spain (MINECO/FEDER, UE) [MTM
   2015-64373-P]; Generalitat Valencians [AICO/2017/059]
FX The authors are very grateful to the reviewers for their valuable
   suggestions. Valentin Gregori and Samuel Morillas acknowledges the
   support of Ministry of Economy and Competitiveness of Spain under grant
   MTM 2015-64373-P (MINECO/FEDER, UE). Bernardino Roig and Almanzor Sapena
   acknowledges the support of Generalitat Valencians under grant
   AICO/2017/059.
CR Aborisade D.O., 2011, INT J ADV SCI TECHNO, V32, P79
   Camarena JG, 2013, IEEE T FUZZY SYST, V21, P971, DOI 10.1109/TFUZZ.2012.2234754
   Camarena JG, 2010, PATTERN RECOGN LETT, V31, P1842, DOI 10.1016/j.patrec.2010.01.008
   Camarena JG, 2010, IMAGE VISION COMPUT, V28, P188, DOI 10.1016/j.imavis.2009.07.005
   Celebi M.E., 2015, COLOR IMAGE VIDEO EN
   Chen BH, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P338, DOI 10.1109/BigMM.2017.42
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Geng X, 2012, SIGNAL PROCESS, V92, P150, DOI 10.1016/j.sigpro.2011.06.015
   Hassan M., 2012, International Journal of Computer Applications, V43, P7
   Jin KH, 2018, IEEE T IMAGE PROCESS, V27, P1448, DOI 10.1109/TIP.2017.2771471
   Jin LH, 2011, SIGNAL PROCESS, V91, P1249, DOI 10.1016/j.sigpro.2010.12.011
   Kuo YL, 2015, INT J FUZZY SYST, V17, P67, DOI 10.1007/s40815-015-0005-8
   KURUOGLU EE, 1997, 5 WORLD M INT SOC BA
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Lukac R, 2006, J VIS COMMUN IMAGE R, V17, P1, DOI 10.1016/j.jvcir.2005.08.007
   Meher SK, 2014, ENG APPL ARTIF INTEL, V30, P145, DOI 10.1016/j.engappai.2014.01.002
   Morillas S, 2008, COMPUT VIS IMAGE UND, V110, P102, DOI 10.1016/j.cviu.2007.05.001
   Morillas S, 2008, SIGNAL PROCESS, V88, P390, DOI 10.1016/j.sigpro.2007.05.019
   Morillas S, 2011, SENSORS-BASEL, V11, P8115, DOI 10.3390/s110808115
   Mukhopadhyay S, 2014, CIRC SYST SIGNAL PR, V33, P2193, DOI 10.1007/s00034-014-9739-z
   Peris-Fajarnés G, 2006, LECT NOTES COMPUT SC, V4141, P74
   Pushpavalli R., 2013, INT J SCI RES PUBL, V3, P1
   Qin H, 2007, FUZZY SET SYST, V158, P1036, DOI 10.1016/j.fss.2006.10.028
   Rahman T, 2014, INT CONF ELECTR ENG
   Ramakrisnan E., 2015, INT J RES, V2, P841
   Roy A, 2018, IEEE T IND ELECTRON, V65, P7268, DOI 10.1109/TIE.2018.2793225
   Schulte S, 2007, IEEE T IMAGE PROCESS, V16, P2565, DOI 10.1109/TIP.2007.904960
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P3567, DOI 10.1109/TIP.2006.877494
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2015, J REAL-TIME IMAGE PR, V10, P289, DOI 10.1007/s11554-012-0307-0
   Nguyen SD, 2018, IEEE T FUZZY SYST, V26, P985, DOI 10.1109/TFUZZ.2017.2701313
   Thirilogasundari V, 2012, PROCEDIA ENGINEER, V38, P2858, DOI 10.1016/j.proeng.2012.06.334
   Wang GH, 2015, OPTIK, V126, P2428, DOI 10.1016/j.ijleo.2015.06.005
   Yin JL, 2018, IEEE T MULTIMEDIA, V20, P3045, DOI 10.1109/TMM.2018.2820910
   Yuan GZ, 2015, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2015.7299175
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Kai, 2017, C COMP VIS PATT REC
NR 38
TC 15
Z9 15
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 518
EP 528
DI 10.1016/j.jvcir.2018.06.025
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100045
OA Green Published
DA 2024-07-18
ER

PT J
AU Jin, LH
   Liu, H
   Zhang, WH
   Song, EM
AF Jin, Lianghai
   Liu, Hong
   Zhang, Wenhua
   Song, Enmin
TI Video oriented filter for impulse noise reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video denoising; Window-adaptive filter; Orientation estimation; Impulse
   noise
ID MEDIAN FILTER; COLOR IMAGES; REMOVAL; SEQUENCES; SPARSE
AB A window-adaptive video filter for removal of impulse noise from grayscale videos is proposed. The new method is based on local orientation estimation. The dominant orientation of the pattern in a local spatial neighborhood is computed by minimizing an expression of directional derivatives, and at the same time the orientation strength is also computed. Based on the local spatial orientation and its strength, the size, shape, and orientation of 3D filter window are adaptively determined, which leads to the proposed window-adaptive 3D median filter. To further enhance denoising performance, a new noise detection mechanism is developed and integrated to the proposed video filter. By using this noise detector, video pixels are classified into noise-free and noisy ones. For the noisy pixels detected, the proposed window-adaptive 3D filter is performed. Experimental results show that the proposed method outperforms other state-of-the-art video denoising methods in both objective measure and visual evaluation.
C1 [Jin, Lianghai; Liu, Hong; Zhang, Wenhua; Song, Enmin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Liu, H (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM hust.hongliu@gmail.com
FU National Natural Science Foundation of China [61370181, 61370179]
FX The authors would like to thank Dr. Kyong Hwan Jin for providing the
   code of ALOHA algorithm [25]. This work is supported by the National
   Natural Science Foundation of China (61370181 and 61370179).
CR Ali RA, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0177-2
   Balster EJ, 2006, IEEE T CIRC SYST VID, V16, P220, DOI 10.1109/TCSVT.2005.857816
   Bhateja V, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P716, DOI 10.1109/SPIN.2014.6777048
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Buades A, 2016, IEEE T IMAGE PROCESS, V25, P2573, DOI 10.1109/TIP.2016.2551639
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dabov Kostadin, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P145
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   El Hassouni M, 2006, IEEE T IMAGE PROCESS, V15, P572, DOI 10.1109/TIP.2005.863039
   Gupta V, 2015, J VIS COMMUN IMAGE R, V26, P296, DOI 10.1016/j.jvcir.2014.10.004
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jin KH, 2018, IEEE T IMAGE PROCESS, V27, P1448, DOI 10.1109/TIP.2017.2771471
   Jin LH, 2017, J VIS COMMUN IMAGE R, V48, P54, DOI 10.1016/j.jvcir.2017.05.012
   Jin LH, 2013, IEEE T CIRC SYST VID, V23, P741, DOI 10.1109/TCSVT.2012.2207272
   Jin LH, 2012, PATTERN RECOGN, V45, P4300, DOI 10.1016/j.patcog.2012.06.003
   Jin LH, 2011, SIGNAL PROCESS, V91, P1249, DOI 10.1016/j.sigpro.2010.12.011
   Kang CC, 2009, SIGNAL PROCESS, V89, P344, DOI 10.1016/j.sigpro.2008.09.003
   Kim JS, 2001, SIGNAL PROCESS-IMAGE, V16, P657, DOI 10.1016/S0923-5965(00)00043-6
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Latha P., 2014, Journal of Theoretical and Applied Information Technology, V64, P22
   Liu C, 2010, LECT NOTES COMPUT SC, V6313, P706
   Lukac R., 2001, EURASIP Journal on Applied Signal Processing, V2001, P110, DOI 10.1155/S1110865701000099
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324
   Mélange T, 2011, IMAGE VISION COMPUT, V29, P407, DOI 10.1016/j.imavis.2011.01.005
   NIEMINEN A, 1987, IEEE T PATTERN ANAL, V9, P74, DOI 10.1109/TPAMI.1987.4767873
   Rahman SMM, 2007, IEEE T CIRC SYST VID, V17, P187, DOI 10.1109/TCSVT.2006.887079
   Rosales-Silva AJ, 2012, J VIS COMMUN IMAGE R, V23, P143, DOI 10.1016/j.jvcir.2011.09.007
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Varghese G, 2010, IEEE T CIRC SYST VID, V20, P1032, DOI 10.1109/TCSVT.2010.2051366
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Xu BH, 2016, MULTIMED TOOLS APPL, V75, P2681, DOI 10.1007/s11042-015-2545-1
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Yu SG, 2010, IEEE T CIRC SYST VID, V20, P780, DOI 10.1109/TCSVT.2010.2045806
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 40
TC 0
Z9 0
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 1
EP 11
DI 10.1016/j.jvcir.2018.05.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100001
DA 2024-07-18
ER

PT J
AU Zhang, SJ
   Shen, L
   Zhan, RY
   Yang, YH
   Zhang, YQ
AF Zhang, Shujun
   Shen, Li
   Zhan, Ruoyi
   Yang, Yihan
   Zhang, Youqian
TI Robust eye detection using deeply-learned gaze shifting path
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eye detection; Gaze shifting path; Deep feature
ID OBJECT DETECTION; FEATURES
AB Eye detection is a very useful technique in many intelligent applications. Since the importance of eyes to human beings, eye detection technique is an indispensable component in intelligent systems, e.g., emotional analysis, iris detection and gaze estimation. Recently, there have been proposed a large number of methods for eye detection, wherein good performances have been achieved. But these methods cannot take human visual perception into account, that is to say, human beings will first pay attention to the eyes when they are communicating with each other, and then nose, then mouth. In addition, their geometric positions are almost fixed, i.e., eyes are above the nose and mouth, and eyes are on both sides of the nose. So in our work, a novel method for eye detection is proposed using human visual perception. More specifically, we first derive object patches from a large quantity of training images. Then, a geometry-preserved object patches ranking method is designed to effectively mimic human visual mechanism when human beings are communicating with each other. After that, these ordered object patches will be fed into CNN to extract patch-level deep features, then patch-level deep features will be represented by deep representations. Finally, eye detection can be achieved using learned deep representation. Experimental results on different database show that our method can achieve high efficiency and accuracy of eye detection.
C1 [Zhang, Shujun] State Grid Zhejiang Elect Power Co Ltd, Hangzhou, Zhejiang, Peoples R China.
   [Shen, Li] State Grid Hangzhou Power Supply Co, Mkt Dept, Hangzhou, Zhejiang, Peoples R China.
   [Zhan, Ruoyi] State Grid Hangzhou Power Supply Co, Regulat & Control Ctr, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Yihan; Zhang, Youqian] Guizhou Univ, Sch Elect Engn, Guiyang, Guizhou, Peoples R China.
C3 State Grid Corporation of China; Guizhou University
RP Zhang, SJ (corresponding author), State Grid Zhejiang Elect Power Co Ltd, Hangzhou, Zhejiang, Peoples R China.
EM 2570057957@qq.com
RI 章, 述军/HJZ-0859-2023
OI 章, 述军/0000-0002-9103-7671
CR [Anonymous], 2016, ARXIV161001708
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P1460, DOI 10.1109/TSMCB.2010.2040078
   Sun L, 2014, IEEE MULTIMEDIA, V21, P28, DOI 10.1109/MMUL.2014.54
   Sun X, 2018, INFORM SCIENCES, V429, P37, DOI 10.1016/j.ins.2017.10.051
   Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008
   Wu X., 2015, 2015 IEEE C IEEE COM, V4
   Xia YJ, 2017, IEEE T MULTIMEDIA, V19, P1811, DOI 10.1109/TMM.2017.2679900
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
NR 26
TC 1
Z9 1
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 654
EP 659
DI 10.1016/j.jvcir.2018.07.013
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100056
DA 2024-07-18
ER

PT J
AU Shen, XB
   Yuan, YH
   Shen, FM
   Xu, Y
   Sun, QS
AF Shen, Xiaobo
   Yuan, Yun-Hao
   Shen, Fumin
   Xu, Yang
   Sun, Quan-Sen
TI A novel multi-view dimensionality reduction and recognition framework
   with applications to face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view learning; Canonical correlations; Dimensionality reduction;
   Face recognition
ID CANONICAL CORRELATION-ANALYSIS; PRESERVING PROJECTIONS;
   FEATURE-EXTRACTION; FEATURE FUSION; VECTOR; FORMULATION; EXTENSIONS;
   SIGNAL
AB Multi-view data with each view corresponding to a type of feature generally provides more comprehensive information. Learning from multi-view data is a challenging research topic in pattern recognition. For recognition task, most multi-view learning methods separately learn multi-view dimensionality reduction (MvDR) and classification models. Thus, the connection between the two models has not been well studied. In this paper, we propose a novel multi-view dimensionality reduction and recognition framework, which can establish the connection between MvDR and classification. Specifically, a multi-view dimensionality reduction method, termed as sparse representation regularized multiset canonical correlation analysis ((SRMCC)-M-2) is first proposed. (SRMCC)-M-2 considers both correlation and sparse discrimination among multiple views. In accord with (SRMCC)-M-2, a classifier, called multi-view sparse representation based classifier (MvSRC) is further developed. MvSRC performs classification by comparing the reconstruction residuals of different classes among all views. An efficient iterative algorithm is proposed to solve the proposed model. Extensive experiments on the AR, CMU PIE, FERET, and FRGC datasets demonstrate that the proposed framework can achieve superior recognition performance than several state-of-the-art methods.
C1 [Shen, Xiaobo] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Shen, Xiaobo; Xu, Yang; Sun, Quan-Sen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Yuan, Yun-Hao] Yangzhou Univ, Dept Comp Sci & Technol, Yangzhou, Jiangsu, Peoples R China.
   [Shen, Fumin] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
C3 Nanyang Technological University; Nanjing University of Science &
   Technology; Yangzhou University; University of Electronic Science &
   Technology of China
RP Shen, XB (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM njust.shenxiaobo@gmail.com; yyhzbh@163.com; fumin.shen@gmail.com;
   xuyangth90@gmail.com; sunquansen@njust.edu.cn
RI xu, yang/HOC-0456-2023
OI Shen, Xiaobo/0000-0001-8655-1265; Shen, Xiaobo/0000-0001-8494-4532
FU National Science Foundation of China [61673220, 61402203]
FX This work is supported by the National Science Foundation of China
   (Grant Nos. 61673220, 61402203).
CR [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 2007, 0749 U MASS
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Chu DL, 2013, IEEE T PATTERN ANAL, V35, P3050, DOI 10.1109/TPAMI.2013.104
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Diethe T., 2008, NIPS WORKSH LEARN MU
   Farquhar J.D. R., 2005, NIPS
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hou CP, 2010, PATTERN RECOGN, V43, P720, DOI 10.1016/j.patcog.2009.07.015
   Jing XY, 2011, SIGNAL PROCESS, V91, P2132, DOI 10.1016/j.sigpro.2011.02.016
   Kan Meina, 2016, IEEE T PATTERN ANAL, V38
   Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342
   Shen XB, 2015, NEURAL PROCESS LETT, V42, P301, DOI 10.1007/s11063-014-9358-5
   Shen XB, 2014, J VIS COMMUN IMAGE R, V25, P1894, DOI 10.1016/j.jvcir.2014.09.004
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Shen Xiaobo, 2016, IEEE T CYBERNET
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Su Y, 2012, IEEE T IMAGE PROCESS, V21, P1381, DOI 10.1109/TIP.2011.2169972
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun YJ, 2017, INT J SENS NETW, V23, P258, DOI 10.1504/IJSNET.2017.083531
   Tian Q, 2017, NEUROCOMPUTING, V238, P286, DOI 10.1016/j.neucom.2017.01.064
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Tsang IW, 2005, J MACH LEARN RES, V6, P363
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xu C., 2013, ABS13045634 CORR
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang JA, 2011, PATTERN RECOGN, V44, P1387, DOI 10.1016/j.patcog.2011.01.009
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Yuan YH, 2014, PATTERN RECOGN, V47, P3907, DOI 10.1016/j.patcog.2014.06.016
   Yuan YH, 2014, IEEE T NEUR NET LEAR, V25, P1131, DOI 10.1109/TNNLS.2013.2288062
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
NR 53
TC 12
Z9 14
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 161
EP 170
DI 10.1016/j.jvcir.2018.03.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800015
OA Bronze
DA 2024-07-18
ER

PT J
AU Liu, Z
   Yu, L
   Sun, H
AF Liu, Zhou
   Yu, Lei
   Sun, Hong
TI Image restoration via Bayesian dictionary learning with nonlocal
   structured beta process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Nonparametric Bayesian; Beta process; Image restoration; Nonlocal
   structure prior; Dictionary learning
ID SPARSE REPRESENTATION; LOW-RANK; ALGORITHM
AB Nonparametric Bayesian dictionary learning has shown a powerful potential in image restoration. However, it still lacks exploiting image structure to improve the performance. In this work, we propose a sparse Bayesian dictionary learning framework with structure prior called nonlocal structured beta process factor analysis (NLS-BPFA) which connects nonlocal self-similarity and sparse Bayesian dictionary learning. A nonlocal structured beta process is proposed to introduce the nonlocal self-similarity as a structure prior for image denoising and inpainting. Unlike most of the existing image denoising methods, our proposed method does not need to know noise variance in advance like an unsupervised learning. The experimental results demonstrate the effectiveness of our proposed model.
C1 [Liu, Zhou; Yu, Lei; Sun, Hong] Wuhan Univ, Sch Elect Informat, Signal Proc Lab, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Yu, L (corresponding author), Wuhan Univ, Sch Elect Informat, Signal Proc Lab, Wuhan 430072, Hubei, Peoples R China.
EM liuzhou@whu.edu.cn; ly.wd@whu.edu.cn; hongsun@whu.edu.cn
FU NSFC [61401315]; Chinese Scholarship Council; SRF for ROCS, SEM [230303]
FX This work was supported by NSFC Grant 61401315, Chinese Scholarship
   Council and by the Project-sponsored by SRF for ROCS, SEM, under Grant
   230303.
CR [Anonymous], 2003, VARIATIONAL ALGORITH
   Babacan SD, 2014, IEEE T SIGNAL PROCES, V62, P2906, DOI 10.1109/TSP.2014.2319775
   Bishop C. M., 2006, PATTERN RECOGN, P542
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chatterjee P, 2009, IEEE T IMAGE PROCESS, V18, P1438, DOI 10.1109/TIP.2009.2018575
   Chen F, 2015, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2015.76
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   HJORT NL, 1990, ANN STAT, V18, P1259, DOI 10.1214/aos/1176347749
   Jacob L., 2009, P 26 ANN INT C MACH, P433, DOI DOI 10.1145/1553374.1553431
   Jia TT, 2016, J VIS COMMUN IMAGE R, V38, P461, DOI 10.1016/j.jvcir.2016.03.022
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Nejati M, 2016, J VIS COMMUN IMAGE R, V36, P28, DOI 10.1016/j.jvcir.2016.01.004
   Paisley J., 2009, P 26 ANN INT C MACH, P777
   Peyré G, 2011, EUR SIGNAL PR CONF, P303
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Yang SY, 2013, J VIS COMMUN IMAGE R, V24, P181, DOI 10.1016/j.jvcir.2012.07.011
   Yu L, 2015, SIGNAL PROCESS, V108, P259, DOI 10.1016/j.sigpro.2014.09.018
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang ZL, 2011, IEEE J-STSP, V5, P912, DOI 10.1109/JSTSP.2011.2159773
   Zhou M., 2009, NIPS
   ZHOU M., 2011, INT C ART INT STAT, P883
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
   Zhou YY, 2016, J VIS COMMUN IMAGE R, V41, P74, DOI 10.1016/j.jvcir.2016.09.007
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 35
TC 9
Z9 9
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 159
EP 169
DI 10.1016/j.jvcir.2018.02.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300016
DA 2024-07-18
ER

PT J
AU Czúni, L
   Rashad, M
AF Czuni, Laszlo
   Rashad, Metwally
TI The use of IMUs for video object retrieval in lightweight devices
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video object retrieval; View-centered retrieval; IMU; Camera sensor;
   Image recognition; Tracking; KD-Tree indexing
AB We introduce a new object retrieval approach where besides cameras, Inertial Measurement Unit (IMU) sensors are used for the retrieval of 3D objects. Contrary to computationally intensive deep learning recognition and retrieval solutions we focus on lightweight methods which could be utilized in handheld devices and autonomous systems equipped with moderate computing power and memory. We use fast and robust compact image descriptors and the relative orientation of the camera to build multi-view centered retrieval object models. As for retrieval the Hough transformation paradigm is used to evaluate the results of queries applied on several frames of a video. We analyze the performance of our lightweight approach on several test datasets and with different comparisons, including automatic tracking for the generation of queries. These experiments show the advantages of our proposed techniques since retrieval rate could be significantly increased. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Czuni, Laszlo; Rashad, Metwally] Univ Pannonia, Egyet U 10, Veszprem, Hungary.
C3 University of Pannonia
RP Czúni, L (corresponding author), Univ Pannonia, Egyet U 10, Veszprem, Hungary.
EM czuni@almos.vein.hu
RI Rashad, Metwally/KHX-9454-2024; Rashad, Magdi/V-5145-2019
OI Rashad, Magdi/0000-0002-1826-9791
FU Hungarian Research Fund [OTKA K 120367]; Szchenyi
   [EFOP-3.6.1-16-2016-00015]
FX The work and publication of results have been supported by the Hungarian
   Research Fund, grant OTKA K 120367 and by Szchenyi 2020 under
   EFOP-3.6.1-16-2016-00015.
CR Ahmad N., 2013, INT J SIGNAL PROCESS, V1, P256, DOI [DOI 10.12720/IJSPS.1.2.256-262, 10.12720/ijsps.1.2.256-262]
   [Anonymous], SYMBOLIC PROJECTION
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P 14 ANN ACM INT C M
   [Anonymous], 6 INT C SIGN PROC PA
   [Anonymous], TECHNICAL REPORT
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], 1999, P WORKSH VIS ALG THE
   [Anonymous], INT WORKSH COMP INT
   [Anonymous], 7 INT C ICT KNOWL EN
   [Anonymous], 7 IEEE INT C
   Basri Ronen., 1993, Handbook of pattern recognition and computer vision, P863
   Bruno Alessandro, 2014, 3rd International Conference on Pattern Recognition Applications and Methods (ICPRAM 2014). Proceedings, P662
   BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60
   Chan-Hon-Tong A, 2013, LECT NOTES COMPUT SC, V8156, P51
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Czuni L., 2016, INT C SYSTEMS SIGNAL, P1
   Czúni L, 2014, IEEE IMAGE PROC, P3426, DOI 10.1109/ICIP.2014.7025695
   Exner D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P9
   Fang F, 2005, NEURON, V45, P793, DOI 10.1016/j.neuron.2005.01.037
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Gall J., 2013, Decision Forests for Computer Vision and Medical Image Analysis, P143
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Gammeter S., 2010, CVPR Workshops, P1
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hol JD, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1857, DOI 10.1109/ICARCV.2008.4795810
   Javed N, 2004, IEEE IMAGE PROC, P2713
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Miksik O, 2012, INT C PATT RECOG, P2681
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Torr P H S, 1999, Vision Algorithms: Theory and Practice, P278, DOI DOI 10.1007/3-540-44480-7_19
NR 33
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 30
EP 42
DI 10.1016/j.jvcir.2017.06.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700003
DA 2024-07-18
ER

PT J
AU Ferrara, P
   Piva, A
   Argenti, F
   Kusuno, J
   Niccolini, M
   Ragaglia, M
   Uccheddu, F
AF Ferrara, Pasquale
   Piva, Alessandro
   Argenti, Fabrizio
   Kusuno, Junya
   Niccolini, Marta
   Ragaglia, Matteo
   Uccheddu, Francesca
TI Wide-angle and long-range real time pose estimation: A comparison
   between monocular and stereo vision systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vision systems; Visual tracking; Target detection; Monocular vision
   system; Stereo vision systems; Pose estimation
AB In this work, a comparison of the performances of a stereo and a monocular vision system for the 3D pose estimation of a planar target in very challenging conditions is presented. In particular, the systems have been designed to detect in real tithe a target moving with a maximum speed of 1 m/s, in a range of distances from 0.5 to 4 m from the cameras, with an accuracy of less than 1 cm (referred to the estimation of the real world coordinates) and with a field of view of 80 deg. A theoretical evaluation and experimental results to assess the performance of the proposed systems are presented. Our analysis demonstrates the good accuracy in terms of target position estimation of the presented approaches not only for close range applications, but also for mid-to-long range ones. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Ferrara, Pasquale; Piva, Alessandro; Argenti, Fabrizio; Uccheddu, Francesca] Univ Florence, Dept Informat Engn, Florence, Italy.
   [Kusuno, Junya] Yanmar Co Ltd, Res & Dev Unit, Osaka, Osaka, Japan.
   [Niccolini, Marta; Ragaglia, Matteo] Yanmar R&D Europe, Florence, Italy.
C3 University of Florence
RP Uccheddu, F (corresponding author), Univ Florence, Dept Informat Engn, Florence, Italy.
EM francesca.uccheddu@unin.it
RI Piva, Alessandro/B-8948-2008; Uccheddu, Francesca/J-5124-2012
OI Ragaglia, Matteo/0000-0002-7216-3664; Argenti,
   Fabrizio/0000-0001-7776-4015; Ferrara, Pasquale/0000-0002-2651-6211
FU Yanmar Research & Development Europe, Florence (Italy)
FX The authors would like to thank the reviewers for their constructive
   comments that helped them to improve the quality of the original
   submission. The research leading to these results has received funding
   from Yanmar Research & Development Europe, Viale Galileo 3/A, 50125
   Florence (Italy).
CR [Anonymous], 2003, DICTA, DOI [10.1177/0734242X0302100404, DOI 10.1177/0734242X0302100404]
   [Anonymous], 1977, TECHNIQUES AUTOMATIC
   [Anonymous], IMPLEMENTATION SHITO
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Craig JJ., 1986, INTRO ROBOTICS MECH
   Diaz-Cabrera M, 2015, EXPERT SYST APPL, V42, P3911, DOI 10.1016/j.eswa.2014.12.037
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li X, 2016, IEEE T PATTERN ANAL, V38, P931, DOI 10.1109/TPAMI.2015.2469276
   Li Xueyi, 2013, ScientificWorldJournal, V2013, P624512, DOI 10.1155/2013/624512
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mosberger R, 2013, IEEE INT CONF ROBOT, P5850, DOI 10.1109/ICRA.2013.6631419
   Rufli M, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3121, DOI 10.1109/IROS.2008.4650703
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Sinha P.K., 2012, Image acquisition and preprocessing for machine vision systems
   Tippetts B, 2016, J REAL-TIME IMAGE PR, V11, P5, DOI 10.1007/s11554-012-0313-2
   Velez G, 2015, J REAL-TIME IMAGE PR, V10, P725, DOI 10.1007/s11554-014-0412-3
   Wang WX, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 2, PROCEEDINGS, P559, DOI 10.1109/IITA.2009.439
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao LM, 2015, AAAI CONF ARTIF INTE, P3864
NR 25
TC 20
Z9 21
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 159
EP 168
DI 10.1016/j.jvcir.2017.06.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700013
DA 2024-07-18
ER

PT J
AU Farhi, L
   Yusuf, A
   Raza, RH
AF Farhi, Lubna
   Yusuf, Adeel
   Raza, Rana Hammad
TI Adaptive stochastic segmentation via energy-convergence for brain tumor
   in MR images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active contours; Level set; Statistical energies; Stochastic
   segmentation; MR images
ID REGION COMPETITION; LEVEL; FRAMEWORK; TRACKING
AB An adaptive algorithm that formulates an energy based stochastic segmentation with a level set methodology is proposed.The hybrid method uses global and local energies, which are efficient in matching, segmenting and tracing anatomic structures by exploiting constraints computed from the data of the image. The algorithm performs autonomous stochastic segmentation of tumor in Magnetic Resonance Imaging (MRI) by combining region based level sets globally and three established energies (uniform, separation and histogram) in a local framework. The local region is defined by the segmentation boundary which, in the case of level set method, consists of global statistics and local energies of every individual point and the local region is then updated by minimizing (or maximizing) the energies. For analysis, the algorithm is tested on low grade and high grade MR images dataset. The obtained results show that the proposed methodology provides similarity between segmented and truth image up to 89.5% by dice method, and minimum distance of 0.5(mm) by Hausdorff algorithm. This adaptive stochastic segmentation algorithm can also be used to compute segmentation when binary thresholding level is greater than 0.2. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Farhi, Lubna; Yusuf, Adeel; Raza, Rana Hammad] Natl Univ Sci & Technol, PNEC, Dept Elect & Power Engn, Karachi, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Farhi, L (corresponding author), Natl Univ Sci & Technol, PNEC, Dept Elect & Power Engn, Karachi, Pakistan.
EM lubna.farhi@pnec.nust.edu.pk; adeel@pnec.nust.edu;
   hammad@pnec.nust.edu.pk
CR [Anonymous], 2012, International Journal of Scientific & Engineering Research
   [Anonymous], 2006, Geometric partial differential equations and image analysis
   [Anonymous], 2014, INT J ENG RES TECHNO
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang CJ, 2004, INT J PATTERN RECOGN, V18, P101, DOI 10.1142/S0218001404003071
   Farhi L., 2017, IASTED INT C INNSBR
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Lee CH, 2005, LECT NOTES COMPUT SC, V3765, P469
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mansouri AR, 2003, IEEE T IMAGE PROCESS, V12, P201, DOI 10.1109/TIP.2002.807582
   Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621
   MICCAI, BRATS2012 DAT
   Osher S.J., 2002, APPL MATH SCI, V153
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Tsai R., 2003, Commun. Math. Sci., V1, P623, DOI DOI 10.4310/CMS.2003.V1.N4.AL
   Valipour M, 2016, AGRICULTURE-BASEL, V6, DOI 10.3390/agriculture6040053
   Valipour M, 2016, METEOROL APPL, V23, P91, DOI 10.1002/met.1533
   Wang Y, 2011, ADV MATER RES-SWITZ, V219-220, P1342, DOI 10.4028/www.scientific.net/AMR.219-220.1342
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhang T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1056, DOI 10.1109/ICCV.2003.1238466
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 22
TC 21
Z9 21
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 303
EP 311
DI 10.1016/j.jvcir.2017.04.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500027
DA 2024-07-18
ER

PT J
AU Ahmad, J
   Mehmood, I
   Baik, SW
AF Ahmad, Jamil
   Mehmood, Irfan
   Baik, Sung Wook
TI Efficient object-based surveillance image search using spatial pooling
   of convolutional features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Surveillance image search; Surveillance network; Features extraction;
   Convolutional features
ID RETRIEVAL
AB Modern surveillance networks are large collections of computational sensor nodes, where each node can be programmed to capture, prioritize, segment salient objects, and transmit them to central repositories for indexing. Visual data from such networks grow exponentially and present many challenges concerning their transmission, storage, and retrieval. Searching for particular surveillance objects is a common but challenging task. In this paper, we present an efficient features extraction framework which utilizes an optimal subset of kernels from the first layer of a convolutional neural network pre-trained on ImageNet dataset for object-based surveillance image search. The input image is convolved with the set of kernels to generate feature maps, which are aggregated into a single feature map using a novel spatial maximal activator pooling approach. A low-dimensional feature vector is computed to represent surveillance objects. The proposed system provides improvements in both performance and efficiency over other similar approaches for surveillance datasets. (C) 2017 Published by Elsevier Inc.
C1 [Ahmad, Jamil; Mehmood, Irfan; Baik, Sung Wook] Sejong Univ, Digital Contents Res Inst, Coll Elect & Informat Engn, Seoul, South Korea.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Digital Contents Res Inst, Coll Elect & Informat Engn, Seoul, South Korea.
EM jamilahmad@sju.ac.kr; irfan@sejong.ac.kr; sbaik@sejong.ac.kr
RI Baik, Sung Wook/AAR-8236-2020; Ahmad, Jamil/H-6264-2019
OI Ahmad, Jamil/0000-0001-8407-5971; Baik, Sung Wook/0000-0002-6678-7788;
   Mehmood, Irfan/0000-0001-7864-957X
FU National Research Foundation of Korea (NRF) - Korea Government (MSIP)
   [2016R1A2B4011712]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MSIP) (No.
   2016R1A2B4011712).
CR Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], 2008, P 6 ACM C EMB NETW S
   [Anonymous], 2011, P 2011 JOINT ACM WOR
   [Anonymous], 2011, BMVC
   [Anonymous], 2009, Construction and Analysis of a Large Scale Image Ontology
   [Anonymous], PROG ELECTROMAGN R B
   Arróspide J, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-2
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Glasner D, 2012, IMAGE VISION COMPUT, V30, P923, DOI 10.1016/j.imavis.2012.09.006
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maia G, 2013, AD HOC NETW, V11, P1588, DOI 10.1016/j.adhoc.2013.01.004
   Mehmood I, 2015, INFORM FUSION, V24, P16, DOI 10.1016/j.inffus.2014.07.002
   Milovanovic S, 2012, LECT NOTES COMPUT SC, V7363, P449, DOI 10.1007/978-3-642-31638-8_34
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Sulic V, 2011, IEEE T CIRC SYST VID, V21, P903, DOI 10.1109/TCSVT.2011.2133330
   Tao H, 2007, 10 INT WORKSH PERF E
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
NR 29
TC 17
Z9 18
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 62
EP 76
DI 10.1016/j.jvcir.2017.02.010
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100006
DA 2024-07-18
ER

PT J
AU Unde, AS
   Deepthi, PP
AF Unde, Amit Satish
   Deepthi, P. P.
TI Block compressive sensing: Individual and joint reconstruction of
   correlated images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Joint sparsity model; Joint reconstruction;
   Correlation model
ID PARALLEL FRAMEWORK; SIGNAL RECOVERY
AB Compressive sensing provides simultaneous sensing and compression of data. Block compressive sensing (BCS) of images has gained a prominence in recent years due to low encoding complexity. In this paper, we propose the reconstruction algorithm for BCS framework based on iterative re-weighted 11 norm minimization. In the proposed algorithm, the desired signal sparsity is achieved using 1.1 norm minimization while Wiener filtering is incorporated as the smoothing operator. We also propose block based joint reconstruction algorithm for correlated images and video frames. The correlation is captured through the joint sparsity model by minimizing the objective function which promotes the common sparsity structure. The performance of proposed algorithms is tested on different stereo images and video data. Our analysis shows that the proposed individual reconstruction algorithm gives good compression performance as compared to existing schemes. Extensive analysis on correlated images demonstrates that the proposed joint reconstruction algorithm outperforms individual reconstruction algorithms. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Unde, Amit Satish; Deepthi, P. P.] Natl Inst Technol, Dept Elect & Commun Engn, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Unde, AS (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Calicut, Kerala, India.
EM amitsunde@gmail.com
RI Unde, Amit/AAG-5426-2021
OI Unde, Amit/0000-0002-3874-1272
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2006, IPSN 2006: THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P177
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   George SN, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0085-9
   Li X, 2010, ELECTRON LETT, V46, P1548, DOI 10.1049/el.2010.2325
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Park JY, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-37
   Thirumalai V, 2012, IEEE T IMAGE PROCESS, V21, P3206, DOI 10.1109/TIP.2012.2188035
   Trocan M, 2010, IEEE IMAGE PROC, P3345, DOI 10.1109/ICIP.2010.5652767
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 23
TC 29
Z9 32
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 187
EP 197
DI 10.1016/j.jvcir.2017.01.028
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600016
DA 2024-07-18
ER

PT J
AU Wen, Y
   Li, Y
   Zhang, XH
   Shi, WZ
   Wang, L
   Chen, JW
AF Wen, Yang
   Li, Ying
   Zhang, Xiaohua
   Shi, Wuzhen
   Wang, Lin
   Chen, Jiawei
TI A weighted full-reference image quality assessment based on visual
   saliency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual saliency computation; Weighted image quality assessment; Human
   visual system
ID INFORMATION
AB In full reference image quality assessment (IQA), the images without distortion are usually employed as reference, while the structures in both reference images and distorted images are ignored and all pixels are equally treated. In addition, the role of human visual system (HVS) is not taken account into subjective IQA metric. In this paper, a weighted full-reference image quality metric is proposed, where a weight imposed on each pixel indicates its importance in IQA. Furthermore, the weights can be estimated via visual saliency computation, which can approximate the subjective IQA via exploiting the HVS. In the experiments, the proposed metric is compared with several objective IQA metrics on LIVE release 2 and TID 2008 database. The results demonstrate that SROCC and PLCC of the proposed metric are 0.9647 and 0.9721, respectively,which are higher than other methods and it only takes 427.5 s, which is lower than that of most other methods.(C) 2016 Elsevier Inc. All rights reserved.
C1 [Wen, Yang; Li, Ying] Shangluo Univ, Sch Elect Informat & Elect Engn, Shangluo 726000, Peoples R China.
   [Zhang, Xiaohua; Chen, Jiawei] Xidian Univ, Int Res Ctr Intelligent Percept & Computat,Minist, Int Collaborat Joint Lab Intelligent Percept & Co, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Shi, Wuzhen] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Wang, Lin] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
C3 Shangluo University; Xidian University; Harbin Institute of Technology;
   Northwest University Xi'an
RP Chen, JW (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat,Minist, Int Collaborat Joint Lab Intelligent Percept & Co, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM jawaechan@gmail.com
FU National Natural Science Foundation of China [61403305, 61503300];
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China [20136118120005]; Natural Science Foundation of Shaanxi
   Province of China [2014JQ8327]; Research Program of Shangluo University
   [16SKY001]
FX This work was supported by National Natural Science Foundation of China
   (Nos. 61403305, 61503300), Specialized Research Fund for the Doctoral
   Program of Higher Education of China (No. 20136118120005), Natural
   Science Foundation of Shaanxi Province of China (No. 2014JQ8327) and the
   Research Program of Shangluo University (No. 16SKY001).
CR [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Cadík M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366166
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Isono K., 2013, 2013 IEEE INT C IEEE, P1, DOI [10.1109/TENCON.2013.6719032, DOI 10.1109/TENCON.2013.6719032]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Khasraghi MM, 2015, ARCH AGRON SOIL SCI, V61, P929, DOI 10.1080/03650340.2014.981163
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Scharr H., 2000, Ph.D. thesis,
   Sheikh H., 2005, LIVE IMAGE QUAL ASSE, V2
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Valipour Mohammad, 2015, International Journal of Hydrology Science and Technology, V5, P51, DOI 10.1504/IJHST.2015.069279
   Valipour M., 2012, Journal of Agricultural Science (Toronto), V4, P125
   Valipour M, 2016, METEOROL APPL, V23, P91, DOI 10.1002/met.1533
   Valipour M, 2013, J HYDROL, V476, P433, DOI 10.1016/j.jhydrol.2012.11.017
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yamamoto L., 1997, P EXPERT ATM TRAFF S
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116312
NR 31
TC 17
Z9 20
U1 1
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 119
EP 126
DI 10.1016/j.jvcir.2016.12.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400012
DA 2024-07-18
ER

PT J
AU Guo, XM
   Jiang, G
   Cui, ZP
   Tao, P
AF Guo, Xiaoming
   Jiang, Guang
   Cui, Zhaopeng
   Tao, Pei
TI Homography-based block motion estimation for video coding of PTZ cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Homography; Motion estimation; Adaptive thresholds; Video coding; PTZ
   cameras
ID SEARCH ALGORITHM; PATTERN
AB Due to the constrained movement of pan-tilt-zoom (PTZ) cameras, two frames in the video sequences captured by such cameras can be geometrically related by a relationship (homography). This geometric relationship is helpful for reducing the spatial redundancy in video coding. In this paper, by exploiting the homography between two frames with optical flow tracking algorithm, we propose a novel homography-based search (HBS) algorithm for block motion estimation in coding the sequences captured by PTZ cameras. In addition, adaptive thresholds are adopted in our method to classify different kinds of blocks. Compared with other traditional fast algorithms, the proposed HBS algorithm is proved to be more efficient for the sequences captured by PTZ cameras. And compared to our previous work in ICME (Cui et al., 2011), which only deals with pan-tilt (PT) camera and calculates the homography with mechanical devices, in this extended work we compute the homography by using information on images instead. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Guo, Xiaoming; Jiang, Guang; Cui, Zhaopeng; Tao, Pei] Xidian Univ, Sch Telecommun Engn, ISN Natl Key Lab, Xian, Peoples R China.
C3 Xidian University
RP Jiang, G (corresponding author), Xidian Univ, Sch Telecommun Engn, ISN Natl Key Lab, Xian, Peoples R China.
EM xdxiaomingguo@gmail.com; gjiang@mail.xidian.edu.cn; zhpcui@gmail.com;
   peitaoxidian@gmail.com
OI Jiang, Guang/0000-0001-9363-2012
FU Specialized Research Fund for State Key Laboratories [ISN03080004]; 111
   Project [B08038]; NSFC [60775020]
FX This work was supported by the Specialized Research Fund for State Key
   Laboratories (ISN03080004), the 111 Project (B08038) and the NSFC Grants
   (60775020).
CR [Anonymous], 1981, P NAT TEL C NEW ORL
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Braspenning R, 2004, PROC SPIE, V5308, P396, DOI 10.1117/12.525625
   Chen ZB, 2006, J VIS COMMUN IMAGE R, V17, P264, DOI 10.1016/j.jvcir.2004.12.002
   Cui Z.X., 2011, P 5 INT C UBIQUITOUS, P1, DOI [10.1145/1968613.1968706, DOI 10.1145/1968613.1968706]
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   HSIEH CH, 1990, ELECTRON LETT, V26, P276, DOI 10.1049/el:19900183
   Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Tsai JJ, 2009, IEEE T CIRC SYST VID, V19, P108, DOI 10.1109/TCSVT.2008.2009248
   Vincent E, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P182, DOI 10.1109/ISPA.2001.938625
   Yang JF, 2002, IEEE T CIRC SYST VID, V12, P948, DOI 10.1109/TCSVT.2002.804892
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 20
TC 4
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 164
EP 171
DI 10.1016/j.jvcir.2016.05.016
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900016
DA 2024-07-18
ER

PT J
AU Ospina-Borras, JE
   Restrepo, HDB
AF Ospina-Borras, J. E.
   Benitez Restrepo, Hernan Dario
TI Non-reference assessment of sharpness in blur/noise degraded images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Singular value decomposition; Gradient; Image sharpness; Image quality
   assessment
ID QUALITY ASSESSMENT; STATISTICS; BLUR
AB Image sharpness perception is not only affected by blur but also by noise. Noise effect on perceived image sharpness is a puzzling problem since image sharpness may increase, up to a certain amount of noise, on even regions when noise is added to an image. In this paper, we propose a NR perceived sharpness metric GSVD (Gradient Singular Value Decomposition), that shows to be effective in correlating with subjective quality evaluation of images affected by either blur or noise. This metric (i) requires no training on human image quality ratings, (ii) provides comparable performance with full reference (FR) peak signal to noise ratio (PSNR) and multiscale structural similarity (MSSIM), and (iii) performs better than most of the state-of-the-art NR sharpness metrics when assessing quality in blurry image sets and noisy image sets jointly. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ospina-Borras, J. E.; Benitez Restrepo, Hernan Dario] Pontificia Univ Javeriana, Secc Cali, Dept Elect & Ciencias Comp, Calle 18,118-250, Cali, Colombia.
C3 Pontificia Universidad Javeriana
RP Restrepo, HDB (corresponding author), Pontificia Univ Javeriana, Secc Cali, Dept Elect & Ciencias Comp, Calle 18,118-250, Cali, Colombia.
EM ospina.juanesteban@gmail.com; hbeni-tez@javerianacali.edu.co
FU COLCIENCIAS in the research project: Estimation of boron concentration
   in bamboo samples through Infrared Thermography
FX The authors acknowledge the financial support received by COLCIENCIAS in
   the research project: Estimation of boron concentration in bamboo
   samples through Infrared Thermography.
CR [Anonymous], IEEE SIGNAL PROC LET
   [Anonymous], 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119
   [Anonymous], ISRN SIGNAL PROCESS
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Bovik AC, 2013, P IEEE, V101, P2008, DOI 10.1109/JPROC.2013.2257632
   Cass S, 2014, IEEE Spectrum, V51, P68, DOI DOI 10.1109/MSPEC.2014.6840816
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Han H.-S., 2010, 2010 INT C CONS EL I
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mittal A., 2011, 45 AS C SIGN SYST CO
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad M. A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3093, DOI 10.1109/ICIP.2011.6116319
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   VQEG, 2000, FRTV PHAS 1 FIN REP
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wee CY, 2007, INFORM SCIENCES, V177, P2533, DOI 10.1016/j.ins.2006.12.023
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
NR 32
TC 7
Z9 10
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 142
EP 151
DI 10.1016/j.jvcir.2016.05.015
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900014
DA 2024-07-18
ER

PT J
AU Wong, CY
   Jiang, GN
   Rahman, MA
   Liu, SL
   Lin, SCF
   Kwok, N
   Shi, HY
   Yu, YH
   Wu, TH
AF Wong, Chin Yeow
   Jiang, Guannan
   Rahman, Md Arifur
   Liu, Shilong
   Lin, Stephen Ching-Feng
   Kwok, Ngaiming
   Shi, Haiyan
   Yu, Ying-Hao
   Wu, Tonghai
TI Histogram equalization and optimal profile compression based approach
   for colour image enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality improvement; Histogram equalization; Profile adaptation;
   Range stretching; Saturation restoration
ID CONTRAST ENHANCEMENT
AB Many vision based applications depend on images with sufficiently high contrast and colourfulness so that ample amount of information is available to accurately describe objects captured in an image scene. Poor image capturing conditions are often unavoidable but can be compensated. Approaches based on intensity histogram equalization are popular to increase the information content within an image but over-enhancement often results in the production of unwanted artefacts. Furthermore, when constrained to only an intensity-based enhancement, insufficient enrichment on colourfulness and saturation is often observed. In order to address these limitations concurrently, a pipelined approach that incorporates a colour channel stretching process, a histogram equalization step, a magnitude compression procedure, and a saturation maximization stage is proposed. Quantitative and qualitative results obtained from experiments on a wide variety of natural scene images demonstrate the effectiveness of the proposed approach over other methods at reducing artefact while increasing image contrast and colourfulness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wong, Chin Yeow; Jiang, Guannan; Rahman, Md Arifur; Liu, Shilong; Lin, Stephen Ching-Feng; Kwok, Ngaiming] Univ New S Wales, Sch Mech & Mfg Engn, Sydney, NSW 2052, Australia.
   [Shi, Haiyan] Shaoxing Univ, Sch Comp Sci & Technol, Shaoxing 312000, Zhejiang, Peoples R China.
   [Yu, Ying-Hao] Natl Chung Cheng Univ, Dept Elect Engn, 168 Univ Rd, Min Hsiung Township 621, Chiayi, Taiwan.
   [Kwok, Ngaiming; Wu, Tonghai] Xi An Jiao Tong Univ, Key Lab Modern Design & Rotor Bearing Syst, Minist, Xian 710049, Shaanxi, Peoples R China.
C3 University of New South Wales Sydney; Shaoxing University; National
   Chung Cheng University; Xi'an Jiaotong University
RP Kwok, N (corresponding author), Univ New S Wales, Sch Mech & Mfg Engn, Sydney, NSW 2052, Australia.; Kwok, N (corresponding author), Xi An Jiao Tong Univ, Key Lab Modern Design & Rotor Bearing Syst, Minist, Xian 710049, Shaanxi, Peoples R China.
EM chin.wong@student.unsw.edu.au; nmkwok@unsw.edu.au
RI liu, shilong/JZD-8395-2024; Kwok, Ngai Ming/F-1608-2011
OI Rahman, Md Arifur/0000-0001-8941-3685; Wu, Tonghai/0000-0003-1277-7848
CR Abdoli M, 2015, IET IMAGE PROCESS, V9, P569, DOI 10.1049/iet-ipr.2014.0583
   Babu P, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/265723
   Buzuloiu V, 2001, J ELECTRON IMAGING, V10, P445, DOI 10.1117/1.1353200
   Chang YC, 2010, IEEE T CONSUM ELECTR, V56, P737, DOI 10.1109/TCE.2010.5505995
   Chong E.K., 2013, An introduction to optimization, V76
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Khan MF, 2015, OPTIK, V126, P4868, DOI 10.1016/j.ijleo.2015.09.161
   Khan MF, 2014, OPTIK, V125, P1385, DOI 10.1016/j.ijleo.2013.08.005
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Kwok NM, 2011, COMPUT ELECTR ENG, V37, P681, DOI 10.1016/j.compeleceng.2011.08.002
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Poddar S, 2013, IET IMAGE PROCESS, V7, P641, DOI 10.1049/iet-ipr.2012.0507
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Su F, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/509597
   Sun ZB, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.053006
   Tiwari M, 2015, IET IMAGE PROCESS, V9, P80, DOI 10.1049/iet-ipr.2013.0778
   Wu TH, 2014, WEAR, V316, P19, DOI 10.1016/j.wear.2014.04.014
   Xu HL, 2015, OPT REV, V22, P246, DOI 10.1007/s10043-015-0073-x
   Yao Y., 2006, DEF SEC S
   Zhang GY, 2012, INT GEOSCI REMOTE SE, P4335, DOI 10.1109/IGARSS.2012.6351708
   Zhang H, 2013, OPTIK, V124, P5906, DOI 10.1016/j.ijleo.2013.04.046
   Zuo C, 2013, OPTIK, V124, P425, DOI 10.1016/j.ijleo.2011.12.057
NR 28
TC 55
Z9 62
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 802
EP 813
DI 10.1016/j.jvcir.2016.04.019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100067
DA 2024-07-18
ER

PT J
AU Ma, HR
   Li, L
   Liang, YQ
   Chen, JP
   Yin, J
AF Ma, Hongrun
   Li, Liang
   Liang, Yongquan
   Chen, Junpeng
   Yin, Jian
TI Efficient virtual network transmission using correlated equilibrium on
   Xen-based platform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Virtualization; Upgrade mechanism; Correlated equilibrium; Network
   transmission; Traffic data; Image delivering; Xen-based platform;
   Transmission efficiency
ID PARALLEL FRAMEWORK
AB In the study of upgrading large computer systems based on Xen-based platform, One key problem is about multimedia delivering on internal virtual network transmission. The upgrade efficiency has still been flat on current upgrade mechanism. Our goal is to solve the virtual network transmission problems, and make redesigned upgrade mechanism more efficient than the current one. In this paper, we focus on balancing multiple aspects of network traffic by adding coordination mechanisms along with correlated equilibrium, resulting in great internal virtual network transmission efficiency. The efficiency of the proposed method is validated in the test networks. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ma, Hongrun; Chen, Junpeng; Yin, Jian] Shandong Univ, Dept Comp, Weihai, Peoples R China.
   [Li, Liang] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Liang, Yongquan] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Jinan, Peoples R China.
C3 Shandong University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Shandong University of Science & Technology
RP Li, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.; Yin, J (corresponding author), Shandong Univ Sci & Technol, Jinan, Peoples R China.
EM liang.li@vipl.ict.ac.cn; jianyinsdu@126.com
OI Li, Liang/0000-0002-1943-8219
FU National Natural Science Foundation of China [61332016, 61402431,
   61472203]; China Postdoctoral Science Foundation
FX This work was supported in part by National Natural Science Foundation
   of China: 61332016, 61402431, and 61472203, in part by Project Funded by
   China Postdoctoral Science Foundation.
CR Abels T., 2005, DELL POWER SOLUT, V8, P109
   [Anonymous], 2003, ACM SIGOPS OPERATING
   AUMANN RJ, 1987, ECONOMETRICA, V55, P1, DOI 10.2307/1911154
   Aumann Robert J., 1974, Journal of mathematical Economics, V1, P67, DOI DOI 10.1016/0304-4068(74)90037-8
   Chang DW, 2007, SOFTWARE PRACT EXPER, V37, P1349, DOI 10.1002/spe.808
   CHEN B, 2009, VIRTUAL DISK IMAGE R, P43, DOI DOI 10.1109/NAS.2009.14
   Dias D, 2005, U. S. Patent Application, Patent No. [11/ 128,618[P]. 2005-5-13, 11128618]
   Dsouza R P, 2002, U. S. Patent, Patent No. [6,453,468[P]. 2002-9-17, 6453468]
   Dunlap G.W., 2009, Xen Summit Asia
   Fawcett P E, 1998, U. S. Patent, Patent No. [5,845,077[P]. 1998-12-1, 5845077]
   Fjellheim F., 2006, IEEE SOFTW ENG C AUS
   Fraser K., 2004, SAFE HARDWARE ACCESS
   Haibo Chen, 2006, VEE 2006. Proceedings of the Second International Conference on Virtual Execution Environments, P35
   HART S, 1989, MATH OPER RES, V14, P18, DOI 10.1287/moor.14.1.18
   Hesse F W, 1999, U. S. Patent, Patent No. [5,950,010[P]. 1999-9-7, 5950010]
   Hosek P, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P612, DOI 10.1109/ICSE.2013.6606607
   Jilesen J, 2006, 2006 PROCEEDINGS 10TH INTERSOCIETY CONFERENCE ON THERMAL AND THERMOMECHANICAL PHENOMENA IN ELECTRONICS SYSTEMS, VOLS 1 AND 2, P361
   Kejiang Ye, 2010, Proceedings of the 2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC 2010), P273, DOI 10.1109/HPCC.2010.79
   Li L, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2013.15
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Liu D, 2013, 2013 10TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P245, DOI 10.1109/ICCWAMTIP.2013.6716641
   Luu L, 1999, U. S. Patent, Patent No. [5,860,012[P]. 1999-1-12, 5860012]
   McGuire T D, 2002, U. S. Patent, Patent No. [6,493,871[P]. 2002-12-10, 6493871]
   Menon Aravind., 2005, Proceedings of the 1st ACM/USENIX international conference on Virtual execution environments, VEE '05, P13
   Murray D.G., 2008, P 4 ACM SIGPLAN SIGO
   Neyman A, 1997, INT J GAME THEORY, V26, P223, DOI 10.1007/BF01295851
   PAPADIMITRIOU C, COMPUTING CORRELATED
   Tamura Y., 2008, XEN SUMMIT 2008
   Tan J, 2007, PROCEEDINGS OF THE FIRST INTERNATIONAL SYMPOSIUM ON DATA, PRIVACY, AND E-COMMERCE, P421
   Wei W.K., 2003, IEEE COMP SOFTW APPL
   Xue H.-f., 2007, J SYSTEM SIMULATION, V23
   Yan C., 2014, ELECT LETT, V50
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yu J., 2012, VIRTUAL MACHINE REPL, P1
   ZHONG A, 2012, CLOUD GREEN COMPUTIN, P31, DOI DOI 10.1109/CGC.2012.115
NR 36
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 248
EP 256
DI 10.1016/j.jvcir.2015.12.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600022
DA 2024-07-18
ER

PT J
AU Razakarivony, S
   Jurie, F
AF Razakarivony, Sebastien
   Jurie, Frederic
TI Vehicle detection in aerial imagery : A small target detection benchmark
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Detection; Low resolution images; Vehicles; Database; Aerial imagery;
   Infrared imagery; Target detection; Computer vision
ID OBJECT; RECOGNITION; SEGMENTATION; PEDESTRIANS; DATABASE; SCALE
AB This paper introduces VEDAI: Vehicle Detection in Aerial Imagery a new database of aerial images provided as a tool to benchmark automatic target recognition algorithms in unconstrained environments. The vehicles contained in the database, in addition of being small, exhibit different variabilities such as multiple orientations, lighting/shadowing changes, specularities or occlusions. Furthermore, each image is available in several spectral bands and resolutions. A precise experimental protocol is also given, ensuring that the experimental results obtained by different people can be properly reproduce and compared. Finally, the paper also gives the performance of baseline algorithms on this dataset, for different settings of these algorithms, to illustrate the difficulties of the task and provide baseline comparisons. (c) 2015 Elsevier Inc. All rights reserved.
C1 [Razakarivony, Sebastien] Safran, 1 Rue Genevive Aube, F-78114 Magny Les Hameaux, France.
   [Razakarivony, Sebastien; Jurie, Frederic] Univ Caen, CNRS UMR 6602, ENSICAEN, F-14000 Caen, France.
C3 Safran S.A.; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Engineering & Systems Sciences (INSIS); Universite de Caen
   Normandie
RP Razakarivony, S (corresponding author), Safran, 1 Rue Genevive Aube, F-78114 Magny Les Hameaux, France.
EM sebastien.razakarivony@safran.fr
FU ANRT through the CIFRE sponsorship [2011/0850]; SAGEM-SAFRAN group
FX This work was supported by ANRT through the CIFRE sponsorship No
   2011/0850 and by SAGEM-SAFRAN group.
CR Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2009, BMVC
   [Anonymous], CLUSTERING MEANS MED
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 1999, REPOSIT TU DORTMUND, DOI DOI 10.17877/DE290R-5098
   [Anonymous], 2004, ECCV
   [Anonymous], 2010 IEEE 39 APPL IM
   [Anonymous], 2010, Fddb: A benchmark for face detection in unconstrained settings
   [Anonymous], ARXIV14036382
   [Anonymous], 2006, Toward Category-Level Object Recognition
   [Anonymous], ROBUST REAL TIME FAC
   [Anonymous], EXPT STUDY PEDESTRIA
   BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   Carbonetto P, 2008, INT J COMPUT VISION, V77, P219, DOI 10.1007/s11263-007-0067-7
   Cheng HY, 2012, IEEE T IMAGE PROCESS, V21, P2152, DOI 10.1109/TIP.2011.2172798
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divvala SK, 2012, LECT NOTES COMPUT SC, V7585, P31, DOI 10.1007/978-3-642-33885-4_4
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2
   Forsyth, 2005, ADV NEURAL INFORM PR, V17, P137
   Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740
   Gleason J, 2011, IEEE INT CONF ROBOT, P2065
   Gu CH, 2012, LECT NOTES COMPUT SC, V7575, P445, DOI 10.1007/978-3-642-33765-9_32
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791
   Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909
   Kembhavi A, 2011, IEEE T PATTERN ANAL, V33, P1250, DOI 10.1109/TPAMI.2010.182
   Lampert C., 2008, Computer Vision and Pattern Recognition
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu G, 2002, PATTERN RECOGN, V35, P2125, DOI 10.1016/S0031-3203(01)00204-7
   Loui AC, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P146, DOI 10.1109/ICIP.1998.723446
   LUSTED LB, 1971, SCIENCE, V171, P1217, DOI 10.1126/science.171.3977.1217
   Maji S., 2008, IEEE C COMPUTER VISI, P1
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mariano VY, 2002, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2002.1048198
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18
   Pedersoli M, 2011, PROC CVPR IEEE, P1353, DOI 10.1109/CVPR.2011.5995668
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ponce J, 2006, LECT NOTES COMPUT SC, V4170, P29
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   RAGHAVAN VV, 1989, ACM T INFORM SYST, V7, P205, DOI 10.1145/65943.65945
   Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Stilla U., 2004, International Archives of Photogrammetry and Remote Sensing, V35, P973
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tanner F, 2009, P IEEE APPL IM PATT, P1, DOI DOI 10.1109/AIPR.2009.5466304
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wong T, 2007, 2007 IEEE Symposium on Computational Intelligence in Security and Defense Applications, P30, DOI 10.1109/CISDA.2007.368131
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
NR 85
TC 343
Z9 375
U1 11
U2 101
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 187
EP 203
DI 10.1016/j.jvcir.2015.11.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400017
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Yi, Y
   Mo, ZW
   Tan, JW
AF Yi, Yang
   Mo, Zengwei
   Tan, Jie-wen
TI A novel hierarchical data association with dynamic viewpoint model for
   multiple targets tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Online multiple targets tracking; Tracking-by-detection; Data
   association; Dynamic viewpoint model; Structural context model; Branch
   partition; Candidate upgrading; Incremental motion pairing inference
ID MULTIOBJECT TRACKING; MULTITARGET TRACKING; ONLINE; OBJECTS
AB A new framework of hierarchical data association tracking (HDAT) with branch partition, candidate upgrading and incremental motion pairing inference is proposed to resolve the problem of online multiple targets tracking. Branch partition divides the process into several independent parts so as to reduce the computational complexity on affinity. Candidate upgrading improves the robustness of target initialization by tracking potential targets and incremental motion pairing inference could benefit the occlusion handling. Furthermore, a dynamic viewpoint model (DVM) and its iterative computation algorithm are developed for tracking multiple targets under moving camera videos. Extensive data experiments on several public benchmarks show that the presented approach achieves comparable results to state-of-the-art on static camera videos and promising results on moving camera videos, and moreover, the runtime performance is significantly improved. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yi, Yang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Mo, Zengwei] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Yi, Yang] SYSU CMU Shunde Int Joint Res Inst, Shunde, Guangdong, Peoples R China.
   [Tan, Jie-wen] Sun Yat Sen Univ, Sun Yat Sen Mem Hosp, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen University
RP Yi, Y (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM issyy@mail.sysu.edu.cn
RI Yi, Yang/AFP-5892-2022
FU Guangzhou Science and Technology Project [2013B090500030]
FX This work was partly supported by Guangzhou Science and Technology
   Project (No. 2013B090500030). We would like to express our grateful
   acknowledgements to the reference authors where we got lots of
   inspirations, and the kind helps and works of the anonymous reviewers.
CR Andriyenko A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1839, DOI 10.1109/ICCVW.2011.6130472
   Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Butt AA, 2013, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2013.241
   Chen S, 2014, J VIS COMMUN IMAGE R, V25, P793, DOI 10.1016/j.jvcir.2014.01.010
   Chen XJ, 2014, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2014.162
   Cheng HY, 2011, J VIS COMMUN IMAGE R, V22, P673, DOI 10.1016/j.jvcir.2011.07.001
   Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40
   Cifuentes C., 2012, P EUR C COMP VIS
   Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI [10.1109/CVPR.2008.4587581, DOI 10.1109/CVPR.2008.4587581]
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Gao Y, 2014, IEEE T CIRC SYST VID, V24, P1122, DOI 10.1109/TCSVT.2014.2302366
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532
   Hofmann M, 2013, IEEE INT W PERFORM, P22, DOI 10.1109/PETS.2013.6523791
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Ji RR, 2011, PATTERN RECOGN, V44, P624, DOI 10.1016/j.patcog.2010.08.022
   Koo S, 2014, J VIS COMMUN IMAGE R, V25, P108, DOI 10.1016/j.jvcir.2013.03.020
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Li GR, 2012, J VIS COMMUN IMAGE R, V23, P254, DOI 10.1016/j.jvcir.2011.11.001
   Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472
   Milan A, 2013, IEEE COMPUT SOC CONF, P735, DOI 10.1109/CVPRW.2013.111
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Nieto M., 2010, IS T SPIE INT C REAL
   Pallavi V, 2008, IEEE T MULTIMEDIA, V10, P794, DOI 10.1109/TMM.2008.922869
   Pellegrini S, 2010, LECT NOTES COMPUT SC, V6311, P452, DOI 10.1007/978-3-642-15549-9_33
   Possegger H, 2014, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2014.170
   Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44
   Tretyak E, 2012, INT J COMPUT VISION, V97, P305, DOI 10.1007/s11263-011-0488-1
   Wang FL, 2015, INFORM SCIENCES, V301, P215, DOI 10.1016/j.ins.2014.12.022
   Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174
   Wu Z, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.63
   Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468
   Yan X., 2011, P BRIT MACH VIS C, DOI DOI 10.5244/C.25.102
   Yan X, 2014, INT C PATT RECOG, P2221, DOI 10.1109/ICPR.2014.386
   Yan X, 2014, LECT NOTES COMPUT SC, V8690, P314, DOI 10.1007/978-3-319-10605-2_21
   Yan X, 2012, LECT NOTES COMPUT SC, V7576, P594, DOI 10.1007/978-3-642-33715-4_43
   Yang B, 2012, LECT NOTES COMPUT SC, V7572, P484, DOI 10.1007/978-3-642-33718-5_35
   Yang B, 2012, PROC CVPR IEEE, P2034, DOI 10.1109/CVPR.2012.6247907
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yi Y, 2014, IEEE SIGNAL PROC LET, V21, P288, DOI 10.1109/LSP.2014.2300497
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zamir AR, 2012, LECT NOTES COMPUT SC, V7573, P343, DOI 10.1007/978-3-642-33709-3_25
NR 51
TC 6
Z9 7
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 37
EP 49
DI 10.1016/j.jvcir.2015.10.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400004
DA 2024-07-18
ER

PT J
AU Feng, L
   Wu, J
   Liu, SL
   Zhang, HW
AF Feng, Lin
   Wu, Jun
   Liu, Shenglan
   Zhang, Hongwei
TI Global Correlation Descriptor: A novel image representation for image
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; HSV color space; Texton detection; Global Correlation
   Descriptor (GCD); Global Correlation Vector (GCV); Global Correlation
   Vector (DGCV); Feature fusion; Structure element correlation (SEC)
AB The image descriptors based on multi-features fusion have better performance than that based on simple feature in content-based image retrieval (CBIR). However, these methods still have some limitations: (1) the methods that define directly texture in color space put more emphasis on color than texture feature; (2) traditional descriptors based on histogram statistics disregard the spatial correlation between structure elements; (3) the descriptors based on structure element correlation (SEC) disregard the occurring probability of structure elements. To solve these problems, we propose a novel image descriptor, called Global Correlation Descriptor (GCD), to extract color and texture feature respectively so that these features have the same effect in CBIR. In addition, we propose Global Correlation Vector (GCV) and Directional Global Correlation Vector (DGCV) which can integrate the advantages of histogram statistics and SEC to characterize color and texture features respectively. Experimental results demonstrate that GCD is more robust and discriminative than other image descriptors in CBIR. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Feng, Lin; Wu, Jun] Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Liaoning, Peoples R China.
   [Feng, Lin; Wu, Jun] Dalian Univ Technol, Sch Comp Sci & Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Liaoning, Peoples R China.
   [Liu, Shenglan] Dalian Univ Technol, Sch Control Sci & Engn, Fac Elect Informat & Elect Engn, Dalian 116024, Liaoning, Peoples R China.
   [Zhang, Hongwei] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Liaoning, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University of Technology; Dalian University of Technology
RP Zhang, HW (corresponding author), Dalian Univ Technol, Sch Math Sci, Dalian 116024, Liaoning, Peoples R China.
EM hwzhang@dlut.edu.cn
FU National Natural Science Foundation of PR China [61173163, 61370200]
FX This work was supported by National Natural Science Foundation of PR
   China (Grant Nos. 61173163 and 61370200).
CR [Anonymous], 2013 INT JOINT C NEU
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Dubey RajshreeS., 2010, International Journal on Computer Science and Engineering, V2, P2145
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jalali S., 2013, VISUAL RECOGNITION U
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu CJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P270, DOI 10.1109/ICCV.2001.937635
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Junling, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P921
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Penatti OAB, 2014, PATTERN RECOGN, V47, P705, DOI 10.1016/j.patcog.2013.08.012
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Singha M., 2011, Assam University Journal of Science and Technology, V7, P94
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Watanabe T, 2009, LECT NOTES COMPUT SC, V5414, P37, DOI 10.1007/978-3-540-92957-4_4
   Zhi-Chun Huang, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P719, DOI 10.1109/ICMLC.2010.5580566
NR 33
TC 40
Z9 44
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 104
EP 114
DI 10.1016/j.jvcir.2015.09.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700011
DA 2024-07-18
ER

PT J
AU Rathee, N
   Ganotra, D
AF Rathee, Neeru
   Ganotra, Dinesh
TI A novel approach for pain intensity detection based on facial feature
   deformations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Thin Plate Spline; Distance metric method; Pain detection; Pain
   intensity level detection; Support Vector Machine; Facial feature
   descriptors; Distance metric learning; Feature extraction
ID EXPRESSION RECOGNITION; SCALES; RELIABILITY
AB The pain intensity detection approach proposed in this paper is based on the fact that facial features get deformed during pain. To model facial feature deformations, Thin Plate Spline is adopted that separates rigid and non-rigid deformations very well. For efficient pain level detection, we have mapped the deformation parameters to higher discriminative space using Distance Metric Learning (DML) method. In DML, we seek a common distance metric such that the features belonging to the same pain intensity are pulled close to each other and the features belonging to the different pain intensity are pushed as far as possible. The assessment of the proposed approach is carried out on the popularly accepted UNBC-McMaster Shoulder Pain Expression Archive Database by using Support Vector Machine as a classifier. To prove the efficacy of the proposed approach, it is compared with state-of-the-art approaches mentioned in literature. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Rathee, Neeru] Gobind Singh Indraprastha Univ, New Delhi, India.
   [Ganotra, Dinesh] Indira Gandhi Delhi Tech Univ Women, Room 117-B,Appl Sci & IT Block, Delhi 110006, India.
C3 GGS Indraprastha University; Indira Gandhi Delhi Technical University
   for Women (IGDTUW)
RP Ganotra, D (corresponding author), Indira Gandhi Delhi Tech Univ Women, Room 117-B,Appl Sci & IT Block, Delhi 110006, India.
EM neeru1rathee@gmail.com; dinesh_ganotra@hotmail.com
FU UGC; DST government of India
FX The authors would like to acknowledge the financial support of UGC and
   DST government of India.
CR Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bellet Aurelien, CORR
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Burckhardt C.S., 2003, ARTHRITIS RHEUMATISM, V49, pS96, DOI DOI 10.1002/ART.11440
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   DeGood DE., 2001, Handbook of pain assessment, P320
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Fang H, 2014, PATTERN RECOGN, V47, P1271, DOI 10.1016/j.patcog.2013.09.023
   Faraj MI, 2007, IEEE T COMPUT, V56, P1169, DOI 10.1109/TC.2007.1074
   FERRAZ MB, 1990, J RHEUMATOL, V17, P1022
   Florea C, 2015, LECT NOTES COMPUT SC, V8927, P778, DOI 10.1007/978-3-319-16199-0_54
   Hadjistavropoulos HD, 1996, PAIN, V65, P251, DOI 10.1016/0304-3959(95)00218-9
   Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688
   Hammal Z, 2012, PATTERN RECOGN, V45, P1265, DOI 10.1016/j.patcog.2011.09.014
   Huang S., 1970, ANN MATH STAT, V41, P495
   JENSEN MP, 1986, PAIN, V27, P117, DOI 10.1016/0304-3959(86)90228-9
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Khan R. A., 2013, 2013 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI [10.1109/ICME.2013.6607608, DOI 10.1109/ICME.2013.6607608]
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   Lai ZH, 2012, IEEE T NEUR NET LEAR, V23, P1948, DOI 10.1109/TNNLS.2012.2217154
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey Patrick, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P12, DOI 10.1109/CVPR.2009.5204279
   Lucey Patrick, 2009, Int Conf Affect Comput Intell Interact Workshops, V2009, P1
   Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   McCall JC, 2004, INT C PATT RECOG, P958, DOI 10.1109/ICPR.2004.1334688
   MCCORMACK HM, 1988, PSYCHOL MED, V18, P1007, DOI 10.1017/S0033291700009934
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Sprengel R, 1997, P IEEE EMBS, V18, P1190, DOI 10.1109/IEMBS.1996.652767
   Vapnik VladimirNaumovich., 1998, STAT LEARNING THEORY, V2
   Williams ACD, 2000, PAIN, V85, P457, DOI 10.1016/S0304-3959(99)00299-7
   Yang L., 2006, Distance metric learning: A comprehensive survey
   Yin-Chiao Tsai, 2000, Chinese Journal of Medical and Biological Engineering, V20, P203
NR 36
TC 31
Z9 34
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 247
EP 254
DI 10.1016/j.jvcir.2015.09.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700022
DA 2024-07-18
ER

PT J
AU Tsai, HC
   Lin, HJ
   Leou, JJ
AF Tsai, Hui-Chun
   Lin, Hui-Jing
   Leou, Jin-Jang
TI Multiexposure image fusion using intensity enhancement and detail
   extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low dynamic range (LDR) image; High dynamic range (HDR) image;
   Multiexposure image fusion; Contrast limited adaptive histogram
   equalization (CLAHE); Weighted least squares (WLS) optimization; Cross
   bilateral filtering; Homomorphic filtering; Gamma correction
ID PHOTOGRAPHY ENHANCEMENT; EXPOSURE FUSION; TONE; DISPLAY; FLASH
AB In this study, a multiexposure image fusion approach using intensity enhancement and detail extraction is proposed. The N input low dynamic range (LDR) RGB color images are transformed into HSI color space. Intensity enhancement is achieved by CLAHE and homomorphic filtering. Gamma correction is used to compensate the nonlinear response of display devices, whereas "cross-image" median filtering is used to generate the reference intensity image. L-0 smoothing filter and weighted least squares (WLS) optimization are used to perform local and global detail extractions on the N processed LDR images, respectively. The N weighting maps of the N processed LDR images are estimated by spatial and cross-image consistencies and then refined by cross bilateral filtering. Finally, the multiresolution spline based scheme is used to perform multiexposure image fusion. Based on the experimental results obtained in this study, the performance of the proposed approach is better than those of four comparison approaches. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Tsai, Hui-Chun; Lin, Hui-Jing; Leou, Jin-Jang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM thc100m@cs.ccu.edu.tw; lhc101m@cs.ccu.edu.tw; jjleou@cs.ccu.edu.tw
FU Ministry of Science and Technology, Taiwan, Republic of China [MOST
   102-2221-E-194-028-MY2, MOST 102-2221-E-194-041-MY3]
FX This work was supported in part by Ministry of Science and Technology,
   Taiwan, Republic of China under Grants MOST 102-2221-E-194-028-MY2 and
   MOST 102-2221-E-194-041-MY3.
CR BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cho DW, 2014, SIGNAL PROCESS, V98, P295, DOI 10.1016/j.sigpro.2013.11.007
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Duan J, 2010, PATTERN RECOGN, V43, P1847, DOI 10.1016/j.patcog.2009.12.006
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Granados M, 2010, PROC CVPR IEEE, P215, DOI 10.1109/CVPR.2010.5540208
   Gu B, 2013, IEEE T IMAGE PROCESS, V22, P70, DOI 10.1109/TIP.2012.2214047
   Gu B, 2012, J VIS COMMUN IMAGE R, V23, P604, DOI 10.1016/j.jvcir.2012.02.009
   Guarnieri G, 2011, IEEE T IMAGE PROCESS, V20, P1351, DOI 10.1109/TIP.2010.2092436
   He K., 2010, Eccv, P1
   Huang P., 2011, P IEEE INT C MULT TE, P3143
   Jo KH, 2011, COMPUT HUM BEHAV, V27, P1507, DOI 10.1016/j.chb.2010.10.015
   Kim K, 2011, IEEE T CONSUM ELECTR, V57, P1807, DOI 10.1109/TCE.2011.6131157
   Kotwal K., 2011, INF FUS FUSION 2011, P1
   Kou F., 2013, P IEEE INT C IND EL, P19
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li Y., 2005, ACM T GRAPHIC, V24, P249
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Mann S, 2001, PROC CVPR IEEE, P842
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Piella G, 2009, INT J COMPUT VISION, V83, P1, DOI 10.1007/s11263-009-0206-4
   Raman S., 2009, P 26 INT C MACHINE L, P1
   Raman S., 2007, P IEEE INT C COMP VI, P1
   Reinhard E., 2010, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting
   Robertson MA, 2003, J ELECTRON IMAGING, V12, P219, DOI 10.1117/1.1557695
   Shen JB, 2009, SIGNAL PROCESS, V89, P901, DOI 10.1016/j.sigpro.2008.11.009
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   Nguyen TM, 2013, SIGNAL PROCESS, V93, P3171, DOI 10.1016/j.sigpro.2013.04.014
   Tumblin J, 1999, ACM T GRAPHIC, V18, P56, DOI 10.1145/300776.300783
   Vanmali A.V., 2013, 2013 NAT C COMM NCC, P1, DOI [10.1109/NCC.2013.6488013, DOI 10.1109/NCC.2013.6488013]
   Wang TH, 2010, IEEE T IMAGE PROCESS, V19, P3089, DOI 10.1109/TIP.2010.2052269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yujie Mei, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P22, DOI 10.1109/ICIG.2011.52
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhang W, 2010, PROC CVPR IEEE, P530, DOI 10.1109/CVPR.2010.5540168
   Zhang ZW, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P334
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 48
TC 8
Z9 8
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 165
EP 178
DI 10.1016/j.jvcir.2015.09.012
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700016
DA 2024-07-18
ER

PT J
AU Lian, GY
AF Lian, Guoyun
TI Rotation invariant color texture classification using multiple sub-DLBPs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color texture classification; Rotation invariance; DLBP; Multiple
   sub-DLBPs descriptor; Color index space; Different color spaces; Rotated
   color texture; Dissimilarity measurement
ID COOCCURRENCE MATRICES; IMAGE-ANALYSIS; GRAY-SCALE; REPRESENTATION;
   PRESERVATION; SEGMENTATION; FEATURES; LEVEL; SPACE
AB It is known that the rotations of real-world color textures will vary arbitrarily. This paper presents a novel, simple, yet powerful method for rotation-invariant color texture classification. Firstly, we define a Distance-based Local Binary Pattern (DLBP) descriptor to characterize the color texture. By learning the joint distribution of the rotation-invariant DLBP and color intensity information, we define our Multiple Sub-DLBPs (MS_DLBP) descriptor. The MS_DLBP features defined in this paper are invariant to rotation. Here, we also compared seven important color spaces in terms of their effectiveness in our proposed MS_DLBP approach. The experimental results on the Outex and CUReT databases show the defined DLBP descriptor performs better than the existing color LBP descriptors and the proposed MS_DLBP approach is very robust to rotation invariance and outperforms state-of-the-art texture analysis methods. Also, HSV color space is shown to outperform the other color spaces in many cases. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lian, Guoyun] Shenzhen Polytech, Sch Comp Engn, Shenzhen 518055, Peoples R China.
   [Lian, Guoyun] Shenzhen Univ, Shenzhen 518060, Peoples R China.
C3 Shenzhen Polytechnic University; Shenzhen University
RP Lian, GY (corresponding author), Shenzhen Polytech, Sch Comp Engn, Shenzhen 518055, Peoples R China.
EM lianguoyun@szpt.edu.cn
FU National Science Founding of China [61202157]; Shenzhen basic research
   project [JCYJ20120613114733545]; Key Research Project of Shenzhen
   Polytechnic [601422K20007]
FX We would like to thank Dr. Guo and Dr. Bianconi as well as the MVG and
   VGG groups for sharing their codes. Our work is supported by National
   Science Founding of China (61202157), Shenzhen basic research project
   (JCYJ20120613114733545) and Key Research Project of Shenzhen Polytechnic
   (601422K20007).
CR Abbadeni N, 2010, J VIS COMMUN IMAGE R, V21, P651, DOI 10.1016/j.jvcir.2010.04.004
   [Anonymous], 2002, P 16 INT C PATT REC
   [Anonymous], 2008, ELCVIA Electron. Lett. Comput. Vis. Image Anal, DOI DOI 10.5565/REV/ELCVIA.268
   ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481
   Bianconi F, 2009, PATTERN RECOGN LETT, V30, P765, DOI 10.1016/j.patrec.2009.02.006
   Bradley A., 1995, P 14 INT C INF PROC
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Chindaro S, 2005, ELECTRON LETT, V41, P589, DOI 10.1049/el:20050594
   Crosier M., 2008, P INT C COMP VIS PAT
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Drimbarean A, 2001, PATTERN RECOGN LETT, V22, P1161, DOI 10.1016/S0167-8655(01)00058-7
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hanbury A, 2003, LECT NOTES COMPUT SC, V2749, P804
   Hiremath PS, 2006, INT J COMPUT SCI NET, V6, P124
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Lepistö L, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2149872
   Liang Y, 2014, J SIGNAL PROCESS SYS, V74, P59, DOI 10.1007/s11265-013-0809-4
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Lu YY, 2014, NEUROCOMPUTING, V126, P132, DOI 10.1016/j.neucom.2012.08.071
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Petrou Maria., 2006, IMAGE PROCESSING DEA
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Pietikainen M., 2002, P 2 INT WORKSH TEXT
   Porebski A., 2008, P 1 INT WORKSH IM PR
   Qazi IUH, 2011, PATTERN RECOGN, V44, P16, DOI 10.1016/j.patcog.2010.07.007
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Reyes-Aldasoro CC, 2006, PATTERN RECOGN, V39, P812, DOI 10.1016/j.patcog.2005.12.003
   Sertel O, 2008, INT CONF ACOUST SPEE, P597, DOI 10.1109/ICASSP.2008.4517680
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Song ML, 2013, NEUROCOMPUTING, V119, P222, DOI 10.1016/j.neucom.2013.03.037
   Song ML, 2010, IEEE T PATTERN ANAL, V32, P1537, DOI 10.1109/TPAMI.2009.74
   van den Broek E.L., 2004, P 16 BELGIUM NETHERL, P51
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Verdoolaege G., 2008, P INT C IM PROC
   Wang L, 1999, PATTERN RECOGN LETT, V20, P171, DOI 10.1016/S0167-8655(98)00129-9
   Yin QB, 2009, OPT ENG, V48, DOI 10.1117/1.3070640
NR 42
TC 5
Z9 5
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 1
EP 13
DI 10.1016/j.jvcir.2015.05.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600001
DA 2024-07-18
ER

PT J
AU da Silva, RD
   Schwartz, WR
   Pedrini, H
   Pulido, J
   Hamann, B
AF da Silva, Ricardo Dutra
   Schwartz, William Robson
   Pedrini, Helio
   Pulido, Jesus
   Hamann, Bernd
TI A topology-based approach to computing neighborhood-of-interest points
   using the Morse complex
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interest points; Topological neighborhood; Matching; Correspondence;
   Morse complex; Local context; Image descriptors; Geometric similarity
ID IMAGE; FEATURES; ALGORITHM; SIFT
AB A central problem in image processing and computer vision is the computation of corresponding interest points in a given set of images. Usually, interest points are considered as independent elements described by some local information. Due to the limitations of such an approach, many incorrect correspondences can be obtained. A specific contribution of this paper is the proposition of a topological operator, called Local Morse Context (LMC), computed over Morse complexes, introduced as a way of efficiently computing neighborhoods of interest points to explore the structural information in images. The LMC is used in the development of a matching algorithm, that helps reducing the number of incorrect matches, and obtaining a confidence measure of whether a correspondence is correct or incorrect. The approach is designed and tested for the correspondence of narrow-baseline synthetic and specially challenging underwater stereo pairs of images, for which traditional methods present difficulties for finding correct correspondences. (C) 2015 Elsevier Inc. All rights reserved.
C1 [da Silva, Ricardo Dutra] Fed Univ Technol, Dept Informat, BR-80230901 Curitiba, Parana, Brazil.
   [Schwartz, William Robson] Univ Fed Minas Gerais, Dept Comp Sci, BR-31270010 Belo Horizonte, MG, Brazil.
   [Pedrini, Helio] Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
   [Pulido, Jesus; Hamann, Bernd] Univ Calif Davis, Dept Comp Sci, Inst Data Anal & Visualizat, Davis, CA 95616 USA.
C3 Universidade Tecnologica Federal do Parana; Universidade Federal de
   Minas Gerais; Universidade Estadual de Campinas; University of
   California System; University of California Davis
RP da Silva, RD (corresponding author), Fed Univ Technol, Dept Informat, BR-80230901 Curitiba, Parana, Brazil.
EM ricardodutr@gmail.com
RI SILVA, EDUARDO/IQS-1403-2023; da Silva, Ricardo Dutra/AAS-9618-2020;
   Pedrini, Helio/A-7556-2012; Schwartz, William Robson/E-6612-2011
OI da Silva, Ricardo Dutra/0000-0002-8002-8411; Schwartz,
   William/0000-0003-1449-8834
FU FAPESP; FAPEMIG; CNPq; CAPES
FX The authors are grateful to FAPESP, FAPEMIG, CNPq, and CAPES for the
   financial support. The underwater images were cordially by colleagues
   from the Department of Computer Science and Department of Earth and
   Planetary Sciences, University of California, Davis.
CR [Anonymous], P IEEE C COMP VIS PA
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bremer PT, 2007, J PHYS CONF SER, V78, DOI 10.1088/1742-6596/78/1/012007
   Bunke H., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P1, DOI 10.1007/BFb0033223
   Carlsson G., 2004, P 2004 EUR ACM SIGGR, P124
   Cech J, 2010, IEEE T PATTERN ANAL, V32, P1568, DOI 10.1109/TPAMI.2009.176
   Chen Wang, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2957, DOI 10.1109/ICIP.2011.6116282
   Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51
   Cho M., 2009, BRIT MACH VIS C
   Collins A, 2004, COMPUT GRAPH-UK, V28, P881, DOI 10.1016/j.cag.2004.08.015
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cyganek B., 2007, INTRO 3D COMPUTER VI
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Delponte E, 2006, GRAPH MODELS, V68, P415, DOI 10.1016/j.gmod.2006.07.002
   Di Fabio B, 2012, PATTERN RECOGN LETT, V33, P1445, DOI 10.1016/j.patrec.2011.11.003
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650
   Gao XB, 2010, PATTERN ANAL APPL, V13, P113, DOI 10.1007/s10044-008-0141-y
   Grady L., 2010, Discrete calculus: Applied analysis on graphs for computational science
   Hao Jiang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2473, DOI 10.1109/CVPR.2011.5995580
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Kannala J, 2008, PROC CVPR IEEE, P1006
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim G., 2008, ACM INT C MULT INF R, P419
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Letscher D, 2007, LECT NOTES COMPUT SC, V4673, P587
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Middlebury, 2015, MIDDL STER DAT
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Oliver K., 2010, IEEE C COMP VIS PATT, P60
   Paris S, 2007, PROC CVPR IEEE, P1978
   Raveaux R, 2010, PATTERN RECOGN LETT, V31, P394, DOI 10.1016/j.patrec.2009.10.011
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Schwartz WR, 2011, IEEE IMAGE PROC, P1033, DOI 10.1109/ICIP.2011.6115600
   SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045
   SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144
   SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   Wang LB, 2011, IEEE IMAGE PROC, P1769, DOI 10.1109/ICIP.2011.6115803
   Winder SAJ, 2007, PROC CVPR IEEE, P17
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zomorodian A., 2010, ALGORITHMS THEORY CO, V2
   Zomorodian A.J., 2005, Topology for Computing, V1st edn
NR 55
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 299
EP 311
DI 10.1016/j.jvcir.2015.05.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900027
DA 2024-07-18
ER

PT J
AU Chen, X
   Yang, TQ
   Xu, JM
AF Chen, Xian
   Yang, Tianqi
   Xu, Jiaming
TI Cross-view gait recognition based on human walking trajectory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; GCT; 3-D projection; Cross-view; CCA; View variance;
   View calculation; Walking trajectory
ID IMAGE; MODEL; IDENTIFICATION; EXTRACTION; FEATURES; ANGLE
AB We propose in this paper a novel cross-view gait recognition method based on projection of gravity center trajectory (GCT). We project the coefficients of 3-D GCT in reality to different view planes to complete view variation. Firstly, we estimate the real GCT curve in 3-D space under different views by statistics of limb parameters. Then, we get the view transformation matrix based on the projection principle between curve and plane, and estimate the view of a silhouette sequence by this matrix to complete view variance of gait features. We calculate the body part trajectory on silhouette sequence to improve recognition accuracy by using correlation strength as similarity measure. Lastly, we take nested match method to calculate the final matching score of two kinds of features. Experimental results on the widely used CASIA-B gait database demonstrate the effectiveness and practicability of the proposed method. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chen, Xian; Yang, Tianqi] Jinan Univ, Dept Informat Sci & Technol, Guangzhou 510000, Guangdong, Peoples R China.
   [Xu, Jiaming] Jinan Univ, Sch Elect & Informat, Guangzhou 510000, Guangdong, Peoples R China.
C3 Jinan University; Jinan University
RP Chen, X (corresponding author), Jinan Univ, Dept Informat Sci & Technol, Guangzhou 510000, Guangdong, Peoples R China.
EM 843597029@qq.com; 740345085@qq.com; 596049806@qq.com
FU Science and Technology Plan of Guangzhou City in Guangdong Province
   [2014J4100107]
FX In this paper, the research was sponsored by the Science and Technology
   Plan of Guangzhou City in Guangdong Province (Project No. 2014J4100107).
CR [Anonymous], 18 IEEE INT C IM PRO
   [Anonymous], BMVC
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], 2008, 2008 IEEE 2 INT C BI
   Ashraf N, 2014, COMPUT VIS IMAGE UND, V123, P41, DOI 10.1016/j.cviu.2014.03.005
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bissacco A, 2001, PROC CVPR IEEE, P52
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Han J., 2005, IEEE INT C IM PROC 2, V3, P297
   Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640
   Hu HF, 2014, IEEE T CIRC SYST VID, V24, P617, DOI 10.1109/TCSVT.2013.2280098
   Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914
   Jean F, 2009, IMAGE VISION COMPUT, V27, P1272, DOI 10.1016/j.imavis.2008.11.009
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Kim HS, 2001, IEEE T MED IMAGING, V20, P1314, DOI 10.1109/42.974926
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Kusakunniran W, 2012, PATTERN RECOGN LETT, V33, P882, DOI 10.1016/j.patrec.2011.04.014
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lam THW, 2006, INT C PATT RECOG, P996
   Liu NN, 2011, IEEE SIGNAL PROC LET, V18, P431, DOI 10.1109/LSP.2011.2157143
   Liu NN, 2010, INT CONF ACOUST SPEE, P1410, DOI 10.1109/ICASSP.2010.5495466
   Lu JW, 2010, PATTERN RECOGN LETT, V31, P382, DOI 10.1016/j.patrec.2009.11.006
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Ngo TT, 2014, PATTERN RECOGN, V47, P228, DOI 10.1016/j.patcog.2013.06.028
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang ZH, 2005, NEUROCOMPUTING, V69, P250, DOI 10.1016/j.neucom.2005.06.002
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 45
TC 8
Z9 10
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1842
EP 1855
DI 10.1016/j.jvcir.2014.09.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300004
DA 2024-07-18
ER

PT J
AU Ozkaya, N
   Kurat, N
AF Ozkaya, Necla
   Kurat, Neslihan
TI Discriminative common vector based finger knuckle recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Biometrics; Knuckle recognition; Pattern recognition; Identity
   authentication; Identification; Verification; Discriminative common
   vector; Security
AB The main issue in personal authentication systems for military, security, industrial and social applications is accuracy. This paper presents a finger knuckle print (FKP) recognition approach to identity authentication. It applies a discriminative common vectors (DCV) based method to obtain the unique feature vectors, called discriminative common vectors, and the Euclidean distance as matching strategy to achieve the identification and verification tasks. The recognition process can be divided into the following phases: capturing the image; pre-processing; extracting the discriminative common vectors; matching and, finally, making a decision. In order to test and evaluate the proposed approach both the most representative FKP public databases and an established non-uniform FKP database were used. Experiments with these databases confirm that the DCV-based FKP recognition method achieves the authentication tasks effectively. The results showed the performance of the system in terms of the recognition rate had 100% accuracy for both training data and unseen test data. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Ozkaya, Necla; Kurat, Neslihan] Erciyes Univ, Fac Engn, Dept Comp Engn, TR-38039 Kayseri, Turkey.
C3 Erciyes University
RP Ozkaya, N (corresponding author), Erciyes Univ, Fac Engn, Dept Comp Engn, TR-38039 Kayseri, Turkey.
EM neclaozkaya@erciyes.edu.tr; n_kurat@yahoo.com
CR [Anonymous], POLYU PALMPR DAT
   [Anonymous], P 2010 SPE AS PAC OI
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   Kumar A, 2009, ELECTRON LETT, V45, P1023, DOI 10.1049/el.2009.1435
   Kumar A., 2009, P INT C BIOM THEOR A, P1
   Kumar A, 2009, IEEE T INF FOREN SEC, V4, P98, DOI 10.1109/TIFS.2008.2011089
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Meraoumia A, 2011, IEEE ICC
   Morales A, 2011, ELECTRON LETT, V47, P380, DOI 10.1049/el.2011.0156
   Ravikanth C., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Wang Chang-Yu, 2006, Acta Automatica Sinica, V32, P360
   Woodard DL, 2005, COMPUT VIS IMAGE UND, V100, P357, DOI 10.1016/j.cviu.2005.06.003
   Zhang L., 2009, NOVEL PERSONAL AUTHE
   Zhang Lei., 2010, Pattern Recogn
   Zhang L, 2009, IEEE IMAGE PROC, P1981, DOI 10.1109/ICIP.2009.5413734
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
   Zhang L, 2009, LECT NOTES COMPUT SC, V5702, P141, DOI 10.1007/978-3-642-03767-2_17
NR 19
TC 10
Z9 10
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1647
EP 1675
DI 10.1016/j.jvcir.2014.08.003
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100016
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Lin, WY
   Zhou, B
   Chen, ZZ
   Sheng, B
   Wu, JX
AF Zhang, Yihao
   Lin, Weiyao
   Zhou, Bing
   Chen, Zhenzhong
   Sheng, Bin
   Wu, Jianxin
TI Facial expression cloning with elastic and muscle models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression cloning; Elastic model; Muscle-distribution-based
   model; Distance-based metric; Facial features; Global warping; Local
   warping; Expression details enhancement
AB Expression cloning plays an important role in facial expression synthesis. In this paper, a novel algorithm is proposed for facial expression cloning. The proposed algorithm first introduces a new elastic model to balance the global and local warping effects, such that the impacts from facial feature diversity among people can be minimized, and thus more effective geometric warping results can be achieved. Furthermore, a muscle-distribution-based (MD) model is proposed, which utilizes the muscle distribution of the human face and results in more accurate facial illumination details. In addition, we also propose a new distance-based metric to automatically select the optimal parameters such that the global and local warping effects in the elastic model can be suitably balanced. Experimental results show that our proposed algorithm outperforms the existing methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Yihao; Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
   [Zhou, Bing] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [Chen, Zhenzhong] Wuhan Univ, Wuhan 430072, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Wu, Jianxin] Nanjing Univ, Dept Comp Sci, Nanjing 210023, Jiangsu, Peoples R China.
C3 Shanghai Jiao Tong University; Zhengzhou University; Wuhan University;
   Shanghai Jiao Tong University; Nanjing University
RP Lin, WY (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, 800 DongChuan Rd, Shanghai 200240, Peoples R China.
EM hellomikelin@gmail.com
RI lin, yuxi/HKF-6212-2023; Wu, Jianxin/B-8539-2012; Chen,
   Zhenzhong/C-2529-2015
OI Lin, Weiyao/0000-0001-8307-7107
FU National Science Foundation of China [61379079, 61025005, 61202154,
   61102100]; Shanghai Pujiang Program [12PJ1404300]; SMC grant of SITU;
   Chinese national 973 project [2013CB329603]
FX This work was supported in part by the National Science Foundation of
   China, under Grants. 61379079, 61025005, 61202154, and 61102100, in part
   by the Shanghai Pujiang Program, under Grant 12PJ1404300, in part by the
   SMC grant of SITU, and in part by the Chinese national 973 project,
   under Grant 2013CB329603.
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   [Anonymous], 2010, ACM SIGGRAPH 2010 Papers. SIGGRAPH'10, DOI [DOI 10.1145/1833349.1778769, DOI 10.1145/1778765.1778769]
   [Anonymous], TECHNICAL REPORT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM TRANS GRAPH
   [Anonymous], SIGGRAPH
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C., 2013, SIGGRAPH
   Chen YZ, 2013, IEEE T CIRC SYST VID, V23, P74, DOI 10.1109/TCSVT.2012.2203198
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Kahler K., 2001, GRAPHICS INTERFACE 2, P37, DOI DOI 10.20380/GI2001.05
   Liu ZC, 2001, COMP GRAPH, P271
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   RYCHLEWSKI J, 1984, PMM-J APPL MATH MEC+, V48, P303
   Seol Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159519
   Song ML, 2007, IEEE T MULTIMEDIA, V9, P1384, DOI 10.1109/TMM.2007.906591
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Sun MX, 2009, IEEE T CIRC SYST VID, V19, P1819, DOI 10.1109/TCSVT.2009.2026967
   Theobald BJ, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P134
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang S., 2008, CVPR, P1
   Waters K., 1987, COMPUTER GRAPHICS, V22, P17
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Wolberg G., 1990, Digital image warping
   Zhang YH, 2012, IEEE INT SYMP CIRC S, P2685, DOI 10.1109/ISCAS.2012.6271860
   Zhang ZY, 2004, INT J COMPUT VISION, V58, P93, DOI 10.1023/B:VISI.0000015915.50080.85
NR 26
TC 16
Z9 16
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 916
EP 927
DI 10.1016/j.jvcir.2014.02.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200020
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Imran, R
   Odeh, M
   Zorba, N
   Verikoukis, C
AF Imran, Reema
   Odeh, Maha
   Zorba, Nizar
   Verikoukis, Christos
TI Spatial opportunistic transmission for Quality of Experience
   satisfaction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality of Experience; Multibeam Opportunistic Beamforming; Cognitive
   systems; MIMO; Wireless; Delay; Data rate; Jitter; Throughput
ID SYSTEMS
AB The capability of Multiple Input Multiple Output (MIMO) to deliver service simultaneously to more than one user is an exceptional characteristic for the cognitive radio (CR) communication. In this paper, statistical optimization techniques are applied to assess the performance of the Quality of Experience (QoE) in CR systems, where each user has different demands. The Multiuser scenario is considered where the transmitter runs the Multibeam Opportunistic Beamforming technique to service more than one user. Closed form expressions are derived for different scenarios and obtained for four QoE indicators in the system. The performance of primary and secondary users in such scenarios are mathematically formulated and the results are compared with computer simulations. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Imran, Reema] Univ Jordan, Amman 11942, Jordan.
   [Odeh, Maha] Univ Luxemborg, Interdisciplinary Ctr Secur Reliable & Trust SnT, L-2721 Luxembourg, Luxembourg.
   [Zorba, Nizar] QMIC, Doha 210531, Qatar.
   [Verikoukis, Christos] CTTC, Barcelona 08860, Spain.
C3 University of Jordan; University of Luxembourg; Qatar University
RP Zorba, N (corresponding author), QMIC, Doha 210531, Qatar.
EM r.imran@ju.edu.jo; maha.alodeh@uni.lu; nizarz@qmic.com; cveri@cttc.es
RI Alodeh, Maha/AAZ-9423-2020
OI Alodeh, Maha/0000-0001-9326-1100
FU Research Projects Crossfire [FP7-ITN-GA317126]; GREEN-T [CP8-006];
   Jordan University [DAR-1313]
FX This work was partially supported by the Research Projects Crossfire
   (FP7-ITN-GA317126), GREEN-T (CP8-006) and Jordan University DAR-1313.
CR *3GPP TS, 2009, 36104 3GPP TS
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], 2002, ET Docket No. 02-135
   ATZORI L, 2013, IEEE COMMUNICATIONS, V50, P18
   DEMICHELIS C, 2002, IETF RFC
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   GOPALAN A, 2012, IEEE INF ORL MARCH
   Hamdi K, 2009, IEEE T WIREL COMMUN, V8, P4098, DOI 10.1109/TWC.2009.080528
   Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380
   HJELM B, 2000, IEEE VTC FALL BOST U
   HUNG T, 2012, EURO NGI C NEXT GEN
   Jiang TG, 2012, IEEE J SEL AREA COMM, V30, P1215, DOI 10.1109/JSAC.2012.120807
   KETYKO I, 2010, IEEE BMSB SHANGH CHI
   MARTINEZYELMO I, 2010, WWIC 2010 LUL SWED J
   Martini MG, 2012, IEEE J SEL AREA COMM, V30, P1153, DOI 10.1109/JSAC.2012.120801
   Mchenry M., 2003, Spectrum White Space Measurements
   Mochaourab R, 2012, IEEE J-STSP, V6, P151, DOI 10.1109/JSTSP.2011.2174962
   Serral-Graci R., 2010, WWIC 2010 LUL SWED J
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Svedman P, 2007, IEEE T COMMUN, V55, P941, DOI 10.1109/TCOMM.2007.896082
   VERVERIDIS CN, 2010, IEEE WOWMOM MONTR CA
   VISHWANATH A, 2009, ACM SIGMOBILE MOBILE, V13, P15
   WEIFEI Z, 2012, IEEE SECON SEOUL JUN
   Yoo T, 2006, IEEE J SEL AREA COMM, V24, P528, DOI 10.1109/JSAC.2005.862421
   Zorba N., 2007, IEEE PIMRC
   Zorba N, 2009, WIRELESS PERS COMMUN, V51, P549, DOI 10.1007/s11277-009-9750-z
NR 26
TC 3
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 578
EP 585
DI 10.1016/j.jvcir.2013.08.014
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100007
DA 2024-07-18
ER

PT J
AU Attia, M
   Nazih, W
   Al-Badrashiny, M
   Elsimary, H
AF Attia, Mohamed
   Nazih, Waleed
   Al-Badrashiny, Mohamed
   Elsimary, Hamed
TI Encoding true-color images with a limited palette via soft vector
   clustering as an instance of dithering multidimensional signals
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital signal processing; Digital image processing; Dithering;
   Multidimensional signals; Quantization noise; Reduced color depth; Soft
   vector clustering; Soft Data Clustering
ID QUANTIZATION; ALGORITHM
AB One of the classic problems of digital image processing is to encode true-color images for the optimal viewing on displays with a limited set of colors. A major manifestation of optimal viewing in this regard is to maximally remove parasitic artifacts in the degraded encoded images such as the contouring effect. Several robust attempts have been made to solve this problem over the past 50 years, and the first contribution of this paper is to introduce a simple - yet effective - novel solution that is based on soft vector clustering.
   The other contribution of this paper is to propose the application of the soft clustering methodology deployed in our color-encoding solution for the dithering of multidimensional signals. Dithering essentially adds controlled noise to the analog signal upon its digitization so that the resulting quantization noise is dispersed over a much wider band of the frequency domain and is therefore less perceptible in the digitized signal. This comes of course at the price of more overall quantization noise. Dithering is a vital operation that is performed via well-known simple schemes upon the analog-to-digital conversion of one-dimensional signals; however, the published literature is still missing a general neat scheme for the dithering of multidimensional signals that is able to handle arbitrary dimensionality, arbitrary number and distribution of quantization centroids, and with computable and controllable noise power. This gap is also filled by this paper. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Attia, Mohamed] RDI, Engn Co Dev Comp Syst, Giza, Egypt.
   [Attia, Mohamed] Luxor Technol Inc, Oakville, ON L6L6V2, Canada.
   [Attia, Mohamed] Arab Acad Sci & Technol, Cairo, Egypt.
   [Nazih, Waleed; Elsimary, Hamed] Salman Univ, Coll Comp Engn & Sci, Alkharj, Saudi Arabia.
   [Al-Badrashiny, Mohamed] King Abdul Aziz City Sci & Technol KACST, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Arab Academy for Science, Technology &
   Maritime Transport; Egyptian Academy of Scientific Research & Technology
   (ASRT); Prince Sattam Bin Abdulaziz University
RP Attia, M (corresponding author), Luxor Technol Inc, Oakville, ON L6L6V2, Canada.
EM m_Atteya@RDI-eg.com
RI Nazih, Waleed/HDO-1156-2022
OI Nazih, Waleed/0000-0003-3153-4251
FU Deanship of Scientific Research at Salman Bin Abdulaziz (formerly
   AlKharj) University [27/A.H./1432]
FX The work presented in this paper has been achieved through the 12-month
   research project (27/A.H./1432) funded by the Deanship of Scientific
   Research at Salman Bin Abdulaziz (formerly AlKharj) University
   http://www.sau.edu.sa - AlKharj - Kingdom of Saudi Arabia (KSA) from
   Oct. 2011 up to Sept. 2012.
CR [Anonymous], 2009, Basic algebra
   Attia M., 2011, LECT NOTES ELECT ENG, V103, P339
   Attia M, 2010, LECT NOTES ENG COMP, P574
   Au Cheuk-Hong Cheng, 2009, P IEEE PAC RIM C COM
   DIXIT S, 1991, COMPUT GRAPH, V15, P561, DOI 10.1016/0097-8493(91)90057-O
   Flohr T., 1993, P SPIE HUMAN VISION, V1913, P265
   FLOYD RW, 1976, P SID, V17, P75
   GENTILE RS, 1990, P SOC PHOTO-OPT INS, V1249, P249, DOI 10.1117/12.19675
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   Hunt RW G., 1998, MEASURING COLOUR
   Jain A.K., 2008, 50 YEARS K MEANS
   Ketterer J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P563, DOI 10.1007/BFb0055690
   KOLLIAS S, 1991, IEEE T SIGNAL PROCES, V39, P980, DOI 10.1109/78.80930
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Petri D., 1996, Measurement, V19, P147, DOI 10.1016/S0263-2241(97)00010-9
   Pohlmann K.C., 2005, PRINCIPLES DIGITAL A
   Roberts M.J., 2007, FUNDAMENTALS SIGNAL
   SCHUCHMAN L, 1964, IEEE T COMMUN TECHN, VCO12, P162, DOI 10.1109/TCOM.1964.1088973
   VANDERKOOY J, 1987, J AUDIO ENG SOC, V35, P966
   Widrow B., 2008, QUANTIZATION NOISE R, P485
NR 21
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 349
EP 360
DI 10.1016/j.jvcir.2013.10.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300012
DA 2024-07-18
ER

PT J
AU Chen, FE
   Jiao, YL
   Ma, GR
   Qin, QQ
AF Chen, Fenge
   Jiao, Yuling
   Ma, Guorui
   Qin, Qianqing
TI Hybrid regularization image deblurring in the presence of impulsive
   noise
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total variation; Framelet; Image modeling; Hybrid regularization; Image
   deblurring; Impulsive noise; Augmented Lagrangian algorithm; Fast
   Fourier transform
ID ALGORITHM; EFFICIENT; FRAME; MINIMIZATION; RESTORATION; CARTOON
AB Image deblurring is one of the fundamental problems in the image processing and computer vision fields. In this paper, we propose a new approach for restoring images corrupted by blur and impulse noise. The existing methods used to address this problem are based on minimizing the objective functional, which is the sum of the L-1-data fidelity term, and the total variation (TV) regularization term. However, TV introduces staircase effects. Thus, we propose a new objective functional that combines the tight framelet and TV to restore images corrupted by blur and impulsive noise while mitigating staircase effects. The minimization of the new objective functional presents a computational challenge. We propose a fast minimization algorithm by employing the augmented Lagrangian technique. The experiments on a set of image deblurring benchmark problems show that the proposed method outperforms previous state-of-the-art methods for image restoration. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Fenge; Ma, Guorui; Qin, Qianqing] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
   [Jiao, Yuling] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University
RP Ma, GR (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
EM fengch@whu.edu.cn
FU National Natural Science Foundation of China [61001187, 41001256,
   41101425]
FX The authors are very grateful to the Editor and the two referees for
   their helpful comments and suggestions on the original version of the
   paper, which led to the improved version of the paper. This research was
   supported by the National Natural Science Foundation of China (Nos.
   61001187, 41001256 and 41101425).
CR Bar L, 2005, LECT NOTES COMPUT SC, V3459, P107
   Bar L, 2007, IEEE T IMAGE PROCESS, V16, P1101, DOI 10.1109/TIP.2007.891805
   Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bioucas-Dias JM, 2008, IEEE IMAGE PROC, P685, DOI 10.1109/ICIP.2008.4711847
   Cai JF, 2008, SIAM J SCI COMPUT, V30, P1205, DOI 10.1137/040615298
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Cai JF, 2008, APPL COMPUT HARMON A, V24, P131, DOI 10.1016/j.acha.2007.10.002
   Cai JF, 2010, INVERSE PROBL IMAG, V4, P379, DOI 10.3934/ipi.2010.4.379
   Cai JF, 2010, J COMPUT MATH, V28, P289, DOI [10.4208/jcm.2009.10-m1002, 10.4208/jcm.1001-m1002]
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7
   Cai JF, 2009, ADV COMPUT MATH, V31, P87, DOI 10.1007/s10444-008-9084-5
   Chai AW, 2007, NUMER MATH, V106, P529, DOI 10.1007/s00211-007-0075-0
   Chan RH, 2007, APPL COMPUT HARMON A, V23, P153, DOI 10.1016/j.acha.2006.10.003
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, APPL COMPUT HARMON A, V17, P91, DOI 10.1016/j.acha.2004.02.003
   Chan RH, 2003, SIAM J SCI COMPUT, V24, P1408, DOI 10.1137/S1064827500383123
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Daubechies I, 2003, APPL COMPUT HARMON A, V14, P1, DOI 10.1016/S1063-5203(02)00511-0
   Dong B, 2013, J SCI COMPUT, V54, P350, DOI 10.1007/s10915-012-9597-4
   Dong B, 2012, APPL COMPUT HARMON A, V32, P268, DOI 10.1016/j.acha.2011.06.001
   Dong YQ, 2009, SIAM J IMAGING SCI, V2, P1168, DOI 10.1137/090758490
   Esser E., 2009, CAM REP, P9
   Fu HY, 2006, SIAM J SCI COMPUT, V27, P1881, DOI 10.1137/040615079
   Gonzalez R.C., 2010, DIGITAL IMAGE PROCES, P333
   Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673
   Jain A.K., 1989, FUNDAMENTALS DIGITAL, V569, P267
   Jia RQ, 2009, APPL COMPUT HARMON A, V27, P367, DOI 10.1016/j.acha.2009.05.002
   Li YR, 2011, IEEE T IMAGE PROCESS, V20, P1822, DOI 10.1109/TIP.2010.2103950
   Liu QG, 2012, J VIS COMMUN IMAGE R, V23, P753, DOI 10.1016/j.jvcir.2012.04.003
   Meyer Y., 2001, 15 JB LEW MEM LECT, V22, P71
   Ng MK, 2013, IEEE T IMAGE PROCESS, V22, P2233, DOI 10.1109/TIP.2013.2246520
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Oh S, 2013, J VIS COMMUN IMAGE R, V24, P332, DOI 10.1016/j.jvcir.2013.01.010
   Powell M.J.D., 1969, Optimization, P283
   Ron A, 1997, J FUNCT ANAL, V148, P408, DOI 10.1006/jfan.1996.3079
   Shen ZW, 2010, PROCEEDINGS OF THE INTERNATIONAL CONGRESS OF MATHEMATICIANS, VOL IV: INVITED LECTURES, P2834
   Tao M., 2009, ALTERNATING DIRECTIO
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wen YW, 2008, SIAM J SCI COMPUT, V30, P2655, DOI 10.1137/070683374
   Wu C., 2009, Augmented lagrangian method, dual methods, and split bregman iteration for ROF, vectorial TV and high order methods
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
NR 46
TC 7
Z9 10
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1349
EP 1359
DI 10.1016/j.jvcir.2013.09.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700012
DA 2024-07-18
ER

PT J
AU Lee, JS
AF Lee, Jung-San
TI RII: Renovating the irregular illumination of digital image archives
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital archive; Under-exposure; Over-exposure; Illumination;
   Distortion; Gauss-Laplace; Radiance; Edge detection
AB Digitization is critical for preserving valuable culture archives such as texts and images. Considering the physical characters of digital cameras or scanners and the artificial negligence, some distortions such as under-exposure or over-exposure often appear in the digital form of archives. These distortions decrease the quality of the digital pieces and lead to disputation in some circumstances. Several methods have been used to deal with these illumination problems. These existing methods mainly focus on how to mitigate the under-exposure phenomenon in text-only or text-photo images. Over-exposure cases in which brightness comes from different orientations are not considered. Hence, we propose a novel system for renovating irregular illumination (RII) to handle the over-exposure problem as well as under-exposure distortion. Experimental results show that the processing outcomes of RII can guarantee accurate restoration of the transformed digital pieces. In particular, RH can be extended to improve the uneven light distribution problem for complicated and colorful images. (C) 2013 Elsevier Inc. All rights reserved.
C1 Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM leejs@fcu.edu.tw
CR Doermann D, 2003, PROC INT CONF DOC, P606
   Fan J, 2005, PROC INT CONF DOC, P447
   Fan J., 2005, P IEEE INT C IM PROC, P1132
   FAN J, 2007, P 2 INT WORKSH CAM B, P87
   Hsia SC, 2005, IEEE T CIRC SYST VID, V15, P1026, DOI 10.1109/TCSVT.2005.852413
   Hsia SC, 2006, IEEE T IMAGE PROCESS, V15, P2719, DOI 10.1109/TIP.2006.877354
   Hua Z., 2010, Proc. 6th International Conference on Wireless Communications Networking and Mobile Computing (WiCOM), P1
   Kazakova N., 2004, P INT S CIRC SYST, V2, P11913
   Lee S., 2009, IEEE T CIRCUITS SYST, P900
   LIANG J, 2005, INT J DOC ANAL RECOG, V7, P83
   Lu SJ, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P3
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Sun J., 2004, P 1 ACM WORKSH HARDC, P15
   Taylor MJ, 1998, P SOC PHOTO-OPT INS, V3305, P230, DOI 10.1117/12.304635
NR 14
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 739
EP 751
DI 10.1016/j.jvcir.2013.05.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700001
DA 2024-07-18
ER

PT J
AU Zhang, DS
   Islam, MM
   Lu, GJ
AF Zhang, Dengsheng
   Islam, Md. Monirul
   Lu, Guojun
TI Structural image retrieval using automatic image annotation and region
   based inverted file
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Machine learning; Image indexing and searching; Image annotation; Vector
   quantization; Inverted file; Multi-instance learning; Bag-of-features;
   Region annotation
ID CLASSIFICATION; SEGMENTATION; FEATURES; SVMS
AB Image retrieval has lagged far behind text retrieval despite more than two decades of intensive research effort. Most of the research on image retrieval in the last two decades are on content based image retrieval or image retrieval based on low level features. Recent research in this area focuses on semantic image retrieval using automatic image annotation. Most semantic image retrieval techniques in literature, however, treat an image as a bag of features/words while ignore the structural or spatial information in the image. In this paper, we propose a structural image retrieval method based on automatic image annotation and region based inverted file. In the proposed system, regions in an image are treated the same way as keywords in a structural text document, semantic concepts are learnt from image data to label image regions as keywords and weight is assigned to each keyword according to spatial position and relationship. As the result, images are indexed and retrieved in the same way as structural document retrieval. Specifically, images are broken down to regions which are represented using colour, texture and shape features. Region features are then quantized to create visual dictionaries which are similar to monolingual dictionaries like English or Chinese dictionaries. In the next step, a semantic dictionary similar to a bilingual dictionary like the English-Chinese dictionary is learnt to mapping image regions to semantic concepts. Finally, images are then indexed and retrieved using a novel region based inverted file data structure. Results show the proposed method has significant advantage over the widely used Bayesian annotation models. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Dengsheng; Lu, Guojun] Monash Univ, Fac Informat Technol, Churchill, Vic 3842, Australia.
   [Islam, Md. Monirul] Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka 1000, Bangladesh.
C3 Monash University; Bangladesh University of Engineering & Technology
   (BUET)
RP Zhang, DS (corresponding author), Monash Univ, Fac Informat Technol, Churchill, Vic 3842, Australia.
EM Dengsheng.Zhang@monash.au; mmislam@cse.buet.ac.bd; Guojun.Lu@monash.au
RI Zhang, Dengsheng/W-8467-2019
OI Zhang, Dengsheng/0000-0001-8728-1746; Lu, Guojun/0000-0003-2523-7576
CR Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Bramer M., 2007, PRINCIPLES DATA MINI, V180
   Breen C, 2002, PROC SPIE, V4862, P198, DOI 10.1117/12.473036
   Cao L., 2007, ICCV
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Cusano C., 2004, P INT IM 4, V5304
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Del Frate F, 2007, IEEE T GEOSCI REMOTE, V45, P800, DOI 10.1109/TGRS.2007.892009
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fei-Fei L., 2004, CVPR WORKSH GEN MOD, V106, P178, DOI DOI 10.1109/CVPR.2004.383
   Feng H., 2004, P ACM INT C MULT
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Herve N., 2007, P 6 ACM INT C IM VID, P70
   Inoue M., 2004, P ACM SIGIR WORKSHOP, P44
   Islam M., 2009, P 9 AS C COMP VIS AC
   Islam Md Monirul, 2008, 2008 Digital Image Computing: Techniques and Applications, P191, DOI 10.1109/DICTA.2008.17
   Islam M.M., 2008, P IEEE INT C MULT EX
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jin Y., 2005, P ACM MM 05
   Kang S, 2009, PATTERN RECOGN LETT, V30, P789, DOI 10.1016/j.patrec.2008.06.009
   Kim S, 2004, LECT NOTES COMPUT SC, V3115, P393
   Kuroda K, 2002, NEUROCOMPUTING, V43, P259, DOI 10.1016/S0925-2312(01)00344-7
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Long FH, 2003, SIG COM TEC, P1
   Manjunath B.S., 2002, INTRO MPEG 7
   Maree R., 2005, P INT C COMP VIS PAT
   MarSSe R., 2004, P 6 ASIAN C COMPUTER, V2, P860
   Mori Y, 1999, P INT WORKSH MULT IN
   Park J, 2007, 2007 CIT: 7TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P183, DOI 10.1109/CIT.2007.123
   Park SB, 2004, PATTERN RECOGN LETT, V25, P287, DOI 10.1016/j.patrec.2003.10.015
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Rui S, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P322
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi R., 2007, Proceedings of the 15th International Conference on Multimedia, P341
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Town C.P., 2001, MV01211 SOC MAN ENG
   Tseng VS, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1056, DOI 10.1145/1244002.1244233
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vasconcelos N, 2007, COMPUTER, V40, P20, DOI 10.1109/MC.2007.239
   Wang C., 2009, P CVPR 09
   Wang C., 2008, ACM SIGIR, P355, DOI DOI 10.1145/1390334.1390396
   Wang C., 2008, P INT C CONT BAS IM, P113
   Wang C., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383221
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wong RCF, 2008, IEEE T PATTERN ANAL, V30, P1933, DOI 10.1109/TPAMI.2008.125
   Yang C., 2006, P INT C COMP VIS PAT
   Yang C., 2005, P IEEE INT C IM PROC
   YANG J, 2001, P IEEE INT C MULT EX, P313
   Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507
   Zhang D., 2009, P DIG IM COMP TECHN
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
NR 59
TC 11
Z9 11
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1087
EP 1098
DI 10.1016/j.jvcir.2013.07.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700032
DA 2024-07-18
ER

PT J
AU Yan, B
   Chen, Y
AF Yan, Bo
   Chen, Yue
TI Low complexity image interpolation method based on path selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low complexity; Image animation; Pixel interlacing; Path-based
   interpolation; Image interpolation; View interpolation; Optical flow;
   Sub-pixel strategy
ID OPTICAL-FLOW ESTIMATION
AB Image interpolation, the problem of producing a sequence of intermediate frames between two input images, is of significant interest. The application of image interpolation is numerous, including animation of still images, view interpolation and temporal interpolation. In this paper, we achieve an improved path-based interpolation method based on the original path-based framework, by introducing two innovative improvements. On one hand, we use optical flow to decide the direction of path, to constraint the path length and to maintain the global path coherency, which improves the efficiency significantly. On the other hand, we introduce the pixel interlacing model to obtain more accurate optical flows so that the accuracy of path selection will be improved a lot. Our improved path-based method performs as well as the original method in various interpolation applications in image quality and surpass the original method by a large scale in efficiency. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Yan, Bo; Chen, Yue] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Yan, B (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
EM byan@fudan.edu.cn
RI Yan, Bo/AFQ-7025-2022
OI Yan, Bo/0000-0002-7775-1270
FU NSFC [61073067]
FX This work is supported by NSFC (61073067).
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Bouguet Jean-Yves., 1999, OPENCV DOCUMENTS INT
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chen S., 20 ANN C COMP GRAPH, P279
   Fitzgibbon A., IEEE INT C COMP VIS, V2, P1176
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jia J., 2007, IEEE T PATTERN ANAL, P617
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Kolmogorov V., IEEE INT C COMP VIS, P508
   Lucas B., INT JOINT C ART INT, V3, P674
   Mahajan D., 2009, ACM SIGGRAPH, P1
   McMillan L., 22 ANN C COMP GRAPH, P39
   Mémin E, 2002, INT J COMPUT VISION, V46, P129, DOI 10.1023/A:1013539930159
   Perez P., ACM T GRAPHICS TOG, V22, P313
   Schadl A., 27 ANN C COMP GRAPH, P489
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Seitz S., 23 ANN C COMP GRAPH, P21
   Wang HC, 2005, PROC CVPR IEEE, P1201
   Werlberger M., 2009, P BRIT MACH VIS C
   Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211
   Zitnick C., IEEE INT C COMP VIS, P1308
NR 27
TC 9
Z9 9
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 661
EP 668
DI 10.1016/j.jvcir.2011.12.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900003
DA 2024-07-18
ER

PT J
AU Tang, Y
   Yuan, Y
   Yan, PK
   Li, XL
AF Tang, Yi
   Yuan, Yuan
   Yan, Pingkun
   Li, Xuelong
TI Greedy regression in sparse coding space for single-image
   super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality improvement; Super-resolution; Sparsity; Nonlinear coding;
   Machine learning; Empirical risk minimization; Greedy regression;
   L-2-Boosting
ID INTERPOLATION; RESOLUTION; ALGORITHM
AB Based on the assumption about the sparse representation of natural images and the theory of compressed sensing, very promising results about single-image super-resolution were obtained by an excellent algorithm introduced by Yang et al. [45]. However, their success could not be well explained theoretically. The lack of theoretical insight has hindered the further improvement of the algorithm. In this paper, Yang's algorithm is revisited in the view of learning theory. According to this point, Yang's algorithm can be considered as a linear regression method in a special feature space which is named as sparse coding space by us. In fact, it has been shown that Yang's algorithm is a result of optimal linear estimation in sparse coding space. More importantly, our theoretical analysis suggests that Yang's algorithm can be improved by using more flexible regression methods than the linear regression method. Following the idea, a novel single-image super-resolution algorithm which is designed based on the framework of L-2-Boosting is proposed in the paper. The experimental results show the effectiveness of the proposed algorithm by comparing with other methods, which verify our theoretical analysis about Yang's algorithm. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Tang, Yi; Yuan, Yuan; Yan, Pingkun; Li, Xuelong] Chinese Acad Sci, Ctr OPT IMagery Anal & Learning OPTIMAL, State Key Lab Transient Opt & Photon, Xian Inst Opt & Precis Mech, Xian, Shaanxi, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; State Key Laboratory of Transient Optics & Photonics
RP Tang, Y (corresponding author), Chinese Acad Sci, Ctr OPT IMagery Anal & Learning OPTIMAL, State Key Lab Transient Opt & Photon, Xian Inst Opt & Precis Mech, Xian, Shaanxi, Peoples R China.
EM yitang.math@gmail.com
RI Yan, Pingkun/W-5059-2019; Yuan, Yuan/ABB-2379-2020; li,
   xiang/GWM-6319-2022; yuan, Yuan/ISA-0923-2023; Li, Xuelong/Z-3785-2019;
   Yuan, Yuan/GVS-5120-2022; Li, Xuelong/ABF-3381-2020
OI Yan, Pingkun/0000-0002-9779-2141; Li, Xuelong/0000-0002-0019-4197
FU National Basic Research Program of China (973 Program) [2012CB719905];
   National Natural Science Foundation of China [61125106, 91120302,
   61172143, 61105051, 61072093]; State Administration of STIND
   [B1320110042]
FX This work is supported by the National Basic Research Program of China
   (973 Program) (Grant No. 2012CB719905), the National Natural Science
   Foundation of China (Grant Nos. 61125106, 91120302, 61172143, 61105051,
   and 61072093), and State Administration of STIND (Grant No.
   B1320110042).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], SIGNAL PROCESS
   Boucher A, 2008, IEEE T GEOSCI REMOTE, V46, P272, DOI 10.1109/TGRS.2007.907102
   Bühlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125
   Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elad M, 2009, COMPUT J, V52, P15, DOI 10.1093/comjnl/bxm008
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Galbraith AE, 2005, IEEE T GEOSCI REMOTE, V43, P1964, DOI 10.1109/TGRS.2005.853569
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   Gao XB, 2011, IEEE T IMAGE PROCESS, V20, P2738, DOI 10.1109/TIP.2011.2134859
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Gunturk B., 2003, IEEE T IMAGE PROCESS, V12, P137
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Kennedy JA, 2006, IEEE T MED IMAGING, V25, P137, DOI 10.1109/TMI.2005.861705
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li B, 2009, IEEE IMAGE PROC, P1185
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lu XQ, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P316, DOI 10.1109/ACPR.2011.6166654
   Malgouyres F, 2001, SIAM J NUMER ANAL, V39, P1, DOI 10.1137/S0036142999362286
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   Mu GW, 2011, IEEE IMAGE PROC, P1141, DOI 10.1109/ICIP.2011.6115630
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Schapire, 2010, COLT, V10, P308
   Scholkopf B., 2002, Learning with Kernels
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Smale S, 2007, CONSTR APPROX, V26, P153, DOI 10.1007/s00365-006-0659-y
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   Tang Y, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P52, DOI 10.1109/ACPR.2011.6166563
   Tang Y, 2011, INT J MACH LEARN CYB, V2, P15, DOI 10.1007/s13042-011-0011-6
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang Q, 2007, IEEE T IMAGE PROCESS, V16, P889, DOI 10.1109/TIP.2007.891794
   Xiaoqiang L., 2011, Multimedia Signal Processing (MMSP), 2011 IEEE 13th International Workshop on, P1
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yi Tang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P267, DOI 10.1109/ICIG.2011.63
   Yu FJ, 2011, 2011 NINTH IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS WORKSHOPS (ISPAW), P1, DOI 10.1109/ISPAW.2011.14
   Zhang JP, 2010, IEEE T SYST MAN CY B, V40, P986, DOI 10.1109/TSMCB.2010.2042166
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 49
TC 39
Z9 49
U1 0
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 148
EP 159
DI 10.1016/j.jvcir.2012.02.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000008
DA 2024-07-18
ER

PT J
AU Barranco, F
   Díaz, J
   Pino, B
   Ros, E
AF Barranco, F.
   Diaz, J.
   Pino, B.
   Ros, E.
TI A multi-resolution approach for massively-parallel hardware-friendly
   optical flow estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image motion analysis; Optical flow; Field programmable gate array;
   Architectures for embedded systems; Real-time systems;
   Multiscale-with-warping optical flow; Efficient multiresolution optical
   flow; Fusion methods for multiresolution optical flow implementaiton
ID PERFORMANCE; COMPUTATION; ARCHITECTURE; MULTISCALE; MODEL
AB This paper presents a novel hardware-friendly motion estimation for real-time applications such as robotics or autonomous navigation. Our approach is based on the well-known Lucas & Kanade local algorithm, whose main problem is the unreliability of its estimations for large-range displacements. This disadvantage is solved in the literature by adding the sequential multiscale-with-warping extension, although it dramatically increases the computational cost. Our choice is the implementation of a multiresolution scheme that avoids the warping computation and allows the estimation of large-range motion. This alternative allows the parallel computation of the scale-by-scale motion estimation which makes the whole computation lighter and significantly reduces the processing time compared with the multiscale-with-warping approach. Furthermore, this last fact also means reducing the hardware resource cost for its potential implementation in digital hardware devices such as GPUs, ASICs, or FPGAs. In the discussion, we analyze the speedup of the multiresolution approach compared to the multiscale-with-warping scheme. For an FPGA implementation, we obtain a reduction of latency between 40% and 50% and a resource reduction of 30%. The final solution copes with large-range motion estimations with a simplified architecture very well-suited for customized digital hardware datapath implementations as well as current multicore architectures. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Barranco, F.; Diaz, J.; Pino, B.; Ros, E.] Univ Granada, ETSIIT, CITIC, Dep Arquitectura & Tecnol Comp, E-18071 Granada, Spain.
C3 University of Granada
RP Barranco, F (corresponding author), Univ Granada, ETSIIT, CITIC, Dep Arquitectura & Tecnol Comp, C-P Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
EM fbarranco@atc.ugr.es
RI del Pino Prieto, María Begoña/AAL-1877-2021; Barranco,
   Francisco/B-7314-2012; Diaz, Javier/C-2387-2012; Barranco,
   Francisco/B-7314-2012; Ros, Eduardo/B-1107-2012
OI Barranco, Francisco/0000-0002-3721-0170; Diaz,
   Javier/0000-0002-1849-8068; Barranco, Francisco/0000-0003-1157-7596;
   Ros, Eduardo/0000-0001-6613-5256
FU National Grant [AP2007-00275]; project ARC-VISION [TEC2010-15396];
   project MULTIVISION [TIC-3873]; project ITREBA [TIC-5060]; EU Grant
   TOMSY [FP7-270436]
FX This work has been supported by the National Grant (AP2007-00275),
   projects ARC-VISION (TEC2010-15396), MULTIVISION (TIC-3873), and ITREBA
   (TIC-5060), and the EU Grant TOMSY (FP7-270436).
CR Anguita M, 2009, IEEE T CIRC SYST VID, V19, P1475, DOI 10.1109/TCSVT.2009.2026821
   [Anonymous], 2010, MIDDL COMP VIS
   Barranco F, 2012, IEEE T VLSI SYST, V20, P1058, DOI 10.1109/TVLSI.2011.2145423
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Benabbas Y., 2010 7th IEEE Int. Conf. Adv. Video Signal Based Surveillance, Boston, P212
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Botella G, 2010, IEEE T VLSI SYST, V18, P616, DOI 10.1109/TVLSI.2009.2013957
   Brandt JW, 1997, INT J COMPUT VISION, V25, P5, DOI 10.1023/A:1007987001439
   Brox T., 2005, Ph.D. thesis
   Bruhn A, 2006, INT J COMPUT VISION, V70, P257, DOI 10.1007/s11263-006-6616-7
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cassisa C, 2009, LECT NOTES COMPUT SC, V5856, P790, DOI 10.1007/978-3-642-10268-4_93
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Correia M., 16 INT C PATT REC, V4, P247
   Darabiha A, 2003, PROC CVPR IEEE, P203
   Alonso JD, 2008, IEEE T VEH TECHNOL, V57, P2736, DOI 10.1109/TVT.2008.917220
   Díaz J, 2006, IEEE T CIRC SYST VID, V16, P274, DOI 10.1109/TCSVT.2005.861947
   Díaz J, 2008, COMPUT VIS IMAGE UND, V112, P262, DOI 10.1016/j.cviu.2008.05.006
   FRENZ H, 2007, ACM T APPL PERCEPT, V3, P419
   Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944
   Giachetti A., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P146
   Guzman P., 2011, MACH VISION APPL, V1, P1
   Gwosdek P, 2010, J REAL-TIME IMAGE PR, V5, P163, DOI 10.1007/s11554-009-0132-2
   HARTLEY R, 1985, COMPUT VISION GRAPH, V30, P70, DOI 10.1016/0734-189X(85)90019-2
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang YR, 2005, J VIS COMMUN IMAGE R, V16, P668, DOI 10.1016/j.jvcir.2005.03.004
   Huihuan Qian, 2008, 2008 IEEE International Conference on Robotics and Biomimetics, P395, DOI 10.1109/ROBIO.2009.4913036
   Ji XP, 2006, J VIS COMMUN IMAGE R, V17, P647, DOI 10.1016/j.jvcir.2005.07.004
   Kohlberger T, 2005, IEEE T IMAGE PROCESS, V14, P1125, DOI 10.1109/TIP.2005.849778
   Kristan M, 2010, IEEE T SYST MAN CY B, V40, P1505, DOI 10.1109/TSMCB.2010.2041662
   Laptev I., INT C COMP VIS, P432
   Liu H., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P174
   Liu HY, 2003, IEEE T IMAGE PROCESS, V12, P1170, DOI 10.1109/TIP.2003.815296
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mahalingam V, 2010, IEEE T VLSI SYST, V18, P29, DOI 10.1109/TVLSI.2008.2006900
   Motten Andy, 2011, 2011 International Conference on Multimedia Technology, P3559
   Murachi Y, 2008, IEICE T ELECTRON, VE91C, P457, DOI 10.1093/ietele/e91-c.4.457
   NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063
   NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8
   Pauwels K., IEEE COMP SOC C COMP, P1
   Pauwels K, 2012, IEEE T COMPUT, V61, P999, DOI 10.1109/TC.2011.120
   Steinbruecker F., IEEE INT C COMP VIS
   Tomasi M, 2010, J SYST ARCHITECT, V56, P577, DOI 10.1016/j.sysarc.2010.07.012
   Tomasi M, 2010, PROC IEEE INT SYMP, P3033, DOI 10.1109/ISIE.2010.5637211
   Tomasi M, 2010, IEEE T CIRC SYST VID, V20, P1797, DOI 10.1109/TCSVT.2010.2087590
   Vallino J.R., 1995, TECHNICAL REPORT
   Vaudrey Tobi., 2008, 23 INT C IMAGE VISIO, P1
   WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489
   Wright J., 2005, P IEEE WORKSHOP MOTI, V2, P14
   Ye M., INT C IM PROC, V2, P289
NR 51
TC 4
Z9 7
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1272
EP 1283
DI 10.1016/j.jvcir.2012.09.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300010
DA 2024-07-18
ER

PT J
AU Zhang, J
   Kamata, S
AF Zhang, Jian
   Kamata, Sei-ichiro
TI A generalized 3-D Hilbert scan using look-up tables
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hilbert curve; Space-filling; Look-up table; Euclidean distance;
   Self-similarity; Point neighborhoods; One-to-one mapping; Scanning
   length
ID ALGORITHM
AB The Hilbert curve is a one-to-one mapping between multidimensional space and one-dimensional (1-D) space. Due to the advantage of preserving high correlation of multidimensional points, it receives much attention in many areas. Especially in image processing, Hilbert curve is studied actively as a scan technique (Hilbert scan). Currently there have been several Hilbert scan algorithms, but they usually have strict implementation conditions. For example, they use recursive functions to generate scans, which makes the algorithms complex and difficult to implement in real-time systems. Moreover the length of each side in a scanned region should be same and equal to the power of two, which limits the application of Hilbert scan greatly. In this paper, to remove the constraints and improve the Hilbert scan for a general application, an effective generalized three-dimensional (3-D) Hilbert scan algorithm is proposed. The proposed algorithm uses two simple look-up tables instead of recursive functions to generate a scan, which greatly reduces the computational complexity and saves storage memory. Furthermore, the experimental results show that the proposed generalized Hilbert scan can also take advantage of the high correlation between neighboring lattice points in an arbitrarily-sized cuboid region, and give competitive performance in comparison with some common scan techniques. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zhang, Jian; Kamata, Sei-ichiro] Waseda Univ, Grad Sch Informat Prod & Syst, Tokyo, Japan.
C3 Waseda University
RP Zhang, J (corresponding author), Waseda Univ, Grad Sch Informat Prod & Syst, Tokyo, Japan.
EM zj_jay@toki.waseda.jp; kam@waseda.jp
FU Japanese MEXT (Ministry of Education, Culture, Sport, Science and
   Technology); Waseda University [2005B-365]
FX This work was supported by fund from the Japanese MEXT (Ministry of
   Education, Culture, Sport, Science and Technology) via Kitakyushu
   Innovative Cluster Project and Waseda University Grant for Special
   Research Projects (2005B-365).
CR ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827
   AGUI T, 1991, IEICE TRANS COMMUN, V74, P1337
   [Anonymous], 1890, Math. Ann.
   Biswas S, 2000, INT C PATT RECOG, P207, DOI 10.1109/ICPR.2000.903522
   Butz A. R., 1969, J COMPUTER SYSTEM SC, V3, P128, DOI [DOI 10.1016/S0022-0000(69)80010-3, 10.1016/S0022-0000(69)80010-3]
   BUTZ AR, 1968, INFORM CONTROL, V12, P314, DOI 10.1016/S0019-9958(68)90367-7
   Chung KL, 2000, IEEE T IMAGE PROCESS, V9, P2109, DOI 10.1109/83.887978
   Gotsman C, 1996, IEEE T IMAGE PROCESS, V5, P794, DOI 10.1109/83.499920
   Hilbert David, 1891, MATH ANN, V38, P459, DOI [DOI 10.1007/BF01199431, 10.1007/bf01199431]
   JAGADISH HV, 1990, SIGMOD REC, V19, P332, DOI 10.1145/93605.98742
   Kamata S, 1999, IEEE T IMAGE PROCESS, V8, P964, DOI 10.1109/83.772242
   Kamata S, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P707, DOI 10.1109/ICIP.1997.648017
   KAMATA SI, 1994, INT C PATT RECOG, P93, DOI 10.1109/ICPR.1994.576234
   LEMPEL A, 1986, IEEE T INFORM THEORY, V32, P2, DOI 10.1109/TIT.1986.1057132
   Liu X, 1997, IEEE T IMAGE PROCESS, V6, P1333, DOI 10.1109/83.623197
   Memon N, 2000, IEEE T IMAGE PROCESS, V9, P1837, DOI 10.1109/83.877207
   MILLAR RJ, 1993, COMPUT J, V36, P186, DOI 10.1093/comjnl/36.2.186
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   QUINQUETON J, 1981, IEEE T PATTERN ANAL, V3, P403, DOI 10.1109/TPAMI.1981.4767126
   Sagan H, 1993, INT J MATH EDUC SCI, V24, P541, DOI DOI 10.1080/0020739930240405
   SAGAN H, 1994, SPACE FILLING CURVE
   Tian L, 2006, IEICE T INF SYST, VE89D, P290, DOI 10.1093/ietisy/e89-d.1.290
NR 22
TC 7
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 418
EP 425
DI 10.1016/j.jvcir.2011.12.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800002
DA 2024-07-18
ER

PT J
AU De Simone, F
   Goldmann, L
   Lee, JS
   Ebrahimi, T
AF De Simone, Francesca
   Goldmann, Lutz
   Lee, Jong-Seok
   Ebrahimi, Touradj
TI Towards high efficiency video coding: Subjective evaluation of potential
   coding technologies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Subjective quality assessment; Subjective test; Statistical analysis;
   High definition (HD); Video coding; High efficiency video coding (HEVC);
   Joint collaborative team on video coding (JCT-VC); H.264/MPEG-4 AVC
AB This paper describes the details and the results of the subjective quality evaluation performed at EPFL, as a contribution to the effort of the joint collaborative team on video coding (JCT-VC) for the definition of the high efficiency video coding (HEVC) standard. The performance of twenty-seven coding technologies has been evaluated with respect to two H.264/MPEG-4 AVC anchors, for high definition (HD) test material. The test campaign involved a total of 494 naive observers and took place over a period of four weeks. While similar tests have been conducted as part of the standardization process of previous video coding technologies, the test campaign described in this paper is by far the most extensive in the history of video coding standardization. A detailed statistical analysis of the subjective results is provided. The results show high consistency and support an accurate comparison of the performance of the different coding technologies. (C) 2011 Elsevier Inc. All rights reserved.
C1 [De Simone, Francesca; Goldmann, Lutz; Lee, Jong-Seok; Ebrahimi, Touradj] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP De Simone, F (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM francesca.desimone@epfl.ch; lutz.goldman-n@epfl.ch;
   jong-seok.lee@epfl.ch; touradj.ebrahimi@epfl.ch
RI Lee, Jong-Seok/AAF-5197-2020
OI Lee, Jong-Seok/0000-0001-5255-4425; Ebrahimi,
   Touradj/0000-0002-9900-3687; De Simone, Francesca/0000-0001-5272-9221
FU European Network of Excellence PetaMedia [FP7/2007-2011]; Swiss National
   Foundation for Scientific Research in the framework of NCCR Interactive
   Multimodal Information Management (IM2)
FX The work presented here was partially supported by the European Network
   of Excellence PetaMedia (FP7/2007-2011) and the Swiss National
   Foundation for Scientific Research in the framework of NCCR Interactive
   Multimodal Information Management (IM2). The authors thank Dr. Vittorio
   Baroncini and the proponents who provided the test material and made
   this subjective test campaign possible. Also, a special thank goes to
   Dr. Ulrich Engelke, Dr. Ulrich Reiter, Dr. Junyong You, Mrs. Liyuan
   Xing, Mrs. Fitri N. Rahayu, and Mr. Christoph Steindl who helped in
   assisting the test sessions and the subjects who participated with high
   dedication to the subjective tests.
CR [Anonymous], 2000, 1381822000 ISOIEC
   [Anonymous], 2020, INT TELECOMMUNICATIO
   Bech S., 2006, PERCEPTUAL AUDIO EVA
   De Simone F., 2009, WG1N4995 JPEG
   DESIMONE F, P 35 INT C AC SPEECH
   *ISO, 2010, Q616 ISOIEC JTC1SC29
   *ISO, 2005, 14496102005 ISOIEC
   *ITU, 2010, T832 ITU
   *ITU, 1992, T81 ITU
   *ITU, 2002, T800 ITU
   *JCT VC, 2010, A200 JCTVC
   *JCT VC, 2010, VCEGAM91 JCTVC ITUT
   *JCT VC, 2010, A203 JCTVC
   *JCT VC, 2010, A202 JCTVC
   *JCT VC, 2010, A204 JCTVC
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Snedecor GW, 1983, Statistical Methods, V6th
   SULLIVAN GJ, RECENT DEV STANDARDI
   TOURANCHEAU S, P HUMAN VISION ELECT, V14
   *VCEG, 2001, M33 VCEG
   Video Qual. Experts Group Mountain View CA USA, 2010, Report on theValidation of Video Quality Models for High Definition Video Content
NR 21
TC 30
Z9 30
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 734
EP 748
DI 10.1016/j.jvcir.2011.01.008
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200007
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, CC
   Chuang, CY
   Fu, KR
   Lin, SFD
AF Wang, Chih-Cheng
   Chuang, Chih-Yao
   Fu, Kuan-Ru
   Lin, Shinfeng D.
TI An integrated temporal error concealment for H.264/AVC based on spatial
   evaluation criteria
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Error concealment; Error resilience; Flexible macro-block
   ordering (FMO); Boundary matching algorithm (BMA); Mean absolute
   difference (MAD); Boundary distortion; Texture intensity
AB Owing to error-prone transmission networks, the compressed video bit stream is prone to packet loss in the transmission channel. This loss causes serious distortion and the distortion will propagate to successive frames, especially in highly compressed video coding standard. Therefore, it is very important to efficiently enhance the restored result. In this paper, an integrated temporal error concealment technique for H.264/AVC is proposed. The technique could effectively restore the corrupted data by adaptively integrating error concealment approaches with the adaptive weight-based switching algorithm. The integrated mechanism is based on spatial evaluation criteria, judged by boundary distortion estimation and texture intensity. Experimental results show that the technique could effectively enhance the performance of error concealment. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Wang, Chih-Cheng; Chuang, Chih-Yao; Fu, Kuan-Ru; Lin, Shinfeng D.] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 National Dong Hwa University
RP Lin, SFD (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
EM david@mail.ndhu.edu.tw
RI 林, 信鋒/HPC-8798-2023
CR [Anonymous], 2010, H 264 AVC REFERENCE
   Cui Y., 2009, P INT C ULTR TEL WOR, P1, DOI [10.1109/WICOM.2009.5302239, DOI 10.1109/WICOM.2009.5302239]
   Deng XY, 2009, IEEE IMAGE PROC, P941, DOI 10.1109/ICIP.2009.5413973
   *ITU T, 2003, H264ISOIEC1149610 IT
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   KWOK W, 1993, IEEE T CONSUM ELECTR, V39, P455, DOI 10.1109/30.234620
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yi JW, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 3, PROCEEDINGS, P455, DOI 10.1109/IITA.2009.451
   Youjun X., 2009, INT C IM SIGN PROC O, P1
   Zhang XP, 2009, PLANT ECOL, V201, P1, DOI 10.1007/s11258-008-9507-x
NR 14
TC 2
Z9 5
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 522
EP 528
DI 10.1016/j.jvcir.2011.06.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000007
DA 2024-07-18
ER

PT J
AU Yang, L
   Yendo, T
   Tehrani, MP
   Fujii, T
   Tanimoto, M
AF Yang, Lu
   Yendo, Tomohiro
   Tehrani, Mehrdad Panahpour
   Fujii, Toshiaki
   Tanimoto, Masayuki
TI Artifact reduction using reliability reasoning for image generation of
   FTV
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FTV; Depth-image-based rendering; Backward warping; Image interpolation;
   View synthesis; Reliability; Artefacts; Forward warping; Depth error
ID ENERGY MINIMIZATION; 3DTV
AB In this paper, we present a new view synthesis method in multiview camera configurations of Free viewpoint TV (FTV) where potential depth errors are considered. The emphasis is on the artifacts eliminating for photorealistic synthesis especially near object boundaries. In contrast to conventional techniques which ignore geometry errors, we first categorize the artifact cases and depth modes. Furthermore, this paper infers the complementarity principle of the artifacts from left and right references. This complementarity guarantees the effectiveness of our reliability-based synthesis. The reliability reasoning is crucial for artifacts reduction. The reliable and unreliable areas from different views can be correctly labeled. Then artifacts caused by unreliable pixels from one reference can be replaced by the reliable pixels from the other reference. As a final result, artifacts of novel view are demonstrated to be significantly reduced on different multiview sequences. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Yang, Lu; Yendo, Tomohiro; Tehrani, Mehrdad Panahpour; Tanimoto, Masayuki] Nagoya Univ, Grad Sch Engn, Chikusa Ku, Nagoya, Aichi 4648603, Japan.
   [Fujii, Toshiaki] Tokyo Inst Technol, Grad Sch Sci & Engn, Meguro Ku, Tokyo 1528550, Japan.
C3 Nagoya University; Tokyo Institute of Technology
RP Yang, L (corresponding author), Nagoya Univ, Grad Sch Engn, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648603, Japan.
EM yanglu@tanimoto.nuee.nagoya-u.ac.jp
OI Teratani, Mehrdad/0000-0001-9332-1409; Fujii,
   Toshiaki/0000-0002-3440-5132
CR [Anonymous], P SIGGRAPH
   [Anonymous], 2008, M15377 ISOIEC JTC1SC
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chan SC, 2007, IEEE SIGNAL PROC MAG, V24, P22, DOI 10.1109/MSP.2007.905702
   Criminisi A, 2004, PROC CVPR IEEE, P342
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Hasinoff SW, 2006, COMPUT VIS IMAGE UND, V103, P22, DOI 10.1016/j.cviu.2006.02.005
   *ISO IEC JTC1 SC29, 2008, M15413 ISOIEC JTC1SC
   *ISO IEC JTC1 SC29, 2008, M15378 ISOIEC JTC1SC
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kilner J, 2009, SIGNAL PROCESS-IMAGE, V24, P3, DOI 10.1016/j.image.2008.10.004
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Lee CC, 2008, SHOCK, V29, P15
   Min D, 2009, SIGNAL PROCESS-IMAGE, V24, P31, DOI 10.1016/j.image.2008.10.009
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Muller Karsten, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P34, DOI 10.1109/MMSP.2008.4665045
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   SHUM NY, 2006, IMAGE BASED RENDERIN
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Stein AN, 2009, INT J COMPUT VISION, V82, P325, DOI 10.1007/s11263-008-0203-z
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   WEXLER Y, 2002, P ECCV, V3, P487
NR 24
TC 26
Z9 36
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 542
EP 560
DI 10.1016/j.jvcir.2009.09.009
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600016
DA 2024-07-18
ER

PT J
AU Maugey, T
   Pesquet-Popescu, B
AF Maugey, Thomas
   Pesquet-Popescu, Beatrice
TI Side information estimation and new symmetric schemes for multi-view
   distributed video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view; Distributed video coding; Side information; Fusion;
   Rate-distortion analysis; Wyner-Ziv; Motion interpolation; Long-term
   estimation
ID RATE-DISTORTION ANALYSIS; DECODER
AB This paper deals with distributed video coding (DVC) for multi-view sequences. DVC of multi-view sequences is a recent field of research, with huge potential impact in applications such as videosurveillance, real-time event streaming from multiple cameras, and in general immersive communications. It raises however several problems, and in this paper we tackle two of them. Based on the principles of Wyner-Ziv (WZ) coding, in multi-view DVC many estimations can be generated in order to create the side information (SI) at the decoder. It has been shown that the quality of the SI strongly influences the global coding performances. Therefore, this paper proposes to study the contribution of multiple SI estimations (in the temporal and view directions) to the global performances. Moreover, we propose new symmetric schemes for longer group of pictures (GOP) in multi-view DVC and show that we can further exploit the long-term correlations using a new kind of estimation, called diagonal. For such schemes, several decoding strategies may be envisaged. We perform a theoretical study of the temporal and interview dependencies, and confirm by experiments the conclusion about the best decoding strategy. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Maugey, Thomas; Pesquet-Popescu, Beatrice] Ecole Natl Super Telecommun Bretagne, Signal & Image Proc Dept, F-75634 Paris 13, France.
C3 IMT - Institut Mines-Telecom; IMT Atlantique
RP Maugey, T (corresponding author), Ecole Natl Super Telecommun Bretagne, Signal & Image Proc Dept, 46 Rue Barrault, F-75634 Paris 13, France.
EM maugey@telecom-paristech.fr; pesquet@telecom-paristech.fr
FU French ANR [ANR-FI-071215-01-01 (ESSOR)]
FX Part of this work has been funded by the French ANR project no.
   ANR-FI-071215-01-01 (ESSOR).
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   [Anonymous], 2006, Elements of Information Theory
   [Anonymous], P AS C SIGN SYST PAC
   Areia JD, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P453, DOI 10.1109/MMSP.2007.4412914
   ARTIGAS X, 2006, 7 NORD SIGN PROC S I
   ARTIGAS X, 2007, INT C SIGN PROC MULT
   ASCENSO J, 2005, EURASIP C SPEECH IM
   Ascenso J, 2006, IEEE IMAGE PROC, P605, DOI 10.1109/ICIP.2006.312408
   Berger Toby, 1971, RATE DISTORTION THEO
   BRITES C, 2006, IEEE INT C AC SPEECH
   FRAYSSE A, IEEE T INFORM UNPUB
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guillemot C., 2007, IEEE Signal Processing Magazine, Special Issue on Signal Processing for Multiterminal Communication Systems
   GUO X, 2006, SPIE, V6077, P15
   HEMAMI S, 1999, INT C IM PROC ICIP 9, V99, P349
   *ISO IEC MPEG ITU, 2007, JOINT MULT VID MOD J
   Li Z, 2007, IEEE T IMAGE PROCESS, V16, P98, DOI 10.1109/TIP.2006.884934
   MORBEE M, 2007, IEEE INT C AC SPEECH, V1
   OUARET M, 2006, ACM INT WORKSH VID S
   PURI R, 2003, M036 UCBERL EECS U C
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tagliasacchi M, 2007, IEEE SIGNAL PROC LET, V14, P625, DOI 10.1109/LSP.2007.896187
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xu Q, 2006, IEEE T IMAGE PROCESS, V15, P3791, DOI 10.1109/TIP.2006.884925
   Zhan-Wei L., 2007, INT S INT SIGN PROC, P168
NR 26
TC 14
Z9 15
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 589
EP 599
DI 10.1016/j.jvcir.2008.09.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300011
OA Green Published
DA 2024-07-18
ER

PT J
AU Shen, SH
   Liu, YC
AF Shen, Shuhan
   Liu, Yuncai
TI Efficient multiple faces tracking based on Relevance Vector Machine and
   Boosting learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE face tracking; face detection; multiple faces tracking; real-time
   tracking; probabilistic algorithms; Relevance Vector Machine; Boosting;
   AdaBoost
ID COLOR
AB A multiple faces tracking system was presented based on Relevance Vector Machine (RVM) and Boosting learning. In this system, a face detector based on Boosting learning is used to detect faces at the first frame, and the face motion model and color model are created. The face motion model consists of a set of RVMs that learn the relationship between the motion of the face and its appearance, and the face color model is the 2D histogram of the face region in CrCb color space. In the tracking process different tracking methods (RVM tracking, local search, giving up tracking) are used according to different states of faces, and the states are changed according to the tracking results. When the full image search condition is satisfied, a full image search is started in order to find new coming faces and former occluded faces. In the full image search and local search, the similarity matrix is introduced to help matching faces efficiently. Experimental results demonstrate that this system can (a) automatically find new coming faces; (b) recover from occlusion, for example, if the faces are occluded by others and reappear or leave the scene and return; (c) run with a high computation efficiency, run at about 20 frames/s. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Shen, Shuhan; Liu, Yuncai] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Shen, SH (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM shs@sjtu.edu.cn; whomliu@sjtu.edu.cn
RI Shen, Shuhan/B-2223-2009; Shen, Shuhan/B-2439-2015
OI Shen, Shuhan/0000-0002-8704-7914
FU National Natural Science Foundation of China (NSFC) [60675017]; National
   973 Key Basic Research Program of China [2006CB303103]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) under Grant 60675017, and National 973 Key Basic Research Program
   of China under Grant 2006CB303103.
CR [Anonymous], 2003, P 9 INT WORKSH ART I
   [Anonymous], 2001, CVPR
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bing X, 2004, IEEE IMAGE PROC, P1021
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DELSOLAR JR, 2003, P 12 INT C IM AN PRO
   DUHN SV, 2007, P IEEE COMP SOC C CO
   FAUL A, 2002, ADV NEURAL INFORM PR, V14
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Lee HS, 2007, PATTERN RECOGN, V40, P3225, DOI 10.1016/j.patcog.2007.03.003
   Lerdsudwichai C, 2005, PATTERN RECOGN, V38, P1059, DOI 10.1016/j.patcog.2004.11.022
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   LIANG R, 2003, P IEEE INT C SYST MA
   Lienhart R., 2002, P IEEE INT C IM PROC
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   MAURER T, 1996, P INT C AUT FAC GEST
   Pardàs M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P259, DOI 10.1109/ICIP.2000.899295
   Schwerdt K., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P90, DOI 10.1109/AFGR.2000.840617
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Viola P., 2003, P IEEE INT C COMP VI
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
NR 24
TC 10
Z9 13
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2008
VL 19
IS 6
BP 382
EP 391
DI 10.1016/j.jvcir.2008.06.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 343KS
UT WOS:000258853100004
DA 2024-07-18
ER

PT J
AU Zhang, XH
   Lin, WS
   Xue, P
AF Zhang, Xiaohui
   Lin, Weisi
   Xue, Ping
TI Just-noticeable difference estimation with pixels in images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE JND; visual quality; HVS
ID VISUAL DISTORTION; DISCRIMINATION; COMPRESSION; MODELS; NOISE
AB Perceptual visibility threshold estimation, based upon characteristics of the human visual system (HVS), is widely used in digital image and video processing. We propose in this paper a scheme for estimating JND (just-noticeable difference) with explicit formulation for image pixels, by summing the effects of the visual thresholds in sub-bands. The factors being considered include spatial contrast sensitivity function (CSF), luminance adaptation, and adaptive inter- and intra-band contrast masking. The proposed scheme demonstrates favorable results in noise shaping and perceptual visual distortion gauge for different images, in comparison with the relevant existing JND estimators. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Zhang, Xiaohui; Xue, Ping] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Xue, P (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM pl44238551@ntu.edu.sg; wslin@ntu.edu.sg; epxue@ntu.edu.sg
RI Zhang, Xiaohui/AAN-2994-2020; Liu, Anmin/A-4730-2012; Lin,
   Weisi/A-8011-2012; Lin, Weisi/A-3696-2011; Xue, Ping/A-5155-2011; Lin,
   Wei/D-3353-2012
OI Zhang, Xiaohui/0000-0001-8613-076X; Lin, Weisi/0000-0001-9866-1947; 
CR Ahumada A. J.  Jr., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1666, P365, DOI 10.1117/12.135982
   Chiu YJ, 1999, IEEE T CIRC SYST VID, V9, P438, DOI 10.1109/76.754773
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Dumont R, 2003, ACM T GRAPHIC, V22, P152, DOI 10.1145/636886.636888
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Girod Bernd, 1993, P207
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   KLEIN SA, 1992, P SOC PHOTO-OPT INS, V1666, P200, DOI 10.1117/12.135968
   Kuo SS, 2002, IEEE T IMAGE PROCESS, V11, P509, DOI 10.1109/TIP.2002.1006398
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   LEGGE GE, 1981, VISION RES, V21, P457, DOI 10.1016/0042-6989(81)90092-4
   Li B, 1998, P SOC PHOTO-OPT INS, V3299, P98, DOI 10.1117/12.320101
   Lin WS, 2005, IEEE T CIRC SYST VID, V15, P900, DOI 10.1109/TCSVT.2005.848345
   Lubin J., 1995, Vision Models for Target Detection and Recognition, P245
   NADENAU M, 2000, THESIS EPFL LAUSANNE
   Netravali A.N., 1988, DIGITAL PICTURES REP
   PARK J, 1994, SIGNAL PROCESSING HD, V5
   PETERSON HA, 1993, HUMAN VISION VISUAL, V6, P191
   Ramasubramanian M, 1999, COMP GRAPH, P73, DOI 10.1145/311535.311543
   SAFRANEK R, 1994, P SPIE HUM VIS VIS P, V5, P117
   Safranek R. J., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1945, DOI 10.1109/ICASSP.1989.266837
   *SARN CORP, 2002, MEAS IM QUAL SARN JN
   TONG HY, 1998, P IEEE INT C IM PROC
   Tran TD, 1996, INT CONF ACOUST SPEE, P1882, DOI 10.1109/ICASSP.1996.544817
   VANNES FL, 1967, J OPT SOC AM, V57, P401, DOI 10.1364/JOSA.57.000401
   WALTER BJ, 2003, COMPUT GRAPH FORUM, V21, P393
   Watson A.B., 1993, SOC INFORM DISPLAY D, Vxxiv, P946
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P496, DOI 10.1109/TCSVT.2005.844458
   ZENG W, 1999, P 3O ANN AS C SIGN S
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
NR 34
TC 84
Z9 100
U1 2
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2008
VL 19
IS 1
BP 30
EP 41
DI 10.1016/j.jvcir.2007.06.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 257SY
UT WOS:000252820000004
DA 2024-07-18
ER

PT J
AU Choi, YS
   Park, RH
AF Choi, Young-Sic
   Park, Rae-Hong
TI MPEG-2 stereoscopic video coding technique using adaptive bandwidth
   control
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE block-wise quantization; dependent bit allocation; moving picture
   experts group-2; rate control; rate-distortion optimization; stereo
   video coding
ID RATE-DISTORTION OPTIMIZATION; DISPARITY FIELD ESTIMATION; IMAGE;
   COMPRESSION; QUANTIZATION; MOTION
AB According to recent advances in three-dimensional display systems, interest in stereoscopic video coding and reconstruction has been increased in various fields of video processing. Efficient video coding techniques are required to reduce the amount of data. In this paper, we propose an effective algorithm that improves the quality of moving picture experts group-2 stereoscopic sequences, in which optimal quantization parameters (QPs) are selected for pairs of corresponding macroblocks in left and right frames taken at the same time instants but from different view angles. The proposed algorithm reduces the binocular redundancy between the left and right frames. To minimize the total distortion, it adaptively determines QPs and the bandwidth for encoding of pairs of the frame sequence. The proposed algorithm is compared with the conventional video encoding methods in terms of the video quality and the use of bandwidth. Especially for video sequences containing a number of moving blocks and scene changes, the proposed algorithm shows better performance than the conventional methods in terms of the performance of disparity estimation and adaptive bandwidth control. (C) 2005 Elsevier Inc. All rights reserved.
C1 Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea.
C3 Sogang University
RP Park, RH (corresponding author), Sogang Univ, Dept Elect Engn, CPO Box 1142, Seoul 100611, South Korea.
EM rhpark@sogang.ac.kr
RI Park, Rae-Hong/Q-7908-2019
OI Park, Rae-Hong/0000-0002-4792-2980
CR Aydinoglu H, 1998, IEEE T IMAGE PROCESS, V7, P506, DOI 10.1109/83.663495
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   Gersho A., 2003, Vector Quantization and Signal Compression
   Haskell B.G., 1997, DIGITAL VIDEO INTRO
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P1221, DOI 10.1109/76.974677
   *ISO IEC, 1996, JTC1SC29WG11 ISOIEC
   *ISO IEC, 1996, JTC1SC29WG11N1373 IS
   Jain R., 1995, MACHINE VISION
   Kang DG, 2002, OPT ENG, V41, P2008, DOI 10.1117/1.1486000
   Lin LJ, 1998, IEEE T CIRC SYST VID, V8, P446, DOI 10.1109/76.709411
   MICHELL JL, 1997, MPEG VIDEO COMPRESSI
   Moellenhoff MS, 1998, IEEE T IMAGE PROCESS, V7, P804, DOI 10.1109/83.679421
   NAITO S, 1999, P INT C IM PROC KOB, V1, P281
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   ORTEGA A, 1994, IEEE T IMAGE PROCESS, V3, P26, DOI 10.1109/83.265978
   Puri A, 1997, SIGNAL PROCESS-IMAGE, V10, P201, DOI 10.1016/S0923-5965(97)00025-8
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Sexton I, 1999, IEEE SIGNAL PROC MAG, V16, P85, DOI 10.1109/79.768575
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tzovaras D, 1998, IEEE T CIRC SYST VID, V8, P171, DOI 10.1109/76.664102
   Woo W, 1999, IEEE T CIRC SYST VID, V9, P861, DOI 10.1109/76.785724
   Yang Y, 2000, IEEE T CIRC SYST VID, V10, P942, DOI 10.1109/76.867931
   Ziegler M, 1998, SIGNAL PROCESS-IMAGE, V14, P173, DOI 10.1016/S0923-5965(98)00035-6
NR 23
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 842
EP 859
DI 10.1016/j.jvcir.2005.06.003
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500010
DA 2024-07-18
ER

PT J
AU Kenmochi, Y
   Imiya, A
AF Kenmochi, Yukiko
   Imiya, Atsushi
TI Combinatorial boundary of a 3D lattice point set
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE boundary extraction; combinatorial surface; polyhedral complex
ID TOPOLOGY; SURFACES
AB Boundary extraction and surface generation are important topological topics for three-dimensional digital image analysis. However, there is no adequate theory to establish relations between these different topological procedures in a completely discrete way. In this paper, we present a new boundary extraction algorithm which gives not only a set of border points but also a polyhedral surface whose vertices are border points by using the concepts of combinatorial/algebraic topologies. We show that our boundary can be considered to be a triangulation or polyhedrization of border points in the sense of general topology, that is, we clarify relations between border points and the triangulated surface. (C) 2005 Elsevier Inc. All rights reserved.
C1 CNRS, UMLV, ESIEE UMR 8049, Lab A2SI,Grp ESIEE,Inst Gaspard Monge, F-93162 Noisy Le Grand, France.
   Chiba Univ, Inst Media & Informat Technol, Inage Ku, Chiba 2638522, Japan.
C3 Universite Gustave-Eiffel; ESIEE Paris; Centre National de la Recherche
   Scientifique (CNRS); Ecole des Ponts ParisTech; Chiba University
RP Kenmochi, Y (corresponding author), CNRS, UMLV, ESIEE UMR 8049, Lab A2SI,Grp ESIEE,Inst Gaspard Monge, Cite Descartes,BP99, F-93162 Noisy Le Grand, France.
EM y.kenmochi@esiee.fr; imiya@faculty.chiba-u.jp
CR ALEXANDROV PS, 1956, COMBINATORIAL TOPOLO, V11
   Andres E, 1997, IEEE T VIS COMPUT GR, V3, P75, DOI 10.1109/2945.582354
   Andres E, 1997, GRAPH MODEL IM PROC, V59, P302, DOI 10.1006/gmip.1997.0427
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1956, WORLD MATH SMALL LIB
   [Anonymous], P ICIP
   ARTZY E, 1981, COMPUT VISION GRAPH, V15, P1, DOI 10.1016/0146-664X(81)90103-9
   Aumann J.R., 1937, SET THEORY
   Couprie M, 1998, P SOC PHOTO-OPT INS, V3454, P40, DOI 10.1117/12.323265
   DEBLEDRENNESSON I, 1994, SPIE, V2356, P12
   Frank E, 1995, J PRACTICAL PSYCHIAT, V1, P20
   HERMAN GT, 1992, CVGIP-GRAPH MODEL IM, V54, P507, DOI 10.1016/1049-9652(92)90070-E
   Kenmochi Y, 1998, COMPUT VIS IMAGE UND, V71, P281, DOI 10.1006/cviu.1997.0652
   Khalimsky E. D., 1986, Proceedings of the 1986 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.86CH2364-8), P1559
   KLETTE R, 2001, CITRTR101 U AUCKL TA
   KLETTE R, 1983, CARTR6 U MAR
   KONG TY, 1985, COMPUT VISION GRAPH, V32, P221, DOI 10.1016/S0734-189X(85)80070-0
   KONG TY, 1985, COMPUT VISION GRAPH, V29, P60, DOI 10.1016/S0734-189X(85)90151-3
   KONG TY, 1992, TOPOL APPL, V46, P219, DOI 10.1016/0166-8641(92)90016-S
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   Kovalevsky V, 1999, LECT NOTES COMPUT SC, V1568, P118
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Moise E. E., 1977, GEOMETRIC TOPOLOGY D
   MORGENTHALER DG, 1981, INFORM CONTROL, V51, P227, DOI 10.1016/S0019-9958(81)90290-4
   ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570
   Sloboda F, 1998, P SOC PHOTO-OPT INS, V3454, P52, DOI 10.1117/12.323274
   Stillwell J., 1993, Classical Topology and Combinatorial Group Theory
   TOURLAKIS G, 1973, J ACM, V20, P439, DOI 10.1145/321765.321776
   VOSS K, 1993, DISCRETE IMAGES OBJE
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   ZIEGLER G. M., 1994, Lectures on polytopes
NR 32
TC 7
Z9 7
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 738
EP 766
DI 10.1016/j.jvcir.2005.11.001
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, PH
   Chen, HM
   Hung, KJ
   Fang, WH
   Shie, MC
   Lai, FP
AF Chen, Po-Hung
   Chen, Hung-Ming
   Hung, Kuo-Jui
   Fang, Wen-Hsien
   Shie, Mon-Chau
   Lai, Feipei
TI Markov model fuzzy-reasoning based algorithm for fast block motion
   estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Markov chain; fuzzy reasoning; block matching; motion estimation; video
   coding
ID SEARCH ALGORITHM
AB This paper presents a Markov model fuzzy-reasoning based algorithm for fast block motion estimation. To reduce computational complexity, the existing fast search algorithms move iteratively toward the winning point based only on a finite set of search points in every stage. Despite the efficiency of these algorithms, the search process is easily trapped into local minima, especially for high activity video sequences. To overcome this difficulty, we propose a three-states Markov model based algorithm that invokes the fuzzy-reasoning to provide the search an acceptance probability of being able to move out of local minima. Two schemes are employed to further enhance the performance of the algorithm. First, a set of initial search points that exploit high correlations among the motion vectors of the temporally and spatially adjacent blocks as well as their surrounding points are used. Second, an alternate search strategy is addressed to cover more area without increasing computations. Simulation. results show that the new algorithm offers superior performance with lower computational complexity and picture quality increase in terms of search points/block and MSE/pel, respectively, compared with the previous works in various scenarios. (c) 2005 Elsevier Inc. All rights reserved.
C1 Natl Taiwan Univ, Dept Elect Engn, Taipei 106, Taiwan.
   Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.
C3 National Taiwan University; National Taiwan University; National Taiwan
   University of Science & Technology
RP Chen, PH (corresponding author), Natl Taiwan Univ, Dept Elect Engn, Taipei 106, Taiwan.
EM paully@orchid.ee.ntu.edu.tw
CR [Anonymous], 1999, IMAGE VIDEO COMPRESS
   Chalidabhongse J, 1997, IEEE T CIRC SYST VID, V7, P477, DOI 10.1109/76.585927
   CHEN PH, 2002, P IEEE INT S INT SIG, P305
   JAN JS, 1997, P IEEE INT S CIRC SY, P2092
   KOGA T, 1981, P NTC 91
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Shie MC, 2000, IEICE T FUND ELECTR, VE83A, P121
   Shie MC, 1998, APCCAS '98 - IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P607, DOI 10.1109/APCCAS.1998.743893
   Tang CY, 1998, ELECTRON LETT, V34, P1091, DOI 10.1049/el:19980798
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   TORUAPIS AM, 2001, P VISUAL COMMUN IMAG
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 14
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 131
EP 142
DI 10.1016/j.jvcir.2005.09.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900008
OA Green Published
DA 2024-07-18
ER

PT J
AU Peker, KA
   Divakaran, A
AF Peker, KA
   Divakaran, A
TI Framework for measurement of the intensity of motion activity of video
   segments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE motion activity; compressed domain feature extraction; video indexing;
   MPEG-7
AB We present a psychophysical and analytical framework for comparing the performance of motion activity measures for video segments, with respect to a subjective ground truth. We first obtain a ground truth for the motion activity by conducting a psychophysical experiment. Then we present several low-complexity motion activity descriptors computed from compressed domain block motion vectors. In the first analysis, we quantize the descriptors and show that they perform well against the ground truth. The MPEG-7 motion activity descriptor is also among the best performers. In the second analysis, we examine the specific cases where each descriptor fails, using a novel pair-wise comparison method. The analytical measures overestimate or underestimate the intensity of motion activity under strong camera motion or extreme camera angles. We finally discuss the experimental methodology and analysis methods we used, and possible alternatives. We review the applications of motion activity and how our results relate to them. (C) 2004 Elsevier Inc. All rights reserved.
C1 Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.
RP Mitsubishi Elect Res Labs, 201 Broadway, Cambridge, MA 02139 USA.
EM peker@merl.com; ajayd@merl.com
RI Peker, Kadir Aşkın/AAE-7579-2020
CR AKUTSU A, 1992, P SPIE C VIS COMM IM, V18, P1522
   Ardizzone E., 1999, P IEEE INT C MULT CO
   Divakaran A., 2001, P SPIE C STOR RETR M
   DIVAKARAN A, 2000, MPEG0095717 ISO IEC
   DIVAKARAN A, 2001, J ELECT IMAGING, V10
   DIVAKARAN A, 2000, MPEG9975030
   *ISO IEC, 1999, MPEG99W3068 ISO IEC
   JEANNIN S, 2001, P IEEE T CIRC SYST V, V11
   Kobla V, 1997, P SOC PHOTO-OPT INS, V3022, P200, DOI 10.1117/12.263408
   MANORANJAN D, 1999, JTC1SC29WG11MPEG99M4
   PEKER KA, 2001, THESIS NJIT
   PEKER KA, 2001, P SPIE C STOR RETR M
   PEKER KA, 2001, P IEEE INT C MUTL EX
   PEKER KA, 2000, P IEEE INT C MUTL EX
   PEKER KA, 2002, P SPIE C STOR RETR M
   PEKER KA, 2001, P IEEE INT C IM PROC
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   VASCONCELOS N, 1997, P ICIP97
   WOLF W, 1996, P IEEE INT C AC SPEE, V2, P1228
   XIE L, 2002, P ICASSP IEEE INT C
NR 20
TC 9
Z9 9
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 265
EP 284
DI 10.1016/j.jvcir.2004.04.007
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100002
DA 2024-07-18
ER

PT J
AU Zhang, XD
   Feng, H
   Lo, KT
AF Zhang, XD
   Feng, H
   Lo, KT
TI Image watermarking using tree-based spatial-frequency feature of wavelet
   transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE watermarking; wavelet transform; multiresolution; copyright protection
AB In this paper, an image watermarking scheme is developed using the tree-based spatial-frequency feature of wavelet transform. With our approach, the watermark sequence is inserted in those high activity texture regions of an image having the maximum strength of just noticeable distortion (JND) tolerance of the human visual system (HVS). Simulation results show that the proposed method achieves a good compromise between the robustness and transparency. (C) 2003 Elsevier Inc. All rights reserved.
C1 Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
   Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   City Univ Hong Kong, Dept Comp Engn & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; Tsinghua University; City University
   of Hong Kong
RP Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
EM enktlo@polyu.edu.hk
RI Lo, Kwok Tung KT/O-2143-2013
CR [Anonymous], 1998, FUNDAMENTALS STAT SI
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dugad R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P419, DOI 10.1109/ICIP.1998.723406
   Hontsch I, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P41, DOI 10.1109/ICIP.1997.647379
   Inoue H., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P296, DOI 10.1109/ICIP.1999.821617
   Jong Ryul Kim, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P226, DOI 10.1109/ICIP.1999.822889
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   Lo KT, 2000, IEE P-VIS IMAGE SIGN, V147, P261, DOI 10.1049/ip-vis:20000209
   Min Wu, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P291, DOI 10.1109/ICIP.1999.821616
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Su J. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P301, DOI 10.1109/ICIP.1999.821618
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Zeng WJ, 1999, IEEE T IMAGE PROCESS, V8, P1534, DOI 10.1109/83.799882
   ZHANG XD, 1999, P ICSP 98 BEIJ CHIN, P823
NR 15
TC 20
Z9 22
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 474
EP 491
DI 10.1016/S1047-3203(03)00047-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800006
DA 2024-07-18
ER

PT J
AU Wang, HL
   Divakaran, A
   Vetro, A
   Chang, SF
   Sun, HF
AF Wang, HL
   Divakaran, A
   Vetro, A
   Chang, SF
   Sun, HF
TI Survey of compressed-domain features used in audio-visual indexing and
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE features; video indexing; audio indexing; compressed-domain; multimedia;
   compression; MPEG-1; MPEG-2; MPEG-7
ID VIDEO; DCT
AB In this paper, we attempt to provide a comprehensive and high-level review of audiovisual features that can be extracted from the standard compressed domains, such as MPEG-1 and MPEG-2. The paper is motivated by the myriad of active research works in extraction and application of compressed-domain features in various fields, such as indexing, filtering, and manipulation. Compressed-domain approaches avoid expensive computation and memory requirements involved in decoding and/or re-encoding. Selected features are categorized into four groups-spatial visual (e.g., color, texture, edge, shape), motion (e.g., motion field, trajectory), audio (e.g., energy, spectral features, pitch), and coding (e.g., bit rate, frame/block type). For each feature, we briefly discuss the extraction methods, computational complexity, potential effectiveness in applications, and possible limitations caused by compress-domain approaches. Finally, we also discuss the possibilities of extracting some important MPEG-7 visual and audio descriptors directly from the compressed domain. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.
C3 Columbia University
RP Columbia Univ, Dept Elect Engn, 500 W 120th St Rm 1312, New York, NY 10027 USA.
EM hwang@ee.columbia.edu
CR AKUTSU A, 1992, SPIE P VISUAL COMMUN, V1818, P1522
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   ARDIZZONE E, 1996, P INT C PATT REC
   Ardizzone E., 1999, P IEEE INT C MULT CO
   Arman F., 1993, Proceedings ACM Multimedia 93, P267, DOI 10.1145/166266.166297
   BAO OKC, 2000, P SPIE C STOR RETR M, P293
   BERGEN JR, 1992, P 2 EUR C COMP VIS
   BOCCIGNONE G, 2000, P SPIE C STOR RETR M, P523
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   CHANG SF, 1995, IEEE J SEL AREA COMM, P1
   CHEN JY, 1998, P IEEE WORKSH CONT B
   DAVIS JW, 1998, 487 MIT MED LAB PERC
   DIMITROVA N, 1995, ACM T INFORM SYST, V13, P408, DOI 10.1145/211430.211433
   DIVAKARAN A, 2000, P SPIE C STOR RETR I, P382
   DIVAKARAN A, 1999, P SPIE C STOR RETR I, V7, P545
   *DOLB LAB, 1997, DOLB AC3 MULT PERC C
   ENG HL, 1999, P IEEE INT C IM PROC
   Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163
   FENG J, 1996, P IEEE INT C IM PROC
   FERNANDO WAC, 1999, P SPIE C STOR RETR I, P687
   FORD RM, 1999, P SPIE C STOR RETR I, P666
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   HO YS, 1989, P ICASSP, P1890
   HUANG J, 1998, P IEEE INT C IM PROC
   *ISO IEC IS, 1996, 138182 ISOIEC IS
   *ISO IEC IS, 1993, 111722 ISOIEC IS
   *ISO IEC IS, 1996, 138183 ISOIEC IS
   *ISO IEC IS, 1997, 138187 ISOIEC IS
   *ISO IEC IS, 1993, 111723 ISOIEC IS
   Kobla V, 1997, P SOC PHOTO-OPT INS, V3022, P200, DOI 10.1117/12.263408
   Kobla V, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P335, DOI 10.1145/266180.266384
   Kobla V, 1996, P SOC PHOTO-OPT INS, V2916, P78, DOI 10.1117/12.257312
   KOBLA V, 1999, P IEEE WORKSH MULT S
   Kobla V., 1999, P SPIE C STOR RETR I
   Lienhart R., 1999, P SOC PHOTO-OPT INS, P290
   MENG J, 1995, IS T SPIE S P, V2419
   MENG J, 1996, P ACM MULT 96
   Nang J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P23, DOI 10.1145/319463.320047
   NAPHADE MR, 1998, P IEEE INT C IM PROC, V5
   NAPHADE MR, 2000, P IEEE INT C MULT EX, V1
   Ngo C.W., 2001, Proc. ACM Multimedia, P51, DOI DOI 10.1145/500141.500151
   NGO CW, 2000, P IEEE COMP SOC C CO, V2
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   PATEL NV, 1995, P SPIE C STOR RETR I, V4
   Patti AJ, 1997, IEEE T CIRC SYST VID, V7, P328, DOI 10.1109/76.564111
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Saur DD, 1997, P SOC PHOTO-OPT INS, V3022, P176, DOI 10.1117/12.263406
   SCHEIRER E, 1997, P ICASSP 97
   Shen B, 1996, J VIS COMMUN IMAGE R, V7, P411, DOI 10.1006/jvci.1996.0035
   SHEN B, 1996, P SPIE C STOR RETR I, V4
   Shen K, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB252
   SONG BC, 1999, P SPIE C STOR RETR I, V7, P710
   Srinivasan S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P393, DOI 10.1145/319463.319658
   SUNDARAM H, 2000, P ACM MULT 2000 LOS
   SUNDARAM H, 2000, P ICASSP 2000 IST TU
   TAN YP, 1999, P IEEE INT C IM PROC
   TAN YP, 1995, P IEEE INT C IM PROC, V1, P406
   TAN YP, 1999, IEEE T CIRC SYST VID
   Taniguchi Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P427
   TSE YT, 1991, P SPIE C IM PROC ALG, V2, P468
   Wang Y, 1997, ISCAS '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I - IV, P1488, DOI 10.1109/ISCAS.1997.622200
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   WON CS, 1999, P SPIE C STOR RETR I, V7, P677
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   YEO BL, 1995, P INT C MULT COMP SY, P2
   YEO BL, 1995, P IEEE INT C IM PROC, V2, P260
   YOSHIDA T, 1995, P SOC PHOTO-OPT INS, V2501, P799, DOI 10.1117/12.206786
   Zhang H., 1995, Multimedia Tools and Applications, V1, P89, DOI 10.1007/BF01261227
   Zhang T, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P67, DOI 10.1145/319463.319471
   Zhang T, 1999, INT CONF ACOUST SPEE, P3001, DOI 10.1109/ICASSP.1999.757472
   ZHONG Y, 1999, P IEEE INT C IM PROC
NR 73
TC 79
Z9 91
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2003
VL 14
IS 2
BP 150
EP 183
DI 10.1016/S1047-3203(03)00019-1
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 680AJ
UT WOS:000182953900005
DA 2024-07-18
ER

PT J
AU Lin, YH
   Song, WW
   Kang, WX
AF Lin, Yihong
   Song, Wenwei
   Kang, Wenxiong
TI Random hand gesture authentication via efficient Temporal Segment Set
   Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Biometrics; Random hand gesture; Hand gesture authentication; Two-stream
   neural network; Attention mechanism
AB Biometric authentication technologies are rapidly gaining popularity, and hand gestures are emerging as a promising biometric trait due to their rich physiological and behavioral characteristics. Hand gesture authentication can be categorized as defined hand gesture authentication and random hand gesture authenti-cation. Unlike defined hand gesture authentication, random hand gesture authentication is not constrained to specific hand gesture types, allowing users to perform hand gestures randomly during enrollment and verification, thus more flexible and friendly. However, in random hand gesture authentication, the model needs to extract more generalized physiological and behavioral features from different viewpoints and positions without gesture templates, which is more challenging. In this paper, we present a novel efficient Temporal -Segment-Set-Network (TS2N) that directly extracts both behavioral and physiological features from a single RGB video to further enhance the performance of random hand gesture authentication. Our method adopts a new motion pseudo-modality and leverages a set-based representation to capture behavioral characteristics online. Additionally, we propose a channel-spatial attention mechanism, Contextual Squeeze-and-Excitation Network (CoSEN), to better abstract and understand physiological characteristics by explicitly modeling the channel-spatial interdependence, thereby adaptively recalibrating channel-specific and spatial-specific responses. Extensive experiments on the largest public hand gesture authentication dataset SCUT-DHGA demonstrate TS2N's superiority against 21 state-of-the-art models in terms of EER (5.707% for full version and 6.664% for lite version) and computational cost (98.9022G for full version and 46.3741G for lite version). The code is available at https://github.com/SCUT-BIP-Lab/TS2N.
C1 [Lin, Yihong; Song, Wenwei; Kang, Wenxiong] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510641, Peoples R China.
   [Lin, Yihong; Song, Wenwei; Kang, Wenxiong] Pazhou Lab, Guangzhou 510335, Peoples R China.
   [Kang, Wenxiong] South China Univ Technol, Sch Future Technol, Guangzhou 511442, Peoples R China.
C3 South China University of Technology; Pazhou Lab; South China University
   of Technology
RP Kang, WX (corresponding author), South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510641, Peoples R China.; Kang, WX (corresponding author), Pazhou Lab, Guangzhou 510335, Peoples R China.; Kang, WX (corresponding author), South China Univ Technol, Sch Future Technol, Guangzhou 511442, Peoples R China.
EM auwxkang@scut.edu.cn
OI Song, Wenwei/0000-0002-7787-6604
FU National Natural Sci-ence Foundation of China [62376100, 61976095]
FX This work was partially supported by the National Natural Sci-ence
   Foundation of China under Grant No. 62376100 and Grant No. 61976095.
CR Ballas Nicolas, 2015, arXiv, DOI DOI 10.48550/ARXIV.1511.06432
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chan FKS, 2017, IEEE T INF FOREN SEC, V12, P1900, DOI 10.1109/TIFS.2017.2692684
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chen JY, 2023, INFORM SCIENCES, V636, DOI 10.1016/j.ins.2023.03.145
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai L., 2019, Pattern Recognit. Lett.
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Ducray B, 2017, IEEE ICC
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Ferrer MA, 2011, IEEE T INF FOREN SEC, V6, P1305, DOI 10.1109/TIFS.2011.2162948
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Harikrishnan D., 2023, Measurement: Sensors, V25
   He K., 2021, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Q., 2019, Comput. Vis. Pattern Recognit.
   Isbister K., 2012, Hum. Factors Comput. Syst.
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang XY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3180434
   Kocakulak M, 2023, EXPERT SYST APPL, V230, DOI 10.1016/j.eswa.2023.120550
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Lee J.-Y., 2018, British Machine Vision Conference
   Li QQ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3164162
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu C, 2021, IEEE T INF FOREN SEC, V16, P1550, DOI 10.1109/TIFS.2020.3036218
   Liu C, 2019, LECT NOTES COMPUT SC, V11818, P94, DOI 10.1007/978-3-030-31456-9_11
   Liu ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13688, DOI 10.1109/ICCV48922.2021.01345
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Maeda T., 2020, Electronics
   Martin R, 2021, RES ONE
   Matkowski WM, 2020, IEEE T INF FOREN SEC, V15, P1601, DOI 10.1109/TIFS.2019.2945183
   Muhammed A, 2023, J VIS COMMUN IMAGE R, V94, DOI 10.1016/j.jvcir.2023.103854
   Muthusamy D, 2022, EXPERT SYST APPL, V196, DOI 10.1016/j.eswa.2022.116678
   Ng JYH, 2018, IEEE WINT CONF APPL, P1577, DOI 10.1109/WACV.2018.00176
   Niu WJ, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103757
   Paluri M., 2014, INT C COMPUTER VISIO
   Peng G, 2017, IEEE T HUM-MACH SYST, V47, P404, DOI 10.1109/THMS.2016.2623562
   Prasath GA, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108145
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P568, DOI 10.1109/TIFS.2014.2302582
   Sharma S, 2015, EXPERT SYST APPL, V42, P821, DOI 10.1016/j.eswa.2014.08.052
   Song Wenwei, 2022, Biometric Recognition: 16th Chinese Conference, CCBR 2022, Proceedings. Lecture Notes in Computer Science (13628), P237, DOI 10.1007/978-3-031-20233-9_24
   Song Wenwei, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P453, DOI 10.1109/TBIOM.2022.3179279
   Song WW, 2024, IEEE T CIRC SYST VID, V34, P461, DOI 10.1109/TCSVT.2023.3286460
   Song WW, 2023, IEEE T INF FOREN SEC, V18, P1870, DOI 10.1109/TIFS.2023.3256708
   Song WW, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI 10.1109/IJCB52358.2021.9484390
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang F., 2017, arXiv
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wong AMH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122143
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J., 2014, IEEE INT JOINT C BIO, P1
   Wu J, 2016, IEEE COMPUT SOC CONF, P110, DOI 10.1109/CVPRW.2016.21
   Yu DJ, 2014, LECT NOTES ARTIF INT, V8818, P364, DOI 10.1007/978-3-319-11740-9_34
   Zhang C., 2020, ARXIV
   Zhou Y, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103182
   Zhou Z., 2020, IEEE INT C PERVASIVE
NR 63
TC 1
Z9 1
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103985
DI 10.1016/j.jvcir.2023.103985
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FY9H8
UT WOS:001149528200001
DA 2024-07-18
ER

PT J
AU Tang, J
   Wang, ZT
   Hao, GY
   Wang, K
   Zhang, Y
   Wang, N
   Liang, D
AF Tang, Jun
   Wang, Zhentao
   Hao, Guanyu
   Wang, Ke
   Zhang, Yan
   Wang, Nian
   Liang, Dong
TI SAE-PPL: Self-guided attention encoder with prior knowledge-guided
   pseudo labels for weakly supervised video anomaly detection☆
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised video anomaly detection; Self-training; Multiple
   instance learning; Attention mechanism
AB Recently, many weakly supervised video anomaly detection (WS-VAD) methods focus on generating reasonable pseudo-labels for frames by using video-level annotations. To achieve this goal, some existing label-noise cleaning techniques and pseudo-label generators are used by them, but their performance is limited. The main reason is that the useful prior knowledge, i.e., the graduality of anomaly events, is ignored. Here, we propose a Self-Training Framework, which assumes flexible soft boundaries between abnormal and normal clips. The framework consists of: (1) A prior knowledge guided pseudo-label generator that incorporates prior knowledge of video segment distributions into the MIL framework to generate high-confidence pseudo labels; (2) An improved self-guided attention encoder is developed to capture multiscale long-term spatiotemporal features, where dependencies among anomaly frames are preserved. Moreover, a pseudo-label based self-training scheme is adopted to supervise the encoder. Experimental results verify the superiority of our method over baseline approaches.
C1 [Tang, Jun; Wang, Zhentao; Hao, Guanyu; Zhang, Yan; Wang, Nian] Anhui Univ, Sch Elect Informat Engn, Hefei 230601, Peoples R China.
   [Wang, Ke; Liang, Dong] Anhui Univ, Sch Internet, Hefei 230601, Peoples R China.
C3 Anhui University; Anhui University
RP Wang, K (corresponding author), Anhui Univ, Sch Internet, Hefei 230601, Peoples R China.
EM 22014@ahu.edu.cn
FU Anhui Provincial Natural Science Foundation, China [2308085QF228];
   National Natural Science Foundation of China [62306004, 62273001,
   61772032]; University Synergy Innovation Program of Anhui Province
   [GXXT-2022-038]; The 2021 Central Government Special Fund for Guiding
   Local Scientific and Technological Development [202107d06020001]
FX This work was supported in part by the Anhui Provincial Natural Science
   Foundation, China under Grant 2308085QF228, in part by the National
   Natural Science Foundation of China under Grant 62306004, Grant 62273001
   and Grant 61772032, in part by the University Synergy Innovation Program
   of Anhui Province under Grant GXXT-2022-038, and in part by the 2021
   Central Government Special Fund for Guiding Local Scientific and
   Technological Development under Grant 202107d06020001.
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Amini MR, 2002, FR ART INT, V77, P390
   Andrews S., 2002, Adv. Neural Inf. Process. Syst., V15
   [Anonymous], 2015, PROC CVPR IEEE
   Bergman L, 2020, ARXIV
   Bergmann P, 2019, PROC CVPR IEEE, P9584, DOI 10.1109/CVPR.2019.00982
   Binder, 2019, ARXIV
   Burlina P, 2019, PROC CVPR IEEE, P11499, DOI 10.1109/CVPR.2019.01177
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Grandvalet Y, 2004, Advances in neural information processing systems, V17
   Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219
   Hendrycks D., 2016, ARXIV
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeong J, 2020, ICPRAM: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P23, DOI 10.5220/0008940900230032
   Jiang CH, 2018, ADV NEUR IN, V31
   Kamoona A.M., 2020, ARXIV
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Li S, 2022, AAAI CONF ARTIF INTE, P1395
   Liu S., 2022, Advances in Neural Information Processing Systems, V35, P1100, DOI DOI 10.48550/ARXIV.2210.16774,35
   Liu SH, 2023, PROC CVPR IEEE, P3759, DOI 10.1109/CVPR52729.2023.00366
   Liu SH, 2022, LECT NOTES COMPUT SC, V13676, P72, DOI 10.1007/978-3-031-19787-1_5
   Liu W, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3023
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Pang GS, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/3292500.3330871
   Pang GS, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2041, DOI 10.1145/3219819.3220042
   Peng Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P322, DOI 10.1007/978-3-030-58577-8_20
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tian Y., 2021, WEAKLY SUPERVISED VI
   Tian Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4955, DOI 10.1109/ICCV48922.2021.00493
   VonRueden L, 2019, ARXIV
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu D., 2015, ARXIV
   Yang JF, 2018, PROC CVPR IEEE, P7584, DOI 10.1109/CVPR.2018.00791
   Yang X., 2022, Advances in Neural Information Processing Systems, V35, P25739
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   YU F, 2021, P AAAI C ARTIFICIAL, V35, P10
   Zaheer M, 2021, ARXIV
   Zaheer Muhammad Zaigham, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P358, DOI 10.1007/978-3-030-58542-6_22
   Zhang JG, 2019, IEEE IMAGE PROC, P4030, DOI [10.1109/ICIP.2019.8803657, 10.1109/icip.2019.8803657]
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu Y., 2019, ARXIV
NR 50
TC 2
Z9 2
U1 4
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103967
DI 10.1016/j.jvcir.2023.103967
EA NOV 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD4U7
UT WOS:001116517900001
DA 2024-07-18
ER

PT J
AU Zhou, WJ
   Yue, YC
   Fang, MX
   Mao, SS
   Yang, RW
   Yu, L
AF Zhou, Wujie
   Yue, Yuchun
   Fang, Meixin
   Mao, Shanshan
   Yang, Rongwang
   Yu, Lu
TI AMCFNet: Asymmetric multiscale and crossmodal fusion network for RGB-D
   semantic segmentation in indoor service robots
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiscale feature; Crossmodal fusion; Differential feature integration;
   RGB-D information; Semantic segmentation
ID INFORMATION
AB Red-green-blue and depth (RGB-D) semantic segmentation is essential for indoor service robots to achieve accurate artificial intelligence. Various RGB-D indoor semantic segmentation methods have been proposed since the widespread adoption of depth maps. These methods have focused mainly on integrating the multiscale and crossmodal features extracted from RGB images and depth maps in the encoder and used unified strategies to recover the local details at the decoder progressively. However, these methods emphasized crossmodal fusion at the encoder, neglecting the distinguishability between RGB and depth features during decoding, thereby undermining the segmentation performance. To adequately exploit the features, we propose an efficient encoderdecoder architecture called asymmetric multiscale and crossmodal fusion network (AMCFNet) endowed with a differential feature integration strategy. Unlike existing methods, we use simple crossmodal fusion at the encoder and design an elaborate decoder to improve the semantic segmentation performance. Specifically, considering high- and low-level features, we propose a semantic aggregation module (SAM) to process the multiscale and crossmodal features in the last three network layers to aggregate high-level semantic information through a cascaded pyramid structure. Moreover, we design a spatial detail supplement module using low-level spatial details from depth maps to adaptively fuse these details and the information obtained from the SAM. Extensive experiments are conducted to demonstrate that the proposed AMCFNet outperforms state-of-the-art approaches.
C1 [Zhou, Wujie; Yue, Yuchun] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Peoples R China.
   [Zhou, Wujie] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 308232, Singapore.
   [Fang, Meixin; Mao, Shanshan; Yang, Rongwang; Yu, Lu] Zhejiang Univ, Hangzhou 310027, Peoples R China.
C3 Zhejiang University of Science & Technology; Nanyang Technological
   University; Zhejiang University
RP Fang, MX (corresponding author), Zhejiang Univ, Hangzhou 310027, Peoples R China.
EM fangmeixin@zju.edu.cn
FU National Key Research and Devel- opment Program of China
   [2022YFE0196000]; Na- tional Natural Science Foundation of China
   [62371422]
FX This work was supported by the National Key Research and Devel- opment
   Program of China (Grant No. 2022YFE0196000) , and the Na- tional Natural
   Science Foundation of China (Grant No. 62371422) .
CR Cao JM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7068, DOI 10.1109/ICCV48922.2021.00700
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LZ, 2021, IEEE T IMAGE PROCESS, V30, P2313, DOI 10.1109/TIP.2021.3049332
   Couprie C, 2013, Arxiv, DOI arXiv:1301.3572
   Dong SH, 2024, IEEE T INTELL TRANSP, V25, P657, DOI 10.1109/TITS.2023.3306368
   Fan XM, 2024, EXPERT SYST APPL, V238, DOI 10.1016/j.eswa.2023.121999
   Fang TY, 2022, INT CONF ACOUST SPEE, P2405, DOI 10.1109/ICASSP43922.2022.9747767
   Fayyaz M, 2017, LECT NOTES COMPUT SC, V10116, P493, DOI 10.1007/978-3-319-54407-6_33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Ji CM, 2023, IEEE SIGNAL PROC LET, V30, P493, DOI 10.1109/LSP.2023.3270759
   Jiang JD, 2018, Arxiv, DOI arXiv:1806.01054
   Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147
   Lin D, 2020, IEEE T CYBERNETICS, V50, P1120, DOI 10.1109/TCYB.2018.2885062
   Liu FY, 2017, IEEE T IMAGE PROCESS, V26, P2127, DOI 10.1109/TIP.2017.2675166
   Liu H, 2018, MULTIMED TOOLS APPL, V77, P22475, DOI 10.1007/s11042-018-6056-8
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma LN, 2017, IEEE INT C INT ROBOT, P598, DOI 10.1109/IROS.2017.8202213
   Pan Y, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106885
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Qian YQ, 2022, IEEE T INTELL TRANSP, V23, P11836, DOI 10.1109/TITS.2021.3107672
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Wang W., 2020, P EUR C COMP VIS, P135
   Wu YH, 2023, IEEE T PATTERN ANAL, V45, P12760, DOI 10.1109/TPAMI.2022.3202765
   Wu YH, 2022, IEEE T PATTERN ANAL, V44, P10261, DOI 10.1109/TPAMI.2021.3134684
   Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33
   Xiong ZT, 2020, PROC CVPR IEEE, P3991, DOI 10.1109/CVPR42600.2020.00405
   Xu G, 2023, DIGIT SIGNAL PROCESS, V136, DOI 10.1016/j.dsp.2023.104011
   Xu G, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103727
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan XC, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102082
   Yang EQ, 2023, ENG APPL ARTIF INTEL, V125, DOI 10.1016/j.engappai.2023.106729
   Yang JX, 2023, IEEE SIGNAL PROC LET, V30, P972, DOI 10.1109/LSP.2023.3299218
   Yang J, 2024, IEEE T CIRC SYST VID, V34, P1481, DOI 10.1109/TCSVT.2023.3296162
   Yuan JZ, 2019, IEEE ACCESS, V7, P169350, DOI 10.1109/ACCESS.2019.2955101
   Zhang GD, 2021, IEEE SIGNAL PROC LET, V28, P658, DOI 10.1109/LSP.2021.3066071
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou H, 2020, P AS C COMP VIS, P519
   Zhou H, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108468
   Zhou WJ, 2024, IEEE T MULTIMEDIA, V26, P4564, DOI 10.1109/TMM.2023.3323890
   Zhou WJ, 2023, IEEE T AUTOM SCI ENG, DOI 10.1109/TASE.2023.3313122
   Zhou WJ, 2024, IEEE T INTELL VEHICL, V9, P1919, DOI 10.1109/TIV.2023.3314527
   Zhou WJ, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3311480
   Zhou WJ, 2024, IEEE T EM TOP COMP I, V8, P1125, DOI 10.1109/TETCI.2023.3303930
   Zhou WJ, 2023, IEEE T SYST MAN CY-S, V53, P7631, DOI 10.1109/TSMC.2023.3298921
   Zhou WJ, 2023, IEEE T CIRC SYST VID, V33, P7096, DOI 10.1109/TCSVT.2023.3275314
   Zhou WJ, 2023, IEEE T IMAGE PROCESS, V32, P3027, DOI 10.1109/TIP.2023.3275538
   Zhou WJ, 2023, IEEE T MULTIMEDIA, V25, P3483, DOI 10.1109/TMM.2022.3161852
   Zhou WJ, 2021, IEEE INTELL SYST, V36, P73, DOI 10.1109/MIS.2020.2999462
   Zhou WJ, 2018, IEEE T IMAGE PROCESS, V27, P2086, DOI 10.1109/TIP.2018.2794207
   Zou W., 2022, Multimed. Tools Appl., P1
NR 56
TC 0
Z9 0
U1 5
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103951
DI 10.1016/j.jvcir.2023.103951
EA OCT 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y2HO4
UT WOS:001103531100001
DA 2024-07-18
ER

PT J
AU Qiu, JR
   Li, B
   Liao, RQ
   Mo, HQ
   Tian, LF
AF Qiu, Junrong
   Li, Bin
   Liao, Riqiang
   Mo, Hongqiang
   Tian, Lianfang
TI A dual-task region-boundary aware neural network for accurate pulmonary
   nodule segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pulmonary nodules; Segmentation; Region-boundary joint learning;
   Multi-task learning
ID LUNG-CANCER; ALGORITHMS
AB Recently, the performance of pulmonary nodule segmentation has improved fast because of the development of deep learning-based methods. However, existing CNN-based methods still don't solve the two issues, leading to poor segmentation: (1) The information of small nodules lost in continuous down-sampling operation; (2) Discriminative features can't be extracted from non-solid nodules because whose gray values are close to the surrounding environment. This study proposes a novel dual-task region-boundary aware deep convolutional neural network to solve the problems above. A hierarchical feature module is proposed to capture multi-scale information, improving small nodules' segmentation accuracy. Boundary guided module is introduced to extract edge features and predict nodule boundaries directly. In addition, a feature aggregation module is pro-posed to aggregate features at different levels. Besides, to better optimize the segment results and reduce overfitting, the region-boundary aware loss function is proposed. The method is trained and tested on the LIDC-IDRI dataset and the LUNA16 dataset, and the results demonstrate that our method is efficient. More importantly, our method is suitable for the segmentation of various nodules, especially small nodules, GGO nodules, and part-solid nodules.
C1 [Qiu, Junrong; Li, Bin; Mo, Hongqiang; Tian, Lianfang] South China Univ Technol, Automat Sci & Engn, Guangzhou 510640, Peoples R China.
   [Liao, Riqiang] Guangdong Prov Peoples Hosp, Guangdong Lung Canc Inst, Guangzhou 510080, Peoples R China.
   [Liao, Riqiang] Guangdong Acad Med Sci, Guangzhou 510080, Peoples R China.
   [Li, Bin] South China Univ Technol, Automat Sci & Engn, Wushan Rd, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology; Guangdong Academy of Medical
   Sciences & Guangdong General Hospital; Guangdong Academy of Medical
   Sciences & Guangdong General Hospital; South China University of
   Technology
RP Li, B (corresponding author), South China Univ Technol, Automat Sci & Engn, Wushan Rd, Guangzhou, Guangdong, Peoples R China.
EM binlee@scut.edu.cn
FU National Natural Science Foundation of China [62273155]; Key Laboratory
   of Autonomous Systems and Network Control of Ministry of Education (SCUT
   of China); National Engineering Research Center for Tissue Restoration
   and Reconstruction; Guangdong Engineering Technology Research Center of
   Unmanned Aerial Vehicle Systems; Guangdong Engineering Research Center
   of Cloud-Edge-End Collaboration Technology for Smart City
FX This work is supported by the National Natural Science Foundation of
   China under Grant 62273155, the Key Laboratory of Autonomous Systems and
   Network Control of Ministry of Education (SCUT of China) , the National
   Engineering Research Center for Tissue Restoration and Reconstruction,
   Guangdong Engineering Research Center of Cloud-Edge-End Collaboration
   Technology for Smart City, and Guangdong Engineering Technology Research
   Center of Unmanned Aerial Vehicle Systems.
CR Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Basak H, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108673
   Cao HC, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105934
   Cicek Ozgun, 2016, MED IM COMP COMP AS
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao SG, 2020, J THORAC ONCOL, V15, P1567, DOI 10.1016/j.jtho.2020.04.028
   Gu Y, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104806
   Haghighi Fatemeh, 2020, Med Image Comput Comput Assist Interv, V12261, P137, DOI 10.1007/978-3-030-59710-8_14
   Hatamizadeh A, 2022, Arxiv, DOI [arXiv:2201.01266, DOI 10.48550/ARXIV.2201.01266]
   Hatamizadeh A, 2022, IEEE WINT CONF APPL, P1748, DOI 10.1109/WACV51458.2022.00181
   Kalpathy-Cramer J, 2016, J DIGIT IMAGING, V29, P476, DOI 10.1007/s10278-016-9859-z
   Kervadec H, 2019, PR MACH LEARN RES, V102, P285
   Kuhnigk JM, 2006, IEEE T MED IMAGING, V25, P417, DOI 10.1109/TMI.2006.871547
   Li XX, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/6727957
   Liu H, 2019, PHYS MEDICA, V63, P112, DOI 10.1016/j.ejmp.2019.06.003
   Luo SC, 2022, APPL INTELL, V52, P15617, DOI 10.1007/s10489-021-03038-2
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Qin YL, 2019, MED PHYS, V46, P1218, DOI 10.1002/mp.13349
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroeder W., 1998, The visualization toolkit an object-oriented approach to 3D graphics
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shamshad F, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102802
   Keetha NV, 2020, Arxiv, DOI arXiv:2003.09293
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H., 2023, Int. J. Comput. Assist. Radiol. Surg., P1
   Wang S, 2017, IEEE ENG MED BIO, P1752, DOI 10.1109/EMBC.2017.8037182
   Wang Y., 2022, Med. Phys.
   Wu WH, 2020, MED PHYS, V47, P4054, DOI 10.1002/mp.14248
   Yu C., 2021, INT J COMPUT VISION, V129, P3051, DOI [DOI 10.1007/s11263-021-01515-2, 10.1007/s11263-021-01515-2]
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yuan CY, 2023, MED PHYS, V50, P4887, DOI 10.1002/mp.16265
   Zhang ZJ, 2019, LECT NOTES COMPUT SC, V11764, P442, DOI 10.1007/978-3-030-32239-7_49
   Zhou F., 2021, 2021 IEEE INT C BIOI
   Zhou ZX, 2022, IEEE J BIOMED HEALTH, V26, P5619, DOI 10.1109/JBHI.2022.3198509
   Zhou ZW, 2019, LECT NOTES COMPUT SC, V11767, P384, DOI 10.1007/978-3-030-32251-9_42
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 39
TC 2
Z9 2
U1 8
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103909
DI 10.1016/j.jvcir.2023.103909
EA AUG 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T2MG9
UT WOS:001076369300001
DA 2024-07-18
ER

PT J
AU Xiang, DH
   Xu, W
   Zhang, YT
   Peng, B
   Wang, GT
   Li, K
AF Xiang, Donghai
   Xu, Wei
   Zhang, Yuting
   Peng, Bei
   Wang, Guotai
   Li, Kang
TI MTMVC: Semi-supervised 3D hand pose estimation using multi-task and
   multi-view consistency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand pose estimation; Semi-supervised learning; Deep learning;
   Consistency constraint
ID REGRESSION; NETWORK
AB The high performance of state-of-the-art deep learning methods for 3D hand pose estimation heavily depends on a large annotated training set. However, it is difficult and time-consuming to obtain the annotations for 3D hand poses. To leverage unannotated images to reduce the annotation cost, we propose a semi-supervised method based on Multi-Task and Multi-View Consistency (MTMVC) for hand pose estimation. First, we obtain the joints based on heatmap prediction and coordinate regression parallelly and encourage their consistency. Second, we introduce multi-view consistency to encourage the predicted poses to be rotation-invariant. Thirdly, to make the network pay more attention to the hand region, we propose a spatially weighted consistency. Experiments on four public datasets showed that our proposed MTMVC outperformed existing semi-supervised hand pose estimation methods, and by only using half of the annotations, the accuracy of our method was comparable to those of several state-of-the-art fully supervised methods.
C1 [Xiang, Donghai; Peng, Bei; Wang, Guotai] Univ Elect Sci & Technol China, Sch Mech & Elect Engn, Chengdu, Peoples R China.
   [Xu, Wei] Univ Sci & Technol China, Suzhou Inst Adv Res, Suzhou, Peoples R China.
   [Zhang, Yuting] Sichuan Univ, West China Hosp, Dept Rehabil Med, Chengdu, Peoples R China.
   [Wang, Guotai] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.
   [Li, Kang] Sichuan Univ, West China Hosp, West China Biomed Big Data Ctr, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China; Chinese Academy
   of Sciences; University of Science & Technology of China, CAS; Sichuan
   University; Sichuan University
RP Wang, GT (corresponding author), Univ Elect Sci & Technol China, Sch Mech & Elect Engn, Chengdu, Peoples R China.
EM guotai.wang@uestc.edu.cn; likang@wchscu.cn
RI Yao, Chen/JVD-6226-2023; chen, bin/KBQ-8114-2024; liu,
   yuhao/JWP-0475-2024; Zhang, Yuting/JRW-3937-2023; chen,
   qy/JXM-3217-2024; Liu, Jinyu/JYQ-6274-2024; Zhang, Yuting/JZE-2800-2024
OI chen, bin/0000-0002-3398-1314; Xu, Wei/0000-0002-0273-0416
FU National Key Research and Develop-ment Program of China
   [2020YFB1711500]; National Natu-ral Science Foundation of China
   [51975107, 62271115]
FX Acknowledgments This work was supported by National Key Research and
   Develop-ment Program of China under grant 2020YFB1711500, National
   Natu-ral Science Foundation of China under grant 51975107 and 62271115.
CR Cai YJ, 2018, LECT NOTES COMPUT SC, V11210, P678, DOI 10.1007/978-3-030-01231-1_41
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chen XH, 2018, IEEE ACCESS, V6, P43425, DOI 10.1109/ACCESS.2018.2863540
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Ding L, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103200
   Du K, 2019, PROC CVPR IEEE, P9888, DOI 10.1109/CVPR.2019.01013
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Ge LH, 2018, LECT NOTES COMPUT SC, V11217, P489, DOI 10.1007/978-3-030-01261-8_29
   Ge LH, 2018, PROC CVPR IEEE, P8417, DOI 10.1109/CVPR.2018.00878
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Guo HK, 2017, IEEE IMAGE PROC, P4512, DOI 10.1109/ICIP.2017.8297136
   Huang WT, 2020, AAAI CONF ARTIF INTE, V34, P11061
   Huo XY, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108727
   Kortier HG, 2015, IEEE T NEUR SYS REH, V23, P796, DOI 10.1109/TNSRE.2014.2357579
   Li YM, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108472
   Lin Q., 2023, P IEEE C COMPUTER VI, P1
   Liu SW, 2021, PROC CVPR IEEE, P14682, DOI 10.1109/CVPR46437.2021.01445
   Mitra R, 2020, PROC CVPR IEEE, P6906, DOI 10.1109/CVPR42600.2020.00694
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oberweger M, 2020, IEEE T PATTERN ANAL, V42, P1898, DOI 10.1109/TPAMI.2019.2907951
   Pan TH, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103461
   Rad M, 2018, PROC CVPR IEEE, P4663, DOI 10.1109/CVPR.2018.00490
   Remelli E, 2017, IEEE I CONF COMP VIS, P2554, DOI 10.1109/ICCV.2017.277
   Sharma S, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107892
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Spurr Adrian, 2020, P EUR C COMP VIS, P211
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Wan CD, 2017, PROC CVPR IEEE, P1196, DOI 10.1109/CVPR.2017.132
   Wang GJ, 2018, J VIS COMMUN IMAGE R, V55, P404, DOI 10.1016/j.jvcir.2018.04.005
   Wu MY, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102802
   Xiong F, 2019, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2019.00088
   Yang J, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108439
   Yang L., 2021, P IEEE CVF INT C COM, P11364
   Yuan SX, 2018, PROC CVPR IEEE, P2636, DOI 10.1109/CVPR.2018.00279
   Yuan SX, 2017, PROC CVPR IEEE, P2605, DOI 10.1109/CVPR.2017.279
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang XY, 2022, IEEE T MULTIMEDIA, V24, P166, DOI 10.1109/TMM.2020.3047552
   Zhou X., 2016, IJCAI, P2421
NR 42
TC 0
Z9 0
U1 5
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103902
DI 10.1016/j.jvcir.2023.103902
EA AUG 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P7BI5
UT WOS:001052185300001
DA 2024-07-18
ER

PT J
AU Tian, QH
   Sun, WX
   Zhang, LZ
   Pan, H
   Chen, QH
   Wu, JL
AF Tian, Qiuhong
   Sun, Wenxuan
   Zhang, Lizao
   Pan, Hao
   Chen, Qiaohong
   Wu, Jialu
TI Gesture image recognition method based on DC-Res2Net and a feature
   fusion attention module
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand gesture recognition; Multiscale features; Feature fusion attention
   module; Selective kernel network
AB To extract decisive features from gesture images and solve the problem of information redundancy in the existing gesture recognition methods, we propose a new multi-scale feature extraction module named densely connected Res2Net (DC-Res2Net) and design a feature fusion attention module (FFA). Firstly, based on the new dimension residual network (Res2Net), the DC-Res2Net uses channel grouping to extract fine-grained multi scale features, and dense connection has been adopted to extract stronger features of different scales. Then, we apply a selective kernel network (SK-Net) to enhance the representation of effective features. Afterwards, the FFA has been designed to remove redundant information in features by fusing low-level location features with high-level semantic features. Finally, experiments have been conducted to validate our method on the OUHANDS, ASL, and NUS-II datasets. The results demonstrate the superiority of DC-Res2Net and FFA, which can extract more decisive features and remove redundant information while ensuring high recognition accuracy and low computational complexity.
C1 [Tian, Qiuhong; Sun, Wenxuan; Zhang, Lizao; Pan, Hao; Chen, Qiaohong; Wu, Jialu] Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Zhejiang Sci-Tech University
RP Tian, QH (corresponding author), Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Peoples R China.
EM tianqiuhong@zstu.edu.cn
FU National Natural Science Foundation of China [51405448]; Zhejiang
   Sci-Tech University [18032117-Y]; Zhejiang University Student Science
   and Technology Achievement Promotion Project [14530031661961]; Zhejiang
   Sci-Tech University 2021 National University Students Innovation and
   Entrepreneurship Training Program [11120032382104]
FX This work was supported by the National Natural Science Foundation of
   China (51405448). Qiuhong Tian acknowledges financial support from the
   doctoral research start-up funding of Zhejiang Sci-Tech University
   (18032117-Y). This work was also supported by Zhejiang University
   Student Science and Technology Achievement Promotion Project
   (14530031661961) and Zhejiang Sci-Tech University 2021 National
   University Students Innovation and Entrepreneurship Training Program
   (11120032382104).
CR Adthya V., 2020, Procedia Computer Science, V171, P2353, DOI 10.1016/j.procs.2020.04.255
   Ansar H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136481
   Ansari ZA, 2016, SADHANA-ACAD P ENG S, V41, P161, DOI 10.1007/s12046-015-0405-3
   Bhaumik G, 2023, MULTIMED TOOLS APPL, DOI [10.1007/s11042-023-16988-1, 10.1007/s11042-021-11623-3]
   Bhaumik G, 2022, VISUAL COMPUT, V38, P3853, DOI 10.1007/s00371-021-02225-z
   Chatterjee S, 2015, ADV INTELL SYST, V309, P429, DOI 10.1007/978-81-322-2009-1_48
   Chen FY, 2019, IEEE SENS J, V19, P8441, DOI 10.1109/JSEN.2018.2877978
   Chen YP, 2017, ADV NEUR IN, V30
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Han MM, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P287, DOI 10.1109/SNPD.2016.7515915
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hsu FR, 2020, IEEE CONSUM ELECTR M, V9, P43, DOI 10.1109/MCE.2019.2941463
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain Vanita, 2021, International Journal of Information Technology, V13, P1193, DOI 10.1007/s41870-021-00617-x
   Jiang D, 2019, CLUSTER COMPUT, V22, P13261, DOI 10.1007/s10586-018-1844-5
   Joshi G., 2018, INT C ADV COMP DAT S, P65
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Nguyen LT, 2021, INT WORK QUAL MULTIM, P141, DOI 10.1109/QoMEX51781.2021.9465430
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu D, 2020, IEEE T IMAGE PROCESS, V29, P3695, DOI 10.1109/TIP.2020.2964518
   Luo G, 2020, IEEE ACCESS, V8, P31481, DOI 10.1109/ACCESS.2020.2973305
   Meng L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041120
   Mercanoglu Sincan O, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806467
   Pardasani A, 2018, INT CONF RELI INFO, P529, DOI 10.1109/ICRITO.2018.8748590
   Pradhan J, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103396
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Roy K, 2022, VISUAL COMPUT, V38, P2801, DOI 10.1007/s00371-021-02157-8
   Sadeddine K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103193
   Sahoo J. P., 2021, New Paradigms in Computational Modeling and its Applications, P189, DOI [10.1016/B978-0-12-822133-4.00011-6, DOI 10.1016/B978-0-12-822133-4.00011-6]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Siming He, 2019, 2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM). Proceedings, P392, DOI 10.1109/AIAM48774.2019.00083
   Singh DK, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P487, DOI 10.1109/ICCCIS51004.2021.9397203
   Singha J, 2018, NEURAL COMPUT APPL, V29, P1129, DOI 10.1007/s00521-016-2525-z
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan YS, 2021, NEURAL COMPUT APPL, V33, P5339, DOI 10.1007/s00521-020-05337-0
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Tian QH, 2021, TECHNOL HEALTH CARE, V29, P527, DOI 10.3233/THC-192000
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JW, 2018, PROC SPIE, V10806, DOI 10.1117/12.2503080
   Wang S, 2023, VISUAL COMPUT, V39, P4487, DOI 10.1007/s00371-022-02602-2
   Wang WJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136414
   Wang ZB, 2022, IEEE T MOBILE COMPUT, V21, P2398, DOI 10.1109/TMC.2020.3038303
   Wei CC, 2021, IEEE T CIRC SYST VID, V31, P1138, DOI 10.1109/TCSVT.2020.2999384
   Xie B, 2018, J ENG-JOE, P1515, DOI 10.1049/joe.2018.8327
   Xu Kun, 2021, 2021 International Conference on Communications, Information System and Computer Engineering (CISCE), P447, DOI 10.1109/CISCE52179.2021.9445897
   Xu LX, 2022, NEUROCOMPUTING, V480, P99, DOI 10.1016/j.neucom.2022.01.048
   Yadav KS, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12970
   Yang L, 2019, MACH VISION APPL, V30, P1071, DOI 10.1007/s00138-019-01038-4
   Zhang SJ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103280
   Zhang XL, 2019, IEEE SENS J, V19, P5775, DOI 10.1109/JSEN.2019.2904595
NR 53
TC 3
Z9 3
U1 7
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103891
DI 10.1016/j.jvcir.2023.103891
EA JUL 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P0CY3
UT WOS:001047416600001
DA 2024-07-18
ER

PT J
AU Juneja, A
   Kumar, V
   Singla, SK
AF Juneja, Akshay
   Kumar, Vijay
   Singla, Sunil Kumar
TI Aethra-net: Single image and video dehazing using autoencoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Aethra-net; Image reconstruction; Transmission map; Vessel enhancement;
   Video dehazing
ID QUALITY ASSESSMENT; ENHANCEMENT; SCALE
AB A fast and efficient video dehazing system with low computational complexity has a huge demand among drivers during hazy winter nights. There are only a few video dehazing models that exist in literature. Video dehazing requires the sequential extraction and processing of frames. The processed frames must be restored in the same sequence as the original video. However, the existing video dehazing algorithms suffer from color distortion due to the continuous processing of frames. They are not suitable for videos with dense haze. Furthermore, some dehazing systems require hardware, whereas the proposed model is completely software-based to reduce the computational costs. In this paper, an image and video dehazing system called Aethra-Net is developed. A gush enhancer-based autoencoder is modified to obtain the transmission map. The structure of gush enhancement module resembles the processing of light entering the human eye from different paths. The multiple blocks of Resnet-101 layers are employed to overcome vanishing gradient problem. The vessel enhancement filter is also incorporated to enhance the performance of the proposed system. The proposed model has a susceptibility to compute the dehazed images effectively. The proposed model is evaluated on various benchmark datasets and compared with the existing dehazing techniques. Experimental results reveal that the performance of Aethra-Net is found superior as compared to the existing dehazing models.
C1 [Juneja, Akshay; Singla, Sunil Kumar] Thapar Inst Engn & Technol, Dept Elect & Instrumentat Engn, Patiala 147004, Punjab, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Informat Technol, Jalandhar 144027, Punjab, India.
C3 Thapar Institute of Engineering & Technology; National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Juneja, A (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Instrumentat Engn, Patiala 147004, Punjab, India.
EM ajuneja60_phd20@thapar.edu
RI Kumar, Vijay/A-2782-2015; Juneja, Dr. Akshay/KCK-0186-2024
OI Juneja, Dr. Akshay/0000-0002-0616-6613
FU Council of Scientific and Industrial Research (CSIR) , India [22 (0801)
   /19/EMR-II]
FX Funding This research is supported by the Council of Scientific and
   Industrial Research (CSIR) , India. The sanction number of the scheme is
   22 (0801) /19/EMR-II.
CR Adidela S., 2021, 2021 IEEE 18 IND COU, P1
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   [Anonymous], 2020, ANGIOGRAPHY
   Bennur A., 2020, ARXIV
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen ZH, 2020, VISUAL COMPUT, V36, P2189, DOI 10.1007/s00371-020-01929-y
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Fu MH, 2021, IEEE COMPUT SOC CONF, P203, DOI 10.1109/CVPRW53098.2021.00029
   Gandelsman Y, 2019, PROC CVPR IEEE, P11018, DOI 10.1109/CVPR.2019.01128
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Jacques F., 2021, ENCY ENV
   Juneja A, 2023, VISUAL COMPUT, V39, P3905, DOI 10.1007/s00371-022-02534-x
   Juneja A, 2022, ARCH COMPUT METHOD E, V29, P1727, DOI 10.1007/s11831-021-09637-z
   Dhara SK, 2021, IEEE T CIRC SYST VID, V31, P2076, DOI 10.1109/TCSVT.2020.3007850
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Kumar R, 2021, IEEE T INTELL TRANSP, V22, P6536, DOI 10.1109/TITS.2020.2993906
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li XR, 2023, VISUAL COMPUT, V39, P1307, DOI 10.1007/s00371-022-02407-3
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Liu Y, 2023, DISPLAYS
   Mandal G., 2020, SADHANA, V45, P1
   Mehra A, 2021, IEEE T INTELL TRANSP, V22, P4256, DOI 10.1109/TITS.2020.3013099
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Parihar AS, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103722
   Pawar R.P., 2020, NATL CRIME RECORDS B, V53, P117
   Peng SJ, 2021, NEUROCOMPUTING, V458, P602, DOI 10.1016/j.neucom.2020.02.134
   Pietrasik T, 2021, ROAD TRAFFIC INJURIE
   Pro C., 2021, CARPROUSA
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Sharma N, 2021, ARCH COMPUT METHOD E, V28, P4449, DOI 10.1007/s11831-021-09541-6
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Singh Ayush, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12538), P166, DOI 10.1007/978-3-030-66823-5_10
   Singh D, 2019, ARCH COMPUT METHOD E, V26, P1395, DOI 10.1007/s11831-018-9294-z
   Soma P, 2022, VISUAL COMPUT, V38, P2569, DOI 10.1007/s00371-021-02132-3
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Su Z, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103706
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Tu ZZ, 2022, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR52688.2022.00568
   Wang H., 2022, IEEE Transactions on Multimedia
   Wang HB, 2023, Arxiv, DOI arXiv:2301.02484
   Wang HB, 2021, IEEE T MULTIMEDIA, V23, P3828, DOI 10.1109/TMM.2020.3032023
   Wang HB, 2020, IEEE MULTIMEDIA, V27, P112, DOI 10.1109/MMUL.2020.2999464
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang YL, 2021, IET IMAGE PROCESS, V15, P2454, DOI 10.1049/ipr2.12233
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang SD, 2023, VISUAL COMPUT, V39, P953, DOI 10.1007/s00371-021-02377-y
   Zhang XY, 2021, PROC CVPR IEEE, P9235, DOI 10.1109/CVPR46437.2021.00912
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 66
TC 3
Z9 3
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103855
DI 10.1016/j.jvcir.2023.103855
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J1KQ5
UT WOS:001007269100001
DA 2024-07-18
ER

PT J
AU Liang, S
   Liu, RH
   Qian, JS
AF Liang, Song
   Liu, Ruihang
   Qian, Jiansheng
TI Fast saliency prediction based on multi-channels activation optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency prediction; Convolutional neural networks; Human eye fixations;
   Deep learning
ID VISUAL-ATTENTION; MODEL
AB The saliency prediction precision has improved rapidly with the development of deep learning technology, but the inference speed is slow due to the continuous deepening of networks. Hence, this paper proposes a fast saliency prediction model. Concretely, the siamese network backbone based on tailored EfficientNetV2 accelerates the inference speed while maintaining high performance. The shared parameters strategy further curbs parameter growth. Furthermore, we add multi-channel activation maps to optimize the fine features considering different channels and low-level visual features, which improves the interpretability of the model. Extensive experiments show that the proposed model achieves competitive performance on the standard benchmark datasets, and prove the effectiveness of our method in striking a balance between prediction accuracy and inference speed. Moreover, the small model size allows our method to be applied in edge devices. The code is available at: https://github.com/lscumt/fast-fixation-prediction.
C1 [Liang, Song; Qian, Jiansheng] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
   [Liu, Ruihang] China Univ Min & Technol, Xuhai Coll, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Qian, JS (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM qianzhangiqa@126.com
CR [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], 2012, Technical Report
   Borji A., 2015, P CVPR WORKSH FUT DA
   Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Chen L, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR), P85, DOI 10.1109/RCAR.2017.8311840
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Fan SJ, 2023, IEEE T PATTERN ANAL, V45, P1682, DOI 10.1109/TPAMI.2022.3169234
   Frintrop S, 2009, IEEE INT CONF ROBOT, P758
   Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689
   Gao D., 2008, Advances in Neural Information Processing Systems 20, P497
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Hu FY, 2021, INT C PATT RECOG, P9054, DOI 10.1109/ICPR48806.2021.9413057
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Jia XZ, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104549
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kroner A, 2024, Arxiv, DOI arXiv:1902.06634
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2018, LECT NOTES COMPUT SC, V11220, P798, DOI 10.1007/978-3-030-01270-0_47
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Kummerer M., 2015, PROC INT C LEARN REP
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Liang S, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103356
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Lou JX, 2022, NEUROCOMPUTING, V494, P455, DOI 10.1016/j.neucom.2022.04.080
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Mancas M, 2016, SPRINGER SER COG NEU, V10, P331, DOI 10.1007/978-1-4939-3435-5_18
   Pan JT, 2018, Arxiv, DOI arXiv:1701.01081
   Reddy N, 2020, Arxiv, DOI arXiv:2003.04942
   Rosenholtz R, 2016, ANNU REV VIS SCI, V2, P437, DOI 10.1146/annurev-vision-082114-035733
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stewart EEM, 2020, J VISION, V20, DOI 10.1167/jov.20.12.2
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P2413, DOI 10.1109/TPAMI.2020.2966453
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zabihi S., 2022, IMAGE COMMUN, V104
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
NR 59
TC 0
Z9 0
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103831
DI 10.1016/j.jvcir.2023.103831
EA MAY 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H7QY6
UT WOS:000997876800001
DA 2024-07-18
ER

PT J
AU Liu, Z
   Zhang, Y
   Guo, XJ
AF Liu, Zhi
   Zhang, Yi
   Guo, Xiaojie
TI Boosting semantic segmentation via feature enhancement?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Feature enhancement; Deep learning
AB Semantic segmentation aims to map each pixel of an image into its corresponding semantic label. Most existing methods either mainly concentrate on high-level features or simple combination of low-level and high-level features from backbone convolutional networks, which may weaken or even ignore the compensation between different levels. To effectively take advantages from both shallow (textural) and deep (semantic) features, this paper proposes a novel plug-and-play module, namely feature enhancement module (FEM). The proposed FEM first uses an information extractor to extract the desired details or semantics from different stages, and then enhances target features by taking in the extracted message. Two types of FEM, i.e., detail FEM and semantic FEM, can be customized. Concretely, the former type strengthens textural information to protect key but tiny/low-contrast details from suppression/removal, while the other one highlights structural information to boost segmentation performance. By equipping a given backbone network with FEMs, there might contain two information flows, i.e., detail flow and semantic flow. Extensive experiments on the Cityscapes, ADE20K and PASCAL Context datasets are conducted to validate the effectiveness of our design. The code has been released at https://github.com/SuperZ-Liu/FENet.
C1 [Liu, Zhi; Zhang, Yi; Guo, Xiaojie] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Zhang, Y (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM liuzhi@tju.edu.cn; yizhang@tju.edu.cn; xj.max.guo@gmail.com
RI Guo, Xiaojie/AAC-3114-2022; zhang, ly/JMB-7214-2023; chen,
   yanhong/JVE-0289-2024
FU National Key Research and Development Program of China [2022YFF0904301]
FX Acknowledgments This work was supported in part by National Key Research
   and Development Program of China (2022YFF0904301) .
CR Aksoy Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201275
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng B., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2107.06278, 10.48550/arXiv.2107.06278]
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2019, IEEE I CONF COMP VIS, P6818, DOI 10.1109/ICCV.2019.00692
   Fan MY, 2021, PROC CVPR IEEE, P9711, DOI 10.1109/CVPR46437.2021.00959
   Fan QN, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275081
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hua MJ, 2019, IEEE INT CONF COMP V, P886, DOI 10.1109/ICCVW.2019.00117
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X., 2020, P IEEE CVF C COMP VI, P8950, DOI 10.1109/CVPR42600.2020.00897
   Li XT, 2020, AAAI CONF ARTIF INTE, V34, P11418
   Li X, 2019, PROC CVPR IEEE, P9137, DOI 10.1109/CVPR.2019.00936
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu WW, 2022, IEEE T PATTERN ANAL, V44, P7955, DOI 10.1109/TPAMI.2021.3119334
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Paszke A., 2017, NIPS W
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen Dingguo, 2020, P NEUR INF PROC SYST, V6, P8
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Teichmann M, 2018, IEEE INT VEH SYM, P1013, DOI 10.1109/IVS.2018.8500504
   Wang C, 2022, AAAI CONF ARTIF INTE, P2397
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Yin H, 2019, PROC CVPR IEEE, P8750, DOI 10.1109/CVPR.2019.00896
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yuan YH, 2021, Arxiv, DOI arXiv:1809.00916
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhen M., 2020, IEEE C COMPUT VIS PA, P13666, DOI DOI 10.48550/ARXIV.2004.07684
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
   Zhu LY, 2021, PROC CVPR IEEE, P12532, DOI 10.1109/CVPR46437.2021.01235
NR 46
TC 1
Z9 1
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103796
DI 10.1016/j.jvcir.2023.103796
EA FEB 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9W3FE
UT WOS:000948963600001
DA 2024-07-18
ER

PT J
AU Shi, PC
   Zhang, CH
   Xu, SC
   Qi, H
   Chen, XH
AF Shi, Peicheng
   Zhang, Chenghui
   Xu, Shucai
   Qi, Heng
   Chen, Xinhe
TI MT-Net: Fast video instance lane detection based on space time memory
   and template matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lane detection; Jitter; Space -time memory; Template matching; Error
   propagation
ID SYSTEM
AB Currently, only a few lane detection methods focus on the dynamic characteristics of a video. In continuous prediction, single-frame detection results produce different degrees of jitter, resulting in poor robustness. We propose a new fast video instance lane detection network, called MT-Net, based on space-time memory and template matching. Memory templates were used to establish feature associations between past and current frames from a local-global perspective to mitigate jitter from scene changes and other disturbances. Moreover, we also investigated the sources and spreading mechanism of memory errors. We designed new query frame and memory encoders to obtain higher-precision memory and query frame features. The experimental results showed that, compared with state-of-the-art models, the proposed model can reduce the number of parameters by 62.28% and the unnecessary jitter and unstable factors in muti-frame lane prediction results by 12.70%, and increases the muti-frame lane detection speed by 1.79. Our proposed methods has obvious advantages in maintaining multi-frame instance lane stability and reducing errors.
C1 [Shi, Peicheng; Zhang, Chenghui; Qi, Heng; Chen, Xinhe] Anhui Polytech Univ, Coll Mech Engn, Wuhu 241000, Peoples R China.
   [Xu, Shucai] Tsinghua Univ, State Key Lab Automot Safety & Energy, Beijing 100084, Peoples R China.
C3 Anhui Polytechnic University; Tsinghua University
RP Shi, PC (corresponding author), Anhui Polytech Univ, Coll Mech Engn, Wuhu 241000, Peoples R China.; Xu, SC (corresponding author), Tsinghua Univ, State Key Lab Automot Safety & Energy, Beijing 100084, Peoples R China.
EM shipeicheng@126.com; xushc@tsinghua.edu.cn
RI Chen, Xinhe/KKL-9119-2024
FU National Key RD Program [2018YFE0204302]; Natural Science Foundation of
   Anhui Province [2208085MF173]; Anhui Province Key Research and
   Development Program Project [202104a05020003]; Open Project of the Key
   Laboratory of the Transportation Industry for the Detection, Diagnosis
   and Maintenance Technology of Transportation Vehicles [JTZL904]
FX This work was funded by the National Key R&D Program (No.
   2018YFE0204302) , by the Natural Science Foundation of Anhui Province
   (No. 2208085MF173) and the Anhui Province Key Research and Development
   Program Project (No. 202104a05020003) . This research was also funded by
   the Open Project of the Key Laboratory of the Transportation Industry
   for the Detection, Diagnosis and Maintenance Technology of
   Transportation Vehicles (JTZL904) .
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Borkar A, 2012, IEEE T INTELL TRANSP, V13, P365, DOI 10.1109/TITS.2011.2173196
   Cheng HK, 2021, ADV NEUR IN, V34
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Chng Z.M., 2022, ARXIV PREPRINT ARXIV, p2202.13137, DOI [10.48550/arXiv, DOI 10.48550/ARXIV]
   Chng ZM, 2021, INT C PATT RECOG, P6842, DOI 10.1109/ICPR48806.2021.9412572
   Deusch H, 2012, IEEE INT C INTELL TR, P270, DOI 10.1109/ITSC.2012.6338772
   Fan M., 2021, PROC CVPR IEEE, DOI DOI 10.1109/CVPR46437.2021.00959
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Hur J, 2013, IEEE INT VEH SYM, P1297, DOI 10.1109/IVS.2013.6629645
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Kim S, 2007, PROC INT C TOOLS ART, P535, DOI 10.1109/ICTAI.2007.20
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Li JY, 2021, NEUROCOMPUTING, V465, P15, DOI 10.1016/j.neucom.2021.08.105
   Liang D, 2020, J COMPUT SCI TECH-CH, V35, P493, DOI 10.1007/s11390-020-0476-4
   Liang Y., 2020, Adv. Neural Inf. Proces. Syst., V33, P3430
   Lin FQ, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103864
   Liu Lizhe, 2021, P IEEE CVF INT C COM, P3773
   Liu RJ, 2021, IEEE WINT CONF APPL, P3693, DOI 10.1109/WACV48630.2021.00374
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Neven D, 2018, IEEE INT VEH SYM, P286
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Park H, 2021, Arxiv, DOI arXiv:2011.04445
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Qu Z, 2021, PROC CVPR IEEE, P14117, DOI 10.1109/CVPR46437.2021.01390
   Rui Fan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P340, DOI 10.1007/978-3-030-58577-8_21
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Seoung Wug Oh, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P9225, DOI 10.1109/ICCV.2019.00932
   Tabelini L, 2021, INT C PATT RECOG, P6150, DOI 10.1109/ICPR48806.2021.9412265
   TuSimple, 2017, US
   Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542
   Voigtlaender P, 2017, Arxiv, DOI arXiv:1706.09364
   Wang YF, 2012, SIGNAL PROCESS, V92, P319, DOI 10.1016/j.sigpro.2011.07.019
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Yu Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P735, DOI 10.1007/978-3-030-58607-2_43
   Zamir Amir R., 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11194, DOI 10.1109/CVPR42600.2020.01121
   Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391
   Zequn Qin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P276, DOI 10.1007/978-3-030-58586-0_17
   Zhang Y., 2021, P IEEECVF INT C COMP, P15681, DOI DOI 10.48550/ARXIV.2108.08482
   Zhang YZ, 2020, PROC CVPR IEEE, P6947, DOI 10.1109/CVPR42600.2020.00698
NR 41
TC 1
Z9 1
U1 6
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103771
DI 10.1016/j.jvcir.2023.103771
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8X4HI
UT WOS:000931975000001
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Garai, A
AF Ghosh, Sanjay
   Garai, Arpan
TI Image downscaling via co-occurrence learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image downscaling; Kernel filtering; Co-occurrence similarity
ID FILTER
AB Image downscaling is one of the widely used operations in image processing and computer graphics. It was recently demonstrated in the literature that kernel-based convolutional filters could be modified to develop efficient image downscaling algorithms. In this work, we present a new downscaling technique which is based on kernel-based image filtering concept. We propose to use pairwise co-occurrence similarity of the pixelpairs as the range kernel similarity in the filtering operation. The co-occurrence of the pixel-pair is learned directly from the input image. This co-occurrence learning is performed in a neighborhood based fashion all over the image. The proposed method can preserve the high-frequency structures, which were present in the input image, into the downscaled image. The idea is further extended to the case of fractions factor of downscaling. The resulting images retain visually-important details and do not suffer from edge-blurring artifact. We demonstrate the effectiveness of our proposed approach with extensive experiments on a large number of images downscaled with various downscaling factors.
C1 [Ghosh, Sanjay] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.
   [Garai, Arpan] Indian Inst Technol Delhi, Dept Comp Sci & Engn, New Delhi, India.
C3 University of California System; University of California San Francisco;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Ghosh, S (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.
EM sanjay.ghosh@ucsf.edu
OI Garai, Arpan/0000-0002-8233-3591
CR [Anonymous], 2018, P EUROPEAN C COMPUTE
   Beghdadi A, 2013, SIGNAL PROCESS-IMAGE, V28, P811, DOI 10.1016/j.image.2013.06.003
   Chen H, 2021, IEEE T MULTIMEDIA, V23, P584, DOI 10.1109/TMM.2020.2985538
   Chen LH, 2021, Arxiv, DOI arXiv:2105.09999
   Cho SI, 2021, IEEE T IMAGE PROCESS, V30, P4526, DOI 10.1109/TIP.2021.3073316
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Dabhade SD, 2018, IEEE T IND ELECTRON, V65, P1459, DOI 10.1109/TIE.2017.2726960
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Gabiger-Rose A, 2014, IEEE T IND ELECTRON, V61, P4093, DOI 10.1109/TIE.2013.2284133
   Garcia F, 2015, IMAGE VISION COMPUT, V41, P26, DOI 10.1016/j.imavis.2015.06.008
   Gastal ESL, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073670
   Ghosh S., 2019, NAT C COMM
   Hou XX, 2017, Arxiv, DOI arXiv:1707.09482
   Huang CT, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2517668
   Kopf J, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508370
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P1092, DOI 10.1109/TIP.2018.2872876
   Liu JJ, 2018, IEEE T IMAGE PROCESS, V27, P1076, DOI 10.1109/TIP.2017.2772838
   Lugosi G, 1996, ANN STAT, V24, P687
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Mitchell D. P., 1988, Computer Graphics, V22, P221, DOI 10.1145/378456.378514
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nehab Diego, 2011, Tech. Rep. MSR-TR-2011-16
   Occorsio D, 2023, J MATH IMAGING VIS, V65, P513, DOI 10.1007/s10851-022-01135-6
   Occorsio D, 2022, MATH COMPUT SIMULAT, V197, P105, DOI 10.1016/j.matcom.2022.01.017
   Öztireli AC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766891
   Park D, 2020, IEEE IMAGE PROC, P998, DOI 10.1109/ICIP40778.2020.9190972
   Ren Y, 2008, IMAGE VISION COMPUT, V26, P1530, DOI 10.1016/j.imavis.2008.04.023
   Saeedan F, 2018, PROC CVPR IEEE, P9108, DOI 10.1109/CVPR.2018.00949
   Samadani R, 2008, PROC SPIE, V6806, DOI 10.1117/12.765264
   SHANNON CE, 1984, P IEEE, V72, P1192, DOI 10.1109/PROC.1984.12998
   Sun WJ, 2020, IEEE T IMAGE PROCESS, V29, P4027, DOI 10.1109/TIP.2020.2970248
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Trentacoste M, 2011, COMPUT GRAPH FORUM, V30, P573, DOI 10.1111/j.1467-8659.2011.01894.x
   Triggs B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P550, DOI 10.1109/ICCV.2001.937674
   Weber N, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980239
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Xing JB, 2022, Arxiv, DOI arXiv:2201.12576
   Zhang YB, 2011, IEEE T IMAGE PROCESS, V20, P3291, DOI 10.1109/TIP.2011.2158226
   Zhou ZQ, 2018, IEEE T MULTIMEDIA, V20, P1392, DOI 10.1109/TMM.2017.2772438
NR 40
TC 1
Z9 1
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103766
DI 10.1016/j.jvcir.2023.103766
EA JAN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8P8SG
UT WOS:000926787500001
DA 2024-07-18
ER

PT J
AU He, HJ
   Yuan, Y
   Ye, YY
   Tai, HM
   Chen, F
AF He, Hongjie
   Yuan, Yuan
   Ye, Yuyun
   Tai, Heng-Ming
   Chen, Fan
TI Chosen plaintext attack on JPEG image encryption with adaptive key and
   run consistency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE JPEG bitstream encryption; Chosen plaintext attack; Adaptive encryption
   key; ACCs encryption
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS; SECURITY; SCHEME
AB A JPEG image encryption with the adaptive key and run consistency of MCUs is proposed. The chosen-plaintext attack (CPA) is given here on this encryption scheme. First, the adaptive key can be reproduced from the encrypted image, so that the plaintext images with the same adaptive key can be constructed. Second, the existence of run consistency of MCUs (RCM) between the original image and the encrypted image facilitates rapid estimation. In addition, the single swap for the runs of MCUs with RCM is designed for more accurate estimation. Detailed cryptanalytic results suggest that this encryption scheme can only be used to realize perceptual encryption but not to provide content protection for digital images. Furthermore, applications of the CPA to break other encryption schemes with RCM are presented.
C1 [He, Hongjie; Yuan, Yuan] Southwest Jiaotong Univ, Key Lab Signal & Informat Proc, Chengdu 611756, Sichuan, Peoples R China.
   [Ye, Yuyun; Tai, Heng-Ming] Univ Tulsa, Dept Elect & Comp Engn, Tulsa, OK 74104 USA.
   [Chen, Fan] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
C3 Southwest Jiaotong University; University of Tulsa; Southwest Jiaotong
   University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
EM fchen@swjtu.edu.cn
RI Tai, Heng-Ming/A-9267-2009
FU National Natural Science Foundation of China (NSFC) [U1936113, 61872303]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant U1936113 and 61872303.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Cheng H, 2016, J VIS COMMUN IMAGE R, V40, P111, DOI 10.1016/j.jvcir.2016.06.016
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   He JH, 2020, IEEE T INF FOREN SEC, V15, P2121, DOI 10.1109/TIFS.2019.2958758
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   He JH, 2018, IEEE T MULTIMEDIA, V20, P2645, DOI 10.1109/TMM.2018.2817065
   Independent jpeg group, 2019, About us
   Itier V, 2020, IEEE T CIRC SYST VID, V30, P646, DOI 10.1109/TCSVT.2019.2894520
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Khelifi F, 2018, SIGNAL PROCESS, V143, P336, DOI 10.1016/j.sigpro.2017.09.020
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li PY, 2020, IET SIGNAL PROCESS, V14, P475, DOI 10.1049/iet-spr.2019.0276
   Li PY, 2018, IEEE T MULTIMEDIA, V20, P1960, DOI 10.1109/TMM.2017.2786860
   Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2010, IEEE IMAGE PROC, P2085, DOI 10.1109/ICIP.2010.5653467
   Li WH, 2007, INT J COMPUT MATH, V84, P1367, DOI 10.1080/00207160701294376
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Minemura K, 2012, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2012.6466845
   Mitchell J., 1992, ITU-Rec. T. 81
   Niu XA, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P308, DOI 10.1109/IIH-MSP.2008.207
   Ong S, 2013, IEEE IMAGE PROC, P4574, DOI 10.1109/ICIP.2013.6738942
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Peiya Li, 2021, Advances in Intelligent Information Hiding and Multimedia Signal Processing. Proceedings of the 16th International Conference on IIHMSP in Conjunction with the 13th International Conference on FITAT. Smart Innovation, Systems and Technologies (SIST 211), P140, DOI 10.1007/978-981-33-6420-2_18
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2023, IEEE T MULTIMEDIA, V25, P2528, DOI 10.1109/TMM.2022.3148591
   Shreyamsha Kumar BK, 2010, SIGNAL IMAGE VIDEO P, V4, P419, DOI 10.1007/s11760-009-0131-6
   Wright M. A., 2001, Network Security, P11, DOI 10.1016/S1353-4858(01)01018-2
   Yuan Y, 2022, LECT NOTES COMPUT SC, V13180, P58, DOI 10.1007/978-3-030-95398-0_5
   [郑梦阳 Zheng Mengyang], 2018, [信息安全学报, Journal of Cyber Security], V3, P55
NR 34
TC 1
Z9 1
U1 4
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103733
DI 10.1016/j.jvcir.2022.103733
EA DEC 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7W7XK
UT WOS:000913721800001
DA 2024-07-18
ER

PT J
AU Chang, SE
   Chen, Y
   Yang, YC
   Lin, ET
   Hsiao, PY
   Fu, LC
AF Chang, Shuo-En
   Chen, Yi
   Yang, Yi-Cheng
   Lin, En-Ting
   Hsiao, Pei-Yung
   Fu, Li-Chen
TI SE-PSNet: Silhouette-based Enhancement Feature for Panoptic Segmentation
   Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Panoptic segmentation; Instance segmentation; Silhouette;
   confidence score
AB In this work, we propose a panoptic segmentation model that integrates bottom-up and top-down methods. Our framework is designed to guarantee both the performance and the inference speed. We also focus on improving the quality of semantic and instance masks. The proposed auxiliary task with the silhouette-based enhanced features can help the model improve the prediction quality of mask contours. Additionally, we introduce a new mask quality score intending to solve the occlusion problem. The model has less chance of ignoring small objects, which often have lower confidence scores than larger objects behind them. The results show that the proposed mask quality score can better distinguish the priority of objects when the occlusion occurs. We demonstrate the results of our work on two datasets: the COCO dataset and the CityScapes dataset. Via our approach, we obtained competitive results with fast inference time.
C1 [Chang, Shuo-En; Chen, Yi; Lin, En-Ting; Fu, Li-Chen] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Yang, Yi-Cheng] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei, Taiwan.
   [Hsiao, Pei-Yung] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
C3 National Taiwan University; National Taiwan University; National
   University Kaohsiung
RP Fu, LC (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM lichen@ntu.edu.tw
OI Chen, Yi/0000-0003-1446-7982
FU Ministry of Science and Technology of Taiwan; Center for Artificial
   Intelligence & Advanced Robotics, National Taiwan University [MOST
   108-2221-E-390-019-MY3, MOST 110-2634-F-002-049, MOST
   110-2221-E-002-166-MY3]
FX This research was supported by the Ministry of Science and Technology of
   Taiwan, and Center for Artificial Intelligence & Advanced Robotics,
   National Taiwan University, under the grant numbers MOST
   108-2221-E-390-019-MY3, MOST 110-2634-F-002-049 and MOST
   110-2221-E-002-166-MY3.
CR Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chang C.-Y., 2020, P AS C COMP VIS
   Chen Hao, 2020, 2020 IEEE C COMP VIS, DOI [DOI 10.48550/ARXIV.2001.00309, DOI 10.1109/CVPR42600.2020.00860]
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen XL, 2019, IEEE I CONF COMP VIS, P2061, DOI 10.1109/ICCV.2019.00215
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   de Geus D, 2019, Arxiv, DOI arXiv:1809.02110
   Deng J., 2009, IEEE C COMP VIS PATT
   Deng RX, 2018, LECT NOTES COMPUT SC, V11210, P570, DOI 10.1007/978-3-030-01231-1_35
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Ke L, 2021, PROC CVPR IEEE, P4018, DOI 10.1109/CVPR46437.2021.00401
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Lazarow Justin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10717, DOI 10.1109/CVPR42600.2020.01073
   Lee Y, 2020, P IEEE CVF C COMP VI
   Li J, 2019, Arxiv, DOI arXiv:1812.01192
   Li YW, 2021, PROC CVPR IEEE, P214, DOI 10.1109/CVPR46437.2021.00028
   Li YW, 2019, PROC CVPR IEEE, P7019, DOI 10.1109/CVPR.2019.00719
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117
   Liu HY, 2019, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2019.00633
   Qizhu Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13317, DOI 10.1109/CVPR42600.2020.01333
   Sida Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8530, DOI 10.1109/CVPR42600.2020.00856
   Sofiiuk K, 2019, IEEE I CONF COMP VIS, P7354, DOI 10.1109/ICCV.2019.00745
   Tian Z., 2021, ARXIV
   Tian Z, 2022, IEEE T PATTERN ANAL, V44, P1922, DOI 10.1109/TPAMI.2020.3032166
   Tianheng Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P660, DOI 10.1007/978-3-030-58568-6_39
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang X., 2020, ADV NEURAL INF PROCE
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xinlong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P649, DOI 10.1007/978-3-030-58523-5_38
   Xiong YW, 2019, PROC CVPR IEEE, P8810, DOI 10.1109/CVPR.2019.00902
   Yang TJ, 2019, Arxiv, DOI arXiv:1902.05093
   Yang YB, 2020, AAAI CONF ARTIF INTE, V34, P12637
   Yuqing Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9310, DOI 10.1109/CVPR42600.2020.00933
   Zimmermann RS, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.102795
NR 42
TC 0
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103736
DI 10.1016/j.jvcir.2022.103736
EA DEC 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8A0ZG
UT WOS:000915975900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, R
   Tian, Y
   Xu, ZC
   Liu, DS
AF Zhang, Rui
   Tian, Yan
   Xu, Zhaocheng
   Liu, Dongsheng
TI Design of anchor boxes and data augmentation for transformer-based
   vehicle localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object localization; Intelligent transportation systems; Data
   augmentation; Machine learning; Computer vision
AB Vehicle localization is an important task in the signal processing field. In recent years, context exploration has been widely studied, especially the nonlocal dependencies in an image, using, for example, attention and transformer mechanisms. However, these approaches encounter difficulties in achieving accurate localization owing to ineffective design and use of queries. Motivated by the fact that spatial information is determined by decoder embeddings and details of reference boxes, we propose a method of explicitly and dynamically modeling anchor boxes in the query generation module. Moreover, we design a geometry-aware data augmentation approach to increase the diversity of the data by employing multiple augmentation methods on an image. Experiments conducted on public datasets show that our approach can improve the average precision by approximately 1.1%.
C1 [Zhang, Rui] Zhejiang Gongshang Univ, Sch Management & Ebusiness, Hangzhou 310018, Peoples R China.
   [Tian, Yan; Xu, Zhaocheng; Liu, Dongsheng] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou 310018, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University
RP Liu, DS (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou 310018, Peoples R China.
EM DongshengLiuZJGSU@163.com
RI liu, dongsheng/IWM-1597-2023
OI Liu, Dongsheng/0000-0002-6033-4833
FU National Natural Science Foundation of China [61972351, 62111530300];
   Public Welfare Technology Research Project of Zhejiang Province, China
   [LGF19G010002, LGF20G010002]; Science and Technology Program of Zhejiang
   Province (Key Research and Development Plan) , China [2022C01005];
   Special Project for Basic Business Expenses of Zhejiang Provincial
   Colleges and Universities, China [JRK22003]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972351 and 62111530300, in part by the
   Public Welfare Technology Research Project of Zhejiang Province, China
   under Grant LGF19G010002 and LGF20G010002, and in part by the Science
   and Technology Program of Zhejiang Province (Key Research and
   Development Plan) , China under Grant 2022C01005. Special Project for
   Basic Business Expenses of Zhejiang Provincial Colleges and
   Universities, China under Grant JRK22003. The authors would like to
   thank AJE ( www.aje.com ) for its linguistic assistance during the
   preparation of this manuscript.
CR Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen X., 2022, arXiv
   Chen X., 2021, ICCV, P3651
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dai XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2968, DOI 10.1109/ICCV48922.2021.00298
   Gao P., 2021, P IEEE CVF C COMP VI, P3621
   Ghiasi G, 2021, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR46437.2021.00294
   Han JL, 2022, Arxiv, DOI arXiv:2201.12078
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Lee G, 2021, IEEE SIGNAL PROC LET, V28, P1026, DOI 10.1109/LSP.2021.3081041
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Li F., 2022, P IEEECVF C COMPUTER, P13619
   Liu S, 2022, P INT C LEARN REPR, P213
   Mukkamala MC, 2017, PR MACH LEARN RES, V70
   Paszke A, 2019, ADV NEUR IN, V32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Y, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3504033
   Tian Y, 2022, IEEE T INTELL TRANSP, V23, P165, DOI 10.1109/TITS.2020.3009000
   Tian Y, 2019, IET COMPUT VIS, V13, P542, DOI 10.1049/iet-cvi.2018.5492
   Tian Y, 2018, NEUROCOMPUTING, V280, P46, DOI 10.1016/j.neucom.2017.09.098
   Tian Y, 2017, NEUROCOMPUTING, V253, P34, DOI 10.1016/j.neucom.2017.01.098
   Vaswani A., 2017, P INT C NEURAL INFOR
   Wang P, 2022, IET COMPUT VIS, V16, P727, DOI 10.1049/cvi2.12120
   Wang Y., 2022, P AAAI C ART INT, P302
   Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang H., 2018, P INT C LEARNING REP, P682
   Zhang H, 2022, Arxiv, DOI arXiv:2203.03605
   Zhu X., 2021, P INT C LEARNING REP, P882
NR 30
TC 4
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103711
DI 10.1016/j.jvcir.2022.103711
EA DEC 2022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7K8RS
UT WOS:000905544100001
DA 2024-07-18
ER

PT J
AU Tang, CR
   Xue, DY
   Chen, DY
AF Tang, Chunren
   Xue, Dingyu
   Chen, Dongyue
TI Multi-level mutual supervision for cross-domain Person Re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised domain adaptation; Mutual supervision; Person
   Re-identification; Cross domain
AB The challenges of cross-domain person re-identification mainly derive from two aspects: (1) The missing of target data labels. (2) The bias between source domain and target domain. Most of existing works focus on only one problem in the above two or deal with them separately. In this paper, we propose a new approach referred as to multi-level mutual supervision to achieve full utilization of labeled source data and unlabeled target data. Along this approach, we construct a dual-branch framework of which the upper branch is trained with original source data and target data while the lower branch is trained with augmented source data and target data. By applying common-pseudo-label and Maximum Mean Discrepancy (MMD) loss in our framework, the mutual supervision in multi levels is achieved. The results show that our model achieves SOTA performance on multiple popular benchmark datasets.
C1 [Tang, Chunren; Xue, Dingyu; Chen, Dongyue] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Tang, CR (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
EM 1910316@stu.neu.edu.cn
FU Guangdong Basic and Applied Basic Research Foundation, China; 
   [2021B1515120064]
FX Acknowledgments This work is supported by the Guangdong Basic and
   Applied Basic Research Foundation, China under Grant 2021B1515120064.
CR Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Backlund H., 2011, DATA MINING TNM033, V033, P11
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chong YW, 2021, APPL INTELL, V51, P5219, DOI 10.1007/s10489-020-02107-2
   Chuanchen Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P224, DOI 10.1007/978-3-030-58555-6_14
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ge YX, 2020, Arxiv, DOI [arXiv:2001.01526, 10.48550/arXiv.2001.01526]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HJ, 2018, Arxiv, DOI [arXiv:1812.11369, DOI 10.48550/ARXIV.1812.11369]
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Li YJ, 2018, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2018.00054
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Qi L, 2019, IEEE I CONF COMP VIS, P8079, DOI 10.1109/ICCV.2019.00817
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang GQ, 2020, PROC CVPR IEEE, P6677, DOI 10.1109/CVPR42600.2020.00671
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Yang Zou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P87, DOI 10.1007/978-3-030-58536-5_6
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
   Zhou SR, 2021, NEURAL COMPUT APPL, V33, P4001, DOI 10.1007/s00521-020-05566-3
   Zijie Zhuang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P140, DOI 10.1007/978-3-030-58610-2_9
   Zilong Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P20, DOI 10.1007/978-3-030-58604-1_2
NR 37
TC 3
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103674
DI 10.1016/j.jvcir.2022.103674
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600007
DA 2024-07-18
ER

PT J
AU Mao, ZJ
   Chen, X
   Yan, J
   Qu, T
AF Mao, Zhongjie
   Chen, Xi
   Yan, Jia
   Qu, Tao
TI Multimodal object tracking by exploiting appearance and class
   information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Multimodal; Object class
ID PLUS PLUS
AB In this work, we study the method exploiting natural language network to improve tracking performance. We propose a novel architecture which can combine class and visual information presented in tracking. To this end, we introduce a multimodal feature association network, allowing us to correlate the target class with its appearance during training and aid the localization of the target during inference. Specifically, we first utilize an appearance model to extract the target visual features, from which we obtain appearance cues, for instance shape and color. In order to employ target class information, we design a learned lightweight embedding network to embed the target class into a feature representation. The association network of our architecture contains a multimodal fusion module and a predictor module. The fusion module is used to combine features from class and appearance, yielding multimodal features with more expressive representations for the subsequent module. The predictor module is used to determine the target location in the current frame, from which we associate the class to the appearance. The class embedding module thus can learn appearance cues by exploiting the backpropagation functionality. To verify the abilities of our method, we select the official training and test splits of the LaSOT with annotated images and classes to perform experiments. In particular, we analyze the imbalance in the samples and employ a class validator discriminator to alleviate this problem. Extensive experimental results on LaSOT, UAV20L and UAV123@10fps demonstrate our method achieves competitive results while maintaining a considerable real-time speed.
C1 [Mao, Zhongjie; Chen, Xi; Qu, Tao] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Yan, Jia] Wuhan Univ, Sch Elect Informat, Dept Elect Engn, Wuhan, Peoples R China.
C3 Wuhan University; Wuhan University
RP Chen, X (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM robertcx@whu.edu.cn
OI Mao, Zhongjie/0000-0002-5738-2340
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cao ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15437, DOI 10.1109/ICCV48922.2021.01517
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Deng J., 2009, IEEE C COMP VIS PATT
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Feng Q, 2021, PROC CVPR IEEE, P5847, DOI 10.1109/CVPR46437.2021.00579
   Feng Q, 2020, IEEE WINT CONF APPL, P689, DOI [10.1109/WACV45572.2020.9093425, 10.1109/wacv45572.2020.9093425]
   Fu CH, 2021, IEEE INT CONF ROBOT, P510, DOI 10.1109/ICRA48506.2021.9560756
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Javed S., 2021, ARXIV
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li ZY, 2017, PROC CVPR IEEE, P7350, DOI 10.1109/CVPR.2017.777
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Marvasti-Zadeh S. M., 2019, ARXIV
   Mikolov T, 2013, P WORKSHOP ICLR 2013
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P284, DOI 10.1145/2993148.2993176
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Pérez-Rúa JM, 2019, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2019.00713
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Tripp AiliMari., 2019, Oxford Research Encyclopedia of Politics, DOI DOI 10.1093/ACREFORE/9780190228637.013.713
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Wang X., 2021, CVPR, P13763
   Wang X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P899
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang ZY, 2021, IEEE T CIRC SYST VID, V31, P3433, DOI 10.1109/TCSVT.2020.3038720
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
   Ziang Cao, 2021, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P3086, DOI 10.1109/IROS51168.2021.9636309
NR 40
TC 0
Z9 0
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103669
DI 10.1016/j.jvcir.2022.103669
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V1KD
UT WOS:000876994600003
DA 2024-07-18
ER

PT J
AU Dubey, S
   Olimov, F
   Rafique, MA
   Jeon, M
AF Dubey, Shikha
   Olimov, Farrukh
   Rafique, Muhammad Aasim
   Jeon, Moongu
TI Improving small objects detection using transformer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Normalized inductive bias; Features fusion; Small-objects detection;
   Transformer; Self-attention
AB General artificial intelligence counteracts the inductive bias of an algorithm and tunes the algorithm for out-of-distribution generalization. A conspicuous impact of the inductive bias is an unceasing trend in improving deep learning performance. Although a quintessential attention-based object detection technique, DETR, shows better accuracy than its predecessors, its accuracy deteriorates for detecting small-sized (in-perspective) objects. This study examines the inductive bias of DETR and proposes a normalized inductive bias for object detection using data fusion, SOF-DETR. A technique of lazy-fusion of features is introduced in SOF-DETR, which sustains deep contextual information of objects present in an image. The features from multiple subsequent deep layers are fused for object queries that learn long and short-distance spatial association in an image using the attention mechanism. Experimental results on the MS COCO and Udacity Self Driving Car datasets assert the effectiveness of the added normalized inductive bias and feature fusion techniques, showing increased COCO mAP scores on small-sized objects.
C1 [Dubey, Shikha; Rafique, Muhammad Aasim; Jeon, Moongu] Gwangju Inst Sci & Technol GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
   [Olimov, Farrukh; Rafique, Muhammad Aasim] Monitorapp, Threat Intelligence Team, Seoul, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Dubey, S (corresponding author), Gwangju Inst Sci & Technol GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
EM shikha.d@gm.gist.ac.kr; olimov.farrukh@gm.gist.ac.kr;
   aasimrafique@gist.ac.kr; mgjeon@gist.ac.kr
RI Dubey, Shikha/JDN-2162-2023
OI Dubey, Shikha/0000-0003-4672-4306
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) of Ministry of Science and ICT (MSIT) [2014-3-00077];
   Korea Creative Content Agency (KOCCA) of Ministry of Culture, Sports,
   and Tourism (MCST) [R2020060002, R2022060001]
FX This work was financially supported by the Institute of Information &
   communications Technology Planning & Evaluation (IITP) of Ministry of
   Science and ICT (MSIT) (No. 2014-3-00077, AI National Strategy Project)
   , and by the Korea Creative Content Agency (KOCCA) of Ministry of
   Culture, Sports, and Tourism (MCST) (No. R2020060002 and R2022060001,
   the Culture Technology Research Development Program).
CR [Anonymous], 2010, PROC 13 INT C ARTIF
   [Anonymous], 2020, ROBOFLOW UDACITY SEL
   [Anonymous], 2017, Udacity Self Driving Car Simulator
   [Anonymous], 2017, arXiv
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen NX, 2021, IEEE SIGNAL PROC LET, V28, P121, DOI 10.1109/LSP.2020.3044547
   d'Ascoli S, 2021, PR MACH LEARN RES, V139, DOI 10.1088/1742-5468/ac9830
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Dubey S., 2021, ARXIV
   Fang S, 2021, IEEE SIGNAL PROC LET, V28, P6, DOI 10.1109/LSP.2020.3037527
   Fu C.-Y., 2017, arXiv
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., 2016, INDIAN J CHEM B
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang SQ, 2022, NEUROCOMPUTING, V473, P68, DOI 10.1016/j.neucom.2021.11.107
   Khan A, 2021, Arxiv, DOI arXiv:2108.11833
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Lin T.Y., arXiv
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Neyshabur B., 2020, Advances in Neural Information Processing Systems
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Parmar N, 2018, PR MACH LEARN RES, V80
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Stewart R, 2016, PROC CVPR IEEE, P2325, DOI 10.1109/CVPR.2016.255
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Zhang GF, 2021, IEEE SIGNAL PROC LET, V28, P71, DOI 10.1109/LSP.2020.3045641
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 41
TC 6
Z9 6
U1 6
U2 52
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103620
DI 10.1016/j.jvcir.2022.103620
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5M4GW
UT WOS:000871056800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, K
   Wu, W
   Shao, YL
   Fang, JL
   Wang, XQ
   Wei, D
AF Zhou, Kai
   Wu, Wen
   Shao, Yan-Li
   Fang, Jing-Long
   Wang, Xing-Qi
   Wei, Dan
TI Shadow detection via multi-scale feature fusion and unsupervised domain
   adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Shadow detection; Unsupervised domain adaptation;
   Multi-scale feature fusion
ID SOFT SHADOWS; REMOVAL; MODELS; IMAGE
AB Shadow detection is significant for scene understanding. As a common scenario, soft shadows have more ambiguous boundaries than hard shadows. However, they are rarely present in the available benchmarks since annotating for them is time-consuming and needs expert help. This paper discusses how to transfer the shadow detection capability from available shadow data to soft shadow data and proposes a novel shadow detection framework (MUSD) based on multi-scale feature fusion and unsupervised domain adaptation. Firstly, we set the existing labeled shadow dataset (i.e., SBU) as the source domain and collect an unlabeled soft shadow dataset (SSD) as the target domain to formulate an unsupervised domain adaptation problem. Next, we design an efficient shadow detection network based on the double attention module and multi-scale feature fusion. Then, we use the global-local feature alignment strategy to align the task-related feature distributions between the source and target domains. This allows us to obtain a robust model and achieve domain adaptation effectively. Extensive experimental results show that our method can detect soft shadows more accurately than existing state-of-the-art methods.
C1 [Zhou, Kai; Wu, Wen; Shao, Yan-Li; Fang, Jing-Long; Wang, Xing-Qi; Wei, Dan] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Shao, YL (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Peoples R China.
EM zhoukai.hdu.cs@gmail.com; shaoyanli@hdu.edu.cn
RI Zhou, Kai/KVB-1378-2024; Wu, Wen/HKW-7234-2023
OI Zhou, Kai/0000-0003-2968-7267; Wu, Wen/0000-0003-0919-3948
FU Zhejiang Provincial Natural Science Foundation of China [LY20F020015,
   LY21F020015]; National Science Foundation of China [61902345, 61972121,
   61902099]; Open Project Program of the State Key Lab of CAD & CG ,
   Zhejiang University [2109]
FX This work was supported by the Zhejiang Provincial Natural Science
   Foundation of China (LY20F020015, LY21F020015) ; the National Sci-ence
   Foundation of China (61902345, 61972121, 61902099) ; and the Open
   Project Program of the State Key Lab of CAD & CG (Grant No. 2109) ,
   Zhejiang University.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chen J, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3140108
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen ZH, 2020, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR42600.2020.00565
   Dong Q, 2014, COMPUT GRAPH-UK, V38, P310, DOI 10.1016/j.cag.2013.11.005
   Ecins A., 2014, IEEE INT CONF COMPUT, P1
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gong YX, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103541
   Gryka M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2732407
   Guo RQ, 2011, PROC CVPR IEEE
   Guo-Sen Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P562, DOI 10.1007/978-3-030-58548-8_33
   Hu XW, 2021, IEEE T IMAGE PROCESS, V30, P1925, DOI 10.1109/TIP.2021.3049331
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Jin Y., 2021, P IEEECVF INT C COMP, P5027
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Khan SH, 2014, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2014.249
   Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163
   Le HE, 2018, LECT NOTES COMPUT SC, V11206, P680, DOI 10.1007/978-3-030-01216-8_41
   Li Y., 2022, IEEE Trans Multimed, P1
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Nielsen M, 2007, LECT NOTES COMPUT SC, V4522, P918
   Okabe Takahiro, 2009, 2009 IEEE 12th International Conference on Computer Vision (ICCV), P1693, DOI 10.1109/ICCV.2009.5459381
   Panagopoulos A, 2009, PROC CVPR IEEE, P651, DOI 10.1109/CVPRW.2009.5206665
   Ren CX, 2022, IEEE T IMAGE PROCESS, V31, P2122, DOI 10.1109/TIP.2022.3152052
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tian JD, 2016, PATTERN RECOGN, V51, P85, DOI 10.1016/j.patcog.2015.09.006
   Tzeng E, 2014, Arxiv, DOI [arXiv:1412.3474, 10.48550/arXiv.1412.3474, DOI 10.48550/ARXIV.1412.3474]
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang SJ, 2019, LECT NOTES COMPUT SC, V11764, P102, DOI 10.1007/978-3-030-32239-7_12
   Wang TY, 2020, PROC CVPR IEEE, P1877, DOI 10.1109/CVPR42600.2020.00195
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu L, 2010, COMPUT VIS IMAGE UND, V114, P915, DOI 10.1016/j.cviu.2010.04.003
   Wu W, 2022, VISUAL COMPUT, V38, P1665, DOI 10.1007/s00371-021-02095-5
   Yan L, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3065982
   Yue X., 2021, P IEEE CVF C COMP VI, P13834
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zhang Q, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103350
   Zhang Z., 2022, IEEE T KNOWL DATA EN, V14, P1
   Zheng QL, 2019, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2019.00531
   Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209
   Zhu L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4682, DOI 10.1109/ICCV48922.2021.00466
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
   Zou DB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3291
NR 53
TC 8
Z9 8
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103596
DI 10.1016/j.jvcir.2022.103596
EA AUG 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4H2GN
UT WOS:000849699300002
DA 2024-07-18
ER

PT J
AU Peng, J
   Wang, YX
   Zhou, ZP
AF Peng, Jin
   Wang, Yongxiong
   Zhou, Zeping
TI Progressive Erasing Network with consistency loss for fine-grained
   visual classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FGVC; PEN; Multi-grid erasure mechanism; Cross-layer incentive block;
   Consistency loss
AB Fine-grained Visual Categorization (FGVC) in computer vision aims to recognize images belonging to multiple subordinate categories of a super-category. The difficulty of FGVC lies in the close resemblance among interclasses and large variations among intra-classes. Most existing networks only focus on a few discriminative regions, while ignoring many subtle complementary features. So we propose a Progressive Erasing Network (PEN). In PEN, a Multi-Grid Erasure mechanism augments data samples and assists in capturing the local discriminative features, where the overall structure of the image is destroyed indirectly through pixel-wise erasure. Cross-layer feature aggregation by extracting salient class features is of great significance in FGVC. However, the capability of cross-layer feature representation based on a simple aggregation strategy is still inefficient. To this end, the proposed Consistency loss explores the cross-layer semantic affinity, which guides the Cross-Layer Incentive (CLI) block to mine more efficient feature representations of different granularity. We also integrate Cross Entropy and Complementary Entropy to take the distribution of negative classes into account for better classification performance. Our method uses end-to-end training with only classification labels. Experimental results show that our model outperforms the state-of-the-art on three fine-grained benchmarks.
C1 [Peng, Jin; Wang, Yongxiong; Zhou, Zeping] Univ Shanghai Sci & Technol, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Wang, YX (corresponding author), Univ Shanghai Sci & Technol, Shanghai 200093, Peoples R China.
EM wyxiong@usst.edu.cn
RI peng, jin/JRW-4493-2023; Yuan, Yu/KBQ-0606-2024
OI Wang, Yongxiong/0000-0002-3242-0857
FU Natural Science Foundation of Shanghai [22ZR1443700]
FX This work was sponsored by Natural Science Foundation of Shanghai under
   Grant No. 22ZR1443700.
CR Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chen HY, 2019, IEEE I CONF COMP VIS, P4880, DOI 10.1109/ICCV.2019.00498
   Chen P., 2020, ARXIV
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   DeVries T, 2017, PREPRINT
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Engin M, 2018, LECT NOTES COMPUT SC, V11206, P629, DOI 10.1007/978-3-030-01216-8_38
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gao Y, 2020, AAAI CONF ARTIF INTE, V34, P10818
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   He J., 2021, arXiv
   He K., 2021, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jun H., 2019, ARXIV
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li H, 2020, IEEE I C VI COM I PR, P243, DOI [10.1109/vcip49819.2020.9301763, 10.1109/VCIP49819.2020.9301763]
   Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555
   Liu Z., 2022, ARXIV
   Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833
   Maji Subhransu, 2013, ARXIV
   Min SB, 2020, IEEE T IMAGE PROCESS, V29, P4996, DOI 10.1109/TIP.2020.2977457
   Rao Yongming, 2021, P IEEE CVF INT C COM, P1025
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Singh K.K., 2018, ARXIV
   Song JW, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534004
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Tan M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3209666
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wei X, 2018, LECT NOTES COMPUT SC, V11207, P365, DOI 10.1007/978-3-030-01219-9_22
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wu JF, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION (ICCMS 2019) AND 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND APPLICATIONS (ICICA 2019), P133, DOI 10.1145/3307363.3307382
   Xiong W, 2020, PROC CVPR IEEE, P5839, DOI 10.1109/CVPR42600.2020.00588
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang H., 2017, ARXIV
   Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842
   Zhang TL, 2021, PROCEDIA COMPUT SCI, V187, P1, DOI 10.1016/j.procs.2021.04.025
   Zheng HL, 2019, ADV NEUR IN, V32
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 45
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103570
DI 10.1016/j.jvcir.2022.103570
EA AUG 2022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4U2UR
UT WOS:000858655700001
DA 2024-07-18
ER

PT J
AU Zhang, GQ
   Chen, C
   Chen, YH
   Zhang, HW
   Zheng, YH
AF Zhang, Guoqing
   Chen, Chao
   Chen, Yuhao
   Zhang, Hongwei
   Zheng, Yuhui
TI Fine-grained-based multi-feature fusion for occluded person
   re-identification*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Occludedpersonre-identification; Multi-granularityfeature; Featurefusion
ID ALIGNMENT
AB Many previous occluded person re-identification(re-ID) methods try to use additional clues (pose estimation or semantic parsing models) to focus on non-occluded regions. However, these methods extremely rely on the performance of additional clues and often capture pedestrian features by designing complex modules. In this work, we propose a simple Fine-Grained Multi-Feature Fusion Network (FGMFN) to extract discriminative features, which is a dual-branch structure consisting of global feature branch and partial feature branch. Firstly, we utilize a chunking strategy to extract multi-granularity features to make the pedestrian information contained in it more comprehensive. Secondly, a spatial transformer network is introduced to localize the pedestrian's upper body, and then introduce a relation-aware attention module to explore the fine-grained information. Finally, we fuse the features obtained from the two branches to obtain a more robust pedestrian representation. Extensive experiments verify the effectiveness of our method under the occlusion scenario.
C1 [Zhang, Guoqing; Chen, Chao; Chen, Yuhao; Zhang, Hongwei; Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.
   [Zhang, Guoqing] Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Minist Educ, Nanjing, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Zhang, GQ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.
EM xiayang14551@163.com; chenchao19962020@163.com
RI Wang, lili/IXD-9828-2023; Zhang, Hw/HPD-4999-2023; zhang,
   guoqing/GXG-4800-2022
OI guoqing, zhang/0000-0002-8741-8607
FU National Natural Sci-ence Foundation of China [62172231, 62011540407,
   61806099]; Natural Science Foundation of Jiangsu Province of China
   [BK20180790, BK20211539]
FX Acknowledgments This research is supported in part by the National
   Natural Sci-ence Foundation of China under Grant 62172231, 62011540407
   and 61806099; and by the Natural Science Foundation of Jiangsu Province
   of China under Grant BK20180790 and BK20211539.
CR [Anonymous], 2019, ABS190703253 CORR
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen P., 2021, P IEEECVF INT C COMP, P11833
   Chen YH, 2022, NEUROCOMPUTING, V494, P171, DOI 10.1016/j.neucom.2022.04.081
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He L., ARXIV PREPRINT ARXIV
   Hou RB, 2022, IEEE T PATTERN ANAL, V44, P4894, DOI 10.1109/TPAMI.2021.3079910
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Huang HJ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102789
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jia MX, 2021, AAAI CONF ARTIF INTE, V35, P1673
   Jin H., 2021, IEEE T CIRC SYST VID
   Jin HY, 2022, IEEE T CIRC SYST VID, V32, P2170, DOI 10.1109/TCSVT.2021.3088446
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kingma D. P., 2015, P INT C LEARN REPR I, P1
   Kiran M., 2021, ARXIV210406524
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lin X., 2020, MATH PROBLEMS ENG, P1
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Ma ZX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1487, DOI 10.1145/3474085.3475283
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Rao YM, 2019, INT J COMPUT VISION, V127, P701, DOI 10.1007/s11263-018-1135-x
   Ren LL, 2019, IEEE T IMAGE PROCESS, V28, P4970, DOI 10.1109/TIP.2019.2915655
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan H., 2022, IEEE Trans. Neural Netw. Learn. Syst., P1
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2021, IEEE SIGNAL PROC LET, V28, P1155, DOI 10.1109/LSP.2021.3087079
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Xu YJ, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106554
   Yang J., 2021, P IEEE INT C COMP VI, P11885
   Yang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164431
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang G., 2021, IJCAI, P1295
   Zhang G., 2021, P IEEE INT C MULT EX, P1
   Zhang G., 2022, P IEEE INT C MULTIME
   Zhang G., 2022, IEEE T CIRCUITS SYST
   Zhang GQ, 2022, NEUROCOMPUTING, V486, P93, DOI 10.1016/j.neucom.2022.02.051
   Zhang GQ, 2021, IEEE T IMAGE PROCESS, V30, P8913, DOI 10.1109/TIP.2021.3120054
   Zhang GQ, 2021, INFORM SCIENCES, V578, P525, DOI 10.1016/j.ins.2021.07.058
   Zhang GQ, 2021, MULTIMED TOOLS APPL, V80, P20687, DOI 10.1007/s11042-021-10671-z
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao BQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1680, DOI 10.1145/3123266.3123406
   Zhao CR, 2021, IEEE T IMAGE PROCESS, V30, P4212, DOI 10.1109/TIP.2021.3070182
   Zheng KC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4537, DOI 10.1145/3474085.3475610
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12045, DOI 10.1109/ICCV48922.2021.01185
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou SR, 2020, PATTERN RECOGN LETT, V138, P617, DOI 10.1016/j.patrec.2020.09.009
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 56
TC 8
Z9 8
U1 9
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103581
DI 10.1016/j.jvcir.2022.103581
EA JUL 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3C7GN
UT WOS:000828788400002
DA 2024-07-18
ER

PT J
AU Liu, YF
   Liang, YL
   Chen, ZH
AF Liu, Yifei
   Liang, Yaling
   Chen, Ziheng
TI LRHW-AP: Using ranking-based metric as loss for Person Re-Identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person Re-Identification; Image Retrieval; Average Precision; Pooling
ID NETWORK
AB Optimizing a ranking-based metric as the loss function, such as Average Precision (AP), has been found very effective in image retrieval tasks, but it has received less attention in Person Re-Identification (Re-ID). In this paper, Low Rank High Weight (LRHW) AP is proposed to apply the AP-optimizing method on the Re-ID task. LRHW-AP employs high weight on the low rank positive instances, which provides more information for model optimization than high rank positive instances and distribute in high gradient area. We propose a new pooling method called Power Activation Weighted Mean (PAWM) pooling which can unify a set of pooling methods because of a changeable activation function and a trainable parameter. Thus one can adjust and train PAWM to adapt to the target task to improve the model performance. Besides, we incorporate Warmup and Exponentially Decay Scheduler with a delay period, called Warmup Delay Exponentially Decay Scheduler, which brings further improvement. Through an extensive set of ablation studies, we verify that all methods mentioned above contribute to the performance boosts on Re-ID and the model achieves 95.3% rank-1 and 88.4% mAP on Market1501 with ResNet50.
C1 [Liu, Yifei; Liang, Yaling; Chen, Ziheng] South China Univ Technol, Sch Elect & Informat Engn, 381 Wushan Rd, Guangzhou 510641, Guangdong, Peoples R China.
C3 South China University of Technology
RP Liang, YL (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, 381 Wushan Rd, Guangzhou 510641, Guangdong, Peoples R China.
EM ylliang@scut.edu.cn
FU National Natural Science Founda-tion of China [61701181]; Guangdong
   Natural Science Founda-tion [2017A030325430]; Science and Technology
   Program of Guangzhou, China [201707010070]
FX Acknowledgments This work is supported by the National Natural Science
   Founda-tion of China (No. 61701181) , Guangdong Natural Science
   Founda-tion 2017A030325430 and the Science and Technology Program of
   Guangzhou, China. 201707010070
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2015, ARXIV150906033
   Brown Andrew, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P677, DOI 10.1007/978-3-030-58545-7_39
   Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen HR, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Ding CX, 2022, IEEE T PATTERN ANAL, V44, P1474, DOI 10.1109/TPAMI.2020.3024900
   Fan X, 2019, LECT NOTES COMPUT SC, V11362, P19, DOI 10.1007/978-3-030-20890-5_2
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gong X, 2022, IEEE T MULTIMEDIA, V24, P217, DOI 10.1109/TMM.2021.3050082
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He L., 2020, ARXIV PREPRINT ARXIV
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Howard A. G., 2017, PREPRINT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li W, 2017, IEEE INT CONF AUTOMA, P103, DOI 10.1109/FG.2017.136
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu XD, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103033
   Loshchilov I., 2017, INT C LEARN REPR
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   McFee B., 2010, ICML, P775
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Ni XY, 2021, INT C PATT RECOG, P9601, DOI 10.1109/ICPR48806.2021.9412481
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Qiu S., 2018, ARXIV PREPRINT ARXIV
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Rao Y., P IEEE CVF INT C COM, V2021, P1025
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Rolinek Michal, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7617, DOI 10.1109/CVPR42600.2020.00764
   Salamon J., DETECTION CLASSIFICA, V2017
   Shin H, 2019, IEEE ACCESS, V7, P150237, DOI 10.1109/ACCESS.2019.2947090
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Taylor M.J., 2008, P INT C WEB SEARCH D, P77, DOI [DOI 10.1145/1341531.1341544, 10.1145]
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JB, 2020, NEUROCOMPUTING, V404, P61, DOI 10.1016/j.neucom.2020.05.007
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xiang WM, 2019, IEEE IMAGE PROC, P1237, DOI [10.1109/icip.2019.8803735, 10.1109/ICIP.2019.8803735]
   Xiao Q., 2017, ARXIV171000478
   Xie Ben, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12307), P16, DOI 10.1007/978-3-030-60636-7_2
   Yan C., P IEEE CVF INT C COM, V2021, P11875
   Yang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164431
   Yuan Y, 2020, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW50498.2020.00185
   Zhang L., 2020, ARXIV201004819
   Zhang YY, 2019, AAAI CONF ARTIF INTE, P9243
   Zhang ZZ, 2022, IEEE T MULTIMEDIA, V24, P4158, DOI 10.1109/TMM.2021.3115451
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong WL, 2019, J VIS COMMUN IMAGE R, V62, P267, DOI 10.1016/j.jvcir.2019.06.001
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 80
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103517
DI 10.1016/j.jvcir.2022.103517
EA APR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L9NQ
UT WOS:000799607600003
DA 2024-07-18
ER

PT J
AU Shakeel, MS
   Lam, KM
AF Shakeel, Saad M.
   Lam, Kin-Man
TI Deep low-rank feature learning and encoding for cross-age face
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-age face recognition; Feature encoding; Kernel canonical
   correlation analysis; Low-rank features; Manifold learning
ID CONVOLUTIONAL NEURAL-NETWORK; REPRESENTATION; LOCALITY; MODEL
AB Cross-age face recognition (CAFR) is a challenging task, due to significant intra-personal variations. Furthermore, the training and testing data may contain random noise components. To address these issues, this paper proposes a deep low-rank feature learning and encoding method. Firstly, our method employs manifold learning in the low-rank optimization, which preserves the global and local structure of the data samples, while learning the clean low-rank features. Secondly, we encode the low-rank features using our locality-constrained feature encoding method, which learns an age-insensitive codebook from training data, and enables the intra-class samples to share the same local bases in a codebook. In the testing stage, the gallery and probe features are encoded by the learned codebook, which represents the images of the same identity by similar codewords for recognition. Furthermore, the periocular region of human faces is investigated for CAFR. Extensive experiments on five datasets demonstrate the effectiveness of our method.
C1 [Shakeel, Saad M.] Guangdong Univ Petrochem Technol, Sch Automat, Maoming, Peoples R China.
   [Shakeel, Saad M.; Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Guangdong University of Petrochemical Technology; Hong Kong Polytechnic
   University
RP Shakeel, MS (corresponding author), Guangdong Univ Petrochem Technol, Sch Automat, Maoming, Peoples R China.
EM 15902620r@connect.polyu.hk; enkmlam@polyu.edu.hk
FU GRF Grant of the Hong Kong SAR Government [PolyU 152765/16E, B-Q55J]
FX The work described in this paper was supported by the GRF Grant PolyU
   152765/16E (project code: B-Q55J) of the Hong Kong SAR Government.
CR [Anonymous], 2011, Signal Processing and Communication Systems (ICSPCS), 2011 5th International Conference on, DOI [10.1109/IJCB.2011.6117600, DOI 10.1109/IJCB.2011.6117600]
   Bai S., 2020, IEEE INT C PATT REC
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bianco S, 2017, PATTERN RECOGN LETT, V90, P36, DOI 10.1016/j.patrec.2017.03.006
   Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dodge S, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Du LS, 2020, IEEE T CIRC SYST VID, V30, P2830, DOI 10.1109/TCSVT.2019.2923262
   Facial Image Processing and Analysis (FIPA), FG NET AG DAT
   Fu YL, 2017, NEUROCOMPUTING, V260, P104, DOI 10.1016/j.neucom.2017.04.001
   Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huang YJ, 2021, IEEE T CIRC SYST VID, V31, P148, DOI 10.1109/TCSVT.2020.2965739
   Jing XY, 2016, PATTERN RECOGN, V59, P14, DOI 10.1016/j.patcog.2016.01.023
   Koch G., 2015, PROC ICML DEEP LEARN, V2, P1
   Li HX, 2018, IEEE T INF FOREN SEC, V13, P2383, DOI 10.1109/TIFS.2018.2819124
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284
   Lin ZC, 2011, PROG MOL BIOL TRANSL, V98, P1, DOI 10.1016/B978-0-12-385506-0.00001-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Meng M, 2018, IEEE SIGNAL PROC LET, V25, P1379, DOI 10.1109/LSP.2018.2857201
   Miller P.E., 2010, INT C BIOM THEOR APP
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Ng CJ, 2018, J VIS COMMUN IMAGE R, V55, P548, DOI 10.1016/j.jvcir.2018.07.002
   Pang JB, 2015, IEEE T CYBERNETICS, V45, P2937, DOI 10.1109/TCYB.2015.2433926
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shakeel MS, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102590
   Shakeel MS, 2019, PATTERN RECOGN, V93, P442, DOI 10.1016/j.patcog.2019.04.028
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P899
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H, 2019, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2019.00364
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wang XL, 2017, IEEE INT CONF AUTOMA, P596, DOI 10.1109/FG.2017.75
   Wang YT, 2018, LECT NOTES COMPUT SC, V11219, P764, DOI 10.1007/978-3-030-01267-0_45
   Wang YH, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102764
   Wen YD, 2016, PROC CVPR IEEE, P4893, DOI 10.1109/CVPR.2016.529
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Xu ZS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P214, DOI 10.1109/CIAPP.2017.8167210
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao J, 2022, IEEE T PATTERN ANAL, V44, P474, DOI 10.1109/TPAMI.2020.3011426
   Zhao SY, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107097
   Zhou H., 2015, APSIPA, P1
NR 56
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103423
DI 10.1016/j.jvcir.2021.103423
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I8FF
UT WOS:000779649200002
DA 2024-07-18
ER

PT J
AU Liu, J
   Wang, WK
   Yu, JX
   Zhang, CP
   Su, YT
AF Liu, Jing
   Wang, Weikang
   Yu, Jiexiao
   Zhang, Chunping
   Su, Yuting
TI 3DFP-FCGAN: Face completion generative adversarial network with 3D
   facial prior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face completion; 2D geometry priors; 3D depth prior; Generative model
ID IMAGE
AB Face completion is a domain-specific image inpainting problem. Most existing face completion methods fail to synthesize fine-grained facial structures due to the undifferentiated treatment of face images and other scene images. To handle this problem, we propose an end-to-end deep generative model based approach which makes full use of the facial prior knowledge, including 2D facial geometry priors from facial parsing maps and landmarks, as well as the 3D depth prior. We adopt a coarse-to-fine inpainting framework where the 2D facial geometry priors based on coarse faces are extracted to guide the refinement network for better planar facial textures and structures. Moreover, a novel 3D regularized reconstruction loss is proposed for the enhancement of the stereo perception of generated faces. Experimental results on two large-scale benchmarks CelebA and CelebA-HQ show that our method significantly outperforms the state-of-the-arts in generating more visually realistic and pleasing faces. Code is available at https://github.com/TJUMMG/3DFP_FCGAN.
C1 [Liu, Jing; Wang, Weikang; Yu, Jiexiao; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Zhang, Chunping] Baidu Com Times Technol Beijing Co Ltd, Beijing 100085, Peoples R China.
C3 Tianjin University; Baidu
RP Yu, JX (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM yjx@tju.edu.cn
OI Wang, Weikang/0000-0001-9591-8559
FU Natural Science Foundation of Tianjin [20JCQNJC01150]; Innovation Fund
   of Tianjin University
FX Acknowledgment This work was supported by the Natural Science Foundation
   of Tianjin (Grant No. 20JCQNJC01150) and Innovation Fund of Tianjin
   University (2001) .
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Faltemier TC, 2008, COMPUT VIS IMAGE UND, V112, P114, DOI 10.1016/j.cviu.2008.01.004
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gao ZP, 2020, DISPLAYS, V65, DOI 10.1016/j.displa.2020.101972
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han C, 2021, IEEE SIGNAL PROC LET, V28, P190, DOI 10.1109/LSP.2020.3048608
   He Y, 2019, IEEE I CONF COMP VIS, P2111, DOI 10.1109/ICCV.2019.00220
   Hensel M, 2017, ADV NEUR IN, V30
   Hong X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2033, DOI 10.1145/3343031.3351002
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Karras T., 2018, INT CONFLEARN REPRES
   Kim D, 2019, PROC CVPR IEEE, P5785, DOI 10.1109/CVPR.2019.00594
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu SF, 2015, PROC CVPR IEEE, P3451, DOI 10.1109/CVPR.2015.7298967
   Liu XW, 2020, NEURAL PROCESS LETT, V51, P211, DOI 10.1007/s11063-019-10080-2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mathai J., 2019, INT CONF BIOMETR, P1, DOI DOI 10.1109/icb45273.2019.8987388
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Sagong MC, 2019, PROC CVPR IEEE, P11352, DOI 10.1109/CVPR.2019.01162
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1007/978-3-030-01216-8_1, 10.1109/APCAP.2017.8420330]
   Sugita N, 2019, DISPLAYS, V58, P20, DOI 10.1016/j.displa.2018.10.007
   Tong Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7677, DOI 10.1109/CVPR42600.2020.00770
   Wang Q, 2021, IEEE T MULTIMEDIA, V23, P429, DOI 10.1109/TMM.2020.2978633
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilczkowiak M., 2005, BRIT MACH VIS C BMVC
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang J, 2020, AAAI CONF ARTIF INTE, V34, P12605
   Yang XH, 2021, IEEE ACCESS, V9, P42100, DOI 10.1109/ACCESS.2021.3065661
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang S, 2018, IEEE T INF FOREN SEC, V13, P637, DOI 10.1109/TIFS.2017.2763119
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhou YX, 2019, PROC CVPR IEEE, P1097, DOI 10.1109/CVPR.2019.00119
NR 52
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103380
DI 10.1016/j.jvcir.2021.103380
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0SO
UT WOS:000783933400006
DA 2024-07-18
ER

PT J
AU Raveendra, M
   Nagireddy, K
AF Raveendra, Malle
   Nagireddy, K.
TI Tamper video detection and localization using an adaptive segmentation
   and deep network technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video forgery; Double compression; Modified Brain storm optimization
   (MBSO); Adaptive galactic Swarm optimization (AGSO); Deep Neural Network
   (DNN)
ID CONVOLUTIONAL NEURAL-NETWORK; FORGERY DETECTION; DOUBLE COMPRESSION;
   FRAME DELETION
AB In this work we have explored the hybrid deep learning architecture for recognizing the tampering from the videos. This hybrid architecture explores the features from the authentic videos to categorize the tampered portions from the forged videos. Initially, the process begins by compressing the input video using the Discrete cosine transform (DCT) based double compression approach. Then, the filtering process is carried out to improve the quality of compressed frame using the bilateral filtering. Then, the modified segmentation approach is applied to segment the frames into different regions. The features from these segmented portions are extracted and fed into hybrid DNN-AGSO (deep neural network-Adaptivf RELATED WORKSe Galactic Swarm Optimization) using Gabor wavelet transform (GWT) technique. Three different datasets are used to evaluate the overall performance they are, VTD, MFC-18, and VIRAT by MATLAB platform. The recognition rate achieved by VTD, MFC-18, and VIRAT datasets are 96%, 95.2%, and 93.47% respectively.
C1 [Raveendra, Malle] Jawaharlal Nehru Technol Univ, Elect & Commun Engn, Anantapuramu, India.
   [Nagireddy, K.] NBKR Inst Sci & Technol, Elect & Commun Engn, Vijayanagar, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Raveendra, M (corresponding author), Jawaharlal Nehru Technol Univ, Elect & Commun Engn, Anantapuramu, India.
EM ravindra439@gmail.com
CR Abdalla Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101280
   Afchar D, 2018, IEEE INT WORKS INFOR
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Alipour N, 2020, MULTIMED TOOLS APPL, V79, P8249, DOI 10.1007/s11042-019-08597-8
   Aloraini M, 2021, IEEE T CIRC SYST VID, V31, P917, DOI 10.1109/TCSVT.2020.2993004
   [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Bagchi Chhandak, 2019, Information Systems Design and Intelligent Applications. Proceedings of Fifth International Conference INDIA 2018. Advances in Intelligent Systems and Computing (AISC 862), P123, DOI 10.1007/978-981-13-3329-3_12
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bernal Emer, 2018, METAHEURISTICS, P1
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   Cheng JR, 2009, IEEE T BIO-MED ENG, V56, P741, DOI 10.1109/TBME.2008.2008635
   He PS, 2017, NEUROCOMPUTING, V228, P84, DOI 10.1016/j.neucom.2016.09.084
   He PS, 2016, J VIS COMMUN IMAGE R, V35, P55, DOI 10.1016/j.jvcir.2015.11.014
   Hong JH, 2019, DIGIT INVEST, V30, P23, DOI 10.1016/j.diin.2019.06.002
   Hu HM, 2017, NEUROCOMPUTING, V266, P361, DOI 10.1016/j.neucom.2017.05.052
   Huang Z, 2016, BIOMED SIGNAL PROCES, V25, P53, DOI 10.1016/j.bspc.2015.11.002
   Huang ZS, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P306, DOI 10.1109/ChinaSIP.2014.6889253
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Julliand Thibaut, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P3, DOI 10.1007/978-3-319-31960-5_1
   Kaur H, 2020, WIRELESS PERS COMMUN, V112, P1763, DOI 10.1007/s11277-020-07126-3
   Liao D., 2011, IS T SPIE EL IMAG IN
   Long C., 2019, CVPR WORKSHOPS, P1
   Nguyen X.H., 2020, Int. J. Image, V3, P1
   Pamela J., 2019, DIGIT INVEST
   Prasad PMK, 2018, ADV INTELL SYST COMP, V668, P473, DOI 10.1007/978-981-10-7868-2_46
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Raveendra M., 2019, Int J Eng Adv Technol, V9, P1190, DOI [10.35940/ijeat.A9517.109119, DOI 10.35940/IJEAT.A9517.109119]
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Sitara K, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P73, DOI 10.1109/CSPA.2017.8064927
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Velliangiri S, 2020, CMES-COMP MODEL ENG, V125, P625, DOI 10.32604/cmes.2020.010869
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Xu JY, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413540013
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
NR 44
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103401
DI 10.1016/j.jvcir.2021.103401
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400006
DA 2024-07-18
ER

PT J
AU Yang, LQ
   Kou, KI
   Miao, JF
AF Yang, Liqiao
   Kou, Kit Ian
   Miao, Jifei
TI Weighted truncated nuclear norm regularization for low-rank quaternion
   matrix completion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quaternion matrix completion; Low-rank; Quaternion truncated nuclear
   norm; Weights
ID MINIMIZATION; ERROR
AB In recent years, quaternion matrix completion (QMC) based on low-rank regularization has been gradually used in image processing. Unlike low-rank matrix completion (LRMC) which handles RGB images by recovering each color channel separately, QMC models retain the connection of three channels and process them as a whole. Most of the existing quaternion-based methods formulate low-rank QMC (LRQMC) as a quaternion nuclear norm (a convex relaxation of the rank) minimization problem. The main limitation of these approaches is that they minimize the singular values simultaneously such that cannot approximate low-rank attributes efficiently. To achieve a more accurate low-rank approximation, we introduce a quaternion truncated nuclear norm (QTNN) for LRQMC and utilize the alternating direction method of multipliers (ADMM) to get the optimization in this paper. Further, we propose weights to the residual error quaternion matrix during the update process for accelerating the convergence of the QTNN method with admissible performance. The weighted method utilizes a concise gradient descent strategy which has a theoretical guarantee in optimization. The effectiveness of our method is illustrated by experiments on real visual data sets.
C1 [Yang, Liqiao; Kou, Kit Ian; Miao, Jifei] Univ Macau, Fac Sci & Technol, Dept Math, Macau 999078, Peoples R China.
C3 University of Macau
RP Kou, KI (corresponding author), Univ Macau, Fac Sci & Technol, Dept Math, Macau 999078, Peoples R China.
EM liqiaoyoung@163.com; kikou@umac.mo; jifmiao@163.com
RI Kou, Kit Ian/J-6581-2012
OI Kou, Kit Ian/0000-0003-1924-9087
CR [Anonymous], 2011, Advances in Neural Information Processing Systems
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès E, 2012, COMMUN ACM, V55, P111, DOI 10.1145/2184319.2184343
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Chen YY, 2020, IEEE T IMAGE PROCESS, V29, P1426, DOI 10.1109/TIP.2019.2941319
   Fazel M, 2004, P AMER CONTR CONF, P3273
   Girard PR., 2007, Quaternions, Clifford algebras and relativistic physics
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Jain P, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P665
   Jiang TS, 2003, APPL MATH LETT, V16, P883, DOI 10.1016/S0893-9659(03)90012-7
   Johnson, 2012, MATRIX ANAL
   Koltchinskii V, 2011, ANN STAT, V39, P2302, DOI 10.1214/11-AOS894
   Kyrchei I. I., 2017, Adv. Math. Resear., V23, P35
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu M, 2015, AAAI CONF ARTIF INTE, P2778
   Liu Q, 2016, IEEE T IMAGE PROCESS, V25, P316, DOI 10.1109/TIP.2015.2503238
   Marshall Albert W., 1979, Inequalities Theory of Majorization and Its Applications, V143
   Miao JF, 2020, IEEE T SIGNAL PROCES, V68, P5617, DOI 10.1109/TSP.2020.3025519
   MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Strasek R, 2003, LINEAR ALGEBRA APPL, V367, P235, DOI 10.1016/S0024-3795(02)00635-3
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2015, IEEE T IMAGE PROCESS, V24, P1315, DOI 10.1109/TIP.2015.2397314
   Xue S., 2019, ARXIV190101711
   Yu YB, 2019, NEUROCOMPUTING, V332, P283, DOI 10.1016/j.neucom.2018.12.034
   Zhang FZ, 1997, LINEAR ALGEBRA APPL, V251, P21, DOI 10.1016/0024-3795(95)00543-9
   Zhou P, 2018, IEEE T IMAGE PROCESS, V27, P1152, DOI 10.1109/TIP.2017.2762595
   Zou CM, 2016, IEEE T IMAGE PROCESS, V25, P3287, DOI 10.1109/TIP.2016.2567077
NR 32
TC 11
Z9 11
U1 4
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103335
DI 10.1016/j.jvcir.2021.103335
EA OCT 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, W
   Chen, SB
   Xu, LX
   Luo, B
AF Zhou, Wei
   Chen, Si-Bao
   Xu, Li-Xiang
   Luo, Bin
TI Multi-ColorGAN: Few-shot vehicle recoloring via memory-augmented
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Memory-augmented network; Generative adversarial network; Image
   recoloring; Vehicle recoloring; Few-shot learning
AB Despite the notable successes of Generative adversarial networks (GANs) achieved to date, applying them to real-world problems still poses significant challenges. In real traffic surveillance scenarios, for the task of generating images of multiple color of truck heads and cars without changing textures and license plates, conditional image generation hardly manipulate the generated images by the color attribute. Image style transfer methods inevitably produce color smearing. Even state-of-the-art methods of disentangled representation learning (e.g. MixNMatch) cannot disentangle colors individually, ensuring that irrelevant factors, such as texture remain the same. To solve this problem, we present an approach called Multi-ColorGAN based on memory-augmented networks for multi-color real vehicle coloring/generation with limited data. In particular, our model could filter out unwanted color changes in specific areas with a simple but effective method called Fusion Module, and generate more natural color images. Experiments on three vehicle image benchmarks and a new truck image dataset are conducted to evaluate the proposed Multi-ColorGAN compared to state-of-the-art.
C1 [Zhou, Wei; Chen, Si-Bao; Luo, Bin] Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, MOE Key Lab ICSP, Hefei 230601, Peoples R China.
   [Xu, Li-Xiang] Hefei Univ, Sch Artificial Intelligence & Big Data, Hefei 230092, Peoples R China.
C3 Anhui University; Hefei University
RP Chen, SB (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, MOE Key Lab ICSP, Hefei 230601, Peoples R China.
EM sbchen@ahu.edu.cn
RI lu, bin/HPE-4790-2023
OI Zhou, Wei/0000-0003-0687-9223
CR Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Benaim S., 2018, ADV NEUR IN
   Bsnvc A., J VIS COMMUN IMAGE R
   Chen R., 2020, PROC IEEECVF C COMPU, P8165, DOI DOI 10.1109/CVPR42600.2020.00819
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cohen T, 2019, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2019.00187
   Deshpande A, 2017, PROC CVPR IEEE, P2877, DOI 10.1109/CVPR.2017.307
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gonzalezgarcia A., 2018, ADV NEURAL INFORM PR, P1287
   Gu SY, 2019, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2019.00355
   Hensel M, 2017, ADV NEUR IN, V30
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kim T, 2017, PR MACH LEARN RES, V70
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li X, 2020, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR42600.2020.00294
   Li YJ, 2018, LECT NOTES COMPUT SC, V11207, P468, DOI 10.1007/978-3-030-01219-9_28
   Li ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2418
   Lin J., ARXIV200404634
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lorenz D, 2019, PROC CVPR IEEE, P10947, DOI 10.1109/CVPR.2019.01121
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shen C., ARXIV210300430
   Shu ZX, 2018, LECT NOTES COMPUT SC, V11214, P664, DOI 10.1007/978-3-030-01249-6_40
   Singh KK, 2019, PROC CVPR IEEE, P6483, DOI 10.1109/CVPR.2019.00665
   Wang YX, 2020, PROC CVPR IEEE, P4452, DOI 10.1109/CVPR42600.2020.00451
   Xiao Y, 2019, INT CONF ACOUST SPEE, P1887, DOI 10.1109/ICASSP.2019.8683686
   Xing X., ARXIV180606298
   Yi Z, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND DIGITAL IMAGE PROCESSING (CGDIP 2017), DOI 10.1145/3110224.3110230
   Yoo S, 2019, PROC CVPR IEEE, P11275, DOI 10.1109/CVPR.2019.01154
   Yuheng Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8036, DOI 10.1109/CVPR42600.2020.00806
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhao HT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102921
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
NR 48
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103317
DI 10.1016/j.jvcir.2021.103317
EA SEP 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7DP
UT WOS:000709884500002
DA 2024-07-18
ER

PT J
AU Zamani, F
   Jamzad, M
   Rabiee, HR
AF Zamani, Fatemeh
   Jamzad, Mansour
   Rabiee, Hamid R.
TI Atom specific multiple kernel dictionary based Sparse Representation
   Classifier for medium scale classification*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse Representation Classifier; Multiple Kernel Learning; Kernel local
   weighting; Dictionary learning; Image classification
ID ROBUST FACE RECOGNITION; DISCRIMINATIVE DICTIONARY; K-SVD; FEATURES;
   FRAMEWORK; MATRIX; MODEL; SET
AB Kernel based Sparse Representation Classifier (KSRC) can classify images with acceptable performance. In addition, Multiple Kernel Learning based SRC (MKL-SRC) computes the weighted sum of multiple kernels in order to construct a unified kernel while the weight of each kernel is calculated as a fixed value in the training phase. In this paper, an MKL-SRC with non-fixed kernel weights for dictionary atoms is proposed. Kernel weights are embedded as new variables to the main KSRC goal function and the resulted optimization problem is solved to find the sparse coefficients and kernel weights simultaneously. As a result, an atom specific multiple kernel dictionary is computed in the training phase which is used by SRC to classify test images. Also, it is proved that the resulting optimization problem is convex and is solvable via common algorithms. The experimental results demonstrate the effectiveness of the proposed approach.
C1 [Zamani, Fatemeh; Jamzad, Mansour; Rabiee, Hamid R.] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Zamani, F (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM f_zamani@ce.sharif.edu; jamzad@sharif.edu; rabiee@sharif.edu
RI Zamani, Fatemeh/AFM-7532-2022; Rabiee, Hamid R./L-7866-2017
OI Zamani, Fatemeh/0000-0001-5066-7485; Rabiee, Hamid
   R./0000-0002-9835-4493
FU Iran National Science Foundation (INSF)
FX We would like to thank Iran National Science Foundation (INSF) for their
   partial support of this work.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bertsekas D. P., 1997, Journal of the Operational Research Society, V48, P334, DOI 10.1057/palgrave.jors.2600425
   Chen Y, 2016, IEEE T MULTIMEDIA, V18, P576, DOI 10.1109/TMM.2016.2525010
   Chun IY, 2018, IEEE T IMAGE PROCESS, V27, P1697, DOI 10.1109/TIP.2017.2761545
   COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Feng QX, 2016, IEEE T MULTIMEDIA, V18, P1956, DOI 10.1109/TMM.2016.2602062
   Foroughi H, 2018, IEEE T IMAGE PROCESS, V27, P806, DOI 10.1109/TIP.2017.2766446
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Gonen M., 2008, ICML, P352, DOI DOI 10.1145/1390156.1390201
   Huang J., 2013, 27 AAAI C ART INT
   Huang L, 2019, PATTERN RECOGN, V86, P344, DOI 10.1016/j.patcog.2018.09.016
   Jian M, 2013, IEEE T SIGNAL PROCES, V61, P4416, DOI 10.1109/TSP.2013.2271479
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jiang ZL, 2012, PROC CVPR IEEE, P3418, DOI 10.1109/CVPR.2012.6248082
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Kang LW, 2011, IEEE T MULTIMEDIA, V13, P1019, DOI 10.1109/TMM.2011.2159197
   Kang Z., 2018, P 27 INT JOINT C ART
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lei H, 2014, PATTERN RECOGN, V47, P899, DOI 10.1016/j.patcog.2013.07.016
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li XL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2201
   Li XL, 2017, AAAI CONF ARTIF INTE, P4147
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48
   Luo W, 2018, IEEE T NEUR NET LEAR, V29, P3289, DOI 10.1109/TNNLS.2017.2712793
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Nesterov Yurii, 1994, SIAM Studies in Applied Mathematics, DOI [DOI 10.1137/1.9781611970791, 10.1137/1.9781611970791]
   Nilsback M.-E., 2006 IEEE COMP SOC C, V2, P1447
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Powell M. J. D., 1973, MATH PROGRAM, V4, P193, DOI DOI 10.1007/BF01584660
   Puthenputhussery A, 2017, IEEE T MULTIMEDIA, V19, P1757, DOI 10.1109/TMM.2017.2685179
   Quan YH, 2016, PATTERN RECOGN, V55, P247, DOI 10.1016/j.patcog.2016.01.028
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Shechtman E., COMPUTER VISION PATT, P1
   Shen XB, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178119
   Shen XB, 2018, J VIS COMMUN IMAGE R, V53, P161, DOI 10.1016/j.jvcir.2018.03.004
   Shrivastava A, 2014, IEEE T IMAGE PROCESS, V23, P3013, DOI 10.1109/TIP.2014.2324290
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Tan SB, 2017, IEEE T IMAGE PROCESS, V26, P4661, DOI 10.1109/TIP.2017.2716180
   Thiagarajan JJ, 2014, IEEE T IMAGE PROCESS, V23, P2905, DOI 10.1109/TIP.2014.2322938
   Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vedaldi A., 2015, MULTIPLE KERNELS IMA
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wilson S, 2018, IEEE T MULTIMEDIA, V20, P96, DOI 10.1109/TMM.2017.2716835
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu H, 2018, J VIS COMMUN IMAGE R, V55, P415, DOI 10.1016/j.jvcir.2018.06.021
   Xu C., 2013, arXiv
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang JJ, 2012, IEEE T IMAGE PROCESS, V21, P2838, DOI 10.1109/TIP.2012.2183139
   Yang M, 2017, NEUROCOMPUTING, V269, P13, DOI 10.1016/j.neucom.2016.08.146
   Yang M, 2017, NEUROCOMPUTING, V219, P404, DOI 10.1016/j.neucom.2016.09.037
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Yina Han, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3109, DOI 10.1109/ICPR.2010.761
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Zare T, 2017, NEUROCOMPUTING, V234, P164, DOI 10.1016/j.neucom.2016.12.056
   Zhang FZ, 2018, SIGNAL PROCESS, V143, P354, DOI 10.1016/j.sigpro.2017.06.023
   Zhang GQ, 2016, J VIS COMMUN IMAGE R, V40, P470, DOI 10.1016/j.jvcir.2016.07.015
   Zhang H., Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (2006), V2, P2126
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang SQ, 2014, J VIS COMMUN IMAGE R, V25, P1878, DOI 10.1016/j.jvcir.2014.09.011
   Zheng JW, 2018, NEUROCOMPUTING, V296, P1, DOI 10.1016/j.neucom.2018.03.035
   Zhou Y, 2013, PATTERN RECOGN, V46, P3208, DOI 10.1016/j.patcog.2013.06.007
NR 76
TC 2
Z9 2
U1 3
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103228
DI 10.1016/j.jvcir.2021.103228
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900002
DA 2024-07-18
ER

PT J
AU Pérez-Delgado, ML
AF Perez-Delgado, Maria-Luisa
TI Revisiting the Iterative Ant-tree for color quantization algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color quantization; Clustering; Artificial ants
ID MEANS CLUSTERING-ALGORITHM; IMAGE QUANTIZATION; REDUCTION
AB The Iterative Ant-tree for color quantization algorithm has recently been proposed to reduce the colors of an image at a low computational cost. It is a clustering-based method that generates good images compared to several well-known color quantization methods. This article proposes the modification of two features of the original algorithm: the value assigned to the parameter associated with the algorithm and the order in which the pixels of the image are processed. As a result, the new variant of the algorithm generates better images than the original and the results are less sensitive to the value selected for the parameter.
C1 [Perez-Delgado, Maria-Luisa] Univ Salamanca, Escuela Politecn Super Zamora, Ave Requejo 33, Zamora 49022, Spain.
C3 University of Salamanca
RP Pérez-Delgado, ML (corresponding author), Univ Salamanca, Escuela Politecn Super Zamora, Ave Requejo 33, Zamora 49022, Spain.
EM mlperez@usal.es
RI Pérez-Delgado, María Luisa/AAA-8313-2019
OI Pérez-Delgado, María Luisa/0000-0003-1810-0264
FU Samuel Solorzano Barruso Memorial Foundation of the University of
   Salamanca, Spain [FS/102015]
FX This work was supported by the Samuel Solorzano Barruso Memorial
   Foundation of the University of Salamanca, Spain [grant number
   FS/102015] .
CR Atsalakis A, 2006, ENG APPL ARTIF INTEL, V19, P769, DOI 10.1016/j.engappai.2006.05.004
   Azzag H, 2007, EUR J OPER RES, V179, P906, DOI 10.1016/j.ejor.2005.03.062
   Celebi ME, 2014, IMAGING SCI J, V62, P80, DOI 10.1179/1743131X13Y.0000000059
   Celebi ME, 2015, J REAL-TIME IMAGE PR, V10, P329, DOI 10.1007/s11554-012-0291-4
   Celebi ME, 2011, IMAGE VISION COMPUT, V29, P260, DOI 10.1016/j.imavis.2010.10.002
   Celebi ME, 2009, J OPT SOC AM A, V26, P2434, DOI 10.1364/JOSAA.26.002434
   Chang CH, 2005, IEEE T NEURAL NETWOR, V16, P237, DOI 10.1109/TNN.2004.836543
   Cheng SC, 2001, PATTERN RECOGN LETT, V22, P845, DOI 10.1016/S0167-8655(01)00025-3
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Emre Celebi M., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P876
   Franzen R., 2019, KODAK LOSSLESS TRUE
   GAREY MR, 1982, IEEE T INFORM THEORY, V28, P255, DOI 10.1109/TIT.1982.1056488
   Gervautz M., 1990, GLASSNER GRAPHICS GE, P287, DOI [10.1016/B978-0-08-050753-8.50061-9, DOI 10.1016/B978-0-08-050753-8.50061-9]
   Heckbert P., 1982, Computer Graphics, V16, P297, DOI 10.1145/965145.801294
   Hu YC, 2008, IMAGING SCI J, V56, P29, DOI 10.1179/174313107X176298
   Joy G., 1993, Visual Computer, V10, P62, DOI 10.1007/BF01905532
   Kanjanawanishkul K, 2005, J VIS COMMUN IMAGE R, V16, P311, DOI 10.1016/j.jvcir.2004.07.002
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kasuga H., 2000, Systems and Computers in Japan, V31, P33, DOI 10.1002/1520-684X(200007)31:8<33::AID-SCJ4>3.0.CO;2-C
   Kennedy James., 2010, Particle Swarm Optimization, P760, DOI DOI 10.1007/978-0-387-30164-8_630
   Omran MG, 2005, INFORM-J COMPUT INFO, V29, P261
   ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417
   Özdemir D, 2002, PATTERN RECOGN, V35, P1785, DOI 10.1016/S0031-3203(01)00170-4
   Ozturk C, 2014, INFORMATICA-LITHUAN, V25, P485, DOI 10.15388/Informatica.2014.25
   Palomo EJ, 2014, J MATH IMAGING VIS, V49, P1, DOI 10.1007/s10851-013-0433-8
   Papamarkos N, 2002, IEEE T SYST MAN CY B, V32, P44, DOI 10.1109/3477.979959
   Pérez-Delgado ML, 2015, APPL SOFT COMPUT, V36, P656, DOI 10.1016/j.asoc.2015.07.048
   Pérez-Delgado ML, 2020, J REAL-TIME IMAGE PR, V17, P581, DOI 10.1007/s11554-018-0814-8
   Pérez-Delgado ML, 2019, APPL INTELL, V49, P2482, DOI 10.1007/s10489-018-1389-6
   Pérez-Delgado ML, 2019, ENG APPL ARTIF INTEL, V79, P142, DOI 10.1016/j.engappai.2019.01.002
   Pérez-Delgado ML, 2018, APPL SOFT COMPUT, V73, P153, DOI 10.1016/j.asoc.2018.08.018
   Pérez-Delgado ML, 2018, INT J BIO-INSPIR COM, V12, P87, DOI 10.1504/IJBIC.2018.10015516
   Schaefer G, 2009, TELECOMMUN SYST, V40, P17, DOI 10.1007/s11235-008-9143-8
   Scheunders P, 1997, PATTERN RECOGN, V30, P859, DOI 10.1016/S0031-3203(96)00131-8
   Sirisathitkul Y, 2004, PATTERN RECOGN LETT, V25, P1025, DOI 10.1016/j.patrec.2004.02.012
   WAN SJ, 1990, COLOR RES APPL, V15, P52, DOI 10.1002/col.5080150109
   Wang CH, 2007, PATTERN RECOGN LETT, V28, P1616, DOI 10.1016/j.patrec.2007.04.005
   Weber A.G., 2019, The USC-SIPI Image Database: Version 5, Original Release
   Wen Q, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-118
   Wu X., 1991, Graphics Gems, V11, P126, DOI DOI 10.1016/B978-0-08-050754-5.50035-9
   WU XL, 1992, ACM T GRAPHIC, V11, P348, DOI 10.1145/146443.146475
   Yang X.-S., 2013, International Journal of Swarm Intelligence, P36, DOI DOI 10.1504/IJSI.2013.055801
NR 42
TC 6
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103180
DI 10.1016/j.jvcir.2021.103180
EA JUN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500004
DA 2024-07-18
ER

PT J
AU Gao, P
   Zhu, TT
   Paul, M
AF Gao, Pan
   Zhu, Tiantian
   Paul, Manoranjan
TI Disocclusion filling for depth-based view synthesis with adaptive
   utilization of temporal correlations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth-image-based-rendering; Gaussian mixture model; Expectation
   maximization; Foreground depth correlation; Adaptive hole-filling
ID FREE-VIEWPOINT VIDEO; INFORMATION
AB The depth image-based rendering paves the path to success of 3-D video. However, one issue still remained in 3-D video is how to fill the disocclusion areas. To this end, Gaussian mixture model (GMM) is commonly employed to generate the background, and then to fill the holes. Nevertheless, GMM usually has poor performance for sequences with big foreground reciprocation. In this paper, we aim to enhance the synthesis performance. Firstly, we propose an expectation maximization based GMM background generation method, in which the pixel mixture distribution is derived. Secondly, we propose a refined foreground depth correlation approach, which recovers the background frame-by-frame based on depth information. Finally, we adaptively choose the background pixels from these two methods for filling. Experimental results show that the proposed method outperforms existing non-deep learning based hole filling methods by around 1.1 dB, and significantly surpasses deep learning based alternative in terms of subjective quality.
C1 [Gao, Pan; Zhu, Tiantian] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Paul, Manoranjan] Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia.
   [Gao, Pan] Collaborat Innovat Ctr Novel Software Technol & I, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Charles Sturt
   University
RP Gao, P (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.; Gao, P (corresponding author), Collaborat Innovat Ctr Novel Software Technol & I, Nanjing, Jiangsu, Peoples R China.
EM gaopan.1005@gmail.com; ztian@nuaa.edu.cn; mpaul@csu.edu.au
RI Paul, Manoranjan/AAD-4047-2021
OI Paul, Manoranjan/0000-0001-6870-5056
CR [Anonymous], 2008, JTC1SC29WG11 ISOIEC
   Barazzetti L, 2018, ADV ENG INFORM, V38, P605, DOI 10.1016/j.aei.2018.09.007
   Cai CT, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013010
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen ML, 2018, IEEE T PATTERN ANAL, V40, P1518, DOI 10.1109/TPAMI.2017.2717828
   Chen Y, 2020, J ADV MODEL EARTH SY, P1, DOI DOI 10.1029/2019MS001719
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chen YT, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02778-2
   Chen YT, 2021, APPL INTELL, V51, P3460, DOI 10.1007/s10489-020-01971-2
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Choi S, 2013, IEEE T IMAGE PROCESS, V22, P2429, DOI 10.1109/TIP.2013.2251646
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dai J, 2017, IEEE IMAGE PROC, P1387, DOI 10.1109/ICIP.2017.8296509
   Daribo Ismael, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P167, DOI 10.1109/MMSP.2010.5662013
   de Oliveira AQ, 2018, IEEE SIGNAL PROC LET, V25, P1705, DOI 10.1109/LSP.2018.2870342
   Dellaert F., 2002, TECH REP
   Doan H.N., 2015, P 2015 RES AD CONV S, P152, DOI [10.1145/2811411.2811497, DOI 10.1145/2811411.2811497]
   Doan HN, 2015, LECT NOTES COMPUT SC, V9315, P598, DOI 10.1007/978-3-319-24078-7_61
   Fang L, 2016, IEEE T IMAGE PROCESS, V25, P1961, DOI 10.1109/TIP.2016.2535345
   Farid MS, 2013, IEEE INT WORKSH MULT, P135, DOI 10.1109/MMSP.2013.6659277
   Fiandrotti A, 2019, 2019 INT C DISTR SMA, P1
   Fujihashi T, 2019, IEEE T MULTIMEDIA, V21, P1000, DOI 10.1109/TMM.2018.2870074
   Gao P, 2019, IEEE T IMAGE PROCESS, V28, P5266, DOI 10.1109/TIP.2019.2919198
   Gao P, 2017, IEEE T IMAGE PROCESS, V26, P2781, DOI 10.1109/TIP.2017.2690058
   Goyal K, 2018, ARTIF INTELL REV, V50, P241, DOI 10.1007/s10462-017-9542-x
   Haque M, 2008, INT C PATT RECOG, P1001
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim WS, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2447737
   Köppel M, 2012, IEEE INT WORKSH MULT, P25, DOI 10.1109/MMSP.2012.6343410
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lei JJ, 2017, IEEE T IMAGE PROCESS, V26, P1732, DOI 10.1109/TIP.2017.2656463
   Li S, 2018, IEEE T MULTIMEDIA, V20, P1948, DOI 10.1109/TMM.2018.2791810
   Liu C, 2019, PATTERN RECOGN, V87, P269, DOI 10.1016/j.patcog.2018.10.025
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Paul M, 2018, IEEE T BROADCAST, V64, P235, DOI 10.1109/TBC.2017.2781118
   Paul M, 2016, NEUROCOMPUTING, V175, P544, DOI 10.1016/j.neucom.2015.10.094
   Podder PK, 2016, NEUROCOMPUTING, V173, P1211, DOI 10.1016/j.neucom.2015.08.079
   Rahaman D. M. M., 2016, IEEE INT CONF MULTI, P1
   Rahaman DMM, 2018, IEEE T IMAGE PROCESS, V27, P1190, DOI 10.1109/TIP.2017.2772858
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P577, DOI 10.1109/ICMA.2014.6885761
   Shen LQ, 2014, IEEE T BROADCAST, V60, P128, DOI 10.1109/TBC.2013.2289635
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Thatte J., 2019, 2019 IEEE Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP47243.2019.8966071
   Tian D, 2009, PROC SPIE, V7443, DOI 10.1117/12.829372
   Nguyen TD, 2019, IEEE T MULTIMEDIA, V21, P1345, DOI 10.1109/TMM.2018.2880954
   Vaananen P., 2019, INT ARCH PHOTOGRAMME, V42, P393, DOI [10.5194/isprsarchivesXLII-2-W17-393-2019, DOI 10.5194/ISPRSARCHIVESXLII-2-W17-393-2019]
   Xi M, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-9
   Xiao-han Lu, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P339, DOI 10.1109/ICME.2012.116
   Yan B, 2013, J VIS COMMUN IMAGE R, V24, P669, DOI 10.1016/j.jvcir.2012.04.006
   Yao C, 2014, IEEE T BROADCAST, V60, P394, DOI 10.1109/TBC.2014.2321671
   Zhu C, 2016, IEEE T BROADCAST, V62, P482, DOI 10.1109/TBC.2016.2550762
NR 55
TC 1
Z9 1
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103148
DI 10.1016/j.jvcir.2021.103148
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200003
DA 2024-07-18
ER

PT J
AU Baisa, NL
AF Baisa, Nathanael L.
TI Robust online multi-target visual tracking using a HISP filter with
   discriminative deep appearance learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple target filtering; HISP filter; Online tracking; Appearance
   learning; CNN; MOT challenge
ID MULTIPLE-TARGET; ALGORITHM
AB We propose a novel online multi-target visual tracker based on the recently developed Hypothesized and Independent Stochastic Population (HISP) filter. The HISP filter combines advantages of traditional tracking approaches like MHT and point-process-based approaches like PHD filter, and it has linear complexity while maintaining track identities. We apply this filter for tracking multiple targets in video sequences acquired under varying environmental conditions and targets density using a tracking-by-detection approach. We also adopt deep CNN appearance representation by training a verification-identification network (VerIdNet) on large-scale person re-identification data sets. We construct an augmented likelihood in a principled manner using this deep CNN appearance features and spatio-temporal information. Furthermore, we solve the problem of two or more targets having identical label considering the weight propagated with each confirmed hypothesis. Extensive experiments on MOT16 and MOT17 benchmark data sets show that our tracker significantly outperforms several state-of-the-art trackers in terms of tracking accuracy.
C1 [Baisa, Nathanael L.] Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4WA, England.
C3 Lancaster University
RP Baisa, NL (corresponding author), Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4WA, England.
EM nathanaellmss@gmail.com
CR [Anonymous], 2017, 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)
   [Anonymous], 2016, EUROPEAN C COMPUTER
   [Anonymous], 2014, ARXIV14097618
   Vo BN, 2017, IEEE T SIGNAL PROCES, V65, P1975, DOI 10.1109/TSP.2016.2641392
   Vo BN, 2014, IEEE T SIGNAL PROCES, V62, P6554, DOI 10.1109/TSP.2014.2364014
   Baisa N.L, 2018, THESIS HERIOT WATT U
   Baisa NL, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019), DOI 10.23919/fusion43075.2019.9011441
   Baisa NL, 2019, DIGIT SIGNAL PROCESS, V89, P49, DOI 10.1016/j.dsp.2019.03.005
   Baisa NL, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P429, DOI 10.5220/0006564504290438
   Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026
   Baisa NL, 2018, J VIS COMMUN IMAGE R, V55, P464, DOI 10.1016/j.jvcir.2018.06.027
   Bar-Shalom Y., 2011, Tracking and Data Fusion: A Handbook of Algorithms
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Borah A., 2017, Poly-lactic-co-glycolic acid Nanoformulation of Small Molecule Antagonist GANT61 for Cancer Annihilation, P1, DOI DOI 10.1109/AVSS.2017.8078481
   BOURGEOIS F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945
   Chu P., 2019, ABS190208231 CORR
   Delande E, 2019, ADV SPACE RES, V64, P645, DOI 10.1016/j.asr.2019.04.012
   Delande E, 2016, ARXIV150104671V2
   Delande E, 2017, 27 AAS AIAA SPAC FLI
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Eiselein V, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P325, DOI 10.1109/AVSS.2012.59
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu ZY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4299, DOI 10.1109/ICASSP.2018.8461946
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Houssineau J, 2018, IEEE T SIGNAL PROCES, V66, P4957, DOI 10.1109/TSP.2018.2863672
   Houssineau J, 2015, EUR SIGNAL PR CONF, P1251, DOI 10.1109/EUSIPCO.2015.7362584
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kim DY, 2017, INT CONF CONTR AUTO, P181, DOI 10.1109/ICCAIS.2017.8217572
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Lee S, 2019, IEEE ACCESS, V7, P8181, DOI 10.1109/ACCESS.2018.2889442
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu QK, 2019, IEEE ACCESS, V7, P76489, DOI 10.1109/ACCESS.2019.2921975
   Mahler R., 2014, ADV STAT MULTISOURCE
   Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119
   Maksai A, 2019, PROC CVPR IEEE, P4634, DOI 10.1109/CVPR.2019.00477
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Milan A., 2016, ARXIV160300831
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi SH, 2015, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2015.349
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Song Guanglu, 2017, ARXIV171108766
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Sun Y, 2014, PROC CVPR IEEE
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vo B.-N., 2015, Wiley encyclopedia of electrical and electronics engineering
   Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wei L., 2017, ABS171108565 CORR
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
NR 66
TC 8
Z9 10
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 102952
DI 10.1016/j.jvcir.2020.102952
EA MAY 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qin, C
   Zhang, YZ
   Liu, YD
   Lv, GH
AF Qin, Cao
   Zhang, Yunzhou
   Liu, Yingda
   Lv, Guanghao
TI Semantic loop closure detection based on graph matching in multi-objects
   scenes?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Loop closure detection; Object detection; Semantic; Simultaneous
   localization and mapping (SLAM); Graph matching
ID LOCALIZATION; SLAM; RECOGNITION; SCALE; TIME
AB Robust loop-closure detection is essential for visual SLAM. Traditional methods often focus on the geometric and visual features in most scenes but ignore the semantic information provided by objects. Based on this consideration, we present a strategy that models the visual scene as semantic sub-graph by only preserving the semantic and geometric information from object detection. To align two sub-graphs efficiently, we use a sparse Kuhn?Munkres algorithm to speed up the search for correspondence among nodes. The shape similarity and the Euclidean distance between objects in the 3-D space are leveraged unitedly to measure the image similarity through graph matching. Furthermore, the proposed approach has been analyzed and compared with the state-of-the-art algorithms at several datasets as well as two indoor real scenes, where the results indicate that our semantic graph-based representation without extracting visual features is feasible for loop-closure detection at potential and competitive precision.
C1 [Qin, Cao; Zhang, Yunzhou; Liu, Yingda; Lv, Guanghao] Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Peoples R China.
C3 Northeastern University - China
RP Zhang, YZ (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Peoples R China.
EM zhangyunzhou@mail.neu.edu.cn
FU Open Fundation of Zhijiang Laboratory, China [2019KD0AD01/006]; National
   Natural Science Foundation of China [61973066, 61471110]; Fundation of
   Key Laboratory of Aerospace System Simulation, China [61420020301];
   Fundamental Research Funds for the Central Universities, China
   [N182608004, N2004022]; Distinguished Creative Talent Program of
   Liaoning Colleges and Universities, China [LR2019027]
FX Supported by Open Fundation of Zhijiang Laboratory, China (No.
   2019KD0AD01/006) , National Natural Science Foundation of China (No.
   61973066, 61471110) , Fundation of Key Laboratory of Aerospace System
   Simulation, China (61420020301) , Fundamental Research Funds for the
   Central Universities, China (N182608004, N2004022) and Distinguished
   Creative Talent Program of Liaoning Colleges and Universities, China
   (LR2019027) .
CR [Anonymous], 2015, P ICRA WORKSH VIS PL
   Arandjelovic R., 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Cascianelli S, 2017, ROBOT AUTON SYST, V92, P53, DOI 10.1016/j.robot.2017.03.004
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Civera J, 2011, IEEE INT C INT ROBOT, P1277, DOI 10.1109/IROS.2011.6048293
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Drouilly R, 2014, IEEE INT C INT ROBOT, P1839, DOI 10.1109/IROS.2014.6942804
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921
   Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2
   Garg S., 2018, 2018 IEEE International Conference on Communications (ICC), P1, DOI [10.1109/ATSIP.2018.8364481, DOI 10.1109/ATSIP.2018.8364481]
   Garg S, 2022, INT J ROBOT RES, V41, P573, DOI 10.1177/0278364919839761
   Garg S, 2019, IEEE INT CONF ROBOT, P4916, DOI [10.1109/ICRA.2019.8794178, 10.1109/icra.2019.8794178]
   Gawel Abel, 2018, IEEE Robotics and Automation Letters, V3, P1687, DOI 10.1109/LRA.2018.2801879
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glocker B, 2013, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2013.6671777
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, V25, P1097
   Labbé M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910
   Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0_15
   Liu Y, 2019, IEEE INT CONF ROBOT, P4909, DOI [10.1109/ICRA.2019.8794475, 10.1109/icra.2019.8794475]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   McCormac J, 2018, INT CONF 3D VISION, P32, DOI 10.1109/3DV.2018.00015
   Merrill N., 2018, ROBOTICS SCI SYSTEMS
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623
   Mousavian A, 2015, IEEE INT CONF ROBOT, P4882, DOI 10.1109/ICRA.2015.7139877
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Munoz-Salinas R., 2017, DBOW3 DBOW3
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Murillo A. C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305
   Nicholson L, 2019, IEEE ROBOT AUTOM LET, V4, P1, DOI 10.1109/LRA.2018.2866205
   Oh JH, 2015, ELECTRON LETT, V51, P44, DOI 10.1049/el.2014.3996
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Rosinol A, 2020, IEEE INT CONF ROBOT, P1689, DOI [10.1109/icra40945.2020.9196885, 10.1109/ICRA40945.2020.9196885]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Schönberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721
   Segvic S., 2013, ARXIV PREPRINT ARXIV
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Stückler J, 2015, J REAL-TIME IMAGE PR, V10, P599, DOI 10.1007/s11554-013-0379-5
   Stumm E, 2016, PROC CVPR IEEE, P4535, DOI 10.1109/CVPR.2016.491
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sünderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986
   Sünderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Wu YM, 2020, IEEE INT C INT ROBOT, P4966, DOI 10.1109/IROS45743.2020.9341757
   Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 61
TC 20
Z9 21
U1 4
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103072
DI 10.1016/j.jvcir.2021.103072
EA MAR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700004
DA 2024-07-18
ER

PT J
AU Weng, SW
   Zhang, CY
   Zhang, TC
   Chen, KM
AF Weng, Shaowei
   Zhang, Caiying
   Zhang, Tiancong
   Chen, Kaimeng
TI High capacity reversible data hiding in encrypted images using SIBRW and
   GCC *
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; SIBRW; GCC; Image recovery;
   Embedding performance
AB In this paper, a reversible data hiding in encrypted images (RDHEI) method combining GCC (group classification encoding) and SIBRW containing sixteen image-based rearrangement ways is proposed to achieve high-capacity data embedding in encrypted images. Each way of SIBRW aims at bringing strongly-correlated bits of each higher bit-plane together by rearranging each higher bit-plane. For each higher bit-plane, the optimal way achieving the most concentrated aggregation performance is selected from SIBRW to rearrange this bit-plane, and then, GCC compresses the rearranged bit-plane in group-by-group manner. By making full use of strong-correlation between adjacent groups, GCC can compress not only consecutive several groups whose bits are valued 1 (or 0) but also a single group so that a large embedding space is provided. The encryption method including the bit-level XORencryption and scrambling operations enhances the security. The experimental results show that the proposed scheme can achieve large embedding capacity and high security.
C1 [Weng, Shaowei; Zhang, Caiying] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Weng, Shaowei; Zhang, Tiancong] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
   [Chen, Kaimeng] Jimei Univ, Comp Engn Coll, Xiamen 361021, Peoples R China.
C3 Guangdong University of Technology; Fujian University of Technology;
   Jimei University
RP Zhang, TC (corresponding author), Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
EM 2445433848@qq.com; chenkaimeng@jmu.edu.cn
RI tian'cong, zhang/IQU-9892-2023
OI tian'cong, zhang/0000-0002-5343-6233
FU National NSF of China [61872095, 61571139, 61872128]; International
   Scientific and Technological Cooperation of Guangdong Province
   [2019A050513012]; Open Project Program of Shenzhen Key Laboratory of
   Media Security [ML201803]; Fujian Science Fund for Distinguished Young
   Scholars [2020J06043]
FX This work was supported in part by the National NSF of China under Grant
   61872095, Grant 61571139, Grant 61872128, in part by International
   Scientific and Technological Cooperation of Guangdong Province under
   Grant 2019A050513012, in part by the Open Project Program of Shenzhen
   Key Laboratory of Media Security under Grant ML201803, in part by Fujian
   Science Fund for Distinguished Young Scholars under Grant 2020J06043.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Bas P., P 13 INR C INF, P59
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Computer vision group, 2002, TEST IMAGE DATABASE
   De Vleeschouwer C, 2002, P IEEE, V90, P64, DOI 10.1109/5.982406
   Feng Deng-Guo, 2011, Journal of Software, V22, P71, DOI 10.3724/SP.J.1001.2011.03958
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Strauss O., 2008, P SPIE INT SOC OPT E, V6819
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2016, J VIS COMMUN IMAGE R, V35, P25, DOI 10.1016/j.jvcir.2015.11.005
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Xiang S.J., 2018, IEEE T CIRC SYST VID, P1
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
NR 38
TC 18
Z9 20
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 102932
DI 10.1016/j.jvcir.2020.102932
EA FEB 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BX
UT WOS:000633494400003
DA 2024-07-18
ER

PT J
AU Tang, QF
   Yang, J
   Liu, HB
   Guo, ZQ
   Jia, WJ
AF Tang, Qunfang
   Yang, Jie
   Liu, Haibo
   Guo, Zhiqiang
   Jia, Wenjing
TI Single image deraining using Context Aggregation Recurrent Network?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deraining; Context awareness; Dilated convolution; Recurrent
   network; Perceptual loss
ID RAIN
AB Single image deraining is a challenging problem due to the presence of non-uniform rain densities and the ill-posedness of the problem. Moreover, over-/under-deraining can directly impact the performance of vision systems. To address these issues, we propose an end-to-end Context Aggregation Recurrent Network, called CARNet, to remove rain streaks from single images. In this paper, we assume that a rainy image is the linear combination of a clean background image with rain streaks and propose to take advantage of the context information and feature reuse to learn the rain streaks. In our proposed network, we first use the dilation technique to effectively aggregate context information without sacrificing the spatial resolution, and then leverage a gated subnetwork to fuse the intermediate features from different levels. To better learn and reuse rain streaks, we integrate a LSTM module to connect different recurrences for passing the information learned from the previous stages about the rain streaks to the following stage. Finally, to further refine the coarsely derained image, we introduce a refinement module to better preserve image details. As for the loss function, the L1-norm perceptual loss and SSIM loss are adopted to reduce the gridding artifacts caused by the dilated convolution. Experiments conducted on synthetic and real rainy images show that our CARNet achieves superior deraining performance both qualitatively and quantitatively over the state-of-the-art approaches.
C1 [Tang, Qunfang; Yang, Jie; Guo, Zhiqiang] Wuhan Univ Technol, Hubei Key Lab Broadband Wireless Commun & Sensor, Wuhan, Peoples R China.
   [Tang, Qunfang; Liu, Haibo] Hunan Inst Technol, Sch Elect Informat Engn, Hengyang, Peoples R China.
   [Jia, Wenjing] Univ Technol Sydney, Global Big Data Technol Ctr GBDTC, Ultimo, Australia.
C3 Wuhan University of Technology; Hunan Institute of Technology;
   University of Technology Sydney
RP Yang, J (corresponding author), Wuhan Univ Technol, Hubei Key Lab Broadband Wireless Commun & Sensor, Wuhan, Peoples R China.
EM jieyang509@163.com
RI Jia, Weijia/W-6152-2019; Yang, Jie/JCD-9867-2023
OI Jia, Wenjing/0000-0002-0940-3338; Tang, Qunfang/0000-0001-8164-3662
FU National Natural Science Foundation of China [51879211]; Hunan
   Provincial Natural Science Foundation of China [2017JJ3053]; Hunan
   Provincial Science Research Project of China [17A051]
FX This work was supported by National Natural Science Foundation of China
   (No. 51879211), Hunan Provincial Natural Science Foundation of China
   (No. 2017JJ3053), and Hunan Provincial Science Research Project of China
   (Nos. 17A051).
CR [Anonymous], 2018, ARXIV181107387
   [Anonymous], 1997, NEURAL COMPUT
   Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   De-An Huang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P164, DOI 10.1109/ICME.2012.92
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Du YJ, 2020, IEEE WINT CONF APPL, P2395, DOI 10.1109/WACV45572.2020.9093393
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Lan Y, 2020, IEEE ACCESS, V8, P30615, DOI 10.1109/ACCESS.2020.2972909
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Paszke Adam, 2017, NIPS 2017 WORKSH AUT
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santhaseelan V, 2015, INT J COMPUT VISION, V112, P71, DOI 10.1007/s11263-014-0759-8
   Shen C., 2016, ARXIV PREPRINT ARXIV, V2
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang GQ, 2019, IEEE I CONF COMP VIS, P5643, DOI 10.1109/ICCV.2019.00574
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei W, 2019, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2019.00400
   Xiang P, 2019, IEEE SIGNAL PROC LET, V26, P650, DOI 10.1109/LSP.2019.2903874
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yasarla R, 2020, PROC CVPR IEEE, P2723, DOI 10.1109/CVPR42600.2020.00280
   You S, 2016, IEEE T PATTERN ANAL, V38, P1721, DOI 10.1109/TPAMI.2015.2491937
   Zhang H., 2016, THESIS CHINA XIAN SH
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang H, 2017, IEEE WINT CONF APPL, P1259, DOI 10.1109/WACV.2017.145
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 48
TC 2
Z9 2
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103039
DI 10.1016/j.jvcir.2021.103039
EA FEB 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BY
UT WOS:000633494500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Banitalebi-Dehkordi, M
   Ebrahimi-Moghadam, A
   Khademi, M
   Hadizadeh, H
AF Banitalebi-Dehkordi, Mehdi
   Ebrahimi-Moghadam, Abbas
   Khademi, Morteza
   Hadizadeh, Hadi
TI No-reference quality assessment of HEVC video streams based on visual
   memory modelling *
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No-Reference Video Quality; Visual Memory; Saliency Detection;
   Bitstream; HEVC
ID SALIENCY DETECTION MODEL; COMPRESSION; ATTENTION; PERFORMANCE; METRICS;
   IMAGE
AB Providing adequate Quality of Experience (QoE) to end-users is crucial for streaming service providers. In this paper, in order to realize automatic quality assessment, a No-Reference (NR) bitstream Human-Vision-System(HVS)-based video quality assessment (VQA) model is proposed. Inspired by discoveries from the neuroscience community, which suggest there is a considerable overlap between active areas of the brain when engaging in video quality assessment and saliency detection tasks, saliency maps are used in the proposed method to improve the quality assessment accuracy. To this end, saliency maps are first generated from features extracted from the HEVC bitstream. Then, saliency map statistics are employed to create a model of visual memory. Finally, a support vector regression pipeline learns an estimate of the video quality from the visual memory, saliency, and frame features. Evaluations on SJTU dataset indicate that the proposed bitstream based no reference video quality assessment algorithm achieves a competitive performance.
C1 [Banitalebi-Dehkordi, Mehdi; Ebrahimi-Moghadam, Abbas; Khademi, Morteza] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
   [Hadizadeh, Hadi] Quchan Univ Technol, Dept Elect Engn, Quchan, Iran.
C3 Ferdowsi University Mashhad
RP Ebrahimi-Moghadam, A (corresponding author), Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
EM mehdi.banitalebidehkordi@mail.um.ac.ir; a.ebrahimi@um.ac.ir;
   khademi@um.ac.ir; h.hadizadeh@qiet.ac.ir
OI Ebrahimi-Moghadam, Abbas/0000-0002-3921-9814
CR Akamine WYL, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.061107
   Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   [Anonymous], 2004, P ITU T 145 RECOMMEN
   [Anonymous], 1886, Mind, DOI [DOI 10.1037/11304-037, DOI 10.1093/MIND/OS-XI.41.63]
   [Anonymous], 2005, JMP BASIC UNIVARIATE
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Banitalebi-Dehkordi A., 2018, ARXIV PREPRINT ARXIV
   Banitalebi-Dehkordi A, 2017, MULTIMED TOOLS APPL, V76, P23859, DOI 10.1007/s11042-016-4155-y
   Banitalebi-Dehkordi A, 2016, MULTIMED TOOLS APPL, V75, P4187, DOI 10.1007/s11042-015-2466-z
   Banitalebi-Dehkordi Mehdi, 2019, IEEE T BROADCAST, V1, P1
   Bird CM, 2008, NAT REV NEUROSCI, V9, P182, DOI 10.1038/nrn2335
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   China Video Service User Experience Standard Working Group, 2017, DROP
   Chun MM, 2007, CURR OPIN NEUROBIOL, V17, P177, DOI 10.1016/j.conb.2007.03.005
   Coverdale P, 2011, IEEE SIGNAL PROC MAG, V28, P91, DOI 10.1109/MSP.2011.942467
   Currie J, 2018, IEEE T HUM-MACH SYST, V48, P113, DOI 10.1109/THMS.2017.2754880
   Desimone R, 1996, P NATL ACAD SCI USA, V93, P13494, DOI 10.1073/pnas.93.24.13494
   Eichenbaum H, 2007, ANNU REV NEUROSCI, V30, P123, DOI 10.1146/annurev.neuro.30.051606.094328
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Feng X, 2011, IEEE T BROADCAST, V57, P81, DOI 10.1109/TBC.2010.2092150
   Fine MS, 2009, J NEUROSCI, V29, P8016, DOI 10.1523/JNEUROSCI.5503-08.2009
   Ghadiyaram D, 2017, IEEE IMAGE PROC, P3445, DOI 10.1109/ICIP.2017.8296922
   Gotz-Hahn F., 2020, ARXIV PREPRINT ARXIV
   Gunawan IP, 2008, IEEE T BROADCAST, V54, P669, DOI 10.1109/TBC.2008.2000734
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hands DS, 2001, APPL COGNITIVE PSYCH, V15, P639, DOI 10.1002/acp.731
   He T, 2018, 2018 INT WORKSH PATT, P1, DOI [DOI 10.1109/PRNI.2018.8423958, 10.1109/PRNI.2018.8423958]
   Hong WH, 2018, IEEE SIGNAL PROC LET, V25, P214, DOI 10.1109/LSP.2017.2780285
   Hooper D.F, GOOGLE PATENTS
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jiang L., 2020, VIDEO EYE TRACKING D
   Joskowicz J., 2011, P 6 LATIN AM NETWORK, P4, DOI DOI 10.1145/2078216.2078218
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Kaldy Z, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00001
   Katayama T., 2018, IEEJ T ELECT INF SYS, V138, P1185
   KAUFMAN EL, 1949, AM J PSYCHOL, V62, P498, DOI 10.2307/1418556
   Khatoonabadi SH, 2015, PROC CVPR IEEE, P5501, DOI 10.1109/CVPR.2015.7299189
   Kremkow J, 2014, P NATL ACAD SCI USA, V111, P3170, DOI 10.1073/pnas.1310442111
   Lab S.M., 2016, SJTU 4K HEVC VID SUB
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Lin XY, 2012, IEEE T CONSUM ELECTR, V58, P505, DOI 10.1109/TCE.2012.6227454
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Ngau CWH, 2012, IET WIREL SENS SYST, V2, P115, DOI 10.1049/iet-wss.2011.0038
   Park J, 2013, IEEE T IMAGE PROCESS, V22, P610, DOI 10.1109/TIP.2012.2219551
   Park J, 2011, IEEE IMAGE PROC
   Postle BR, 2015, CURR OPIN BEHAV SCI, V1, P40, DOI 10.1016/j.cobeha.2014.08.004
   Raake A., 2017, 2017 9 INT C QUALITY, P1, DOI DOI 10.1109/QOMEX.2017.7965631
   Ries Michal, 2008, Journal of Communications, V3, P41, DOI 10.4304/jcm.3.1.41-50
   Rodriguez J, 2015, Fundamentals of 5G Mobile Networks, P1, DOI 10.1002/9781118867464
   Santangelo V, 2013, J NEUROSCI, V33, P4110, DOI 10.1523/JNEUROSCI.4138-12.2013
   Scharstein D., 1999, View Synthesis Using Stereo Vision
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Smith J.D., 2004, Google Patents
   Song L, 2013, INT WORK QUAL MULTIM, P34, DOI 10.1109/QoMEX.2013.6603201
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   SULLIVAN GJ, 1994, IEEE T IMAGE PROCESS, V3, P327, DOI 10.1109/83.287030
   Takagi M, 2013, PICT COD SYMP, P422, DOI 10.1109/PCS.2013.6737773
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Tian SS, 2018, IEEE T IMAGE PROCESS, V27, P1652, DOI 10.1109/TIP.2017.2781420
   Tutorials S., 2014, PEARSON CORRELATION, V4
   Vu C., 2013, GOOGLE PATENTS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu M, 2017, IEEE T IMAGE PROCESS, V26, P369, DOI 10.1109/TIP.2016.2628583
   Yamawaki K, 2009, PROG THEOR PHYS SUPP, P1, DOI 10.1143/PTPS.180.1
   Yang FZ, 2012, IEEE COMMUN MAG, V50, P203, DOI 10.1109/MCOM.2012.6353702
   Yang JC, 2018, IEEE T BROADCAST, V64, P341, DOI 10.1109/TBC.2018.2789583
   Yang YZ, 2010, LECT NOTES COMPUT SC, V6315, P631, DOI 10.1007/978-3-642-15555-0_46
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P1275, DOI 10.1109/TIP.2017.2651410
   Zhang W, 2016, IEEE T NEUR NET LEAR, V27, P1266, DOI 10.1109/TNNLS.2015.2461603
   Zhao W, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P523, DOI 10.1109/IAEAC.2015.7428608
NR 78
TC 2
Z9 4
U1 2
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103011
DI 10.1016/j.jvcir.2020.103011
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BX
UT WOS:000633494400004
DA 2024-07-18
ER

PT J
AU Wang, YF
   Ye, P
   Xia, YM
   An, P
AF Wang, Yongfang
   Ye, Peng
   Xia, Yumeng
   An, Ping
TI A heuristic framework for perceptual saliency prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency prediction; Orientation selectivity; Visual acuity; Visual
   error sensitivity; Free energy principle
ID BINOCULAR INTERACTION; VISUAL SALIENCY; SELECTIVITY
AB Saliency prediction can be regarded as the human spontaneous activity. The most effective saliency model should highly approximate the response of viewers to the perceived information. In the paper, we exploit the perception response for saliency detection and propose a heuristic framework to predict salient region. First, to find the perceptually meaningful salient regions, an orientation selectivity based local feature and a visual Acuity based global feature are proposed to jointly predict candidate salient regions. Subsequently, to further boost the accuracy of saliency map, we introduce a visual error sensitivity based operator to activate the meaningful salient regions from a local and global perspective. In addition, an adaptive fusion method based on free energy principle is designed to combine the sub-saliency maps from each image channel to obtain the final saliency map. Experimental results on five natural and emotional datasets demonstrate the superiority of the proposed method compared to twelve state-of-the-art algorithms.
C1 [Wang, Yongfang; An, Ping] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wang, Yongfang; Ye, Peng; Xia, Yumeng; An, Ping] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Wang, YF (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM yfw@shu.edu.cn
RI xin, liang/JFS-5770-2023; Cheng, Yuan/JKJ-0794-2023; cheng,
   cheng/JBR-8359-2023
FU Natural Science Foundation of China [61671283, 61301113]
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61671283, 61301113.
CR Aboudib A, 2015, INT CONF ACOUST SPEE, P1493, DOI 10.1109/ICASSP.2015.7178219
   Attias H, 2000, ADV NEUR IN, V12, P209
   BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32, DOI 10.1523/jneurosci.02-01-00032.1982
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Bruce N., 2010, Journal of Vision, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005
   CAMPBELL FW, 1966, J PHYSIOL-LONDON, V187, P437, DOI 10.1113/jphysiol.1966.sp008101
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Chen JZ, 2019, J VIS COMMUN IMAGE R, V60, P149, DOI 10.1016/j.jvcir.2019.02.026
   Chen JZ, 2017, NEUROCOMPUTING, V251, P16, DOI 10.1016/j.neucom.2017.04.020
   Chen TL, 1996, COLOR RES APPL, V21, P18, DOI 10.1002/(SICI)1520-6378(199602)21:1<18::AID-COL2>3.0.CO;2-8
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2015, IEEE SIGNAL PROC LET, V22, P1552, DOI 10.1109/LSP.2015.2413944
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Huang K, 2018, IEEE SIGNAL PROC LET, V25, P1059, DOI 10.1109/LSP.2018.2830755
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li J, 2014, INT J COMPUT VISION, V107, P239, DOI 10.1007/s11263-013-0678-0
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023025
   Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132
   Lu HC, 2017, IEEE T IMAGE PROCESS, V26, P414, DOI 10.1109/TIP.2016.2627804
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Shang XW, 2013, IEEE IMAGE PROC, P1914, DOI 10.1109/ICIP.2013.6738394
   Tavakoli HR, 2017, LECT NOTES COMPUT SC, V10116, P287, DOI 10.1007/978-3-319-54407-6_19
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Troyer TW, 1998, J NEUROSCI, V18, P5908
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   Wolfe JM, 2011, TRENDS COGN SCI, V15, P77, DOI 10.1016/j.tics.2010.12.001
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Wu JJ, 2015, IEEE T IMAGE PROCESS, V24, P4602, DOI 10.1109/TIP.2015.2460467
   Yang KF, 2016, IEEE T IMAGE PROCESS, V25, P3475, DOI 10.1109/TIP.2016.2572600
   Yantis S, 2005, NAT NEUROSCI, V8, P975, DOI 10.1038/nn0805-975
   Zhai G., 2019, ARXIV PREPRINT ARXIV
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 58
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102913
DI 10.1016/j.jvcir.2020.102913
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200003
DA 2024-07-18
ER

PT J
AU Kim, JW
   Ryu, JH
   Kim, JO
AF Kim, Jae-Woo
   Ryu, Je-Ho
   Kim, Jong-Ok
TI Deep gradual flash fusion for low-light enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Flash fusion; Pseudo multi-exposure; Auto-encoder; GAN;
   Low light enhancement
ID EXPOSURE IMAGE FUSION; NEURAL-NETWORK; PHOTOGRAPHY
AB In this paper, we propose gradual flash fusion, a new imaging concept that enables acquisition of pseudo multi-exposure images in a passive manner. This means that our gradual flash capture does not require any user-side manipulation (taking multiple shots or varying camera settings). Continuous high-speed capture naturally contains different intensities of flash in a single shooting. The captured gradual flash images, containing different information of the same scene, are fused to generate higher-quality images, especially in a low light scenario. For gradual flash fusion, we use a Generative Adversarial Network (GAN) based approach, where the generator is a tailored convolutional Auto-Encoder for image fusion. For the training, we build a custom dataset comprising gradual flash images and corresponding ground truths. This enables supervised learning, unlike most conventional image fusion studies. Experimental results demonstrate that gradual flash fusion achieves artifact-free and noise-free results resembling ground truth, owing to supervised adversarial fusion.
C1 [Kim, Jae-Woo; Ryu, Je-Ho; Kim, Jong-Ok] Korea Univ, Sch Elect Engn, 145 Anam Ro, Seoul, South Korea.
C3 Korea University
RP Kim, JO (corresponding author), Korea Univ, Sch Elect Engn, 145 Anam Ro, Seoul, South Korea.
EM lxraptx@korea.ac.kr; herosky6@korea.ac.kr; jokim@korea.ac.kr
RI KIM, MINJI/IXD-7702-2023
FU National Research Foundation of Korea (NRF), Ministry of Science and ICT
   (MSIT), South Korea - Korea Government [2019R1A2 C1005834]; MSIT
   (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program by the IITP (Institute of
   Information & Communications Technology Planning Evaluation)
   [IITP2020-0-01749]
FX This work was partially supported by the National Research Foundation of
   Korea (NRF), Ministry of Science and ICT (MSIT), South Korea, funded by
   the Korea Government, under Grant 2019R1A2 C1005834 and partially by the
   MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program (IITP2020-0-01749)
   supervised by the IITP (Institute of Information & Communications
   Technology Planning & Evaluation).
CR Adelsberger Rolf., 2008, Spatially adaptive photographic flash
   Agrawal A, 2005, ACM T GRAPHIC, V24, P828, DOI 10.1145/1073204.1073269
   Baba Tatsuya, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1185, DOI 10.1109/ICASSP.2014.6853784
   Bouzaraa F., 2018, ARXIV180401611
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Farneback G., 2003, Two-frame motion estimation based on polynomial expansion
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hae Jong Seo, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1324, DOI 10.1109/ICCVW.2011.6130405
   Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254
   He SF, 2014, LECT NOTES COMPUT SC, V8691, P110, DOI 10.1007/978-3-319-10578-9_8
   Hui Zhuo, 2017, CORR
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402
   Kumar J, 2014, IEEE IMAGE PROC, P5871, DOI 10.1109/ICIP.2014.7026186
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li H, 2018, IEEE IMAGE PROC, P1723, DOI 10.1109/ICIP.2018.8451689
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Liu QG, 2019, INFORM FUSION, V46, P114, DOI 10.1016/j.inffus.2018.05.007
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Lu C., 2006, P IS T CIC SCOTTSD A, V2006, P84
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Marnerides D, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13340
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Miao X., 2005, P IEEE ICIP, V2, pII
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Sakakibara N, 2018, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2018.00670
   Samain E., 2015, 2015 IEEE International Conference on Space Optical Systems and Applications (ICSOS), P1, DOI 10.1109/ICSOS.2015.7425085
   Saxena A, 2007, IEEE I CONF COMP VIS, P1
   Seo HJ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-3
   Sharma A, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P768, DOI 10.1109/SPIN.2015.7095419
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Shirai K., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3437, DOI 10.1109/ICIP.2011.6116451
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954
   Tursun OT, 2015, COMPUT GRAPH FORUM, V34, P683, DOI 10.1111/cgf.12593
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Zhuo SJ, 2010, PROC CVPR IEEE, P2440, DOI 10.1109/CVPR.2010.5539941
NR 47
TC 5
Z9 5
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102903
DI 10.1016/j.jvcir.2020.102903
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400015
DA 2024-07-18
ER

PT J
AU Li, P
   Ma, JF
   Ma, Q
AF Li, Peng
   Ma, Jianfeng
   Ma, Quan
TI (<i>t</i>, <i>k</i>, <i>n</i>) XOR-based visual cryptography scheme with
   essential shadows
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE XOR operation; Essential participants; Visual cryptography; Secret image
   sharing
ID IMAGE SHARING SCHEME; CONSTRUCTION; SIZE
AB Visual cryptography scheme (VCS) shares a binary secret image into multiple shadows, only qualified set of shadows can reveal the secret image by stacking operation. However, VCS suffers the problems of low visual quality of the revealed image and large shadow size. A (t, k, n) XOR-based visual cryptography scheme (XVCS) shares the secret image into n shadows including t essentials and n-t non-essentials. A qualified set of shadows contains any k shadows including t essentials. The revealing process is implemented by XOR operation on the involved shadows. In this paper, we propose a construction method for (t, k, n)-XVCS with essential shadows. The secret image can be revealed perfectly, and the shadow size is small compared with VCS. Theoretical analysis and experimental results show the security and effectiveness of the proposed scheme.
C1 [Li, Peng; Ma, Jianfeng] North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei, Peoples R China.
   [Ma, Quan] Nucl Power Inst China, Sci & Technol Reactor Syst Design Technol Lab, Chengdu 610213, Peoples R China.
C3 North China Electric Power University
RP Li, P (corresponding author), North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei, Peoples R China.
EM lphit@163.com
RI Ma, Jianfeng/GZB-0110-2022
FU National Natural Science Foundation of China [61602173]; Natural Science
   Foundation of Hebei Province [F2019502173]; Fundamental Research Funds
   for Central Universities [2019M5116]
FX We would like to thank the anonymous reviewers for their important and
   helpful comments. This work was supported by the National Natural
   Science Foundation of China (No. 61602173), Natural Science Foundation
   of Hebei Province (No. F2019502173) and the Fundamental Research Funds
   for Central Universities (No. 2019M5116).
CR Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Chao HC, 2018, MULTIMED TOOLS APPL, V77, P11867, DOI 10.1007/s11042-017-4836-1
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Guo T, 2014, LECT NOTES COMPUT SC, V8317, P56, DOI 10.1007/978-3-319-04268-8_4
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Li P, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8050838
   Li P, 2020, IEEE ACCESS, V8, P32840, DOI 10.1109/ACCESS.2020.2973659
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1380, DOI 10.1016/j.jvcir.2013.09.010
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Liu Y, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3145479
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wu XT, 2019, J VIS COMMUN IMAGE R, V61, P74, DOI 10.1016/j.jvcir.2019.03.020
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Yang CN, 2008, PATTERN RECOGN, V41, P3114, DOI 10.1016/j.patcog.2008.03.031
   Yang CN, 2015, INFORM SCIENCES, V312, P131, DOI 10.1016/j.ins.2015.03.024
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2013, PERS UBIQUIT COMPUT, V17, P843, DOI 10.1007/s00779-012-0535-0
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 27
TC 13
Z9 13
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102911
DI 10.1016/j.jvcir.2020.102911
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400020
DA 2024-07-18
ER

PT J
AU Ma, QL
   Zou, Q
   Wang, N
   Guan, QJ
   Pei, YT
AF Ma, Qiulin
   Zou, Qi
   Wang, Nan
   Guan, Qingji
   Pei, Yanting
TI Looking ahead: Joint small group detection and tracking in crowd scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Group tracking; Delay decision; Joint optimization; Multiple hypothesis
   tracking
ID ACTIVITY RECOGNITION
AB Small group detection and tracking in crowd scenes are basis for high level crowd analysis tasks. However, it suffers from the ambiguities in generating proper groups and in handling dynamic changes of group configurations. In this paper, we propose a novel delay decision-making based method for addressing the above problems, motivated by the idea that these ambiguities can be solved using rich temporal context. Specifically, given individual detections, small group hypotheses are generated. Then candidate group hypotheses across consecutive frames and their potential associations are built in a tree. By seeking for the best non-conflicting subset from the hypothesis tree, small groups are determined and simultaneously their trajectories are got. So this framework is called joint detection and tracking. This joint framework reduces the ambiguities in small group decision and tracking by looking ahead for several frames. However, it results in the unmanageable solution space because the number of track hypotheses grows exponentially over time. To solve this problem, effective pruning strategies are developed, which can keep the solution space manageable and also improve the credibility of small groups. Experiments on public datasets demonstrate the effectiveness of our method. The method achieves the state-of-the-art performance even in noisy crowd scenes.
C1 [Ma, Qiulin; Zou, Qi; Wang, Nan; Guan, Qingji; Pei, Yanting] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
   [Guan, Qingji] Univ Technol Sydney, Ctr Artificial Intelligence, 15 Broadway, Sydnedy, NSW 2007, Australia.
C3 Beijing Jiaotong University; University of Technology Sydney
RP Zou, Q (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
EM qzou@bjtu.edu.cn
RI Li, Guo/JNR-1700-2023; Wang, Nan/ACI-4675-2022
OI Wang, Nan/0000-0001-5601-7838
FU National Natural Science Foundation of China [61473031, 61472029];
   Beijing Natural Science Foundation, China [4152042]
FX This work is supported by National Natural Science Foundation of China
   (61473031, 61472029) and Beijing Natural Science Foundation, China
   (4152042). We thank Xue Lin and Xixia Xu for their valuable suggestions
   on our manuscript.
CR Afiq AA, 2019, J VIS COMMUN IMAGE R, V58, P285, DOI 10.1016/j.jvcir.2018.11.035
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Arrow H., 2000, Small Groups as Complex Systems: Formation, Coordination, Development, and Adaptation, DOI 10.4135/9781452204666
   Bazzani L, 2015, IEEE T PATTERN ANAL, V37, P746, DOI 10.1109/TPAMI.2014.2353641
   Bazzani L, 2012, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2012.6247888
   Bazzani L, 2010, IEEE IMAGE PROC, P837, DOI 10.1109/ICIP.2010.5653463
   Busygin S, 2006, DISCRETE APPL MATH, V154, P2080, DOI 10.1016/j.dam.2005.04.010
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   Feldmann M, 2011, IEEE T SIGNAL PROCES, V59, P1409, DOI 10.1109/TSP.2010.2101064
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Forsyth DR, 2014, GROUP DYNAMICS IN EXERCISE AND SPORT PSYCHOLOGY, 2ND EDITION, pXXV
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Gao G, 2019, J DRUG TARGET, V27, P853, DOI 10.1080/1061186X.2018.1564924
   Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176
   Gennari G, 2004, PROC CVPR IEEE, P876
   Ghodsi S, 2018, J VIS COMMUN IMAGE R, V55, P729, DOI 10.1016/j.jvcir.2018.08.001
   Gilholm K, 2005, PROC SPIE, V5913, DOI 10.1117/12.618730
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Lau B, 2010, INT J SOC ROBOT, V2, P19, DOI 10.1007/s12369-009-0036-0
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Leal-Taixé L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130233
   Meditskos G, 2018, J VIS COMMUN IMAGE R, V51, P169, DOI 10.1016/j.jvcir.2018.01.009
   Milan A, 2013, IEEE COMPUT SOC CONF, P735, DOI 10.1109/CVPRW.2013.111
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Solera F, 2016, IEEE T PATTERN ANAL, V38, P995, DOI 10.1109/TPAMI.2015.2470658
   Su H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2772
   Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   Zhou BL, 2014, IEEE T PATTERN ANAL, V36, P1586, DOI 10.1109/TPAMI.2014.2300484
   Zhu F, 2014, ENERGY AND PROCESS OPTIMIZATION FOR THE PROCESS INDUSTRIES, P138
   Zou Q, 2018, IEEE T INTELL TRANSP, V19, P1950, DOI 10.1109/TITS.2017.2745683
NR 35
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102876
DI 10.1016/j.jvcir.2020.102876
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400006
DA 2024-07-18
ER

PT J
AU Barajas-Solano, C
   Ramirez, JM
   Arguello, H
AF Barajas-Solano, Crisostomo
   Ramirez, Juan-Marcos
   Arguello, Henry
TI Convolutional sparse coding framework for compressive spectral imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive spectral imaging; Convolutional sparse coding; Sparse
   representation; Spectral images
ID RECONSTRUCTION; ALGORITHMS; INVERSE; DESIGN
AB Spectral images (SI) can be represented as 3D-arrays of spatial information across multiple wavelengths. Compressive Spectral Imaging (CSI) reduces sensing costs by sensing compressed versions of the scene, recovering a suitable version of the original SI solving a sparsity-inducing inverse problem. On the other hand, Convolutional Sparse Coding (CSC) has been successfully proved for representing gray-scale images, however it misses any correlation between images. This work considers the spatial-spectral correlation within SIs introducing an extension of the CSC signal model describing the SI as the sum of convolutions of 3D sparse coefficient maps with their respective 3D dictionary filters. Furthermore, we use the proposed CSC framework for recovering SIs from CSI measurements. The simulations results, using two different CSI acquisition architectures, show that the proposed CSC framework yields better representations of the SIs than those obtained under the traditional sparse signal representation approach, improving the quality of the recovered Sls. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Barajas-Solano, Crisostomo] Univ Ind Santander, Dept Elect Engn, Bucaramanga, Santander, Colombia.
   [Ramirez, Juan-Marcos; Arguello, Henry] Univ Ind Santander, Dept Comp Sci, Bucaramanga, Santander, Colombia.
C3 Universidad Industrial de Santander; Universidad Industrial de Santander
RP Arguello, H (corresponding author), Univ Ind Santander, Dept Comp Sci, Bucaramanga, Santander, Colombia.
EM henarfu@uis.edu.co
RI Ramirez, Juan M/HJG-7498-2022; Ramirez, Juan/ABH-7334-2020
OI Ramirez, Juan/0000-0003-0000-1073
FU Colciencias scholarship [785]
FX Ph.D. (c) Crisostomo Barajas-Solano is supported by the Colciencias
   scholarship #785.
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Arce GR, 2014, IEEE SIGNAL PROC MAG, V31, P105, DOI 10.1109/MSP.2013.2278763
   Arguello H, 2013, APPL OPTICS, V52, pD12, DOI 10.1364/AO.52.000D12
   Bacca J, 2019, IEEE J-STARS, V12, P1231, DOI 10.1109/JSTARS.2019.2902332
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Bioucas-Dias JM, 2008, IEEE T GEOSCI REMOTE, V46, P2435, DOI 10.1109/TGRS.2008.918089
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bristow H, 2013, PROC CVPR IEEE, P391, DOI 10.1109/CVPR.2013.57
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Cao X, 2016, IEEE SIGNAL PROC MAG, V33, P95, DOI 10.1109/MSP.2016.2582378
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Correa CV, 2015, J OPT SOC AM A, V32, P1754, DOI 10.1364/JOSAA.32.001754
   Galvis L, 2017, APPL OPTICS, V56, P6332, DOI 10.1364/AO.56.006332
   Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013
   Gelvez T, 2017, APPL OPTICS, V56, P6785, DOI 10.1364/AO.56.006785
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   HENDERSON HV, 1981, SIAM REV, V23, P53, DOI 10.1137/1023004
   Karp B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P243, DOI 10.1145/345910.345953
   Liang HM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020099
   Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Martín G, 2015, IEEE T GEOSCI REMOTE, V53, P2819, DOI 10.1109/TGRS.2014.2365534
   Nishihara R, 2015, PR MACH LEARN RES, V37, P343
   Papyan V, 2018, IEEE SIGNAL PROC MAG, V35, P72, DOI 10.1109/MSP.2018.2820224
   Papyan V, 2017, IEEE T SIGNAL PROCES, V65, P5687, DOI 10.1109/TSP.2017.2733447
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   Shannon CE, 1998, P IEEE, V86, P447, DOI 10.1109/JPROC.1998.659497
   Shaw G. A., 2003, Lincoln Laboratory Journal, V14, P3
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tan J, 2016, IEEE J-STSP, V10, P389, DOI 10.1109/JSTSP.2015.2500190
   Vargas E, 2019, IEEE T GEOSCI REMOTE, V57, P5043, DOI 10.1109/TGRS.2019.2895822
   Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44
   Wang L, 2018, IEEE J-STARS, V11, P1266, DOI 10.1109/JSTARS.2017.2787483
   Weeks M, 1998, ISCAS '98 - PROCEEDINGS OF THE 1998 INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-6, pC57
   Wohlberg B, 2016, IEEE IMAGE PROC, P1833, DOI 10.1109/ICIP.2016.7532675
   Wohlberg B, 2016, IEEE SW SYMP IMAG, P57, DOI 10.1109/SSIAI.2016.7459174
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Yasuma F., 2008, TECH REP
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Yuan X, 2015, IEEE J-STSP, V9, P964, DOI 10.1109/JSTSP.2015.2411575
   Zhou Y, 2014, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2014.394
NR 45
TC 5
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102690
DI 10.1016/j.jvcir.2019.102690
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200002
DA 2024-07-18
ER

PT J
AU Guan, B
   Xu, DW
AF Guan, Bo
   Xu, Dawen
TI An efficient high-capacity reversible data hiding scheme for encrypted
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; Image security; MSB
   prediction; High capacity
ID WATERMARKING; EXPANSION; ALGORITHM
AB Reversible data hiding in encrypted images is an effective technique to embed information in encrypted domain, without knowing the original content of the image or the encryption key. In this paper, a high-capacity reversible data hiding scheme for encrypted images based on MSB (most significant bit) prediction is proposed. Since the prediction is not always accurate, it is necessary to identify the prediction error and store this information in the location map. The stream cipher is then used to encrypt the original image directly. During the data hiding phase, up to three MSBs of each available pixel in the encrypted image are substituted by the bits of the secret message. At the receiving end, the embedded data can be extracted without any errors and the original image can be perfectly reconstructed by utilizing MSB prediction. Experimental results show that the scheme can achieve higher embedding capacity than most related methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Guan, Bo; Xu, Dawen] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Peoples R China.
C3 Ningbo University of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Peoples R China.
EM dawenxu@126.com
RI xu, dawen/ABF-5343-2021
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [61771270]; Zhejiang
   Provincial Natural Science Foundation of China [LY17F020013,
   LR20F020001]; Ningbo Natural Science Foundation [2018A610054]
FX This work is supported by the National Natural Science Foundation of
   China (61771270), Zhejiang Provincial Natural Science Foundation of
   China (LY17F020013, LR20F020001), and Ningbo Natural Science Foundation
   (2018A610054).
CR [Anonymous], [No title captured]
   [Anonymous], 2018, BIOMED RES INT
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen B, 2019, SIGNAL PROCESS, V164, P48, DOI 10.1016/j.sigpro.2019.05.036
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Karim MSA, 2014, SIGNAL PROCESS, V94, P174, DOI 10.1016/j.sigpro.2013.06.014
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xu DW, 2017, J VIS COMMUN IMAGE R, V45, P34, DOI 10.1016/j.jvcir.2017.02.008
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 37
TC 14
Z9 18
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102744
DI 10.1016/j.jvcir.2019.102744
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200016
DA 2024-07-18
ER

PT J
AU Ji, C
   Huang, XB
   Cao, W
   Zhu, YC
   Zhang, Y
AF Ji, Chao
   Huang, Xinbo
   Cao, Wen
   Zhu, Yongcan
   Zhang, Ye
TI Saliency detection using Multi-layer graph ranking and combined neural
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Machine vision; Saliency detection; Past R-CNN; Region Net; Local-Global
   Net
ID OBJECT DETECTION
AB In this paper, a new algorithm based on a combined neural network is proposed to improve salient object detection in the complex images. It consists of two main steps. The first step, an objective function which is optimized on a multi-layer graph structure is constructed to diffuse saliency from borders to salient objects, aiming to roughly estimate the location and extent salient objects of an image, meanwhile, color attribute is adopted to rapidly find a set of object-related regions in the image. The second step, establish a combined neural network with Region Net and Local-Global Net. Region Net is adopted to efficiently generate the salient map with the sharp object boundary. Then Local-Global Net based on multi-scale spatial context is proposed to provide strongly reliable multi-scale contextual information, and thus achieves an optimized performance. Experimental results and comparison analysis demonstrate that the proposed algorithm is more effective and superior than most low-level oriented prior methods in terms of precision recall curves, F-measure and mean absolute errors. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ji, Chao; Huang, Xinbo; Cao, Wen; Zhu, Yongcan; Zhang, Ye] Xian Polytech Univ, Sch Elect & Informat, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an Polytechnic University
RP Huang, XB (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian 710048, Shaanxi, Peoples R China.
EM txcljqxx@163.com
OI Huang, Xinbo/0000-0002-9996-711X
FU National Natural Science Foundation of China [51707141]; Project of
   Natural Science Foundation of Shaanxi Fund [2017JQ6054]
FX The authors thank the referees for many valuable comments that are
   beneficial to improving this manuscript. This work was supported in part
   by the National Natural Science Foundation of China (Grant No.
   51707141), Project of Natural Science Foundation of Shaanxi Fund (Grant
   No. 2017JQ6054).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Akilan T, 2018, IET IMAGE PROCESS, V12, P1102, DOI 10.1049/iet-ipr.2017.0232
   Allili Mohand Said, 2007, Signal, Image and Video Processing, V1, P101, DOI 10.1007/s11760-007-0021-8
   Allili M.S., 2007, IEEE Conf. on Computer Vision and pattern Recognition, P1
   Allili MS, 2012, IEEE T IMAGE PROCESS, V21, P1452, DOI 10.1109/TIP.2011.2170701
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], IEEE P CVPR
   [Anonymous], IEEE P CVPR
   [Anonymous], IEEE P CVPR
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE P CVPR
   [Anonymous], IEEE P CVPR
   [Anonymous], IEEE P CVPR
   [Anonymous], P EUR C COMPUT VIS
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, IEEE T IMAGE PROCESS
   [Anonymous], IEEE P CVPR
   [Anonymous], IEEE TPAMI
   [Anonymous], IEEE P CVPR
   [Anonymous], IJCV
   [Anonymous], IEEE P CVPR
   Bu XX, 2018, PR ELECTROMAGN RES S, P801, DOI 10.23919/PIERS.2018.8597896
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Hu HX, 2017, IEEE SYS MAN CYBERN, P1892, DOI 10.1109/SMC.2017.8122893
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Imani M, 2016, I SYMPOS LOW POWER E, P162, DOI 10.1145/2934583.2934595
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kiamehr K, 2017, AEI 2017: RESILIENCE OF THE INTEGRATED BUILDING, P432
   Kong LC, 2017, IET IMAGE PROCESS, V11, P1094, DOI 10.1049/iet-ipr.2017.0407
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y., 2016, FORTH INT C LEARNING, P196
   Li Z, 2018, J VIS COMMUN IMAGE R, V50, P16, DOI 10.1016/j.jvcir.2017.11.004
   Liang XP, 2018, IET IMAGE PROCESS, V12, P1079, DOI 10.1049/iet-ipr.2017.1061
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Y, 2016, LECT NOTES COMPUT SC, V9797, P611, DOI 10.1007/978-3-319-42634-1_49
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2018, INT J COMPUT VISION, V126, P751, DOI 10.1007/s11263-017-1062-2
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Wang X, 2016, IEEE IMAGE PROC, P1042
   Wu HS, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P277, DOI 10.1109/SIPROCESS.2016.7888267
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu YY, 2018, J VIS COMMUN IMAGE R, V53, P113, DOI 10.1016/j.jvcir.2018.02.015
   Yan Q., 2013, IEEE PROC CVPR, P1
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
NR 60
TC 0
Z9 0
U1 2
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102673
DI 10.1016/j.jvcir.2019.102673
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700017
DA 2024-07-18
ER

PT J
AU Shang, F
   Zhang, HX
   Sun, JD
   Liu, L
AF Shang, Fei
   Zhang, Huaxiang
   Sun, Jiande
   Liu, Li
TI Semantic consistency cross-modal dictionary learning with rank
   constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-modal retrieval; Dictionary learning; Rank constraint
ID REPRESENTATION; FUSION
AB Cross-modal retrieval develops rapidly due to the growth and widespread applications of multimodal data. How to reduce the heterogeneous gap and impose effective constraints on different modalities are two basic problems. In this paper, we propose a novel Semantic Consistency cross-modal Dictionary learning algorithm with rank Constraint (SCDC) to solve these aforementioned problems. An orthogonal space learned by spectral regression is introduced, in which different modalities can be measured directly. Specifically, images and texts are encoded by their dictionaries to obtain corresponding reconstruction coefficients. A l(21)-norm term is imposed on these coefficients in order to select discriminative features and avoid over-fitting simultaneously. In the meantime, a rank constraint is imposed on the transformed features so as to improve the correlation of different modalities. Experimental results on three popular datasets demonstrate that SCDC is significantly superior to several state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Shang, Fei; Zhang, Huaxiang; Sun, Jiande; Liu, Li] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang; Sun, Jiande; Liu, Li] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@163.com
RI ARSLAN, Okan/AAA-3232-2020
FU National Natural Science Foundation of China [61772322, U1836216,
   61702310]; Technology and Development Project of Shandong [2017GGX10117,
   2017CXGC0703]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61772322, U1836216, 61702310) and the
   Technology and Development Project of Shandong (Nos. 2017GGX10117 and
   2017CXGC0703).
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2016, PACIS
   Bahrampour S, 2016, IEEE T IMAGE PROCESS, V25, P24, DOI 10.1109/TIP.2015.2496275
   Basak Jayanta, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1322, DOI 10.1109/ICPR.2010.329
   Deng C, 2016, IEEE T MULTIMEDIA, V18, P208, DOI 10.1109/TMM.2015.2508146
   Hao YB, 2017, IEEE T MULTIMEDIA, V19, P1, DOI 10.1109/TMM.2016.2610324
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Hu X, 2017, IEEE T AFFECT COMPUT, V8, P228, DOI 10.1109/TAFFC.2016.2523503
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Luo X., 2019, IEEE T IMAGE PROCESS, VPP, P1
   Mandal D, 2016, IEEE T IMAGE PROCESS, V25, P3826, DOI 10.1109/TIP.2016.2577885
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Peng YX, 2017, FRONT INFORM TECH EL, V18, P44, DOI 10.1631/FITEE.1601787
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shang F, 2018, J ADV COMPUT INTELL, V22, P280, DOI 10.20965/jaciii.2018.p0280
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang LQ, 2017, SIGNAL PROCESS, V131, P249, DOI 10.1016/j.sigpro.2016.08.012
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Wei Y, 2016, J STRUCT FIRE ENG, V7, P2, DOI 10.1108/JSFE-03-2016-001
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu F, 2007, P IEEE INT C IM PROC, P1465
   Wu JL, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1663, DOI 10.1145/3269206.3269296
   Wu JL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P917, DOI 10.1145/3077136.3080678
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Xu XL, 2016, IEEE T CLOUD COMPUT, V4, P166, DOI 10.1109/TCC.2015.2453966
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhong FM, 2018, PATTERN RECOGN, V83, P64, DOI 10.1016/j.patcog.2018.05.018
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu ZQ, 2016, NEUROCOMPUTING, V214, P471, DOI 10.1016/j.neucom.2016.06.036
NR 45
TC 8
Z9 8
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 259
EP 266
DI 10.1016/j.jvcir.2019.05.017
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600025
DA 2024-07-18
ER

PT J
AU Chaabouni, S
   Benois-Pineau, J
   Ben Amar, C
AF Chaabouni, Souad
   Benois-Pineau, Jenny
   Ben Amar, Chokri
TI ChaboNet : Design of a deep CNN for prediction of visual saliency in
   natural video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention prediction in video; Deep convolutional neural
   networks; Saliency map; Residual motion; Dynamic content
ID SPATIOTEMPORAL SALIENCY; ATTENTION; SCENE; MODEL
AB Prediction of visual saliency in images and video is needed for video understanding, search and retrieval, coding, watermarking and other applications. The majority of prediction models are founded only on "bottom-up" features. Nevertheless, the "top-down" component of human visual attention becomes prevalent as human observers explore the visual scene. Visual saliency which is always a mix of bottom-up and top-down cues can be predicted on the basis of seen data. In this paper, a model of prediction of visual saliency in video on the basis of Deep convolutional neural networks (CNNs) is proposed. A Deep CNN architecture is designed. Various input channels for a CNN architecture are studied: using the known sensitivity of human visual system to residual motion, pixel colour values are completed with residual motion map. The latter is a normalized energy of residual motion in video frames with regard to the estimated global affine motion model. The experiments show that the choice of the input features for the Deep CNN depends on visual task: for highly dynamic content, the proposed model with residual motion is more efficient and gives decent results with relatively shallow Deep architecture. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chaabouni, Souad; Benois-Pineau, Jenny] Univ Bordeaux, LaBRI UMR 5800, F-33400 Bordeaux, France.
   [Chaabouni, Souad; Ben Amar, Chokri] Univ Sfax, REGIM Lab LR11ES48, Dept Comp Sci, Sfax 3038, Tunisia.
C3 Universite de Bordeaux; Universite de Sfax; Faculty of Sciences Sfax
RP Chaabouni, S (corresponding author), Univ Bordeaux, LaBRI UMR 5800, F-33400 Bordeaux, France.; Chaabouni, S (corresponding author), Univ Sfax, REGIM Lab LR11ES48, Dept Comp Sci, Sfax 3038, Tunisia.
EM souad.chaabouni@u-bordeaux.fr; jenny.benois-pineau@u-bordeaux.fr;
   chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; Benois-Pineau, Jenny/ABG-6325-2020
OI Benois-Pineau, Jenny/0000-0003-0659-8894
FU University of Bordeaux; University of Sfax; UNetBA
FX This research has been supported by University of Bordeaux, University
   of Sfax and the grant UNetBA.
CR [Anonymous], VISUAL ATTENTION SAC
   [Anonymous], 2009 IEEE C COMP VIS
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ABS13126034 CORR
   [Anonymous], 2013, FOUND TRENDS SIGNAL, DOI DOI 10.1561/2000000039
   [Anonymous], 2009, Technical report
   [Anonymous], ABS150701422 CORR
   [Anonymous], ABS14111045 CORR
   [Anonymous], ABS161006449 CORR
   [Anonymous], 2012, JMLR WORKSHOP C P
   [Anonymous], PREDICTION VISUAL SA
   [Anonymous], BEHAV RES METH
   [Anonymous], NO REFERENCE VIDEO Q
   [Anonymous], IEEE INT C IM PROC C
   [Anonymous], ABS170200372 CORR
   [Anonymous], COLL RES COMP NEUR A
   [Anonymous], ABS170906505 CORR
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chaabouni S., 2016, 2016 14 INT WORKSH C, V91, P1
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Cornia M, 2016, LECT NOTES COMPUT SC, V9914, P302, DOI 10.1007/978-3-319-48881-3_21
   Duan LJ, 2015, SIGNAL PROCESS-IMAGE, V38, P45, DOI 10.1016/j.image.2015.08.005
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   González-Díaz I, 2016, PATTERN RECOGN, V56, P129, DOI 10.1016/j.patcog.2016.03.007
   Han BJ, 2017, J VIS COMMUN IMAGE R, V49, P27, DOI 10.1016/j.jvcir.2017.08.003
   Han JW, 2014, NEUROCOMPUTING, V145, P140, DOI 10.1016/j.neucom.2014.05.049
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li Z, 2018, J VIS COMMUN IMAGE R, V50, P16, DOI 10.1016/j.jvcir.2017.11.004
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Long Mai, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P91, DOI 10.1109/ISM.2011.23
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154
   Pang YW, 2018, IEEE T CIRC SYST VID, V28, P640, DOI 10.1109/TCSVT.2016.2630731
   Pinto Y, 2013, J VISION, V13, DOI 10.1167/13.3.16
   Purves D., 2001, NEUROSCIENCE
   Ren JR, 2018, J VIS COMMUN IMAGE R, V50, P227, DOI 10.1016/j.jvcir.2017.12.002
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen CY, 2014, NEUROCOMPUTING, V138, P61, DOI 10.1016/j.neucom.2013.09.053
   Shen J, 2012, VISION RES, V65, P62, DOI 10.1016/j.visres.2012.06.001
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wooding DS, 2002, BEHAV RES METH INS C, V34, P518, DOI 10.3758/BF03195481
   Yang J, 2016, IEEE T CIRC SYST VID, V26, P1070, DOI 10.1109/TCSVT.2015.2433171
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhong S.-h., 2013, AAAI Conference on Artificial Intelligence, P1063
NR 58
TC 15
Z9 16
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 79
EP 93
DI 10.1016/j.jvcir.2019.02.004
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000011
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Foumani, SNM
   Nickabadi, A
AF Foumani, Seyed Navid Mohammadi
   Nickabadi, Ahmad
TI A probabilistic topic model using deep visual word representation for
   simultaneous image classification and annotation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification and annotation; Topic models; Probabilistic model;
   Deep learning; Convolutional neural network; LLC
ID SCENE
AB Researches have shown that holistic examination of an image provides better understanding of the image compared to separate processes each devoted to a single task like annotation, classification or segmentation. During the past decades, there have been several efforts for simultaneous image classification and annotation using probabilistic or neural network based topic models. Despite their relative success, most of these models suffer from the poor visual word representation and the imbalance between the number of visual and annotation words in the training data. This paper proposes a novel model for simultaneous image classification and annotation model based on SupDocNADE, a neural network based topic model for image classification and annotation. The proposed model, named wSupDocNADE, addresses the above shortcomings by using a new coding and introducing a weighting mechanism for the SupDocNADE model. In the coding step of the model, several patches extracted from the input image are first fed to a deep convolutional neural network and the feature vectors obtained from this network are coded using the LLC coding. These vectors are then aggregated in a final descriptor through sum pooling. To overcome the imbalance between the visual and annotation words, a weighting factor is considered for each visual or annotation word. The weights of the visual words are set based on their frequencies obtained from the pooling method and the weights of the annotation words are learned from the training data. The experimental results on three benchmark datasets show the superiority of the proposed model in both image classification and annotation tasks over state-of-the-art models. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Foumani, Seyed Navid Mohammadi; Nickabadi, Ahmad] Amirkabir Univ Technol, Dept Comp Engn & IT, Tehran, Iran.
C3 Amirkabir University of Technology
RP Nickabadi, A (corresponding author), 424 Hafez Ave, Tehran, Iran.
EM nickabadi@aut.ac.ir
OI Mohammadi Foumani, Navid/0000-0003-2475-6040
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hinton GE, 2009, INT C NEURAL INF PRO, P1607
   Jing LP, 2012, IEEE T IMAGE PROCESS, V21, P4508, DOI 10.1109/TIP.2012.2206040
   Koskela M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1169, DOI 10.1145/2647868.2655024
   Larochelle H., 2012, ADV NEURAL INFORM PR, P2708
   Larochelle H., 2011, P 14 INT C ARTIFICIA, P29
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li JH, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P345, DOI [10.1109/CIS.2016.0084, 10.1109/CIS.2016.83]
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li Xiao-xu, 2012, Journal of China Universities of Posts and Telecommunications, V19, P107, DOI 10.1016/S1005-8885(11)60254-9
   Li XX, 2018, NEUROCOMPUTING, V312, P324, DOI 10.1016/j.neucom.2018.05.077
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McAuliffe J. D., 2008, ADV NEURAL INFORM PR, P121, DOI DOI 10.1109/MWSCAS.2011.6026348
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Simonyan K., 2014, 14091556 ARXIV
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang YS, 2011, ADV MAT SCI ENG-BOCA, P1
   Williams C.K.I., PASCAL VISUAL OBJECT
   Yang L, 2016, IMAGE VISION COMPUT, V51, P22, DOI 10.1016/j.imavis.2016.03.005
   Zang MJ, 2015, NEUROCOMPUTING, V148, P467, DOI 10.1016/j.neucom.2014.07.018
   Zhang H, 2015, J VIS COMMUN IMAGE R, V28, P28, DOI 10.1016/j.jvcir.2015.01.004
   Zheng Y, 2016, IEEE T PATTERN ANAL, V38, P1056, DOI 10.1109/TPAMI.2015.2476802
   Zheng Y, 2014, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2014.178
NR 34
TC 9
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 195
EP 203
DI 10.1016/j.jvcir.2019.01.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600020
DA 2024-07-18
ER

EF