FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Chaurasia, D
   Chhikara, P
AF Chaurasia, Dhiraj
   Chhikara, Prateek
TI Sea-Pix-GAN: Underwater image enhancement using adversarial neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adversarial neural network; Deep learning; Image processing; Underwater
   imaging
AB In the last decade, the exploration of deep-sea ecosystems has surged, offering exciting prospects for discovering untapped resources such as medical drugs, food and energy sources, and renewable energy products. Consequently, research in underwater image processing has witnessed substantial growth. However, underwater imaging poses significant challenges, particularly without sophisticated, specialized cameras. Traditional cameras are impacted by absorption and scattering in the aquatic environment, producing hazy images with a blue-green tint. This phenomenon holds implications for marine research and other disciplines that rely on underwater imaging. While hardware advancements have been made over the years, image processing remains a valuable, cost-effective, and practical approach for underwater enhancement. Despite the existence of state-of-the-art techniques for underwater enhancement and restoration, their performance is often inconsistent. While some methods excel in contrast restoration, color restoration remains a pervasive challenge. In this paper, we introduce Sea-Pix-GAN , a Generative Adversarial Network (GAN)-based model that addresses these issues in underwater image enhancement. We redefine the problem as an image-to-image translation task and tailor the objective and loss functions to achieve color, content, and style transfer. The model is trained on a large dataset of underwater scenes, encompassing the diverse color dynamics of underwater subjects. Sea-Pix-GAN demonstrates promising results in restoring color, contrast, texture, and saturation. To validate its effectiveness, we compare the performance of Sea-Pix-GAN quantitatively based on metrics like PSNR, SSIM, and UIQM and qualitatively against several existing techniques.
C1 [Chaurasia, Dhiraj; Chhikara, Prateek] Univ Southern Calif, Los Angeles, CA USA.
   [Chhikara, Prateek] Viterbi Sch Engn, 3650 McClintock Ave, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Chhikara, P (corresponding author), Viterbi Sch Engn, 3650 McClintock Ave, Los Angeles, CA 90089 USA.
EM dchauras@usc.edu; pchhikar@usc.edu
OI Chhikara, Prateek/0000-0003-4833-474X
CR Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Bec KB, 2019, FRONT CHEM, V7, DOI 10.3389/fchem.2019.00048
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Caimi Frank Michael, 2014, Computer Vision: A Reference Guide, P831
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Chhikara P, 2022, SOFTWARE PRACT EXPER, V52, P658, DOI 10.1002/spe.2876
   Chhikara Prateek, 2022, JOINT EUROPEAN C MAC, P627
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Ghani ASA, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-757
   Ghani ASA, 2014, INT J NAV ARCH OCEAN, V6, P840, DOI 10.2478/IJNAOE-2013-0217
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson Laura J., 2015, Ph.D. thesis
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Liu Chao, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P35, DOI 10.1109/ICCET.2010.5485339
   Liu SB, 2022, IEEE ROBOT AUTOM LET, V7, P5326, DOI 10.1109/LRA.2022.3156176
   Lutz Y, 2011, PROC SPIE, V8170, DOI 10.1117/12.896312
   Mariani P, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11010162
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Mobley C. D., 1994, LIGHT WATER RAD TRAN
   Nave R., 2017, Hyperphysics
   Nilsson J., 2006, arXiv, DOI DOI 10.48550/ARXIV.2006.13846
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng LT, 2023, IEEE T IMAGE PROCESS, V32, P3066, DOI 10.1109/TIP.2023.3276332
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Raveendran S, 2021, ARTIF INTELL REV, V54, P5413, DOI 10.1007/s10462-021-10025-z
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma P, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3511021
   Shin YS, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761342
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   VIJ K., 2009, Int J Comp Tech Appl, V2, P309
   Vishwakarma A., 2012, Color image enhancement techniques: A critical review
   Wu HD, 2020, OPT LASER ENG, V126, DOI 10.1016/j.optlaseng.2019.105871
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Zhang WD, 2022, IEEE T IMAGE PROCESS, V31, P3997, DOI 10.1109/TIP.2022.3177129
   Zhao X, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Zhuang PX, 2022, IEEE T IMAGE PROCESS, V31, P5442, DOI 10.1109/TIP.2022.3196546
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 53
TC 0
Z9 0
U1 6
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104021
DI 10.1016/j.jvcir.2023.104021
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EK9K4
UT WOS:001138935800001
DA 2024-07-18
ER

PT J
AU Majumder, A
   Kundu, S
   Changder, S
AF Majumder, Anandaprova
   Kundu, Sumana
   Changder, Suvamoy
TI A unique database synthesis technique for coverless data hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Security and privacy protection; Coverless data hiding; Privacy attacks;
   Object synthesis; Database synthesis; Steganography
ID IMAGE STEGANOGRAPHY; SIGNIFICANT-BIT; ALGORITHM
AB Coverless data hiding is a powerful technique for data security, but synthesizing text or images, often leads to semantically incorrect results. Prior state-of-the-art works have typically used media files as covers or as references for cover synthesis. This scope of improvement has inspired us to propose a novel data hiding technique by synthesizing self-sufficient, independent object without using any cover, even as metadata for data hiding. The approach focuses on synthesis of a database, by generating a dataset for the domain values of the attributes of it. Application of comparison-based sorting technique to the dataset, reveals the hidden message. The skill of the technique lies in unlimited hiding capacity, while preserving the semantic integrity of the database. Multiple security measures are taken into account along with thorough analysis of time complexity, to evaluate the efficacy of our method, that surpasses recently proposed approaches, providing solution for highly resistant covert communication.
C1 [Majumder, Anandaprova; Kundu, Sumana] Dr BC Roy Engn Coll, Dept CSE, Durgapur, India.
   [Changder, Suvamoy] Natl Inst Technol, Dept CSE, Durgapur, India.
C3 Dr. B. C. Roy Engineering College; National Institute of Technology (NIT
   System); National Institute of Technology Durgapur
RP Majumder, A (corresponding author), Dr BC Roy Engn Coll, Dept CSE, Durgapur, India.
EM anandaprova.majumder@bcrec.ac.in; sumana.kundu@yahoo.co.in;
   suvamoy@cse.nitdgp.ac.in
OI KUNDU, SUMANA/0000-0003-0731-8284; Majumder,
   Anandaprova/0000-0003-1676-6206
CR Ahvanooey MT, 2018, IEEE ACCESS, V6, P65981, DOI 10.1109/ACCESS.2018.2866063
   Baagyere EY, 2020, IEEE ACCESS, V8, P100438, DOI 10.1109/ACCESS.2020.2997838
   Chan CK, 2001, ELECTRON LETT, V37, P1017, DOI 10.1049/el:20010714
   Changder S., 2010, 2nd International Conference on Computer Technology and Development (ICCTD 2010), P501, DOI 10.1109/ICCTD.2010.5645849
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Kasapbasi MC, 2019, IEEE ACCESS, V7, P148495, DOI 10.1109/ACCESS.2019.2946807
   Kraetzer C, 2019, 13TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2018), DOI 10.1145/3230833.3233263
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu GJ, 2014, MULTIMEDIA SYST, V20, P227, DOI 10.1007/s00530-013-0313-5
   Liu J, 2020, IEEE ACCESS, V8, P60575, DOI 10.1109/ACCESS.2020.2983175
   Niu K, 2019, IEEE ACCESS, V7, P61523, DOI 10.1109/ACCESS.2019.2902464
   Qin JH, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091394
   Qin JH, 2019, IEEE ACCESS, V7, P171372, DOI 10.1109/ACCESS.2019.2955452
   Roy R, 2014, INT CONF CONTEMP, P218, DOI 10.1109/IC3.2014.6897176
   Saad AS, 2021, IEEE ACCESS, V9, P16522, DOI 10.1109/ACCESS.2021.3050737
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang J, 2019, IEEE ACCESS, V7, P119393, DOI 10.1109/ACCESS.2019.2936614
   Wang KX, 2019, IEEE ACCESS, V7, P95665, DOI 10.1109/ACCESS.2019.2929123
   Wu DC, 2020, IEEE ACCESS, V8, P20459, DOI 10.1109/ACCESS.2020.2966889
   Wu HZ, 2018, Arxiv, DOI arXiv:1712.03621
   Wu N, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720914257
   Xue YM, 2019, IEEE ACCESS, V7, P153724, DOI 10.1109/ACCESS.2019.2948946
   Ying KY, 2021, IEEE ACCESS, V9, P11705, DOI 10.1109/ACCESS.2021.3050004
   Zhang Z, 2020, TSINGHUA SCI TECHNOL, V25, P516, DOI 10.26599/TST.2019.9010027
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
NR 28
TC 0
Z9 0
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103911
DI 10.1016/j.jvcir.2023.103911
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q5EG0
UT WOS:001057742700001
DA 2024-07-18
ER

PT J
AU Lee, SH
   Kim, SW
AF Lee, Se-Ho
   Kim, Seung-Wook
TI Dual-branch vision transformer for blind image quality assessment*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image quality assessment; No-reference image quality assessment;
   Vision transformer; Perceptual image processing
ID STATISTICS
AB Blind image quality assessment (BIQA) has always been a challenging problem due to the absence of reference images. In this paper, we propose a novel dual-branch vision transformer for BIQA, which simultaneously considers both local distortions and global semantic information. It first extracts dual-scale features from the backbone network, and then each scale feature is fed into one of the transformer encoder branches as a local feature embedding to consider the scale-variant local distortions. Each transformer branch obtains the context of global image distortion as well as the local distortion by adopting content-aware embedding. Finally, the outputs of the dual-branch vision transformer are combined by using multiple feed-forward blocks to predict the image quality scores effectively. Experimental results demonstrate that the proposed BIQA method outperforms the conventional methods on the six public BIQA datasets.
C1 [Lee, Se-Ho] Jeonbuk Natl Univ, Dept Informat Technol IT, Jeonju 54896, South Korea.
   [Kim, Seung-Wook] Pukyong Natl Univ, Sch Elect & Commun Engn, Pusan 48513, South Korea.
C3 Jeonbuk National University; Pukyong National University
RP Kim, SW (corresponding author), Pukyong Natl Univ, Sch Elect & Commun Engn, Pusan 48513, South Korea.
EM seholee@jbnu.ac.kr; swkim@pknu.ac.kr
OI Kim, Seung-Wook/0000-0002-6004-4086
FU Pukyong National University Re-search Fund [202203570001]
FX Acknowledgment This paper was supported by research funds for newly
   appointed professors of Jeonbuk National University in 2021. This work
   was supported by the Pukyong National University Re-search Fund in 2022
   (202203570001) .
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Dosovitskiy Alexey, 2021, ICLR
   Duan HY, 2022, IEEE T IMAGE PROCESS, V31, P7206, DOI 10.1109/TIP.2022.3220404
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Golestaneh S Alireza, 2022, P IEEE CVF WINT C AP, P3209
   Golestaneh S, 2016, IEEE T IMAGE PROCESS, V25, P5293, DOI 10.1109/TIP.2016.2601821
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Ke JJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5128, DOI 10.1109/ICCV48922.2021.00510
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Kingma D, 2014, C LEARNING REPRESENT, P12
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li DQ, 2019, IEEE T MULTIMEDIA, V21, P1221, DOI 10.1109/TMM.2018.2875354
   Lin HH, 2019, INT WORK QUAL MULTIM
   Liu MN, 2023, IEEE T IMAGE PROCESS, V32, P1656, DOI 10.1109/TIP.2023.3245991
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mei KF, 2022, LECT NOTES COMPUT SC, V13667, P384, DOI 10.1007/978-3-031-20071-7_23
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Pearson K., 1895, P R SOC LOND, V58, P240, DOI 10.1098/rspl.1895.0041
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vaswani A, 2017, ADV NEUR IN, V30
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yan JZ, 2014, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2014.382
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   You JY, 2021, IEEE IMAGE PROC, P1389, DOI 10.1109/ICIP42928.2021.9506075
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE MULTIMEDIA, V21, P67, DOI 10.1109/MMUL.2014.50
   Zhang W., 2019, ABS190700516 CORR
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhou ML, 2023, IEEE T BROADCAST, V69, P369, DOI 10.1109/TBC.2022.3215249
NR 58
TC 4
Z9 4
U1 4
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103850
DI 10.1016/j.jvcir.2023.103850
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I0GN6
UT WOS:000999646600001
DA 2024-07-18
ER

PT J
AU Memon, S
   Arain, RH
   Mallah, GA
AF Memon, Sanaullah
   Arain, Rafaqat Hussain
   Mallah, Ghulam Ali
TI AMSFF-Net: Attention-Based Multi-Stream Feature Fusion Network for
   Single Image Dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Channel attention; Pixel attention; Mixed convolution
   attention; Residual dense block; Feature fusion
AB this paper, an end-to-end convolutional neural network is proposed to recover haze-free image named as Attention-Based Multi-Stream Feature Fusion Network (AMSFF-Net). The encoder-decoder network structure is used to construct the network. An encoder generates features at three resolution levels. The multi-stream features are extracted using residual dense blocks and fused by feature fusion blocks. AMSFF-Net has ability to pay more attention to informative features at different resolution levels using pixel attention mechanism. A sharp image can be recovered by the good kernel estimation. Further, AMSFF-Net has ability to capture semantic and sharp textural details from the extracted features and retain high-quality image from coarse-to-fine using mixed-convolution attention mechanism at decoder. The skip connections decrease the loss of image details from the larger receptive fields. Moreover, deep semantic loss function emphasizes more semantic information in deep features. Experimental findings prove that the proposed method outperforms in synthetic and real-world images.
C1 [Memon, Sanaullah; Arain, Rafaqat Hussain; Mallah, Ghulam Ali] Shah Abdul Latif Univ Khairpur, Inst Comp Sci, Khairpur, Sindh, Pakistan.
C3 Shah Abdul Latif University
RP Memon, S (corresponding author), Shah Abdul Latif Univ Khairpur, Inst Comp Sci, Khairpur, Sindh, Pakistan.
EM sanaullahmemon13@gmail.com; rafaqat.arain@salu.edu.pk;
   ghulam.ali@salu.edu.pk
CR Bassanini P., 1997, THEORY APPL PARTIAL, P213, DOI [10.1007/978-1-4899-1875-8_5, DOI 10.1007/978-1-4899-1875-8_5]
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Fan GD, 2021, APPL INTELL, V51, P7262, DOI 10.1007/s10489-021-02236-2
   Handa A, 2018, 2018 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN ELECTRICAL, ELECTRONICS & COMMUNICATION ENGINEERING (ICRIEECE 2018), P2099, DOI 10.1109/ICRIEECE44171.2018.9008937
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Kingma D. P., 2015, INT C LEARNING REPRE
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Z, 2019, IEEE SIGNAL PROC LET, V26, P833, DOI 10.1109/LSP.2019.2910403
   Ma YL, 2022, IET IMAGE PROCESS, V16, P1897, DOI 10.1049/ipr2.12455
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Rashid H, 2019, PROCEDIA COMPUT SCI, V147, P124, DOI 10.1016/j.procs.2019.01.201
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahu G, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103008
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, 14091556 ARXIV
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang XY, 2022, SIGNAL PROCESS-IMAGE, V105, DOI 10.1016/j.image.2022.116719
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu XS, 2021, IEEE T IMAGE PROCESS, V30, P7620, DOI 10.1109/TIP.2021.3108022
NR 35
TC 2
Z9 2
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103748
DI 10.1016/j.jvcir.2022.103748
EA JAN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8D6PM
UT WOS:000918412900001
DA 2024-07-18
ER

PT J
AU Fu, CR
   Yuan, H
   Xu, HJ
   Zhang, H
   Shen, LQ
AF Fu, Congrui
   Yuan, Hui
   Xu, Hongji
   Zhang, Hao
   Shen, Liquan
TI TMSO-Net: Texture adaptive multi-scale observation for light field image
   depth estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light field; Depth estimation; Epipolar plane image; Convolution neural
   network; Texture classification
AB Light field can record the four-dimensional information of light rays, i.e. the position and direction information in which depth information is implied. To improve the depth estimation accuracy, we propose a depth estimation algorithm based on convolutional neural network (CNN). First, a single image super resolution algorithm is adopted to spatially super resolve the sub-aperture images (SAIs). Second, to adapt the texture complexity, the SAIs are partitioned into two regions, i.e., simple texture region and complex texture region, based on the texture analysis of the central SAI. Third, the epipolar plane images (EPIs) in horizontal, vertical, 45 degree diagonal, and 135 degree diagonal directions for both complex and simple texture regions are extracted, and the corresponding EPIs for the simple and complex texture regions are fed into the specified network branches. Finally, a fusion module is designed to generate the depth map. Experimental results show that the quality of the estimated depth maps by the proposed method is better than the state-of-the-art methods in terms of both objective quality and subjective quality. Moreover, the proposed method is more robust to noise.
C1 [Fu, Congrui; Xu, Hongji] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Shandong, Peoples R China.
   [Yuan, Hui] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
   [Zhang, Hao] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266520, Peoples R China.
   [Shen, Liquan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shandong University; Shandong University; Qingdao University of
   Technology; Shanghai University
RP Yuan, H (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
EM huiyuan@sdu.edu.cn
RI Yuan, Hui/HDO-3699-2022; Shen, Liquan/D-4832-2012
OI Yuan, Hui/0000-0001-5212-3393; Xu, Hongji/0000-0001-6916-348X
FU National Natural Science Foundation of China [62222110, 62172259];
   Taishan Scholar Projectof Shandong Province, China [tsqn202103001];
   Central Guidance Fund for Local Science and Technology Development of
   Shandong Province, China [YDZX2021002]; Natural Science Foundation of
   Shandong Province, China [ZR2022ZD38]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62222110 and 62172259, the Taishan
   Scholar Projectof Shandong Province, China (tsqn202103001), the Central
   Guidance Fund for Local Science and Technology Development of Shandong
   Province, China, under Grant YDZX2021002 and the Natural Science
   Foundation of Shandong Province, China, under Grant ZR2022ZD38.
CR Alain M, 2019, IEEE IMAGE PROC, P3761, DOI [10.1109/icip.2019.8803558, 10.1109/ICIP.2019.8803558]
   Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197
   Chen JX, 2021, AAAI CONF ARTIF INTE, V35, P1009
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Feng MT, 2018, IEEE T IMAGE PROCESS, V27, P3586, DOI 10.1109/TIP.2018.2814217
   Heber Stefan, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P66, DOI 10.1007/978-3-642-40395-8_6
   Heber S., 2016, BRIT MACHINE VISION
   Heber S, 2014, LECT NOTES COMPUT SC, V8694, P751
   Heber S, 2017, IEEE I CONF COMP VIS, P2271, DOI 10.1109/ICCV.2017.247
   Heber S, 2016, PROC CVPR IEEE, P3746, DOI 10.1109/CVPR.2016.407
   Honauer K, 2017, LECT NOTES COMPUT SC, V10113, P19, DOI 10.1007/978-3-319-54187-7_2
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Kim Y, 2018, IEEE T IMAGE PROCESS, V27, P4131, DOI 10.1109/TIP.2018.2836318
   Kingma D. P, 2014, 3 INT C LEARN REPR I, P1
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li JQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440760
   Li NY, 2017, IEEE T PATTERN ANAL, V39, P1605, DOI 10.1109/TPAMI.2016.2610425
   Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394
   Lu W., 3D IMAGE STITCHING L
   Lytro, US
   Mattoccia S., STEREO VISION ALGORI
   Raytrix, About us
   Rerabek M., 2016, P 8 INT C QUAL MULT
   Shin C, 2018, PROC CVPR IEEE, P4748, DOI 10.1109/CVPR.2018.00499
   Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Tsai YJ, 2020, AAAI CONF ARTIF INTE, V34, P12095
   Wang YQ, 2019, IEEE SIGNAL PROC LET, V26, P204, DOI 10.1109/LSP.2018.2885213
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wanner S, 2013, PROC CVPR IEEE, P1011, DOI 10.1109/CVPR.2013.135
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Xu L, 2016, IEEE T MULTIMEDIA, V18, P590, DOI 10.1109/TMM.2016.2525004
   Xu YC, 2019, IEEE T COMPUT IMAG, V5, P465, DOI 10.1109/TCI.2019.2893820
   Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347
   Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007
   Zhou W., 2021, SIGNAL PROCESS, V186
NR 36
TC 57
Z9 57
U1 4
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103731
DI 10.1016/j.jvcir.2022.103731
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7L9VF
UT WOS:000906305600001
DA 2024-07-18
ER

PT J
AU Hai, J
   Xuan, Z
   Yang, R
   Hao, YT
   Zou, FZ
   Lin, F
   Han, SC
AF Hai, Jiang
   Xuan, Zhu
   Yang, Ren
   Hao, Yutong
   Zou, Fengzhu
   Lin, Fang
   Han, Songchen
TI R2RNet: Low-light image enhancement via Real-low to Real-normal Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Retinex theory; Low-light image enhancement; Image processing;
   Real-world low; normal-light image pairs
ID RETINEX
AB Images captured in weak illumination conditions could seriously degrade the image quality. Solving a series of degradation of low-light images can effectively improve the visual quality of images and the performance of high-level visual tasks. In this study, a novel Retinex-based Real-low to Real-normal Network (R2RNet) is proposed for low-light image enhancement, which includes three subnets: a Decom-Net, a Denoise-Net, and a Relight-Net. These three subnets are used for decomposing, denoising, contrast enhancement and detail preservation, respectively. Our R2RNet not only uses the spatial information of the image to improve the contrast but also uses the frequency information to preserve the details. Therefore, our model achieved more robust results for all degraded images. Unlike most previous methods that were trained on synthetic images, we collected the first Large-Scale Real-World paired low/normal-light images dataset (LSRW dataset) to satisfy the training requirements and make our model have better generalization performance in real-world scenes. Extensive experiments on publicly available datasets demonstrated that our method outperforms the existing state-of-the-art methods both quantitatively and visually. In addition, our results showed that the performance of the high-level visual task (i.e., face detection) can be effectively improved by using the enhanced results obtained by our method in low-light conditions. Our codes and the LSRW dataset are available at: https://github.com/JianghaiSCU/R2RNet.
C1 [Hai, Jiang; Xuan, Zhu; Yang, Ren; Hao, Yutong; Zou, Fengzhu; Lin, Fang; Han, Songchen] Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Hai, J (corresponding author), Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Peoples R China.
EM jianghai1@stu.scu.edu.cn; j_zhxxx@163.com; renyang20212021@163.com;
   15522808379@163.com; Y15286544560@163.com; PhotoAtoms@163.comn;
   hansongchen@scu.edu.cn
RI Jiang, Hai/HSE-6819-2023
OI Jiang, Hai/0000-0002-7087-6775
FU Key R and D project of Sichuan Province, China [22ZDYF3720]
FX Acknowledgments We would like to thank Mingrui Wu, Zhiyun Jiang, and
   Wenxuan Liu for helping us collect the LSRW dataset. This work is
   partially supported by Key R and D project of Sichuan Province, China
   (No. 22ZDYF3720) .
CR Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen LL, 2022, IEEE T CIRC SYST VID, V32, P1889, DOI 10.1109/TCSVT.2021.3086598
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng JK, 2019, Arxiv, DOI [arXiv:1905.00641, DOI 10.48550/ARXIV.1905.00641, 10.48550/ARXIV.1905.00641]
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Goossens B., 2008, 2008 International Workshop on Local and Non-Local Approximation in Image Processing, P143
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hai J, 2021, APPL ARTIF INTELL, V35, P1529, DOI 10.1080/08839514.2021.1985799
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isogawa K, 2018, IEEE SIGNAL PROC LET, V25, P224, DOI 10.1109/LSP.2017.2782270
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim DW, 2019, IEEE COMPUT SOC CONF, P2086, DOI 10.1109/CVPRW.2019.00261
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kingma D, 2014, ICLR P, V2014, P1
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361
   Lin K., 2019, P IEEE CVF C COMP VI
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Liu Y, 2018, Arxiv, DOI arXiv:1807.00202
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F, 2018, BR MACH VIS C
   Lv FF, 2021, INT J COMPUT VISION, V129, P2175, DOI 10.1007/s11263-021-01466-8
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mei YQ, 2020, Arxiv, DOI arXiv:2004.13824
   Rahman Z, 2020, IEEE ACCESS, V8, P109038, DOI 10.1109/ACCESS.2020.3001206
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salmon J, 2014, J MATH IMAGING VIS, V48, P279, DOI 10.1007/s10851-013-0435-6
   Shen L, 2017, Arxiv, DOI arXiv:1711.02488
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Trabalón Carina I., 2018, Polis, V17, P163
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2015, DOI 10.1145/3343031.3350983
   Wei C., 2018, BRIT MACHINE VISION
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Xue Ke, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P59, DOI 10.1109/ICIVC50857.2020.9177454
   Ying ZQ, 2017, Arxiv, DOI arXiv:1711.00591
   Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhou S., 2022, ECCV, DOI DOI 10.1007/978-3-031-20068-7_33
   Zou WB, 2021, IEEE INT CONF COMP V, P1895, DOI 10.1109/ICCVW54120.2021.00216
NR 57
TC 50
Z9 53
U1 8
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103712
DI 10.1016/j.jvcir.2022.103712
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E3KE1
UT WOS:000974557200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, CZ
   Gong, X
AF Wang, Chenzhong
   Gong, Xun
TI Bounding box regression with balance for harmonious object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Reinforcement learning; Bounding box regression
AB Localization is an essential part of object detection, which is usually accomplished by bounding box regression guided by en-norm-based or IoU-based loss functions, where IoU is known for its scale-invariant characteristics. However, introducing the scale-invariance into regression loss in traditional IoU-based methods may result in a bias in favor of smaller boxes and cause redundancy and unstable oscillations. To make up for these shortages of IoU-based losses, we propose a Scale-Balanced Factor (SF) that stabilizes the regression process via a simple adaptive factor. Furthermore, to compensate for the imbalance of different types of losses caused by SF and other IoU-based loss functions, regression losses are always multiplied by a hyperparameter, which is purely empirical and is hard to find an optimum. To address this issue, a Multi-Task Reinforced Equilibrium (MRE) is proposed to dynamically tweak the learning rate of each task based on reinforcement learning. The MRE can guarantee more balanced parameters and maximize the benefit of SF or other improvement methods for IoU. By incorporating the proposed SF and MRE into the classic detectors (RetinaNet, YOLO, and Faster R-CNN, etc.), we have achieved significant performance gains on MS COCO (0.8 AP similar to 1.9 AP) and PASCAL VOC (0.6 AP similar to 2.2 AP).
C1 [Wang, Chenzhong; Gong, Xun] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Sichuan, Peoples R China.
   [Gong, Xun] Mfg Ind Chains Collaborat & Informat Support Techn, Chengdu 610031, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Gong, X (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Sichuan, Peoples R China.
EM xgong@swjtu.edu.cn
RI Wang, Chenzhong/ACB-1204-2022; Wang, Chenzhong/JYP-6497-2024
OI Gong, Xun/0000-0002-1494-0955
FU National Natural Science Foundation of China; Fundamental Research Funds
   for the Central Universities, China;  [61876158];  [2682021ZTPY030]
FX This work is supported by National Natural Science Foundation of China
   (61876158) , Fundamental Research Funds for the Central Universities,
   China (2682021ZTPY030) .
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen JY, 2021, Arxiv, DOI arXiv:1909.04868
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen Z, 2018, PR MACH LEARN RES, V80
   Dai JF, 2016, ADV NEUR IN, V29
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   Elrefaei LA, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ANTI-CYBER CRIMES (ICACC), P75, DOI 10.1109/Anti-Cybercrime.2017.7905267
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu C.-Y., 2017, arXiv
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo M, 2018, LECT NOTES COMPUT SC, V11220, P282, DOI 10.1007/978-3-030-01270-0_17
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hengduo Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10585, DOI 10.1109/CVPR42600.2020.01060
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kenndy J., 1995, P ICNN 95 INT C NEUR, P1942
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X, 2020, Arxiv, DOI arXiv:2006.04388
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Lin T.-Y., 2014, CoRR, P740
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Lu Y, 2018, REV BREAST CANC DETE, DOI [10.1109/vcip.2018.8698732, 10.1109/VCIP.2018.869873, DOI 10.1109/VCIP.2018.869873]
   Mnih V, 2013, Arxiv, DOI [arXiv:1312.5602, 10.48550/arxiv.1312.5602]
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Paszke Adam, 2017, NIPS 2017 WORKSH AUT
   Patel Nikunjkumar, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P448, DOI 10.1007/978-3-030-04375-9_39
   Qiu H., 2020, P IEEE C COMPUTER VI, P13188
   Redmon A., 2017, P IEEE C COMP VIS PA, P7263, DOI 10.1109/cvpr.2017.690
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719
   Wang KY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3611, DOI 10.1109/ICCV48922.2021.00361
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Yue Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10183, DOI 10.1109/CVPR42600.2020.01020
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zhang JP, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103348
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 59
TC 0
Z9 0
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103665
DI 10.1016/j.jvcir.2022.103665
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500005
DA 2024-07-18
ER

PT J
AU Xu, SP
   Chen, XJ
   Luo, J
   Cheng, XH
   Xiao, N
AF Xu, Shaoping
   Chen, Xiaojun
   Luo, Jie
   Cheng, Xiaohui
   Xiao, Nan
TI An unsupervised fusion network for boosting denoising performance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Boosting denoising performance; Deep fusion network;
   Unsupervised training strategy
AB While many efforts have been devoted to addressing image denoising and achieve continuously improving results during the past few decades, it is fair to say that no a stand-alone method is consistently better than others. Nonetheless, many existing denoising methods, each having a different denoising capability, can yield various but complementary denoised images with respect to specific local areas. To effectively exploit the complementarity and diversity among the denoised images obtained with different denoisers, in this work we fuse them to produce an overall better result, which is fundamental to achieve robust and competitive denoising performance especially for complex scenes. A framework called deep fusion network (DFNet) is proposed to generate a consistent estimation about the final denoised image, taking advantage of the complementarity of denoisers and suppressing the bias. Specifically, given a noisy image, we first exploit a set of representative image denoisers to denoise it respectively, and obtain the corresponding initial denoised images. Then these initial denoised images are concatenated and fed into the proposed DFNet, and the proposed DFNet seeks to adjust its network parameters to produce the fused image (as the final denoised image) with an unsupervised training strategy through minimizing the carefully designed loss function. The experimental results show that our approach outperforms the stand-alone methods as well as the ones using combination strategy by large margin both in objective and subjective evaluations. Compared to the those methods that are relatively close to our strategy, the proposed DFNet is extensible and parameter free, which means it can cope with a variable number of different denoisers and avoid the manual intervention during the fusion process. The proposed DFNet has greater flexibility and better practicality.
C1 [Xu, Shaoping; Chen, Xiaojun; Cheng, Xiaohui; Xiao, Nan] Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Jiangxi, Peoples R China.
   [Luo, Jie] Nanchang Univ, Affiliated Infect Dis Hosp, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University
RP Xu, SP (corresponding author), Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Jiangxi, Peoples R China.
EM xushaoping@ncu.edu.cn
RI Xu, Shaoping/JAO-3891-2023
CR Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Choi JH, 2019, IEEE T IMAGE PROCESS, V28, P4016, DOI 10.1109/TIP.2019.2903321
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai HL, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3182-1
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Geyer S, 2022, ENG STRUCT, V253, DOI 10.1016/j.engstruct.2021.113761
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jo Y., 2021, P IEEE CVF INT C COM, P5087
   Ko K, 2022, IEEE T IMAGE PROCESS, V31, P1657, DOI 10.1109/TIP.2022.3145160
   Li H., 2022, IEEE Trans. Geosci. Remote Sens., V60
   Liu SQ, 2021, IEEE T GEOSCI REMOTE, V59, P3956, DOI 10.1109/TGRS.2020.3014130
   Luo JY, 2021, SIGNAL IMAGE VIDEO P, V15, P1275, DOI 10.1007/s11760-021-01858-w
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Maas A.L, 2013, ICML
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Ote K, 2020, IEEE T RADIAT PLASMA, V4, P720, DOI 10.1109/TRPMS.2020.3000221
   Pang TY, 2021, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR46437.2021.00208
   Quan YH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107639
   Quan YH, 2020, PROC CVPR IEEE, P1887, DOI 10.1109/CVPR42600.2020.00196
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scetbon M, 2021, IEEE T IMAGE PROCESS, V30, P5944, DOI 10.1109/TIP.2021.3090531
   Sidorov O, 2019, IEEE INT CONF COMP V, P3844, DOI 10.1109/ICCVW.2019.00477
   Song B, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3119859
   Su J., 2022, NEUROCOMPUTING, V487, P46, DOI [10.1016/j.neucom.2022.02.046, DOI 10.1016/J.NEUCOM.2022.02.046]
   Sun YL, 2021, IEEE T GEOSCI REMOTE, V59, P1231, DOI 10.1109/TGRS.2020.3002561
   Titova A., 2021, 1 INT M APPL GEOSC E, P115
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Valsesia D, 2020, IEEE T IMAGE PROCESS, V29, P8226, DOI 10.1109/TIP.2020.3013166
   Wang QQ, 2021, IEEE T IMAGE PROCESS, V30, P6648, DOI 10.1109/TIP.2021.3096089
   Xu HQ, 2021, IEEE T IMAGE PROCESS, V30, P4516, DOI 10.1109/TIP.2021.3073285
   Yang FJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113857
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Yang XH, 2020, IEEE T IMAGE PROCESS, V29, P5038, DOI 10.1109/TIP.2020.2978645
   Yin H, 2021, MULTIMED TOOLS APPL, V80, P6105, DOI 10.1007/s11042-020-10009-1
   Yue ZS, 2019, ADV NEUR IN, V32
   Zhang K, 2022, IEEE T PATTERN ANAL, V44, P6360, DOI 10.1109/TPAMI.2021.3088914
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2021, IEEE T IMAGE PROCESS, V30, P6255, DOI 10.1109/TIP.2021.3093396
NR 42
TC 2
Z9 2
U1 5
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103626
DI 10.1016/j.jvcir.2022.103626
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800007
DA 2024-07-18
ER

PT J
AU Chang, XY
   Zhang, YX
   Xue, DY
   Chen, DY
AF Chang, Xingya
   Zhang, Yuxin
   Xue, Dingyu
   Chen, Dongyue
TI Multi-task learning for video anomaly detection*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomalydetection; Multi-tasklearning; DeepSVDD; Futureframeprediction;
   Localprobabilityestimation
AB We propose a multi-task learning framework for video anomaly detection based on a novel pipeline. Our model contains two crossing streams, one stream employs the backbone of Attention-R2U-net for future frame prediction, while the other is designed based on an encoder-decoder network to reconstruct the input optical flow maps. In addition, the latent layers of the two streams are merged together and assigned with a Deep SVDD-based loss at each location individually. Through the combination of these three tasks, the two-stream -crossing pipeline can be trained end-to-end to provide a comprehensive evaluation for the anomaly targets. Experimental results on several popular benchmark datasets show that our model outperforms the state-of-the-art competing models, which can be applied to different types of anomalous targets and meanwhile achieves remarkable precision.
C1 [Chang, Xingya; Zhang, Yuxin; Xue, Dingyu; Chen, Dongyue] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
   [Chen, Dongyue] Northeastern Univ, Key Lab Data Analyt & Optimizat Smart Ind, Minist Educ, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Chen, DY (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.; Chen, DY (corresponding author), Northeastern Univ, Key Lab Data Analyt & Optimizat Smart Ind, Minist Educ, Shenyang 110819, Liaoning, Peoples R China.
EM chendongyue@ise.neu.edu.cn
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Alom M. Z., 2018, ARXIV180206955, V6, P014006, DOI 10.1109/NAECON.2018.8556686
   Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431), P15
   Chalapathy R., 2018, Anomaly detection using one-class neural networks
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Doshi Keval, 2020, P IEEE CVF C COMP VI, P934
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Ergen Tolga, 2017, ARXIV PREPRINT ARXIV
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kingma D. P., 2014, arXiv
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nguyen T.N., 2019, ARXIV PREPRINT ARXIV
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Ramaswamy S, 2000, SIGMOD REC, V29, P427, DOI 10.1145/335191.335437
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruff L, 2018, PR MACH LEARN RES, V80
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Zhang K, 2009, LECT NOTES ARTIF INT, V5476, P813, DOI 10.1007/978-3-642-01307-2_84
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zong B., 2018, INT C LEARNING REPRE, P1
NR 46
TC 1
Z9 1
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103547
DI 10.1016/j.jvcir.2022.103547
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100005
DA 2024-07-18
ER

PT J
AU Mallick, T
   Das, PP
   Majumdar, AK
AF Mallick, Tanwi
   Das, Partha Pratim
   Majumdar, Arun Kumar
TI Posture and sequence recognition for<i> Bharatanatyam</i> dance
   performances using machine learning approaches
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Posturerecognition; Sequencerecognition; Dancesegmentation;
   Multi-modaldancemodeling; Machinelearning; BharatanatyamDanceanalysis
ID INDIAN CLASSICAL DANCE; HIDDEN MARKOV-MODELS
AB Understanding the underlying semantics of performing arts like dance is a challenging task. Analysis of dance is useful to preserve cultural heritage, make video recommendation systems, and build tutoring systems. To create such a dance analysis application, three aspects of dance analysis must be addressed: (1) segment the dance video to find representative action elements, (2) recognize the detected action elements, and (3) recognize sequences formed by combining action elements according to specific rules. This paper attempts to address the three fundamental problems of dance analysis raised above, with a focus on Indian Classical Dance, em Bharatanatyam. Since dance is driven by music, we use both musical and motion information to extract action elements. The action elements are then recognized using machine learning and deep learning techniques. Finally, the Hidden Markov Model (HMM) and Long Short-Term Memory (LSTM) are used to recognize the dance sequence.
C1 [Mallick, Tanwi] Argonne Natl Lab, 9700 S Cass Ave, Lemont, IL 60439 USA.
   [Das, Partha Pratim] Indian Inst Technol Kharagpur, Kharagpur 721302, West Bengal, India.
   [Majumdar, Arun Kumar] JIS Inst Adv Studies & Res, Kolkata 700091, West Bengal, India.
C3 United States Department of Energy (DOE); Argonne National Laboratory;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Mallick, T (corresponding author), Argonne Natl Lab, 9700 S Cass Ave, Lemont, IL 60439 USA.
EM tanwimallick@gmail.com
RI Mallick, Tanwi/AAC-1785-2021; Das, Partha/Q-8644-2016
OI Mallick, Tanwi/0000-0003-3716-4693; Das, Partha/0000-0003-1435-6051
CR Aich A., 2018, COMPUT VIS PATTERN R, V841
   Aich A., 2018, NAT C COMP VIS PATT, P481
   Alexiadis DS, 2014, IEEE T MULTIMEDIA, V16, P1391, DOI 10.1109/TMM.2014.2317311
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Guo F, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P481
   Guo YA, 2016, IEEE T MULTIMEDIA, V18, P1977, DOI 10.1109/TMM.2016.2597007
   Han TT, 2017, IEEE T MULTIMEDIA, V19, P712, DOI 10.1109/TMM.2016.2631881
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Kahol K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P883, DOI 10.1109/AFGR.2004.1301645
   Koniusz P, 2022, IEEE T PATTERN ANAL, V44, P648, DOI 10.1109/TPAMI.2021.3107160
   Majumdar A. K., 2017, ANNOTATED BHARATANAT
   Mallick T., 2022, IEEE T AUDIO SPEECH
   Mallik A., 2011, Journal on Computing and Cultural Heritage JOCCH, V4, P11
   Mohanty A, 2018, PATTERN RECOGN, V79, P97, DOI 10.1016/j.patcog.2018.01.035
   Mohanty A, 2016, SIGNAL PROCESS-IMAGE, V47, P529, DOI 10.1016/j.image.2016.05.019
   Natarajan P., 2007, MOTION VIDEO COMPUTI, P10, DOI DOI 10.1109/WMVC.2007.12
   Ning H., 2008, COMPUTER VISION PATT, P1
   Ofli F, 2012, IEEE T MULTIMEDIA, V14, P747, DOI 10.1109/TMM.2011.2181492
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   Peng B, 2008, PROC CVPR IEEE, P144
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Samanta S., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P265, DOI 10.1109/WACV.2012.6163050
   Sankhla A., 2018, COMPUT VIS PATTERN R, V841
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   Senecal S, 2020, MULTIMED TOOLS APPL, V79, P24621, DOI 10.1007/s11042-020-09192-y
   Senecal S, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274514
   Shailesh S, 2020, INTELL DECIS TECHNOL, V14, P119, DOI 10.3233/IDT-190097
   Sharma A., 2013, THESIS IIT KANPUR
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shiratori T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P857, DOI 10.1109/AFGR.2004.1301641
   Shiratori T, 2003, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P89, DOI 10.1109/MFI-2003.2003.1232638
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tian YD, 2012, LECT NOTES COMPUT SC, V7576, P256, DOI 10.1007/978-3-642-33715-4_19
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang L, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4324, DOI 10.1145/3474085.3475572
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang L, 2017, IEEE T MULTIMEDIA, V19, P646, DOI 10.1109/TMM.2016.2617079
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Xu WR, 2017, IEEE T MULTIMEDIA, V19, P1494, DOI 10.1109/TMM.2017.2674622
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
NR 51
TC 6
Z9 6
U1 6
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103548
DI 10.1016/j.jvcir.2022.103548
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100010
DA 2024-07-18
ER

PT J
AU Xu, T
   Huang, TZ
   Deng, LJ
   Zhao, XL
   Hu, JF
AF Xu, Ting
   Huang, Ting-Zhu
   Deng, Liang-Jian
   Zhao, Xi-Le
   Hu, Jin-Fan
TI Exemplar-based image inpainting using adaptive two-stage
   structure-tensor based priority function and nonlocal filtering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Exemplar-based image inpainting; Non-local texture matching;
   Structure-tensor; Texture and structure synthesis; Object removal;
   Remote sensing image inpainting
ID OBJECT REMOVAL; COMPLETION; PDE; ALGORITHM; GRADIENT; PATCHES
AB For the exemplar-based image inpainting problem, the filling order and local intensity smoothness are two crucial factors that should be considered carefully. This work gives a new exemplar-based image inpainting method, preventing geometric structures from being destroyed and reconstructing textures well to obtain elegant-looking outputs. For a better filling order, we define a new adaptive two-stage structure-tensor based priority function. To promote the local intensity smoothness, we adopt a non-local way, and at the same time, propose a weighted filter based on a Gaussian-like function to generate the ideal filling patch by combining non-local patches. We compare the proposed method with some recent state-of-the-art image inpainting approaches on different tasks, such as texture and structure synthesis, object removal, and remote sensing images inpainting. Experimental results demonstrate the superiority of the proposed method, both visually and quantitatively.
C1 [Xu, Ting; Huang, Ting-Zhu; Deng, Liang-Jian; Zhao, Xi-Le; Hu, Jin-Fan] Univ Elect Sci & Technol China, Sch Math Sci, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Huang, TZ; Deng, LJ (corresponding author), Univ Elect Sci & Technol China, Sch Math Sci, Chengdu 611731, Sichuan, Peoples R China.
EM 17742879536@163.com; tingzhuhuang@126.com; liangjian.deng@uestc.edu.cn;
   xlzhao122003@163.com; hujf0206@163.com
RI Hu, Jin-Fan/ACM-8452-2022; Xu, Ting/GRS-7498-2022; huang,
   ting/GRR-3141-2022
FU NSFC, China [12171072, 61702083]; Key Projects of Applied Basic Research
   in Sichuan Province, China [2020YJ0216]; National Key Research and
   Development Program of China [2020YFA0714001]
FX Acknowledgments This research is supported by NSFC, China (12171072,
   61702083) , Key Projects of Applied Basic Research in Sichuan Province,
   China (Grant No. 2020YJ0216) , and National Key Research and Development
   Program of China (Grant No. 2020YFA0714001) . The authors would like to
   thank Dr. Ding for providing codes of work [3] for the compar-isons. The
   authors also thank the anonymous referees of this article for helpful
   comments and suggestions.
CR Arias P, 2011, INT J COMPUT VISION, V93, P319, DOI 10.1007/s11263-010-0418-7
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bin Mansoor A, 2010, LECT NOTES COMPUT SC, V6474, P10, DOI 10.1007/978-3-642-17688-3_2
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Bugeau A, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P26
   Buyssens P, 2015, IEEE T IMAGE PROCESS, V24, P1809, DOI 10.1109/TIP.2015.2411437
   Cai L, 2015, IET IMAGE PROCESS, V9, P866, DOI 10.1049/iet-ipr.2015.0184
   Chan T., 2006, SIAM J APPL MATH, V62, P1019
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dahl J, 2010, NUMER ALGORITHMS, V53, P67, DOI 10.1007/s11075-009-9310-3
   Thanh DNH, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107797
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Deng LJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141199
   Deng LJ, 2015, J COMPUT APPL MATH, V287, P88, DOI 10.1016/j.cam.2015.03.035
   Ding D, 2019, IEEE T IMAGE PROCESS, V28, P1705, DOI 10.1109/TIP.2018.2880681
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Facciolo G., 2006, P BR MACH VIS C, DOI [10.5244/C.20.107, DOI 10.5244/C.20.107]
   Farrell J.E., 1999, Color Imaging: Vision and Technology, P285
   Grossauer H, 2004, LECT NOTES COMPUT SC, V3022, P214
   Grossauer H, 2003, LECT NOTES COMPUT SC, V2695, P225
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Huang J, 2019, IEEE T GEOSCI REMOTE, V57, P2419, DOI 10.1109/TGRS.2018.2873326
   Ji TY, 2016, INFORM SCIENCES, V326, P243, DOI 10.1016/j.ins.2015.07.049
   Jin KH, 2015, IEEE T IMAGE PROCESS, V24, P3498, DOI 10.1109/TIP.2015.2446943
   Kumar V, 2016, IEEE T IMAGE PROCESS, V25, P5212, DOI 10.1109/TIP.2016.2605919
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Le Meur O, 2013, IEEE T IMAGE PROCESS, V22, P3779, DOI 10.1109/TIP.2013.2261308
   Le Meur O, 2012, LECT NOTES COMPUT SC, V7577, P554, DOI 10.1007/978-3-642-33783-3_40
   Lee JH, 2016, PROC CVPR IEEE, P2727, DOI 10.1109/CVPR.2016.298
   Li F, 2012, IEEE SIGNAL PROC LET, V19, P555, DOI 10.1109/LSP.2012.2206582
   Li JJ, 2020, IEEE COMPUT SOC CONF, P1894, DOI 10.1109/CVPRW50498.2020.00239
   Li P, 2013, IET IMAGE PROCESS, V7, P260, DOI 10.1049/iet-ipr.2012.0592
   Li ZD, 2015, IEEE T IMAGE PROCESS, V24, P1138, DOI 10.1109/TIP.2014.2383322
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   MARINESCU DC, 1987, INFORM SCIENCES, V43, P3, DOI 10.1016/0020-0255(87)90029-6
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   Ogawa T, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-179
   Oh J, 2014, INFORM SCIENCES, V280, P261, DOI 10.1016/j.ins.2014.05.003
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ram S, 2014, IEEE SW SYMP IMAG, P121, DOI 10.1109/SSIAI.2014.6806044
   Ringholmt T, 2018, SIAM J IMAGING SCI, V11, P2665, DOI 10.1137/17M1162354
   Ruzic T, 2015, IEEE T IMAGE PROCESS, V24, P444, DOI 10.1109/TIP.2014.2372479
   Shao H, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115929
   Siegel Sidney, 1988, Nonparametric statistics for the behavioral sciences
   Song XN, 2020, INFORM SCIENCES, V510, P50, DOI 10.1016/j.ins.2019.09.012
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Wan W, 2020, APPL MATH MODEL, V87, P317, DOI 10.1016/j.apm.2020.05.030
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Wang YT, 2019, SIGNAL PROCESS-IMAGE, V73, P96, DOI 10.1016/j.image.2018.11.008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Wu JY, 2006, INT C PATT RECOG, P810
   Xiang S, 2019, SIGNAL PROCESS-IMAGE, V71, P56, DOI 10.1016/j.image.2018.07.005
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yang JH, 2020, J COMPUT APPL MATH, V363, P124, DOI 10.1016/j.cam.2019.06.004
   Yang L, 2016, INT J RADIAT ONCOL, V96, pE621, DOI 10.1016/j.ijrobp.2016.06.2186
   Yang XH, 2019, SIGNAL PROCESS-IMAGE, V73, P84, DOI 10.1016/j.image.2018.02.006
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhou Y, 2016, INFORM SCIENCES, V360, P1, DOI 10.1016/j.ins.2016.03.027
   Zhu XS, 2018, SIGNAL PROCESS-IMAGE, V67, P90, DOI 10.1016/j.image.2018.05.015
NR 74
TC 5
Z9 5
U1 2
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103430
DI 10.1016/j.jvcir.2021.103430
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200006
DA 2024-07-18
ER

PT J
AU Beddiar, DR
   Oussalah, M
   Nini, B
AF Beddiar, Djamila Romaissa
   Oussalah, Mourad
   Nini, Brahim
TI Fall detection using body geometry and human pose estimation in video
   sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Body geometry; Elderly assistance; Fall detection; Pose estimation;
   Video sequence
AB According to the World Health Organization, falling is a significant health problem that causes thousands of deaths every year. Fall detection and fall prediction tasks enable accurate medical assistance to vulnerable populations whenever required, allowing local authorities to predict daily health care resources and to reduce fall damages accordingly. We present in this paper, a fall detection approach that explores human body geometry available at different frames of the video sequence. Especially, pose estimation, the angle and the distance between the vector formed by the head-centroid of the identified facial image and the center hip of the body, and the vector aligned with the horizontal axis of the center hip, are employed to construct new distinctive image features. A two-class Support Vector Machine (SVM) classifier and a Temporal Convolution Network (TCN) are trained on the newly constructed feature images. At the same time, a Long-Short-Term Memory (LSTM) network is trained on the calculated angle and distance sequences to classify fall and non-fall activities. We perform experiments on the Le2i FD dataset and the UR FD dataset, where we also propose a cross-dataset evaluation. The results demonstrate the effectiveness and efficiency of the developed approach.
C1 [Beddiar, Djamila Romaissa; Oussalah, Mourad] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
   [Beddiar, Djamila Romaissa; Nini, Brahim] Univ Laarbi Ben Mhidi, Res Lab Comp Sci Complex Syst, Oum El Bouaghi, Algeria.
C3 University of Oulu; Universite d'Oum El Bouaghi
RP Beddiar, DR (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
EM Djamila.Beddiar@oulu.fi
RI Beddiar, Romaissa/E-1591-2017
OI Beddiar, Romaissa/0000-0002-1371-3881
FU European Youngsters Resilience through Serious Games, under the Internal
   Security Fund-Police action [823701-ISFP-2017-AG-RAD]
FX This work is supported by the European Youngsters Resilience through
   Serious Games, under the Internal Security Fund-Police action:
   823701-ISFP-2017-AG-RAD grant, which is gratefully acknowledged.
CR Adhikari Kripesh., 2019, International Journal of Computer and Systems Engineering, V13, P255
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Angelini F, 2020, IEEE T MULTIMEDIA, V22, P1433, DOI 10.1109/TMM.2019.2944745
   Aziz O, 2011, IEEE T NEUR SYS REH, V19, P670, DOI 10.1109/TNSRE.2011.2162250
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Bhandari S, 2017, IEEE GLOB CONF CONSU
   Charfi I, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041106
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Ciabattoni L, 2018, 2018 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P130, DOI 10.1109/ZINC.2018.8448970
   Dentamaro V, 2021, INT C PATT RECOG, P2328, DOI 10.1109/ICPR48806.2021.9413331
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Ezatzadeh S, 2017, 2017 9TH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT 2017), P93, DOI 10.1109/IKT.2017.8258624
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Florence CS, 2018, J AM GERIATR SOC, V66, P693, DOI 10.1111/jgs.15304
   Geertsema EE, 2019, J BIOMECH, V88, P25, DOI 10.1016/j.jbiomech.2019.03.007
   Han Q, 2020, IEEE ACCESS, V8, P17556, DOI 10.1109/ACCESS.2019.2962778
   Haque A, 2016, LECT NOTES COMPUT SC, V9905, P160, DOI 10.1007/978-3-319-46448-0_10
   Huang ZY, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON UNIVERSAL VILLAGE (IEEE UV 2018)
   Iscen A., 2014, P IEEE C COMP VIS PA, P794
   Khan SS, 2017, MED ENG PHYS, V39, P12, DOI 10.1016/j.medengphy.2016.10.014
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lee JK, 2015, IEEE T NEUR SYS REH, V23, P258, DOI 10.1109/TNSRE.2014.2357806
   Liu Y, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00064
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Luo CW, 2019, IEEE T MULTIMEDIA, V21, P2473, DOI 10.1109/TMM.2019.2903724
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Putra IPES, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010020
   Ramachandran A, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/2167160
   Remy P., 2020, Temporal Convolutional Networks for Keras
   Romaissa B.D., 2020, INT CONF IMAG PROC, P1, DOI DOI 10.1109/ipta50016.2020.9286456
   Sabatini AM, 2016, IEEE T NEUR SYS REH, V24, P774, DOI 10.1109/TNSRE.2015.2460373
   Tuner R.W, 2015, FALLS OLDER ADULTS E
   Nguyen VA, 2016, PROCEEDINGS OF THE SEVENTH SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2016), P339, DOI 10.1145/3011077.3011103
   Wang BH, 2020, IEEE ACCESS, V8, P103443, DOI 10.1109/ACCESS.2020.2999503
   Wang CH, 2018, IEEE J BIOMED HEALTH, V22, P1929, DOI 10.1109/JBHI.2017.2778271
   Wang SM, 2012, ROBOTICS: SCIENCE AND SYSTEMS VII, P345
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   World Health Organization, 2007, WHO global report on falls prevention in older age Internet
   Wu G, 2008, IEEE T NEUR SYS REH, V16, P178, DOI 10.1109/TNSRE.2007.916282
   Yajai A, 2017, J VIS COMMUN IMAGE R, V49, P257, DOI 10.1016/j.jvcir.2017.08.008
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zerrouki N, 2018, MULTIMED TOOLS APPL, V77, P6405, DOI 10.1007/s11042-017-4549-5
NR 47
TC 10
Z9 10
U1 4
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103407
DI 10.1016/j.jvcir.2021.103407
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I8FF
UT WOS:000779649200003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mo, YZ
   Li, CF
   Zheng, YH
   Wu, XJ
AF Mo, Yaozong
   Li, Chaofeng
   Zheng, Yuhui
   Wu, Xiaojun
TI DCA-CycleGAN: Unsupervised single image dehazing using Dark Channel
   Attention optimized CycleGAN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Adversarial network; Dark channel attention; Local
   discriminator
ID VISIBILITY; HAZE
AB Single image dehazing has great significance in computer vision. In this paper, we propose a novel unsupervised Dark Channel Attention optimized CycleGAN (DCA-CycleGAN) to deal with the challenging scene with uneven and dense haze concentration. Firstly, the DCA-CycleGAN adopts the dark channel as input and then generate attention through a DCA subnetwork to handle the nonhomogeneous haze. Secondly, in addition to the conventional global discriminator, we also leverage two local discriminators to enhance the dehazing performance on the local dense haze, and a new local adversarial loss calculated strategy is been proposed. Specifically, the dehazing generator consists of two subnetworks: an auto-encoder and a dark channel attention subnetwork. The auto-encoder consists of an encoder, a feature transformation module, and a decoder. The dark channel attention subnetwork has the same structure as the encoder and the feature transformation module to ensure the same receptive field, which utilizes the dark channel to generate attention map and fine-tune the auto-encoder. Experimental results against several state-of-the-art methods demonstrate that our method can generate better visual effects, and is effective.
C1 [Mo, Yaozong; Li, Chaofeng] Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 214063, Peoples R China.
   [Zheng, Yuhui] Nanjing Univ Inform Sci & Technol, Coll Comp & Software, Nanjing 210044, Peoples R China.
   [Wu, Xiaojun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
C3 Shanghai Maritime University; Jiangnan University
RP Li, CF (corresponding author), Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 214063, Peoples R China.
EM wxlichaofeng@126.com
FU National Natural Science Foundation of China [61771223, 62176150]
FX Acknowledgment We thank the financial support of The National Natural
   Science Foundation of China (No. 61771223, No. 62176150) .
CR Ancuti CO, 2011, LECT NOTES COMPUT SC, V6493, P501
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dudhane A, 2022, IEEE T EM TOP COMP I, V6, P159, DOI 10.1109/TETCI.2020.3035407
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   King DB, 2015, ACS SYM SER, V1214, P1
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Kumar A, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103122
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li LRH, 2020, IEEE T IMAGE PROCESS, V29, P2766, DOI 10.1109/TIP.2019.2952690
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   McCartney E.J., 1976, Optics of the atmosphere: Scattering by molecules and particles, P421
   Mehra A, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103137
   Mei KF, 2019, LECT NOTES COMPUT SC, V11361, P203, DOI 10.1007/978-3-030-20887-5_13
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taigman Y., 2016, INT C LEARN REPR
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan JJ, 2020, IEEE ACCESS, V8, P25431, DOI 10.1109/ACCESS.2020.2971092
   Yang D., 2018, PROC EUR C COMPUT VI, P702
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhao SY, 2021, IEEE T IMAGE PROCESS, V30, P3391, DOI 10.1109/TIP.2021.3060873
   Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 15
Z9 16
U1 3
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103431
DI 10.1016/j.jvcir.2021.103431
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I8FF
UT WOS:000779649200004
DA 2024-07-18
ER

PT J
AU Qiao, T
   Zhao, QR
   Zheng, N
   Xu, M
   Zhang, L
AF Qiao, Tong
   Zhao, Qianru
   Zheng, Ning
   Xu, Ming
   Zhang, Li
TI Geographical position spoofing detection based on camera sensor
   fingerprint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geographical position spoofing detection; Source identification; Camera
   sensor fingerprint
ID IDENTIFICATION; DEVICE
AB Currently, position check-in on mobile devices has become a fashionable social activity. Meanwhile, criminals probably tamper the geographical position (geo-position) information to provide an alibi. Therefore, it is of importance to identify the authenticity of geo-position. To our knowledge, many current methods for geo-position spoofing detection mainly rely on geo-position information in the database. However, these methods possibly fail in the case of missing prior information or lacking rich training samples. To address that challenge, this paper proposes an alternative manner for detecting the geo-position spoofing via camera sensor fingerprint. In particular, the camera sensor fingerprint is first extracted through the images posted by an inquiry user based on the well-designed denoising filter. Second, the authenticity of the geo-position is verified by comparing the consistency of the residual noise from newly-posted images with position check-in and the unique camera sensor fingerprint from an inquiry user. Finally, the extensive experiments are conducted on the image database, that empirically indicates the relevance of our proposed simple but effective method.
C1 [Qiao, Tong; Zheng, Ning; Xu, Ming; Zhang, Li] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
   [Zhao, Qianru; Zheng, Ning] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Qiao, T (corresponding author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
EM tong.qiao@hdu.edu.cn
OI Qiao, Tong/0000-0003-4912-2132
FU Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK219909299001-007]; Public Research Project of Zhejiang Province
   [LGG19F020015]
FX This work was funded by the Fundamental Research Funds for the
   Provincial Universities of Zhejiang under grant No. GK219909299001-007,
   the Public Research Project of Zhejiang Province under grant No.
   LGG19F020015.
CR [Anonymous], 2017, Elect. Imaging
   [Anonymous], 2009, MEDIA FORENSICS SECU, DOI DOI 10.1117/12.805701
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Carbunar B, 2012, IEEE INT CONF MOB, P182, DOI 10.1109/MASS.2012.6502516
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Ding C., 2018, INT C COLL COMP NETW, P138
   Efstathiades H, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P218, DOI 10.1145/2808797.2808877
   Georgiev P, 2014, P INT AAAI C WEB SOC, V8, P141
   Goljan M, 2009, LECT NOTES COMPUT SC, V5450, P454, DOI 10.1007/978-3-642-04438-0_38
   Jiang X, 2019, LECT NOTES COMPUT SC, V11902, P52, DOI 10.1007/978-3-030-34110-7_5
   Jurdak R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131469
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kay Steven M, 1998, DETECTION THEORY
   Li GL, 2014, PROC INT CONF DATA, P880, DOI 10.1109/ICDE.2014.6816708
   Lin XF, 2016, IEEE SIGNAL PROC LET, V23, P381, DOI 10.1109/LSP.2016.2521349
   Mahmud J, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2528548
   Marra F, 2017, IEEE T INF FOREN SEC, V12, P2197, DOI 10.1109/TIFS.2017.2701335
   Mihçak MK, 1999, INT CONF ACOUST SPEE, P3253, DOI 10.1109/ICASSP.1999.757535
   Papalexakis E, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P551, DOI 10.1145/2567948.2576950
   Qiao T, 2018, IEEE ACCESS, V6, P78038, DOI 10.1109/ACCESS.2018.2884710
   Qiao T, 2017, SIGNAL PROCESS-IMAGE, V52, P74, DOI 10.1016/j.image.2016.12.011
   Qiao T, 2015, IEEE IMAGE PROC, P3812, DOI 10.1109/ICIP.2015.7351518
   Ryoo K, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P643, DOI 10.1145/2567948.2579236
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Tuama A, 2016, IEEE INT WORKS INFOR
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Zeng H, 2020, IEEE ACCESS, V8, P18874, DOI 10.1109/ACCESS.2020.2968855
   Zhao B, 2017, ANN GIS, V23, P1, DOI 10.1080/19475683.2017.1280536
   Zhao Q., 2020, P 2020 4 INT C VIS I, P1
   Zhao YH, 2019, MULTIMED TOOLS APPL, V78, P8247, DOI 10.1007/s11042-018-6809-4
NR 30
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103320
DI 10.1016/j.jvcir.2021.103320
EA NOV 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD4BM
UT WOS:000722656700004
DA 2024-07-18
ER

PT J
AU Liu, GQ
   Wu, JZ
AF Liu, Guiqing
   Wu, Jinzhao
TI Unsupervised person re-identification by Intra-Inter Camera Affinity
   Domain Adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intra-Inter Camera Affinity Domain Adaptation; Person re-identification;
   Generative adversarial learning; Affinity transfer learning
ID CONFIDENCE
AB Person re-identification (re-ID) based on unsupervised domain adaptation intends to distill knowledge from annotated source dataset to identify target persons in another dataset. Although the advanced UDA re-ID models are dominated by pseudo-label methods, they almost transform images from various camera views into the same feature space, without considering the camera distribution gaps, which may lead to generate considerably noisy pseudo-labels. In this study, we develop an Intra-Inter Camera Affinity Domain Adaptation (I(2)CADA) to tackle these problems for UDA person re-ID. Precisely, I(2)CADA framework is composed of two modules. The first one is generative adversarial learning module, aiming to train a feature extractor that can map target data to source feature space by supervised learning and adversarial learning, which can relieve the distribution gap between different datasets (domains). The second one is affinity transfer learning module, which simultaneously considers intra-camera clustering and inter-camera separation among persons with similar appearances in the target domain, thus mitigating the distribution inconsistency among person images collected from multiple target camera views. Besides, comprehensive experiments exhibit that I(2)CADA outperforms the existing UDA person re-identification approaches.
C1 [Liu, Guiqing; Wu, Jinzhao] Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu 610041, Sichuan, Peoples R China.
   [Liu, Guiqing] Guangxi Univ Nationalities, Coll ASEAN Studies, Nanning 530006, Peoples R China.
   [Wu, Jinzhao] Guangxi Univ, Coll Math & Informat Sci, Nanning 530004, Peoples R China.
   [Liu, Guiqing; Wu, Jinzhao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chengdu Institute of Computer Application,
   CAS; Guangxi Minzu University; Guangxi University; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Wu, JZ (corresponding author), Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu 610041, Sichuan, Peoples R China.
EM wuasean@163.com
FU National Natural Science Foundation of China Error analysis and control
   of semi-algebraic model detection method [61772006]; Science and
   Technology Major Project of Guangxi, China Research and Application
   Demonstration of Key Technologies [AA17204096, AB17129012]; Special Fund
   for Bagui Schol-ars of Guangxi Control system design and verification
   (2017); Promotion Project of Basic Faculties for Young and Middle-aged
   College Teachers in Guangxi, China [2021KY0168]; Talent Introduction
   Project of Guangxi University for Nationalities, China [2020KJQD05]
FX This research has been financed by the National Natural Science
   Foundation of China Error analysis and control of semi-algebraic model
   detection method (61772006) , the Science and Technology Major Project
   of Guangxi, China Research and Application Demonstration of Key
   Technologies for Intelligent Ship Networking in Beibu Gulf (AA17204096)
   , the Key Research and Development Project of Guangxi DPA-proof full
   asynchronous RSA security crypto chip: design methods, tools and
   prototypes (AB17129012) , the Special Fund for Bagui Schol-ars of
   Guangxi Control system design and verification (2017) , and the
   Promotion Project of Basic Faculties for Young and Middle-aged College
   Teachers in Guangxi, China (2021KY0168) , the Talent Introduction
   Project of Guangxi University for Nationalities, China (2020KJQD05) .
   This research has been financed by the National Natural Science
   Foundation of China Error analysis and control of semi-algebraic model
   detection method (61772006) , the Science and Technology Major Project
   of Guangxi, China Research and Application Demonstration of Key
   Technologies for Intelligent Ship Networking in Beibu Gulf (AA17204096)
   , the Key Research and Development Project of Guangxi DPA-proof full
   asynchronous RSA security crypto chip: design methods, tools and
   prototypes (AB17129012) , the Special Fund for Bagui Schol-ars of
   Guangxi Control system design and verification (2017) , and the
   Promotion Project of Basic Faculties for Young and Middle-aged College
   Teachers in Guangxi, China (2021KY0168) , the Talent Introduction
   Project of Guangxi University for Nationalities, China (2020KJQD05) .
CR Bai Z., 2021, ARXIV PREPRINT ARXIV
   Chang XB, 2019, AAAI CONF ARTIF INTE, P3288
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chuanchen Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P224, DOI 10.1007/978-3-030-58555-6_14
   DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755
   Delany SJ, 2005, LECT NOTES ARTIF INT, V3620, P177, DOI 10.1007/11536406_16
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding C., 2020, IEEE T PATTERN ANAL
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Feng H, 2021, IEEE T IMAGE PROCESS, V30, P2898, DOI 10.1109/TIP.2021.3056212
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ge Y., 2020, INT C LEARNING REPRE
   Ge Y., 2020, P NIPS, V33, P11309
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gretton Arthur, 2008, CoRR
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li R., 2020, P IEEE CVF C COMP VI, P9641, DOI DOI 10.1109/CVPR42600.2020.00966
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long Mingsheng, 2016, ARXIV PREPRINT ARXIV
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Qi L, 2019, IEEE I CONF COMP VIS, P8079, DOI 10.1109/ICCV.2019.00817
   Ren P., 2018, ARXIV PREPRINT ARXIV
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang ML, 2021, AAAI CONF ARTIF INTE, V35, P2764
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu AC, 2019, IEEE I CONF COMP VIS, P6921, DOI 10.1109/ICCV.2019.00702
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xuan SY, 2021, PROC CVPR IEEE, P11921, DOI 10.1109/CVPR46437.2021.01175
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yang FX, 2020, AAAI CONF ARTIF INTE, V34, P12597
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
   Zou Yixiong, 2020, ARXIV200710315
NR 63
TC 5
Z9 5
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103310
DI 10.1016/j.jvcir.2021.103310
EA SEP 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900008
DA 2024-07-18
ER

PT J
AU Han, H
   Zhuo, L
   Li, JF
   Zhang, J
   Wang, M
AF Han, Han
   Zhuo, Li
   Li, Jiafeng
   Zhang, Jing
   Wang, Meng
TI Blind image quality assessment with channel attention based deep
   residual network and extended LargeVis dimensionality reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image quality assessment; ResNet-50; Channel attention mechanism;
   LargeVis dimensionality reduction
ID NATURAL SCENE STATISTICS
AB Image Quality Assessment (IQA) is one of the fundamental problems in the fields of image processing, image/ video coding and transmission, and so on. In this paper, a Blind Image Quality Assessment (BIQA) approach with channel attention based deep Residual Network (ResNet)and extended LargeVis dimensionality reduction is proposed. Firstly, ResNet50 with channel attention mechanism is used as the backbone network to extract the deep features from the image. In order to reduce the dimensionality of the deep features, LargeVis, which is originally designed for the visualization of large scale high-dimensional data, is extended by using Support Vector Regression (SVR) to perform on a single feature vector data. The extended LargeVis can remove the redundant information of the deep features so as to obtain a low-dimensional and discriminative feature rep-resentation. Finally, the quality prediction model is established by using SVR as the fitting method. The low-dimensional feature representation and quality score of the image form the pair-wise data samples to train the fitting model. Experimental results on authentic distortions datasets and synthetic distortions datasets show that our proposed method can achieve superior performance compared with the state-of-the-art methods.
C1 [Han, Han; Zhuo, Li; Li, Jiafeng; Zhang, Jing; Wang, Meng] Beijing Univ Technol, Fac Informat, Beijing 100124, Peoples R China.
   [Han, Han; Zhuo, Li; Li, Jiafeng; Zhang, Jing; Wang, Meng] Beijing Univ Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing 100124, Peoples R China.
   [Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.
C3 Beijing University of Technology; Beijing University of Technology;
   Hefei University of Technology
RP Zhuo, L (corresponding author), Beijing Univ Technol, Fac Informat, Beijing 100124, Peoples R China.
EM zhuoli@bjut.edu.cn
RI Wang, Siyi/JNT-2690-2023; LI, MINGZE/KEI-2317-2024; li,
   jiafeng/KVY-4468-2024
OI ZHANG, JING/0000-0003-1290-0738
FU National Natural Science Foundation of China [61871006, 61971016];
   Beijing Municipal Education Commission Cooperation Beijing Natural
   Science Foundation [KZ201810005002, KZ201910005007]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Number 61871006, 61971016), and Beijing Municipal Education
   Commission Cooperation Beijing Natural Science Foundation (No.
   KZ201810005002, No. KZ201910005007).
CR [Anonymous], 2020, IEEE T CIRC SYST VID, DOI DOI 10.1109/TCSVT.2018.2886771
   [Anonymous], 2013, The business value report of 2013 Chinese Super League
   Ba J., 2014, ARXIV PREPRINT ARXIV
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bovik AC, 2013, P IEEE, V101, P2008, DOI 10.1109/JPROC.2013.2257632
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Gao XB, 2013, IEEE T NEUR NET LEAR, V24, P2013, DOI 10.1109/TNNLS.2013.2271356
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hu J, 2020, IEEE T PATTERN ANAL, V42, P2011, DOI 10.1109/TPAMI.2019.2913372
   Ji Shihao, 2015, ARXIV151106909
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang YD, 2016, LECT NOTES COMPUT SC, V9909, P3, DOI 10.1007/978-3-319-46454-1_1
   Lin H., 2018, CORR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Liu X., 2017, Rankiqa: Learning from rankings for no-reference image quality assessment
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mnih V, 2014, ADV NEUR IN, V27
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Otroshi-Shahreza H, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P637, DOI 10.1109/ISTEL.2018.8661024
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sak H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1468
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Simonyan K., 2014, 14091556 ARXIV
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P287, DOI 10.1145/2872427.2883041
   Varga D, 2018, IEEE INT CON MULTI
   Wang SG, 2017, IEEE T CYBERNETICS, V47, P232, DOI 10.1109/TCYB.2015.2512852
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhu H., 2020, P IEEE CVF C COMP VI, P14143
   Zhuo Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174718
NR 52
TC 3
Z9 3
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103296
DI 10.1016/j.jvcir.2021.103296
EA AUG 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900002
DA 2024-07-18
ER

PT J
AU Zhang, SJ
   Zhang, Q
AF Zhang, Shujun
   Zhang, Qun
TI Sign language recognition based on global-local attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sign language recognition; 3D convolution network; Global-local
   attention; Time series modeling
AB Video-level sign language recognition is still a challenging task due to the influence of sign language-independent factors and timing requirements. This paper constructs a sign language recognition framework based on globallocal feature description, and proposes a three-dimensional residual global network model with attention layer and a local network model based on target detection. The global feature description is based on the whole video behavior for time series modeling. The improved timing conversion layer is used to explore the timing information of different periods and learn the video representations of different timings. In the local module the hand is located through the target detection network to highlight its key role in the whole sign language behavior, which strengthens the category differences, and compensates the global network. Experiments on two wellknown Chinese sign language datasets (SLR_Dataset and DEVSIGN_D) show that the proposed method can obtain higher recognition accuracy (respectively 89.2%, 91%) and better generalization performance.
C1 [Zhang, Shujun; Zhang, Qun] Qingdao Univ Sci & Technol, Coll Informat Sci & Technol, Qingdao 266061, Peoples R China.
C3 Qingdao University of Science & Technology
RP Zhang, Q (corresponding author), Qingdao Univ Sci & Technol, Coll Informat Sci & Technol, Qingdao 266061, Peoples R China.
EM zhangsj@qust.edu.cn; 1451187339@qq.com
FU National Natural Science Foundation of China [61702295, 61672305]; Key
   Research & Development Plan Project of Shandong Province, China
   [2017GGX10127]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61702295, No. 61672305) and the Key Research &
   Development Plan Project of Shandong Province, China (No.2017GGX10127).
CR Bowden R, 2016, P 7 WORKSH REPR PROC, P121
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Garcia B., 2016, Convolutional Neural Netw. Vis. Recognit., V2, P225
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang J, 2019, IEEE T CIRC SYST VID, V29, P2822, DOI 10.1109/TCSVT.2018.2870740
   Huang J, 2018, AAAI CONF ARTIF INTE, P2257
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Huang SL, 2018, IEEE SIGNAL PROC LET, V25, P442, DOI 10.1109/LSP.2018.2797228
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kim T, 2017, COMPUT SPEECH LANG, V46, P209, DOI 10.1016/j.csl.2017.05.009
   Köpüklü O, 2018, IEEE COMPUT SOC CONF, P2184, DOI 10.1109/CVPRW.2018.00284
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P8823, DOI 10.1007/s11042-017-4776-9
   Kumar P, 2018, INFORM SCIENCES, V428, P30, DOI 10.1016/j.ins.2017.10.046
   Kumar P, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P157, DOI 10.23919/MVA.2017.7986825
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li YA, 2018, IEEE T CIRC SYST VID, V28, P2956, DOI 10.1109/TCSVT.2017.2749509
   Li YN, 2016, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2016.7899602
   Liang ZJ, 2018, COMPUT J, V61, P1724, DOI 10.1093/comjnl/bxy049
   Liao YQ, 2019, IEEE ACCESS, V7, P38044, DOI 10.1109/ACCESS.2019.2904749
   Liu T, 2016, IEEE IMAGE PROC, P2871, DOI 10.1109/ICIP.2016.7532884
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Miao QG, 2017, IEEE INT CONF COMP V, P3047, DOI 10.1109/ICCVW.2017.360
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Mohammed AAQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235282
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schmid C., 2011, ACTION RECOGNITION D
   Shetty S., 2016, ARXIV PREPRINT ARXIV
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang A, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2735952
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H., 2016, ACM T ACCESS COMPUT, V8, P1, DOI DOI 10.1145/2897735
   Wang HJ, 2016, NEUROCOMPUTING, V175, P674, DOI 10.1016/j.neucom.2015.10.112
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L., 2016, P ECCV
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Ye YC, 2018, IEEE COMPUT SOC CONF, P2145, DOI 10.1109/CVPRW.2018.00280
   Zhou Y, 2010, STUDY ADAPTIVE PROBL
NR 44
TC 10
Z9 13
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103280
DI 10.1016/j.jvcir.2021.103280
EA AUG 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600009
DA 2024-07-18
ER

PT J
AU Chang, YL
   Li, SM
   Liu, AQ
   Jin, J
AF Chang, Yongli
   Li, Sumei
   Liu, Anqi
   Jin, Jie
TI Quality assessment of screen content images based on multi-stage
   dictionary learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Screen content images; Sparse dictionary;
   Hierarchical feature extraction
ID SIMILARITY; FEATURES
AB In this paper, we propose an effective method for quality assessment of screen content images (SCIs) based on multi-stage dictionary learning. To simulate the brain's layered processing of signals, we proposed a hierarchical feature extraction strategy, which is called multi-stage dictionary learning, to simulate the hierarchical information processing of brain. First, the standard deviation of normalized map obtained from training image is used to select the training data in a certain proportion, which can ensure the learning efficiency and reduce the training burden. Next, the reconstructed map is weighted as the input of the next -stage dictionary learning. Then using the trained dictionary, the sparse representation is applied to extract features. Meanwhile, considering that some important features may be ignored in the process of multi-stage dictionary learning, we use Log Gabor filter to extract feature maps, and then calculate the correlation between feature maps as another kind of compensation features. Final, for the two feature sets, we choose SVR and feature codebook to learn two objective scores, and then use the adaptive weighting strategy to get the final objective quality score. Experimental results show that the proposed method is superior to several mainstream SCIs metrics on two publicly available databases.
C1 [Chang, Yongli; Li, Sumei; Liu, Anqi; Jin, Jie] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Li, SM (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM chang_yli@163.com; lisumei@tju.edu.cn; liuanqi@tju.edu.cn;
   jinjie@tju.edu.cn
OI Li, Sumei/0000-0002-4793-3161
FU National Natural Science Founda-tion of China [61971306, 61520106002,
   61471262]
FX This work was supported by the National Natural Science Founda-tion of
   China under Grant 61971306, 61520106002, 61471262.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bai YQ, 2019, SIGNAL PROCESS, V161, P248, DOI 10.1016/j.sigpro.2019.03.013
   Ding X, 2019, J VIS COMMUN IMAGE R, V67, P1
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P2016, DOI 10.1109/TIP.2017.2669840
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Ji WP, 2019, J VIS COMMUN IMAGE R, V58, P195, DOI 10.1016/j.jvcir.2018.11.038
   Jiang QP, 2017, IEEE IMAGE PROC, P3160, DOI 10.1109/ICIP.2017.8296865
   Lin JX, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P292, DOI 10.1109/SIPROCESS.2018.8600420
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Ni ZK, 2016, IEEE IMAGE PROC, P81, DOI 10.1109/ICIP.2016.7532323
   Ni ZK, 2016, IEEE SIGNAL PROC LET, V23, P1394, DOI 10.1109/LSP.2016.2599294
   Oszust M, 2018, J VIS COMMUN IMAGE R, V56, P15, DOI 10.1016/j.jvcir.2018.08.019
   Rajchel M, 2021, SIGNAL IMAGE VIDEO P, V15, P83, DOI 10.1007/s11760-020-01725-0
   Ruidong Li, 2019, 2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP), P1010, DOI 10.1109/SIPROCESS.2019.8868389
   Shao F, 2018, IEEE T SYST MAN CY-S, V48, P1521, DOI 10.1109/TSMC.2017.2676180
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Wang SQ, 2018, IEEE COMPUT GRAPH, V38, P47, DOI 10.1109/MCG.2016.46
   Wang SQ, 2016, IEEE T CIRC SYST VID, V26, P1595, DOI 10.1109/TCSVT.2015.2461891
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang JC, 2018, SIGNAL PROCESS, V153, P336, DOI 10.1016/j.sigpro.2018.07.006
   Yue GH, 2019, DIGIT SIGNAL PROCESS, V91, P21, DOI 10.1016/j.dsp.2018.12.007
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zheng LR, 2019, IEEE T MULTIMEDIA, V21, P2057, DOI 10.1109/TMM.2019.2894939
   Zhou WJ, 2019, SIGNAL IMAGE VIDEO P, V13, P525, DOI 10.1007/s11760-018-1378-6
NR 28
TC 1
Z9 1
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103248
DI 10.1016/j.jvcir.2021.103248
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800008
DA 2024-07-18
ER

PT J
AU Zhao, TY
   Yuan, L
   Chi, YY
AF Zhao, Tieyu
   Yuan, Lin
   Chi, Yingying
TI Image encryption using linear weighted fractional-order transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fractional-order Fourier transform; Weighted fractional-order transform;
   Image encryption
ID FOURIER-TRANSFORM; COSINE; SINE; HARTLEY
AB As the linear weighted fractional-order Fourier transform (LWFRFT), an extension of the Fourier transform, has been widely studied, many linear weighted fractional-order transforms (LWFRTs) have been proposed consequently. Our research shows that the LWFRT has limitations when applied to image encryption. For example, its application to image encryption leads to the security risks of key invalidation. In this paper, we propose a new reformulation of the LWFRT which establishes the relation between many fractional-order transforms. With the help of the new reformulation, we point out the limitations of the LWFRT and analyze the reasons for key invalidation in image encryption. Finally, numerical simulation verifies our perspective.
C1 [Zhao, Tieyu; Chi, Yingying] Northeastern Univ, Informat Sci Teaching & Res Sect, Qinhuangdao 066004, Hebei, Peoples R China.
   [Yuan, Lin] Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.
C3 Northeastern University - China; Zhejiang Normal University
RP Zhao, TY (corresponding author), Northeastern Univ, Informat Sci Teaching & Res Sect, Qinhuangdao 066004, Hebei, Peoples R China.
EM zhaotieyu@neuq.edu.cn
FU National Natural Science Foundation of China [61702088]
FX The authors would like to thank the reviewers for their valuable
   comments. This study was supported by the National Natural Science
   Foundation of China (No. 61702088).
CR ALMEIDA LB, 1994, IEEE T SIGNAL PROCES, V42, P3084, DOI 10.1109/78.330368
   Cariolaro G, 1998, IEEE T SIGNAL PROCES, V46, P3206, DOI 10.1109/78.735297
   Kang XJ, 2016, IEEE T SIGNAL PROCES, V64, P3402, DOI 10.1109/TSP.2016.2544740
   Li J, 2018, CHINA COMMUN, V15, P147, DOI 10.1109/CC.2018.8456459
   Li Y., 2018, EURASIP J WIREL COMM, V2018, P1
   Lima JB, 2013, LINEAR ALGEBRA APPL, V438, P3217, DOI 10.1016/j.laa.2012.12.021
   Liu ST, 1997, J PHYS A-MATH GEN, V30, P973, DOI 10.1088/0305-4470/30/3/020
   Ma Y., 2019, CRYPTANALYSIS IMAGE CRYPTANALYSIS IMAGE
   Mei L, 2010, SCI CHINA INFORM SCI, V53, P1251, DOI 10.1007/s11432-010-0073-1
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Pei SC, 2002, IEEE T SIGNAL PROCES, V50, P1661, DOI 10.1109/TSP.2002.1011207
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P1198, DOI 10.1109/78.923302
   Pei SC, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, P179, DOI 10.1109/ISCAS.1999.778814
   Pei SC, 1998, IEEE T CIRCUITS-II, V45, P665, DOI 10.1109/82.686685
   Ran QW, 2014, OPT LASER ENG, V62, P80, DOI 10.1016/j.optlaseng.2014.05.008
   Ran QW, 2009, OPT LETT, V34, P1729, DOI 10.1364/OL.34.001729
   Ran QW, 2005, IEEE T SIGNAL PROCES, V53, P83, DOI 10.1109/TSP.2004.837397
   Santhanam B, 1996, IEEE T SIGNAL PROCES, V44, P994, DOI 10.1109/78.492554
   SHIH CC, 1995, OPT COMMUN, V118, P495, DOI 10.1016/0030-4018(95)00268-D
   Tao R, 2008, OPT LETT, V33, P581, DOI 10.1364/OL.33.000581
   Tao R, 2010, IEEE T SIGNAL PROCES, V58, P3912, DOI 10.1109/TSP.2010.2044288
   Tao R, 2009, OPT COMMUN, V282, P1531, DOI 10.1016/j.optcom.2008.12.070
   Yeh MH, 2003, IEEE T SIGNAL PROCES, V51, P889, DOI 10.1109/TSP.2002.808113
   Zhao TY, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/4789194
   Zhao TY, 2016, OPT COMMUN, V376, P47, DOI 10.1016/j.optcom.2016.05.016
   Zhu BH, 2000, OPT LETT, V25, P1159, DOI 10.1364/OL.25.001159
NR 26
TC 4
Z9 4
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103098
DI 10.1016/j.jvcir.2021.103098
EA APR 2021
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700007
DA 2024-07-18
ER

PT J
AU Yuan, F
   Xiao, FQ
   Zhang, KH
   Huang, YF
   Cheng, E
AF Yuan, Fei
   Xiao, Fengqi
   Zhang, Kaihan
   Huang, Yifan
   Cheng, En
TI Noise reduction for sonar images by statistical analysis and fields of
   experts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sonar image; Denoising; Gamma distribution; Fields of Experts
ID SEGMENTATION; MODEL
AB Sonar images are usually suffering from speckle noise which results in poor visual quality. In order to improve the sonar imaging quality, removing or reducing these speckle noises is a very important and arduous task. In this paper, the imaging principle and noise characteristics of the side-scan sonar (SSS) are analyzed, and five typical probability distribution functions are used to fit the seabed reverberation. Through experiment comparison, the Gamma distribution is selected to simulate the noise of the SSS image caused by the reverberation. Simultaneously, the fields of experts denoising algorithm based on the Gamma distribution (Gamma FoE) is proposed for SSS image denoising. In order to perceive and measure the denoising effect better, evaluation indexes of Fast Noise Variance Estimation (FNVE, an image noise estimation method) and Blind Referenceless Image Spatial Quality Evaluator (BRISQUE, an image quality evaluation method) are selected for image quality perception. The final results of the SSS image denoise experiment show that the Gamma FoE denoise algorithm has a better effect on SSS image denoise application than other denoise algorithms.
C1 [Yuan, Fei; Xiao, Fengqi; Zhang, Kaihan; Huang, Yifan; Cheng, En] Xiamen Univ, Lab Underwater Acoust Commun & Marine Informat Te, Minist Educ, Xiamen, Peoples R China.
C3 Xiamen University
RP Cheng, E (corresponding author), Xiamen Univ, Lab Underwater Acoust Commun & Marine Informat Te, Minist Educ, Xiamen, Peoples R China.
EM chengen@xmu.edu.cn
RI Xiao, Fengqi/AHD-3962-2022
OI Xiao, Fengqi/0000-0001-5721-3267; Huang, Yifan/0000-0002-6883-9158
FU National Natural Science Foundation of China [61871336, 61771412,
   62071401]; Fundamental Research Funds for the Central Universities,
   China [20720180068]
FX The authors would like to thank the National Natural Science Foundation
   of China (grant no 61871336, 61771412, and 62071401) and the Fundamental
   Research Funds for the Central Universities, China (grant no
   20720180068).
CR Aja-Fernández S, 2009, IMAGE VISION COMPUT, V27, P756, DOI 10.1016/j.imavis.2008.08.002
   ALEXANDROU D, 1992, J ACOUST SOC AM, V91, P1403, DOI 10.1121/1.402471
   Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   [Anonymous], 2016, IEEE INT CON MULTI, DOI DOI 10.1109/JET-CAS.2016.2547681
   [Anonymous], RAIRO RECH OPER
   [Anonymous], 2006, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2016.2621478
   [Anonymous], 2003, Advances in Neural Info. Processing Systems
   [Anonymous], 2019, IEEE T IMAGE PROCESS
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Bianchi T, 2013, DIGIT SIGNAL PROCESS, V23, P1353, DOI 10.1016/j.dsp.2013.04.011
   Chaillan F, 2007, SIGNAL PROCESS, V87, P762, DOI 10.1016/j.sigpro.2006.08.001
   Chao Huang, 2015, STUD COLL MATH, V18, P8
   Chen chun Lu, 2013, OCEAN SURV MAPP, V33, P35
   Chen WL, 2020, IEEE T CIRC SYST VID, V30, P334, DOI 10.1109/TCSVT.2019.2890878
   Chen YJ, 2014, IEEE SIGNAL PROC LET, V21, P1370, DOI 10.1109/LSP.2014.2337274
   Cozzolino D, 2014, IEEE GEOSCI REMOTE S, V11, P524, DOI 10.1109/LGRS.2013.2271650
   Dempster A. P., MAXIMUM LIKELIHOOD I
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gai S, 2019, IET SIGNAL PROCESS, V13, P133, DOI 10.1049/iet-spr.2018.5127
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Hefner BT, 2017, IEEE J OCEANIC ENG, V42, P1110, DOI 10.1109/JOE.2017.2702005
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Huang S, 2019, IMAGING SCI J, V67, P224, DOI 10.1080/13682199.2019.1612589
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Jin W J, 2012, J ZHEJIANG U TECHNOL, V45, P320
   Kawasaki Y, 2018, PROC INT WORKSH ADV
   Kim J, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/6590713
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li TT, 2018, IEEE INT C INT ROBOT, P134, DOI 10.1109/ICRIS.2018.00042
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Luan G.D., 2003, ACTA ACOUST SIN, P99
   Lucchetti A, 2012, CAN J FISH AQUAT SCI, V69, P1806, DOI 10.1139/f2012-107
   MIDDLETON D, 1967, IEEE T INFORM THEORY, V13, P372, DOI 10.1109/TIT.1967.1054044
   Mignotte M, 2000, IEEE T IMAGE PROCESS, V9, P1216, DOI 10.1109/83.847834
   Mignotte M, 1999, COMPUT VIS IMAGE UND, V76, P191, DOI 10.1006/cviu.1999.0804
   Mittal A., 2012, IEEE Signal processing letters, V20, P209
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Neal R., 1993, CRGTR931 U TOR DEP C
   Neal Radford M, 1993, PROBABILISTIC INFERE
   Niu Xiaohui, 2013, COMP INF SCI ICCIS 2
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rai HM, 2019, MEASUREMENT, V144, P72, DOI 10.1016/j.measurement.2019.05.028
   Roth S, 2005, PROC CVPR IEEE, P860
   Roth Stefan, 2007, HIGH ORDER MARKOV RA, V68
   Sun Zeng-Guo, 2013, ACTA PHYS SIN, V64, P81
   Suresh S, 2018, IEEE T GEOSCI REMOTE, V56, P4334, DOI 10.1109/TGRS.2018.2815281
   TRUONG TV, 1984, RAIRO-RECH OPER, V18, P297
   Wang FS, 2013, COMPUT J, V56, P1102, DOI 10.1093/comjnl/bxs141
   Wang Xin, 2018, Computer Engineering and Applications, V54, P198, DOI 10.3778/j.issn.1002-8331.1707-0161
   Woodford O.J., 2006, P 17 BRIT MACHINE VI, V3, P1109
   Wu D, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P389, DOI 10.1109/ICIVC.2018.8492877
   Yousefi A, 2015, IEEE ENG MED BIO, P7819, DOI 10.1109/EMBC.2015.7320205
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhao WZ, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2916976
   Zhou Qiang, 2017, J SIGNAL PROCESS, V33, P1003
NR 59
TC 19
Z9 22
U1 7
U2 49
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102995
DI 10.1016/j.jvcir.2020.102995
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I2ON
UT WOS:000779264200005
DA 2024-07-18
ER

PT J
AU Shahid, AR
   Khan, S
   Yan, H
AF Shahid, Ali Raza
   Khan, Sheheryar
   Yan, Hong
TI Contour and region harmonic features for sub-local facial expression
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contour description; Facial expression recognition; Local facial shape
   harmonics; Region description
ID DESCRIPTORS; 3D
AB Expression recognition relies on intensity, edges, and geometry that overlooks the actual shape curvatures of facial regions. This paper presents a novel two-stage approach to distinguish seven expressions on the basis of eleven different facial areas. The combination of contour and region harmonics is used to develop the interrelationship of sub-local areas in the human face for expression recognition. We applied a multi-class support vector machine (SVM) with subject dependent k-fold cross-validation to classify the human emotions into expressions. We tested our proposed method on three public facial expression datasets for sub-local regions in human face and achieved 94.90%, 93.43%, and 92.57% recognition rate for the CK+, CFEE, and MUG datasets respectively. Experiments show that the contour and region harmonics have high classification power and can be computed efficiently. Our method provides higher accuracy, less computing time, and less memory space than existing techniques, including deep learning.
C1 [Shahid, Ali Raza; Yan, Hong] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Shahid, Ali Raza] COMSATS Univ Islamabad, Elect & Comp Engn Dept, Islamabad, Pakistan.
   [Khan, Sheheryar] Chinese Univ Hong Kong, Dept Imaging & Intervent Radiol, Hong Kong, Peoples R China.
C3 City University of Hong Kong; COMSATS University Islamabad (CUI);
   Chinese University of Hong Kong
RP Shahid, AR (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.; Shahid, AR (corresponding author), COMSATS Univ Islamabad, Elect & Comp Engn Dept, Islamabad, Pakistan.
EM a.raza@my.cityu.edu.hk
RI Shahid, Ali Raza/ABE-6765-2020; khan, Sheheryar/JZD-4895-2024; khan,
   sheheryar/AAV-2517-2021
OI Shahid, Ali Raza/0000-0002-6877-1405; khan,
   sheheryar/0000-0002-1975-4334
FU Hong Kong Research Grants Council [C1007-15G]; City University of Hong
   Kong [9610034]
FX This work is supported by the Hong Kong Research Grants Council (Project
   C1007-15G) and City University of Hong Kong (Project 9610034).
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   [Anonymous], 1965, The expression of emotions in man and animal
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Braun M, 2019, J MULTIMODAL USER IN, V13, P71, DOI 10.1007/s12193-019-00301-2
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Delopoulos C., 2010, MUG FACIAL EXPRESSIO
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Fan XJ, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102659
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7921, DOI 10.1007/s11042-016-3428-9
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jia Q., 2016, Int J Aerosp Eng, V2016, P1
   Kanatani K, 2016, ADV COMPUT VIS PATT, P11, DOI 10.1007/978-3-319-48493-8_2
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Khan S, 2020, IEEE T AFFECT COMPUT, V11, P348, DOI 10.1109/TAFFC.2017.2780838
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   Lekdioui K, 2017, SIGNAL PROCESS-IMAGE, V58, P300, DOI 10.1016/j.image.2017.08.001
   Li H, 2015, PATTERN RECOGN, V48, P3895, DOI 10.1016/j.patcog.2015.06.002
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   da Silva FAM, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500194
   Mingqiang Yang., 2008, PATTERN RECOGN
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Narottambhai M., 2016, INT J COMPUTER APPL, V137, P16, DOI [DOI 10.5120/IJCA2016908782, 10.5120/ijca2016908782]
   Rehman ZU, 2019, EXPERT SYST APPL, V120, P461, DOI 10.1016/j.eswa.2018.12.008
   Rehman ZU, 2019, EXPERT SYST APPL, V118, P598, DOI 10.1016/j.eswa.2018.10.040
   Sadeghi H, 2019, J VIS COMMUN IMAGE R, V62, P152, DOI 10.1016/j.jvcir.2019.05.004
   Safar M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P141, DOI 10.1109/ICME.2000.869564
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Shawe-Taylor, 2014, SUPPORT VECTOR MACHI, DOI [10.1002/asia.201301696, DOI 10.1002/ASIA.201301696]
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wang FY, 2019, J VIS COMMUN IMAGE R, V59, P84, DOI 10.1016/j.jvcir.2018.11.010
   Wang LL, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102847
   Yan, HUMAN EXPRESSION REC, DOI [10.1117/12.2557450, DOI 10.1117/12.2557450]
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Yan Chenggang, 2020, IEEE Trans. Pattern Anal. Machine Intell.
   Yang HS, 1998, J VIS COMMUN IMAGE R, V9, P171, DOI 10.1006/jvci.1998.0384
   Yassine R, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Youssif AliaaA. A., 2011, Computer and Information Science, P115
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 50
TC 17
Z9 17
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102949
DI 10.1016/j.jvcir.2020.102949
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000004
DA 2024-07-18
ER

PT J
AU Yan, YY
   Xiang, GQ
   Li, Y
   Xie, XD
   Jia, HZ
AF Yan, Yunyao
   Xiang, Guoqing
   Li, Yuan
   Xie, Xiaodong
   Jia, Huizhu
TI An adaptive spatio-temporal perception aware quantization algorithm for
   AVS2
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive quantization; Perceptual video coding (PVC); Just noticeable
   distortion (JND); Spatially perceptual complexity; Temporally perceptual
   complexity; Subjective quality
AB Adaptive quantization proves to be an effective tool to improve coding performance. In this paper, we propose an adaptive spatiotemporal perception aware quantization algorithm to increase subjective coding performance. To measure the spatiotemporally perceptual redundancy, the perceptual complexity models are firstly established with spatial and temporal characteristics respectively. With the help of the models, the adaptive spatial and temporal quantization parameter (QP) offsets are then calculated for each coding tree unit (CTU), respectively. Finally, the perceptually optimal Lagrange multiplier of each CTU is determined with the spatial-temporal QP offset. Experimental results show that the proposed algorithm reduces 8.6% and 8.4% Bjontegaard-Delta Rate (BD-Rate) with Structural Similarity Index Metric (SSIM) in average over the second generation of Audio Video Coding Standard (AVS2) reference software RD17.0 in Low-Delay-P (LDP) and Random-Access (RA) configurations, respectively. The subjective assessment proves that the proposed algorithm can reduce the bitrates with the same subjective quality significantly.
C1 [Yan, Yunyao] Peking Univ, Sch Elect & Comp Engn, Shenzhen, Peoples R China.
   [Yan, Yunyao; Xiang, Guoqing; Li, Yuan; Xie, Xiaodong; Jia, Huizhu] Peking Univ, Natl Engn Lab Video Technol, Beijing, Peoples R China.
   [Yan, Yunyao] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Peking University; Peking University; Peng Cheng Laboratory
RP Jia, HZ (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing, Peoples R China.
EM yunyaoyan@pku.edu.cn; gqxiang@pku.edu.cn; yuanli@pku.edu.cn;
   dongxie@pku.edu.cn; hzjia@pku.edu.cn
RI liu, jianyang/JXL-6273-2024
CR [Anonymous], 2002, ITURBT50011, P500
   [Anonymous], 2000, FINAL REPORT VIDEO Q
   Bjontegaard G., 2001, CALCULATION AVERAGE
   He ZC, 2013, IEEE IMAGE PROC, P1515, DOI 10.1109/ICIP.2013.6738311
   Li S, 2016, IEEE T CIRC SYST VID, V26, P117, DOI 10.1109/TCSVT.2015.2450131
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tianwu Yang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P85, DOI 10.1109/ICME.2012.171
   Turk-Browne NB, 2005, J EXP PSYCHOL GEN, V134, P552, DOI 10.1037/0096-3445.134.4.552
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   Wu JJ, 2016, INT CONF ACOUST SPEE, P1581, DOI 10.1109/ICASSP.2016.7471943
   Xiang GQ, 2018, MULTIMED TOOLS APPL, V77, P14817, DOI 10.1007/s11042-017-5064-4
   Xiang GQ, 2018, J VIS COMMUN IMAGE R, V50, P280, DOI 10.1016/j.jvcir.2017.11.011
   Yan C., 2020, IEEE T PATTERN ANAL
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yeo CH, 2013, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2013.6637940
   Zheng X., 2014, COMMON TEST CONDITIO
   1993, ISOIECJTC1SC29WG11
NR 21
TC 2
Z9 2
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102917
DI 10.1016/j.jvcir.2020.102917
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200006
DA 2024-07-18
ER

PT J
AU Wang, XR
   Juang, J
   Chan, SH
AF Wang, Xiran
   Juang, Jason
   Chan, Stanley H.
TI Automatic foreground extraction from imperfect backgrounds using
   multi-agent consensus equilibrium
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Foreground extractionl; Alpha matting; Background subtraction; Video
   segmentation; Saliency detection; Plug-and-play ADMM; Consensus
   equilibrium
AB Extracting accurate foreground objects from a scene is an essential step for many video applications. Traditional background subtraction algorithms can generate coarse estimates, but generating high quality masks requires professional softwares with significant human interventions, e.g., providing trimaps or labeling key frames. We propose an automatic foreground extraction method in applications where a static but imperfect background is available. Examples include filming and surveillance where the background can be captured before the objects enter the scene or after they leave the scene. Our proposed method is very robust and produces significantly better estimates than state-of-the-art background subtraction, video segmentation and alpha matting methods. The key innovation of our method is a novel information fusion technique. The fusion framework allows us to integrate the individual strengths of alpha matting, background subtraction and image denoising to produce an overall better estimate. Such integration is particularly important when handling complex scenes with imperfect background. We show how the framework is developed, and how the individual components are built. Extensive experiments and ablation studies are conducted to evaluate the proposed method.
C1 [Wang, Xiran; Chan, Stanley H.] Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.
   [Juang, Jason] HypeVR, 7540 Metropolitan Dr, San Diego, CA 92108 USA.
C3 Purdue University System; Purdue University
RP Chan, SH (corresponding author), Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.
EM stanchan@purdue.edu
OI Chan, Stanley/0000-0001-5876-2073
FU National Science Foundation [CCF-1763896, CCF-1718007]
FX The authors thank the anonymous reviewers for valuable feedback. This
   work is supported, in part, by the National Science Foundation under
   grants CCF-1763896 and CCF-1718007.
CR Cho JH, 2011, 3DTV CONF
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Davis M, 2005, SCIENTIFIC PAPERS AND PRESENTATIONS, P11, DOI 10.1016/B978-012088424-7/50003-0
   Dehghan M., 2019, IEEE INT C ROB AUT I
   Dong S., 2018, P INT C WIR COMM SIG, P1
   Faktor Alon, 2014, BMVC
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Guo RQ, 2011, PROC CVPR IEEE
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82
   Javed S, 2018, 2018 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P836, DOI 10.1109/SSP.2018.8450718
   Lee YC, 2013, I SYMP CONSUM ELECTR, P3
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Li Y, 2008, IEEE ENG MED BIO, P439, DOI 10.1109/IEMBS.2008.4649184
   Märki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   Mahajan V, 2008, IEEE MILIT COMMUN C, P966
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Tang JW, 2019, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2019.00317
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang HZ, 2006, INT C PATT RECOG, P223
   Wang J, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P90, DOI 10.1109/ISDA.2007.66
   Wang W., 2019, ANN IEEE INT CONF SE
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang XR, 2017, INT CONF ACOUST SPEE, P1323, DOI 10.1109/ICASSP.2017.7952371
   Xi W., 2019, P IEEE INT C IM PROC
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 34
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102907
DI 10.1016/j.jvcir.2020.102907
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lu, CS
   Zhai, F
AF Lu, Congsheng
   Zhai, Feng
TI Weakly-supervised large-scale image modeling for sport scenes and its
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sport scene modeling; Weakly-supervised learning; MDA
ID CONVOLUTIONAL NEURAL-NETWORK; HIGHLIGHTS; EXTRACTION
AB Image modeling towards sport scenes plays an important role in sport image classification and analysis. Traditional algorithms for sport image modeling required carefully hand-crafted features, which cannot be popularized in practical application, especially with the emergence of massive-scale data. Weaklysupervised learning algorithms have shown effectiveness in modeling data with image-level labels. Thus, in this paper, we propose a weakly-supervised learning based method for sport image modeling without utilizing bounding box annotations, which can be used for various sport image applications. More specifically, we first collect large-scale sport images from existing datasets and Internet, and we annotate them at image-level labels. Subsequently, we leverage region proposal generation algorithm to select discriminative regions that can effectively represent the category of images. Each region is fed into a pre-trained CNN architecture to extract deep representation. Afterwards, we design an improved multiple discriminant analysis (MDA) algorithm to project these datapoints to a subspace that can more easily to distinguish different sport categories. Comprehensive experiments have shown the effectiveness and robustness of our proposed method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Lu, Congsheng] Haian Senior Sch Jiangsu Prov, Nantong 226600, Peoples R China.
   [Zhai, Feng] China Univ Min & Technol, Coll Phys Educ, Xuzhou 221000, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Lu, CS (corresponding author), Haian Senior Sch Jiangsu Prov, Nantong 226600, Peoples R China.
EM Congsheng_Lu@hotmail.com
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], EUR C COMP VIS
   Bertini M, 2005, PATTERN ANAL APPL, V7, P411, DOI 10.1007/s10044-004-0234-1
   Chen Y, 2016, J VIS COMMUN IMAGE R, V37, P3, DOI 10.1016/j.jvcir.2015.10.004
   Deng C, 2007, LOCALITY SENSITIVE D
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Li SJ, 2015, INT J COMPUT VISION, V113, P19, DOI 10.1007/s11263-014-0767-8
   Lin S., 2018, MULTITASK MIDLEVEL F
   Lu GF, 2012, INFORM SCIENCES, V193, P72, DOI 10.1016/j.ins.2012.01.015
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Redondo-Cabrera C., 2018, IEEE T IMAGE PROCESS, P1
   Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Silos E.D.L.C., 2014, IEEE INT C IM PROC
   Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361
   Wang F., 2005, INT MULT MOD C
   Wu J., 2006, INT MULT MOD C
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Yazdian-Dehkordi M, 2016, J VIS COMMUN IMAGE R, V37, P14, DOI 10.1016/j.jvcir.2015.06.015
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 31
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102718
DI 10.1016/j.jvcir.2019.102718
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900001
DA 2024-07-18
ER

PT J
AU Elayaperumal, D
   Joo, YH
AF Elayaperumal, Dinesh
   Joo, Young Hoon
TI Visual object tracking using sparse context-aware spatio-temporal
   correlation filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Context; ADMM; Spatio-temporal; l(1) regularization; Visual tracking;
   Correlation filter
AB This paper presents a novel sparse context-aware spatio-temporal correlation filter tracker (SCAST) method for robust visual object tracking. Different from the existing trackers, this paper introduce an l(1) multi-scale regularization parameter-based correlation filter that reduces the boundary effect due to partial occlusions, illumination and scale variations. At each iteration, the l(1) regularization parameter is updated through spatial knowledge of each correlation filter coefficient. Besides, the contextual information acquired from the target region can lead to determining the accurate localization of the target. Moreover, contextual information has combined with spatio-temporal factor to achieve the better performance. Further, an objective function is designed with system constraints to ensure the applicability of the model and the optimal solution is derived by utilizing the alternating direction method of multiplier, which leads to low computational cost. Finally, the feasibility and superiority of proposed tracker algorithm is evaluated through three benchmark dataset: OTB-2013, OTB-2015, and TempleColor-128. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Elayaperumal, Dinesh; Joo, Young Hoon] Kunsan Natl Univ, Sch IT Informat & Control Engn, 588 Daehak Ro, Gunsan Si 54150, Jeonbuk, South Korea.
C3 Kunsan National University
RP Joo, YH (corresponding author), Kunsan Natl Univ, Sch IT Informat & Control Engn, 588 Daehak Ro, Gunsan Si 54150, Jeonbuk, South Korea.
EM yhjoo@kunsan.ac.kr
RI ELAYAPERUMAL, DINESH/L-8840-2014; Joo, Young Hoon/AAU-7285-2020
OI ELAYAPERUMAL, DINESH/0000-0001-5219-1505; Joo, Young
   Hoon/0000-0002-4662-1916
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1A6A1A03013567,
   NRF-2018R1A2A2A14023632]; Korea Institute of Energy Technology
   Evaluation and Planning (KETEP); Ministry of Trade, Industry &
   Energy(MOTIE) of the Republic of Korea [20194030202300]
FX This work was partially supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2016R1A6A1A03013567, NRF-2018R1A2A2A14023632)
   and by the Korea Institute of Energy Technology Evaluation and Planning
   (KETEP) and the Ministry of Trade, Industry & Energy(MOTIE) of the
   Republic of Korea (No. 20194030202300).
CR [Anonymous], 2017, IEEE INT C COMP VIS
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen CLZ, 2015, PATTERN RECOGN, V48, P2885, DOI 10.1016/j.patcog.2015.01.025
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Gao JY, 2018, IEEE T IMAGE PROCESS, V27, P3074, DOI 10.1109/TIP.2018.2813166
   Gao L, 2018, J VIS COMMUN IMAGE R, V50, P74, DOI 10.1016/j.jvcir.2017.11.008
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010073
   Ij ZJ, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102602
   Ji ZJ, 2018, J VIS COMMUN IMAGE R, V55, P354, DOI 10.1016/j.jvcir.2018.06.017
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P1165, DOI 10.1109/TCE.2011.6018870
   Kim JS, 2010, INT J CONTROL AUTOM, V8, P967, DOI 10.1007/s12555-010-0505-0
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li DD, 2019, J VIS COMMUN IMAGE R, V58, P149, DOI 10.1016/j.jvcir.2018.11.036
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li GJ, 2018, J VIS COMMUN IMAGE R, V56, P92, DOI 10.1016/j.jvcir.2018.09.004
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu P, 2019, PATTERN RECOGN, V87, P216, DOI 10.1016/j.patcog.2018.10.013
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sui Y, 2015, IEEE T IMAGE PROCESS, V24, P4686, DOI 10.1109/TIP.2015.2462076
   Tian S, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102576
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang LF, 2019, PATTERN RECOGN, V91, P272, DOI 10.1016/j.patcog.2019.02.008
   Wang X., 2015, IEEE T PATTERN ANAL, V38, P2312
   Wang XY, 2014, IEEE ENER CONV, P17, DOI 10.1109/ECCE.2014.6953370
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu JH, 2019, J VIS COMMUN IMAGE R, V62, P182, DOI 10.1016/j.jvcir.2019.05.014
   Zhang BC, 2018, IEEE T IMAGE PROCESS, V27, P1038, DOI 10.1109/TIP.2017.2775060
   Zhang KH, 2018, PATTERN RECOGN, V83, P185, DOI 10.1016/j.patcog.2018.05.017
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zheng WW, 2018, J VIS COMMUN IMAGE R, V55, P688, DOI 10.1016/j.jvcir.2018.08.004
NR 50
TC 6
Z9 6
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102820
DI 10.1016/j.jvcir.2020.102820
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900024
DA 2024-07-18
ER

PT J
AU Wei, R
   Mi, L
   Hu, YS
   Chen, ZZ
AF Wei, Ran
   Mi, Li
   Hu, Yaosi
   Chen, Zhenzhong
TI Exploiting the local temporal information for video captioning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local temporal information; Video captioning; Sliding windows;
   Reinforcement learning
AB Typical video captioning methods are developed based on the encoder-decoder architecture. To better exploit the local temporal information, e.g., details about objects and their corresponding actions, we propose a reinforcement learning based method to predict the adaptive sliding window size sequentially for better event exploration. More specifically, we introduce the single Monte-Carlo sample to approximate the gradient of reward-based loss function. And the self-critical strategy is employed to estimate baseline reward to diminish the variance of gradients. Moreover, temporal attention is utilized to selectively focus on a subset of temporal frame representations while generating each word. In addition, to better initialize the decoder's state, we utilize the motion features extracted by 3D CNN5 with mean pooling to endow the decoder with the prior knowledge of the entire video. To evaluate the proposed method, experiments are performed on three public benchmark datasets: Microsoft Video Description Corpus (MSVD), MSR Video to Text challenge (MSR-VTT) and Charades. The experimental results demonstrate the effectiveness of our method by comparing with state-of-the-art methods. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wei, Ran; Mi, Li; Hu, Yaosi; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
EM zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015; wei, wei/HHR-8613-2022; wei,
   wei/IQW-1347-2023; Hu, Yaosi/GRY-6324-2022
OI Hu, Yaosi/0000-0003-2784-6738
FU National Key RD Program China [2017YFB1002202]
FX This work was supported by National Key R&D Program China under contract
   No. 2017YFB1002202.
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   [Anonymous], P INT LEARN REPR
   [Anonymous], 2016, P INT C LEARN REPR
   [Anonymous], N AM CHAPTER ASS COM
   [Anonymous], P 2017 C EMP METH NA
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], ARXIV150500521
   [Anonymous], ARXIV161102261
   [Anonymous], P INT C MACH LEARN
   [Anonymous], ARXIV150400325
   Bin Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P436, DOI 10.1145/2964284.2967258
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chen JW, 2019, AAAI CONF ARTIF INTE, P8167
   Chen S, 2019, J ENG-JOE, P2837, DOI 10.1049/joe.2018.8433
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang KC, 2019, AAAI CONF ARTIF INTE, P8271
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Jin Q, 2016, INTERSPEECH, P570, DOI 10.21437/Interspeech.2016-380
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Li XP, 2019, WORLD WIDE WEB, V22, P621, DOI 10.1007/s11280-018-0531-z
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Sutskever I, 2014, ADV NEUR IN, V27
   Sutton RS., 2020, REINFORCEMENT LEARNI
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu X, 2018, PROC CVPR IEEE, P6829, DOI 10.1109/CVPR.2018.00714
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yang ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1877, DOI 10.1145/3123266.3127904
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhang JC, 2019, PROC CVPR IEEE, P8319, DOI 10.1109/CVPR.2019.00852
NR 48
TC 9
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102751
DI 10.1016/j.jvcir.2020.102751
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800009
DA 2024-07-18
ER

PT J
AU Mei, JH
   Jiang, XD
   Cai, JF
AF Mei, Jianhan
   Jiang, Xudong
   Cai, Jianfei
TI Learning local feature representation from matching, clustering and
   spatial transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local image representation; Local feature learning; Convolutional Neural
   Network (CNN); Semi-supervised learning; Spatial transform
AB This paper focuses on learning the local image region representation via deep neural networks. Existing works mainly learn from matched corresponding image patches, with which the learned feature is too sensitive to the individual local patch matching result and cannot handle aggregation based tasks such as image level retrieval. Thus, we propose to use both the matched corresponding image patches and the clustering result as labels for the network training. To resolve the inconsistency between the matched correspondences and clustering results, we propose a semi-supervised iterative training scheme together with a dual margins loss. Moreover, a jointly learned spatial transform prediction network is utilized to obtain better spatial transform invariance of the learned local features. Using SIFT as the label initializer, experimental results show the comparable or even better performance than the hand-crafted feature, which sheds lights on learning local feature representation in an unsupervised or weakly supervised manner. (C) 019 Elsevier Inc. All rights reserved.
C1 [Mei, Jianhan; Jiang, Xudong; Cai, Jianfei] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University
RP Jiang, XD (corresponding author), Nanyang Technol Univ, Singapore, Singapore.
EM exdjiang@ntu.edu.sg
RI Jiang, Xudong/B-1555-2008; Cai, Jianfei/A-3691-2011
OI Jiang, Xudong/0000-0002-9104-2315; Mei, jianhan/0000-0002-3510-2897;
   Cai, Jianfei/0000-0002-9444-3763
FU National Research Foundation, Singapore; Infocomm Media Development
   Authority, Singapore; MoE Tier-1 Grant of Singapore [RG28/18]; Nanyang
   Technological University (NTU) Singapore; University of North Carolina
   (UNC) at Chapel Hill; National Research Foundation, Prime Minister's
   Office, Singapore under its International Research Centres in Singapore
   Funding Initiative
FX This research was carried out at the Rapid-Rich Object Search (ROSE) Lab
   at the Nanyang Technological University, Singapore. The ROSE Lab is
   supported by the National Research Foundation, Singapore, and the
   Infocomm Media Development Authority, Singapore. This research is also
   supported by MoE Tier-1 Grant (RG28/18) of Singapore. And the research
   is also supported by the BeingTogether Centre, a collaboration between
   Nanyang Technological University (NTU) Singapore and University of North
   Carolina (UNC) at Chapel Hill. The BeingTogether Centre is supported by
   the National Research Foundation, Prime Minister's Office, Singapore
   under its International Research Centres in Singapore Funding
   Initiative.
CR [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], ARXIV160105030
   [Anonymous], P 17 ANN C NEUR INF
   Arandjelovic R., 2013, INT C COMP VIS PATT
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bar-Hillel A., 2003, ICML, P11
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bilenko M., 2004, INT C MACH LEARN ICM
   Campello RJGB, 2013, DATA MIN KNOWL DISC, V27, P344, DOI 10.1007/s10618-013-0311-4
   Chen CY, 2017, J VIS COMMUN IMAGE R, V48, P16, DOI 10.1016/j.jvcir.2017.06.002
   Dai J., 2017, Deformable Convolutional Networks
   Davis J. V., 2007, ICML, P209
   Fischler M., 1981, COMMUN ACM
   Han X., 2015, INT C COMP VIS PATT
   Jacobs A. K. D. W., 2016, INT C COMP VIS PATT
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Lelis L, 2009, IEEE DATA MINING, P842, DOI 10.1109/ICDM.2009.143
   Lowe D. G., COMPUT VIS IJCV
   Perronnin F., 2010, INT C COMP VIS PATT
   Philbin J., 2010, EUR C COMP VIS ECCV
   Philbin J., 2007, INT C COMP VIS PATT
   Rangapuram S. S., CONSTRAINED 1 SPECTR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ruiz C, 2007, LECT NOTES ARTIF INT, V4482, P216
   Schonberger J. L., 2017, INT C COMP VIS PATT
   Schrof F., 2015, INT C COMP VIS PATT
   Simonyan K., 2012, EUR C COMP VIS ECCV
   Song H. O., 2016, INT C COMP VIS PATT
   Talmi I., 2017, INT C COMP VIS PATT
   Ufer N., 2017, INT C COMP VIS PATT
   Van Craenendonck T, 2017, MACH LEARN, V106, P1497, DOI 10.1007/s10994-017-5643-7
   Wagstaff K., 2001, P 18 INT C MACH LEAR, P577, DOI DOI 10.1109/TPAMI.2002.1017616
   Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9
   Weinberger K. Q., 2006, C WORKSH NEUR INF PR
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
NR 38
TC 2
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102601
DI 10.1016/j.jvcir.2019.102601
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200030
DA 2024-07-18
ER

PT J
AU Zhao, LJ
   Bai, HH
   Wang, AH
   Zhao, Y
AF Zhao, Lijun
   Bai, Huihui
   Wang, Anhong
   Zhao, Yao
TI Learning a virtual codec based on deep convolutional neural network to
   compress image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; Image compression; Soft-projection; Virtual codec;
   Post-processing
ID BLOCKING ARTIFACT REDUCTION; DEBLOCKING; FILTER; SUPERRESOLUTION;
   VISIBILITY; DCT
AB In this paper, we propose a standard-compliant image compression framework based on image representation network (IRN) and post-processing neural network (PNN), which are trained by learning a virtual codec network (VCN). Firstly, we use a mixed-resolution image coding considering different types of distortions caused by image compression with different quality factors. Secondly, the VCN is introduced to learn a differentiable soft-projection from the represented image to the post-processed image to resolve the non-differentiable problem of hard quantization. Thirdly, the PNN is used to greatly enhance the quality of decoded images, since standard codecs always result in visually unpleasant blocking artifacts and ringing artifacts. Finally, our framework is trained in an end-to-end manner, whose convolutional kernels of the IRN, PNN and VCN are initialized by pre-training an auto-encoder network. Experimental results verify that our method has higher coding efficiency than the newest image representation-based compression method and many post-processing approaches. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhao, Lijun] Beijing Jiaotong Univ, Taiyuan Univ Sci & Technol, Beijing Key Lab Adv Informat Sci & Network Techno, Inst Digital Media & Commun, 66 Waliulu, Beijing, Peoples R China.
   [Zhao, Lijun; Bai, Huihui; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, 3 Shangyuancun, Beijing, Peoples R China.
   [Bai, Huihui; Zhao, Yao] Beijing Jiaotong Univ, Beijing Key Lab Adv Informat Sci & Network Techno, 3 Shangyuancun, Beijing, Peoples R China.
   [Wang, Anhong] Taiyuan Univ Sci & Technol, Inst Digital Media & Commun, Taiyuan, Shanxi, Peoples R China.
C3 Taiyuan University of Science & Technology; Beijing Jiaotong University;
   Beijing Jiaotong University; Beijing Jiaotong University; Taiyuan
   University of Science & Technology
RP Bai, HH (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, 3 Shangyuancun, Beijing, Peoples R China.; Bai, HH (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Adv Informat Sci & Network Techno, 3 Shangyuancun, Beijing, Peoples R China.
EM hhbai@bjtu.edu.cn
RI Zhao, Lijun/S-7237-2019
OI Zhao, Lijun/0000-0002-2305-1914; Bai, Huihui/0000-0002-3879-8957
FU National Natural Science Foundation of China [61672373]; Key Innovation
   Team of Shanxi 1331 Project [KITSX1331]; Fundamental Research Funds for
   the Central Universities [2017YJS053]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61672373), Key Innovation Team of Shanxi 1331 Project
   (KITSX1331) and the Fundamental Research Funds for the Central
   Universities (No. 2017YJS053).
CR Agustsson E., 2017, NEURAL INFORM PROCES
   Andra K, 2003, IEEE T CIRC SYST VID, V13, P209, DOI 10.1109/TCSVT.2003.809834
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Baldev S, 2018, IEEE T CONSUM ELECTR, V64, P127, DOI 10.1109/TCE.2018.2812518
   Balle J., 2016, INT C LEARN REPR SAN
   Ballé J, 2016, PICT COD SYMP, DOI 10.1109/pcs.2016.7906310
   Blau Y., 2018, P IEEE EUR C OMP VIS
   Blau Y., 2017, IEEE C COMP VIS PATT
   Cavigelli L, 2017, IEEE C NEURAL NETWOR
   Chang HB, 2014, IEEE T SIGNAL PROCES, V62, P718, DOI 10.1109/TSP.2013.2290508
   Dar Y., 2018, IEEE T IMAGE PROCESS, VPP, P1
   Dong C, 2015, IEEE COMPUT SOC CONF
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Francisco NC, 2012, SIGNAL PROCESS-IMAGE, V27, P985, DOI 10.1016/j.image.2012.05.005
   Galteri L, 2017, IEEE I CONF COMP VIS, P4836, DOI 10.1109/ICCV.2017.517
   Gan XC, 2003, J VIS COMMUN IMAGE R, V14, P492, DOI 10.1016/S1047-3203(03)00044-0
   Gavaskar RG, 2019, IEEE T IMAGE PROCESS, V28, P779, DOI 10.1109/TIP.2018.2871597
   Guo J., 2016, 14 EUR C COMP VIS NE
   Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838
   Kingma D. P., 2014, arXiv
   Li K., 2017, IEEE INT C MULT EXP
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu XM, 2016, IEEE T IMAGE PROCESS, V25, P1649, DOI 10.1109/TIP.2016.2526910
   Mathieu M., 2015, PROC INT C LEARN REP
   Rippel O., 2017, ARXIV 1705 05823
   Shao L, 2011, J VIS COMMUN IMAGE R, V22, P23, DOI 10.1016/j.jvcir.2010.09.007
   Sun DQ, 2007, IEEE T IMAGE PROCESS, V16, P2743, DOI 10.1109/TIP.2007.904969
   Tang T, 2016, J VIS COMMUN IMAGE R, V38, P721, DOI 10.1016/j.jvcir.2016.04.002
   Theis L., 2017, INT C LEARN REPR TOU
   Toderici G., 2016, INT C LEARN REPR SAN
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang C, 2013, SIGNAL PROCESS-IMAGE, V28, P522, DOI 10.1016/j.image.2013.01.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2016, IEEE CONFERENCE ON C
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang R, 2019, IEEE T CIRC SYST VID, V29, P2039, DOI 10.1109/TCSVT.2018.2867568
   Yoo SB, 2014, IEEE T MULTIMEDIA, V16, P1536, DOI 10.1109/TMM.2014.2327563
   Zhang J, 2016, IEEE T IMAGE PROCESS, V25, P1246, DOI 10.1109/TIP.2016.2515985
   Zhang XF, 2013, IEEE T IMAGE PROCESS, V22, P4613, DOI 10.1109/TIP.2013.2274386
   Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3827, DOI 10.1109/TIP.2018.2815841
   Zhao L, 2019, IEEE INT C DAT COMPR
   Zhao LJ, 2019, PATTERN RECOGN, V88, P356, DOI 10.1016/j.patcog.2018.11.028
   Zhao L, 2019, INT J HYPERTHER, V35, P528, DOI 10.1080/02656736.2018.1511836
   Zhao T, 2018, IEEE INT CONF COMP
NR 46
TC 15
Z9 18
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102589
DI 10.1016/j.jvcir.2019.102589
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200023
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, K
   Shen, XL
   Qiao, P
   Li, SJ
   Li, DS
   Dou, Y
AF Yang, Ke
   Shen, Xiaolong
   Qiao, Peng
   Li, Shijie
   Li, Dongsheng
   Dou, Yong
TI Exploring frame segmentation networks for temporal action localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action detection; Temporal action localization; Convolutional Neural
   Network
AB Temporal action localization is an important task of computer vision. Though many methods have been proposed, it still remains an open question how to predict the temporal location of action segments precisely. Most state-of-the-art works train action classifiers on video segments pre-determined by action proposal. However, recent work found that a desirable model should move beyond segment-level and make dense predictions at a fine granularity in time to determine precise temporal boundaries. In this paper, we propose a Frame Segmentation Network (FSN) that places a temporal CNN on top of the 2D spatial CNNs. Spatial CNNs are responsible for abstracting semantics in spatial dimension while temporal CNN is responsible for introducing temporal context information and performing dense predictions. The proposed FSN can make dense predictions at frame-level for a video clip using both spatial and temporal context information. FSN is trained in an end-to-end manner, so the model can be optimized in spatial and temporal domain jointly. We also adapt FSN to use it in weakly supervised scenario (WFSN), where only video level labels are provided when training. Experiment results on public dataset show that FSN achieves superior performance in both frame-level action localization and temporal action localization. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yang, Ke; Shen, Xiaolong; Qiao, Peng; Li, Shijie; Li, Dongsheng; Dou, Yong] Natl Univ Def Technol, Coll Comp, Natl Lab Parallel & Distributed Proc, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Shen, XL (corresponding author), Natl Univ Def Technol, Coll Comp, Natl Lab Parallel & Distributed Proc, Changsha, Hunan, Peoples R China.
EM yangke13@nudt.edu.cn
RI Li, Dongsheng/HHC-4903-2022
FU National Basic Research Program of China (973) [2014CB340303]; National
   Natural Science Foundation of China [U1435219, 61402507, 61572515]
FX This work was supported by the National Basic Research Program of China
   (973) under Grant No. 2014CB340303 and the National Natural Science
   Foundation of China under Grants U1435219, 61402507 and 61572515.
CR [Anonymous], 2017, ARXIV170404232
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Courtney PG, 2015, IEEE COMP SEMICON
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Oneata D., 2014, The lear submission at thumos
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wang Limin., 2014, THUMOS14 Action Recognition Challenge
   Yang K, 2018, AAAI CONF ARTIF INTE, P7477
   Yeung S., 2015, Every moment counts: Dense detailed labeling of actions in complex videos, P1
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yu F., 2015, ARXIV
   Yuan J, 2016, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2016.337
   Zhe Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301330
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 36
TC 7
Z9 7
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 296
EP 302
DI 10.1016/j.jvcir.2019.02.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chang, J
   Zhang, LM
   Gu, NJ
   Zhang, XC
   Ye, MQ
   Yin, RZ
   Meng, QQ
AF Chang, Jie
   Zhang, Luming
   Gu, Naijie
   Zhang, Xiaoci
   Ye, Minquan
   Yin, Rongzhang
   Meng, Qianqian
TI A mix-pooling CNN architecture with FCRF for brain tumor segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MR image segmentation; Convolutional Neural Network; Fully CRF
ID NEURAL-NETWORKS
AB MR technique is prevalent for doctor to diagnose and assess glioblastomas which are the most lethal form of brain tumors. Although Convolutional Neural Networks (CNN) has been applied in automatic brain tumor segmentation and is proved useful and efficient, traditional one-pathway CNN architecture with convolutional layers and max pooling layers has limited receptive fields representing the local context information. Such mindset in traditional CNN may dismiss useful global context information. In this paper, we design a two-pathway model with average and max pooling layers in different paths. Besides, 1 x 1 kernels are followed input layers to add the non-linearity dimensions of input data. Finally, we combine the CNN architecture with fully connected CRF(FCRF) as a mixture model to introduce the global context information to optimize prediction results. Our experiments proved that the mixture model improved segmentation and labeling accuracy. (C) 2018 Elsevier Inc, All rights reserved.
C1 [Chang, Jie; Gu, Naijie; Zhang, Xiaoci] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230000, Anhui, Peoples R China.
   [Chang, Jie] Wannan Med Coll, Sch Med Informat, Wuhu 241002, Anhui, Peoples R China.
   [Chang, Jie] Wannan Med Coll, Res Ctr Hlth Big Data Min & Applicat, Wuhu 241002, Anhui, Peoples R China.
   [Zhang, Luming] Zhejiang Univ, Coll Comp Sci, Hangzhou 310000, Zhejiang, Peoples R China.
   [Ye, Minquan; Yin, Rongzhang] Wannan Med Coll, Sch Med Informat, Wuhu 241000, Peoples R China.
   [Meng, Qianqian] Capital Med Univ, Beijing Tiantan Hosp, Med Engn Dept, Beijing 100050, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Wannan Medical College; Wannan Medical College; Zhejiang
   University; Wannan Medical College; Capital Medical University
RP Gu, NJ (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230000, Anhui, Peoples R China.
EM cjfuture@mail.ustc.edu.cn; gunj@ustc.edu.cn; zxiaoci@mail.ustc.edu.cn;
   ymq@wnmc.edu.cn; yrz@wnmc.edu.cn
RI Lei, Ming/JAD-1050-2023; zhang, lu/GRO-2969-2022
FU National Natural Science Foundation of China [61672386]; Anhui
   Provincial Natural Science Foundation of China [1708085MF142]; Major
   Research Project Breeding Foundation of Wannan Medical College
   [WK2017Z01]; Anhui Provincial Humanities and Social Science Foundation
   of China [SK2018A0201 I]; ANHUI Province Key Laboratory of Affective
   Computing & Advanced Intelligent Machine [ACAIM180202]
FX This work was supported by the National Natural Science Foundation of
   China [Grant numbers 61672386]; the Anhui Provincial Natural Science
   Foundation of China [Grant numbers 1708085MF142]; the Major Research
   Project Breeding Foundation of Wannan Medical College [Grant numbers
   WK2017Z01]; the Anhui Provincial Humanities and Social Science
   Foundation of China [Grant numbers SK2018A0201 I; ANHUI Province Key
   Laboratory of Affective Computing & Advanced Intelligent Machine [Grant
   numbers ACAIM180202].
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], ARXIV160502688
   [Anonymous], 2011, ADV NEURAL INF PROCE
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], LASAGNE 1 RELEASE
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], IMAGE
   [Anonymous], BRIT J RADIOL
   [Anonymous], SEGMENTING BRAIN TUM
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Deng WK, 2010, INT CONF BIOMED, P393, DOI 10.1109/BMEI.2010.5639536
   Dvorak P., 2015, Proceeding of the Multimodal Brain Tumor Image Segmentation Challenge, P13, DOI DOI 10.1007/978-3-319-42016-5_6
   Gering DT, 2002, LECT NOTES COMPUT SC, V2488, P388
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakare S., 2000, 3D SEGMENTATION TECH
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Menze BH, 2010, LECT NOTES COMPUT SC, V6362, P151
   Nie JX, 2009, COMPUT MED IMAG GRAP, V33, P431, DOI 10.1016/j.compmedimag.2009.04.006
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Rao WW, 2017, IEEE ICC
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
NR 40
TC 47
Z9 51
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 316
EP 322
DI 10.1016/j.jvcir.2018.11.047
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100031
DA 2024-07-18
ER

PT J
AU Liu, D
   Chen, ZZ
AF Liu, Di
   Chen, Zhenzhong
TI Disparity tuning guided stereoscopic saliency detection for eye fixation
   prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic saliency; Disparity tuning; Diffusion-based saliency
ID BINOCULAR DISPARITY; HORIZONTAL DISPARITY; NEURONS; PERCEPTION; AREA;
   SENSITIVITY; MECHANISMS; ATTENTION; RESPONSES; CORTEX
AB The development of emerging 3D display brings increasing attention of stereoscopic techniques such as quality assessment, re-targeting, and compression of 3D image, that require new saliency detection methods to deal with stereoscopic data. In this paper, we present a disparity tuning guided stereoscopic saliency (DTSS) model which apply the disparity tuning mechanism of visual cortical neurons into visual attention modeling. First, we investigate the rationality of converting features from physical quantity into perception quantity before computing saliency. Second, we discuss the biological principles that depth affects visual attention and consider both absolute and relative depth tuning mechanisms to model visual attention. Then, we propose a diffusion saliency feature combining depth and RGB features. Specifically, we use RGB contrast as primitive labels to diffuse a saliency map for depth map and using depth contrast as primitive labels to diffuse a saliency map for RGB image. Finally, an adaptively weighted fusion method is proposed for the integration of feature maps. Experiments demonstrate that the proposed model performs well against to the state-of-art methods on the task of 3D eye fixation prediction. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Di; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM dliu@whu.edu.cn; zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015
OI Liu, Di/0000-0002-9689-6846
FU National Natural Science Foundation of China [61771348, 61471273]; Wuhan
   Morning Light Plan of Youth Science and Technology [2017050304010302]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant 61771348 and 61471273, and Wuhan Morning
   Light Plan of Youth Science and Technology under Grant 2017050304010302.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2009, P IEEE INT C COMP VI
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], 2007, P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], 2013, P IEEE INT C COMP VI
   [Anonymous], 2009, P IEEE INT C COMP VI
   [Anonymous], P SPIE
   [Anonymous], 2012, P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2013 IEEE C COMP VIS
   [Anonymous], 2012, P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chen YZ, 2001, J NEUROPHYSIOL, V86, P143, DOI 10.1152/jn.2001.86.1.143
   Chen ZZ, 2013, IEEE SIGNAL PROC LET, V20, P95, DOI 10.1109/LSP.2012.2230442
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cottereau BR, 2012, J NEUROSCI, V32, P826, DOI 10.1523/JNEUROSCI.2709-11.2012
   Cottereau BR, 2011, J NEUROSCI, V31, P954, DOI 10.1523/JNEUROSCI.3795-10.2011
   Cumming BG, 1997, NATURE, V389, P280, DOI 10.1038/38487
   Cumming BG, 1999, J NEUROSCI, V19, P5602
   DeAngelis GC, 2003, J NEUROPHYSIOL, V89, P1094, DOI 10.1152/jn.00717.2002
   DeAngelis GC, 1998, NATURE, V394, P677, DOI 10.1038/29299
   Deas LM, 2015, J VISION, V15, DOI 10.1167/15.11.11
   Fang YM, 2016, INFORM SCIENCES, V372, P347, DOI 10.1016/j.ins.2016.08.062
   Fang YM, 2015, INFORM SCIENCES, V309, P1, DOI 10.1016/j.ins.2015.03.004
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Han JW, 2016, IEEE T CYBERNETICS, V46, P487, DOI 10.1109/TCYB.2015.2404432
   Hinkle DA, 2005, J NEUROPHYSIOL, V94, P2726, DOI 10.1152/jn.00341.2005
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jansen L, 2009, J VISION, V9, DOI 10.1167/9.1.29
   Li H, 2017, INFORM SCIENCES, V415, P1, DOI 10.1016/j.ins.2017.06.014
   Liu Y, 2008, J VISION, V8, DOI 10.1167/8.11.19
   Ma CY, 2015, J VISION, V15, DOI 10.1167/15.6.19
   Masson GS, 1997, NATURE, V389, P283, DOI 10.1038/38496
   MAUNSELL JHR, 1983, J NEUROPHYSIOL, V49, P1148, DOI 10.1152/jn.1983.49.5.1148
   Ning QA, 1997, NEURON, V18, P359, DOI 10.1016/S0896-6273(00)81238-6
   Parker AJ, 2007, NAT REV NEUROSCI, V8, P379, DOI 10.1038/nrn2131
   POGGIO GF, 1988, J NEUROSCI, V8, P4531
   POGGIO GF, 1977, J NEUROPHYSIOL, V40, P1392, DOI 10.1152/jn.1977.40.6.1392
   Prince SJD, 2002, J NEUROPHYSIOL, V87, P209, DOI 10.1152/jn.00466.2000
   Rea MarkS., 2000, The IESNA Lighting Handbook
   Read J, 2005, PROG BIOPHYS MOL BIO, V87, P77, DOI 10.1016/j.pbiomolbio.2004.06.005
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Roelfsema PR, 2007, NEURON, V56, P785, DOI 10.1016/j.neuron.2007.10.006
   Sekuler R Blake R., 1990, Perception, V2nd
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   STEVENSON SB, 1992, VISION RES, V32, P1685, DOI 10.1016/0042-6989(92)90161-B
   Wang JW, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2522380
   Wang JL, 2012, J EYE MOVEMENT RES, V5
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang Y. X., 2015, WATER RESOUR MANAG, V15, P1, DOI DOI 10.1371/J0URNAL.P0NE.0130941
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 58
TC 4
Z9 4
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 218
EP 227
DI 10.1016/j.jvcir.2018.10.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400026
DA 2024-07-18
ER

PT J
AU Wen, CB
   Liu, PL
   Ma, WB
   Jian, ZR
   Lv, CH
   Hong, JT
   Shi, XW
AF Wen, Changbao
   Liu, Pengli
   Ma, Wenbo
   Jian, Zhirong
   Lv, Changheng
   Hong, Jitong
   Shi, Xiaowen
TI Edge detection with feature re-extraction deep convolutional neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edge detection; Feature re-extract; Deep convolutional neural network;
   Generalization ability
AB In this paper, we propose an edge detector based on feature re-extraction (FRE) of a deep convolutional neural network to effectively utilize features extracted from each stage, and design a new loss function. The proposed detector is mainly composed of three modules: backbone, side-output, and feature fusion. The backbone module provides preliminary feature extraction; the side-output module makes network architecture more robustly map features from different stages of the backbone network to edge-pixel space by applying residual learning, and the feature fusion module generates the edge map. Generalization ability on the same distribution is verified using the BSDS500 dataset, achieving optimal dataset scale (ODS) F-score = 0.804. Cross-distribution generalization ability is verified on the NYUDv2 dataset, achieving ODS F-score = 0.701. In addition, we find that freezing backbone network can significantly speed up training process, without much overall accuracy loss (ODS F-score of 0.791 after 5.4k iterations). (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wen, Changbao; Liu, Pengli; Ma, Wenbo; Hong, Jitong; Shi, Xiaowen] Changan Univ, Sch Elect & Control Engn, Inst Micronanoelect, Xian 710064, Shaanxi, Peoples R China.
   [Jian, Zhirong] Glory Global Solut, Shanghai, Peoples R China.
   [Lv, Changheng] Nanjing Univ Aeronaut & Astronaut, Nanjing, Jiangsu, Peoples R China.
C3 Chang'an University; Nanjing University of Aeronautics & Astronautics
RP Wen, CB (corresponding author), Changan Univ, Sch Elect & Control Engn, Inst Micronanoelect, Xian 710064, Shaanxi, Peoples R China.
EM estlab@chd.edu.cn
FU National Natural Science Foundation of China [61701044]; Natural Science
   Basic Research Plan in Shaanxi Province [2018JQ6056, 2018XNCG-G-01];
   Special Fund for Basic Scientific Research of Central Colleges
   [300103187051, 300104283215]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61701044), the Natural Science Basic Research Plan in Shaanxi
   Province (Nos. 2018JQ6056 and 2018XNCG-G-01), and the Special Fund for
   Basic Scientific Research of Central Colleges (Nos. 300103187051 and
   300104283215).
CR Akinlar C, 2017, J VIS COMMUN IMAGE R, V44, P82, DOI 10.1016/j.jvcir.2017.01.024
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2017, C COMP VIS PATT REC
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.622
   [Anonymous], 2017, MARGINAL VALUE ADAPT
   [Anonymous], 2016, PROC 4 INT C LEARN R
   [Anonymous], P 14 INT C ART INT S
   [Anonymous], N 4 FIELDS NEURAL NE
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782
   Hwang Jyh-Jing., 2015, ICLR
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma D. P, 2015, International Conference on Learning Representations
   Kittler J., 1983, Image and Vision Computing, V1, P37, DOI [DOI 10.1016/0262-8856(83)90006-9, 10.1016/0262-8856(83)90006-9]
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32
   Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Ren X, 2012, ADV NEURAL INFORM PR, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zheng YF, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040310
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 42
TC 10
Z9 10
U1 1
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 84
EP 90
DI 10.1016/j.jvcir.2018.10.017
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400011
DA 2024-07-18
ER

PT J
AU Florea, C
   Gieseke, F
AF Florea, Corneliu
   Gieseke, Fabian
TI Artistic movement recognition by consensus of boosted SVM based experts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Randomized boosted SVMs; Multi-scale topography; Painting style
   recognition; Consensus of experts; Ensembles
ID ANCIENT PAINTINGS; RANDOM SUBSPACE; CLASSIFICATION; TEXTURE; SCALE;
   STYLE; SHAPE
AB In this work we aim to automatically recognize the artistic movement from a digitized image of a painting. Our approach uses a new system that resorts to descriptions induced by color structure histograms and by novel topographical features for texture assessment. The topographical descriptors accumulate information from the first and second local derivatives within four layers of finer representations. The classification is performed by two layers of ensembles. The first is an adapted boosted ensemble of support vector machines, which introduces further randomization over feature categories as a regularization. The training of the ensemble yields individual experts by isolating initially misclassified images and by correcting them in further stages of the process. The solution improves the performance by a second layer build upon the consensus of multiple local experts that analyze different parts of the images. The resulting performance compares favorably with classical solutions and manages to match the ones of modern deep learning frameworks. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Florea, Corneliu] Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, Bucharest, Romania.
   [Gieseke, Fabian] Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark.
C3 National University of Science & Technology POLITEHNICA Bucharest;
   University of Copenhagen
RP Florea, C (corresponding author), Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, Bucharest, Romania.
EM corneliu.florea@upb.ro; fabian.gieseke@di.ku.dk
RI Florea, Corneliu/B-5540-2012
OI Florea, Corneliu/0000-0001-9754-6795; Gieseke,
   Fabian/0000-0001-7093-5803
FU Romanian National Authority for Scientific Research and Innovation, CNCS
   UEFISCDI [PN-II-RU-TE-2014-4-0733]
FX Corneliu Florea is supported by supported by a grant of the Romanian
   National Authority for Scientific Research and Innovation, CNCS
   UEFISCDI, number PN-II-RU-TE-2014-4-0733.
CR Agarwal S, 2015, IEEE WINT CONF APPL, P588, DOI 10.1109/WACV.2015.84
   Ahn H, 2007, COMPUT STAT DATA AN, V51, P6166, DOI 10.1016/j.csda.2006.12.043
   [Anonymous], CoRR
   [Anonymous], Squeeze-and-Excitation Networks
   [Anonymous], 2017, IEEE C COMP VIS PATT
   Arora RS, 2012, INT C PATT RECOG, P3541
   Bar Y, 2015, LECT NOTES COMPUT SC, V8925, P71, DOI 10.1007/978-3-319-16178-5_5
   Bastan M, 2010, IEEE MULTIMEDIA, V17, P62, DOI 10.1109/MMUL.2010.5692184
   Breiman L, 1998, ANN STAT, V26, P801
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Condorovici RG, 2015, J VIS COMMUN IMAGE R, V26, P222, DOI 10.1016/j.jvcir.2014.11.016
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dutton D, 2006, J AESTHET ART CRITIC, V64, P367, DOI 10.1111/j.1540-594X.2006.00217.x
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Florea C, 2017, LECT NOTES COMPUT SC, V10269, P337, DOI 10.1007/978-3-319-59126-1_28
   Florea C, 2017, IEEE WINT CONF APPL, P569, DOI 10.1109/WACV.2017.69
   Florea C, 2015, LECT NOTES COMPUT SC, V8927, P778, DOI 10.1007/978-3-319-16199-0_54
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   García-Pedrajas N, 2009, PATTERN RECOGN, V42, P1742, DOI 10.1016/j.patcog.2008.12.023
   Gardner JR, 2014, PR MACH LEARN RES, V32, P937
   Gatys LA, 2017, CURR OPIN NEUROBIOL, V46, P178, DOI 10.1016/j.conb.2017.08.019
   Günsel B, 2005, IEEE IMAGE PROC, P2197
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jiang SY, 2017, IEEE T EVOLUT COMPUT, V21, P65, DOI 10.1109/TEVC.2016.2574621
   Jiang SQ, 2006, PATTERN RECOGN LETT, V27, P734, DOI 10.1016/j.patrec.2005.10.017
   Karayev S., 2014, P BRIT MACH VIS C, P1, DOI [DOI 10.5244/C.28.122, 10.5244/c.28.122, 10.5244%2Fc.28.122, 10.5244/C.28.122]
   Keren D, 2003, PATTERN RECOGN LETT, V24, P2913, DOI 10.1016/S0167-8655(03)00152-1
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4
   Knerr S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P41
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J, 2004, IEEE T IMAGE PROCESS, V13, P338, DOI 10.1109/TIP.2003.821349
   Li J, 2012, IEEE T PATTERN ANAL, V34, P1159, DOI 10.1109/TPAMI.2011.203
   Li XC, 2008, ENG APPL ARTIF INTEL, V21, P785, DOI 10.1016/j.engappai.2007.07.001
   Little Stephen., 2004, Isms :Understanding Art
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mason L, 2000, ADV NEUR IN, V12, P512
   Mayhua-López E, 2015, INFORM FUSION, V25, P63, DOI 10.1016/j.inffus.2014.10.005
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Peng KC, 2015, IEEE IMAGE PROC, P3057, DOI 10.1109/ICIP.2015.7351365
   Saleh B, 2016, MULTIMED TOOLS APPL, V75, P3565, DOI 10.1007/s11042-014-2193-x
   Sandler M., Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Shen JL, 2009, PATTERN RECOGN, V42, P293, DOI 10.1016/j.patcog.2008.04.016
   Sheng JC, 2014, PATTERN RECOGN, V47, P612, DOI 10.1016/j.patcog.2013.08.017
   Siddiquie B., 2009, The IEEE Winter Conference on Applications of Computer Vision (WACV) Workshop, P1, DOI DOI 10.1109/WACV.2009.5403040
   Simonyan K., 2014, 14091556 ARXIV
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van Noord N, 2017, PATTERN RECOGN, V61, P583, DOI 10.1016/j.patcog.2016.06.005
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang SJ, 2009, EXPERT SYST APPL, V36, P6466, DOI 10.1016/j.eswa.2008.07.041
   Wang ZH, 2016, IEEE T PATTERN ANAL, V38, P2198, DOI 10.1109/TPAMI.2015.2513396
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zou Q, 2014, PATTERN RECOGN LETT, V49, P146, DOI 10.1016/j.patrec.2014.07.002
NR 62
TC 9
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 220
EP 233
DI 10.1016/j.jvcir.2018.09.015
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500022
DA 2024-07-18
ER

PT J
AU Liu, XJ
   Ding, WP
   Shi, YH
   Yin, BC
AF Liu, Xiaojie
   Ding, Wenpeng
   Shi, Yunhui
   Yin, Baocai
TI Content adaptive interpolation filters based on HEVC framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Interpolation; Adaptive; Filter; Fractional samples
ID H.264/AVC; STANDARD; PREDICTION
AB Motion compensation is the key technique to reduce temporal redundancy in video coding. Interpolation filters are adopted to generate the inter frame prediction for motion compensation with fractional pixel accuracy. In existing video coding standards such as H.264/AVC and HEVC, a set of predefined interpolation filters is adopted in motion compensation. However, predefined interpolation filters cannot adapt to the video content, which may compromise the coding efficiency. In this paper, a content adaptive interpolation scheme is proposed for motion compensation. In the proposed scheme, a set of adaptive interpolation filters is derived for each frame as additional interpolation filters to minimize the inter prediction difference. Rate-distortion optimization is employed to choose between the predefined interpolation filters and the derived adaptive interpolation filters to achieve the best coding performance at the low bit rates. The proposed scheme is implemented into the HM 12.1 software. Experimental results show that the proposed scheme achieves 5.13 percent, 3.42 percent and 4.07 percent bit rate saving on average compared with HEVC under the "low delay P", the "low delay B" and the "random access" configurations respectively. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Xiaojie; Ding, Wenpeng; Shi, Yunhui; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing Adv Innovat Ctr Future Internet Technol, Beijing 100124, Peoples R China.
   [Yin, Baocai] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Beijing University of Technology; Dalian University of Technology
RP Ding, WP (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing Adv Innovat Ctr Future Internet Technol, Beijing 100124, Peoples R China.
EM wpding@qq.com
FU NSFC [61472018, 61390510, 61632006, 61672066, 61772049]; BJNSF [4162009]
FX This work is supported by NSFC (No. 61472018, 61390510, 61632006,
   61672066, 61772049) and BJNSF (No. 4162009).
CR Alshin A., 2012, SPIE OPTICAL ENG APP
   [Anonymous], 12 M GEN JAN
   Bjontegaard G., 2001, VCEGM33ITUTQ6116
   Bross B., 2014, High Efficiency Video Coding HEVC, P113
   Bross B., 2012, 11 JCT VC M OCT
   Chono K., 2002, JVTC040 ISOIEC JTC1S
   Dong J, 2010, IEEE T CIRC SYST VID, V20, P1892, DOI 10.1109/TCSVT.2010.2087530
   Flierl M, 2003, IEEE T CIRC SYST VID, V13, P587, DOI 10.1109/TCSVT.2003.814963
   GIROD B, 1993, IEEE T COMMUN, V41, P604, DOI 10.1109/26.223785
   Rusanovskyy D, 2009, IEEE T CIRC SYST VID, V19, P1239, DOI 10.1109/TCSVT.2009.2022708
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Ugur K., 2011, JCTVCD321
   Ugur K, 2013, IEEE J-STSP, V7, P946, DOI 10.1109/JSTSP.2013.2272771
   Vatis Y., 2005, COMP COMPLEXITY 2 DI, V6
   Vatis Y, 2006, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2006.313148
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T., 2003, DRAFT ITU T RECOMMEN
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Ye Y, 2010, IEEE DATA COMPR CONF, P435, DOI 10.1109/DCC.2010.46
   Zhang K, 2012, IEEE T CIRC SYST VID, V22, P43, DOI 10.1109/TCSVT.2011.2157194
NR 20
TC 1
Z9 1
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 131
EP 138
DI 10.1016/j.jvcir.2018.09.006
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500011
DA 2024-07-18
ER

PT J
AU Williem
   Park, IK
AF Williem
   Park, In Kyu
TI Cost aggregation benchmark for light field depth estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light field; Depth estimation; Cost aggregation; Weighted rank;
   Benchmark
AB Light field depth estimation has become a mature research topic and there are numerous algorithms introduced by various research groups. However, comprehensive and fair benchmark is difficult to apply because there are large step variances of the introduced algorithms. It is essential to analyze each step in the light field depth estimation so that it could help design better and more robust algorithms. Thus, a thorough analysis of cost aggregation is conducted in this paper to analyze the performance of various cost aggregation methods on light field depth estimation. A study on the parameter setting for each cost aggregation method is performed. Then, each cost aggregation with its optimal parameters is evaluated individually. Instead of using the standard rank system, this paper utilizes the weighted rank system based on the score difference on each criterion. Experimental results confirm that the guided-filter based method outperforms other methods in most evaluation criteria. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Williem] Bina Nusantara Univ, Sch Comp Sci, Comp Sci Dept, Jakarta 11480, Indonesia.
   [Park, In Kyu] Inha Univ, Dept Informat & Commun Engn, Incheon 22212, South Korea.
C3 Universitas Bina Nusantara; Inha University
RP Park, IK (corresponding author), Inha Univ, Dept Informat & Commun Engn, Incheon 22212, South Korea.
EM williem@binus.edu; pik@inha.ac.kr
RI Williem, Williem/O-6205-2019; Park, In Kyu/B-5967-2013
OI Williem, Williem/0000-0002-2763-7883; 
FU Inha University Research Grant
FX This work was supported by Inha University Research Grant.
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE C COMP VIS PA
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197
   Pham CC, 2013, IEEE T CIRC SYST VID, V23, P1119, DOI 10.1109/TCSVT.2012.2223794
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Heber Stefan, 2014, Computer Vision - ECCV 2014. 13th European Conference. Proceedings: LNCS 8694, P751, DOI 10.1007/978-3-319-10599-4_48
   Hosni A, 2013, COMPUT VIS IMAGE UND, V117, P620, DOI 10.1016/j.cviu.2013.01.007
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601125
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Johannsen O., 2017, P IEEE C COMPUTER VI, P82
   Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sheng H, 2018, PATTERN RECOGN, V74, P587, DOI 10.1016/j.patcog.2017.09.010
   Srinivasan Pratul P, 2017, P IEEE C COMP VIS PA, P3958
   Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Wang TT, 2017, J MICROBIOL METH, V133, P1, DOI 10.1016/j.mimet.2016.12.002
   Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615
   Wanner S., 2013, INT S VIS MOD VIS, P225
   Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656
   Williem, 2018, IEEE T PATTERN ANAL, V40, P2484, DOI 10.1109/TPAMI.2017.2746858
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yang Q., 2007, PROC IEEE C COMPUTER, P1
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333
   Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007
NR 33
TC 6
Z9 6
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 38
EP 51
DI 10.1016/j.jvcir.2018.08.015
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500004
DA 2024-07-18
ER

PT J
AU Li, XS
   Cao, G
   Zhang, YQ
   Wang, BS
AF Li, Xuesong
   Cao, Guo
   Zhang, Youqiang
   Wang, Bisheng
TI Single image super-resolution via adaptive sparse representation and
   low-rank constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Adaptive sparse representation; Self-similarity
   learning; Robust principal component analysis
ID FACE RECOGNITION; INTERPOLATION; REGRESSION; ALGORITHM
AB Sparse representation theory shows effectiveness in single image super-resolution (SR). Existing image super-resolution methods usually make use of l(1)-regularization, l(2)-regularization or their combination to restrict the sparsity. However, the nonlocal similarity of images, which can be helpful to image SR, is often neglected. In order to utilize the nonlocal similarity and improve SR results in this paper, we propose a new single image super-resolution method by combining the adaptive sparse representation and robust principal component analysis (RPCA). Furthermore, we adopt the self-similarity learning framework to construct the dictionary pair. In our method, we first compute the sparse coefficient of each testing image patch through adaptive sparse representation with the constructed dictionary. Then, for each testing image block, we search for its similar patches and use RPCA as a low-rank optimization strategy to the corresponding coefficients. Extensive experiment results demonstrate that the proposed method can possesses better performance compared with some state-of-the-art methods.
C1 [Li, Xuesong; Cao, Guo; Zhang, Youqiang; Wang, Bisheng] NanJing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Cao, G (corresponding author), NanJing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM caoguo@njust.edu.cn
RI , Guo/AAC-1388-2022; Zhang, Youqiang/ISV-0771-2023; Zhang,
   Youqiang/O-2797-2015
OI , Guo/0000-0002-2689-0932; Zhang, Youqiang/0000-0002-4761-4726; Zhang,
   Youqiang/0000-0002-4761-4726; li, xuesong/0000-0002-2370-8998
FU National Nature Science Foundation of China [61371168]; National Key
   Research and Development Program of China [2016YFC0801304]
FX This work was supported by the National Nature Science Foundation of
   China (Grant Number. 61371168), the National Key Research and
   Development Program of China (Grant Number. 2016YFC0801304).
CR Angst R, 2011, IEEE I CONF COMP VIS, P2502, DOI 10.1109/ICCV.2011.6126536
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cui Z, 2014, LECT NOTES COMPUT SC, V8693, P49, DOI 10.1007/978-3-319-10602-1_4
   Dai D, 2015, COMPUT GRAPH FORUM, V34, P95, DOI 10.1111/cgf.12544
   Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Gao GW, 2016, IEEE ACCESS, V4, P8775, DOI 10.1109/ACCESS.2016.2633281
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Guan L, 1996, IEEE T SYST MAN CY A, V26, P513, DOI 10.1109/3468.508831
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Ibragimov B, 2015, MED IMAGE ANAL, V20, P198, DOI 10.1016/j.media.2014.11.006
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Nguyen K, 2013, COMPUT VIS IMAGE UND, V117, P1526, DOI 10.1016/j.cviu.2013.06.010
   Kim J., 2015, IEEE T PATTERN ANAL, V38, P295, DOI [10.1109/TPAM1.2015.2439281, DOI 10.1109/TPAM1.2015.2439281]
   Li W, 2005, IEEE T SYST MAN CY A, V35, P546, DOI 10.1109/TSMCA.2005.850605
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin Z.C., 2010, 100920105055 ARXIV, V1009, P5055, DOI [DOI 10.1016/J.JSB.2012.10.010, 10.1016/j.jsb.2012.10.010]
   Lu T, 2017, IEEE ACCESS, V5, P13103, DOI 10.1109/ACCESS.2017.2717963
   Lu XQ, 2013, IEEE T CIRC SYST VID, V23, P2022, DOI 10.1109/TCSVT.2013.2244798
   Lu XQ, 2012, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR.2012.6247858
   Ming Y, 2015, IMAGE VISION COMPUT, V35, P14, DOI 10.1016/j.imavis.2014.12.003
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Ren X, 2013, INT J COMPUT VISION, V104, P1, DOI 10.1007/s11263-013-0611-6
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Shen JG, 2016, IEEE T SYST MAN CY-S, V46, P1492, DOI 10.1109/TSMC.2016.2523948
   Shi JH, 2016, IEEE IMAGE PROC, P1424, DOI 10.1109/ICIP.2016.7532593
   Sun JA, 2010, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2010.5540206
   Suo JL, 2011, IEEE T SYST MAN CY A, V41, P226, DOI 10.1109/TSMCA.2010.2064304
   Tang Y, 2016, NEUROCOMPUTING, V172, P38, DOI 10.1016/j.neucom.2014.12.102
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang J, 2014, IEEE T CYBERNETICS, V44, P2368, DOI 10.1109/TCYB.2014.2307067
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Wang Q, 2014, NEUROCOMPUTING, V131, P348, DOI 10.1016/j.neucom.2013.09.032
   Wang XL, 2016, NEUROCOMPUTING, V173, P1402, DOI 10.1016/j.neucom.2015.09.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wright J., 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1002/CPA.20132
   Xiao H, 2015, IEEE T SYST MAN CY-S, V45, P1047, DOI 10.1109/TSMC.2014.2383997
   Xu HT, 2013, IEEE T CIRC SYST VID, V23, P1740, DOI 10.1109/TCSVT.2013.2248305
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JF, 2013, MATH COMPUT, V82, P301
   Yang WM, 2017, IEEE T SYST MAN CY-S, V47, P2478, DOI 10.1109/TSMC.2016.2523947
   Yuan Xiaoming., 2009, Optimization Online, P1
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YB, 2016, IEEE T MULTIMEDIA, V18, P405, DOI 10.1109/TMM.2015.2512046
   Zhang YL, 2015, IEEE IMAGE PROC, P591, DOI 10.1109/ICIP.2015.7350867
   Zhao JW, 2017, KNOWL-BASED SYST, V124, P23, DOI 10.1016/j.knosys.2017.02.029
NR 63
TC 11
Z9 11
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 319
EP 330
DI 10.1016/j.jvcir.2018.06.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100025
DA 2024-07-18
ER

PT J
AU Roy, A
   Banerjee, B
   Murino, V
AF Roy, Abhinaba
   Banerjee, Biplab
   Murino, Vittorio
TI Discriminative body part interaction mining for mid-level action
   representation and classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Mid level feature; Zero shot learning
ID ACTION RECOGNITION; DENSE
AB In this paper, we propose a novel mid-level feature representation for the recognition of actions in videos. This descriptor proves to posses relevant discriminative power when used in a generic action recognition pipeline. It is well known that mid-level feature descriptors learnt using class-oriented information are potentially more distinctive than the low-level features extracted in a bottom-up unsupervised fashion. In this regard, we introduce the notion of concepts, a mid-level feature representation capable of tracking the dynamics of motion salient regions over consecutive frames in a video sequence. Our feature representation is based on the idea of region correspondence over consecutive frames and we make use of an unsupervised iterative bipartite graph matching algorithm to extract representative visual concepts from action videos. The progression of such salient regions, which are also consistent in appearance, are henceforth represented as chain graphs. Finally, we adopt an intuitive time-series pooling strategy to extract discriminant features from the chains, which are then used in a dictionary learning based classification framework. Given the high variability of the movements of different human body parts in separate actions, the extracted conceptual descriptors are proved to capture the different dynamic characteristics by exclusively encoding the interaction parts associated to the chains. Further, we use such descriptors in a semi-supervised, clustering-based zero-shot action recognition setting, showing good performance and without resorting to costly attribute annotation. We validate the proposed framework on four public datasets namely KTH, UCF-101, HOHA and HMDB-51, reporting increased (and comparable in some cases) classification accuracies with respect to the state of the art.
C1 [Roy, Abhinaba; Murino, Vittorio] Ist Italiano Technol, Genoa, Italy.
   [Banerjee, Biplab] Indian Inst Technol, Roorkee, Uttar Pradesh, India.
C3 Istituto Italiano di Tecnologia - IIT; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Roorkee
RP Roy, A (corresponding author), Ist Italiano Technol, Genoa, Italy.
EM abhinaba.roy@iit.it; vittorio.murino@iit.it
RI Murino, Vittorio/A-5570-2011
OI Murino, Vittorio/0000-0002-8645-2328
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2016, International Conference on Learning Representations
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   EDMONDS J, 1972, J ACM, V19, P248, DOI 10.1145/321694.321699
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   GABOW HN, 1985, J COMPUT SYST SCI, V31, P148, DOI 10.1016/0022-0000(85)90039-X
   Goldberg Y., 14023722 ARXIV
   Halkidi M, 2000, LECT NOTES COMPUT<D>, V1910, P265
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Herath S., ARXIV160504988
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Palou G, 2013, PROC CVPR IEEE, P2099, DOI 10.1109/CVPR.2013.273
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy A, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P519, DOI 10.5220/0006200205190526
   Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691
   Schrijver A., 2003, COMBINATORIAL OPTIMI
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shojaee S. M., ARXIV160509016
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Srivastava N., CORR
   Sugiyama M., 2006, P 23 INT C MACH LEAR, P905, DOI DOI 10.1145/1143844.1143958
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Gemert Jan C., 2015, BMVC, V2, P4
   Varol G., ARXIV160404494
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333
   Wang P., ARXIV160200224
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Xu X, 2015, IEEE IMAGE PROC, P63, DOI 10.1109/ICIP.2015.7350760
   Yi Y, 2016, PATTERN RECOGN, V53, P148, DOI 10.1016/j.patcog.2015.11.022
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953
NR 55
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 829
EP 840
DI 10.1016/j.jvcir.2018.06.026
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100073
DA 2024-07-18
ER

PT J
AU Zheng, ZQ
   Huo, JY
   Li, BB
   Yuan, H
   Lin, WS
AF Zheng, Ziqi
   Huo, Junyan
   Li, Bingbing
   Yuan, Hui
   Lin, Weisi
TI A novel distortion criterion of rate-distortion optimization for depth
   map coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three dimensional video (3DV); Multiview video plus depth (MVD);
   Rate-distortion optimization; Virtual view distortion; 3D-HEVC
ID SYNTHESIZED VIEW; MULTIVIEW VIDEO; BIT ALLOCATION; 3D VIDEO; MODEL;
   COMPRESSION; 3D-HEVC; HEVC
AB In 3D video coding systems, depth maps are not displayed to the viewers, but provide the geometric information to generate virtual views. To ensure the quality of virtual views, the rate-distortion optimization (RDO) in depth map coding adopts the virtual view distortion as the distortion item. The virtual view distortion comes from the reconstructed color video distortion and depth distortion. It is usually recognized that the virtual view distortion caused by reconstructed color video distortion is independent of that in depth map coding. Preliminary experiments reveal that the virtual view distortion in depth map coding is also influenced by the reconstructed color video distortion. Therefore, we proposed a novel distortion criterion of depth map coding in which the reconstructed color video distortion is modeled and joins into the virtual view distortion calculation. Correspondingly, the associated Lagrange multiplier is also proposed. Experimental results demonstrate that the method by integrating the proposed distortion criterion into RDO for depth map coding can achieve an average 12.72% bitrate saving compared with SSD based RDO method and can also lead a bitrate reduction (0.64%) compared with the existing distortion estimation method in the current 3D-HEVC reference software. With the associated Lagrange multiplier, the proposed distortion criterion can achieve 12.98% bitrate saving compared with SSD based RDO method on average.
C1 [Zheng, Ziqi; Huo, Junyan; Li, Bingbing] Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Shaanxi, Peoples R China.
   [Yuan, Hui] Shandong Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Xidian University; Shandong University; Nanyang Technological University
RP Huo, JY (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Shaanxi, Peoples R China.
EM jyhuo@mail.xidian.edu.cn
RI Yuan, Hui/HDO-3699-2022; Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012
OI Yuan, Hui/0000-0001-5212-3393; Lin, Weisi/0000-0001-9866-1947; 
FU NSF of China [61571274]; 111 Project [B08038]; Shandong Natural Science
   Funds for Distinguished Young Scholar [JQ201614]; Young Scholars Program
   of Shandong University (YSPSDU) [2015WLJH39]
FX The authors would like to thank the editors and anonymous reviewers for
   their valuable comments. They would also like to thank the JCT-3 V for
   their standardization work on 3DV and Poznan University of Technology,
   Nokia, Nagoya University, GIST and NICT for their 3D video sequences.
   This work is supported in part by the NSF of China under Grant 61571274,
   the 111 Project B08038, the Shandong Natural Science Funds for
   Distinguished Young Scholar under Grant JQ201614, and the Young Scholars
   Program of Shandong University (YSPSDU) under Grant 2015WLJH39.
CR Bjntegaard G., 2001, P 13 M ITU T VID COD
   Chen F, 2017, J VIS COMMUN IMAGE R, V43, P41, DOI 10.1016/j.jvcir.2016.12.004
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   Daribo I, 2014, IEEE T IMAGE PROCESS, V23, P4696, DOI 10.1109/TIP.2014.2353817
   Domanski Marek, 2009, POZNAN MULTIVIEW VID
   Dou H, 2017, J VIS COMMUN IMAGE R, V42, P104, DOI 10.1016/j.jvcir.2016.11.012
   Fang L, 2016, IEEE T IMAGE PROCESS, V25, P1961, DOI 10.1109/TIP.2016.2535345
   Fang L, 2014, IEEE T IMAGE PROCESS, V23, P185, DOI 10.1109/TIP.2013.2287608
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   GIST, 3DV TEST SEQ
   Hannuksela M., 2011, EXTENSION EXISTING 3
   Kim WS, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2447737
   Koppel M., 2016, IEEE T BROADCAST, V63, P1
   Li CY, 2014, IEEE IMAGE PROC, P3228, DOI 10.1109/ICIP.2014.7025653
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Nagoya University, FTV TEST SEQ
   Oh BT, 2014, IEEE T CIRC SYST VID, V24, P1006, DOI 10.1109/TCSVT.2013.2290577
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   Peng ZJ, 2015, J VIS COMMUN IMAGE R, V33, P309, DOI 10.1016/j.jvcir.2015.10.003
   Rusanovskyy D., 2013, P 3 M ITU T ISO IEC
   Shao F, 2016, IEEE T BROADCAST, V62, P94, DOI 10.1109/TBC.2015.2496818
   Song Y, 2014, SIGNAL IMAGE VIDEO P, V8, P1031, DOI 10.1007/s11760-013-0609-0
   Tanimoto M, 2012, SIGNAL PROCESS-IMAGE, V27, P555, DOI 10.1016/j.image.2012.02.016
   Tech G., 2012, 3D HEVC CE10 RESULTS
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tech G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P25, DOI 10.1109/PCS.2012.6213277
   Wang L, 2013, IEEE INT SYMP CIRC S, P17, DOI 10.1109/ISCAS.2013.6571771
   Wolberg G., 1990, Digital image warping
   Yanwei Liu, 2009, 2009 Data Compression Conference. DCC 2009, P352, DOI 10.1109/DCC.2009.27
   Yoo S., 2014, P 9 M ITU T ISO IEC
   Yuan H, 2016, IEEE T BROADCAST, V62, P134, DOI 10.1109/TBC.2015.2492461
   Yuan H, 2014, IEEE T CIRC SYST VID, V24, P443, DOI 10.1109/TCSVT.2013.2280071
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
   Zhang Y, 2013, IEEE T IMAGE PROCESS, V22, P3497, DOI 10.1109/TIP.2013.2265883
NR 35
TC 3
Z9 3
U1 2
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 145
EP 154
DI 10.1016/j.jvcir.2018.05.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800013
DA 2024-07-18
ER

PT J
AU Rao, L
   Da, FP
AF Rao, Li
   Da, Feipeng
TI High dynamic range 3D shape determination based on automatic exposure
   selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D measurement; Fringe projection; Random noises; High dynamic range;
   Multiple exposures
ID FRINGE PROJECTION PROFILOMETRY; SATURATION AVOIDANCE; ENHANCEMENT;
   SYSTEM; CALIBRATION; INTENSITY; ACCURACY; COLOR
AB Traditional multi-exposure based high dynamic range fringe projection profilometry (FPP) technique is an effective method to obtain the 3D profiles of objects with drastic surface reflectivity variations. However, in this technique different exposure times often need to be selected empirically, making this method rather complicated. In this paper a completely automatic multi-exposure based FPP technique is proposed. No human intervention is required while applying the proposed method, which greatly simplify the whole reconstruction process. It is mathematically proved that once a pixel's modulation is larger than a threshold, the phase quality of this pixel can be considered satisfactory. This threshold can be used to guide the calculation of the needed exposure times. The software then automatically adjusts the camera's exposure time and captures the needed fringe images. Experiments show that with these captured images, the final reconstruction with a high dynamic range can be readily obtained.
C1 [Da, Feipeng] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Da, FP (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM dafp@seu.edu.cn
FU National Natural Science Foundation of China [61462072, 61628304,
   61405034, 51475092]; Scientific Research Foundation of Graduate School
   of Southeast University [YBJJ1666]
FX This work was supported by the National Natural Science Foundation of
   China [Grant Nos. 61462072, 61628304, 61405034, 51475092]; the
   Scientific Research Foundation of Graduate School of Southeast
   University [Grant No. YBJJ1666].
CR [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.207
   Babaie G, 2015, PRECIS ENG, V39, P243, DOI 10.1016/j.precisioneng.2014.06.007
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Chen B, 2016, OPT LASER ENG, V87, P83, DOI 10.1016/j.optlaseng.2016.04.012
   Chen Y., 2008, OPT COMMUN, V281, P30
   Couture V, 2011, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2011.6126458
   Ekstrand L, 2011, OPT ENG, V50, DOI 10.1117/1.3662387
   Feng SJ, 2014, OPT LASER ENG, V59, P56, DOI 10.1016/j.optlaseng.2014.03.003
   FREISCHLAD K, 1990, J OPT SOC AM A, V7, P542, DOI 10.1364/JOSAA.7.000542
   GREIVENKAMP JE, 1984, OPT ENG, V23, P350, DOI 10.1117/12.7973298
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Hoang T, 2010, OPT LETT, V35, P1992, DOI 10.1364/OL.35.001992
   Hu Q., 2005, P SOC PHOTO-OPT INS
   Jeong J, 2007, P SOC PHOTO-OPT INS, V6718, P71808, DOI 10.1117/12.754548
   Jeong J, 2010, OPT EXPRESS, V18, P27787, DOI 10.1364/OE.18.027787
   Jiang CF, 2016, OPT EXPRESS, V24, P7337, DOI 10.1364/OE.24.007337
   Jiang HZ, 2012, OPT LASER ENG, V50, P1484, DOI 10.1016/j.optlaseng.2011.11.021
   Koninckx TP, 2005, PROC CVPR IEEE, P611
   Li D, 2014, OPT EXPRESS, V22, P9887, DOI 10.1364/OE.22.009887
   Li JL, 2003, J OPT SOC AM A, V20, P106, DOI 10.1364/JOSAA.20.000106
   Lin H, 2016, OPT EXPRESS, V24, P7703, DOI 10.1364/OE.24.007703
   Madden BC, 1993, TECH REP CIS, P248
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Nayar S., 2000, P IEEE C COMP VIS PA, P1063
   Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113
   OHYAMA N, 1988, J OPT SOC AM A, V5, P2019, DOI 10.1364/JOSAA.5.002019
   Proll KP, 2002, APPL OPTICS, V41, P130, DOI 10.1364/AO.41.000130
   Rao L, 2016, OPT EXPRESS, V24, P1222, DOI 10.1364/OE.24.001222
   RATHJEN C, 1995, J OPT SOC AM A, V12, P1997, DOI 10.1364/JOSAA.12.001997
   Ri S, 2008, APPL OPTICS, V47, P5400, DOI 10.1364/AO.47.005400
   Salahieh B, 2014, OPT EXPRESS, V22, P10064, DOI 10.1364/OE.22.010064
   Song Z, 2017, OPT LASER ENG, V95, P8, DOI 10.1016/j.optlaseng.2017.03.008
   Waddington C, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.8.084109
   Waddington C, 2014, OPT COMMUN, V333, P32, DOI 10.1016/j.optcom.2014.07.039
   Waddington C, 2010, OPT LASER ENG, V48, P251, DOI 10.1016/j.optlaseng.2009.07.001
   Waddle C., 2010, 2010 INT S OPT TECHN, P1
   Wang MM, 2017, OPT COMMUN, V385, P43, DOI 10.1016/j.optcom.2016.10.023
   Yang ZD, 2014, OPT LASER ENG, V54, P31, DOI 10.1016/j.optlaseng.2013.09.003
   Zhang C, 2014, IEEE T AUTOM SCI ENG, V11, P775, DOI 10.1109/TASE.2013.2293576
   Zhang S, 2007, APPL OPTICS, V46, P36, DOI 10.1364/AO.46.000036
   Zhang S, 2009, OPT ENG, V48, DOI 10.1117/1.3099720
   Zuo C, 2016, OPT LASER ENG, V85, P84, DOI 10.1016/j.optlaseng.2016.04.022
NR 42
TC 56
Z9 64
U1 9
U2 79
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 217
EP 226
DI 10.1016/j.jvcir.2017.12.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700022
DA 2024-07-18
ER

PT J
AU Lin, HY
   Lin, CY
   Zhao, Y
   Wang, AH
AF Lin, Hongyun
   Lin, Chunyu
   Zhao, Yao
   Wang, Anhong
TI 3D saliency detection based on background detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D saliency detection; Background detection; Envisioned background;
   Polynomial fitting; Salient region
ID VISUAL-ATTENTION; OBJECT DETECTION; BOTTOM-UP; MODEL
AB Unlike 2D saliency detection, 3D saliency detection can consider the effects of depth and binocular parallax. In this paper, we propose a 3D saliency detection approach based on background detection via depth information. With the aid of the synergism between a color image and the corresponding depth map, our approach can detect the distant background and surfaces with gradual changes in depth. We then use the detected background to predict the potential characteristics of the background regions that are occluded by foreground objects through polynomial fitting; this step imitates the human imagination/envisioning process. Finally, a saliency map is obtained based on the contrast between the foreground objects and the potential background. We compare our approach with 14 state-of-the-art saliency detection methods on three publicly available databases. The proposed model demonstrates good performance and succeeds in detecting and removing backgrounds and surfaces of gradually varying depth on all tested databases.
C1 [Lin, Hongyun; Lin, Chunyu; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
   [Wang, Anhong] Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
C3 Beijing Jiaotong University; Taiyuan University of Science & Technology
RP Lin, CY (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
EM cylin@bjtu.edu.cn
RI Lin, Chunyu/AAI-5185-2021
OI Lin, Chunyu/0000-0003-2847-0349
FU National Natural Science Foundation of China [61402034, 61210006,
   61501379]; Fundamental Research Funds for the Central Universities
   [2017JBZ108, 2015JBZ002]
FX This work has been supported by National Natural Science Foundation of
   China (Nos. 61402034, 61210006, 61501379), supported by the Fundamental
   Research Funds for the Central Universities (2017JBZ108, 2015JBZ002).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], IS T SPIE ELECT IMAG
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruce NDB, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P88, DOI 10.1109/CRV.2005.13
   Chen SH, 2014, OPTIK, V125, P569, DOI 10.1016/j.ijleo.2013.07.014
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Findlay J., 1991, REPRESENT VISION TRE, V12, P153
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Grady L, 2011, IEEE I CONF COMP VIS, P367, DOI 10.1109/ICCV.2011.6126264
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Judd T., A benchmark of computational models of saliency to predict human fixations
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouerhani N, 2000, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2000.905356
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Potapova Ekaterina, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P132, DOI 10.1007/978-3-642-23968-7_14
   Roy S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P523
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   van Zoest W, 2004, PERCEPTION, V33, P927, DOI 10.1068/p5158
   Wang J., 2010, IS T SPIE ELECT IMAG
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 42
TC 4
Z9 4
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 238
EP 253
DI 10.1016/j.jvcir.2017.06.011
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700019
DA 2024-07-18
ER

PT J
AU Moeini, H
   Mozaffari, S
AF Moeini, Hossein
   Mozaffari, Saeed
TI Gender dictionary learning for gender classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gender classification; Real-world face images; Dictionary learning;
   Probability decision making; Sparse representation
ID DISCRIMINATIVE DICTIONARY; FACE-RECOGNITION; K-SVD; FUSION; ROBUST
AB Human gender is one of the important demographic distinctiveness for facial image description. In this paper, a novel method is proposed for gender classification from real-world images under wide ranges of pose, expression and so on. To this end, an automatic feature extraction method is proposed by two types of features. Then, two separate dictionaries for male and female genders are defined for representing the gender in facial images. Also, two dictionary learning methods are proposed to learn the defined dictionaries in training process. Then, the Sparse Representation Classification (SRC) is adopted for classification in the testing process. Finally, a probability decision making approach is proposed to classify the gender from estimated values by SRC and proposed gender formulation. Convincing results are obtained for gender classification on three publicity databases including the FERET, LFW and Groups databases compared to several state-of-the-arts. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Moeini, Hossein; Mozaffari, Saeed] Semnan Univ, Dept Elect Engn, Semnan, Iran.
C3 Semnan University
RP Moeini, H (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM hosseinmoeini@semnan.ac.ir
OI zy, P/0009-0006-2820-8788
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   Andreu Y, 2014, IMAGE VISION COMPUT, V32, P27, DOI 10.1016/j.imavis.2013.11.001
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C INT COMP
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, CVPR
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 2012, CVPR
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   BenAbdelkader C., 2005, IEEE WORKSH COMP VIS
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011
   Hadid A., 2015, PATTERN RECOGN LETT
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Huang G.B., 2008, PROC WORKSHOP FACES
   Ji YL, 2015, J VIS COMMUN IMAGE R, V33, P340, DOI 10.1016/j.jvcir.2015.10.001
   Jia S, 2015, PATTERN RECOGN LETT, V58, P35, DOI 10.1016/j.patrec.2015.02.006
   Jiang H, 2011, PROC CVPR IEEE
   Jiang QP, 2015, J VIS COMMUN IMAGE R, V33, P123, DOI 10.1016/j.jvcir.2015.09.009
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Krizhevsky A., 2012, C ADV NEUR INF PROC
   Kumar N., 2008, INT EUR C COMP VIS E
   Lapedriza A., 2006, IEEE C COMP VIS PATT
   Levi G, 2015, IEEE COMPUT SOC CONF
   Li L, 2015, J VIS COMMUN IMAGE R, V31, P231, DOI 10.1016/j.jvcir.2015.06.008
   Li S., 2015, CVPR
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Mery D., 2015, Pattern Recognition Letters
   Moeini A, 2015, ELECTRON LETT, V51, P760, DOI 10.1049/el.2015.0520
   Moeini A., 2015, IET IMAGE P
   Moeini A, 2016, J VIS COMMUN IMAGE R, V35, P1, DOI 10.1016/j.jvcir.2015.11.006
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Moeini A, 2015, IMAGE VISION COMPUT, V36, P9, DOI 10.1016/j.imavis.2015.01.007
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rai P, 2014, J VIS COMMUN IMAGE R, V25, P1118, DOI 10.1016/j.jvcir.2014.03.009
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Sun Y., 2014, CVPR
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003
   Xu LL, 2016, J VIS COMMUN IMAGE R, V38, P561, DOI 10.1016/j.jvcir.2016.04.003
   Yang ZG, 2006, INT C PATT RECOG, P1099
   Zhanga L., 2011, IEEE INT C COMP VIS
NR 48
TC 17
Z9 17
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 1
EP 13
DI 10.1016/j.jvcir.2016.11.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200001
DA 2024-07-18
ER

PT J
AU Hu, J
   He, G
   Li, YS
AF Hu, Jing
   He, Gang
   Li, Yunsong
TI Fast algorithm based on the sole- and multi-depth texture measurements
   for HEVC intra coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Fast coding algorithm; Depth decision; Intra prediction
ID STANDARD; PREDICTION; DECISION
AB In High Efficiency Video Coding (HEVC), intra coding plays an important role, but also involves huge computational complexity due to a flexible coding unit (CU) structure and a large number of prediction modes. This paper presents a fast algorithm based on the sole- and multi-depth texture measurements to reduce the complexity from CU size and prediction mode decisions. For the CU size decision, evaluation results in the CU coding with one and multiple depths are utilized to classify CUs into heterogeneous, homogeneous, depth-prominent and other ones. Fast CU size decisions are made for different kinds of CUs. For the prediction mode decision, the tendencies for different CU sizes are detected based on multiple depths. The number of searching modes is decreased adaptively for the CU size with fewer tendencies. Experimental results show the proposed algorithm by off-line training reduces 53.32% computational complexity, with 1.47% bit-rate increasing. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hu, Jing; He, Gang; Li, Yunsong] Xidian Univ, Sch Telecommun, 2 Tai Bai Rd, Xian 710071, Peoples R China.
C3 Xidian University
RP He, G (corresponding author), Xidian Univ, Sch Telecommun, 2 Tai Bai Rd, Xian 710071, Peoples R China.
EM ghe@xidian.edu.cn
FU National Natural Science Foundation of China [61502367]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016JQ6018];
   Fundamental Research Funds for the Central Universities; China
   Postdoctoral Science Foundation [61222101]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61502367, Natural Science Basic Research Plan in
   Shaanxi Province of China (Program No. 2016JQ6018), Fundamental Research
   Funds for the Central Universities, China Postdoctoral Science
   Foundation funded project 61222101.
CR [Anonymous], 2014, CONS EL ISCE 2014 18
   [Anonymous], VCEGM33ITUTO616
   [Anonymous], 2012, P 20 INT C SOFTW TEL
   Bossen F., IDCT PRUNING SCAN DE
   Cassa MB, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P493, DOI 10.1109/PCS.2012.6213262
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Côté G, 1998, IEEE T CIRC SYST VID, V8, P849, DOI 10.1109/76.735381
   Fu C.-M., 2011, PROC IEEE 13 INT WOR, P1
   Heindel A, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P559, DOI 10.1109/ChinaSIP.2015.7230465
   Johar S, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P721, DOI 10.1109/CCNC.2013.6488534
   Khan MUK, 2013, IEEE IMAGE PROC, P1578, DOI 10.1109/ICIP.2013.6738325
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Ohm Jens-Rainer, 2012, JCTVCH0022R1 ITUT SG, P1
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Saurty K, 2014, INT CONF DIGIT INFO, P247, DOI 10.1109/DICTAP.2014.6821690
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Shi W, 2015, IEEE ICCE, P298, DOI 10.1109/ICCE-TW.2015.7216908
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   SULLIVAN GJ, 2010, SPIE OPTICAL ENG APP, V7798
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
   Zou F., 2011, 2011 IEEE INT C ROB, P1
NR 30
TC 4
Z9 4
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 671
EP 681
DI 10.1016/j.jvcir.2016.08.007
PN B
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600022
DA 2024-07-18
ER

PT J
AU Zheng-Ping, H
   Fan, B
   Shu-Huan, Z
   Meng, W
   Zhe, S
AF Zheng-ping, Hu
   Fan, Bai
   Shu-huan, Zhao
   Meng, Wang
   Zhe, Sun
TI Extended common molecular and discriminative atom dictionary based
   sparse representation for face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Sparse representation; Extended dictionary; Principal
   component analysis; Maximum probability
ID ILLUMINATION; PATTERN
AB The employed dictionary plays an important role in sparse representation classification, however how to build the relationship between dictionary atoms and class labels is still an important open question. Many existing sparse representation classification dictionary models exploit only the discriminative information either in the representation coefficients or in the representation residual, which limits their performance. To address this issue, we introduce a novel dictionary building method which is constructed by two parts: the common molecular dictionary and the discriminative atom dictionary. More specifically, the discriminative atom dictionary builds its relationship to class labels and the extended molecular dictionary can reduce the representation residual for all the classes. Therefore, the new dictionary not only has correspondence to the class labels, but also has the perfect representation ability. Besides, the maximum probability representation is used for the final classification. In conclusion, the sparse coefficient of our method is sparser than the sparse representation-based classification (SRC), and our method can achieve better performance. Experiments on the AR, Extended Yale B and CMU PIE face datasets verify that our algorithm outperforms many recently proposed methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zheng-ping, Hu; Fan, Bai; Shu-huan, Zhao; Meng, Wang; Zhe, Sun] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Peoples R China.
   [Meng, Wang] Taishan Univ, Sch Phys & Elect Engn, Tai An, Shandong, Peoples R China.
C3 Yanshan University; Taishan University
RP Zheng-Ping, H (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Peoples R China.
EM hzp@ysu.edu.cn
RI Lu, Rui/KCJ-8212-2024
CR [Anonymous], 1998, AR FAC DAT
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Hamidi H, 2015, IET IMAGE PROCESS, V9, P716, DOI 10.1049/iet-ipr.2013.0663
   He R, 2011, NEURAL COMPUT, V23, P2074, DOI 10.1162/NECO_a_00155
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hua G., IEEE T PATTERN ANAL, V33
   Jain A. K., 2011, HDB FACE RECOGNITION
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Ren JF, 2013, IEEE IMAGE PROC, P3680, DOI 10.1109/ICIP.2013.6738759
   Shiau YH, 2012, IEEE IMAGE PROC, P1445, DOI 10.1109/ICIP.2012.6467142
   Shrivastava A, 2014, IEEE T IMAGE PROCESS, V23, P3013, DOI 10.1109/TIP.2014.2324290
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Wang CP, 2015, J VIS COMMUN IMAGE R, V26, P265, DOI 10.1016/j.jvcir.2014.09.013
   Wei CP, 2015, IEEE T IMAGE PROCESS, V24, P1722, DOI 10.1109/TIP.2015.2409738
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu C., 2013, arXiv
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhao SH, 2015, INFORM PROCESS LETT, V115, P677, DOI 10.1016/j.ipl.2015.04.004
NR 27
TC 5
Z9 6
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 42
EP 50
DI 10.1016/j.jvcir.2016.05.019
PN A
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500005
DA 2024-07-18
ER

PT J
AU Chen, Y
   Yang, XN
   Zhong, BN
   Zhang, HZ
   Lin, CL
AF Chen, Yan
   Yang, Xiangnan
   Zhong, Bineng
   Zhang, Huizhen
   Lin, Changlong
TI Network in network based weakly supervised learning for visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Little supervision; Handcrafted features; Visual tracking; Deep network;
   Network in network; Object appearance model; Large scale training data;
   Drifting problem
ID MODELS
AB One of the key limitations of the many existing visual tracking method is that they are built upon low-level visual features and have limited predictability power of data semantics. To effectively fill the semantic gap of visual data in visual tracking with little supervision, we propose a tracking method which constructs a robust object appearance model via learning and transferring mid-level image representations using a deep network, i.e., Network in Network (NIN). First, we design a simple yet effective method to transfer the mid-level features learned from NIN on the source tasks with large scale training data to the tracking tasks with limited training data. Then, to address the drifting problem, we simultaneously utilize the samples collected in the initial and most previous frames. Finally, a heuristic schema is used to judge whether updating the object appearance model or not. Extensive experiments show the robustness of our method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Yan; Yang, Xiangnan; Zhong, Bineng; Zhang, Huizhen; Lin, Changlong] Huaqiao Univ, Dept Comp Sci & Technol, Xiamen 361021, Fujian, Peoples R China.
C3 Huaqiao University
RP Chen, Y (corresponding author), Huaqiao Univ, Xiamen 361021, Fujian, Peoples R China.
EM yannychen@hqu.edu.cn
RI Zhang, Hw/HPD-4999-2023; Zhang, Cheng/JAD-2236-2023; zhang,
   hui/GXH-6098-2022; ZHANG, hui jie/HTN-1690-2023; Zhang,
   Hui/HHN-8494-2022
FU Natural Science Foundation of China [61572205, 61202299, 61502181,
   61403150]; Natural Science Foundation of Fujian Province of China
   [2015J01257, 2014J05075]; Promotion Program for Young and Middle-aged
   Teacher in Science and Technology Research of Huaqiao University
   [ZQN-PY210]; 2015 Program for New Century Excellent Talents in Fujian
   Province University; Outstanding Young Persons' Research Program for
   Higher Education of Fujian Province [JA13007]
FX This work is supported by Natural Science Foundation of China (Nos.
   61572205, 61202299, 61502181, and 61403150), Natural Science Foundation
   of Fujian Province of China (Nos. 2015J01257 and 2014J05075), Promotion
   Program for Young and Middle-aged Teacher in Science and Technology
   Research of Huaqiao University (No. ZQN-PY210), 2015 Program for New
   Century Excellent Talents in Fujian Province University, and Outstanding
   Young Persons' Research Program for Higher Education of Fujian Province
   (No. JA13007).
CR [Anonymous], BRIT MACH VIS C
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2013, P IEEE COMP SOC C CO
   [Anonymous], 2013, CoRR
   [Anonymous], ARXIV150104587
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Carneiro G, 2013, IEEE T PATTERN ANAL, V35, P2592, DOI 10.1109/TPAMI.2013.96
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Donahue J, 2014, PR MACH LEARN RES, V32
   Duffner S., 2013, IEEE C COMP VIS
   Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Godec M., 2011, IEEE C COMP VIS
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Guan T, 2014, IEEE MULTIMEDIA, V21, P32, DOI 10.1109/MMUL.2013.31
   Guan T, 2013, IEEE T MULTIMEDIA, V15, P1688, DOI 10.1109/TMM.2013.2265674
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A., 2012, NEURAL INFORM PROCES, V2012
   Kwon J, 2014, IEEE T PATTERN ANAL, V36, P1428, DOI 10.1109/TPAMI.2013.213
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, IEEE T IMAGE PROCESS, V22, P3028, DOI 10.1109/TIP.2013.2253478
   Lu Y., 2014, IEEE C COMP VIS PATT
   Luo YW, 2015, NEUROCOMPUTING, V156, P105, DOI 10.1016/j.neucom.2014.12.079
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mei X., 2009, IEEE C COMP VIS
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Sermanet P., 2013, IEEE C COMP VIS PATT
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Takala V., 2007, CVPR
   Wang C, 2015, DES AUT TEST EUROPE, P884
   Wang C, 2015, IEEE ACM T COMPUT BI, V12, P166, DOI 10.1109/TCBB.2014.2351800
   Wang N, 2013, P ADV NEURAL INFORM
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700
   Wei BC, 2014, IEEE MULTIMEDIA, V21, P41, DOI 10.1109/MMUL.2013.65
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang K.H., 2015, ROBUST TRACKING VIA
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
NR 59
TC 4
Z9 6
U1 0
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 3
EP 13
DI 10.1016/j.jvcir.2015.10.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700002
DA 2024-07-18
ER

PT J
AU Sun, SW
   Kuo, CH
   Chang, PC
AF Sun, Shih-Wei
   Kuo, Chien-Hao
   Chang, Pao-Chi
TI People tracking in an environment with multiple depth cameras: A
   skeleton-based pairwise trajectory matching scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE People tracking; Multiple depth cameras; Trajectory matching; Fusion;
   Skeleton; Pairwise; Occlusion; Hand gesture
AB This paper proposes a pairwise trajectory matching scheme from multiple cameras for people tracking, handling the mistracking situations caused by occlusion events occurred in one of the cameras. In a multiple cameras environment, a geometric calibration process is necessary for the co-plane of the overlapping field of views from different cameras as the initial step. Once the geometry is calibrated, according to the 2D positions of the analyzed foot joints from the depth cameras. Homography transformation is applied to project the detected foot points from different views into a synergistic virtual bird's eye view for people tracking. At the virtual bird's eye view, the people tracking results from each of the cameras based on Kalman filter are fused according to the proposed pairwise trajectory matching scheme. The contribution of this paper is trifold: (1) The proposed hand-gesture-triggered calibration process with temporally synchronization capability can effectively build and calibrate the geometry in a region of interest. (2) The proposed interleaving-based skeleton obtaining and moving average based valid skeleton determination can extend the skeleton tracking capability to track more people. (3) The proposed pairwise trajectory matching scheme effectively manages occlusion situations happened in one of the depth cameras. In addition, in the extensive experimental results, the proposed method can track up to six simultaneously freely moving persons in the field of view, with affordable complexity for realtime applications. Furthermore, the infrared-based depth cameras track people satisfactorily from bright to extremely dark environments. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Sun, Shih-Wei] Taipei Natl Univ Arts, Dept New Media Art, Taipei, Taiwan.
   [Sun, Shih-Wei] Taipei Natl Univ Arts, Ctr Art & Technol, Taipei, Taiwan.
   [Kuo, Chien-Hao; Chang, Pao-Chi] Natl Cent Univ, Commun Engn, Jhongli, Taiwan.
C3 National Central University
RP Sun, SW (corresponding author), Taipei Natl Univ Arts, Dept New Media Art, Taipei, Taiwan.
EM swsun@newmedia.tnua.edu.tw
OI Sun, Shih-Wei/0000-0003-2761-7484
FU Ministry of Science and Technology, Taiwan [MOST 104-2221-E-119-001]
FX This research is partially supported by Ministry of Science and
   Technology, Taiwan, under Grant No. MOST 104-2221-E-119-001.
CR [Anonymous], 2003, IEEE COMPUT SOC C CO
   [Anonymous], 2004, Probabilistic curve-aligned clustering and prediction with regression mixture models
   Bagautdinov T., 2015, IEEE COMP SOC C COMP
   Baum M., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P186, DOI 10.1109/MFI.2012.6343003
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Black J, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P169, DOI 10.1109/MOTION.2002.1182230
   Bradshaw KJ, 1997, IEEE T PATTERN ANAL, V19, P219, DOI 10.1109/34.584099
   Cai Q, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P356, DOI 10.1109/ICCV.1998.710743
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Giebel J, 2004, LECT NOTES COMPUT SC, V2034, P241
   Gruenwedel S, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2530282
   Han M, 2004, PROC CVPR IEEE, P864
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Jafari OH, 2014, IEEE INT CONF ROBOT, P5636, DOI 10.1109/ICRA.2014.6907688
   Khan S, 2000, AS C COMP VIS, P1132
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lee S., 2014, J ELECTRON IMAGING, V23
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maimone A, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P51, DOI 10.1109/VR.2012.6180879
   Mikic I., 1998, IMAGE UNDERSTANDING, P183
   Munaro M, 2014, AUTON ROBOT, V37, P227, DOI 10.1007/s10514-014-9385-0
   Ozturk Ovgu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1020, DOI 10.1109/ICCVW.2009.5457590
   Sharma K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033017
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Smith K, 2005, PROC CVPR IEEE, P962
   Sun S.W., 2009, AS PAC SIGN INF PROC
   Welch Greg., 2002, An Introduction to the Kalman Filter
NR 31
TC 13
Z9 14
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 36
EP 54
DI 10.1016/j.jvcir.2015.11.012
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600004
DA 2024-07-18
ER

PT J
AU Dakua, SP
   Abinahed, J
   Al-Ansari, AA
AF Dakua, Sarada Prasad
   Abinahed, Julien
   Al-Ansari, Abdulla A.
TI Pathological liver segmentation using stochastic resonance and cellular
   automata
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CT; Image segmentation; Dynamic cellular automata; Stochastic resonance;
   Graph cut; Liver; Contrast enhancement; Discrete Gabor transform
ID CT; IMAGES; ENHANCEMENT; NOISE; MODELS
AB Liver segmentation continues to remain a major challenge, largely due to its intensity complexity with surrounding anatomical structures (stomach, kidney, and heart), high noise level and lack of contrast in pathological computed tomography data. In this paper, we present an approach to reconstructing the liver surface in low contrast computed tomography. The main contributions are: (1) a stochastic resonance based methodology in discrete cosine transform domain is developed to enhance the contrast of pathological liver images, (2) a new formulation is proposed to prevent the object boundary, resulted by cellular automata method, from leaking into the surrounding areas of similar intensity, and (3) a level-set method is suggested to generate intermediate segmentation contours from two segmented slices distantly located in a subject sequence. We have tested the algorithm on real datasets obtained from two sources, Hamad General Hospital and MICCAI Grand Challenge workshop. Both qualitative and quantitative evaluation performed on liver data show promising segmentation accuracy when compared with ground truth data reflecting the potential of the proposed method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Dakua, Sarada Prasad; Abinahed, Julien] Qatar Robot Surg Ctr, Qatar Sci & Technol Pk, Doha, Qatar.
   [Al-Ansari, Abdulla A.] Hamad Gen Hosp, Dept Urol, Doha, Qatar.
C3 Qatar Mobility Innovations Center (QMIC); Hamad Medical Corporation;
   Hamad General Hospital
RP Dakua, SP (corresponding author), Qatar Robot Surg Ctr, Qatar Sci & Technol Pk, Doha, Qatar.
EM sdakua@qstp.org.qa
OI Dakua, Sarada Prasad/0000-0003-2979-0272; , Julien/0000-0002-6386-4813
CR Balcan DC, 2012, APPL COMPUT HARMON A, V33, P300, DOI 10.1016/j.acha.2012.03.008
   Beck A., 2007, MICCAI 2007 WORKSHOP, P225
   Beichel R., 2007, Proc. of 3D Segmentation in The Clinic: A Grand Challenge, P235
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bracewell R. N, 1986, FOURIER TRANSFORM IT, V3rd
   BRACEWELL RN, 1983, J OPT SOC AM, V73, P1832, DOI 10.1364/JOSA.73.001832
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chandrasekhar S, 1943, REV MOD PHYS, V15, P0001, DOI 10.1103/RevModPhys.15.1
   Chang CL, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3830
   Choudhary A., 2008, MICCAIWorkshop, V41, P43
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Cui S, 2010, J MICROELECTROMECH S, V19, P1153, DOI 10.1109/JMEMS.2010.2067433
   Dawant BM., 2007, Proc MICCAI Workshop on 3D Segmentation in the Clinic: a Grand Challenge, P215
   DOMANY E, 1984, PHYS REV LETT, V53, P311, DOI 10.1103/PhysRevLett.53.311
   Eslami A, 2013, MED IMAGE ANAL, V17, P236, DOI 10.1016/j.media.2012.10.005
   Foruzan AH, 2009, INT J COMPUT ASS RAD, V4, P287, DOI 10.1007/s11548-009-0293-2
   Foruzan AH, 2009, COMPUT MED IMAG GRAP, V33, P567, DOI 10.1016/j.compmedimag.2009.03.008
   Gallego J, 2012, LOG J IGPL, V20, P617, DOI 10.1093/jigpal/jzr003
   Gammaitoni L, 1998, REV MOD PHYS, V70, P223, DOI 10.1103/RevModPhys.70.223
   Gao J, 2005, ACAD RADIOL, V12, P1178, DOI 10.1016/j.acra.2005.05.005
   Gard T. C, 1998, Introduction to Stochastic Differential Equations
   Goryawala M, 2012, IEEE T INF TECHNOL B, V16, P62, DOI 10.1109/TITB.2011.2171191
   Han SD, 2009, IEEE T IMAGE PROCESS, V18, P2289, DOI 10.1109/TIP.2009.2025560
   Heimann T, 2005, LECT NOTES COMPUT SC, V3565, P566
   Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851
   Hermoye L, 2005, RADIOLOGY, V234, P171, DOI 10.1148/radiol.2341031801
   Hongler MO, 2003, IEEE T PATTERN ANAL, V25, P1051, DOI 10.1109/TPAMI.2003.1227982
   Jha R. K., 2012, P ADV COMP SCI ENG A, V166, P235
   Ji HW, 2013, IEEE J BIOMED HEALTH, V17, P690, DOI 10.1109/JBHI.2013.2242480
   Kauffmann C, 2010, INT J COMPUT ASS RAD, V5, P251, DOI 10.1007/s11548-009-0392-0
   Kim E., 2010, P 23 IEEE INT S COMP, P1849
   Lee J., 2007, Proc. MICCAI Workshop on 3-D Segmentat. Clinic: A Grand Challenge, P189
   Lee J, 2007, COMPUT METH PROG BIO, V88, P26, DOI 10.1016/j.cmpb.2007.07.005
   Lim SJ, 2006, J VIS COMMUN IMAGE R, V17, P860, DOI 10.1016/j.jvcir.2005.07.001
   Liu F, 2005, MED PHYS, V32, P3699, DOI 10.1118/1.2132573
   Massoptier L, 2008, EUR RADIOL, V18, P1658, DOI 10.1007/s00330-008-0924-y
   Mejia JM, 2014, IEEE T MED IMAGING, V33, P2010, DOI 10.1109/TMI.2014.2329702
   Mharib AM, 2012, ARTIF INTELL REV, V37, P83, DOI 10.1007/s10462-011-9220-3
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Mukherjee J, 2008, IEEE T IMAGE PROCESS, V17, P1783, DOI 10.1109/TIP.2008.2002826
   NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570
   Nowozin S, 2006, HUMAN INTERACTION WITH MACHINES, P177, DOI 10.1007/1-4020-4043-1_19
   Oliva Maria Raquel, 2004, Cancer Imaging, V4 Spec No A, pS42, DOI 10.1102/1470-7330.2004.0011
   Park H, 2003, IEEE T MED IMAGING, V22, P483, DOI 10.1109/TMI.2003.809139
   PRATT WK, 1978, IEEE T SYST MAN CYB, V8, P796, DOI 10.1109/TSMC.1978.4309867
   Rallabandi VPS, 2010, MAGN RESON IMAGING, V28, P1361, DOI 10.1016/j.mri.2010.06.014
   Rallabandi VPS, 2008, J COMPUT ASSIST TOMO, V32, P966, DOI 10.1097/RCT.0b013e318159c638
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rousseau D, 2006, SIGNAL PROCESS, V86, P3456, DOI 10.1016/j.sigpro.2006.03.008
   Ryu C, 2011, PATTERN RECOGN LETT, V32, P107, DOI 10.1016/j.patrec.2010.09.008
   Seghers D., 2007, Proc MICCAI Workshop on 3D Segmentation in the Clinic: a Grand Challenge, P135
   Selver MA, 2008, COMPUT BIOL MED, V38, P765, DOI 10.1016/j.compbiomed.2008.04.006
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Singh S, 2005, IEEE T INF TECHNOL B, V9, P109, DOI 10.1109/TITB.2004.837851
   Suzuki K, 2010, MED PHYS, V37, P2159, DOI 10.1118/1.3395579
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Villasenor J. D., 1993, IEEE T IMAGE MED IMA, V12
   Wang ST, 2007, ARTIF INTELL MED, V39, P65, DOI 10.1016/j.artmed.2006.08.001
   Wimmer Andreas., 2007, Proc MICCAI Workshop on 3D Segmentation in the Clinic: a Grand Challenge, P179
   Ye Q, 2003, P IEEE INT C IM PROC, V5, P1849
   Zhang X, 2010, IEEE T BIO-MED ENG, V57, P2622, DOI 10.1109/TBME.2010.2056369
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 64
TC 29
Z9 30
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 89
EP 102
DI 10.1016/j.jvcir.2015.10.016
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400008
DA 2024-07-18
ER

PT J
AU Xia, XP
   Liu, EH
   Qin, JJ
AF Xia, Xiao-Peng
   Liu, En-Hai
   Qin, Jun-Ju
TI Improved SAP based on adaptive directional prediction for HEVC lossless
   intra prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Intra-coding; Lossless video coding; SAP; Linear interpolation;
   Prediction modes; ADSAP; Frame-level pretreatment
AB In HEVC (High Efficiency Video Coding), linear interpolation of the boundary pixels is used as the predictor and pixels within the same PU (Prediction Unit) are in the same prediction direction. When the PU block is large and in high complexity, the prediction performance would worsen. Although many algorithms use the pixel-based weighted averaging or interpolation operations to perform the prediction which improves the performance of bitrate saving notably, there is still space for further improvement. This paper proposed an improved SAP (Sample-based Angular Prediction) algorithm based on adaptive directional prediction (ADSAP). The innovation of this paper lies in two aspects: it puts forward a new method to estimate the best prediction direction of current pixel and it introduces the concept of "frame-level pretreatment" which could greatly improve the encoding speed. Experimental results show that it could save the output bitrate by about 9.4158% when compared with the HEVC lossless intra prediction algorithm, which is better than other typical algorithms. Besides, the encoding and decoding time are reduced by about 11%. Moreover, when the minimum PU size gets larger, the increase of output bitrate of ADSAP is much less than that of HEVC and the conventional SAP algorithm, which makes the proposed algorithm quite suitable for the compression of high resolution videos. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Xia, Xiao-Peng; Liu, En-Hai] Chinese Acad Sci, Inst Opt & Elect, Chengdu 610209, Peoples R China.
   [Xia, Xiao-Peng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Qin, Jun-Ju] Chengdu Normal Univ, Chengdu 610072, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Optics & Electronics, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chengdu Normal University
RP Xia, XP (corresponding author), Chinese Acad Sci, Inst Opt & Elect, Chengdu 610209, Peoples R China.
EM tabam07uestc@163.com
RI liu, jianyang/JXL-6273-2024
FU National Key Basic Research Program of China [2014CB744200]
FX This research was in part supported by National Key Basic Research
   Program of China (2014CB744200).
CR [Anonymous], JCTVCG093
   [Anonymous], 2012, document JCTVC-H1100 of JCT-VC
   [Anonymous], JCTVCH0083
   Dong L., 2011, JCTVCD255
   Gao W., 2012, JCTVH0530
   Gao W., 2013, P SPIE INT SOC OPTIC, P8666
   Hong S.-W., 2013, SIGNAL PROCESS-IMAGE, V9, P1
   곽재희, 2012, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V17, P734
   Song L, 2011, IEEE T CIRC SYST VID, V21, P1924, DOI 10.1109/TCSVT.2011.2154710
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan Y.-H., 2012, JCTVCK0157
   Tan YH, 2013, INT CONF ACOUST SPEE, P2021, DOI 10.1109/ICASSP.2013.6638008
   Wang LL, 2013, IEEE INT SYMP CIRC S, P265, DOI 10.1109/ISCAS.2013.6571833
   Wige E, 2013, IEEE IMAGE PROC, P1806, DOI 10.1109/ICIP.2013.6738372
   Wu P., 2012, ZTE COMMUN, V110, P1
   Zhang Q, 2009, IEEE INT SYMP CIRC S, P617, DOI 10.1109/ISCAS.2009.5117824
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 17
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 78
EP 84
DI 10.1016/j.jvcir.2015.09.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700008
DA 2024-07-18
ER

PT J
AU Chen, F
   Zeng, XX
   Wang, MQ
AF Chen, Fei
   Zeng, Xunxun
   Wang, Meiqing
TI Image denoising via local and nonlocal circulant similarity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Circulant similarity; Patch filter; Nonlocal; Gaussian
   kernel; Circulant matrix; Low-rank method; Fast Fourier transform
ID SPARSE; ALGORITHM
AB A patch based image denoising method is developed in this paper by introducing a new type of image self-similarity. This self-similarity is obtained by cyclic shift, which is called "circulant similarity". Given a corrupted image patch, it can be estimated by incorporating circulant similarity into a weighted averaging filter. By choosing an appropriate kernel as weight function, the patch filter is implemented by circular convolution, and can be efficiently solved using fast Fourier transform. In addition, the circulant similarity can be enhanced by using nonlocal modeling. We stack the similar image patches into 3D groups, and propose a denoising scheme based on group estimation across the patches. Numerical experiments demonstrate that the proposed method with local circulant similarity outperforms much its local filtering based counterparts, and the proposed method with nonlocal circulant similarity shows very competitive performance with state-of-the-art denoising method, especially on images corrupted by strong noise. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Fei; Zeng, Xunxun; Wang, Meiqing] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.
C3 Fuzhou University
RP Chen, F (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.
EM chenfei314@fzu.edu.cn; xunxun@fzu.edu.cn; mqwang@fzu.edu.cn
OI Chen, Fei/0000-0002-3676-6011
FU Natural Science Foundation of China [61401098]; Open Project Program of
   the State Key Lab of CAD&CG, Zhejiang University [A1415]; Scientific
   Research Starting Foundation of Fuzhou University [022575]; Science and
   Technology Development Foundation of Fuzhou University [2014-XY-21]
FX This work is supported by the Natural Science Foundation of China (Grant
   No. 61401098), the Open Project Program of the State Key Lab of CAD&CG
   (Grant No. A1415), Zhejiang University, the Scientific Research Starting
   Foundation of Fuzhou University (Grant No. 022575), and Science and
   Technology Development Foundation of Fuzhou University (Grant No.
   2014-XY-21).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], WAVELET TOUR SIGNAL
   Buades A., P CVPR
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M., P IEEE SPEC ISS APPL
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fergus R., P ACM SIGGRAPH
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gray R.M., 2001, Toeplitz and circulant matrices: a review
   Gu S., P CVPR
   Henriques J., P ECCV
   LINDENBAUM M, 1994, PATTERN RECOGN, V27, P1, DOI 10.1016/0031-3203(94)90013-2
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P516, DOI 10.1016/j.jvcir.2012.01.012
   Liu QG, 2012, J VIS COMMUN IMAGE R, V23, P753, DOI 10.1016/j.jvcir.2012.04.003
   Mairal J., P ICCV
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Muresan D., P ICIP
   Peng Y., P CVPR
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rabbani H, 2009, IEEE T BIO-MED ENG, V56, P2826, DOI 10.1109/TBME.2009.2028876
   Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140
   Ram I, 2013, IEEE T IMAGE PROCESS, V22, P2764, DOI 10.1109/TIP.2013.2257813
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tomasi C., P ICCV
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zontak M., P CVPR
   Zuo W., P CVPR
NR 35
TC 20
Z9 21
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 117
EP 124
DI 10.1016/j.jvcir.2015.03.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900011
DA 2024-07-18
ER

PT J
AU Chuang, CH
   Hsieh, JW
   Chiang, HF
   Chiou, YD
AF Chuang, Chi-Hung
   Hsieh, Jun-Wei
   Chiang, Hui-Fen
   Chiou, Yi-Da
TI Human movement analysis around a view circle using time-order similarity
   distributions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video surveillance; Centroid context; Behavior analysis; View
   invariance; View circle; Time-order similarity distribution; Action
   classification; HMM; Symmetrical projection; View alignment
ID RECOGNITION
AB This paper presents a new behavior classification system to analyze human movements around a view circle using time-order similarity distributions. To maintain the view in-variance, an action is represented not only from its spatial domain but also its temporal domain. After that, a novel alignment scheme is proposed for aligning each action to a fixed view. With the best view, the task of behavior analysis becomes a string matching problem. One novel idea proposed in this paper is to code a posture using not only its best matched key posture but also other unmatched key postures to form various similarity distributions. Then, recognition of two actions becomes a problem of matching two time-order distributions which can be very effectively solved by comparing their KL distance via a dynamic programming scheme. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chuang, Chi-Hung] Fo Guang Univ, Dept Learning & Digital Technol, Jiaosi 26247, Yilan, Taiwan.
   [Hsieh, Jun-Wei; Chiang, Hui-Fen] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
   [Chiou, Yi-Da] Yuan Ze Univ, Dept Elect Engn, Chungli 320, Taiwan.
C3 Fo Guang University; National Taiwan Ocean University; Yuan Ze
   University
RP Hsieh, JW (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Beining Rd, Keelung 202, Taiwan.
EM shieh@ntou.edu.tw
FU National Science Council of Taiwan,Taiwan, R.O.C [NSC
   100-2221-E-019-043-MY3]
FX This work was supported in part by National Science Council of
   Taiwan,Taiwan, R.O.C., under Grant NSC 100-2221-E-019-043-MY3.
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2007, IEEE C COMPUTER VISI
   [Anonymous], 2001, Cmu Ri Tr 01-18
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2007, 2007 IEEE C COMPUTER
   [Anonymous], 1997, Information theory and statistics
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   Farhadi A, 2009, IEEE I CONF COMP VIS, P948, DOI 10.1109/ICCV.2009.5459350
   Fathi A., 2008, IEEE COMPUTER SOC C, P1
   Gaidon A, 2011, PROC CVPR IEEE
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Karthikeyan S, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Lee CS, 2007, IEEE I CONF COMP VIS, P1570
   Maji S., 2011, IEEE C COMP VIS PATT
   Ping Y., 2008, IV International Conference on Wireless Comunications, Networking and Mobile Computing, Dalian-China, 12-17 October, P1, DOI DOI 10.1109/ISABEL.2008.4712613
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Souvenir R., 2008, IEEE C COMPUTER VISI, P1
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Weinland D., 2008, CVPR, P1
   Weinland D., 2006, COMPUTER VISION PATT, V2, P1639
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
NR 32
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 22
EP 34
DI 10.1016/j.jvcir.2015.02.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900003
DA 2024-07-18
ER

PT J
AU Li, YF
AF Li, Yafeng
TI Image segmentation via image decomposition and fuzzy region competition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Image decomposition; Variational model; Wavelet;
   Dictionary learning; Sparse representation; Morphological component
   analysis; Variational optimization
ID TOTAL VARIATION MINIMIZATION; SPARSE REPRESENTATIONS; RESTORATION;
   ALGORITHM; CARTOON
AB Taking into account the morphological diversity of images, this paper presents a novel multiphase image segmentation method that combines image decomposition and fuzzy region competition into a unified model. To efficiently solve the minimization of the energy functional, we design an optimal iteration algorithm which integrates a modified cartoon-texture dictionary learning algorithm and wavelet shrinkage. Compared with the classical fuzzy region competition method, the proposed method not only improves the overall segmentation results, but also has more strong robustness. A series of experimental results demonstrate the applicability and effectiveness of the proposed method. (C) 2015 Elsevier Inc. All rights reserved.
C1 Baoji Univ Arts & Sci, Dept Comp Sci, Baoji 721016, Shaanxi, Peoples R China.
C3 Baoji University of Arts & Sciences
RP Li, YF (corresponding author), Baoji Univ Arts & Sci, Dept Comp Sci, Baoji 721016, Shaanxi, Peoples R China.
EM liyafeng770729@126.com
FU Foundation of the National Natural Science of China [61379030];
   Scientific Research Plan Project of Shaanxi Education Department
   [14JK1048]; Natural Science Basic Research Plan in Shaanxi Province of
   China [2015JM6329]; Key Project of Baoji University of Arts and Science
   [ZK15057]
FX I would like to thank the anonymous reviewers for their help in
   improving the manuscript. This work is supported by the Foundation of
   the National Natural Science of China (No. 61379030), the Scientific
   Research Plan Project of Shaanxi Education Department (No. 14JK1048),
   the Natural Science Basic Research Plan in Shaanxi Province of China
   (No. 2015JM6329) and the Key Project of Baoji University of Arts and
   Science (No. ZK15057).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 1993, C SIGN SYST COMP
   [Anonymous], U LECT SERIES
   Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2662, DOI 10.1109/TIP.2007.906256
   Borup L, 2007, J FOURIER ANAL APPL, V13, P39, DOI 10.1007/s00041-006-6024-y
   Buades A, 2010, IEEE T IMAGE PROCESS, V19, P1978, DOI 10.1109/TIP.2010.2046605
   Choy SK, 2011, IEEE T IMAGE PROCESS, V20, P1473, DOI 10.1109/TIP.2010.2095023
   Cohen A, 2003, REV MAT IBEROAM, V19, P235
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Han Y, 2012, PATTERN RECOGN, V45, P363, DOI 10.1016/j.patcog.2011.05.002
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Jiang LL, 2008, J MATH IMAGING VIS, V30, P125, DOI 10.1007/s10851-007-0051-4
   Jung YM, 2007, SIAM J APPL MATH, V67, P1213, DOI 10.1137/060662708
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li F, 2010, SIAM J IMAGING SCI, V3, P277, DOI 10.1137/080736752
   Li F, 2010, COMMUN COMPUT PHYS, V8, P623, DOI 10.4208/cicp.160609.311209a
   Li YF, 2012, PATTERN RECOGN LETT, V33, P111, DOI 10.1016/j.patrec.2011.09.036
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mory B, 2007, IEEE I CONF COMP VIS, P1032
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Rao SR, 2010, LECT NOTES COMPUT SC, V5994, P135
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2009, LECT NOTES COMPUT SC, V5567, P464, DOI 10.1007/978-3-642-02256-2_39
   SKLANSKY J, 1978, IEEE T SYST MAN CYB, V8, P237, DOI 10.1109/TSMC.1978.4309944
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
NR 32
TC 3
Z9 3
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 328
EP 342
DI 10.1016/j.jvcir.2015.04.017
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900029
DA 2024-07-18
ER

PT J
AU Ma, XL
   Xie, XD
   Lam, KM
   Zhong, YS
AF Ma, Xiaolong
   Xie, Xudong
   Lam, Kin-Man
   Zhong, Yisheng
TI Efficient saliency analysis based on wavelet transform and entropy
   theory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Human vision system; Preprocessing technique; Color
   information; Bottom-up approach; Fixation-prediction; Wavelet transform;
   Entropy theory
ID DETECTION MODEL; IMAGE; ATTENTION; CORTEX
AB Saliency detection has extensive applications in daily life. In this paper, an efficient saliency-detection method based on wavelet transform and entropy theory is proposed. In the algorithm proposed in this paper, salient regions are viewed as uncommon regions in the background of an image. The uncommon regions can be caused by differences in color, orientation, texture, shape, or other factors. Considering the fact that wavelet coefficients can represent the local features of an image in different scales and orientations, the wavelet transform is therefore employed to identify the salient regions. Unlike those conventional wavelet-based methods, our proposed method need not perform the inverse wavelet transformation; this can reduce the computational requirements. In addition, because the different factors (i.e. color, orientation, texture, shape, etc.) stimulate different aspects of the human visual system, a saliency-map combination scheme based on the entropy theory is devised in this paper, which can evaluate the influence or significance of the different factors. Experimental results show that our method, based on wavelet transformation and entropy theory, can achieve excellent performance in terms of the area under the receiver operating characteristic curve (AUC) score, the linear correlation coefficient (CC), the normalized scan-path saliency (NSS) score, and visual performance, as compared to existing state-of-the-art methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ma, Xiaolong; Xie, Xudong; Zhong, Yisheng] Tsinghua Univ, TNlist, Beijing 100084, Peoples R China.
   [Ma, Xiaolong; Xie, Xudong; Zhong, Yisheng] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Ma, Xiaolong; Lam, Kin-Man] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
C3 Tsinghua University; Tsinghua University; Hong Kong Polytechnic
   University
RP Xie, XD (corresponding author), Tsinghua Univ, TNlist, Beijing 100084, Peoples R China.
EM go0up@163.com
CR [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2011, BMVC
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2009, ICCV
   [Anonymous], 2014, CVPR
   [Anonymous], P 20 ACM MULT C
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cat Le Ngo A., 2013, FAST NONPARAMETRIC E
   Chen HY, 2012, J VIS COMMUN IMAGE R, V23, P343, DOI 10.1016/j.jvcir.2011.11.006
   CHEN WT, 1994, PATTERN RECOGN, V27, P885, DOI 10.1016/0031-3203(94)90154-6
   Cheng Chen, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P539, DOI 10.1007/978-3-642-36669-7_66
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Ergen B, 2012, COMPUT METHOD BIOMEC, V15, P371, DOI 10.1080/10255842.2010.538386
   Fan JP, 2004, LECT NOTES COMPUT SC, V3115, P365
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Imamoglu N., 2013, IEEE T MULTIMEDIA
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jianping Fan, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P361
   KAPLAN E, 1986, P NATL ACAD SCI USA, V83, P2755, DOI 10.1073/pnas.83.8.2755
   Kishimoto K, 1995, J APPL MECH-T ASME, V62, P841, DOI 10.1115/1.2896009
   Klein D.A., 2011, 2011 IEEE INT C COMP
   Kootstra G., 2008, BMVC
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P269
   Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Ma L, 2011, IEEE IMAGE PROC, P233, DOI 10.1109/ICIP.2011.6116109
   Ma Q, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3302129
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Ramirez-Villegas JF, 2013, BIOL CYBERN, V107, P39, DOI 10.1007/s00422-012-0522-6
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846
   Szatmary B., 2013, BMC NEUROSCI
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Wei LS, 2012, DIGIT SIGNAL PROCESS, V22, P760, DOI 10.1016/j.dsp.2012.04.017
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang L., 2008, J VIS, V1, P7
NR 48
TC 15
Z9 17
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 201
EP 207
DI 10.1016/j.jvcir.2015.04.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900018
DA 2024-07-18
ER

PT J
AU Li, L
   Dong, ZH
   Lu, JF
   Dai, JP
   Huang, QR
   Chang, CC
   Wu, T
AF Li, Li
   Dong, Zihui
   Lu, Jianfeng
   Dai, Junping
   Huang, Qianru
   Chang, Chin-Chen
   Wu, Ting
TI AN H.264/AVC HDTV watermarking algorithm robust to camcorder recording
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video watermark; Camcorder recording; Watermark pattern; Robustness;
   Copyright; Geometric attack; Watson visual model; Temporal
   synchronization
ID RESISTANT
AB With the purpose of copyright protection of digital video, this paper proposes an H.264/AVC HDTV watermarking method that is robust to camcorder recording. Because contents in the consecutive frames of a video are almost identical, we embed the copyright information by fine-tuning the luminance relationship of the consecutive frames. To ensure the quality of the video and the robustness of the algorithm, we use an adaptive watermark pattern to reduce the image area to be modified, and we make the embedding strength adaptive according to the improved Watson visual model. When detecting watermarks, to reduce detecting errors caused by recording errors and shot changes, we determine the detecting area adaptively according to the size of the watermarked video and segment the video into shots using the directional empirical mode decomposition method. Experimental results show that the proposed method achieves high video quality and is robust to camcorder recording, transcoding, recoding, and other geometric attacks. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Li, Li; Dong, Zihui; Lu, Jianfeng; Huang, Qianru; Wu, Ting] Hangzhou Dianzi Univ, Inst Graph & Image, Hangzhou, Zhejiang, Peoples R China.
   [Dai, Junping] Hangzhou Dianzi Univ, Inst Digital Media, Hangzhou, Zhejiang, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; Feng Chia
   University; Asia University Taiwan
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM jflu@hdu.edu.cn; alan3c@gmail.com
RI Huang, Qianru/HNP-1533-2023; zhu, yujie/KBC-4009-2024; Chang,
   Ching-Chun/JAN-6210-2023
OI Li, Ling/0000-0001-9722-9503
FU National Science and Technology Support Program of China [2012BAH91F03];
   National Natural Science Found of China [61370218]; Natural Science
   Foundation of Zhejiang Province [LY12F02006]
FX This work was partially supported by the Sub-project under National
   Science and Technology Support Program of China (No. 2012BAH91F03) and
   the National Natural Science Found of China (No. 61370218) and the
   Natural Science Foundation of Zhejiang Province (No. LY12F02006).
CR Cedillo-Hernandez M, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P715, DOI 10.1109/TSP.2012.6256390
   Do H, 2008, IEEE INT SYMP SIGNAL, P330, DOI 10.1109/ISSPIT.2008.4775680
   Jianfeng L., 2011, MPEG2 VIDEO WATERMAR, P194
   Lee MJ, 2012, DIGIT SIGNAL PROCESS, V22, P190, DOI 10.1016/j.dsp.2011.08.001
   Lee MJ, 2009, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2009.5414109
   Manoochehri M., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P265, DOI 10.1109/ICCSN.2011.6014719
   Monga V, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P229, DOI 10.1109/ICME.2005.1521402
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Prabakaran G., 2013, ROBUST QR CODE VIDEO
   Qi X., 2004, P ICASSP 04 IEEE INT, V3
   Schlesinger M., 2010, Modern Electroplating, P1, DOI [DOI 10.1109/MUE.2010.5575079, 10.1002/9780470602638, DOI 10.1002/9780470602638]
   Shao-wen X., 2012, INF SCI CONTR ENG 20, P1, DOI [10.1049/cp.2012.2317, DOI 10.1049/CP.2012.2317]
   Su Qing-tang, 2012, Application Research of Computers, V29, P1441, DOI 10.3969/j.issn.1001-3695.2012.04.067
   Swamy P., 2013, INCORPORATING BIOMET
   Verstrepen L., 2009, 16 INT C DIG SIGN PR, P1, DOI DOI 10.1109/ICDSP.2009.5201048
   Wang XY, 2012, J VIS COMMUN IMAGE R, V23, P892, DOI 10.1016/j.jvcir.2012.05.008
   Wang YL, 2009, PROCEEDINGS 2009 IEEE INTERNATIONAL WORKSHOP ON OPEN-SOURCE SOFTWARE FOR SCIENTIFIC COMPUTATION, P169, DOI 10.1109/OSSC.2009.5416913
   Watson A. B., 1993, DCC '93. Data Compression Conference (Cat. No.93TH0536-3), P178, DOI 10.1109/DCC.1993.253132
   Xin Xu, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P831, DOI 10.1109/ICITIS.2010.5689703
   Yuan XC, 2013, IEEE INT CONF TRUST, P763, DOI 10.1109/TrustCom.2013.92
   Yuan Y., 2010, ROBUST VIDEO WATERMA, P7
NR 21
TC 20
Z9 23
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 1
EP 8
DI 10.1016/j.jvcir.2014.08.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000001
DA 2024-07-18
ER

PT J
AU Huang, DY
   Chen, CH
   Chen, TY
   Hu, WC
   Chen, BC
AF Huang, Deng-Yuan
   Chen, Chao-Ho
   Chen, Tsong-Yi
   Hu, Wu-Chih
   Chen, Bo-Cin
TI Rapid detection of camera tampering and abnormal disturbance for video
   surveillance system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Camera tampering; Camera motion; Camera occlusion; Background
   subtraction; Video surveillance system; Screen shaking; Defocus; Color
   cast
AB Camera tampering may indicate that a criminal act is occurring. Common examples of camera tampering are turning the camera lens to point to a different direction (i.e., camera motion) and covering the lens by opaque objects or with paint (i.e., camera occlusion). Moreover, various abnormalities such as screen shaking, fogging, defocus, color cast, and screen flickering can strongly deteriorate the performance of a video surveillance system. This study proposes an automated method for rapidly detecting camera tampering and various abnormalities for a video surveillance system. The proposed method is based on the analyses of brightness, edge details, histogram distribution, and high-frequency information, making it computationally efficient. The proposed system runs at a frame rate of 20-30 frames/s, meeting the requirement of real-time operation. Experimental results show the superiority of the proposed method with an average of 4.4% of missed events compared to existing works. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, Dacun 515, Changhua, Taiwan.
   [Chen, Chao-Ho; Chen, Tsong-Yi; Chen, Bo-Cin] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.
   [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Makung 880, Penghu, Taiwan.
C3 Da Yeh University; National Kaohsiung University of Science &
   Technology; National Penghu University of Science & Technology
RP Chen, CH (corresponding author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.
EM kevin@mail.dyu.edu.tw; thouho@kuas.edu.tw; chentso@kuas.edu.tw;
   wchu@npu.edu.tw; 1100305149@kuas.edu.tw
FU National Science Council of Taiwan [NSC102-2221-E-151-042,
   NSC-102-2221-E-212-015]
FX This work was partially supported by the National Science Council of
   Taiwan under Grants NSC102-2221-E-151-042 and NSC-102-2221-E-212-015.
CR Aksay A, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P558, DOI 10.1109/AVSS.2007.4425371
   Chen C.H., 2009, P 4 INT LIV TECHN C, P1596
   Chen CH, 2011, INT J INNOV COMPUT I, V7, P5285
   Chun-Liang Tung, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P1760, DOI 10.1109/ICMLC.2012.6359641
   Collins R., 2000, CMURITR0012 VSAM
   Daw-Tung Lin, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P383, DOI 10.1109/IIH-MSP.2012.99
   Galic S., 2000, P IEEE INT WORKSH IM
   Gil-Jiménez P, 2007, LECT NOTES COMPUT SC, V4528, P222
   Gutchess D., 2001, P IEEE INT C COMP VI
   Huang DY, 2012, J VIS COMMUN IMAGE R, V23, P648, DOI 10.1016/j.jvcir.2012.03.002
   Lipton A.J., 1998, P 4 IEEE WORKSH APPL
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Ribnick E., 2006, P INT C ADV VID SIGN, P1
   Saglam A, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P430, DOI 10.1109/AVSS.2009.29
   Shen-Chuan Tai, 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P571
   Stauffer C., 1999, P IEEE INT C COMP VI
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhang C., 2000, P IEEE 51 VEH TECHN
NR 18
TC 16
Z9 16
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1865
EP 1877
DI 10.1016/j.jvcir.2014.09.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300006
DA 2024-07-18
ER

PT J
AU Lin, CH
   Chen, TH
   Wu, YT
   Tsao, KH
   Lin, KS
AF Lin, Chih-Hung
   Chen, Tzung-Her
   Wu, Yan-Ting
   Tsao, Kai-Hsiang
   Lin, Kai-Siang
TI Multi-factor cheating prevention in visual secret sharing by hybrid
   codebooks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; Cheating attack; Cheating prevention; Hybrid
   codebook; Multi-factor; Visual cryptography; Share image; (k,n) Codebook
ID CRYPTOGRAPHY
AB Visual secret sharing, or the so-called visual cryptography, is a well-known scheme that encrypts a secret image into several meaningless share images, usually printed on transparencies, and decrypts as stacking some or all share images by the human visual system. More and more researches about visual secret sharing and its applications have been recently proposed. Unfortunately, the cheating attack in which malicious participants cheat the honest one(s) by forging a fake share image has existed. Since 2006, some cheating prevention schemes have been proposed but suffered from one or more disadvantages as follows: (1) maintaining extra share images used to verify the integrity of a share image prior to stacking, (2) introducing extra pixel expansion, (3) raising heavy computation cost, and (4) giving ambiguous cheating detection. In this paper, a multi-factor cheating-preventing scheme, aiming at exploiting the hybrid codebook to hide the additional verification images into the share images, has been proposed without suffering the above-mentioned deficiencies. Two-factor cheating-detection exploits the design of verification to both share images and stacked results to deter attackers' cheating. The experimental results demonstrate the proposed scheme is feasible. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lin, Chih-Hung] Natl Chiayi Univ, Grad Inst Math & Sci Educ, Chiayi 621, Taiwan.
   [Chen, Tzung-Her; Wu, Yan-Ting; Tsao, Kai-Hsiang; Lin, Kai-Siang] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan.
C3 National Chiayi University; National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan.
EM thchen@mail.ncyu.edu.tw
RI Wu, Yanting/IUN-0484-2023
OI Wu, Yanting/0000-0003-1386-3422; Chen, Tzung-Her/0000-0001-5775-6034
FU National Science Council, Taiwan, R.O.C. [NSC 102-2221-E-415-014, NSC
   102-2511-S-415-012-MY4]
FX This research was partially supported by National Science Council,
   Taiwan, R.O.C., under contract no. NSC 102-2221-E-415-014- and NSC
   102-2511-S-415-012-MY4.
CR Chen TH, 2008, INT J INNOV COMPUT I, V4, P3005
   De Prisco R, 2006, LECT NOTES COMPUT SC, V4116, P216
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Lu ZM, 2007, INT J INNOV COMPUT I, V3, P621
   Martin K, 2005, PATTERN RECOGN, V38, P1111, DOI 10.1016/j.patcog.2005.01.002
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Tsai D. S., 2007, P 17 INF SEC C, P769
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Yang C.-N., 1999, NATL COMPUTER S, V3, P260
NR 11
TC 7
Z9 7
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1543
EP 1557
DI 10.1016/j.jvcir.2014.06.011
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100005
DA 2024-07-18
ER

PT J
AU Lee, CP
   Tan, AWC
   Tan, SC
AF Lee, Chin Poo
   Tan, Alan W. C.
   Tan, Shing Chiang
TI Gait probability image: An information-theoretic model of gait
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait; Gait recognition; Gait analysis; Gait biometric; Probability; Gait
   probability; Gait probability image; Binomial probability
ID ENERGY IMAGE; RECOGNITION; ANGLE
AB In this paper, we propose a new probabilistic gait representation to characterize human walking for recognition by gait. The approach obtains the binomial distribution of every pixel in a gait cycle. Organizing the binomial distribution of all pixels in the gait image, we obtain the gait signature, which we denote as the Gait Probability Image (GPI). In the recognition stage, symmetric Kullback-Leibler divergence is used to measure the information theoretical distance between gait signatures. The experimental results reveal that GPI achieves promising recognition rates. Besides that, experiments on different walking speeds demonstrate that GPI is robust to slight variation in walking speed. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lee, Chin Poo; Tan, Shing Chiang] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
   [Tan, Alan W. C.] Multimedia Univ, Fac Engn & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
C3 Multimedia University; Multimedia University
RP Lee, CP (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
EM cplee@mmu.edu.my; wctan@mmu.edu.my; sctan@mmu.edu.my
RI /AGV-9105-2022; Tan, SC/E-6463-2010
OI Tan, SC/0000-0002-1267-1894; Lee, Chin Poo/0000-0003-3679-8977
CR Ang T, 2012, INT J INNOV COMPUT I, V8, P3565
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2001, Cmu Ri Tr 01-18
   [Anonymous], IEEE T PATTERN ANAL
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hu Z., 2013, Kullback-Leibler divergence constrained distributionally robust optimization
   Huang GC, 2007, INT C WAVEL ANAL PAT, P1134
   Kellokumpu V, 2009, LECT NOTES COMPUT SC, V5558, P1000, DOI 10.1007/978-3-642-01793-3_101
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liu YX, 2002, LECT NOTES COMPUT SC, V2351, P657
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Mowbray SD, 2003, LECT NOTES COMPUT SC, V2688, P566
   Mu Y, 2010, NEUROCOMPUTING, V73, P895, DOI 10.1016/j.neucom.2009.09.017
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Ohara Y., 2004, Proceedings of 5th Workshop on Omnidirectional Vision, Camera Networks and Non-classical Cameras, P79
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Wang M, 2011, LECT NOTES COMPUT SC, V6838, P257, DOI 10.1007/978-3-642-24728-6_34
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang R., 2004, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW'04), June 2004, P18
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 36
TC 27
Z9 30
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1489
EP 1492
DI 10.1016/j.jvcir.2014.05.006
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100017
DA 2024-07-18
ER

PT J
AU Hou, SD
   Sun, QS
AF Hou, Shudong
   Sun, Quansen
TI An orthogonal regularized CCA learning algorithm for feature fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Canonical correlation analysis; Orthonormalization; Regularization;
   Feature fusion; Partial least squares; Dimensionality reduction; Feature
   extraction; Pattern recognition
ID CANONICAL CORRELATIONS; RECOGNITION
AB Canonical correlation analysis (CCA) aims at extracting statistically uncorrelated features via conjugate orthonormalization constraints of the projection directions. However, the formulated directions under conjugate orthonormalization are not reliable when the training samples are few and the covariance matrix has not been exactly estimated. Additionally, this widely pursued property is focused on data representation rather than task discrimination. It is not suitable for classification problems when the samples that belong to different classes do not share the same distribution type. In this paper, an orthogonal regularized CCA (ORCCA) is proposed to avoid the above questions and extract more discriminative features via orthogonal constraints and regularized parameters. Experimental results on both handwritten numerals and face databases demonstrate that our proposed method significantly improves the recognition performance. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Hou, Shudong] China Elect Technol Grp Corp, Res Inst 38, Hefei 230088, Peoples R China.
   [Sun, Quansen] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
C3 China Electronics Technology Group; Nanjing University of Science &
   Technology
RP Hou, SD (corresponding author), China Elect Technol Grp Corp, Res Inst 38, Hefei 230088, Peoples R China.
EM hou_shudong@hotmail.com; sunquansen@njust.edu.cn
FU National Science Foundation of China; Project of civil space technology
   pre-research of the 12th five-year plan [61273251, D040201]
FX The authors would like to thank the anonymous reviewers for their
   critical and constructive comments and suggestions. This work was
   supported by the National Science Foundation of China and Project of
   civil space technology pre-research of the 12th five-year plan under
   Grant No. 61273251 and D040201.
CR [Anonymous], 2009, ELEMENTS STAT LEARNI
   Bach F., 2005, TECHREPORT 688
   Baek J, 2004, PATTERN RECOGN, V37, P1303, DOI 10.1016/j.patcog.2003.10.014
   Ching WK, 2012, PATTERN RECOGN, V45, P2719, DOI 10.1016/j.patcog.2012.01.007
   Gehler P., 2009, PROCEEDINGS OF THIRD
   Hardoon DR, 2009, MACH LEARN, V74, P23, DOI 10.1007/s10994-008-5085-3
   Hoegaerts L, 2005, NEUROCOMPUTING, V63, P293, DOI 10.1016/j.neucom.2004.04.013
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu Zhong-Shan, 1999, Chinese Journal of Computers, V22, P369
   Jia CC, 2012, NEUROCOMPUTING, V83, P56, DOI 10.1016/j.neucom.2011.11.006
   Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4
   Jing XY, 2011, SIGNAL PROCESS, V91, P2132, DOI 10.1016/j.sigpro.2011.02.016
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lee SH, 2007, IEEE SIGNAL PROC LET, V14, P735, DOI 10.1109/LSP.2007.896438
   Li YO, 2009, IEEE T SIGNAL PROCES, V57, P3918, DOI 10.1109/TSP.2009.2021636
   Lu JW, 2010, IEEE SIGNAL PROC LET, V17, P185, DOI 10.1109/LSP.2009.2035017
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sargin ME, 2006, INT CONF ACOUST SPEE, P613
   Sun BY, 2010, IEEE T NEURAL NETWOR, V21, P163, DOI 10.1109/TNN.2009.2036363
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang HX, 2010, IEEE SIGNAL PROC LET, V17, P921, DOI 10.1109/LSP.2010.2071863
   Wolf L., 2003, PROCEEDINGS OF IEEE, V1
   Wu XX, 2009, IEEE I CONF COMP VIS, P2035, DOI 10.1109/ICCV.2009.5459448
   Yakhnenko Oksana, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P8, DOI 10.1109/CVPR.2009.5204274
NR 31
TC 7
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 785
EP 792
DI 10.1016/j.jvcir.2014.01.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200007
DA 2024-07-18
ER

PT J
AU Li, DX
   Wang, J
   Zhao, XQ
   Liu, Y
   Wang, DW
AF Li, Daxiang
   Wang, Jing
   Zhao, Xiaoqiang
   Liu, Ying
   Wang, Dianwei
TI Multiple kernel-based multi-instance learning algorithm for image
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-instance learning (MIL); Image classification; Affinity
   propagation (AP); Multiple kernel learning (MKL); Image retrieval;
   Visual words; Cluster analysis; Support vector machines
AB In this paper, a novel multi-instance learning (MIL) algorithm based on multiple-kernels (MK) framework has been proposed for image classification. This newly developed algorithm defines each image as a bag, and the low-level visual features extracted from its segmented regions as instances. This algorithm is started from constructing a "word-space" from instances based on a collection of "visual-words" generated by affinity propagation (AP) clustering method. After calculating the distance between a "visual-word" and the bag (image), a nonlinear mapping mechanism is introduced for registering each bag as a coordinate point in the "word-space". In this case, the MIL problem is transformed into a standard supervised learning problem, which allows multiple-kernels support vector machine (MKSVM) classifiers to be trained for the image categorization. Compared with many popular MIL algorithms, the proposed method, named as MKSVM-MIL, shows its satisfactorily experimental results on the COREL dataset, which highlights the robustness and effectiveness for image classification applications. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Li, Daxiang; Zhao, Xiaoqiang; Liu, Ying; Wang, Dianwei] Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
   [Wang, Jing] Univ Huddersfield, Sch Comp & Engn, CGIV Res Grp, Huddersfield HD1 3DH, W Yorkshire, England.
   [Li, Daxiang; Liu, Ying; Wang, Dianwei] Crime Scene Invest Unit Shaanxi Prov, Lab Image Proc, Xian 710121, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; University of
   Huddersfield
RP Li, DX (corresponding author), Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
EM 35108809@qq.com; jing.wang.ac@gmail.com
FU National Natural Scientific Youth Foundation [61202183, 61102095];
   Natural Science Foundation Research Project of the Shaanxi Province
   [2013JM8031, 2012JM8022]; Postdoctoral Science Foundation [2013M542386];
   Natural Science Foundation Research Project of Shaanxi Province
   Department of Education, China [12JK0734, 12JK0504, 12JK0731, 12JK0543]
FX The author acknowledges the support of the National Natural Scientific
   Youth Foundation (Grant Nos. 61202183, 61102095), the Natural Science
   Foundation Research Project of the Shaanxi Province (Grant Nos.
   2013JM8031, 2012JM8022), Postdoctoral Science Foundation funded project
   (Grant No. 2013M542386) and the Natural Science Foundation Research
   Project of Shaanxi Province Department of Education (Grant Nos.
   12JK0734, 12JK0504, 12JK0731, 12JK0543), China.
CR Andrews S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P943
   [Anonymous], 2006, P 23 INT C MACH LEAR, DOI [10.1145/1143844.1143933, DOI 10.1145/1143844.1143933]
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gartner T., 2002, P 9 INT C MACH LEARN, P179
   Gehler P.V., 2007, Artificial intelligence and statistics, P123
   Guan RC, 2011, IEEE T KNOWL DATA EN, V23, P627, DOI 10.1109/TKDE.2010.144
   Kwok JT, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P901
   Li DX, 2011, SIGNAL PROCESS, V91, P1993, DOI 10.1016/j.sigpro.2011.03.004
   Li Daxiang, 2012, J XIAN U POSTS TELEC, V17, P15
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li WJ, 2009, PROC CVPR IEEE, P1666, DOI 10.1109/CVPRW.2009.5206796
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Sun CS, 2013, IEEE T IMAGE PROCESS, V22, P3050, DOI 10.1109/TIP.2013.2255303
   Zhang CJ, 2013, J VIS COMMUN IMAGE R, V24, P786, DOI 10.1016/j.jvcir.2013.05.004
   [张敏灵 Zhang Minling], 2003, [软件学报, Journal of Software], V14, P1238
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
   Zhou ZH., 2007, ICML '07, V227, P1167
NR 21
TC 13
Z9 14
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1112
EP 1117
DI 10.1016/j.jvcir.2014.03.011
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200037
DA 2024-07-18
ER

PT J
AU Tykkälä, T
   Comport, AI
   Kämäräinen, JK
   Hartikainen, H
AF Tykkala, Tommi
   Comport, Andrew I.
   Kamarainen, Joni-Kristian
   Hartikainen, Hannu
TI Live RGB-D camera tracking for television production studios
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dense tracking; Dense 3D reconstruction; Augmented reality; Real-Time;
   RGB-D; GPU; Image registration; Parallel computing
ID SOFTWARE PACKAGE
AB In this work, a real-time image-based camera tracker is designed for live television production studios. The major concern is to decrease camera tracking expenses by an affordable vision-based approach. First, a dense keyframe model of the static studio scene is generated using image-based dense tracking and bundle adjustment. Online camera tracking is then defined as registration problem between the current RGB-D measurement and the nearest keyframe. With accurate keyframe poses, our camera tracking becomes virtually driftless. The static model is also used to avoid moving actors in the scene. Processing dense RGB-D measurements requires special attention when aiming for real-time performance at 30 Hz. We derive a real-time tracker from our cost function for a low-end GPU. The system requires merely a RGB-D sensor, laptop and a low-end CPU. Camera tracking properties are compared with KinectFusion. Our solution demonstrates robust and driftless real-time camera tracking in a television production studio environment. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Tykkala, Tommi] Lappeenranta Univ Technol, Machine Vis & Pattern Recognit Lab, Kouvola Unit, Lappeenranta, Finland.
   [Comport, Andrew I.] Univ Nice Sophia Antipolis, CNRS, I3S, Sophia Antipolis, France.
   [Kamarainen, Joni-Kristian] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
   [Hartikainen, Hannu] Aalto Univ, Dept Media Technol, Espoo, Finland.
C3 Lappeenranta-Lahti University of Technology LUT; Universite Cote d'Azur;
   Centre National de la Recherche Scientifique (CNRS); Tampere University;
   Aalto University
RP Tykkälä, T (corresponding author), Lappeenranta Univ Technol, Machine Vis & Pattern Recognit Lab, Kouvola Unit, Lappeenranta, Finland.
EM ttykkala@gmail.com
RI Kämäräinen, Joni-Kristian JK/G-4296-2014; Comport, Andrew I/A-4672-2012
CR [Anonymous], 2012, VOOD CAM TRACK TOOL
   [Anonymous], 2011, REAL TIME DENSE RGB
   [Anonymous], 2011, IEEE INT C ROBOTICS
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bouguet J., CAMERA CALIBRATION T
   Comport A., 2007, IEEE INT C ROB AUT I
   DOBBERT T, 2005, MATCHMOVING INVISIBL
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Herrera C., IEEE T PAMI, V34
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Klein George, 2007, P1
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Ma Y., 2004, INTERD APPL
   Meilland M., 2010, IEEE RSJ INT C INT R
   Newcombe R.A., 2011, ICCV, V1
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Podlozhnyuk V., 2007, CUDA SDK
   Sidje RB, 1998, ACM T MATH SOFTWARE, V24, P130, DOI 10.1145/285861.285868
   Silveira G, 2008, IEEE T ROBOT, V24, P969, DOI 10.1109/TRO.2008.2004829
   Steinbrucker F., 2011, WORKSH LIV DENS REC
   Sturm J., 2011, RGB D WORKSH ADV REA
   Tykkala T.M., 2011, IEEE INT C ROB AUT
   Tykkala T.M., 2011, ICCV WORKSH CVVT
NR 24
TC 6
Z9 8
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 207
EP 217
DI 10.1016/j.jvcir.2013.02.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, P
   Yang, CN
   Kong, Q
   Ma, YP
   Liu, Z
AF Li, Peng
   Yang, Ching-Nung
   Kong, Qian
   Ma, Yanpeng
   Liu, Zheng
TI Sharing more information in gray visual cryptography scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Image secret sharing; Polynomial-based secret
   sharing; Gray mixing model; Secret sharing; Lagrange's interpolation;
   Information hiding; Image processing
ID MULTIPLE SECRETS; COLOR IMAGES; AUTHENTICATION; STEGANOGRAPHY;
   IMPROVEMENTS; CONTRAST; SIZE
AB Visual cryptography scheme (VCS) shares a binary secret image into several binary shadows, and the secret image can be visually revealed by stacking qualified shadows without computation. From the point of view of sharing secret information, VCS is not efficiency because of the large size expansion and low visual quality. In this paper, we introduce a general gray visual cryptography scheme, which can share more information, called Sharing More Information Gray Visual Cryptography Scheme (SMIGVCS). All the shadow pixels of VCS embed additional information to generate gray shadows of SMIGVCS, and the embedded information comes from the shadows of a polynomial-based secret sharing scheme (PSSS). In the revealing process, a vague secret image is visually decoded by stacking qualified shadows, and more information is revealed by computation. Compared with the two-in-one image secret sharing scheme (TiOISSS), our SMIGVCS can achieve smaller shadow size with acceptable visual quality. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Li, Peng; Kong, Qian; Ma, Yanpeng; Liu, Zheng] North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei Province, Peoples R China.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien 974, Taiwan.
C3 North China Electric Power University; National Dong Hwa University
RP Li, P (corresponding author), North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei Province, Peoples R China.
EM lphit@163.com
RI Kong, Qina/KFS-6817-2024; Jiang, Cheng/JHU-0179-2023; Li,
   Peng/D-7073-2012; Yang, Ching-Nung/HKV-1639-2023
OI Yang, Ching-Nung/0000-0002-3881-7329
FU Fundamental Research Funds for the Central Universities [13MS107]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (No. 13MS107). Thanks for the anonymous reviewers'
   constructive comments and suggestions.
CR Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Krause M, 2003, COMB PROBAB COMPUT, V12, P285, DOI 10.1017/S096354830200559X
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Yang CN, 2008, PATTERN RECOGN, V41, P3114, DOI 10.1016/j.patcog.2008.03.031
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2013, PERS UBIQUIT COMPUT, V17, P843, DOI 10.1007/s00779-012-0535-0
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2011, VISUAL CRYPTOGRAPHY
NR 28
TC 22
Z9 22
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1380
EP 1393
DI 10.1016/j.jvcir.2013.09.010
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700014
DA 2024-07-18
ER

PT J
AU Ge, YX
   Yang, D
   Lu, JW
   Li, B
   Zhang, XH
AF Ge, Yongxin
   Yang, Dan
   Lu, Jiwen
   Li, Bo
   Zhang, Xiaohong
TI Active appearance models using statistical characteristics of Gabor
   based texture representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active appearance model (AAM); Gabor wavelet; Image registration; Gabor
   magnitude; Gabor phase; Statistical model; Gamma distribution; Gamma
   Gaussian distribution
ID FEATURES; RECOGNITION; RETRIEVAL
AB Active appearance model (AAM) has been successfully applied to register many types of deformable objects in images. However, the high dimension of intensity used in AAM usually leads to an expensive storage and computational cost. Moreover, intensity values cannot provide enough information for image alignment. In this paper, we propose a new AAM method based on Gabor texture feature representation. Our contributions are two-fold. On one hand, based on the assumption that Gabor magnitude and Gabor phase follow a lognormal distribution and a general Gaussian distribution respectively, three simplified texture representations are proposed. One the other hand, we apply the proposed texture representations in AAM, which is the first time to extract statistical features from both Gabor magnitude and Gabor phase as the texture representation in AAM. Tests on public and our databases show that the proposed Gabor representations lead to more accurate and robust matching between model and images. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Ge, Yongxin; Yang, Dan; Zhang, Xiaohong] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
   [Ge, Yongxin; Zhang, Xiaohong] Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Lu, Jiwen] Adv Digital Sci Ctr, Singapore 138632, Singapore.
   [Li, Bo] Chongqing Police Coll, Dept Criminal Sci & Technol, Chongqing 400044, Peoples R China.
C3 Chongqing University; Chongqing Police College
RP Ge, YX (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
EM yongxinge@cqu.edu.cn; dyang@cqu.edu.cn; jiwen.lu@adsc.com.sg;
   boli.cqu@gmail.com; xhongz@yahoo.com.cn
RI Zhang, Xiaohong/A-3060-2015; YANG, Dan/HHD-2733-2022; Lu,
   Jiwen/C-5291-2009
OI Lu, Jiwen/0000-0002-6121-5529
FU Fundamental Research Funds for the Central Universities [CDJZR12090002]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (CDJZR12090002).
CR Bhagavathy S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P745
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   Cootes TF, 2001, PROC CVPR IEEE, P1114
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P145, DOI 10.1109/TSMCC.2009.2035631
   Gao XB, 2009, NEUROCOMPUTING, V72, P3174, DOI 10.1016/j.neucom.2009.03.003
   Jahanbin S, 2008, IEEE IMAGE PROC, P2768, DOI 10.1109/ICIP.2008.4712368
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kittipanya-Ngam P, 2006, INT C PATT RECOG, P328
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Larsen R, 2007, COMPUT VIS IMAGE UND, V106, P20, DOI 10.1016/j.cviu.2005.09.007
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu J, 2009, ELECTRON LETT, V45, P880, DOI 10.1049/el.2009.0871
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Nordstroom M., 2004, TECHNICAL REPORT
   Scott IM, 2003, LECT NOTES COMPUT SC, V2732, P258
   Stemann M.B., 2003, IMAGE VISION COMPUT, V21, P61
   Su Y., 2009, P IEEE INT C SYST MA
   Subbanna N., 2006, IET INT C VIS INF EN, P482
   Super B. J., 1991, Journal of Visual Communication and Image Representation, V2, P114, DOI 10.1016/1047-3203(91)90002-W
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wu P, 2000, SIGNAL PROCESS-IMAGE, V16, P33, DOI 10.1016/S0923-5965(00)00016-3
   Yu L, 2010, IMAGE VISION COMPUT, V28, P177, DOI 10.1016/j.imavis.2009.05.012
   Yu MS, 2006, MEX INT CONF ARTIF I, P61
   Zibulski M, 1997, APPL COMPUT HARMON A, V4, P188, DOI 10.1006/acha.1997.0209
   Zibulski M, 1997, IEEE T SIGNAL PROCES, V45, P1428, DOI 10.1109/78.599955
NR 31
TC 9
Z9 9
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 627
EP 634
DI 10.1016/j.jvcir.2013.04.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900011
DA 2024-07-18
ER

PT J
AU Wang, SS
   Xia, Y
   Liu, QG
   Luo, JH
   Zhu, YM
   Feng, DD
AF Wang, Shanshan
   Xia, Yong
   Liu, Qiegen
   Luo, Jianhua
   Zhu, Yuemin
   Feng, David Dagan
TI Gabor feature based nonlocal means filter for textured image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Nonlocal means filter; Gabor filter; Image denoising; Textured image
   analysis; Feature extraction; Similarity detection; Signal restoration;
   Gaussian noise
ID ALGORITHM; REPRESENTATION; TRANSFORM; DOMAIN; SEGMENTATION
AB The nonlocal means (NLM) filter has distinct advantages over traditional image denoising techniques. However, in spite of its simplicity, the pixel value-based self-similarity measure used by the NLM filter is intrinsically less robust when applied to images with non-stationary contents. In this paper, we use Gabor-based texture features to measure the self-similarity, and thus propose the Gabor feature based NLM (GFNLM) filter for textured image denoising. This filter recovers noise-corrupted images by replacing each pixel value with the weighted sum of pixel values in its search window, where each weight is defined based on the Gabor-based texture similarity measure. The GFNLM filter has been compared to the classical NLM filter and four other state-of-the-art image denoising algorithms in textured images degraded by additive Gaussian noise. Our results show that the proposed GFNLM filter can denoise textured images more effectively and robustly while preserving the texture information. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Wang, Shanshan; Liu, Qiegen; Luo, Jianhua] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China.
   [Wang, Shanshan; Xia, Yong; Feng, David Dagan] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol BMIT Res Grp, Sydney, NSW 2006, Australia.
   [Feng, David Dagan] Shanghai Jiao Tong Univ, Med X Res Inst, Shanghai 200240, Peoples R China.
   [Luo, Jianhua] Shanghai Jiao Tong Univ, Coll Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
   [Zhu, Yuemin] Univ Lyon 1, INSA Lyon, CREATIS, CNRS,UMR 5220,Inserm,U630, F-69365 Lyon, France.
C3 Shanghai Jiao Tong University; University of Sydney; Shanghai Jiao Tong
   University; Shanghai Jiao Tong University; Universite Claude Bernard
   Lyon 1; Institut National de la Sante et de la Recherche Medicale
   (Inserm); Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS)
RP Luo, JH (corresponding author), Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China.
EM jhluo@sjtu.edu.cn
RI Xia, Yong/J-4273-2013; Zhu, Yuemin/K-7292-2014; Wang,
   Shanshan/T-6972-2017; Shi, Yaolin/JXN-8322-2024; Xia, Yong/C-6567-2008;
   Luo, jian/HGE-7331-2022
OI Zhu, Yuemin/0000-0001-6814-1449; Wang, Shanshan/0000-0002-0575-6523;
   Feng, Dagan/0000-0002-3381-214X
FU Region Rhone-Alpes of France under project Mira Recherche; Chinese NSFC
   [30911130364]; French ANR [ANR-09-BLAN-0372-01]; ARC grants; China
   Scholarship Council [2011623084]; Agence Nationale de la Recherche (ANR)
   [ANR-09-BLAN-0372] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX This work was supported in part by the Region Rhone-Alpes of France
   under project Mira Recherche 2008, in part by the joint project of
   Chinese NSFC under Grant 30911130364 and French ANR 2009 under Grant
   ANR-09-BLAN-0372-01, in part by the ARC grants, and in part by the China
   Scholarship Council under Grant 2011623084. The authors would like to
   thank Dr. Elias Aboutanios at the School of Electrical Engineering and
   Telecommunications, University of New South Wales, Australia, for his
   invaluable assistance.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aja-Fernandez Santiago, 2006, 2006 INT C IEEE ENG, P4815
   [Anonymous], LECT NOTES STAT
   Arivazhagan S, 2006, MACH VISION APPL, V16, P356, DOI 10.1007/s00138-005-0007-x
   Brigham E.O., 1978, IEEE Transactions on Systems, Man and Cybernetics, V8, P146, DOI DOI 10.1109/TSMC.1978.4309919
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P13
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   Coupé P, 2006, LECT NOTES COMPUT SC, V4191, P33
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DANIEL PM, 1961, J PHYSIOL-LONDON, V159, P203, DOI 10.1113/jphysiol.1961.sp006803
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Idrissa M, 2002, PATTERN RECOGN LETT, V23, P1095, DOI 10.1016/S0167-8655(02)00056-9
   Ji ZX, 2009, INFORM PROCESS LETT, V109, P1238, DOI 10.1016/j.ipl.2009.09.007
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Kleinschmidt O., 2008, P INT WORKSH LOC NON, P103
   Liu YL, 2008, J COMPUT SCI TECH-CH, V23, P270, DOI 10.1007/s11390-008-9129-8
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Manjon-Herrera J.V., 2006, MATLAB BASED IMPLEME
   Mital D.P., 2000, P 4 INT C KNOWL BAS, P109
   Movellan J. R., 2002, Open Source Document, V40, P1
   Nestares O, 1998, J ELECTRON IMAGING, V7, P166, DOI 10.1117/1.482638
   Pappasa T.N., 2010, P VIS COMM IM PROC, P19
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Portilla J, 1996, OPT ENG, V35, P2403, DOI 10.1117/1.600814
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Thomos N, 2006, IEEE T IMAGE PROCESS, V15, P54, DOI 10.1109/TIP.2005.860338
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918
   Zhang JG, 2002, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2002.1048450
NR 43
TC 28
Z9 31
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1008
EP 1018
DI 10.1016/j.jvcir.2012.06.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900005
DA 2024-07-18
ER

PT J
AU Yang, HY
   Wang, XY
   Wang, QY
   Zhang, XJ
AF Yang, Hong-Ying
   Wang, Xiang-Yang
   Wang, Qin-Yan
   Zhang, Xian-Jin
TI LS-SVM based image segmentation using color and texture information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Least squares support vector machine; Homogeneity;
   Gabor filter; Arimoto entropy thresholding; Maximum second moment
   matrix; Color image; Local human visual sensitivity
ID SUPPORT VECTOR MACHINE
AB Image segmentation partitions an image into nonoverlapping regions, which ideally should be meaningful for a certain purpose. Automatic segmentation of images is a very challenging fundamental task in computer vision and one of the most crucial steps toward image understanding. In recent years, many image segmentation algorithms have been developed, but they are often very complex and some undesired results occur frequently. In this paper, we present an effective color image segmentation approach based on pixel classification with least squares support vector machine (LS-SVM). Firstly, the pixel-level color feature. Homogeneity, is extracted in consideration of local human visual sensitivity for color pattern variation in HSV color space. Secondly, the image pixel's texture features, Maximum local energy, Maximum gradient, and Maximum second moment matrix, are represented via Gabor filter. Then, both the pixel-level color feature and texture feature are used as input of LS-SVM model (classifier), and the LS-SVM model (classifier) is trained by selecting the training samples with Arimoto entropy thresholding. Finally, the color image is segmented with the trained LS-SVM model (classifier). This image segmentation not only can fully take advantage of the local information of color image, but also the ability of LS-SVM classifier. Experimental evidence shows that the proposed method has very effective segmentation results and computational behavior, and decreases the time and increases the quality of color image segmentation in comparison with the state-of-the-art segmentation methods recently proposed in the literature. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Yang, Hong-Ying; Wang, Xiang-Yang; Wang, Qin-Yan; Zhang, Xian-Jin] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-Yang] Chinese Acad Sci, Inst Software, State Key Lab Informat Secur, Beijing 100190, Peoples R China.
C3 Liaoning Normal University; Chinese Academy of Sciences; Institute of
   Software, CAS
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [60773031, 60873222]; Open
   Foundation of State Key Laboratory of Information Security of China
   [04-06-1]; Open Foundation of Network and Data Security Key Laboratory
   of Sichuan Province; Open Foundation of Key Laboratory of Modern
   Acoustics Nanjing University [08-02]; Liaoning Research Project for
   Institutions of Higher Education of China [2008351, L2010230]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 60773031 and 60873222, the Open Foundation of
   State Key Laboratory of Information Security of China under Grant No.
   04-06-1, the Open Foundation of Network and Data Security Key Laboratory
   of Sichuan Province, the Open Foundation of Key Laboratory of Modern
   Acoustics Nanjing University under Grant No. 08-02, and Liaoning
   Research Project for Institutions of Higher Education of China under
   Grant No. 2008351 and L2010230.
CR [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383017
   Ben Salah M, 2011, IEEE T IMAGE PROCESS, V20, P545, DOI 10.1109/TIP.2010.2066982
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chaabane SB, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/367297
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Ciesielski KC, 2011, COMPUT VIS IMAGE UND, V115, P721, DOI 10.1016/j.cviu.2011.01.003
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cyganek B, 2008, INT J NEURAL SYST, V18, P339, DOI 10.1142/S0129065708001646
   Cyganek B, 2010, LECT NOTES ARTIF INT, V6076, P254, DOI 10.1007/978-3-642-13769-3_31
   Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z
   Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191
   Hanbay D, 2009, EXPERT SYST APPL, V36, P4248, DOI 10.1016/j.eswa.2008.03.003
   Huang JJ, 2007, EXPERT SYST APPL, V32, P313, DOI 10.1016/j.eswa.2005.11.028
   Ilea DE, 2011, PATTERN RECOGN, V44, P2479, DOI 10.1016/j.patcog.2011.03.005
   Juang CF, 2007, IEEE T SYST MAN CY A, V37, P1077, DOI 10.1109/TSMCA.2007.904579
   Khan JF, 2009, IMAGE VISION COMPUT, V27, P489, DOI 10.1016/j.imavis.2008.07.001
   Malmberg F, 2011, THEOR COMPUT SCI, V412, P1338, DOI 10.1016/j.tcs.2010.11.030
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mashford J, 2010, AUTOMAT CONSTR, V19, P875, DOI 10.1016/j.autcon.2010.06.001
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Qin AK, 2010, IEEE T IMAGE PROCESS, V19, P2157, DOI 10.1109/TIP.2010.2045708
   Quan JJ, 2008, APPL MATH COMPUT, V205, P578, DOI 10.1016/j.amc.2008.05.030
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sowmya B, 2011, APPL SOFT COMPUT, V11, P3170, DOI 10.1016/j.asoc.2010.12.019
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Ugarriza LG, 2009, IEEE T IMAGE PROCESS, V18, P2275, DOI 10.1109/TIP.2009.2025555
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang HZ, 2010, COMPUT VIS IMAGE UND, V114, P731, DOI 10.1016/j.cviu.2010.02.001
   Wang J, 2009, IEEE T IMAGE PROCESS, V18, P1844, DOI 10.1109/TIP.2009.2021087
   Wang XY, 2011, PATTERN RECOGN, V44, P777, DOI 10.1016/j.patcog.2010.08.008
   Wang XY, 2010, DIGIT SIGNAL PROCESS, V20, P1173, DOI 10.1016/j.dsp.2009.11.007
   Xiaokai Wang, 2010, Proceedings 2010 International Conference on Optoelectronics and Image Processing (ICOIP 2010), P553, DOI 10.1109/ICOIP.2010.286
   Xu Haixiang, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1207, DOI 10.1109/ICOSP.2008.4697347
   Xue Z, 2009, P SPIE MED IMAGING, V7259
   Yu YH, 2004, FUND INFORM, V61, P379
   Yu ZW, 2011, IMAGE VISION COMPUT, V29, P29, DOI 10.1016/j.imavis.2010.08.003
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   [卓问 ZHUO Wen], 2009, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V22, P208
NR 39
TC 30
Z9 33
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1095
EP 1112
DI 10.1016/j.jvcir.2012.07.007
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900013
DA 2024-07-18
ER

PT J
AU Gu, B
   Li, WJ
   Wong, JT
   Zhu, MY
   Wang, MH
AF Gu, Bo
   Li, Wujing
   Wong, Jiangtao
   Zhu, Minyun
   Wang, Minghui
TI Gradient field multi-exposure images fusion for high dynamic range image
   visualization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Image gradient; Multi-exposure; HDR; Riemannian manifold;
   Structure tensor; Gradient modification; Dynamic range compression
AB This paper presents a novel method for fusing multi-exposure images into a low dynamic range (LDR) image that is suitable for display and visualization but it contains details in the high dynamic range (HDR) counterpart. Fused gradient field is derived from the structure tensor of inputs based on multidimensional Riemannian geometry with a Euclidean metric assumed. Afterwards, a new method is proposed for modifying the gradient field iteratively with twice average filtering and nonlinearly compressing in multi-scales. These modification operations are all done at the finest resolution. The result is obtained through solving a Poisson equation then linearly stretching to the common range. Experimental results demonstrate the efficiency and effectiveness of this method. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Gu, Bo; Li, Wujing; Zhu, Minyun; Wang, Minghui] Sichuan Univ, Coll Comp Sci, Chengdu 610064, Peoples R China.
   [Wong, Jiangtao] Guangxi Teachers Educ Univ, Coll Comp & Informat Engn, Guangxi, Peoples R China.
C3 Sichuan University; Nanning Normal University
RP Gu, B (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610064, Peoples R China.
EM goobo@163.com; liwujing12345@gmail.com; prognosis@l63.com;
   zhuminyun88@126.com; wangminghui@scu.edu.cn
RI Gu, Bo/HLW-3853-2023; Li, Wujing/GZL-9066-2022
OI Huang, Jiangtao/0009-0003-0846-5099; Gu, Bo/0000-0002-0108-8820
FU National Nature Science Foundation of China [61071162]
FX This work was partly supported by the National Nature Science Foundation
   of China (Grant No. 61071162). We thank Professor A. Ardeshir Goshtasby
   for sharing his result (Fig. 5(c)), and the reviewers for insightful
   comments.
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 1996, ANISOTROPIC DIFFUSIO
   Battiato S, 2003, J ELECTRON IMAGING, V12, P459, DOI 10.1117/1.1580829
   Briggs William, 2000, A Multigrid Tutorial, Vsecond
   Chatzis IS, 2006, CIRCUITS AND SYSTEMS FOR SIGNAL PROCESSING , INFORMATION AND COMMUNICATION TECHNOLOGIES, AND POWER SOURCES AND SYSTEMS, VOL 1 AND 2, PROCEEDINGS, P385
   CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F
   Debevec P.E., ACM SIGGRAPH 97 P 19, P369
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   GUAN J, 2007, IEEE INT C IM PROC, V3, P521
   Li XG, 2007, J VIS COMMUN IMAGE R, V18, P397, DOI 10.1016/j.jvcir.2007.06.005
   Lin S, 2005, PROC CVPR IEEE, P66
   Lin S, 2004, PROC CVPR IEEE, P938
   Matsushita Y., 2007, P IEEE C COMPUTER VI, P1, DOI DOI 10.1109/CVPR.2007.383213
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Nakano S, 2009, INT J ROTATING MACH, V2009, DOI 10.1155/2009/718107
   Raman S., 2009, P 26 INT C MACHINE L, P1
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Robertson MA, 2003, J ELECTRON IMAGING, V12, P219, DOI 10.1117/1.1557695
   Shen F, 2009, J VIS COMMUN IMAGE R, V20, P521, DOI 10.1016/j.jvcir.2009.07.006
   Socolinsky D. A., 2000, Proceedings of the IASTED International Conference. Signal and Image Processing, P349
   Socolinsky D A, 2000, THESIS J HOPKINS U
   Takamatsu Jun., 2008, 2008 IEEE C COMPUTER, P1
   Várkonyi-Kóczy AR, 2008, IEEE T INSTRUM MEAS, V57, P1779, DOI 10.1109/TIM.2008.925715
   Zhang J, 2008, IEEE INT CON AUTO SC, P1, DOI 10.1109/COASE.2008.4626431
   Zhang W, 2010, PROC CVPR IEEE, P530, DOI 10.1109/CVPR.2010.5540168
NR 27
TC 101
Z9 107
U1 1
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 604
EP 610
DI 10.1016/j.jvcir.2012.02.009
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500002
DA 2024-07-18
ER

PT J
AU Lai, JL
   Yi, Y
AF Lai, Jie-Ling
   Yi, Yang
TI Key frame extraction based on visual attention model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video summarization; Key frame extraction; Visual attention model; Human
   perception; Fusion scheme; Saliency map; Attention curve; Frame
   clustering
AB Key frame extraction is an important technique in video summarization, browsing, searching and understanding. In this paper, we propose a novel approach to extract the most attractive key frames by using a saliency-based visual attention model that bridges the gap between semantic interpretation of the video and low-level features. First, dynamic and static conspicuity maps are constructed based on motion, color and texture features. Then, by introducing suppression factor and motion priority schemes, the conspicuity maps are fused into a saliency map that includes only true attention regions to produce attention curve. Finally, after time-constraint cluster algorithm grouping frames with similar content, the frames with maximum saliency value are selected as key-frames. Experimental results demonstrate the effectiveness of our approach for video summarization by retrieving the meaningful key frames. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Lai, Jie-Ling; Yi, Yang] Sun Yat Sen Univ, Dept Comp Sci, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Yi, Y (corresponding author), Sun Yat Sen Univ, Dept Comp Sci, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
EM issyy@mail.sysu.edu.cn
RI Yi, Yang/AFP-5892-2022
CR [Anonymous], P INT WORKSH REAL TI
   [Anonymous], 2000, THESIS PASADENA CALI
   Armanfard Z, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS, P230, DOI 10.1109/ACTEA.2009.5227866
   Broadbent DE, 2013, PERCEPTION COMMUNICA
   Castelhano MS, 2007, J EXP PSYCHOL HUMAN, V33, P753, DOI 10.1037/0096-1523.33.4.753
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chernyak DA, 2001, IEEE T SYST MAN CY B, V31, P514, DOI 10.1109/3477.938257
   Drew M. S., 2000, Proceedings ACM Multimedia 2000, P365, DOI 10.1145/354384.354534
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   GRESLE PO, 1997, P 2 INT C VIS INF SY, P279
   HU Y, 2004, P 5 IEEE C MULT TOK
   HU Y, 2005, IEEE INT C MULT EXP
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Parkhurst DJ, 2003, SPATIAL VISION, V16, P125, DOI 10.1163/15685680360511645
   Styles E.A., 1997, PSYCHOL ATTENTION, DOI 10.4324/9780203016435
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 21
TC 65
Z9 78
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 114
EP 125
DI 10.1016/j.jvcir.2011.08.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100011
DA 2024-07-18
ER

PT J
AU Han, B
   Paulson, C
   Wu, DP
AF Han, Bing
   Paulson, Christopher
   Wu, Dapeng
TI 3D dense reconstruction from 2D video sequence via 3D geometric
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geometric segmentation; Surface fitting; Dense matching; Dense
   reconstruction; 3D scene reconstruction; Deterministic annealing;
   Expanded deterministic annealing; 3D geometry
ID OPTIMIZATION; CALIBRATION; REGRESSION; SCENES
AB 3D reconstruction is a major problem in computer vision. This paper considers the problem of reconstructing 3D structures, given a 2D video sequence. This problem is challenging since it is difficult to identify the trajectory of each object point/pixel over time. Traditional stereo 3D reconstruction methods and volumetric 3D reconstruction methods suffer from the blank wall problem, and the estimated dense depth map is not smooth, resulting in loss of actual geometric structures such as planes. To retain geometric structures embedded in the 3D scene, this paper proposes a novel surface fitting approach for 3D dense reconstruction. Specifically, we develop an expanded deterministic annealing algorithm to decompose 3D point cloud to multiple geometric structures, and estimate the parameters of each geometric structure. In this paper, we only consider plane structure, but our methodology can be extended to other parametric geometric structures such as spheres, cylinders, and cones. The experimental results show that the new approach is able to segment 3D point cloud into appropriate geometric structures and generate accurate 3D dense depth map. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Han, Bing; Paulson, Christopher; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Wu, DP (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM wu@ece.ufl.edu
OI Wu, Dapeng/0000-0003-1755-0183
FU AFRL [FA8650-06-1-1027]
FX This material is based on research sponsored by AFRL under agreement
   number FA8650-06-1-1027. The US Government is authorized to reproduce
   and distribute reprints for Governmental purposes notwithstanding any
   copyright notation thereon.
CR [Anonymous], 2004, An invitation to 3-D vision
   [Anonymous], 1981, IJCAI 81 7 INT JOINT
   [Anonymous], P 5 EUR C COMP VIS F
   [Anonymous], P EUR C COMP VIS
   Arce E, 2007, IMAGE VISION COMPUT, V25, P623, DOI 10.1016/j.imavis.2006.05.006
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Chang HH, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P880
   Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9
   DEVERNAY F, 1995, P SOC PHOTO-OPT INS, V2567, P62, DOI 10.1117/12.218487
   FAUGERAS O, 1998, P 5 EUR C COMP VIS, P393
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon AW, 2000, LECT NOTES COMPUT SC, V1842, P891
   Harris C., 1988, P ALV VIS C, P5210
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7
   KIM J, 2005, P IEEE 3DIM
   KIRKPATRICK S, 1984, J STAT PHYS, V34, P975, DOI 10.1007/BF01009452
   KOCH R, 1998, P 5 EUR C COMP VIS, P71
   Kulis B, 2009, MACH LEARN, V74, P1, DOI 10.1007/s10994-008-5084-4
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Lhuillier M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1313
   Li H., 2009, AS PAC POW EN ENG C, P1
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Pollefeys M, 2000, ISPRS J PHOTOGRAMM, V55, P251, DOI 10.1016/S0924-2716(00)00023-X
   Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4
   POLLEFEYS M, 1998, J COMPUTER VISION
   POPESCU V, 2004, EUR S POINT BAS GRAP
   Qian G, 2005, IEEE T IMAGE PROCESS, V14, P94, DOI 10.1109/TIP.2004.837551
   Rao AV, 1999, IEEE T PATTERN ANAL, V21, P159, DOI 10.1109/34.748824
   Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194
   Strecha C, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P416, DOI 10.1109/TDPVT.2002.1024097
   Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Vidal R, 2006, INT J COMPUT VISION, V68, P7, DOI 10.1007/s11263-005-4839-7
   WOLF L, 2001, 2 BODY SEGMENTATION
   YAGNIK J, 2005, 7 IEEE INT S MULT, P4
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 41
TC 7
Z9 11
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 421
EP 431
DI 10.1016/j.jvcir.2011.03.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Daribo, I
   Miled, W
   Pesquet-Popescu, B
AF Daribo, Ismael
   Miled, Wided
   Pesquet-Popescu, Beatrice
TI Joint depth-motion dense estimation for multiview video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview; Video coding; Depth; Joint motion-depth estimation; Total
   variation; Convex optimization; H.264/MPEG-4 AVC; MVC
AB The multiview video coding (MVC) extension of H.264/MPEG-4 AVC [1] is one of the most promising visual encoders for three-dimensional television and free viewpoint video applications. In this paper, we propose a joint dense motion/disparity estimation algorithm, designed to replace the classical temporal/inter-view unit within MVC, which uses a block-based motion/disparity estimation. The motion vector fields and the disparity vector fields are therefore simultaneously derived using the stereo-motion consistency constraint in a set theoretic convex optimization framework. The obtained displacement vector fields are then jointly segmented by minimizing a rate-distortion cost function, in line with the multiple reference frame strategy used in H.264/MPEG-4 AVC. Experimental results demonstrate the benefits of the proposed method compared to the separated dense estimation scheme Or the block-based estimation technique. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Daribo, Ismael; Miled, Wided; Pesquet-Popescu, Beatrice] Telecom ParisTech, Signal & Image Proc Dept, F-75014 Paris, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   Paris
RP Daribo, I (corresponding author), Telecom ParisTech, Signal & Image Proc Dept, 37-39 Rue Dareau, F-75014 Paris, France.
EM daribo@telecom-paristech.fr; miled@telecom-paristech.fr;
   pesquet@telecom-paristech.fr
CR [Anonymous], P 13 INT C PATT REC
   Bjotegaard G., 2001, VCEGM33
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Combettes PL, 2004, IEEE T IMAGE PROCESS, V13, P1213, DOI 10.1109/TIP.2004.832922
   Combettes PL, 2003, IEEE T SIGNAL PROCES, V51, P1771, DOI 10.1109/TSP.2003.812846
   DARIBO I, 2009, P IEEE WORKSH MULT S
   Daribo I, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P417
   Fehn C, 2002, SIGNAL PROCESS-IMAGE, V17, P705, DOI 10.1016/S0923-5965(02)00079-6
   FELDMANN II, 2008, HHI TEST MAT 3D VIDE
   *ITU T, 2005, H264 ITUT
   LIU J, 1993, SIGNAL PROCESS-IMAGE, V5, P305
   Miled W, 2009, IEEE T IMAGE PROCESS, V18, P813, DOI 10.1109/TIP.2008.2011386
   Miled W, 2009, INT CONF ACOUST SPEE, P741, DOI 10.1109/ICASSP.2009.4959690
   Min D, 2006, SIGNAL PROCESS-IMAGE, V21, P252, DOI 10.1016/j.image.2005.10.003
   Renlong He, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1279, DOI 10.1109/ICOSP.2008.4697365
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   TAMTAOUI A, 1991, INT CONF ACOUST SPEE, P2845, DOI 10.1109/ICASSP.1991.150995
   VETRO A, 2008, JVTAA207 ISOIEC MPEG
   WEILER H, 2003, P VIS IM IM PROC MAL, P102
   Yang W, 2005, SIGNAL PROCESS-IMAGE, V20, P265, DOI 10.1016/j.image.2004.12.003
   YEA S, 2007, P IEEE INT C IM PROC, V1, DOI DOI 10.1109/ICIP.2007.4378928
   2005, SURVEY ALGORITHMS US
NR 24
TC 8
Z9 9
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 487
EP 497
DI 10.1016/j.jvcir.2009.12.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600011
DA 2024-07-18
ER

PT J
AU Jarusirisawad, S
   Nozick, V
   Saito, H
AF Jarusirisawad, Songkran
   Nozick, Vincent
   Saito, Hideo
TI Real-time video-based rendering from uncalibrated cameras using
   plane-sweep algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video-based rendering; Free viewpoint video; Plane-sweep; Projective
   grid space; Real-time; Graphics processing unit (GPU); View
   interpolation; Uncalibrated cameras
ID FREE-VIEWPOINT VIDEO
AB In this paper, we present a new online video-based rendering (VBR) method that creates new views of a scene from uncalibrated cameras. Our method does not require information about the cameras intrinsic parameters. For obtaining a geometrical relation among the cameras, we use projective grid space (PGS) which is 3D space defined by epipolar geometry between two basis cameras. The other cameras are registered to the same 3D space by trifocal tensors between these basis cameras. We simultaneously reconstruct and render novel view using our proposed plane-sweep algorithm in PGS. To achieve real-time performance, we implemented the proposed algorithm in graphics processing unit (CPU). We succeed to create novel view images in real-time from uncalibrated cameras and the results show the efficiency of our proposed method. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Jarusirisawad, Songkran; Saito, Hideo] Keio Univ, Dept Informat & Comp Sci, Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
   [Nozick, Vincent] Univ Paris Est Marne la Vallee, Inst Gaspard Monge, F-77454 Marne La Vallee 2, France.
C3 Keio University; Universite Gustave-Eiffel
RP Jarusirisawad, S (corresponding author), Keio Univ, Dept Informat & Comp Sci, Kohoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.
EM songkran@hvrl.ics.keio.ac.jp
RI Saito, Hideo/D-6223-2014
OI Saito, Hideo/0000-0002-2421-9862
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097
   Geys I., 2005, P 2 IEE EUR C VIS ME, P94
   JARUSIRISAWAD S, 2009, IMAGE COMMUNICATION, V24, P17
   JARUSIRISAWAD S, 2009, P IEEE INT WORKSH 3D, P1740
   Kanade T., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P69, DOI 10.1109/WVRS.1995.476854
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Li M, 2003, PROC GRAPH INTERF, P65
   LI M, 2003, J WSCG 2003, V11, P290
   Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   Moezzi S, 1997, IEEE MULTIMEDIA, V4, P18, DOI 10.1109/93.580392
   Moezzi S, 1996, IEEE COMPUT GRAPH, V16, P58, DOI 10.1109/38.544073
   Nozick V, 2007, LECT NOTES COMPUT SC, V4678, P72
   Nozick V, 2008, INT J AUTOM COMPUT, V5, P257, DOI 10.1007/s11633-008-0257-y
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   SAITO H, 1999, P IEEE C COMP VIS PA, V2, P49
   SCHIRMACHER H, 2001, P EUROGRAPHICS 2001, P165
   Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915
   STARCK J, 2008, P 3DTV C TRUE VIS CA, P225
   THEOBALT C, 2003, P VVG, P9
   Yang J, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P77, DOI 10.1109/INFVIS.2002.1173151
   Yang RG, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P225, DOI 10.1109/PCCGA.2002.1167864
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 25
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 577
EP 585
DI 10.1016/j.jvcir.2010.01.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600018
DA 2024-07-18
ER

PT J
AU Lee, DB
   Song, H
AF Lee, Dai-Boong
   Song, Hwangjun
TI QoE-aware mobile IPTV channel control algorithm over WiMAX network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mobile IPTV; Channel control; Quality of experience; WiMAX; Channel
   zapping time; Video quality; Proactive TV channels; On-demand TV
   channels
ID SERVICES
AB In this paper, we present an effective IPTV channel control algorithm that improves the quality of experience for subscribers to mobile IPTV services over WiMAX network. We consider the video quality of TV channels and the channel zapping time as quality of experience metrics. The proposed algorithm controls the channel distribution state and the target bit rate of TV channels based on the channel preference information of subscribers to achieve an effective trade-off between channel zapping time and video quality. Finally, simulation results are provided to demonstrate the performance of the proposed system. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Song, Hwangjun] Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Pohang 790784, Gyungbuk, South Korea.
   [Lee, Dai-Boong] Samsung Elect Co Ltd, Telecommun Syst Div, Suwon 443742, Gyeonggi Do, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Samsung; Samsung
   Electronics
RP Song, H (corresponding author), Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Pohang 790784, Gyungbuk, South Korea.
EM hwangjun@postech.ac.kr
FU MKE/IITA [2007-F-038-03]; MKE (The Ministry of Knowledge Economy), Korea
   [NIPA-2009-C1090-0902-0006]
FX This work was supported by the IT R&D program of MKE/IITA
   (2007-F-038-03, Fundamental Technologies for the Future Internet) and
   the MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center) support program supervised by
   the NIPA (National IT Industry Promotion Agency)
   (NIPA-2009-C1090-0902-0006).
CR AN C, 2007, IEEE INT C IM PROC S, V5
   [Anonymous], 2004, 302304 ETSI EN
   [Anonymous], 2006, 25346 3GPP TS
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 80216 IEEE
   *ATIS IIF, 2006, ATIS0800004
   Boyce JM, 2005, IEEE ICCE, P1
   *CABL TEL LAB INC, 2003, DOCSISSPCMCI10903073
   Cho C, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P971
   *CISC SYST, 2005, MAN DEL IP VID NETW
   Demircin MU, 2008, IEEE T MULTIMEDIA, V10, P1155, DOI 10.1109/TMM.2008.2001383
   *DSL, 2006, TR126 DSL
   Hou F, 2008, IEEE ICC, P2566, DOI 10.1109/ICC.2008.486
   *IEEE, 2004, 02162004 IEEE
   IRELAND HG, 2005, ENABLING IPTV WHAT C
   *ITU T, IPTVC0411 ITUT FG
   Jennehag U, 2004, IEEE IMAGE PROC, P2075
   Jiang T, 2007, IEEE COMMUN MAG, V45, P78, DOI 10.1109/MCOM.2007.4290318
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   Kim J, 2005, 7TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P1152
   KIM J, 2006, INT C ADV COMM TECHN, V1, P465
   Lee DB, 2007, IEEE T BROADCAST, V53, P789, DOI 10.1109/TBC.2007.910919
   LEE YW, 2004, IEEE INT C IMAG PROC, V2, P803
   Luna CE, 2003, IEEE T CIRC SYST VID, V13, P141, DOI 10.1109/TCSVT.2002.808439
   Park WK, 2005, I SYMP CONSUM ELECTR, P285, DOI 10.1109/ISCE.2005.1502388
   *QUALCOMM, QUALCOMM MEDIAFLO
   She J, 2007, IEEE COMMUN MAG, V45, P87, DOI 10.1109/MCOM.2007.4290319
   Sun M.-T., 2000, Compressed Video over Networks, V1st
   TEKLA S, 1996, IEEE SPECTRUM, V4, P22
   Wang Q, 2002, IEEE SIGNAL PROC LET, V9, P33, DOI 10.1109/97.991132
   ZIPF G, 1994, HUMAN BEHAV PRINCIPL
NR 31
TC 8
Z9 9
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 245
EP 255
DI 10.1016/j.jvcir.2010.01.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400006
OA Bronze
DA 2024-07-18
ER

PT J
AU Allouche, A
   Feuer, A
AF Allouche, Amiram
   Feuer, Arie
TI 2D motion aided sampling and reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Multi-dimensional; Nonuniform sampling; Multi-frame;
   Induced motion; Generalized sampling expansion (GSE)
ID SUPERRESOLUTION RECONSTRUCTION; NONUNIFORM; SIGNALS; IMAGE
AB In this paper we consider the problem of generating data which is sufficient for super resolution reconstruction. The method considered here is by inducing motion on the (low resolution) image acquisition device which then generates a number of low resolution images - this is the data we use for the super resolution reconstruction. Our main concern is in investigating a number of motion types and providing the conditions which will guarantee the feasibility of the super resolution reconstruction from data available. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Feuer, Arie] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
   [Allouche, Amiram] Surf Commun Solut Ltd, IL-20692 Yokneam, Israel.
C3 Technion Israel Institute of Technology
RP Feuer, A (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
EM Amirama@Surf-com.com; feuer@ee.technion.ac.il
CR Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509
   CHAUDHURI S, 2001, KLUWER INT SERIES EN
   Cheung K., 1993, ADV TOPICS SHANNON S, P86
   DUBOIS E, 1985, P IEEE, V73, P502, DOI 10.1109/PROC.1985.13182
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Elad M, 1999, IEEE T PATTERN ANAL, V21, P817, DOI 10.1109/34.790425
   EVANS RJ, 1976, P AM MATH SOC, V58, P51, DOI 10.2307/2041358
   Feuer A, 2005, IEEE T SIGNAL PROCES, V53, P4273, DOI 10.1109/TSP.2005.857047
   Feuer A, 2005, IEE P-VIS IMAGE SIGN, V152, P115, DOI 10.1049/ip-vis:20051188
   Feuer A, 2004, IEEE SIGNAL PROC LET, V11, P420, DOI 10.1109/LSP.2004.824022
   Goldberg N, 2003, J VIS COMMUN IMAGE R, V14, P508, DOI 10.1016/S1047-3203(03)00042-7
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   KIM SP, 1990, IEE PROC-F, V137, P197, DOI 10.1049/ip-f-2.1990.0030
   MOLLIN RA., 1998, Fundamental Number Theory with Applications
   Netravali A.N., 1995, DIGITAL PICTURES REP, V2nd
   PATTI AJ, 1994, SIGNAL PROCESS-IMAGE, V6, P213, DOI 10.1016/0923-5965(94)90026-4
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
NR 20
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 1
EP 8
DI 10.1016/j.jvcir.2008.09.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700001
DA 2024-07-18
ER

PT J
AU Guo, H
   Fu, XY
   Chen, F
   Yang, HJ
   Wang, YX
   Li, H
AF Guo, He
   Fu, Xinyuan
   Chen, Feng
   Yang, Hongji
   Wang, Yuxin
   Li, Han
TI As-rigid-as-possible shape deformation and interpolation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE triangle mesh; edge length constraint; global properties; local
   properties; boundary properties; contour vertices matching
AB We provide a detailed analysis of the 2D deformation algorithm based on non-linear least squares optimization, and prove that different mesh structure is of critical importance to deforming result. Based on triangle mesh, preserving the length of edges during deforming is enough to preserve the local, global and boundary properties of the shape. Sufficient theoretical analysis and experiments proved the advantage of the algorithm: (1) It is more stable. The constraint of edges length is strong enough to preserve the stability of triangle, thus the local and global structure are stable. (2) Due to less constraints, the calculating cost is reduced and the performance is improved. (3) The problem of parameter adjusting is solved in the approach. Further more, the algorithm has the ability to control facial expression and to adjust the area of shape etc.
   In addition, a new approach to shape interpolation is presented. The inputs of the shape interpolation algorithm are bitmap represented images without any topology information in both the original and the target shapes. The strategy is to extract the topology of the original shape, and set up the correspondence between the original and the target shapes, which is to find the matching contour vertices between the original and target shapes. And the shape deformation algorithm is applied using the interpolation of the matching vertices as controlling points. The algorithm guarantees as-rigid-as-possible and rotation invariant shape interpolation. The interpolated shapes have the same topology structure with the original and the target shapes. Experiments indicate that the algorithm is stable and well performed. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Guo, He; Fu, Xinyuan; Chen, Feng; Yang, Hongji; Wang, Yuxin; Li, Han] Dalian Univ Technol, Dept Comp Sci & Technol, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Fu, XY (corresponding author), Dalian Univ Technol, Dept Comp Sci & Technol, 43,Sect 4,Keelung Rd, Dalian 116024, Peoples R China.
EM fuxinyuan@gmail.com
RI Wang, Yuxin/ABF-2724-2020; Yang, Hongji/AAJ-4079-2020
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   [Anonymous], 1997, TR9719 MITS EL RES L
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   CELNIKER G, 1991, COMP GRAPH, V25, P257, DOI 10.1145/127719.122746
   CHE WJ, 2004, GRAPHICAL MODELS, V66
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Johan H, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P348, DOI 10.1109/PCCGA.2000.883958
   Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   MACCRACKEN R, P ACM SIGGRAPH, P181
   SCOTT S, 2006, P ACM SIGGRAPH, V25, P533
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   SHEFFER A, P 3D DAT PROC VIS TR, P68
   Surazhsky T, 2001, COMPUT GRAPH-UK, V25, P29, DOI 10.1016/S0097-8493(00)00105-9
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   WENG YL, 2006, INT J COMPUTER GRAPH, V22
NR 18
TC 6
Z9 11
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2008
VL 19
IS 4
BP 245
EP 255
DI 10.1016/j.jvcir.2008.01.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 311MK
UT WOS:000256604100003
DA 2024-07-18
ER

PT J
AU Okuda, M
   Adami, N
AF Okuda, Masahiro
   Adami, Nicola
TI Two-layer coding algorithm for high dynamic range images based on
   luminance compensation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE high dynamic range images; two-layer encoding; inverse tone mapping
   function
AB A two-layer coding algorithm for high dynamic range images is discussed. In the first layer, a low dynamic range image is encoded by a conventional codec, and then the residual information that represents the difference between an original and the decoded images in the first layer is encoded in the second layer, which realizes compatibility with conventional image file formats. Our method utilizes the approximation of an inverse tone mapping function that reduces the high dynamic range to a displayable range. Our algorithm significantly improves a compression performance, compared to conventional methods. (C) 2007 Elsevier Inc. All rights reserved.
C1 Univ Kitakyushu, Fukuoka 8080135, Japan.
   Univ Brescia, I-25123 Brescia, Italy.
C3 University of Kitakyushu; University of Brescia
RP Okuda, M (corresponding author), Univ Kitakyushu, 1-1 Hibikino, Fukuoka 8080135, Japan.
EM okuda-m@env.kitakyu-u.ac.jp; adami@ing.unibs.it
OI Adami, Nicola/0000-0002-8879-9456
CR AKAHANE N, 2006, INT C IM SCI
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2005, Image Sensors and Signal Processing for Digital Still Cameras
   [Anonymous], ACM T COMPUTER GRAPH
   DALY S, 1993, DIGITAL IMAGE HUMAN
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   *ISO, 2003, JASPER SOFTW REF MAN
   Kainz F., 2003, SIGGRAPH TECHNICAL S
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Liu XQ, 2003, IEEE T CIRCUITS-I, V50, P530, DOI 10.1109/TCSI.2003.809815
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   MANTIUK R, 2006, ACM SIGGRAPH
   MANTIUK R, 2004, ACM T GRAPHIC, V123, P741
   PAL C, 2004, IEEE COMP SOC C COMP, V2, P173
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   PATTANAIK SN, 2004, TUTORIAL NOES ACM SI
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Reinhard E., 2005, The Morgan Kaufmann Series in Computer Graphics
   Schlick Christophe., 1994, Quantization techniques for visualization of high dynamic range pictures, P7
   Spaulding K. E., 2003, PICS C, P307
   SPAULDING KE, 2001, Patent No. 6301393
   Spillmann L., 1990, Visual perception: the neurophysiological foundations
   Taubman David S., JPEG 2000 IMAGE COMP
   TSIN Y, 2001, IEEE INT C COMP VIS
   Tumblin J, 1999, COMP GRAPH, P83, DOI 10.1145/311535.311544
   Tumblin J, 1999, ACM T GRAPHIC, V18, P56, DOI 10.1145/300776.300783
   WARD G, 2005, P 13 COL IM C NOV
   Xu RF, 2005, IEEE COMPUT GRAPH, V25, P57, DOI 10.1109/MCG.2005.133
NR 30
TC 35
Z9 42
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 377
EP 386
DI 10.1016/j.jvcir.2007.06.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000004
DA 2024-07-18
ER

PT J
AU Xu, F
   Zhang, YJ
AF Xu, Feng
   Zhang, Yu-Jin
TI Evaluation and comparison of texture descriptors proposed in MPEG-7
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE content-based image retrieval; MPEG-7; homogeneous texture descriptor;
   texture browsing descriptor; edge histogram descriptor
ID IMAGE RETRIEVAL; FEATURES
AB Texture description contributes as one of the most important low-level features in content-based image retrieval. In MPEG-7, homogeneous texture descriptor (HTD), texture browsing descriptor (TBD), and edge histogram descriptor (EHD) have been proposed as texture descriptors. However, no comprehensive evaluation and comparison of these three descriptors have been made. In this paper, we propose a comprehensive evaluation and comparison benchmark for feature descriptors, especially for visual descriptors in MPEG-7. In the proposed benchmark, three texture descriptors in MPEG-7 are evaluated and compared. First, the descriptors are analyzed according to the standard criteria. Second, experiments are implemented on the Brodatz texture image database. Analysis of the experimental results shows that each descriptor has some specific characteristics and performs better than the other two in certain applications. The applicability is also summarized for each descriptor. The survey as well as performance evaluation and comparison in this paper provide several guidelines for using these descriptors in image retrieval and other applications. (C) 2005 Elsevier Inc. All rights reserved.
C1 Tsing Hua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Xu, F (corresponding author), Tsing Hua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM f-xu02@mails.tsinghua.edu.cn
CR [Anonymous], 2002, JTC1SC29WG11 ISOIEC, pN4668
   Brodatz P., 1996, TEXTURE PHOTOGRAPHIC
   Chetverikov D, 2000, IMAGE VISION COMPUT, V18, P975, DOI 10.1016/S0262-8856(00)00041-X
   EIDENBERGER H, 2003, TR1882200320 VIENN U
   GRGIC M, 2001, EUROCON 2001, V2, P365
   HUANG XY, ICICS PCM 2003
   *ISO IEC, 2003, JTCISC29WG11 ISOIEC
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Kruizinga P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P142, DOI 10.1109/ICIAP.1999.797585
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   McIntyre A.R., 2002, P IEEE CAN C EL COMP, V2, P957
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Pun CM, 2003, COMPUT VIS IMAGE UND, V89, P24, DOI 10.1016/S1077-3142(03)00012-2
   Ro YM, 2001, ETRI J, V23, P41, DOI 10.4218/etrij.01.0101.0201
   SONG KY, 1992, MACHINE VISION ROBOT, V1708, P99
   Wang HL, 2003, J VIS COMMUN IMAGE R, V14, P150, DOI 10.1016/S1047-3203(03)00019-1
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wu P, 2000, SIGNAL PROCESS-IMAGE, V16, P33, DOI 10.1016/S0923-5965(00)00016-3
   Zhang DS, 2003, J VIS COMMUN IMAGE R, V14, P41, DOI 10.1016/S1047-3203(03)00003-8
   Zhang Y., 2003, CONTENT BASED VISUAL
NR 21
TC 14
Z9 15
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 701
EP 716
DI 10.1016/j.jvcir.2005.10.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500003
DA 2024-07-18
ER

PT J
AU Chiou, HJ
   Lee, YR
   Lin, CW
AF Chiou, HJ
   Lee, YR
   Lin, CW
TI Content-aware error-resilient transcoding using prioritized
   intra-refresh for video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video coding; video transcoding; error-resilient coding; intra-refresh;
   video streaming
ID MODE SELECTION; TRANSMISSION; COMMUNICATION; ARCHITECTURES; H.263
AB Transmitting video data over wireless networks can be very unreliable due to packet-loss, leading to serious video quality degradation which is annoying to human perception. The lost packets not only affect the quality of Current frame, but also lead to error propagation to subsequent frames due to motion-compensated prediction techniques used in standard video codecs. Adding error-resilience to a video bitstream for robust video delivery to users thus becomes a very important issue. In this work, we propose a two-pass intra-refresh transcoding scheme for inserting error-resilience features to a compressed video at the media gateway of a three-tier streaming system. The proposed transcoder can adaptively vary the intra-refresh rate according to the video content and the channel's packet-loss rate to protect the most important macroblocks (MBs) against packet loss. In the first-pass encoding, the encoder estimates the amount of error propagation at MB level, and then generates side information as transcoding hints for use at the transcoder. In the second-pass transcoding, the error-resilient transcoder adaptively determines the intra-refresh rate and the locations of MBs to perform intra-refresh according to the side information. Experimental results show that the proposed method can effectively mitigate the error propagation due to packet loss so as to improve the visual quality significantly. The proposed transcoder can also meet the real-time requirement. (c) 2005 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM cwlin@cs.ccu.edu.tw
RI Lin, Chia-Wen/ABH-6075-2020; Lin, Chia-Wen/M-4571-2013
OI Lin, Chia-Wen/0000-0002-9097-2318
CR Assunçao PAA, 1998, IEEE T CIRC SYST VID, V8, P953, DOI 10.1109/76.736724
   Chang PC, 2000, IEEE T CIRC SYST VID, V10, P600, DOI 10.1109/76.845005
   Chen WHJ, 2001, IEEE T CIRC SYST VID, V11, P974, DOI 10.1109/76.937447
   CHULZRINNE H, 1996, 1889 RFC
   Côté G, 1999, SIGNAL PROCESS-IMAGE, V15, P25, DOI 10.1016/S0923-5965(99)00022-3
   Côté G, 2000, IEEE J SEL AREA COMM, V18, P952, DOI 10.1109/49.848249
   de los Reyes G, 2000, IEEE J SEL AREA COMM, V18, P1063, DOI 10.1109/49.848256
   Dogan S, 2002, IEEE T CIRC SYST VID, V12, P453, DOI 10.1109/TCSVT.2002.800308
   GILBERT EN, 1960, BELL SYST TECH J, V39, P1253, DOI 10.1002/j.1538-7305.1960.tb03959.x
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   LAM WM, 1993, P ICASSP, V5, P417
   Puri R, 2001, IEEE T MULTIMEDIA, V3, P18, DOI 10.1109/6046.909591
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   Steinbach E, 1997, IEEE T CIRC SYST VID, V7, P872, DOI 10.1109/76.644067
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   SWANN R, 1996, P IEEE INT C IM PROC, V2, P813
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Vetro A., 2002, J WIRELESS COMMUNICA, V2, P549
   Wang TC, 2002, IEEE T CIRC SYST VID, V12, P1049, DOI 10.1109/TCSVT.2002.806807
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Warabino T, 2000, IEEE COMMUN MAG, V38, P66, DOI 10.1109/35.874971
   Youn J, 1999, IEEE T MULTIMEDIA, V1, P30, DOI 10.1109/6046.748169
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P861, DOI 10.1109/ICME.2002.1035918
NR 25
TC 16
Z9 21
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 563
EP 588
DI 10.1016/j.jvcir.2004.11.009
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600011
DA 2024-07-18
ER

PT J
AU Shen, JH
AF Shen, JH
TI On the foundations of vision modeling - II. Mining of mirror symmetry of
   2-D shapes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE mirror symmetry; shapes; mass center; PCA; Lebesgue; Hausdorff; feature
   sets; existence; convex shape; support function; normal shooting
ID APPROXIMATION; FEATURES
AB Vision can be considered as a feature mining problem. Visually meaningful features are often geometrical, e.g., boundaries (or edges), corners, T-junctions, and symmetries. Mirror symmetry or near mirror symmetry is one of the most common and useful symmetry types in image and vision analysis. The current paper proposes several different approaches for studying 2-dimensional (2-D) mirror symmetric shapes. Proper mirror symmetry metrics are introduced based upon the Lebesgue measure, Hausdorff distance, as well as lower-dimensional feature sets. Theory and computation of these approaches and measures are developed, and numerical results are demonstrated. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Minnesota, Sch Math, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Univ Minnesota, Sch Math, 206 Church St SE, Minneapolis, MN 55455 USA.
EM jhshen@math.umn.edu
RI Shen, Jianhong Jackie/S-7419-2019
OI Shen, Jackie/0000-0003-0653-3951
CR AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805
   AMBROSIO L, 1992, B UNIONE MAT ITAL, V6B, P105
   [Anonymous], 1992, 10 LECT WAVELETS
   [Anonymous], 1992, Scientific Computing and Differential Equations: An Introduction to Numerical Methods
   [Anonymous], IMAGE PROCESSING ANA
   Candes E., 2000, P SPIE, V4119
   CAO Y, 2002, SIGNAL PROCESS PATTE, P92
   Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   GRENANDER U, 1976, LECT PATTERN THEORY, V3
   Grenander U., 1976, LECT PATTERN THEORY, V2
   Grenander Ulf., 1976, Lectures in Pattern Theory, Volume 1: Pattern Synthesis, V1
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Milnor John W., 1997, Topology from the Differentiable Viewpoint
   MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352
   Mochizuki T, 1998, NATURE, V395, P177, DOI 10.1038/26006
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   Shen J., 2003, SIAM News, V36
   Shen JH, 2003, PHYSICA D, V175, P241, DOI 10.1016/S0167-2789(02)00734-0
   STRANG G, 1993, INTRO APPL MATH
   Sun C, 1999, REAL-TIME IMAGING, V5, P63, DOI 10.1006/rtim.1998.0135
   Vogan KJ, 1999, NATURE, V397, P295, DOI 10.1038/16796
   WAGEMANS J, 1996, GEOMETRY TOPOLOGY SU
NR 25
TC 4
Z9 4
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 250
EP 270
DI 10.1016/j.jvcir.2004.11.003
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kherfi, ML
   Ziou, D
   Bernardi, A
AF Kherfi, ML
   Ziou, D
   Bernardi, A
TI Combining positive and negative examples in relevance feedback for
   content-based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE relevance feedback; content-based image retrieval; positive example
   (PE); negative example (NE); feature selection
AB In this paper, we address some issues related to the combination of positive and negative examples to improve the efficiency of image retrieval. We start by analyzing the relevance of the negative example and how it can be interpreted and utilized to mitigate certain problems in image retrieval, such as noise, miss, the page zero problem and feature selection. Then we propose a new relevance feedback approach that uses the positive example (PE) to perform generalization and the negative example (NE) to perform specialization. In this approach, a query containing both PE and NE is processed in two steps. The first step considers the PE alone, in order to reduce the set of images participating in retrieval to a more homogeneous subset. Then, the second step considers both PE and NE and acts on the images retained in the first step. Mathematically; relevance feedback is formulated as an optimization of the intra and inter variances of the PE and NE. The proposed relevance feedback algorithm was implemented in our image retrieval system, which we tested on a collection of more than 10,000 images. The experimental results show how the NE as considered in our model can contribute in improving the relevance of the images retrieved. (C) 2003 Elsevier Inc. All rights reserved.
C1 Univ Sherbrooke, Fac Sci, DMI, Sherbrooke, PQ J1K 2R1, Canada.
   Univ Montreal, Bell Labs, Montreal, PQ H3A 2A5, Canada.
C3 University of Sherbrooke; Universite de Montreal
RP Univ Sherbrooke, Fac Sci, DMI, Sherbrooke, PQ J1K 2R1, Canada.
EM kherfi@dmi.usherb.ca; Djemel.Ziou@dmi.usherb.ca; alan.bernardi@bell.ca
RI Kherfi, Mohammed Lamine/AAF-2930-2020
OI Kherfi, Mohammed Lamine/0000-0003-1017-1113
CR Belkin N. J., 1998, Sixth Text REtrieval Conference (TREC-6) (NIST SP 500-240), P597
   Bhanu B, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P14, DOI 10.1109/IVL.1998.694471
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   COX IJ, 1996, INT C PATT REC VIENN, P361
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   HAN H, 1992, 18 INT C VERY LARG D, P547
   Huang J., 1997, IEEE C COMPUTER VISI
   Ishii H, 1998, IEEE J SEL TOP QUANT, V4, P24, DOI 10.1109/2944.669459
   JING F, 2002, IEEE INT S CIRC SYST, P365
   KHERFI ML, 2001, 276 U SHERBR CAN DEC
   KIM YS, 2000, 6 ACM SIGKDD INT C K, P365
   LI J, 2000, 200 ACM MULT C SAN J, P147
   Meilhac C, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P512, DOI 10.1109/MMCS.1999.779254
   MICHALSKI RS, 1983, MACHINE LEARING ART, V1
   Minka TP, 1996, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.1996.517110
   MULLER H, 2000, 0001 COMP VIS COMP V
   NAKAZATO M, 2003, INT C IM PROC ICIP B
   Nastar C, 1998, PROC CVPR IEEE, P547, DOI 10.1109/CVPR.1998.698659
   PICARF RW, 1996, 382 MIT
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313323
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Rui Y., 2000, IEEE INT C COMP VIS
   RUI Y, 1999, THESIS DEP COMPUT SC
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH J, 1998, IEEE WORKSH CONT BAS
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   TAYCHER L, 1998, IMAGE DIGESTION RELE
   TROUVE A, 2001, 3 EMMCVR INT WORKSH, P50
   VASCONCELOS N, 1999, NEURAL INFORMATION P
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   ZHANG HJ, 2001, 12 INT C NEW INF TEC
   ZHOU XS, 2001, ACM MULTIMEDIA, P137
NR 34
TC 34
Z9 40
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 428
EP 457
DI 10.1016/S1047-3203(03)00043-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800004
DA 2024-07-18
ER

PT J
AU Zhao, J
   Liao, J
   Yuan, J
AF Zhao, Jing
   Liao, Jie
   Yuan, Jin
TI HSP-MFL: A High-level Semantic Property driven Multi-task Feature
   Learning Network for unsupervised person Re-ID
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised person re-identification; Multi-task learning; Feature
   fusion; Discriminative feature learning
AB Unsupervised person re-identification aims to distinguish different pedestrians from discriminative repre-sentations on the basis of unlabeled data. Currently, most unsupervised Re-ID approaches explore visual representations to generate pseudo-labels for model's training, which may suffer from background noise and semantic loss. To tackle this problem, this paper proposes a High-level Semantic Property driven Multi-task Feature Learning Network (HSP-MFL) to firstly introduce three high-level semantic properties for unsupervised person Re-ID. Technically, we design a novel Multiple Feature Fusion Module (MFFM) to deeply explore the complex correlation among multiple semantic and visual features to capture the discriminative feature cues, as well as a multi-task training scheme to generate robust fusion features. The architecture is quite simple and does not consume extra labeling costs. Extensive experiments on three datasets demonstrate that both high-level semantic properties and multi-task learning are effective in performance improvement, yielding SOTA mAPs for unsupervised person Re-ID.
C1 [Zhao, Jing] Nanjing Univ Sci & Technol, Nanjing, Peoples R China.
   [Liao, Jie; Yuan, Jin] Hunan Univ, Changsha, Peoples R China.
C3 Nanjing University of Science & Technology; Hunan University
RP Yuan, J (corresponding author), Hunan Univ, Changsha, Peoples R China.
EM yuanjin@hnu.edu.cn
RI Wang, Zejun/KBB-8454-2024; Yang, Ning/KHD-1133-2024; Wang,
   zhenhua/KFA-8731-2024; Chen, Haili/KHE-2315-2024
FU National Natural Science Foundation of China [62272157]; Natural Science
   Foundation of Changsha [kq2202177]
FX Acknowledgments The authors are highly grateful to the anonymous
   referees for their careful reading and insightful comments. This work
   was supported by National Natural Science Foundation of China No.
   62272157, and Natural Science Foundation of Changsha No. kq2202177.
CR Bai ZC, 2021, PROC CVPR IEEE, P12909, DOI 10.1109/CVPR46437.2021.01272
   Chang H., 2022, P IEEECVF C COMPUTER
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14940, DOI 10.1109/ICCV48922.2021.01469
   Cheng DQ, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104493
   Cho Y., 2022, P IEEE C COMP VIS PA
   Dai ZZ, 2021, Arxiv, DOI [arXiv:2103.11568, 10.48550/arXiv.2103.11568]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   He K., 2016, P IEEE C COMP VIS PA
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   He TY, 2021, PROC CVPR IEEE, P9101, DOI 10.1109/CVPR46437.2021.00899
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang Z., 2022, P IEEE CVF C COMP VI
   Ji HXY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3641, DOI 10.1109/ICCV48922.2021.00364
   Kakadiaris IA, 2016, IEEE IMAGE PROC, P3156, DOI 10.1109/ICIP.2016.7532941
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lin X., 2021, arXiv
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu JW, 2021, PROC CVPR IEEE, P4368, DOI 10.1109/CVPR46437.2021.00435
   Luo Hao, 2019, IEEE T MULTIMEDIA TM
   Saber S, 2022, INFORM SCIENCES, V617, P331, DOI 10.1016/j.ins.2022.10.105
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sung Y., 2021, arXiv
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang D., 2020, P IEEECVF C COMPUTER
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang HC, 2022, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR52688.2022.00715
   Wang JD, 2020, Arxiv, DOI [arXiv:1908.07919, DOI 10.48550/ARXIV.1908.07919, DOI 10.1109/TPAMI.2020.2983686]
   Wang M., 2021, P AAAI C ART INT
   Wang Z., 2022, P AAAI C ART INT
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu L, 2022, IEEE T IMAGE PROCESS, V31, P4803, DOI 10.1109/TIP.2022.3186746
   Wu W., 2022, P IEEE CVF C COMP VI
   Xuan S.Y., 2021, P IEEE INT C COMP VI
   Yan Y., 2019, IEEE CVF INT C COMP
   Yang FX, 2021, PROC CVPR IEEE, P4853, DOI 10.1109/CVPR46437.2021.00482
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yang Z., 2022, P IEEECVF C COMPUTER
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Zhang X, 2021, PROC CVPR IEEE, P3435, DOI 10.1109/CVPR46437.2021.00344
   Zhang Xuanmeng, 2022, P IEEE CVF C COMP VI
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zheng L., 2011, P INT C COMP VIS ICC
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Y., 2021, P IEEE CVF INT C COM
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, IEEE CVF INT C COMP
   Zhu H., 2022, P IEEECVF C COMPUTER
   Zhu K., 2022, P EUR C COMP VIS
   Zhu ZH, 2020, AAAI CONF ARTIF INTE, V34, P13114
NR 52
TC 3
Z9 3
U1 3
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103828
DI 10.1016/j.jvcir.2023.103828
EA APR 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G5YU9
UT WOS:000989918100001
DA 2024-07-18
ER

PT J
AU Wang, L
   Li, J
   Zhang, SQ
   Qi, C
   Wang, P
   Wang, FP
AF Wang, Lin
   Li, Jie
   Zhang, Siqi
   Qi, Chun
   Wang, Pan
   Wang, Fengping
TI Multi-Scale and spatial position-based channel attention network for
   crowd counting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Spatial position -based channel attention model; Multi
   -scale structure; Adaptive loss
AB Crowd counting algorithms have recently incorporated attention mechanisms into convolutional neural networks (CNNs) to achieve significant progress. The channel attention model (CAM), as a popular attention mechanism, calculates a set of probability weights to select important channel-wise feature responses. However, most CAMs roughly assign a weight to the entire channel-wise map, which makes useful and useless information being treat indiscriminately, thereby limiting the representational capacity of networks. In this paper, we propose a multi -scale and spatial position-based channel attention network (MS-SPCANet), which integrates spatial position -based channel attention models (SPCAMs) with multiple scales into a CNN. SPCAM assigns different channel attention weights to different positions of channel-wise maps to capture more informative features. Furthermore, an adaptive loss, which uses adaptive coefficients to combine density map loss and headcount loss, is constructed to improve network performance in sparse crowd scenes. Experimental results on four public datasets verify the superiority of the scheme.
C1 [Wang, Lin; Li, Jie; Qi, Chun; Wang, Pan; Wang, Fengping] Xi An Jiao Tong Univ, Fac Elect & Informat Engn, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
   [Zhang, Siqi] Xian Modern Control Technol Res Inst, Xian 710065, Peoples R China.
C3 Xi'an Jiaotong University
RP Li, J (corresponding author), Xi An Jiao Tong Univ, Fac Elect & Informat Engn, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
EM jielixjtu@xjtu.edu.cn
RI Zhang, Siqi/GLV-5035-2022
FU National Natural Science Foundation of China;  [61675161];  [62275211]
FX This work was supported by the National Natural Science Foundation of
   China [61675161, 62275211] .
CR Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen JW, 2020, NEUROCOMPUTING, V382, P210, DOI 10.1016/j.neucom.2019.11.064
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Chen XY, 2019, IEEE WINT CONF APPL, P1941, DOI 10.1109/WACV.2019.00211
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Fiaschi L, 2012, INT C PATT RECOG, P2685
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   Guerrero-Gómez-Olmedo R, 2015, LECT NOTES COMPUT SC, V9117, P423, DOI 10.1007/978-3-319-19390-8_48
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Hou Y, 2020, INT CONF ACOUST SPEE, P4072, DOI [10.1109/ICASSP40776.2020.9053955, 10.1109/icassp40776.2020.9053955]
   Hu J, 2020, IEEE T PATTERN ANAL, V42, P2011, DOI 10.1109/TPAMI.2019.2913372
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XH, 2021, IEEE T MULTIMEDIA, V23, P443, DOI 10.1109/TMM.2020.2980945
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Kasuya E, 2019, ECOL RES, V34, P235, DOI 10.1111/1440-1703.1011
   KVALSETH TO, 1985, AM STAT, V39, P279, DOI 10.2307/2683704
   Laradji IH, 2018, LECT NOTES COMPUT SC, V11206, P560, DOI 10.1007/978-3-030-01216-8_34
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li HH, 2017, IEEE T IMAGE PROCESS, V26, P5421, DOI 10.1109/TIP.2017.2740119
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin WY, 2021, Arxiv, DOI arXiv:2005.04490
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu XB, 2016, AAAI CONF ARTIF INTE, P3553
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Simonyan K., 2014, 14091556 ARXIV
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2019, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2019.00131
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   Wang BS, 2020, NEURAL COMPUT APPL, V32, P2897, DOI 10.1007/s00521-018-3810-9
   Wang Q, 2022, IEEE T CYBERNETICS, V52, P4675, DOI 10.1109/TCYB.2020.3033428
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang Y, 2021, IEEE T IMAGE PROCESS, V30, P2876, DOI 10.1109/TIP.2021.3055632
   Yi S, 2016, IEEE T IMAGE PROCESS, V25, P4354, DOI 10.1109/TIP.2016.2590322
   Yu F., 2015, ARXIV
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang A, 2019, IEEE I CONF COMP VIS, P5713, DOI 10.1109/ICCV.2019.00581
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YM, 2019, NEUROCOMPUTING, V329, P144, DOI 10.1016/j.neucom.2018.10.058
   Zhu L., 2019, arXiv, DOI DOI 10.48550/ARXIV.1902.01115
   Zhu LP, 2020, NEURAL COMPUT APPL, V32, P5105, DOI 10.1007/s00521-018-3954-7
NR 55
TC 4
Z9 4
U1 8
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103718
DI 10.1016/j.jvcir.2022.103718
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7Q6RM
UT WOS:000909516300001
DA 2024-07-18
ER

PT J
AU Xia, CX
   Duan, SS
   Gao, XJ
   Sun, YG
   Huang, RM
   Ge, B
AF Xia, Chenxing
   Duan, Songsong
   Gao, Xiuju
   Sun, Yanguang
   Huang, Rongmei
   Ge, Bin
TI GCENet: Global contextual exploration network for RGB-D salient object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Convolution neural network; Multi-scale;
   Global contextual
AB Representing contextual features at multiple scales is important for RGB-D SOD. Recently, due to advances in backbone convolutional neural networks (CNNs) revealing stronger multi-scale representation ability, many methods achieved comprising performance. However, most of them represent multi-scale features in a layer -wise manner, which ignores the fine-grained global contextual cues in a single layer. In this paper, we propose a novel global contextual exploration network (GCENet) to explore the performance gain of multi-scale contextual features in a fine-grained manner. Concretely, a cross-modal contextual feature module (CCFM) is proposed to represent the multi-scale contextual features at a single fine-grained level, which can enlarge the range of receptive fields for each network layer. Furthermore, we design a multi-scale feature decoder (MFD) that integrates fused features from CCFM in a top-down way. Extensive experiments on five benchmark datasets demonstrate that the proposed GCENet outperforms the other state-of-the-art (SOTA) RGB-D SOD methods.
C1 [Xia, Chenxing; Duan, Songsong; Sun, Yanguang; Huang, Rongmei; Ge, Bin] Anhui Univ Sci & Technol, Coll Comp Sci & Engn, Huainan 232001, Peoples R China.
   [Xia, Chenxing] Hefei Comprehens Natl Sci Ctr, Inst Energy, Hefei 230031, Peoples R China.
   [Gao, Xiuju] Anhui Univ Sci & Technol, Sch Elect & informat Engn, Huainan 232001, Peoples R China.
C3 Anhui University of Science & Technology; Anhui University of Science &
   Technology
RP Duan, SS (corresponding author), Anhui Univ Sci & Technol, Coll Comp Sci & Engn, Huainan 232001, Peoples R China.
EM cxxia@aust.edu.cn; d15180632812@163.com; xjgao@aust.edu.cn;
   syg1513@163.com; 1683551760@qq.com; bge@aust.edu.cn
OI Duan, Songsong/0000-0003-2983-4044
FU National Natural Science Foundation of China [62102003]; Natural Science
   Research Project of Colleges and Universities in Anhui Province, China
   [KJ2020A0299]; Anhui Natural Science Foundation, China [2108085QF258];
   University-level key projects of Anhui University of science and
   technology, China [QN2019102]; University-level general projects of
   Anhui University of science and technology, China [xjyb2020-04]
FX Acknowledgments This work was supported by the National Natural Science
   Foun-dation of China (62102003) , Natural Science Research Project of
   Col-leges and Universities in Anhui Province, China (KJ2020A0299) ,
   Anhui Natural Science Foundation, China (2108085QF258) ,
   University-level key projects of Anhui University of science and
   technology, China (QN2019102) , University-level general projects of
   Anhui University of science and technology, China (xjyb2020-04) .
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bao YQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103306
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2020, IEEE T IMAGE PROCESS, V29, P8407, DOI 10.1109/TIP.2020.3014734
   Chen Q, 2021, AAAI CONF ARTIF INTE, V35, P1063
   Chen Tianyou, 2022, NEURAL COMPUT APPL, P1
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Cheng Y., 2014, ICIMCS, P23
   Chongyi Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P225, DOI 10.1007/978-3-030-58598-3_14
   Ciptadi A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.112
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Feng G, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108666
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Gao L, 2021, APPL INTELL, V51, P7601, DOI 10.1007/s10489-021-02289-3
   Gongyang Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P665, DOI 10.1007/978-3-030-58520-4_39
   Huang NAC, 2022, IEEE T MULTIMEDIA, V24, P1651, DOI 10.1109/TMM.2021.3069297
   Jin WD, 2021, IEEE T IMAGE PROCESS, V30, P3376, DOI 10.1109/TIP.2021.3060167
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kingma D. P., 2014, arXiv
   Laskar Z, 2017, LECT NOTES COMPUT SC, V10270, P88, DOI 10.1007/978-3-319-59129-2_8
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li GY, 2021, IEEE T IMAGE PROCESS, V30, P3528, DOI 10.1109/TIP.2021.3062689
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Liu T, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-016-9150-x
   Liu YY, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103505
   Liu ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4481, DOI 10.1145/3474085.3475601
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Moradi M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103259
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Piao YR, 2020, IEEE T IMAGE PROCESS, V29, P1879, DOI 10.1109/TIP.2019.2942434
   Qin Z., 2021, PROC IEEECVF INT C C, P783
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Simonyan K., 2014, CORR
   Sun P, 2021, PROC CVPR IEEE, P1407, DOI 10.1109/CVPR46437.2021.00146
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang FY, 2022, IEEE T IMAGE PROCESS, V31, P1285, DOI 10.1109/TIP.2022.3140606
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang XH, 2021, IEEE T IMAGE PROCESS, V30, P458, DOI 10.1109/TIP.2020.3037470
   Wei Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P52, DOI 10.1007/978-3-030-58523-5_4
   Wu YH, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103048
   Wu Z, 2021, IEEE T IMAGE PROCESS, V30, P6226, DOI 10.1109/TIP.2021.3093380
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xia CX, 2020, NEUROCOMPUTING, V383, P194, DOI 10.1016/j.neucom.2019.09.096
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7222, DOI 10.1109/ICCV.2019.00732
   Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564
   Zhang J, 2017, INFORM SCIENCES, V399, P154, DOI 10.1016/j.ins.2017.03.005
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhang Q, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103350
   Zhang WB, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P731, DOI 10.1145/3474085.3475240
   Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhou DX, 2020, APPL COMPUT HARMON A, V48, P787, DOI 10.1016/j.acha.2019.06.004
   Zhou T., 2021, PROC IEEE INT C COMP, P4681
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou WJ, 2022, IEEE T MULTIMEDIA, V24, P2192, DOI 10.1109/TMM.2021.3077767
NR 66
TC 1
Z9 1
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103680
DI 10.1016/j.jvcir.2022.103680
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600001
DA 2024-07-18
ER

PT J
AU He, QL
   Yang, C
   Yang, FX
   An, P
AF He, Qinglin
   Yang, Chao
   Yang, Fanxi
   An, Ping
TI Unsupervised blind image quality assessment based on joint structure and
   natural scene statistics features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blindimagequalityassessment; Structureinformation;
   Naturalscenestatistics; Karhunen-Lo?vetransform
ID BLUR
AB Compared with the widely used supervised blind image quality assessment (BIQA) models, unsupervised BIQA models require little prior knowledge for calculating the objective quality scores of distorted images. In this paper, we propose an unsupervised BIQA method that aims to achieve both good performance and generalization capability with low computational complexity. Carefully selected and extensive structure and natural scene statistics (NSS) features can better represent image quality. First, we employ phase congruency (PC) and finely selected gradient magnitude map and Laplacian of Gaussian response (GM-LOG) features to represent image structure information. Second, we calculate the local mean-subtracted and contrast-normalized (MSCN) coefficients and the Karhunen-Loeve transform (KLT) coefficients to represent the naturalness of the distorted images. Last, multivariate Gaussian (MVG) model with joint features extracted from both the pristine images and the distorted images is adopted to calculate the objective image quality. Extensive experiments conducted on nine IQA databases demonstrate that the proposed method achieves better performance than the state-of-the-art BIQA methods.
C1 [He, Qinglin; Yang, Chao; Yang, Fanxi; An, Ping] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Yang, C (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM yangchaoie@shu.edu.cn
RI Liu, Wenbin/ABC-5721-2020
OI Liu, Wenbin/0000-0002-9469-7499; Yang, Chao/0000-0001-9276-5673
FU NSFC, China [61901252, 62020106011, 62071287]; Science and Technology
   Commission of Shanghai Municipality China [22ZR1424300, 20DZ2290100]
FX This work was supported in part by the NSFC, China under Grant 61901252,
   62020106011, 62071287, and Science and Technology Commission of Shanghai
   Municipality China under Grant 22ZR1424300, 20DZ2290100.
CR [Anonymous], 2011, MICT Image Quality Evaluation Database
   [Anonymous], 2000, FINAL REPORT VIDEO Q
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Deng CW, 2020, IEEE T CYBERNETICS, V50, P1146, DOI 10.1109/TCYB.2018.2889376
   Fang YM, 2020, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR42600.2020.00373
   Fang YM, 2019, J VIS COMMUN IMAGE R, V60, P140, DOI 10.1016/j.jvcir.2018.12.035
   Farah Joumana, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P161, DOI 10.1109/ICASSP.2014.6853578
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Hancheng Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14131, DOI 10.1109/CVPR42600.2020.01415
   He WX, 2019, IEEE IPCCC, DOI 10.1109/ipccc47392.2019.8958718
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hui Q, 2019, CHIN CONT DECIS CONF, P2067, DOI [10.1109/CCDC.2019.8833247, 10.1109/ccdc.2019.8833247]
   Jain A., 2011, Communication and Industrial Application (ICCIA), 2011 International Conference on, P1, DOI [10.1109/ICCIndA.2011.6146668, DOI 10.1109/ICCINDA.2011.6146668]
   Ji WP, 2019, J VIS COMMUN IMAGE R, V58, P195, DOI 10.1016/j.jvcir.2018.11.038
   Joshi P, 2018, IEEE ACCESS, V6, P33871, DOI 10.1109/ACCESS.2018.2846585
   Khalid H, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.1030922019
   Kim J, 2017, IEEE IMAGE PROC, P3180, DOI 10.1109/ICIP.2017.8296869
   Kovesi P., 1999, Videre, V1
   Lahdelma R, 2006, EUR J OPER RES, V170, P957, DOI 10.1016/j.ejor.2004.08.022
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   Lin HH, 2019, INT WORK QUAL MULTIM
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Liu YT, 2020, IEEE ACCESS, V8, P84105, DOI 10.1109/ACCESS.2020.2991842
   Liu YT, 2020, IEEE T CIRC SYST VID, V30, P929, DOI 10.1109/TCSVT.2019.2900472
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma X. Y., 2017, 2017 4 INT C SYST IN
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Sang QB, 2020, IEEE ACCESS, V8, P75925, DOI 10.1109/ACCESS.2020.2989312
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Soundararajan R, 2011, INT CONF ACOUST SPEE, P1149
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P4449, DOI 10.1109/TIP.2021.3072221
   Venkatanath N, 2015, NATL CONF COMMUN
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2017, WIREL TELECOMM SYMP, DOI 10.1109/WTS.2017.7943534
   Wu JJ, 2019, J VIS COMMUN IMAGE R, V58, P353, DOI 10.1016/j.jvcir.2018.12.005
   Wu QB, 2015, IEEE IMAGE PROC, P339, DOI 10.1109/ICIP.2015.7350816
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang C, 2021, IEEE T MULTIMEDIA, V23, P1557, DOI 10.1109/TMM.2020.3001537
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang XH, 2020, NEUROCOMPUTING, V401, P209, DOI 10.1016/j.neucom.2020.03.072
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   You JY, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103399
   Yutao Liu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457858
   Zeng H, 2018, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2018.8451285
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang XF, 2019, IEEE IMAGE PROC, P1730, DOI [10.1109/ICIP.2019.8803184, 10.1109/icip.2019.8803184]
NR 58
TC 1
Z9 1
U1 4
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103579
DI 10.1016/j.jvcir.2022.103579
EA JUL 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100007
DA 2024-07-18
ER

PT J
AU Wang, X
   Chang, CC
   Lin, CC
   Chang, CC
AF Wang, Xu
   Chang, Ching-Chun
   Lin, Chia-Chen
   Chang, Chin-Chen
TI On the multi-level embedding of crypto-image reversible data hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Encrypted images; Multi-Level; Block mapping;
   Very high embedding capacity
ID ENCRYPTED IMAGES; SCHEME
AB Crypto-space reversible image steganography has attracted increasing attention, given its ability to embed authentication information without revealing the image content. This paper presents an efficient reversible data hiding scheme for crypto-images: a block predictor is applied to compute prediction errors, then an adaptive block mapping algorithm is utilized to compress them whose amplitudes are within a small threshold, finally, this strategy can be applied in a multi-level manner to achieve a higher embedding capacity. Due to the correlations among adjacent pixels in the block, images can be sufficiently compressed to reserve abundant space for additional data embedding. Different from the prior arts, the compression code of the image is fully encrypted. Experimental results verify that the embedded data and original image can be perfectly recovered, the security is higher compared with the state-of-the-arts, and a significant improvement in the average embedding rate is achieved on two large-scale image datasets.
C1 [Wang, Xu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Ching-Chun] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
C3 Feng Chia University; University of Warwick; National Chin-Yi University
   of Technology; Providence University - Taiwan
RP Lin, CC (corresponding author), Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
EM wx1990555@gmail.com; ching-chun.chang@warwickgrad.net;
   ally.cclin@ncut.edu.tw; alan3c@gmail.com
RI 王, 旭/GPX-0697-2022; Chang, Ching-Chun/JAN-6210-2023; 王, 旭/JAX-6722-2023
CR [Anonymous], 2011, P 13 INF HID C PRAG
   Bas P., Image database of BOWS-2.
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang CC, 2020, IEEE ACCESS, V8, P198425, DOI 10.1109/ACCESS.2020.3034936
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Shiu PF, 2019, SIGNAL PROCESS-IMAGE, V74, P64, DOI 10.1016/j.image.2019.01.003
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2021, INFORM SCIENCES, V567, P375, DOI 10.1016/j.ins.2021.02.079
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 39
TC 2
Z9 2
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103556
DI 10.1016/j.jvcir.2022.103556
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H5UY
UT WOS:000814360600005
DA 2024-07-18
ER

PT J
AU Karaca, AC
   Kara, O
   Güllü, MK
AF Karaca, Ali Can
   Kara, Ozan
   Gullu, Mehmet Kemal
TI MultiTempGAN: Multitemporal multispectral image compression framework
   using generative adversarial networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multispectral image compression; Generative adversarial networks; Big
   data; Remote sensing; Multitemporal images
ID HYPERSPECTRAL IMAGE
AB Multispectral satellites that measure the reflected energy from the different regions on the Earth generate the multispectral (MS) images continuously. The following MS image for the same region can be acquired with respect to the satellite revisit period. The images captured at different times over the same region are called multitemporal images. Traditional compression methods generally benefit from spectral and spatial correlation within the MS image. However, there is also a temporal correlation between multitemporal images. To this end, we propose a novel generative adversarial network (GAN) based prediction method called MultiTempGAN for compression of multitemporal MS images. The proposed method defines a lightweight GAN-based model that learns to transform the reference image to the target image. Here, the generator parameters of MultiTempGAN are saved for the reconstruction purpose in the receiver system. Due to MultiTempGAN has a low number of parameters, it provides efficiency in multitemporal MS image compression. Experiments were carried out on three Sentinel-2 MS image pairs belonging to different geographical regions. We compared the proposed method with JPEG2000-based conventional compression methods and three deep learning methods in terms of signal-tonoise ratio, mean spectral angle, mean spectral correlation, and laplacian mean square error metrics. Additionally, we have also evaluated the change detection performances and visual maps of the methods. Experimental results demonstrate that MultiTempGAN not only achieves the best metric values among the other methods at high compression ratios but also presents convincing performances in change detection applications.
C1 [Karaca, Ali Can] Yildiz Tech Univ, Dept Comp Engn, Istanbul, Turkey.
   [Kara, Ozan] Kocaeli Univ, Dept Elect & Commun Engn, Kocaeli, Turkey.
   [Gullu, Mehmet Kemal] Izmir Bakircay Univ, Dept Elect & Elect Engn, Izmir, Turkey.
C3 Yildiz Technical University; Kocaeli University; Izmir University of
   Bakircay
RP Karaca, AC (corresponding author), Yildiz Tech Univ, Dept Comp Engn, Istanbul, Turkey.
EM alicankrc@gmail.com
RI Karaca, Ali Can/B-6629-2016; Güllü, Kemal/F-7390-2018
OI Karaca, Ali Can/0000-0002-6835-7634; Güllü, Kemal/0000-0003-2310-2985
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [119E405]
FX This study has been supported by The Scientific and Technological
   Research Council of Turkey (TUBITAK) [119E405] .
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Al Mamun M, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV)
   Alkhatib AAA, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/597368
   Alvarez JLH, 2020, INT GEOSCI REMOTE SE, P2515, DOI 10.1109/IGARSS39084.2020.9324345
   Ao DY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101597
   Aydemir MS, 2019, IEEE J-STARS, V12, P3615, DOI 10.1109/JSTARS.2019.2921033
   Báscones D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060907
   Byju AP, 2020, IEEE T GEOSCI REMOTE, V58, P5739, DOI 10.1109/TGRS.2020.2969374
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng CB, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12213657
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Dua Y, 2022, VISUAL COMPUT, V38, P65, DOI 10.1007/s00371-020-02000-6
   Dumas T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1188, DOI 10.1109/ICASSP.2018.8462263
   Dusselaar R, 2015, INT CONF IMAG VIS
   Ertem A, 2020, INT J REMOTE SENS, V41, P6307, DOI 10.1080/01431161.2020.1737338
   Google Colab, TENS IMPL PIX2PIX, P2021
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karaca AC, 2021, INT J REMOTE SENS, V42, P839, DOI 10.1080/01431161.2020.1823516
   Karaca AC, 2018, SIG PROCESS COMMUN
   Karaca AC, 2019, MULTIDIM SYST SIGN P, V30, P903, DOI 10.1007/s11045-018-0590-4
   Karal O, 2020, 2020 INNOVATIONS INT, P1
   Karami A, 2016, IEEE T GEOSCI REMOTE, V54, P5884, DOI 10.1109/TGRS.2016.2574757
   Klages P, 2020, MED PHYS, V47, P626, DOI 10.1002/mp.13927
   Klimesh M., 2005, IPN PROGR REP, V42-163, P1
   Kong FQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010009
   Kong FQ, 2020, AD HOC NETW, V107, DOI 10.1016/j.adhoc.2020.102272
   Li J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070759
   Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405
   Liu YJ, 2017, IEEE T GEOSCI REMOTE, V55, P1967, DOI 10.1109/TGRS.2016.2632863
   Lu XH, 2020, PROC CVPR IEEE, P856, DOI 10.1109/CVPR42600.2020.00094
   Main-Knorn M, 2017, PROC SPIE, V10427, DOI 10.1117/12.2278218
   Mamun M, 2014, IEEE GEOSCI REMOTE S, V11, P1005, DOI 10.1109/LGRS.2013.2284358
   Nasrabadi NM, 2014, IEEE SIGNAL PROC MAG, V31, P34, DOI 10.1109/MSP.2013.2278992
   Nirmala S.R., 2007, IET UK INT C INF COM
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   Qian S.-E., 2013, Optical Satellite Data Compression and Implementation
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen HD, 2018, J IMAGING, V4, DOI 10.3390/jimaging4120142
   Song CH, 2011, PROC SPIE, V8157, DOI 10.1117/12.895421
   Song JW, 2013, ELECTRON LETT, V49, P992, DOI 10.1049/el.2013.1315
   The Consultative Committee for Space Data Systems (CCSDS) Blue Book, 2019, CCSDS1230B2
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   Tuna S, 2021, IEEE T GEOSCI REMOTE, V59, P9569, DOI 10.1109/TGRS.2020.3031016
   Ülkü I, 2015, APPL OPTICS, V54, P8625, DOI 10.1364/AO.54.008625
   Valsesia D, 2019, IEEE T GEOSCI REMOTE, V57, P9544, DOI 10.1109/TGRS.2019.2927434
   Wang ZL, 2018, IEEE SIGNAL PROC LET, V25, P1161, DOI 10.1109/LSP.2018.2845692
   Yan L, 2018, REMOTE SENS ENVIRON, V215, P495, DOI 10.1016/j.rse.2018.04.021
   Zeegers MT, 2020, J IMAGING, V6, DOI 10.3390/jimaging6120132
   Zhu W, 2011, IEEE GEOSCI REMOTE S, V8, P416, DOI 10.1109/LGRS.2010.2081661
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 52
TC 2
Z9 2
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103385
DI 10.1016/j.jvcir.2021.103385
EA NOV 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XK3OJ
UT WOS:000727378900003
DA 2024-07-18
ER

PT J
AU Chu, HP
   Tang, JL
   Hu, HJ
AF Chu, Huanpeng
   Tang, Jilin
   Hu, Haoji
TI Attention guided feature pyramid network for crowd counting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Feature pyramid network; Attention mechanism; Density
   map generation
AB Crowd counting has become a hot topic because of its wide applications in video surveillance and public security. However, one main problem of the deep learning methods for crowd counting is that the location information about the crowd is degraded irreversibly due to the spatial down-sampling of convolutional neural networks, which degrades the quality of generated density maps. To remedy the above problem, we propose an attention guided feature pyramid network (AG-FPN) for crowd counting, which can adaptively generate a high-quality density map with accurate spatial locations by combining the high-and low-level features. An attention block is added to each encoder layer to further emphasize the crowd regions and suppress the background clutters in feature extraction. Experimental results on the ShanghaiTech, UCF_CC_50, WorldExpo'10 and UCF-QNRF datasets demonstrate the superiority of the proposed method over state-of-the-art approaches.
C1 [Chu, Huanpeng; Tang, Jilin; Hu, Haoji] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Hu, HJ (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
EM chuhp@zju.edu.cn; tangjilin@zju.edu.cn; haoji_hu@zju.edu.cn
RI Chu, Huanpeng/GWQ-8538-2022
OI Tang, Jilin/0000-0001-9478-7489; Huanpeng, Chu/0000-0003-1274-881X; Hu,
   Haoji/0000-0001-6048-6549
CR Bai S, 2020, PROC CVPR IEEE, P4593, DOI 10.1109/CVPR42600.2020.00465
   Bochkovskiy A., 2020, PREPRINT
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cao J., 2020, Attention-guided Context Feature Pyramid Network for Object Detection, DOI 10.48550/arXiv.2005.11475
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Carneiro Carneiro G. G., ARXIV151105635
   Cenggoro TW, 2019, PROCEDIA COMPUT SCI, V157, P175, DOI 10.1016/j.procs.2019.08.155
   Cheng ZQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1897, DOI 10.1145/3343031.3350898
   Dalal N, 2005, P CVPR, P01
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Rong L., 2020, ARXIV PREPRINT ARXIV
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shi MJ, 2019, PROC CVPR IEEE, P7271, DOI 10.1109/CVPR.2019.00745
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Usman S., 2020, ARXIV PREPRINT ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weizhe Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P723, DOI 10.1007/978-3-030-58555-6_43
   Xiong HP, 2019, IEEE I CONF COMP VIS, P8361, DOI 10.1109/ICCV.2019.00845
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 47
TC 8
Z9 8
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103319
DI 10.1016/j.jvcir.2021.103319
EA OCT 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7DP
UT WOS:000709884500004
DA 2024-07-18
ER

PT J
AU Wang, JZ
   Huang, W
   Wang, SC
   Dai, P
   Li, QY
AF Wang, Jianzhu
   Huang, Wei
   Wang, Shengchun
   Dai, Peng
   Li, Qingyong
TI LRGAN: Visual anomaly detection using GAN with locality-preferred
   recoding*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual anomaly detection; GAN; Locality; Recoding
ID SUPPORT
AB Deep neural networks, including deep auto-encoder (DAE) and generative adversarial networks (GAN), have been extensively applied for visual anomaly detection. These models generally assume that reconstruction errors should be lower for normal samples but higher for anomalies. However, it has been found that DAE based models can sometimes reconstruct anomalies very well and thus result in false alarms or misdetections. To address this problem, we propose a model using GAN with locality-preferred recoding, named LRGAN. LRGAN is inspired by the observation that both normal and abnormal samples are not completely scattered throughout the latent space but clustered separately at some local regions. Therefore, a locality-preferred recoding (LR) module is designed to compulsively represent the latent vectors of anomalies by normal ones. As a result, reconstructions of anomalies will approximate to normal samples and corresponding residuals can thus be enlarged. To partly avoid latent vectors of normal samples being recoded, we further present an improved model using GAN with an adaptive LR (ALR) module, named LRGAN+. ALR applies the clustering algorithm to generate a more compact codebook; more importantly, it helps LRGAN + automatically skip the LR module for possible normal samples with a threshold strategy. Our proposed method is evaluated on two public datasets (i.e., MNIST and CIFAR-10) and one real-world industrial dataset (i.e., Fasteners), considering both one-class and multi-class anomaly detection protocols. Experimental results demonstrate that LRGAN is comparable with state-of-the-art methods and LRGAN + outperforms these methods on all datasets.
C1 [Wang, Jianzhu; Huang, Wei; Li, Qingyong] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
   [Wang, Shengchun; Dai, Peng] China Acad Railway Sci LTD, Infrastruct Inspect Res Inst, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Li, QY (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
EM jzwang@bjtu.edu.cn; 17120368@bjtu.edu.cn; wangshengchun@rails.cn;
   daipeng@rails.cn; liqy@bjtu.edu.cn
RI zhao, yuanxin/KDO-9377-2024; Li, Qingyong/GPK-0945-2022; DOU,
   LIPING/KAL-7005-2024; zheng, yi/JOZ-7204-2023
OI Li, Qingyong/0000-0002-3860-4809; 
FU National Natural Science Foundation of China [U2034211, 62006017];
   Fundamental Research Funds for the Central Universities [2020JBZD010];
   Beijing Natural Science Foundation [L191016]; China Railway RD Program
   [P2020T001]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U2034211 and 62006017, in part by the
   Fundamental Research Funds for the Central Universities under Grant
   2020JBZD010, in part by the Beijing Natural Science Foundation under
   Grant L191016 and in part by the China Railway R&D Program under Grant
   P2020T001.
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2016, P ADV NEUR INF PROC
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Aytekin C, 2018, IEEE IJCNN
   Aytekin Ç, 2015, IEEE T SYST MAN CY-S, V45, P1101, DOI 10.1109/TSMC.2014.2388435
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Chen X., 2018, UNSUPERVISED DETECTI, P1, DOI 10.3929/ethz-b-000321650
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hawkins D.M, 1980, IDENTIFICATION OUTLI, V11
   Hou R, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102599
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kingma DP., 2014, C TRACK P
   Liu FT, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133363
   Liu YQ, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102767
   Moshtaghi M, 2011, PATTERN RECOGN, V44, P55, DOI 10.1016/j.patcog.2010.07.024
   Perera P, 2019, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2019.00301
   Pidhorskyi S, 2018, ADV NEUR IN, V31
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Radford A., COMPUTING RES REPOSI
   Rae Jack, 2016, ADV NEURAL INFORM PR, P3621
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ruff L, 2018, PR MACH LEARN RES, V80
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yan MJ, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2019.102747
   Zenati H., ARXIV180206222
NR 33
TC 6
Z9 6
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103201
DI 10.1016/j.jvcir.2021.103201
EA JUL 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100010
DA 2024-07-18
ER

PT J
AU Saldanha, M
   Sanchez, G
   Marcon, C
   Agostini, L
AF Saldanha, Mario
   Sanchez, Gustavo
   Marcon, Cesar
   Agostini, Luciano
TI Performance analysis of VVC intra coding*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile video coding; VVC; Intra-frame coding; Performance analysis
AB This article presents a performance analysis of Versatile Video Coding (VVC) intra-frame prediction. VVC is the next generation of video coding standards, which has been developed to supply the demand of upcoming video applications. VVC brings several innovations and enhancements for the intra-frame prediction to improve the encoding efficiency. These improvements comprise larger block sizes, more flexible block partitioning, more angular intra-frame prediction modes, multiple transform selection, non-separable secondary transform, among others. This article provides a detailed description of these tools, discussing how they work together in the intraframe coding flow to raise the compression performance. Moreover, this article presents encoding complexity, encoding usage distribution, and rate-distortion-complexity analyses of the intra-frame prediction tools over different quantization scenarios. Based on these analyses, this article provides support for future works focusing on VVC intra-frame coding, including complexity reduction, complexity control, and real-time hardware design.
C1 [Saldanha, Mario; Agostini, Luciano] Univ Fed Pelotas, Pelotas, RS, Brazil.
   [Sanchez, Gustavo] IF Farroupilha, Alegrete, Brazil.
   [Marcon, Cesar] Pontificia Univ Catolica Rio Grande do Sul, Porto Alegre, RS, Brazil.
C3 Universidade Federal de Pelotas; Pontificia Universidade Catolica Do Rio
   Grande Do Sul
RP Saldanha, M (corresponding author), Univ Fed Pelotas, Pelotas, RS, Brazil.
EM mrdfsaldanha@inf.ufpel.edu.br; gustavo.sanchez@iffarroupilha.edu.br;
   cesar.marcon@pucrs.br; agostini@inf.ufpel.edu.br
RI Agostini, Luciano/N-1102-2019; Agostini, Luciano/G-8626-2011
OI Saldanha, Mario/0000-0002-6771-6359; Agostini,
   Luciano/0000-0002-3421-5830; Marcon, Cesar/0000-0002-7811-7896
FU FAPERGS; CNPq; CAPES [001]
FX The authors thank FAPERGS, CNPq and CAPES (Finance Code 001) Brazilian
   research support agencies that financed this investigation.
CR Azgin H, 2020, IEEE ICCE, P354, DOI 10.1109/icce46568.2020.9042986
   Bjontegaard G., 2001, Document VCEG-M33
   Bossen F., 2019, Document JVET-N1010
   Bross B., 2018, JVET 12 M MAC OCT
   Budagavi M., 2014, PROC INT C HIGH EFFI, P141
   Cerveira A, 2020, IEEE IMAGE PROC, P1186, DOI 10.1109/ICIP40778.2020.9191358
   Chen J, 2020, JVET 19 M TEL JUL
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   De-Luxán-Hernández S, 2019, IEEE IMAGE PROC, P1203, DOI [10.1109/ICIP.2019.8803777, 10.1109/icip.2019.8803777]
   Dhapola S., 2017, INDIAN EXPRESS
   Fan YB, 2020, IEEE T CIRC SYST VID, V30, P3289, DOI 10.1109/TCSVT.2019.2934752
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Fu T, 2019, IEEE INT CON MULTI, P61, DOI 10.1109/ICME.2019.00019
   García-Lucas D, 2020, MULTIMED TOOLS APPL, V79, P29621, DOI 10.1007/s11042-020-09453-w
   Huang YW, 2020, IEEE T CIRC SYST VID, V30, P1311, DOI 10.1109/TCSVT.2019.2945048
   ITU-T and ISO/IEC, 2020, 230903 ITUT ISOIEC
   Kammoun A, 2020, IEEE T CIRC SYST VID, V30, P4340, DOI 10.1109/TCSVT.2019.2954749
   Koo M, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954507
   Lu TR, 2020, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC47342.2020.00027
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   Pakdaman F, 2020, IEEE IMAGE PROC, P3134, DOI 10.1109/ICIP40778.2020.9190983
   Panayides AS, 2020, IEEE ACCESS, V8, P11469, DOI 10.1109/ACCESS.2020.2965325
   Rivaz P., 2018, AV1 BITSTREAM DECODI
   Saldanha M, 2020, IEEE IMAGE PROC, P3119, DOI [10.1109/ICIP40778.2020.9190970, 10.1109/icip40778.2020.9190970]
   Samuelsson J, 2020, SMPTE MOTION IMAG J, V129, P100, DOI [10.5594/JMI.2020.3002305, DOI 10.5594/JMI.2020.3002305]
   Schäfer M, 2019, IEEE IMAGE PROC, P1089, DOI [10.1109/ICIP.2019.8803724, 10.1109/icip.2019.8803724]
   Schwarz H, 2019, IEEE IMAGE PROC, P1183, DOI [10.1109/icip.2019.8803768, 10.1109/ICIP.2019.8803768]
   SIDATY N, 2019, COMPR PERF VERS VID
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tissier A, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901754
   Topiwala P, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322024
   Wieckowski A, 2019, IEEE IMAGE PROC, P4130, DOI [10.1109/icip.2019.8803533, 10.1109/ICIP.2019.8803533]
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Zhang K, 2019, IEEE T IMAGE PROCESS, V28, P1456, DOI 10.1109/TIP.2018.2877355
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P3983, DOI 10.1109/TIP.2018.2830640
   Zhang QW, 2020, IEEE ACCESS, V8, P117539, DOI 10.1109/ACCESS.2020.3004580
   Zhao L, 2019, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2019.00013
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhao X, 2016, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC.2016.9
NR 40
TC 10
Z9 10
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103202
DI 10.1016/j.jvcir.2021.103202
EA JUL 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100001
OA Green Published
DA 2024-07-18
ER

PT J
AU Lee, JH
   Kim, KR
   Kim, CS
AF Lee, Jae-Han
   Kim, Kyung-Rae
   Kim, Chang -Su
TI Subpixel rendering for diamond-shaped PenTile displays using patch-based
   adaptive filters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Subpixel rendering; Diamond-shaped PenTile displays; Color distortion
   reduction
ID ERROR
AB We propose a novel subpixel rendering algorithm for diamond-shaped PenTile displays, which reduces color distortions while improving apparent resolutions. We develop two types of subpixel rendering filters: main filter and color distortion reduction (CDR) filters. To derive the filters, we formulate a quadratic program to minimize the difference between an original input image and a virtual image that the human visual system perceives. By imposing two constraints for filter size and coefficients, we obtain the main filter, which has a suitable size and is normalized. Then, we design the CDR filters based on the analysis of various patch patterns for image areas. We define the patch patterns to classify local areas with possible color distortions. By imposing additional constraints according to the patch patterns, we derive the CDR filters. Lastly, by matching local areas in the input image into the pre-defined patch patterns, we render the image using the main filter and the CDR filters, which are applied adaptively to the local areas. Experimental results demonstrate that the proposed subpixel rendering algorithm improves apparent resolutions and suppresses color distortions effectively, thereby outperforming conventional algorithms.
C1 [Lee, Jae-Han; Kim, Kyung-Rae; Kim, Chang -Su] Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
C3 Korea University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
EM jaehanlee@mcl.korea.ac.kr; krkim@mcl.korea.ac.kr; changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2018R1A2B3003896]; MSIT, Korea, under the ITRC support program
   [IITP2021-20160-00464]
FX This work was supported partly by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2018R1A2B3003896) and partly by the MSIT, Korea, under the ITRC
   support program (IITP2021-20160-00464) supervised by the IITP.
CR Chae SH, 2017, IEEE T CONSUM ELECTR, V63, P401, DOI 10.1109/TCE.2017.015103
   Engelhardt T, 2014, COMPUT GRAPH FORUM, V33, P199, DOI 10.1111/cgf.12267
   Fang L., 2012, P ICIP
   Fang L., 2009, P ISCAS
   Fang L, 2013, IEEE T IMAGE PROCESS, V22, P3818, DOI 10.1109/TIP.2013.2262288
   Fang L, 2013, IEEE SIGNAL PROC MAG, V30, P177, DOI 10.1109/MSP.2013.2241311
   Fang L, 2012, IEEE T CIRC SYST VID, V22, P740, DOI 10.1109/TCSVT.2011.2179458
   Fang L, 2012, IEEE T IMAGE PROCESS, V21, P1391, DOI 10.1109/TIP.2011.2165550
   Fang L, 2011, IEEE J-STSP, V5, P240, DOI 10.1109/JSTSP.2010.2053346
   Farrell J, 2011, J SOC INF DISPLAY, V19, P513, DOI 10.1889/JSID19.8.513
   Gibson S., 2010, SUBPIXEL FONT RENDER
   Jung SW, 2013, IEEE T CIRC SYST VID, V23, P269, DOI 10.1109/TCSVT.2012.2203734
   Kang SJ, 2014, J DISP TECHNOL, V10, P251, DOI 10.1109/JDT.2014.2304716
   Kang SJ, 2014, IEEE T CIRC SYST VID, V24, P224, DOI 10.1109/TCSVT.2013.2273655
   Kang SJ, 2013, J DISP TECHNOL, V9, P632, DOI 10.1109/JDT.2013.2251996
   Kim J.S., 2007, P 15 EUSIPCO
   Lee J.H., 2017, P ISCAS
   Lee S.-S., 2017, US Patent, Patent No. [9818803B2, 9818803]
   Messing DS, 2002, IEEE IMAGE PROC, P625
   Pang JH, 2016, IEEE T IMAGE PROCESS, V25, P1017, DOI 10.1109/TIP.2015.2512381
   Pollack J, 2006, IEEE SPECTRUM, V43, P40, DOI 10.1109/MSPEC.2006.1665051
   Reinhard E., 2008, Color Imaging: Fundamentals and Applications
   Tang K., 2013, P MMSP
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wong E.L.S., 2011, Active-set methods for quadratic programming
   Yang HY, 2016, J DISP TECHNOL, V12, P158, DOI 10.1109/JDT.2015.2473699
   Zeng J., 2014, P ICASSP
   Zeng J, 2016, IEEE T IMAGE PROCESS, V25, P5841, DOI 10.1109/TIP.2016.2615429
NR 29
TC 1
Z9 1
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103144
DI 10.1016/j.jvcir.2021.103144
EA MAY 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH3KV
UT WOS:000671992600001
DA 2024-07-18
ER

PT J
AU Agrawal, SC
   Jalal, AS
AF Agrawal, Subhash Chand
   Jalal, Anand Singh
TI A joint cumulative distribution function and gradient fusion based
   method for dehazing of long shot hazy images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Joint cumulative distribution; Nearby haze; Faraway
   haze; Image fusion; Gradient domain
ID HISTOGRAM EQUALIZATION; VISIBILITY RESTORATION; CONTRAST ENHANCEMENT;
   WEATHER; VISION
AB Hazy or foggy weather conditions significantly degrade the visual quality of an image in an outdoor environment. It also changes the color and reduces the contrast of an image. This paper introduces a novel single image dehazing technique to restore a hazy image without considering the physical model of haze formation. In order to find haze-free image, the proposed method does not require the transmission map and its costly refinement process. Since haze effect is dependent on the depth, it severely degrades the visibility of the objects located at a far distance. The objects close to the camera are unaffected. In this paper, we propose a fusion-based haze removal method based on the joint cumulative distribution function (JCDF) that treats faraway haze and nearby haze separately. The output images after the JCDF module, fused in the gradient domain to produce a haze-free image. The proposed method not only significantly enhances visibility but also preserves texture details. The proposed method is experimented and evaluated on a large set of challenging hazy images (large scene depth, night time, dense fog, etc.). Both qualitative and quantitative measures show that the performance of the proposed method is better than the state-of-the-art dehazing techniques.
C1 [Agrawal, Subhash Chand; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
EM subhash.agrawal@gla.ac.in; asjalal@gla.ac.in
OI Jalal, Anand/0000-0002-7469-6608
CR Ancuti C. O, IEEE SIGNAL PROC LET, V26, P201
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 1978, IEEE J QUANTUM ELECT, DOI DOI 10.1109/JQE.1978.1069864
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen BH, 2018, IEEE T NEUR NET LEAR, V29, P3828, DOI 10.1109/TNNLS.2017.2741975
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Choi S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2495261
   Cooper TJ, 2004, J ELECTRON IMAGING, V13, P85, DOI 10.1117/1.1636182
   Dippel S, 2002, IEEE T MED IMAGING, V21, P343, DOI 10.1109/TMI.2002.1000258
   Dudhane A, 2020, IEEE T IMAGE PROCESS, V29, P628, DOI 10.1109/TIP.2019.2934360
   Fan X, 2017, IEEE T CIRC SYST VID, V27, P2505, DOI 10.1109/TCSVT.2016.2592328
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Galdran A, 2015, SIAM J IMAGING SCI, V8, P1519, DOI 10.1137/15M1008889
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu X., 2014, Sensors Transducers, V175, P138
   Ju MY, 2018, IEEE SIGNAL PROC LET, V25, P1084, DOI 10.1109/LSP.2018.2839580
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Liu CX, 2016, VISUAL COMPUT, V32, P911, DOI 10.1007/s00371-016-1259-3
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Naidu VPS, 2010, DEFENCE SCI J, V60, P48, DOI 10.14429/dsj.60.105
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Qian W, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4945214
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Sevcenco I.S, 2013, MULTIDIMENSION SYST
   Shen L, 2019, IEEE T MULTIMEDIA, V21
   Singh Dayanita, 2017, Museum Bhavan, V1st, P1
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Treibitz T, 2009, PROC CVPR IEEE, P525, DOI 10.1109/CVPRW.2009.5206551
   Verma M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P426, DOI 10.1145/2791405.2791513
   Wang W, 2017, IEEE CAA J AUTOMATIC IEEE CAA J AUTOMATIC, V4
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xu HT, 2014, IEEE T MULTIMEDIA, V16, P68, DOI 10.1109/TMM.2013.2283453
   Yuan F, 2018, IEEE T IMAGE PROCESS, V27, P4395, DOI 10.1109/TIP.2018.2837900
   Zhang LB, 2018, IET IMAGE PROCESS, V12, P1049, DOI 10.1049/iet-ipr.2017.0959
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 56
TC 5
Z9 5
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103087
DI 10.1016/j.jvcir.2021.103087
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700001
DA 2024-07-18
ER

PT J
AU Li, X
   Fang, M
   Liu, JC
AF Li, Xiao
   Fang, Min
   Liu, Jichuan
TI Low-rank embedded orthogonal subspace learning for zero-shot
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero shot classification; Low-rank; Class similarity; Manifold structure
AB Zero-shot classification methods have attracted considerable attention in recent years. Existing ZSC methods encounter domain shift, hubness and visual-semantic gap problems. To address these problems, we propose a low-rank embedded orthogonal subspace learning method (LEOSL) for ZSC. Many previous works project visual features to the semantic space. However, they often suffer from the visual-semantic gap problem. To handle this problem, we project the visual representations and semantic representations to the common subspace. To address the domain shift problem, we restrict the mapping functions with a low-rank constraint. To handle the hubness problem, we introduce the class similarity term so that samples of the same class are located near each other, while samples of different classes are located far away. Furthermore, we restrict the shared representations in the subspace with an orthogonal constraint to remove the correlation between samples. The results show the superiority of LEOSL compared to many state-of-the-art methods.
C1 [Li, Xiao; Fang, Min] Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
   [Liu, Jichuan] China Elect Technol Grp Corp, Res Inst 54, Shijiazhuang, Hebei, Peoples R China.
C3 Xidian University; China Electronics Technology Group
RP Fang, M (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
EM mfang@mail.xidian.edu.cn
RI liu, jichuan/IWM-3932-2023
FU National Natural Science Foundation of China [61806155]; China
   Postdoctoral Science Foundation [2018M631125]; Fundamental Research
   Funds for the Central Universities, China [XJS200303]; National Natural
   Science Foundation of shaanxi province, China [2020JQ-323, 2020GY-062];
   Nature Science Foundation of Anhui Province, China [1908085MF186]
FX This work is supported by National Natural Science Foundation of China
   under Grant no. 61806155, China Postdoctoral Science Foundation funded
   project under Grant no. 2018M631125, Fundamental Research Funds for the
   Central Universities, China under Grant no. XJS200303, National Natural
   Science Foundation of shaanxi province, China (Grant No. 2020JQ-323,
   2020GY-062), Nature Science Foundation of Anhui Province, China under
   Grant no. 1908085MF186.
CR Akata Z., 2013, NIPS 2013 WORKSH OUT
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   [Anonymous], 2017, IJCAI
   Bucher M, 2017, IEEE INT CONF COMP V, P2666, DOI 10.1109/ICCVW.2017.308
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Cheng Y., 2017, IEEE T NEURAL NETW L
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6
   Dinu Georgiana, 2015, P ICLR
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2
   Ferrari V., 2008, Proc. of NIPS'08, P433
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128
   Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Jiang B, 2017, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2017.66
   Jiang HJ, 2019, IEEE I CONF COMP VIS, P9764, DOI 10.1109/ICCV.2019.00986
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Li X, 2018, KNOWL-BASED SYST, V160, P176, DOI 10.1016/j.knosys.2018.06.034
   Li X, 2015, IEEE I CONF COMP VIS, P4211, DOI 10.1109/ICCV.2015.479
   Meng M, 2019, IEEE T IMAGE PROCESS, V28, P1824, DOI 10.1109/TIP.2018.2881926
   Meng M, 2018, IEEE SIGNAL PROC LET, V25, P1379, DOI 10.1109/LSP.2018.2857201
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mishra A, 2018, IEEE COMPUT SOC CONF, P2269, DOI 10.1109/CVPRW.2018.00294
   Morgado P, 2017, PROC CVPR IEEE, P2037, DOI 10.1109/CVPR.2017.220
   Norouzi M., 2014, P INT C LEARN REPR
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Paul A., IEEE C COMP VIS PATT
   Rahman S, 2018, IEEE T IMAGE PROCESS, V27, P5652, DOI 10.1109/TIP.2018.2861573
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang D, 2016, AAAI CONF ARTIF INTE, P2137
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xu X, 2017, PROC CVPR IEEE, P2007, DOI 10.1109/CVPR.2017.217
   Ye M, 2019, PROC CVPR IEEE, P11720, DOI 10.1109/CVPR.2019.01200
   Ye SQ, 2017, IEEE INT WORKS MACH, DOI 10.1109/TPAMI.2017.2762295
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111
NR 58
TC 2
Z9 2
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102981
DI 10.1016/j.jvcir.2020.102981
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OM
UT WOS:000613151000003
DA 2024-07-18
ER

PT J
AU Geng, YB
   Lian, YJ
   Zhou, ML
   Kong, YX
   Zhu, YN
AF Geng, Yanbing
   Lian, Yongjian
   Zhou, Mingliang
   Kong, Yixue
   Zhu, Yinong
TI Exploiting multigranular salient features with hierarchical multi-mode
   attention network for pedestrian re-IDentification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pedestrian re-identification; Hierarchical; Multi-mode attention
   network; Hierarchical adaptive fusion; Fused attention
AB In this paper, we propose an end-to-end hierarchical-based multi-mode attention network and adaptive fusion (HMAN-HAF) strategy to learn different-level salient features for re-ID tasks. First, according to each layer's characteristics, a hierarchical multi-mode attention network (HMAN) is designed to adopt different attention models for different-level salient feature learning. Specifically, refined channel-wise attention (CA) is adopted to capture high-level valuable semantic information, an attentive region model (AR) is used to detect salient regions in the low layer, and fused attention (FA) is designed to capture the salient regions of valuable channels in the middle layer. Second, a hierarchical adaptive fusion (HAF) is constructed to fulfill the complementary strengths of different-level salient features. Experimental results demonstrate that the proposed method outperforms the state-of-the-art methods on the following challenging benchmarks: Market-1501, DukeMTMC-reID and CUHK03.
C1 [Geng, Yanbing; Lian, Yongjian] North Univ China, Sch Data Sci & Technol, Taiyuan 030051, Shanxi, Peoples R China.
   [Zhou, Mingliang; Kong, Yixue; Zhu, Yinong] Chongqing Univ, Sch Comp Sci, 174 Shazheng St, Chongqing 400044, Peoples R China.
   [Zhou, Mingliang] Univ Macau, State Key Lab Internet Things Smart City, Taipa 999078, Macao, Peoples R China.
C3 North University of China; Chongqing University; University of Macau
RP Zhou, ML (corresponding author), Chongqing Univ, Sch Comp Sci, 174 Shazheng St, Chongqing 400044, Peoples R China.
EM gyb@nuc.edu.cn; lyj@nuc.edu.cn; zml-0913yy@163.com
RI ZHOU, MING/JVP-2920-2024; Zhou, Mingliang/HPC-0298-2023
OI Geng, Yanbing/0009-0004-6971-3276
FU General Program of National Natural Science Foundation of Chongqing
   [cstc2020jcyjmsxmX0790]; Fundamental Research Funds for the Central
   Universities [2020CDJ-LHZZ-052]; Guangxi Key Laboratory of Cryptography
   and Information Security [GCIS201906]; National Natural Science Fund of
   Shanxi Province [201901D111154]
FX This work was supported in part by the General Program of National
   Natural Science Foundation of Chongqing under Grant
   cstc2020jcyjmsxmX0790, in part by the Fundamental Research Funds for the
   Central Universities under Grant 2020CDJ-LHZZ-052, in part by the
   Guangxi Key Laboratory of Cryptography and Information Security under
   Grant GCIS201906, and in part by the National Natural Science Fund of
   Shanxi Province under grant number 201901D111154.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Bai S, 2017, PROC CVPR IEEE, P3356, DOI 10.1109/CVPR.2017.358
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Borrelli Francesco, 2017, ARXIV PREPRINT ARXIV
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Cheng D, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P964
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiang X, 2019, ARXIV PREPRINT ARXIV
   Jiao SS, 2019, IEEE ACCESS, V7, P90497, DOI 10.1109/ACCESS.2019.2927170
   Lan X., 2017, BRIT MACH VIS C BMVC
   Leibe B., 2017, ARXIV170307737CS
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, IEEE INT CONF AUTOMA, P103, DOI 10.1109/FG.2017.136
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin WY, 2017, IEEE T IMAGE PROCESS, V26, P2438, DOI 10.1109/TIP.2017.2683063
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Shen C, 2016, ARXIV PREPRINT ARXIV
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Si JL, 2018, IEEE T SYST MAN CY-S, V48, P1140, DOI 10.1109/TSMC.2016.2645660
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tolias G, 2015, ARXIV PREPRINT ARXIV
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Xiang T., 2016, ARXIV PREPRINT ARXIV
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang JL, 2017, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2017.554
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang LQ, 2017, INT CON DISTR COMP S, P129, DOI 10.1109/ICDCS.2017.95
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou SP, 2017, PROC CVPR IEEE, P5028, DOI 10.1109/CVPR.2017.534
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zou J., 2019, IEEE T CYBERN
NR 61
TC 3
Z9 3
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102914
DI 10.1016/j.jvcir.2020.102914
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200004
DA 2024-07-18
ER

PT J
AU Amaranageswarao, G
   Deivalakshmi, S
   Ko, SB
AF Amaranageswarao, Gadipudi
   Deivalakshmi, S.
   Ko, Seok-Bum
TI Wavelet based medical image super resolution using cross connected
   residual-in-dense grouped convolutional neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Grouped convolution; Low-dose X-ray CT; Residual-in-dense; Super
   resolution; Wavelet sub-bands
AB In clinical analysis and diagnosis, high resolution (HR) computed tomography (CT) images are required for proper treatment of a patient. Developing HR medical images by X-ray CT devices require extended radiation exposure with large radiative dosages, putting the patient at potential risk of inducing cancer. So, radiation exposure should be reduced. However, photon starvation and beam hardening in low-dose X-rays will cause severe artifacts. Thus, an accurate reconstruction of low-dose X-ray CT images is required. To this end, we propose a wavelet based multi-channel and multi-scale cross connected residual-in-dense grouped convolutional neural network (WCRDGCNN) for accurate super resolution (SR) of medical images. The adopted filter groups reduce the connection weights, thereby reducing the computational complexity. Gradient vanishing problem is tackled by using residual and dense skip connections. The extensive experimentation results on benchmark datasets show that our method outperforms the state-of-the-art SR methods. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Amaranageswarao, Gadipudi; Deivalakshmi, S.] Natl Inst Technol, Dept Elect & Commun Engn, Thiruchirappalli, India.
   [Ko, Seok-Bum] Univ Saskatchewan, Saskatoon, SK, Canada.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; University of Saskatchewan
RP Amaranageswarao, G (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Thiruchirappalli, India.
EM amar.nag9@gmail.com
RI Ko, Seokbum/H-8366-2012; Deivalakshmi, S/AAM-9082-2021; Amaranageswarao,
   Gadipudi/AAM-8173-2021
OI Ko, Seokbum/0000-0002-9287-317X; Amaranageswarao,
   Gadipudi/0000-0002-8022-1481; Deivalakshmi, S/0000-0002-7019-9807
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Brenner DJ, 2007, NEW ENGL J MED, V357, P2277, DOI 10.1056/NEJMra072149
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Choi JS, 2017, IEEE COMPUT SOC CONF, P1150, DOI 10.1109/CVPRW.2017.153
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Gu PJ, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1400, DOI [10.1109/itaic.2019.8785482, 10.1109/ITAIC.2019.8785482]
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Jiang CH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27261-z
   Jing Y, 2020, AAAI CONF ARTIF INTE, V34, P11189
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2017, PATTERN RECOGN LETT, V90, P65, DOI 10.1016/j.patrec.2017.03.014
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Li M, 2018, LECT NOTES COMPUT SC, V11045, P291, DOI 10.1007/978-3-030-00889-5_33
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P263
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Salvador J, 2015, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2015.45
   Shaban M., 2019, ASS ADV ARTIFICIAL I
   Sun L, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P2331, DOI 10.1109/icma.2019.8816427
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Yang G, 2016, LECT NOTES COMPUT SC, V9680, P179, DOI 10.1007/978-3-319-33618-3_19
   Yang J, 2019, J VIS COMMUN IMAGE R, V61, P188, DOI 10.1016/j.jvcir.2019.04.002
   You CY, 2020, IEEE T MED IMAGING, V39, P188, DOI 10.1109/TMI.2019.2922960
   Yu HC, 2017, IEEE IMAGE PROC, P3944, DOI 10.1109/ICIP.2017.8297022
   Yu J., 2018, WIDE ACTIVATION EFFI
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang SX, 2019, IEEE ACCESS, V7, P12319, DOI 10.1109/ACCESS.2018.2871626
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu J, 2019, I S BIOMED IMAGING, P1669, DOI [10.1109/ISBI.2019.8759517, 10.17863/cam.40373]
NR 45
TC 11
Z9 12
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102819
DI 10.1016/j.jvcir.2020.102819
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900023
DA 2024-07-18
ER

PT J
AU Shi, Y
   Zhang, ZJ
   Huang, KN
   Ma, WD
   Tu, SS
AF Shi, Yan
   Zhang, Zijun
   Huang, Kaining
   Ma, Wudi
   Tu, Shanshan
TI Human-computer interaction based on face feature localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human interaction; Face point detection; Expression recognition; Sight
   tracking
AB Human-computer interaction is the way in which humans and machines communicate information. With the rapid development of deep learning technology, the technology of human-computer interaction has also made a corresponding breakthrough. In the past, the way human-computer interaction was mostly relied on hardware devices. Through the coordinated work of multiple sensors, people and machines can realize information interaction. However, as theoretical technology continues to mature, algorithms for human-computer interaction are also being enriched. The popularity of convolutional neural networks has made image processing problems easier to solve. Therefore, real-time human-computer interaction can be performed by using image processing, and intelligent of human-computer interaction can be realized. The main idea of this paper is to use the real-time capture of face images and video information to image the face image information. We perform feature point positioning based on the feature points of the face image. We perform expression recognition based on the feature points that are located. At the same time, we perform ray tracing for the identified human eye area. The feature points of the face and the corresponding expressions and implementation movements represent the user's use appeal. Therefore, we can analyze the user's use appeal by locating the face feature area. We define the corresponding action information for specific user face features. We extract the user's corresponding information according to the user's face features, and perform human-computer interaction according to the user's information. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Shi, Yan; Zhang, Zijun; Huang, Kaining; Ma, Wudi] BengBu Univ, Bengbu City 233000, Anhui, Peoples R China.
   [Tu, Shanshan] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Bengbu University; Beijing University of Technology
RP Zhang, ZJ (corresponding author), BengBu Univ, Bengbu City 233000, Anhui, Peoples R China.
EM bbxyzzj@163.com
FU National Natural Science Foundation of China [61801008]; National Key
   R&D Program of China [2018YFB0803600]; Scientific Research Common
   Program of Beijing Municipal Commission of Education [KM201910005025];
   Beijing National Natural Science Foundation [L172049]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61801008), National Key R&D Program of China (No.
   2018YFB0803600), Scientific Research Common Program of Beijing Municipal
   Commission of Education (No. KM201910005025) and Beijing National
   Natural Science Foundation (No. L172049).
CR [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2012, 2012 IEEE C COMP VIS
   [Anonymous], 2017, CVPR
   [Anonymous], BMVC
   [Anonymous], 2016, LIB FACE DETECTION
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Belhumeur P.N., 2011, 24 IEEE C COMP VIS P
   Dhall A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2106, DOI 10.1109/ICCVW.2011.6130508
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Han BA, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9649643
   Huang ZS, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9050683
   Jesorsky O., 2001, P AVB PA
   Kuo C.-M., 2018, P IEEE C COMP VIS PA, P2121
   Liu AM, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814018773852
   Lv P., 2018, IEEE T COMPUTATIONAL, V6, P377
   Qi C.R., 2016, 61200593 ARXIV
   Song M., 2010, IEEE T SYST MAN CY B, V40
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tsai SB, 2015, P I MECH ENG B-J ENG, V229, P1395, DOI 10.1177/0954405414535923
   Wang JJ, 2010, NEURAL NETWORKS, V23, P618, DOI 10.1016/j.neunet.2010.01.004
   Wang QJ, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419590158
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2016, NEUROCOMPUTING, V195, P117, DOI 10.1016/j.neucom.2015.08.117
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhang YW, 2012, 2012 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P128, DOI 10.1109/APCCAS.2012.6418988
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
   Zhou XP, 2018, IEEE T KNOWL DATA EN, V30, P1178, DOI 10.1109/TKDE.2017.2784430
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
NR 34
TC 19
Z9 19
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102740
DI 10.1016/j.jvcir.2019.102740
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900004
DA 2024-07-18
ER

PT J
AU Xie, SR
   Liu, C
   Gao, JT
   Li, XM
   Luo, J
   Fan, BJ
   Chen, JH
   Pu, HY
   Peng, Y
AF Xie, Shaorong
   Liu, Chang
   Gao, Jiantao
   Li, Xiaomao
   Luo, Jun
   Fan, Baojie
   Chen, Jiahong
   Pu, Huayan
   Peng, Yan
TI Diverse receptive field network with context aggregation for fast object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Convolutional neural network; Context aggregation;
   Multi-scale contextual representations
AB Current context-utilizing detectors are all based on two-stage approaches. However, their computational efficiency and context quality extremely depend on the accuracy of proposal-generating methods, which limits their performance and makes them hardly perform real-time detection. In this work, we present a context-exploited method that integrates features in different receptive fields to obtain contextual representation. Based on this idea, we put forward the multi-branch diverse receptive field modules (DRF modules) and their design principles to encode context. To further utilize contextual information for fast object detection, we propose a one-stage diverse receptive field network (DRFNet). In DRFNet, the DRF modules are first applied to capture rich context as the basis, then a parallel structure is constructed to exploit the context at different scales along with DRF modules. Comprehensive experiments indicate that the context introduced by our methods improves the detection performance and DRFNet achieves a good trade-off between speed and accuracy. (C) 2020 Published by Elsevier Inc.
C1 [Xie, Shaorong; Liu, Chang; Gao, Jiantao; Li, Xiaomao; Luo, Jun; Chen, Jiahong; Pu, Huayan; Peng, Yan] Shanghai Univ, 99 Shangda Rd, Shanghai 200000, Peoples R China.
   [Fan, Baojie] Nanjing Univ Posts & Telecommun, 9 Wenyuan Rd, Nanjing 210000, Peoples R China.
C3 Shanghai University; Nanjing University of Posts & Telecommunications
RP Peng, Y (corresponding author), Shanghai Univ, 99 Shangda Rd, Shanghai 200000, Peoples R China.
EM pengyan@shu.edu.cn
RI chen, jia/JDW-7660-2023; Wang, Yiping/IZQ-2052-2023; Chen,
   Jia/HQZ-3908-2023; chen, jia/JLM-4733-2023; cheng, shu/IZE-4788-2023;
   Li, Zilong/JEZ-8642-2023; Wang, Xuezhen/IUN-6267-2023; wang,
   yue/ISA-4119-2023; chen, jiahong/GYR-2917-2022; liang, YU/IYT-4334-2023
OI liang, YU/0009-0007-3922-3454; Liu, Chang/0000-0001-5012-7921
FU National Natural Science Foundation of China [61625304, 91648119,
   61673254]
FX This work was supported by the National Natural Science Foundation of
   China [Grant Nos. 61625304, 91648119, and 61673254].
CR Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Chu WQ, 2018, NEUROCOMPUTING, V275, P1035, DOI 10.1016/j.neucom.2017.09.048
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Nguyen KD, 2019, J VIS COMMUN IMAGE R, V60, P206, DOI 10.1016/j.jvcir.2019.02.020
   Kingma D. P., 2014, arXiv
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278091
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642
   Parikh D, 2012, IEEE T PATTERN ANAL, V34, P1978, DOI 10.1109/TPAMI.2011.276
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren YZ, 2018, J VIS COMMUN IMAGE R, V55, P131, DOI 10.1016/j.jvcir.2018.05.019
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zeng XY, 2018, IEEE T PATTERN ANAL, V40, P2109, DOI 10.1109/TPAMI.2017.2745563
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu J, 2015, J VIS COMMUN IMAGE R, V27, P44, DOI 10.1016/j.jvcir.2015.01.003
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 54
TC 4
Z9 4
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102770
DI 10.1016/j.jvcir.2020.102770
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900007
DA 2024-07-18
ER

PT J
AU Dong, JQ
   Xia, ZY
   Yan, WW
   Zhao, QF
AF Dong, Jiaqi
   Xia, Zeyang
   Yan, Weiwu
   Zhao, Qunfei
TI Dynamic gesture recognition by directional pulse coupled neural networks
   for human-robot interaction in real time
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human-robot interaction; Dynamic gesture recognition; Graph theory
   problem; Directional pulse coupled neuron network (DPCNN); Early
   recognition
AB Dynamic gesture recognition is a major topic for most real-time human-robot interaction applications. Recently, increasingly people have focused on dynamic gesture recognition based on 3D representation. In this paper, the gesture recognition is converted into the shortest path problem by transforming the feature matrix to an undirected graph and a novel dynamic gesture recognition algorithm of directional pulse coupled neuron network (DPCNN) is proposed for real time human-robot interactions. The DPCNN can select the firing direction by giving different excitations to neighbor neurons and reduce the effects of useless neurons. Furthermore, to reduce the recognition time, an early gesture recognition method based on the adaptive window is introduced to recognize the unfinished gestures. DPCNN reduces the computation time and achieves a high recognition rate on three public datasets compared with other algorithms which improves the efficiency of real-time dynamic gesture recognition and ensures a friendly experience for human-robot interactions. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Dong, Jiaqi; Yan, Weiwu; Zhao, Qunfei] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Xia, Zeyang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS
RP Yan, WW (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM yanwwsjtu@sjtu.edu.cn
OI w, yufan/0000-0003-2609-4706
FU Major Research Plan of the National Natural Science Foundation of China
   [91646205]
FX This work was supported by the Major Research Plan of the National
   Natural Science Foundation of China (No. 91646205).
CR Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   [Anonymous], 2009, UNIVERSAL ACCESS HDB
   [Anonymous], P IEEE C COMP VIS PA
   Bannach D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P32, DOI 10.1109/CIG.2007.368076
   Barros P, 2014, IEEE-RAS INT C HUMAN, P646, DOI 10.1109/HUMANOIDS.2014.7041431
   Boian R, 2002, STUD HEALTH TECHNOL, V85, P64
   Chen Y, 2011, IEEE T NEURAL NETWOR, V22, P880, DOI 10.1109/TNN.2011.2128880
   Deng Zhang, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P2627, DOI 10.1109/ICSMC.2010.5641902
   Doliotis P., 2011, Proceedings of the 4th International Conference on PErvasive Technologies Related to Assistive Environments-PETRA '11, P1
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Huang W, 2017, NEURAL NETWORKS, V90, P21, DOI 10.1016/j.neunet.2017.03.002
   Kang K., 2014, COMPUT SYST APPL, V7
   Kim Kye Kyung, 2006, ADV COMM TECHN 2006, V3, p[4, 1827]
   Kong S, 2012, LECT NOTES COMPUT SC, V7572, P186, DOI 10.1007/978-3-642-33718-5_14
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li Z, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON ROBOTIC AND SENSORS ENVIRONMENTS (ROSE 2009), P41, DOI 10.1109/ROSE.2009.5355984
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu GS, 2015, NEUROCOMPUTING, V149, P1162, DOI 10.1016/j.neucom.2014.09.012
   Liu Jiang-hua, 2002, Robot, V24, P197
   Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3177, DOI 10.1109/CVPR.2011.5995631
   Mao X, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.033023
   Mori A, 2006, INT C PATT RECOG, P560
   Nishikawa A, 2003, IEEE T ROBOTIC AUTOM, V19, P825, DOI 10.1109/TRA.2003.817093
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Premaratne P, 2017, NEUROCOMPUTING, V228, P79, DOI 10.1016/j.neucom.2016.06.075
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Saha S, 2017, IEEE IJCNN, P2776, DOI 10.1109/IJCNN.2017.7966198
   Soutschek Stefan, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563162
   Starner T., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P256, DOI 10.1145/325737.325864
   Tang M., 2011, Recognizing hand gestures with microsofts kinect
   Tongjuan Zhao, 2017, International Journal of Simulation and Process Modelling, V12, P356
   Tusor B., 2010, INSTR MEAS TECHN C I, P815
   Várkonyi-Kóczy AR, 2011, IEEE T INSTRUM MEAS, V60, P1505, DOI 10.1109/TIM.2011.2108075
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang QQ, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P654, DOI 10.1109/ROBIO.2014.7090405
   [王晓华 Wang Xiaohua], 2013, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V27, P305
   Wu HY, 2017, VISUAL COMPUT, V33, P1265, DOI 10.1007/s00371-015-1147-2
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Zhao YQ, 2014, BIO-MED MATER ENG, V24, P221, DOI 10.3233/BME-130802
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
NR 46
TC 15
Z9 15
U1 2
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102583
DI 10.1016/j.jvcir.2019.102583
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200011
DA 2024-07-18
ER

PT J
AU Zhang, SH
   Li, H
   Kong, WH
   Wang, L
   Niu, XF
AF Zhang, Shihui
   Li, He
   Kong, Weihang
   Wang, Lei
   Niu, Xiaofang
TI An object counting network based on hierarchical context and feature
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object counting; Density estimation; Feature fusion; Hierarchical
   context
AB Object counting is a challenging task in computer vision. In this paper, we propose an object counting network based on hierarchical context and feature fusion called HFNet. HFNet comprises a hierarchical context extraction module and an end-to-end convolution neural network. The hierarchical context extraction module extracts hierarchical features to the main network as context cues, aiming to provide more information to improve counting performance. The main network adds the relatively lower but naturally high-resolution feature maps into higher but semantic feature maps, whose benefits are: one is to reduce the risk of losing detailed information during multi-convolutions; the other is to against the scale variations in this task due to the fusion operation of the multi-scale feature maps. Experiments demonstrate HFNet achieves competitive results on crowd counting including UCF_CC_50 dataset and ShanghaiTech dataset and on vehicle counting including TRANCOS dataset. The contrast experiments also verify the structure rationality of HFNet. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Shihui; Li, He; Kong, Weihang; Wang, Lei; Niu, Xiaofang] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zhang, Shihui] Key Lab Comp Virtual Technol & Syst Integrat Hebe, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP Zhang, SH (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM sshhzz@ysu.edu.cn; lihe@stumail.ysu.edu.cn; whkong@ysu.edu.cn
RI Zhang, Shihui/HHS-1779-2022; Zhang, Shihui/KFB-3255-2024
FU National Natural Science Foundation of China [61379065]; Natural Science
   Foundation of Hebei province in China [F2014203119]; China Postdoctoral
   Science Foundation [2018M631763]; Yanshan University Doctoral Foundation
   [BL18010]
FX This work was supported partly by Foundation of China (No. 61379065),
   tion of Hebei province in China (No funded by China Postdoctoral the
   National Natural Science the Natural Science Founda. F2014203119), the
   Project Science Foundation (No. 2018M631763) and Yanshan University
   Doctoral Foundation (BL18010).
CR Al-Zaydi ZQH, 2016, J VIS COMMUN IMAGE R, V39, P218, DOI 10.1016/j.jvcir.2016.05.018
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Choi JS, 2017, LECT NOTES ELECTR EN, V421, P712, DOI 10.1007/978-981-10-3023-9_109
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan CS, 2015, FRONT ARTIF INTEL AP, V274, P1479, DOI 10.3233/978-1-61499-484-8-1479
   Fiaschi L, 2012, INT C PATT RECOG, P2685
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Guerrero-Gómez-Olmedo R, 2015, LECT NOTES COMPUT SC, V9117, P423, DOI 10.1007/978-3-319-19390-8_48
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Sabzmeydani P., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383134
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sheng BY, 2018, IEEE T CIRC SYST VID, V28, P1788, DOI 10.1109/TCSVT.2016.2637379
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Sossa H, 2003, PROCEEDINGS OF THE FOURTH MEXICAN INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE (ENC 2003), P216, DOI 10.1109/ENC.2003.1232897
   Spampinato C, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P514
   Sun MJ, 2017, J VIS COMMUN IMAGE R, V49, P412, DOI 10.1016/j.jvcir.2017.10.002
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 30
TC 10
Z9 10
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 166
EP 173
DI 10.1016/j.jvcir.2019.05.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600015
DA 2024-07-18
ER

PT J
AU Zalluhoglu, C
   Ikizler-Cinbis, N
AF Zalluhoglu, Cemil
   Ikizler-Cinbis, Nazli
TI Region based multi-stream convolutional neural networks for collective
   activity recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Collective activity recognition; Action recognition
AB Collective activity recognition, which analyses the behavior of groups of people in videos, is an important goal of video surveillance systems. In this paper, we focus on collective activity recognition problem and propose a new multi-stream convolutional neural network architecture that utilizes information extracted from multiple regions. The proposed method is the first work that uses a multi-stream network and multiple regions in this problem. Various strategies to fuse multiple spatial and temporal streams are explored. We evaluate the proposed method on two benchmark datasets, the Collective Activity Dataset and the Volleyball Dataset. Our experimental results show that the proposed method improves collective activity recognition performance when compared to the state-of-the-art approaches. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zalluhoglu, Cemil; Ikizler-Cinbis, Nazli] Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
C3 Hacettepe University
RP Zalluhoglu, C (corresponding author), Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
EM cemil@cs.hacettepe.edu.tr; nazli@cs.hacettepe.edu.tr
RI ZALLUHOĞLU, CEMİL/G-6035-2013; Ikizler-Cinbis, Nazli/E-8961-2013
OI ZALLUHOĞLU, CEMİL/0000-0001-8716-6297; 
FU Scientific and Technological Research Council of Turkey (TUBITAK) [1001,
   116E102]
FX This work was supported in part by the Scientific and Technological
   Research Council of Turkey (TUBITAK) Research Program (1001), Project
   No: 116E102.
CR Amer MR, 2013, IEEE I CONF COMP VIS, P1353, DOI 10.1109/ICCV.2013.171
   Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14
   Amer MR, 2014, LECT NOTES COMPUT SC, V8694, P572, DOI 10.1007/978-3-319-10599-4_37
   [Anonymous], 2010, Advances in neural information processing systems
   [Anonymous], ARXIV12120402
   Antic B, 2014, LECT NOTES COMPUT SC, V8689, P33, DOI 10.1007/978-3-319-10590-1_3
   Bagautdinov T, 2017, PROC CVPR IEEE, P3425, DOI 10.1109/CVPR.2017.365
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Choi W, 2014, IEEE T PATTERN ANAL, V36, P1242, DOI 10.1109/TPAMI.2013.220
   Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16
   Deng ZW, 2016, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2016.516
   Dengguo Zhang, 2015, 2015 IEEE MTT-S International Microwave Workshop Series on Advanced Materials and Processes for RF and THz Applications (IMWS-AMP). Proceedings, P1, DOI 10.1109/IMWS-AMP.2015.7324911
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Hajimirsadeghi H, 2015, PROC CVPR IEEE, P2596, DOI 10.1109/CVPR.2015.7298875
   He  D., ARXIV180610319
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Ibrahim M. S., 2016, P IEEE COMP SOC C CO
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy  A., 2014, P IEEE COMP SOC C CO
   Khamis S, 2012, LECT NOTES COMPUT SC, V7572, P116, DOI 10.1007/978-3-642-33718-5_9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228
   Li X, 2017, IEEE I CONF COMP VIS, P2895, DOI 10.1109/ICCV.2017.313
   Lin  W., ARXIV171107430
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Lin WY, 2013, IEEE T CIRC SYST VID, V23, P1980, DOI 10.1109/TCSVT.2013.2269780
   Maron O, 1998, ADV NEUR IN, V10, P570
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Saha  S., ARXIV160801529
   Savarese S, 2009, 2009 IEEE 12 INT C C, P1282
   Shu  T., 2017, P IEEE COMP SOC C CO
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Solera F, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P7, DOI 10.1109/AVSS.2013.6636608
   Tran KN, 2014, PATTERN RECOGN LETT, V44, P49, DOI 10.1016/j.patrec.2013.09.015
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
NR 40
TC 12
Z9 15
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 170
EP 179
DI 10.1016/j.jvcir.2019.02.016
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000020
DA 2024-07-18
ER

PT J
AU Xu, ZP
   Lu, W
   Zhang, Q
   Yeung, YL
   Chen, X
AF Xu, Zhaopeng
   Lu, Wei
   Zhang, Qin
   Yeung, Yuileong
   Chen, Xin
TI Gait recognition based on capsule network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; Capsule network; Deep learning
AB Gait as a biometric feature is widely used for human identification, and gait recognition has recently become a significant research problem. According to a small amount of labeled multi-view, multi walking-condition and multi-clothes-condition human walking videos, we can find an effective model based on capsule network to capture more discriminative features and promote gait recognition performance. This paper works on gait recognition based on capsule network and we consider two different architectures, namely matching local features at the bottom layer based on capsule network and matching mid-level features at the middle layer based on capsule network, input images such as GEI, CGI, and resolution of input image. Empirical evaluations are conducted in the aspect of kinds scenarios, namely cross-walking-condition, cross-view and cross-clothes condition. The approaches are evaluated on the CASIA-B dataset and OU-ISIR Treadmill dataset B. These results show that the methods exceed the previous state-of-the-art outcomes. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xu, Zhaopeng; Lu, Wei; Zhang, Qin; Yeung, Yuileong] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Chen, Xin] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Jinan University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
EM xuzhp8@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   zhangq359@mail2.sysu.edu.cn; yeungyl@mail2.sysu.edu.cn;
   chenxin@stu.jnu.edu.cn
OI zhang, qin/0000-0003-3378-9063; Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; National Key
   R&D Program of China [2017YFB0802500]; Natural Science Foundation of
   Guangdong [2016A030313350]; Special Funds for Science and Technology
   Development of Guangdong [2016KZ010103]; Key Project of Scientific
   Research Plan of Guangzhou [201804020068]; Fundamental Research Funds
   for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the National Key R&D Program of China (No.
   2017YFB0802500), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR [Anonymous], INT C INF EL VIS ICI
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], PROC CVPR IEEE
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2016, IEEE T PATTERN ANAL
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Chen CY, 2015, COMM COM INF SC, V525, P176, DOI 10.1007/978-3-662-47791-5_21
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Johnson AY, 2001, LECT NOTES COMPUT SC, V2091, P301
   Kusakunniran Worapan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2186, DOI 10.1109/ICPR.2010.535
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P85, DOI 10.1109/BTAS.2012.6374561
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Ozen H, 2017, 2017 INTERNATIONAL CONFERENCE ON 3D IMMERSION (IC3D)
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Sabour S., 2017, P C NIPS, P3856
   Simonyan K., 2014, 14091556 ARXIV
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Thapar D., 2018, INT C IDENTITY SECUR, P1
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 39
TC 29
Z9 31
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 159
EP 167
DI 10.1016/j.jvcir.2019.01.023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600016
DA 2024-07-18
ER

PT J
AU Xue, HZ
   Cui, HW
AF Xue, Hongzhi
   Cui, Hongwei
TI Research on image restoration algorithms based on BP neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Image processing; Image denoising; BP neural network
ID OBJECT DETECTION; RECONSTRUCTION; SHAPE; DEEP
AB With the development of information transmission technology and computer technology, information acquisition mode is mainly converted from character to image nowadays. However, in the process of acquiring and transmitting images, image damage and quality decrease due to various factors. Therefore, how to restore image has become a research hotspot in the field of image processing. This paper establishes an image restoration model based on BP neural network. The simulation results show that the proposed method has made a great improvement compared with the traditional image restoration method. (C) 2019 Published by Elsevier Inc.
C1 [Xue, Hongzhi] Changan Univ, Sch Sci, Xian, Shaanxi, Peoples R China.
   [Cui, Hongwei] Shenzhen Polytech, Sch Automobile & Transportat Engn, Shenzhen, Peoples R China.
C3 Chang'an University; Shenzhen Polytechnic University
RP Cui, HW (corresponding author), Shenzhen Polytech, Sch Automobile & Transportat Engn, Shenzhen, Peoples R China.
EM hongzhi@chd.edu.cn; hongweicui@szpt.edu.cn
FU Shenzhen innovative project [6016-21K30040]
FX This work was supported by Shenzhen innovative project (No.
   6016-21K30040).
CR Borghys D, 1998, OPT ENG, V37, P477, DOI 10.1117/1.601633
   Burger H. C, 2012, COMPUTER SCI
   Chao SM, 2006, PATTERN RECOGN LETT, V27, P335, DOI 10.1016/j.patrec.2005.08.021
   CHARALAMBOUS C, 1992, IEEE T MED IMAGING, V11, P2, DOI 10.1109/42.126904
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   CLARK LG, 1991, OPT ENG, V30, P147, DOI 10.1117/12.55784
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   HEASLEY JN, 1984, PUBL ASTRON SOC PAC, V96, P767, DOI 10.1086/131417
   Isa NAM, 2008, CONSTR BUILD MATER, V22, P402, DOI 10.1016/j.conbuildmat.2006.08.005
   Jammal G, 1999, P SOC PHOTO-OPT INS, V3661, P1180, DOI 10.1117/12.348512
   Lee DH, 2011, ADV SPACE RES, V47, P690, DOI 10.1016/j.asr.2010.10.006
   Li Q., 2011, INT S PHOT DET IM SP
   [李青峰 LI Qing-feng], 2009, [计算机仿真, Computer Simulation], V26, P223
   Li X.G., 2012, ADV MAT RES, V461, P4
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Muralidharan S, 2011, PUBLIC RELAT REV, V37, P226, DOI 10.1016/j.pubrev.2011.04.006
   Papa JP, 2010, PATTERN RECOGN LETT, V31, P1876, DOI 10.1016/j.patrec.2010.02.012
   Penczek PA, 2010, METHOD ENZYMOL, V482, P35, DOI 10.1016/S0076-6879(10)82002-6
   Preciozzi J., 2017, IEEE INT GEOSC REM S
   Sahoo S.K., 2015, INT C COMM SIGN PROC
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Sun Y, 2000, IEEE T SIGNAL PROCES, V48, P2119
   Wang Ji, 2010, Optics and Precision Engineering, V18, P2116, DOI 10.3788/OPE.20101809.2116
   Wu X.F., 2014, ADV MAT RES, V955-959, P1085
   Xue H.Y., 2011, KEY ENG MATER, P460
   Yuguang Y., 2010, MICROCOMPUTER APPL, V7, P1223
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   [张建锋 ZHANG Jian-Feng], 2011, [四川大学学报. 自然科学版, Journal of Sichuan University. Natural Science Edition], V48, P833
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhou NQ, 2017, IEEE INT C COMPUT, P7, DOI 10.1109/CSE-EUC.2017.13
NR 39
TC 23
Z9 23
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 204
EP 209
DI 10.1016/j.jvcir.2019.01.014
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600021
DA 2024-07-18
ER

PT J
AU Zhang, HB
AF Zhang, Haibo
TI The literature review of action recognition in traffic context
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Traffic; Action recognition; iDT; Deep learning; C3D
AB With the development of science and technology and the progress of computing level, the research field based on video is getting more and more attention. Video understanding is a hot and challenging topic in computer vision area. Human action recognition means to automatically analyze the ongoing actions from an unknown video or image sequence and classify them correctly. Action recognition technology is widely used in many areas, including patient monitoring system, human-computer interaction, intelligent video surveillance, virtual reality, intelligent security and other aspects. In addition, video retrieval based on content and intelligent image compression have broad application prospects, among which many methods of action recognition are used. With the increasing demand for technology, there are still some challenges of action recognition in traffic context. In this paper, we briefly review the development process of action recognition technology, and classify some relevant methods, then we summarize the overall development trend of this technology. Finally, we also discussed the practical significance of it in the future in traffic context. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Haibo] North China Univ Technol, Beijing, Peoples R China.
C3 North China University of Technology
RP Zhang, HB (corresponding author), North China Univ Technol, Beijing, Peoples R China.
RI Zhang, Haibo/HLP-9266-2023
CR [Anonymous], 2016, ARXIV161001708
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Huang Z., 2016, DEEP LEARNING LIE GR, P1243
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Rao WW, 2017, IEEE ICC
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang P., 2017, SCENE FLOW ACTION MA
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   Weng JW, 2017, PROC CVPR IEEE, P445, DOI 10.1109/CVPR.2017.55
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
NR 21
TC 5
Z9 5
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 63
EP 66
DI 10.1016/j.jvcir.2018.10.022
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100007
DA 2024-07-18
ER

PT J
AU Jiang, ZW
AF Jiang, Zhengwei
TI RETRACTED: Camera network analysis for visual surveillance in electric
   industrial context (Retracted article. See vol. 69, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Camera network; Topology; Sparse; Visual surveillance
AB Society is rapidly accepting the use of a wide variety of cameras location and applications: site traffic monitoring, parking lot surveillance, car and smart space. The camera provides data every day in an analysis by an effective way. Recent advances in sensor technology manufacturing, communications and computing are stimulating. The development of new applications that can change the traditional vision system incorporating universal smart camera network was processed. This analysis of visual cues in multi camera networks makes wide applications ranging from smart home and office automation to large area surveillance and traffic surveillance. And dense Camera networks, most of which have large overlapping areas of cameras. In the view of good research, we focus on sparse camera networks. One sparse camera network using large area surveillance was developed. As few cameras as possible, most cameras do not overlap each other's field of vision. This task is challenging. Lack of knowledge of topology network, the specific changes in appearance and movement track different opinions of the target, as well as difficulties understanding complex events in a network were observed. In this review, we present a comprehensive survey of recent studies. Results to solve the problem of topology learning, object appearance modeling and global activity understanding sparse camera network were determined. In addition, some of the current open research issues are discussed. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Jiang, Zhengwei] State Grid Zhejiang Elect Power Co LTD, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Jiang, ZW (corresponding author), State Grid Zhejiang Elect Power Co LTD, Hangzhou, Zhejiang, Peoples R China.
EM jiang_zhengwei@126.com
CR [Anonymous], 2016, ARXIV161001708
   BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   Champleboux G., 1992, Proceedings. 1992 IEEE International Conference on Robotics And Automation (Cat. No.92CH3140-1), P1552, DOI 10.1109/ROBOT.1992.220031
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Farrar RandyO., 2007, P 12 WILDLIFE DAMAGE, P1
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Makris D, 2004, PROC CVPR IEEE, P205
   Medonca P.R.S., 2007, IEEE T PAMI, V27, P21
   Sheikh YA, 2008, IEEE T PATTERN ANAL, V30, P361, DOI 10.1109/TPAMI.2007.70750
   Sinha SN, 2005, IEEE I CONF COMP VIS, P349
   Sinha SN, 2004, PROC CVPR IEEE, P195
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Stauffer C., 2001, P CVPR, P259
   SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
NR 24
TC 2
Z9 2
U1 4
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 201
EP 206
DI 10.1016/j.jvcir.2018.09.014
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500020
DA 2024-07-18
ER

PT J
AU Rachmadi, RF
   Uchimura, K
   Koutaki, G
   Ogata, K
AF Rachmadi, Reza Fuad
   Uchimura, Keiichi
   Koutaki, Gou
   Ogata, Kohichi
TI Single image vehicle classification using pseudo long short-term memory
   classifier
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pseudo-LSTM classifier; Vehicle classification; Deep convolutional
   network
ID AGREEMENT; NETWORKS; SYSTEM; ROAD
AB In this paper, we propose a pseudo long short-term memory (LSTM) classifier for single image vehicle classification. The proposed pseudo-LSTM (P-LSTM) uses spatially divided images rather than time-series images. In other words, the proposed method considers the divided images to be time-series frames. The divided images are formed by cropping input images using two-level spatial pyramid region configuration. Parallel convolutional networks are used to extract the spatial pyramid features of the divided images. To explore the correlations between the spatial pyramid features, we attached an LSTM classifier to the end of the parallel convolutional network and treated each convolutional network as an independent timestamp. Although LSTM classifiers are typically used for time-dependent data, our experiments demonstrated that they can also be used for non-time-dependent data. We attached one fully connected layer to the end of the network to compute a final classification decision. Experiments on an MIO-TCD vehicle classification dataset show that our proposed classifier produces a high evaluation score and is comparable with several other state-of-the-art methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Rachmadi, Reza Fuad; Uchimura, Keiichi; Koutaki, Gou; Ogata, Kohichi] Kumamoto Univ, GSST, Kumamoto 8600862, Japan.
   [Rachmadi, Reza Fuad] Inst Teknol Sepuluh Nopember, Dept Comp Engn, Surabaya 60111, Indonesia.
C3 Kumamoto University; Institut Teknologi Sepuluh Nopember
RP Rachmadi, RF (corresponding author), Kumamoto Univ, GSST, Kumamoto 8600862, Japan.; Rachmadi, RF (corresponding author), Inst Teknol Sepuluh Nopember, Dept Comp Engn, Surabaya 60111, Indonesia.
EM fuad@navi.cs.kumamoto-u.ac.jp
RI Rachmadi, Reza Fuad/AAA-5073-2019
OI Rachmadi, Reza Fuad/0000-0001-9101-5598
CR [Anonymous], 2014, C EMP METH NAT LANG
   [Anonymous], ARXIV160806993
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IIEEJ INT WORKSH IM
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], CAN MOT VEH TRAFF CO
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV160207360
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 17 ARRB C GOLD COA 4
   [Anonymous], P AS C COMP VIS
   [Anonymous], ARXIV PREPRINT ARXIV
   [Anonymous], INVESTIGATION USE IN
   [Anonymous], INT STUD C ADV SCI T
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2
   Chen L, 2017, IEEE COMPUT SOC CONF, P1478, DOI 10.1109/CVPRW.2017.191
   Chen P, 2014, IEEE T INTELL TRANSP, V15, P2340, DOI 10.1109/TITS.2014.2308897
   Chollet F., ARXIV161002357
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Duarte MF, 2004, J PARALLEL DISTR COM, V64, P826, DOI 10.1016/j.jpdc.2004.03.020
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gajda J, 2001, IEEE IMTC P, P460, DOI 10.1109/IMTC.2001.928860
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He K., ARXIV PREPRINT ARXIV
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Luo ZM, 2018, IEEE T IMAGE PROCESS, V27, P5129, DOI 10.1109/TIP.2018.2848705
   Ma XX, 2005, IEEE I CONF COMP VIS, P1185
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nooralahiyan AY, 1998, MATH COMPUT MODEL, V27, P205, DOI 10.1016/S0895-7177(98)00060-0
   Nooralahiyan AY, 1997, TRANSPORT RES C-EMER, V5, P165, DOI 10.1016/S0968-090X(97)00011-9
   Oh C, 2007, PATTERN RECOGN LETT, V28, P1041, DOI 10.1016/j.patrec.2007.01.010
   PURSULA M, 1989, IEE CONF PUBL, V299, P24
   Rachmadi RF, 2017, INT J INNOV COMPUT I, V13, P95
   REIJMERS JJ, 1980, IEEE T VEH TECHNOL, V29, P156, DOI 10.1109/T-VT.1980.23836
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shahbaz Khan Fahad, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P341, DOI 10.1007/978-3-319-19665-7_28
   Shiyang Yan, 2017, Signal Processing: Image Communication, V54, P118, DOI 10.1016/j.image.2017.03.010
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Yu SY, 2017, NEUROCOMPUTING, V257, P97, DOI 10.1016/j.neucom.2016.09.116
   Zhou RH, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P342, DOI 10.1109/VCIP.2014.7051576
NR 54
TC 10
Z9 10
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 265
EP 274
DI 10.1016/j.jvcir.2018.09.021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500026
DA 2024-07-18
ER

PT J
AU Karimi, N
   Taban, MR
AF Karimi, Naser
   Taban, Mohammad Reza
TI Nonparametric blind SAR image super resolution based on combination of
   the compressive sensing and sparse priors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind super resolution; Synthetic aperture radar; Point spread function
   estimation; Compressive sensing; Anisotropic total variation; Conjugate
   gradient least squares
ID SUPERRESOLUTION; MAP
AB This paper by proposing a novel approach, is one the first works that addresses the highly ill-posed problem of nonparametric blind single image super resolution (SISR) of the synthetic aperture radar (SAR) images. Combination of an adaptive compressive sensing (CS) technique and some effective sparse priors, as a powerful regularizer in the both high resolution (HR) image reconstruction and the point spread function (PSF) estimation domains is the fundamental idea of the proposed method. This task is formulated as a new cost function to be minimized with respect to an intermediate reconstructed HR image patch and a nonparametric PSF kernel, according to the alternative minimization (AM) algorithm. To solve the optimization of cost function, a numerical scheme based on the conjugate gradient least squares (CGLS) method is proposed. Experimental results for the both synthetic and realistic low resolution (LR) SAR images demonstrate that the proposed method achieves the state-of-the-art performance.
C1 [Karimi, Naser] Yazd Univ, Dept Elect Engn, Yazd, Iran.
   [Taban, Mohammad Reza] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
C3 University of Yazd; Isfahan University of Technology
RP Karimi, N (corresponding author), Yazd Univ, Dept Elect Engn, Yazd, Iran.
EM naser.karimi@stu.yazd.ac.ir
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   [Anonymous], 1998, Learning from Data: Concepts, Theory, and Methods
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Begin I., 2007 IEEE INT C IM P, P421
   Bu Li-jing, 2010 IEEE INT C PROG, P804
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Efrat N, 2013, IEEE I CONF COMP VIS, P2832, DOI 10.1109/ICCV.2013.352
   Fei Han, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P399, DOI 10.1109/PSIVT.2010.73
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Han Zhang, 2013, Intelligence Science and Big Data Engineering. 4th International Conference, IScIDE 2013. Revised Selected Papers: LNCS 8261, P6, DOI 10.1007/978-3-642-42057-3_2
   He C, 2012, IEEE J-STARS, V5, P1272, DOI 10.1109/JSTARS.2012.2189555
   He Y, 2009, IMAGE VISION COMPUT, V27, P364, DOI 10.1016/j.imavis.2008.05.010
   Karimi N, 2015, J VIS COMMUN IMAGE R, V33, P94, DOI 10.1016/j.jvcir.2015.09.004
   Kulkarni N, 2012, IEEE T CIRC SYST VID, V22, P778, DOI 10.1109/TCSVT.2011.2180773
   LANE RO, 2005, P LOND COMM S SEPT, P5
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P1299, DOI 10.1109/83.941854
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Oliver C., 2004, Understanding Synthetic Aperture Radar Images
   OLIVER CJ, 1989, J PHYS D APPL PHYS, V22, P871, DOI 10.1088/0022-3727/22/7/001
   Protter M, 2010, IEEE T SIGNAL PROCES, V58, P3471, DOI 10.1109/TSP.2010.2046596
   Rajan D, 2003, IEEE T PATTERN ANAL, V25, P1102, DOI 10.1109/TPAMI.2003.1227986
   Shao WZ, 2016, PATTERN RECOGN, V51, P402, DOI 10.1016/j.patcog.2015.09.034
   Sroubek F, 2007, IEEE T IMAGE PROCESS, V16, P2322, DOI 10.1109/TIP.2007.903256
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z. M., 2006, SAR IMAGE RESOLUTION
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
NR 33
TC 12
Z9 13
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 853
EP 865
DI 10.1016/j.jvcir.2018.04.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100075
DA 2024-07-18
ER

PT J
AU Niu, G
   Chen, QQ
AF Niu, Gang
   Chen, Ququ
TI Learning an video frame-based face detection system for security fields
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video frame-based face detection; Libfacedetection; Deep learning;
   Gaussian mixture model
AB It is know that face detection as a kind of artificial intelligence (AI) technology has become an indispensable tool in our daily life, which produce effects on every aspect of us. The demand for detection and recognition is higher accuracy and higher speed in different areas. So a new video frame-based face detection system is designed to help us making good safety precautions in recognition between normal face and abnormal face. Abnormal face means that face is partially occluded by some objects such as mask, sunglass and so on. Since these abnormal faces are easily recognized as normal faces in previous detection systems, they are often ignored. And it brings us some potential dangers, especially in the area of residential face detection access, bank business login and other security areas. This system provides a complete set of process for detecting faces from video and distinction them, which achieves a good real-time performance in accuracy and speed. We adopt libfacedetection to detect faces from each frame. In addition, we introduce a dlib library which is a deep learning tools to help aligning face and extract the characteristic value. And a GMM clustering algorithm is provided to train and test images for the system. This system can help us to make a distinction between normal face and abnormal face, which is of great significance to the security field in the future.
C1 [Niu, Gang] Zhengzhou Huali Informat Technol Co LTD, Zhengzhou, Henan, Peoples R China.
   [Chen, Ququ] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Niu, G (corresponding author), Zhengzhou Huali Informat Technol Co LTD, Zhengzhou, Henan, Peoples R China.
EM 895585302@qq.com
CR [Anonymous], P CVPR
   [Anonymous], INT C ADV COMM CONTR
   [Anonymous], 2016, ARXIV161001708
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Goswami G., 2018, ARXIV180300401
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Liu Xiao, 2013, P CVPR
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Rao WW, 2017, IEEE ICC
   Tang XO, 2004, PROC CVPR IEEE, P902
   Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang L., 2015, ICMR
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang LM, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886775
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang Luming, 2015, ACM MULTIMEDIA
   Zhang Luming, 2014, ACM MULTIMEDIA
   Zhang Luming, 2009, ACM MULTIMEDIA
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
NR 38
TC 19
Z9 20
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 457
EP 463
DI 10.1016/j.jvcir.2018.07.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100040
DA 2024-07-18
ER

PT J
AU Zhang, LZ
   Wang, ZP
AF Zhang, Lizong
   Wang, Zepeng
TI A multi-view camera-based anti-fraud system and its applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anti-fraud; Key frames; Face recognition
ID SUPERVISED IMAGE SEGMENTATION; VIDEOS; MODEL; FACE
AB Anti-fraud system is very useful in many intelligent applications. With the development of the financial field, anti-fraud system is becoming more and more important. But conventional face recognition techniques cannot distinguish real faces and masks effectively from the video stream. In addition, computing the whole video stream is redundant and time-consuming. So computing some key frames selected from video stream is more effective, but many frames gotten randomly from video stream don't contain any faces. So in this paper, we propose a new method only with a camera to estimate a person's behavior to detect whether a person is fraudulent. A camera-based anti-fraud system requires a series of representative video frames (i.e. key frames) from the video stream. First, a set of key frames are extracted from the video stream using our active key frame selection algorithm. The criterion is that the contents of the video stream are maximally covered by these frames. Then, face features are obtained using Dlib. Finally, a probabilistic model is proposed to estimate a person's behavior. Experimental results have demonstrated that: 1) our key frame selection algorithm can reduce redundant frames effectively; 2) our system can estimate a person's behavior in real time.
C1 [Zhang, Lizong] State Grid Shaoxing Elect Power Supply Co, Shaoxing Shi, Zhejiang Sheng, Peoples R China.
   [Wang, Zepeng] Hefei Univ Technol, Dept CSIE, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Wang, ZP (corresponding author), Hefei Univ Technol, Dept CSIE, Hefei, Anhui, Peoples R China.
EM wgzepg9393@gmail.com
CR [Anonymous], 2016, P IEEE WINT C APPL C
   [Anonymous], 2016, ARXIV161001708
   [Anonymous], 2017, ARXIV170200098
   Bouguettaya A, 1996, IEEE T KNOWL DATA EN, V8, P333, DOI 10.1109/69.494170
   Carlsson S, 2001, WORKSH MOD VERS EX C, V1
   Chen YX, 2016, INFORM SCIENCES, V372, P148, DOI 10.1016/j.ins.2016.08.050
   Chen YX, 2014, IEEE T CIRC SYST VID, V24, P1992, DOI 10.1109/TCSVT.2014.2329380
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008
   Wang Z. L., 2017, Mater. Today, V20, P74, DOI DOI 10.1016/J.MATTOD.2016.12.001
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 36
TC 2
Z9 2
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 263
EP 269
DI 10.1016/j.jvcir.2018.06.016
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100023
DA 2024-07-18
ER

PT J
AU Kumar, S
   Bhuyan, MK
   Lovell, BC
   Iwahori, Y
AF Kumar, Sunil
   Bhuyan, M. K.
   Lovell, Brian C.
   Iwahori, Yuji
TI Hierarchical uncorrelated multiview discriminant locality preserving
   projection for multiview facial expression recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Multi-view discriminant analysis; Local
   discriminant analysis (LFDA); Uncorrelated discriminant analysis;
   k-Nearest neighbour (k-NN)
ID GAUSSIAN-PROCESSES; FACE RECOGNITION; SCALE
AB Existing multi-view facial expression recognition algorithms are not fully capable of finding discriminative directions if the data exhibits multi-modal characteristics. This research moves toward addressing this issue in the context of multi-view facial expression recognition. For multi-modal data, local preserving projection (LPP) or local Fisher discriminant analysis (LFDA)-based approach is quite appropriate to find a discriminative space. Also, the classification performance can be enhanced by imposing uncorrelated constraint onto the discriminative space. So for multi-view (multi-modal) data, we proposed an uncorrelated multi-view discriminant locality preserving projection (UMvDLPP)-based approach to find an uncorrelated common discriminative space. Additionally, the proposed UMvDLPP is implemented in a hierarchical fashion (H-UMvDLPP) to obtain an optimal performance. Extensive experiments on BU3DFE dataset show that UMvDLPP performs slightly better than the existing methods. However, an improvement of approximately 3% as compared to the existing state-of-the-art multi-view learning-based approaches is achieved by our H-UMvDLPP. This improvement is due to the fact that the proposed method enhances the discrimination between the classes more effectively, and classifies expressions category-wise followed by classification of the basic expressions embedded in each of the subcategories (hierarchical approach).
C1 [Kumar, Sunil; Bhuyan, M. K.] Indian Inst Technol, Dept Elect & Elect Engn, Gauhati 781039, India.
   [Lovell, Brian C.] UQ St Lucia, Sch ITEE, Brisbane, Qld 4072, Australia.
   [Iwahori, Yuji] Chubu Univ, Dept Comp Sci, 1200 Matsumoto, Kasugai, Aichi 4878501, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; University of Queensland; Chubu University
RP Bhuyan, MK (corresponding author), Indian Inst Technol, Dept Elect & Elect Engn, Gauhati 781039, India.
EM mkb@iitg.ernet.in; sunil2012@iitg.ernet.in; lovell@itee.uq.edu.au;
   iwahori@cs.chubu.ac.jp
RI Iwahori, Yuji/AAH-4257-2020; Bhuyan, Manoj Kumar/D-1562-2012
OI Iwahori, Yuji/0000-0002-6421-8186; Lovell, Brian/0000-0001-6722-1754
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], P 10 IND C COMP VIS
   [Anonymous], 2008, IEEE INT C AUTOMATIC, DOI [DOI 10.1109/AFGR.2008.4813472, 10.1109/AFGR.2008.4813472]
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2016 P 22 NAT C COMM
   [Anonymous], 2007, P 24 INT C MACHINE L
   Chung F. R. K., 1997, AM MATH SOC, V92, DOI DOI 10.1090/CBMS/092
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng Jiankang, 2017, P IEEE INT C COMP VI, V4
   Duan Y., 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Hesse N, 2012, INT C PATT RECOG, P3533
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hsieh CK, 2009, IEEE T MULTIMEDIA, V11, P600, DOI 10.1109/TMM.2009.2017606
   Hu Y., 2008, 8 IEEE INT C AUTOMAT, P1
   Hu Y.X., 2008, IEEE INT C PATT REC, P1
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Kim TK, 2006, LECT NOTES COMPUT SC, V3953, P251
   Kumar S, 2016, IET COMPUT VIS, V10, P567, DOI 10.1049/iet-cvi.2015.0273
   Li Jue., 2015, INT C THERMAL MECH M, P1, DOI [10.1109/IST.2015.7294547, DOI 10.1109/EUROSIME.2015.7103076]
   Liu P, 2014, LECT NOTES COMPUT SC, V8692, P151, DOI 10.1007/978-3-319-10593-2_11
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Mollaeian Aida, 2016, 2016 IEEE Conference on Electromagnetic Field Computation (CEFC), DOI 10.1109/CEFC.2016.7816397
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Nusseck M, 2008, J VISION, V8, DOI 10.1167/8.8.1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rudovic Ognjen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4121, DOI 10.1109/ICPR.2010.1001
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26
   Rupnik J., 2010, P C DATA MINING DATA, P1
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tariq U, 2012, LECT NOTES COMPUT SC, V7585, P578, DOI 10.1007/978-3-642-33885-4_58
   Walecki Robert, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163137
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yu XL, 2008, IEEE SIGNAL PROC LET, V15, P361, DOI 10.1109/LSP.2008.919841
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zheng WM, 2010, LECT NOTES COMPUT SC, V6316, P490, DOI 10.1007/978-3-642-15567-3_36
   Zheng ZL, 2007, SIGNAL PROCESS, V87, P2473, DOI 10.1016/j.sigpro.2007.03.006
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 54
TC 3
Z9 3
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 171
EP 181
DI 10.1016/j.jvcir.2018.04.013
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800015
DA 2024-07-18
ER

PT J
AU Yang, J
   Yuan, JS
AF Yang, Jiong
   Yuan, Junsong
TI Temporally enhanced image object proposals for online video object and
   action detections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video; Proposal; Online; Detection; Temporal
ID LOCALIZATION; RECOGNITION
AB Despite the recent advances of image object proposals (IOPs) and video object proposals (VOPs), it still remains a challenge to apply them to online video object/action detection. To address this problem, we propose a novel form of image object proposals, Temporally Enhanced Image Object Proposals (TE-IOPs), for online video object/action detection. The proposed TE-IOPs augment the existing IOPs at every frame by their temporal dynamics in the past few frames. We develop a dynamic programming scheme to efficiently search for such TE-IOPs in an online manner. Compared with existing VOPs that cannot run online, our TE-IOPs can be used for online detection. Compared with IOPs, our TE-IOPs bring rich temporal dynamics with minor computational cost. Experiments on benchmark datasets validate the superior performance of the proposed TE-IOPs over existing IOPs and VOPs, in terms of both the proposal re-ranking and the application of online action detection.
C1 [Yang, Jiong] Nanyang Technol Univ, Interdisciplinary Grad Sch, Singapore, Singapore.
   [Yuan, Junsong] Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY USA.
C3 Nanyang Technological University; State University of New York (SUNY)
   System; State University of New York (SUNY) Buffalo
RP Yang, J (corresponding author), Nanyang Technol Univ, Interdisciplinary Grad Sch, Singapore, Singapore.
EM yang0374@e.ntu.edu.sg; jsyuan@buffalo.edu
RI Yuan, Junsong/R-4352-2019
OI Yuan, Junsong/0000-0002-7901-8793
FU Singapore Ministry of Education Academic Research Fund Tier 2
   [MOE2015-T2-2-114]; Singapore Ministry of Education Academic Research
   Fund Tier 1 [RG27/14]; National Research Foundation Singapore, under its
   Interactive Digital Media (IDM) Strategic Research Programme; NVAITC
   (NVIDIA AI Tech Centre)
FX This work is supported in part by Singapore Ministry of Education
   Academic Research Fund Tier 2 MOE2015-T2-2-114 and Tier 1 RG27/14. This
   research was carried out at Rapid-Rich Object Search (ROSE) Lab at the
   Nanyang Technological University, Singapore. The ROSE Lab is supported
   by the National Research Foundation Singapore, under its Interactive
   Digital Media (IDM) Strategic Research Programme. We also gratefully
   acknowledge the support of NVAITC (NVIDIA AI Tech Centre) for our
   research at ROSE Lab. This work is also supported in part by start-up
   funds of University at Buffalo.
CR Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2014, P BRIT MACH VIS C
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2014, AS C COMP VIS SPRING
   [Anonymous], 2012, TECH REP
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2011, BRIT MACH VIS C
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2010, BMVC
   [Anonymous], IEEE T IMAGE PROCESS
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chen W, 2014, PROC CVPR IEEE, P748, DOI 10.1109/CVPR.2014.101
   Chen XZ, 2015, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2015.7298874
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cho M, 2015, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2015.7298724
   Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Ke Y., 2007, PROC IEEE INT C COMP
   Kong Y., 2017, CVPR
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48
   Perronnin F., 2007, PROC IEEE C COMPUTER, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Puscas MM, 2015, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2015.193
   Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351
   Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310
   Shah M., 2008, PROC IEEE C COMPUTER, P1
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Van den Bergh M, 2013, IEEE I CONF COMP VIS, P377, DOI 10.1109/ICCV.2013.54
   Wang CY, 2015, PROC CVPR IEEE, P3873, DOI 10.1109/CVPR.2015.7299012
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wu ZY, 2015, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2015.7299047
   Xiao Y, 2015, PROC CVPR IEEE, P778, DOI 10.1109/CVPR.2015.7298678
   Xu Z, 2015, IEEE I CONF COMP VIS, P3191, DOI 10.1109/ICCV.2015.365
   Yang J, 2016, IEEE T CIRC SYST VID, V26, P1070, DOI 10.1109/TCSVT.2015.2433171
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 60
TC 1
Z9 1
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 245
EP 256
DI 10.1016/j.jvcir.2018.03.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800023
DA 2024-07-18
ER

PT J
AU Yao, SK
   Chang, Y
   Qin, XJ
   Zhang, YZ
   Zhang, TX
AF Yao, Shoukui
   Chang, Yi
   Qin, Xiaojuan
   Zhang, Yaozong
   Zhang, Tianxu
TI Principal component dictionary-based patch grouping for image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Nonlocal self-similarity; Transform-domain; External knowledge; Image
   denoising
ID SPARSE; TRANSFORM; ALGORITHM
AB Improving denoising algorithms based on nonlocal self-similarity (NSS) to cope with increasing noise levels has become difficult. This is primarily because of difficulty in accurately grouping similar image patches solely on original spatial-domain of noisy images. To solve this problem, we propose to group similar patches on transform -domain learned from clean natural images. In this paper, we introduce a denoising algorithm comprising principal component dictionary (PCD)-based patch grouping and a low-rank approximation process. In the proposed algorithm, PCD learns from clean natural images and uses the knowledge gained to guide similar patches grouping results in noisy images. Patch grouping is directly implemented on PCD-based transform domain. And, external knowledge and internal NSS prior are used jointly for image denoising. The results of experiments conducted indicate that the proposed denoising algorithm outperforms several state-of-the-art de-noising algorithms, especially in heavy noise conditions.
C1 [Yao, Shoukui; Chang, Yi; Qin, Xiaojuan; Zhang, Yaozong; Zhang, Tianxu] Huazhong Univ Sci & Technol, Sch Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Yao, SK (corresponding author), Huazhong Univ Sci & Technol, Sch Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan, Hubei, Peoples R China.
EM ysk2013@hust.edu.cn
RI Zhang, Yaozong/AAW-6317-2020
FU National Natural Science Foundation of China (NSFC) [61571207]; National
   Key Laboratory of Science and Technology on Multispectral Information
   Processing, School of Automation, Huazhong University of Science and
   Technology, China
FX The authors would like to thank editor and anonymous reviewers who gave
   valuable suggestion that has helped to improve the quality of the paper.
   This work is supported by National Natural Science Foundation of China
   (NSFC) grant (61571207) and National Key Laboratory of Science and
   Technology on Multispectral Information Processing, School of
   Automation, Huazhong University of Science and Technology, China.
CR Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chang Y., 2017, CVPR, P4260
   Chang Y, 2015, IEEE T IMAGE PROCESS, V24, P1852, DOI 10.1109/TIP.2015.2404782
   Chen F, 2015, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2015.76
   Chen F, 2015, J VIS COMMUN IMAGE R, V30, P117, DOI 10.1016/j.jvcir.2015.03.005
   Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Grewenig S, 2011, J VIS COMMUN IMAGE R, V22, P117, DOI 10.1016/j.jvcir.2010.11.001
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Nejati M, 2016, J VIS COMMUN IMAGE R, V36, P28, DOI 10.1016/j.jvcir.2016.01.004
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang SS, 2012, J VIS COMMUN IMAGE R, V23, P1008, DOI 10.1016/j.jvcir.2012.06.011
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang L, 2009, IEEE T IMAGE PROCESS, V18, P797, DOI 10.1109/TIP.2008.2011384
   ZONTAK M, 2011, PROC CVPR IEEE, P977, DOI DOI 10.1109/CVPR.2011.5995401
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 34
TC 13
Z9 14
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 111
EP 122
DI 10.1016/j.jvcir.2017.11.019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700012
DA 2024-07-18
ER

PT J
AU Gao, Z
   Li, SH
   Zhu, YJ
   Wang, C
   Zhang, H
AF Gao, Z.
   Li, S. H.
   Zhu, Y. J.
   Wang, C.
   Zhang, H.
TI Collaborative sparse representation leaning model for RGBD action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGBD action recognition; Collaborative sparse representation leaning
   model; Dense trajectory; Multi-modality; Depth feature
ID ROBUST FACE; MULTIVIEW
AB Multi-modalities action recognition becomes a hot research topic, and this paper proposes a collaborative sparse representation leaning model for RGB-D action recognition where RGB and depth information are adaptive fused. Specifically, dense trajectory feature is firstly extracted and Bag-of-Word (BoW) weight scheme is employed for RGB modality, and then for depth modality, the human pose representation model (HPM) and temporal modeling (TM) representation are utilized. Meanwhile, the collaborative reconstruction structure and corresponding objective functions for the multiple modalities are designed, and then the proposed model is collaboratively optimized which is used to discover the latent complementary information between RGB and depth data. Finally, the collaborative reconstruction error is employed as our classification scheme. Large scale experimental results on challenging and public DHA, (MI)-I-2 and Northwestern-UCLA action datasets show that the performances of our model on two modalities are much better than traditional sole modality, which can boost the performance of human action recognition by taking advance of complementary characteristics from both RGB and depth modalities. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Gao, Z.; Li, S. H.; Zhang, H.] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
   [Gao, Z.; Li, S. H.; Zhang, H.] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
   [Zhu, Y. J.] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing 100093, Peoples R China.
   [Wang, C.] Home Depot, Atlanta, GA USA.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Chinese Academy of Sciences; Institute of Information Engineering, CAS
RP Gao, Z; Zhang, H (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
EM zangaonsh4522@gmail.com; hzhang62@163.com
FU National Natural Science Foundation of China [61572357, 61202168];
   Country China Scholarship Council [201608120021]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61572357, No. 61202168) and Country China
   Scholarship Council (No. 201608120021).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], J OPTOELECTRON LASER
   [Anonymous], NEUROCOMPUTING
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2016, CVPR
   [Anonymous], IEEE T CYBER
   [Anonymous], SIG P
   [Anonymous], IEEE T CYBERN
   [Anonymous], P 2016 ACM MULT C
   [Anonymous], 2013, ICCV
   [Anonymous], ELECT LETT
   [Anonymous], NEUROCOMPUTING
   [Anonymous], J ELECTR ENG TECHNOL
   [Anonymous], P IEEE INT C MULT EX
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Chen Y, 2013, IEEE T GEOSCI REMOTE, V51, P217, DOI 10.1109/TGRS.2012.2201730
   Chen ZX, 2016, LECT NOTES ELECTR EN, V360, P125, DOI 10.1007/978-3-662-48365-7_13
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Gao KZ, 2012, IEEE C EVOL COMPUTAT
   Gao Z., 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P397, DOI 10.1007/978-3-319-27671-7_33
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gao Z, 2014, KSII T INTERNET INF, V8, P483, DOI 10.3837/tiis.2014.02.009
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Ge L, 2015, LECT NOTES COMPUT SC, V9314, P114, DOI 10.1007/978-3-319-24075-6_12
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Gunawardana A, 2005, J MACH LEARN RES, V6, P2049
   Hao T, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17060907
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Huang ZX, 2013, PATTERN RECOGN, V46, P2156, DOI 10.1016/j.patcog.2013.01.022
   Jia Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3744, DOI 10.1109/ICPR.2010.912
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu AA, 2011, ELECTRON LETT, V47, P651, DOI 10.1049/el.2011.0880
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Liu HP, 2016, IEEE T INSTRUM MEAS, V65, P656, DOI 10.1109/TIM.2016.2514779
   Liu J., 2008, EURASIP J ADV SIG PR, V2008, P1, DOI DOI 10.1074/JBC.M802695200
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Megavannan V., 2012, Signal Processing and Communications (SPCOM), 2012 International Conference on, P1
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860
   Rodriguez MD, 2008, CVPR 08, P1
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L., 2009, Advances in Acoustics and Vibration, V2009, P1
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 74
TC 25
Z9 25
U1 2
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 442
EP 452
DI 10.1016/j.jvcir.2017.03.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700038
DA 2024-07-18
ER

PT J
AU Huang, SL
   Izquierdo, E
   Hao, PW
AF Huang, Shenglan
   Izquierdo, Ebroul
   Hao, Pengwei
TI Adaptive packet scheduling for scalable video streaming with network
   coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Network coding; Scalable video streaming; Live streaming; P2P network
AB Over the last decade, the emergence of new multimedia devices has motivated the research on efficient media streaming mechanisms that adapt to dynamic network conditions and heterogeneous devices' capabilities. Network coding as a rateless code has been applied to collaborative media streaming applications and brings substantial improvements regarding throughput and delay. However, little attention has been given to the recoverability of encoded data, especially for the streaming with a strict deadline. This in turn leads to severe quality of experience. In this paper, we solve the unrecoverable transmission by proposing a multi-generation packet scheduling problem, which is treated as a video quality maximization problem and solved using dynamic programming algorithm. Experimental results confirm that the proposed algorithm brings better data recoverability and better quality of service in terms of video quality, delivery ratio, lower redundancy rate under different network sizes. Crown Copyright (C) 2016 Published by Elsevier Inc. All rights reserved.
C1 [Huang, Shenglan; Izquierdo, Ebroul; Hao, Pengwei] Queen Mary Univ London, London, England.
C3 University of London; Queen Mary University London
RP Huang, SL (corresponding author), Queen Mary Univ London, London, England.
EM s.huang@qmul.ac.uk
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   [Anonymous], 2008, P IEEE INT C IND TEC, DOI DOI 10.1109/ICIT.2008.4608549
   Bertsekas DP, 2017, DYNAMIC PROGRAMMING
   Chou P.A., Practical network coding
   Ho T, 2006, IEEE T INFORM THEORY, V52, P4413, DOI 10.1109/TIT.2006.881746
   Huang SL, 2014, IEEE IMAGE PROC, P3993, DOI 10.1109/ICIP.2014.7025811
   Huang SL, 2016, IEEE T MULTIMEDIA, V18, P752, DOI 10.1109/TMM.2016.2530411
   Kellerer H., 2004, Introduction to NP-Completeness of Knapsack Problems, DOI 10.1007/978-3-540-24777-7
   Li BC, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2505805
   Liu ZY, 2009, IEEE T MULTIMEDIA, V11, P1340, DOI 10.1109/TMM.2009.2030656
   Liu Zhong-Hua, 2011, International Journal of Neuropsychopharmacology, V14, P618, DOI 10.1017/S1461145710000520
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Magharei N, 2007, IEEE INFOCOM SER, P1424
   Magli E., NETWORK CODING MEETS
   Nguyen AT., 2010, IEEE INFOCOM'10, San Diego, CA, USA, P1
   Nguyen K, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P396
   PISINGER D, 1995, EUR J OPER RES, V83, P394, DOI 10.1016/0377-2217(95)00015-I
   Sanna M., 2013, 20 INT PACK VID WORK, P1
   Sejdinovic D, 2009, IEEE T COMMUN, V57, P2510, DOI 10.1109/TCOMM.2009.09.070616
   Sheikh AM, 2014, IEEE T MULTIMEDIA, V16, P2294, DOI 10.1109/TMM.2014.2357716
   Sheikh AM, 2013, IEEE INFOCOM SER, P11
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Thomos N, 2015, IEEE T MULTIMEDIA, V17, P893, DOI 10.1109/TMM.2015.2425228
   Thomos N, 2011, IEEE T MULTIMEDIA, V13, P776, DOI 10.1109/TMM.2011.2111364
   Wang M, 2007, IEEE J SEL AREA COMM, V25, P1655, DOI 10.1109/JSAC.2007.071205
   Yu LJ, 2009, IEEE T CONSUM ELECTR, V55, P576, DOI 10.1109/TCE.2009.5174425
   Zhang XY, 2012, COMPUT NETW, V56, P3548, DOI 10.1016/j.comnet.2012.06.013
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhao J, 2006, IEEE T MULTIMEDIA, V8, P1021, DOI 10.1109/TMM.2006.879847
NR 30
TC 8
Z9 8
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 10
EP 20
DI 10.1016/j.jvcir.2016.11.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400002
DA 2024-07-18
ER

PT J
AU Ok, J
   Lee, C
AF Ok, Jiheon
   Lee, Chulhee
TI HDR tone mapping algorithm based on difference compression with adaptive
   reference values
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range image; Tone mapping operator; Objective quality
   assessment; Perceptual quality; Difference compression
ID IMAGE QUALITY ASSESSMENT; REPRODUCTION; ADAPTATION; VISIBILITY; DISPLAY
AB Tone mapping remains a challenging problem since tone mapping operators need to produce high perceptual quality under all conditions. In this paper, we propose a new local tone mapping method based on difference compression with adaptive reference values, which can effectively reproduce the details of bright and shadow regions. We also use a global tone mapping method and blend the output images produced by the global and local methods based on objective quality metrics. To quantitatively measure output images, we developed a new objective quality metric for the tone mapped images. The proposed detailness metric measures detail loss in the bright and shadow regions, and shows good correlations with subjective quality. We combined this metric with the recently proposed tone mapped image quality index (TMQI) that may not sufficiently reflect the amount of local detail loss. The experiments show that the proposed algorithm provides better perceptual quality than existing methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ok, Jiheon; Lee, Chulhee] Yonsei Univ, Dept Elect & Elect Engn, 50 Yonsei Ro, Seoul 03722, South Korea.
C3 Yonsei University
RP Lee, C (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, 50 Yonsei Ro, Seoul 03722, South Korea.
EM chulhee@yonsei.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MEST)
   [2011-0029381]
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MEST) (No.
   2011-0029381).
CR [Anonymous], 2012, METH SUBJ ASS QUAL T
   [Anonymous], 2014, LUMINANCE HDR
   Artusi A, 2013, IEEE IMAGE PROC, P2309, DOI 10.1109/ICIP.2013.6738476
   Ashikhmin M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P145
   Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   Barkowsky M, 2010, IEEE IMAGE PROC, P3245, DOI 10.1109/ICIP.2010.5651143
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   Chiu K., 1993, Proceedings Graphics Interface '93, P245
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Drago Frederic., 2003, Proceedings of ACM SIGGRAPH 2003 Sketches Applications, P1
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fang HM, 2015, IET COMPUT VIS, V9, P937, DOI 10.1049/iet-cvi.2015.0047
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gu B, 2013, IEEE T IMAGE PROCESS, V22, P70, DOI 10.1109/TIP.2012.2214047
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hecht S, 1924, J GEN PHYSIOL, V7, P235, DOI 10.1085/jgp.7.2.235
   ITU, 2015, Parameter values for the HDTV standards for production and international programme exchange
   Kuang JT, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P315
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Li XG, 2007, J VIS COMMUN IMAGE R, V18, P397, DOI 10.1016/j.jvcir.2007.06.005
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Li ZG, 2014, IEEE T IND ELECTRON, V61, P7076, DOI 10.1109/TIE.2014.2314066
   Li ZG, 2014, IEEE T IMAGE PROCESS, V23, P4372, DOI 10.1109/TIP.2014.2349432
   Liu XYB, 2014, LECT NOTES COMPUT SC, V8588, P376, DOI 10.1007/978-3-319-09333-8_41
   Lu SJ, 2014, IEEE T PATTERN ANAL, V36, P195, DOI 10.1109/TPAMI.2013.158
   Ma K, 2014, IEEE INT CON MULTI
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nemoto H., 2015, 9 INT WORKSHOP VIDEO
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   STEVENS SS, 1960, J OPT SOC AM, V50, P1139
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yoshida A, 2005, PROC SPIE, V5666, P192, DOI 10.1117/12.587782
NR 42
TC 18
Z9 19
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 61
EP 76
DI 10.1016/j.jvcir.2016.12.008
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400007
DA 2024-07-18
ER

PT J
AU Huang, CT
   Wang, ZN
   Kuo, CCJ
AF Huang, Chun-Ting
   Wang, Zhengning
   Kuo, C. -C. Jay
TI Visible-light and near-infrared face recognition at a distance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Cross-distance matching; Cross-environment matching;
   Two-stage filtering; Image restoration; Locally Linear Embedding (LLE)
ID RETINEX; ALIGNMENT
AB A method to solve the problem of face recognition at a distance (FRAD) under the visible-light (VIS) and the near-infrared (NIR) spectra is presented in this work. For images taken under visible light at day time, we perform the coarse-scale alignment/enhancement to eliminate a set of unlikely candidates at the first stage. Then, the fine-scale alignment/enhancement steps are conducted to refine the candidate list furthermore iteratively at the second stage. To address the additional challenge associated with NIR images captured at night time, we incorporate a restoration mechanism that reconstructs low-quality patches through a locally linear embedding (LLE) process with a local constraint. It is shown by experimental results that our FRAD solution outperforms state-of-the-art methods on both VIS and NIR images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Huang, Chun-Ting; Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Wang, Zhengning] Univ Elect Sci & Technol China, Dept Elect Engn, Chengdu, Peoples R China.
C3 University of Southern California; University of Electronic Science &
   Technology of China
RP Huang, CT (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM chuntinh@usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU University of Southern California's Center for High Performance
   Computing
FX Computation for the work described in this paper was supported by the
   University of Southern California's Center for High Performance
   Computing (hpc.usc.edu).
CR [Anonymous], ARXIV150402351
   [Anonymous], 2013, CVPR
   [Anonymous], 2011, P INT JOINT C BIOMET
   Ban KD, 2011, ETRI J, V33, P251, DOI 10.4218/etrij.11.1510.0022
   Bourlai T., 2012, SPIE DEFENSE SECURIT
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chun-Ting Huang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301313
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng WH, 2014, IEEE T PATTERN ANAL, V36, P1275, DOI 10.1109/TPAMI.2013.194
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Dong C, IMAGE SUPER RESOLUTI
   Geng C, 2013, MACH VISION APPL, V24, P537, DOI 10.1007/s00138-012-0423-7
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang G.B., 2008, PROC WORKSHOP FACES
   Hyunju Maeng, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P708, DOI 10.1007/978-3-642-37444-9_55
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kang D, 2014, PATTERN RECOGN, V47, P3750, DOI 10.1016/j.patcog.2014.06.004
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163
   Li Stan Z., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204149
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Milborrow S., The MUCT Landmarked Face Database
   Omri F, 2014, LECT NOTES COMPUT SC, V8509, P549, DOI 10.1007/978-3-319-07998-1_63
   Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Rara Ham, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P27, DOI 10.1109/CVPR.2009.5204301
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tome P., 2010, CVPR Workshops, P67
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yao Y, 2008, COMPUT VIS IMAGE UND, V111, P111, DOI 10.1016/j.cviu.2007.09.004
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 39
TC 6
Z9 6
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 140
EP 153
DI 10.1016/j.jvcir.2016.09.012
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000013
DA 2024-07-18
ER

PT J
AU Wang, XF
   Qi, C
AF Wang, Xiaofang
   Qi, Chun
TI Saliency-based dense trajectories for action recognition using low-rank
   matrix decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Dense trajectory; Saliency detection; Low-rank
   matrix decomposition
ID MOTION; DESCRIPTORS; VIDEOS; VECTOR
AB Dense trajectory methods have recently been proved to be successful in recognizing actions in realistic videos. However, their performance is still limited due to the uniform dense sampling, which does not discriminate between action-related areas and background. This paper proposes to improve the dense trajectories for recognizing actions captured in realistic scenes, especially in the presence of camera motion. Firstly, based on the observation that the motion in action-related areas is usually much more irregular than the camera motion in background, we recover the salient regions in a video by implementing low-rank matrix decomposition on the motion information and use the saliency maps to indicate action-related areas. Considering action-related regions are changeable but continuous with time, we temporally split a video into subvideos and compute the salient regions subvideo by subvideo. In addition, to ensure spatial continuity, we spatially divide a subvideo into patches and arrange the vectorized optical flow of all the spatial patches to collect the motion information for salient region detection. Then, after the saliency maps of all subvideos in a video are obtained, we incorporate them into dense tracking to extract saliency-based dense trajectories to describe actions. To evaluate the performance of the proposed method, we conduct experiments on four benchmark datasets, namely, Hollywood2, YouTube, HMDB51 and UCF101, and show that the performance of our method is competitive with the state of the art. (C) 2016 Elsevier Inc.All rights reserved.
C1 [Wang, Xiaofang; Qi, Chun] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Wang, Xiaofang] Qilu Univ Technol, Sch Elect Engn & Automat, Jinan 250353, Shandong, Peoples R China.
C3 Xi'an Jiaotong University; Qilu University of Technology
RP Qi, C (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM wxf2012@stu.xjtu.edu.cn; qichun@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61572395]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20110201110012]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61572395) and the Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20110201110012).
CR Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Cho J, 2014, PATTERN RECOGN, V47, P1813, DOI 10.1016/j.patcog.2013.12.004
   Emmanuel C., 2011, J ACM, V58
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lin Z., ARXIV10095055V3 UIUC
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Murthy OVR, 2015, IMAGE VISION COMPUT, V42, P22, DOI 10.1016/j.imavis.2015.06.009
   Murthy OVR, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P412, DOI 10.1109/ICCVW.2013.61
   Narayan S, 2014, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2014.337
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Somasundaram G, 2014, COMPUT VIS IMAGE UND, V123, P1, DOI 10.1016/j.cviu.2014.01.002
   Soomro K., 2012, ARXIV12120402
   Souly N., 2015, INT J COMPUT VISION, P1
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Wang H., 2013, LEAR SUBM THUM WORKS
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
   Yan JC, 2010, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP.2010.5652280
   Yi Y, 2013, SIGNAL PROCESS, V93, P2932, DOI 10.1016/j.sigpro.2013.05.002
   YUAN F., 2010, ECCV, P168
   Yuan F, 2012, PATTERN RECOGN, V45, P4182, DOI 10.1016/j.patcog.2012.05.001
NR 36
TC 5
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 361
EP 374
DI 10.1016/j.jvcir.2016.10.015
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000032
DA 2024-07-18
ER

PT J
AU De Praeter, J
   Van Wallendael, G
   Vermeir, T
   Slowack, J
   Lambert, P
AF De Praeter, Johan
   Van Wallendael, Glenn
   Vermeir, Thijs
   Slowack, Jurgen
   Lambert, Peter
TI Spatially misaligned HEVC transcoding with computational-complexity
   scalability
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High Efficiency Video Coding (HEVC); Machine learning; Transcoding;
   Picture composition
ID H.264 VIDEO TRANSCODER; MOTION REESTIMATION; PARALLEL FRAMEWORK;
   EFFICIENCY; DECISION; MPEG-2
AB In control rooms, video walls display footage from multiple sources. Often, a composition of these sources is sent to other devices in a single video stream. To minimize the computational complexity of this composition process, information from the original bitstreams can be reused. However, in High Efficiency Video Coding (HEVC), simply copying the original encoding decisions is not compression efficient if the individual videos are spatially misaligned with the grid of coded blocks of the composition. Our proposed HEVC-based transcoder reduces the computational complexity by predicting encoding decisions of misaligned sequences by using a trivial method or a more adaptive, computational complexity scalable machine learning method. Higher compression efficiency is observed when more alignment is preserved with the original block grid. Overall, the machine learning method achieves a higher compression efficiency than the trivial method. Both methods attain a complexity reduction of up to 82% compared to the reference software. (C) 2016 Elsevier Inc. All rights reserved.
C1 [De Praeter, Johan; Van Wallendael, Glenn; Vermeir, Thijs; Lambert, Peter] Ghent Univ iMinds, Data Sci Lab, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
   [Vermeir, Thijs; Slowack, Jurgen] Barco NV, President Kennedypk 35, B-8500 Kortrijk, Belgium.
C3 Ghent University; IMEC
RP De Praeter, J (corresponding author), Ghent Univ iMinds, Data Sci Lab, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM johan.depraeter@ugent.be
RI Van Wallendael, Glenn/H-8315-2015; Lambert, Peter/D-7776-2016
OI Van Wallendael, Glenn/0000-0001-9530-3466; Lambert,
   Peter/0000-0001-5313-4158
FU iMinds V-FORCE (Video 4K Composition and Efficient streaming) project
   (under IWT grant) [130655]; Data Science Lab (Ghent University -
   iMinds); Flanders Innovation & Entrepreneurship (VLAIO); Fund for
   Scientific Research Flanders (FWO Flanders); European Union
FX The work in this paper was performed as part of the iMinds V-FORCE
   (Video 4K Composition and Efficient streaming) project (under IWT grant
   agreement no. 130655).; The research activities described in this paper
   were funded by the Data Science Lab (Ghent University - iMinds),
   Flanders Innovation & Entrepreneurship (VLAIO), the Fund for Scientific
   Research Flanders (FWO Flanders), and the European Union. The
   computational resources (STEVIN Supercomputer Infrastructure) and
   services used in this work were kindly provided by Ghent University, the
   Flemish Supercomputer Center. (VSC), the Hercules Foundation, and the
   Flemish Government department EWI.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   [Anonymous], 2013, Technical Report JCTVC-L1100
   Bjotegaard G., 2001, VCEGM33
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   De Cock J, 2010, SIGNAL PROCESS-IMAGE, V25, P235, DOI 10.1016/j.image.2010.01.006
   De Praeter J., 2013, IEEE 15 INT WORKSH M, P514
   De Praeter J, 2014, IEEE IMAGE PROC, P2487, DOI 10.1109/ICIP.2014.7025503
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Fernández-Escribano G, 2010, IEEE T CIRC SYST VID, V20, P763, DOI 10.1109/TCSVT.2010.2045914
   Fernández-Escribano G, 2008, IEEE T MULTIMEDIA, V10, P286, DOI 10.1109/TMM.2007.911838
   Grois D, 2013, IEEE ICCE, P635, DOI 10.1109/ICCE.2013.6487049
   Hsu CT, 2009, IEEE T BROADCAST, V55, P767, DOI 10.1109/TBC.2009.2032802
   Jiang W., 2013, MULTIMED TOOLS APPL, P1
   Jing X, 2009, IEEE INT SYMP CIRC S, P2349, DOI 10.1109/ISCAS.2009.5118271
   Kim I.-K., 2011, JCTVCF379 ITUT
   Kim I.-K., 2013, JCTVCN1002 ITUT
   Li CH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1691, DOI 10.1109/ICME.2004.1394578
   Liu ZG, 2012, MULTIMEDIA SYST, V18, P359, DOI 10.1007/s00530-011-0256-7
   Van LP, 2016, IEEE T MULTIMEDIA, V18, P364, DOI 10.1109/TMM.2015.2512231
   Van LP, 2015, IEEE T CONSUM ELECTR, V61, P507, DOI 10.1109/TCE.2015.7389806
   Van LP, 2013, IEEE IMAGE PROC, P1573, DOI 10.1109/ICIP.2013.6738324
   Martínez JL, 2009, IEEE T CONSUM ELECTR, V55, P1453, DOI 10.1109/TCE.2009.5278013
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   Michalevsky Y, 2010, IEEE MEDITERR ELECT, P862, DOI 10.1109/MELCON.2010.5475946
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Patil V, 2006, IEEE T CIRC SYST VID, V16, P1164, DOI 10.1109/TCSVT.2006.881859
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan YP, 2004, IEEE T CONSUM ELECTR, V50, P887, DOI 10.1109/TCE.2004.1341696
   Tang Q, 2010, IEEE T CIRC SYST VID, V20, P262, DOI 10.1109/TCSVT.2009.2031521
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Witten I.H., 2005, DATA MINING PRACTICA, P285
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yeh CH, 2013, IEEE T BROADCAST, V59, P38, DOI 10.1109/TBC.2012.2220414
NR 38
TC 1
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 149
EP 158
DI 10.1016/j.jvcir.2016.06.025
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500015
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, YM
   Liu, HY
   Chen, ZZ
AF Li, Yiming
   Liu, Hongyi
   Chen, Zhenzhong
TI Perceptually-lossless image coding based on foveated-JND and H.265/HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.265/HEVC; Foveated JND; Lossless; Image coding; Perceptual coding
ID NOTICEABLE-DISTORTION MODEL; DIFFERENCE; HEVC; QUANTIZATION; EFFICIENCY;
   CONTRAST; STANDARD; NOISE
AB Removing perceptual redundancy plays an important role in image compression. In this paper we develop a foveated just-noticeable-difference (FJND) model to quantify the perceptual redundancy in the image and integrate it in the H.265/HEVC intra encoding framework to provide a perceptually lossless image coding solution. Different to the conventional JND models, our proposed FJND model considers the relationship between contrast masking effect and the foveation properties of HVS. Furthermore, to achieving the perceptually lossless coding, the FJND model is integrated in the H.265/HEVC framework by determining the quantization parameter to ensure that the resulting distortion is no larger than the FJND threshold. The experiments demonstrate that the proposed method effectively improves the compression performance. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Li, Yiming; Liu, Hongyi; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Luoyu Rd 129, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Luoyu Rd 129, Wuhan 430079, Peoples R China.
EM zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015; Ming, Li/JRX-2466-2023
FU National Natural Science Foundation of China [61471273]; National
   Hightech R&D Program of China (863 Program) [2015AA015903]; Natural
   Science Foundation of Hubei Province of China [2015CFA053]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61471273), National Hightech R&D Program of China (863
   Program, 2015AA015903), and Natural Science Foundation of Hubei Province
   of China (No. 2015CFA053).
CR Acharya T., 2000, U.S. Patent, Patent No. [6 154 493, 6154493]
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Franzen R., 2004, KODAK LOSSLESS TRUE
   Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   *ISO IEC, 1998, 144951 ISOIEC
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   Lubin J., 1995, VISION MODELS TARGET, P245
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Safranek R. J., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1945, DOI 10.1109/ICASSP.1989.266837
   Schofield AJ, 1999, VISION RES, V39, P2697, DOI 10.1016/S0042-6989(98)00284-3
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan T.K., 2014, JCTVCQ204
   Nguyen T, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P233, DOI 10.1109/PCS.2012.6213335
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Watson A.B., 1993, SID INT S, V24, P946
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yeo CH, 2013, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2013.6637940
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
   [No title captured]
NR 27
TC 11
Z9 11
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 600
EP 610
DI 10.1016/j.jvcir.2016.07.025
PN B
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600017
DA 2024-07-18
ER

PT J
AU Manchanda, M
   Sharma, R
AF Manchanda, Meenu
   Sharma, Rajiv
TI A novel method of multimodal medical image fusion using fuzzy transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Medical imaging; Image fusion; F-transform (FTR); Objective measures
AB Combined analysis of medical images obtained from multiple imaging modalities is extensively used by clinical professionals for quick diagnosis and treatment of critical diseases. Therefore, multimodal medical image fusion, that fuses information from different medical images into a single fused image, have gained potential interest of researchers in recent years. In this paper, a novel method of multimodal medical image fusion using fuzzy-transform (FTR) is proposed. FTR based fusion helps in preservation as well as effective transfer of detailed information present in input images into a fused image. To evaluate and prove better performance of the proposed fusion method; a number of experiments and comparisons with other existing methods of fusion have been carried out in this paper. Experimental results and comparative analysis prove that the proposed fusion algorithm is effective and generates better results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Manchanda, Meenu] Maharshi Dayanand Univ, Univ Inst Engn & Technol, Rohtak, Haryana, India.
   [Sharma, Rajiv] New Delhi Guru Gobind Singh Indraprastha Univ GGS, Northern India Engn Coll, New Delhi, India.
C3 Maharshi Dayanand University; GGS Indraprastha University
RP Manchanda, M (corresponding author), Maharshi Dayanand Univ, Univ Inst Engn & Technol, Rohtak, Haryana, India.
EM meenumanchanda73@gmail.com; rsap70@re-diffmail.com
CR Alfanol B, 2007, LECT NOTES COMPUT SC, V4816, P117
   Arathi T, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P225, DOI 10.1109/ARTCom.2009.192
   Barra V, 2001, NEUROIMAGE, V13, P410, DOI 10.1006/nimg.2000.0707
   Belohlavek O, 2005, NUCL MED REV, V8, P87
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   Bradley AndrewP., 2003, P 7 INT C DIGITAL IM, P29
   Dankova M, 2006, J ELECT ENG, V7, P82
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Di Martino F, 2008, INT J APPROX REASON, V48, P110, DOI 10.1016/j.ijar.2007.06.008
   Dong J, 2009, SENSORS-BASEL, V9, P7771, DOI 10.3390/s91007771
   Ezzati R., 2012, INT J PHYS SCI, V7, P1578
   Ghantous M, 2013, J SIGNAL PROCESS SYS, V71, P41, DOI 10.1007/s11265-012-0679-1
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1227, DOI 10.1109/36.763278
   Jianlin Li, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P300, DOI 10.1109/IASP.2010.5476108
   Kayani BN, 2007, INNOVATIONS AND ADVANCED TECHNIQUES IN COMPUTER AND INFORMATION SCIENCES AND ENGINEERING, P129, DOI 10.1007/978-1-4020-6268-1_24
   Kor S, 2004, P ANN INT IEEE EMBS, V26, P1479
   Kotwal K, 2013, INFORM FUSION, V14, P5, DOI 10.1016/j.inffus.2011.03.008
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li X., 2007, WAVELET ANAL APPL AP
   Liu Z, 2007, PATTERN RECOGN LETT, V28, P166, DOI 10.1016/j.patrec.2006.06.019
   Maruthi R., 2008, J. Information Technology, V7, P168
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Patanè G, 2011, FUZZY SET SYST, V180, P41, DOI 10.1016/j.fss.2010.10.011
   Perfilieva I, 2006, FUZZY SET SYST, V157, P993, DOI 10.1016/j.fss.2005.11.012
   Perfilieva I, 2005, ADV SOFT COMP, P221
   Perfilieva I, 2007, ACTA MATH U OSTRAV, V15, P27
   Perfilieva I., F TRANSFORM BASED IM
   Perfilieva I, 2008, INT J APPROX REASON, V48, P36, DOI 10.1016/j.ijar.2007.06.003
   Perfilieva I, 2010, INFORM SCIENCES, V180, P3304, DOI 10.1016/j.ins.2010.04.029
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shen R, 2013, IEEE T BIO-MED ENG, V60, P1069, DOI 10.1109/TBME.2012.2211017
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Stathaki T, 2011, Image fusion: algorithms and applications
   Stepnicka M., FUZZY TRANSFORM ITS
   VAJGL M, 2012, ADV FUZZY SYSTEMS, V2012, P4
   Vlasanek P., 2013, 8 C EUR SOC FUZZ LOG
   Vlasánek P, 2013, ADV FUZZY SYST, V2013, DOI 10.1155/2013/593694
   Wang J, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043019
   Wang L, 2013, IMAGING SCI J, V61, P529, DOI 10.1179/1743131X12Y.0000000016
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Zhiming, 2012, Proceedings 2012 IEEE Symposium on Electrical & Electronics Engineering (EEESYM 2012), P639, DOI 10.1109/EEESym.2012.6258740
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang Bo, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P6, DOI 10.1007/s12204-010-7186-y
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   Yong Yang, 2011, Journal of Multimedia, V6, P91, DOI 10.4304/jmm.6.1.91-98
   Yonghong J., 1998, Remote Sensing Technology and Application, V13, P46
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
NR 56
TC 58
Z9 61
U1 0
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 197
EP 217
DI 10.1016/j.jvcir.2016.06.021
PN A
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500019
DA 2024-07-18
ER

PT J
AU Noroozi, N
   Zakerolhosseini, A
AF Noroozi, Navid
   Zakerolhosseini, Ali
TI Computer assisted diagnosis of basal cell carcinoma using Z-transform
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skin cancer; Basal cell carcinoma; Squamous cell carcinoma; Fourier
   transform; Z-transform
ID HISTOPATHOLOGICAL IMAGES; PARALLEL FRAMEWORK; SEGMENTATION; MELANOCYTES;
   MELANOMA; DEPTH
AB Detection of basal cell carcinoma tumor is of great importance for decision making in the disease treatment procedure. Visual inspection of the histopathological slides for tumor detection is laborious, time consuming and prone to inter and intra observer variability. In this paper, we have proposed an automated method for discriminating basal cell carcinoma tumor from squamous cell carcinoma tumor in skin histopathological images using Z-transform features, which were not used previously in image classification tasks. For the first time, it is shown that how two or three Fourier transform features can be combined to form one Z-transform feature. Experiments have shown that the tumor classification results obtained by our method are in reasonable agreement with the gold standards provided by expert pathologists. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Noroozi, Navid; Zakerolhosseini, Ali] Shahid Beheshti Univ, Dept Comp Engn & Sci, Tehran, Iran.
C3 Shahid Beheshti University
RP Noroozi, N (corresponding author), Shahid Beheshti Univ, Dept Elect & Comp Engn, Tehran, Iran.
EM n_noroozi@sbu.ac.ir
CR Abramowitz M, 1972, Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables
   Akbar B, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1735, DOI 10.1109/ECS.2015.7124883
   Alan V., 1997, Oppenheim, Signals and systems
   Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50
   Arevalo J, 2015, ARTIF INTELL MED, V64, P131, DOI 10.1016/j.artmed.2015.04.004
   Arevalo J, 2013, PROC SPIE, V8922, DOI 10.1117/12.2035530
   Bishop ChristopherM., 1995, Neural_networks_for_pattern_recognition
   Caicedo JC, 2014, J BIOMED INFORM, V51, P114, DOI 10.1016/j.jbi.2014.04.016
   Corredor G, 2015, IEEE IMAGE PROC, P3200, DOI 10.1109/ICIP.2015.7351394
   Dass MV, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, ENERGY & COMMUNICATION (CIEC), P558, DOI 10.1109/CIEC.2014.6959151
   De Stefano Alessandro, 2012, Otolaryngol Pol, V66, P419, DOI 10.1016/j.otpol.2012.06.002
   Dundar MM, 2011, IEEE T BIO-MED ENG, V58, P1977, DOI 10.1109/TBME.2011.2110648
   Elder David E., 2007, LEVERS HISTOPATHOLOG
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Gordon Randy, 2013, Semin Oncol Nurs, V29, P160, DOI 10.1016/j.soncn.2013.06.002
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hongming Xu H., 2015, EURASIP J IMAGE VIDE, V18
   Huang PW, 2009, IEEE T MED IMAGING, V28, P1037, DOI 10.1109/TMI.2009.2012704
   Kalia S, 2012, DERMATOL CLIN, V30, P5, DOI 10.1016/j.det.2011.09.004
   Krishnan MMR, 2012, MICRON, V43, P352, DOI 10.1016/j.micron.2011.09.016
   Lu C., 2012, ANN INT C ENG MED BI
   Lu C, 2015, PATTERN RECOGN, V48, P2738, DOI 10.1016/j.patcog.2015.02.023
   Lu C, 2013, IEEE J BIOMED HEALTH, V17, P284, DOI 10.1109/TITB.2012.2199595
   Lu C, 2013, PATTERN RECOGN, V46, P509, DOI 10.1016/j.patcog.2012.07.020
   Meiping Tao, 2015, 2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P43, DOI 10.1109/IHMSC.2015.230
   Miranda G. H. B., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P316, DOI 10.1109/SIBGRAPI.2012.51
   Mokhtari M, 2014, MICRON, V61, P40, DOI 10.1016/j.micron.2014.02.001
   Noroozi N, 2016, COMPUT BIOL MED, V70, P23, DOI 10.1016/j.compbiomed.2015.12.024
   Noroozi N, 2015, MICRON, V77, P44, DOI 10.1016/j.micron.2015.05.007
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, DOI DOI 10.1049/EP.1977.0078
   Rahmadwati G.N., 2011, First IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology, P48
   Rathore S, 2014, COMPUT BIOL MED, V47, P76, DOI 10.1016/j.compbiomed.2013.12.010
   Rippey JJ, 1998, HISTOPATHOLOGY, V32, P393
   Romo-Bucheli D, 2015, I S BIOMED IMAGING, P1008, DOI 10.1109/ISBI.2015.7164041
   Shao-Kuo Tai, 2010, Proceedings of the 2010 6th International Conference on Digital Content, Multimedia Technology and its Applications (IDC 2010), P354
   Tabesh A, 2007, IEEE T MED IMAGING, V26, P1366, DOI 10.1109/TMI.2007.898536
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   Wang YH, 2009, IEEE J-STSP, V3, P112, DOI 10.1109/JSTSP.2008.2011157
   Xu HM, 2014, IEEE J BIOMED HEALTH, V18, P1729, DOI 10.1109/JBHI.2013.2297030
   Xu Zeke, 2013, INT C ADV INF COMM T
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 42
TC 10
Z9 11
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 128
EP 148
DI 10.1016/j.jvcir.2016.06.014
PN A
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500014
DA 2024-07-18
ER

PT J
AU Pun, CM
   Liu, B
   Yuan, XC
AF Pun, Chi-Man
   Liu, Bo
   Yuan, Xiao-Chen
TI Multi-scale noise estimation for image splicing forgery detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Splicing forgery; Multi-scale noise estimation; Noise level function;
   SLIC superpixels; Optimal Parameter Combination Searching (OPCS)
ID EXPOSING DIGITAL FORGERIES; NATURAL IMAGES; AUTHENTICATION; FORENSICS
AB Noise discrepancies in multiple scales are utilized as indicators for image splicing forgery detection in this paper. Specifically, the test image is initially segmented into superpixels of multiple scales. In each individual scale, noise level function, which reflects the relation between noise level and brightness of each segment, is computed. Those segments not constrained by the noise level function are regarded as suspicious regions. In the final step, pixels appears in suspicious regions of each scale, after necessary morphological processing, are marked as spliced region(s). The Optimal Parameter Combination Searching (OPCS) Algorithm is proposed to determine the optimal parameters during the process. Two datasets are created for training the optimal parameters and to evaluate the proposed scheme, respectively. The experimental results show that the proposed scheme is effective, especially for the multi-objects splicing. In addition, the proposed scheme is proven to be superior to the existing state-of-the-art method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pun, Chi-Man; Liu, Bo; Yuan, Xiao-Chen] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo; yb57413@umac.mo; xiaochen_yuan@ieee.org
RI Pun, Chi Man/GRJ-3703-2022; Yuan, Xiaochen/ABH-5255-2020; Liu,
   Bo/ACY-8290-2022
OI Yuan, Xiaochen/0000-0002-7490-6695; Liu, Bo/0000-0002-3164-6299; Pun,
   Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX This research was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (008/2013/A1,
   093-2014-A2).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], J ELECT IMAG
   [Anonymous], ELECT IMAGING 2007
   [Anonymous], 1986, Curve and Surface Fitting: An Introduction
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bethge M, 2006, J OPT SOC AM A, V23, P1253, DOI 10.1364/JOSAA.23.001253
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fu HZ, 2012, IEEE T INF FOREN SEC, V7, P1301, DOI 10.1109/TIFS.2012.2195492
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Li CT, 2010, IEEE INT SYMP CIRC S, P3052, DOI 10.1109/ISCAS.2010.5537994
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin S. D., 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1086, DOI 10.1109/CISP.2011.6100366
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Liu W, 2013, IEEE T IMAGE PROCESS, V22, P872, DOI 10.1109/TIP.2012.2219544
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Lyu SW, 2009, NEURAL COMPUT, V21, P1485, DOI 10.1162/neco.2009.04-08-773
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Pan X., 2012, IEEE INT C COMPUTATI, P1
   Pan XY, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P15
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rao MP, 2014, IEEE T INF FOREN SEC, V9, P583, DOI 10.1109/TIFS.2014.2302895
   Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555
   Valenzise G, 2013, IEEE T INF FOREN SEC, V8, P335, DOI 10.1109/TIFS.2012.2234117
   Wei WM, 2010, IEEE T INF FOREN SEC, V5, P507, DOI 10.1109/TIFS.2010.2051254
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 36
TC 50
Z9 55
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 195
EP 206
DI 10.1016/j.jvcir.2016.03.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100017
DA 2024-07-18
ER

PT J
AU Zhou, ZJ
   Waqas, J
AF Zhou, Zhengjuan
   Waqas, Jadoon
TI Intrinsic structure based feature transform for image classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dimensionality reduction; Manifold learning; Subspace learning; Image
   classification
ID FACE RECOGNITION; DIMENSIONALITY REDUCTION; SPARSE REPRESENTATION;
   PARALLEL FRAMEWORK; COMPONENT ANALYSIS; HEVC; EIGENMAPS; GRAPHS
AB Most dimensionality reduction works construct the nearest-neighbor graph by using Euclidean distance between images; this type of distance may not reflect the intrinsic structure. Different from existing methods, we propose to use sets as input rather than single images for accurate distance calculation. The set named as neighbor circle consists of the corresponding data point and its neighbors in the same class. Then a supervised dimensionality reduction method is developed, i.e., intrinsic structure feature transform (ISFT), it captures the local structure by constructing the nearest-neighbor graph using the Log-Euclidean distance as measurements of neighbor circles. Furthermore, ISFT finds representative images for each class; it captures the global structure by using the projected samples of these representatives to maximize the between-class scatter measure. The proposed method is compared with several state-of-the-art dimensionality reduction methods on various publicly available databases. Extensive experimental results have demonstrated the effectiveness of the proposed approach. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhou, Zhengjuan] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Waqas, Jadoon] COMSATS Inst Informat Technol, Dept Comp Sci, Abbottabad 22060, Pakistan.
C3 Sichuan University; COMSATS University Islamabad (CUI)
RP Zhou, ZJ (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM zhengjuanzhou@yeah.net
RI Jadoon, Waqas/AAE-1358-2021
OI jadoon, Dr. waqas/0000-0002-9498-0008
CR [Anonymous], 2016, IEEE T CYBERN
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953
   Cai D., 1999, P NAT C ART INT, V22, P528
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Ding CT, 2015, PATTERN RECOGN, V48, P1734, DOI 10.1016/j.patcog.2014.08.025
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Einbeck J, 2005, STAT COMPUT, V15, P301, DOI 10.1007/s11222-005-4073-8
   Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852
   Gao QX, 2015, PATTERN RECOGN, V48, P2543, DOI 10.1016/j.patcog.2015.02.015
   Gorban A, 2005, COMPUTING, V75, P359, DOI 10.1007/s00607-005-0122-6
   Gorban A.N., 2008, PRINCIPAL MANIFOLDS, V58, DOI DOI 10.1007/978-3-540-73750-6_5
   Gou JP, 2013, COMPUT J, V56, P1063, DOI 10.1093/comjnl/bxs113
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kégl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu G., 2010, P INT C MACH LEARN, P663
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Martinez A.M., 1998, AR FACE DATABASE
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mosci S., 2007, Proceedings of ICML, P657
   Peng X, 2015, KNOWL-BASED SYST, V90, P14, DOI 10.1016/j.knosys.2015.10.005
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xiang SM, 2009, IEEE T KNOWL DATA EN, V21, P1285, DOI 10.1109/TKDE.2008.204
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   Zang F, 2011, NEUROCOMPUTING, V74, P2176, DOI 10.1016/j.neucom.2011.02.012
   Zhang W, 2006, PATTERN RECOGN, V39, P2240, DOI 10.1016/j.patcog.2006.05.011
NR 50
TC 2
Z9 3
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 735
EP 744
DI 10.1016/j.jvcir.2016.04.016
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100061
DA 2024-07-18
ER

PT J
AU Nejati, M
   Samavi, S
   Derksen, H
   Najarian, K
AF Nejati, Mansour
   Samavi, Shadrokh
   Derksen, Harm
   Najarian, Kayvan
TI Denoising by low-rank and sparse representations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Sparse representation; Low-rank matrix recovery;
   Nonlocal self-similarity; Random matrix theory; Dictionary learning;
   Rank minimization; Optimal singular value shrinkage
ID PRINCIPAL COMPONENT ANALYSIS; THRESHOLDING ALGORITHM; IMAGE; MATRIX;
   REGULARIZATION
AB Due to the ill-posed nature of image denoising problem, good image priors are of great importance for an effective restoration. Nonlocal self-similarity and sparsity are two popular and widely used image priors which have led to several state-of-the-art methods in natural image denoising. In this paper, we take advantage of these priors and propose a new denoising algorithm based on sparse and low-rank representation of image patches under a nonlocal framework. This framework consists of two complementary steps. In the first step, noise removal from groups of matched image patches is formulated as recovery of low-rank matrices from noisy data. This problem is then efficiently solved under asymptotic matrix reconstruction model based on recent results from random matrix theory which leads to a parameter free optimal estimator. Nonlocal learned sparse representation is adopted in the second step to suppress artifacts introduced in the previous estimate. Experimental results, demonstrate the superior denoising performance of the proposed algorithm as compared with the state-of-the-art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Nejati, Mansour; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
   [Derksen, Harm] Univ Michigan, Dept Math, Ann Arbor, MI 48109 USA.
   [Najarian, Kayvan] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
C3 Isfahan University of Technology; McMaster University; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan
RP Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM samavi@mcmaster.ca
RI nejati, mansour/HJP-0888-2023
OI Nejati, Mansour/0000-0001-5891-4460
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Baik J, 2006, J MULTIVARIATE ANAL, V97, P1382, DOI 10.1016/j.jmva.2005.08.003
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2013, IEEE T SIGNAL PROCES, V61, P4643, DOI 10.1109/TSP.2013.2270464
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chatterjee P, 2009, IEEE T IMAGE PROCESS, V18, P1438, DOI 10.1109/TIP.2009.2018575
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Chen K., 2013, REDUCED RANK REGRESS
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Davenport M. A., 2012, Introduction to Compressed Sensing
   Deledalle CA, 2012, J MATH IMAGING VIS, V43, P103, DOI 10.1007/s10851-011-0294-y
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Gavish M, 2014, IEEE T INFORM THEORY, V60, P5040, DOI 10.1109/TIT.2014.2323359
   Goossens B., 2008, 2008 International Workshop on Local and Non-Local Approximation in Image Processing, P143
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Kervrann C, 2008, INT J COMPUT VISION, V79, P45, DOI 10.1007/s11263-007-0096-2
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Lingala SG, 2011, IEEE T MED IMAGING, V30, P1042, DOI 10.1109/TMI.2010.2100850
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Nadakuditi RR, 2014, IEEE T INFORM THEORY, V60, P3002, DOI 10.1109/TIT.2014.2311661
   Nadler B, 2008, ANN STAT, V36, P2791, DOI 10.1214/08-AOS618
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Otazo R., 2014, Magn. Reson. Med
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Paul D, 2007, STAT SINICA, V17, P1617
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Shabalin AA, 2013, J MULTIVARIATE ANAL, V118, P67, DOI 10.1016/j.jmva.2013.03.005
   Shenlong Wang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P231, DOI 10.1007/978-3-642-37431-9_18
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Wang J, 2012, IEEE T SIGNAL PROCES, V60, P6202, DOI 10.1109/TSP.2012.2218810
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P763, DOI 10.1109/LSP.2013.2263135
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
   Zuo WM, 2014, IEEE T IMAGE PROCESS, V23, P2459, DOI 10.1109/TIP.2014.2316423
   Zuo WM, 2013, PROC CVPR IEEE, P1203, DOI 10.1109/CVPR.2013.159
NR 52
TC 26
Z9 28
U1 2
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 28
EP 39
DI 10.1016/j.jvcir.2016.01.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200003
DA 2024-07-18
ER

PT J
AU Tariq, J
   Kwong, S
   Yuan, H
AF Tariq, Junaid
   Kwong, Sam
   Yuan, Hui
TI HEVC intra mode selection based on Rate Distortion (RD) cost and Sum of
   Absolute Difference (SAD)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fast intra prediction; Low complexity video coding; Rough mode decision;
   Rate distortion cost prediction; High Efficiency Video Coding (HEVC);
   Image coding; Video coding; Video compression
ID DECISION; PREDICTION; EFFICIENCY; ALGORITHM
AB High Efficiency Video Coding (HEVC) encoder provides higher compression efficiency by offering 35 intra modes. However, the encoding complexity is increased due to more modes are involved in the decision process. Therefore, it is desired to build a fast intra prediction algorithm that is practical for real time application. In this paper, a quadratic approach for reducing intra coding complexity is proposed. Firstly, the relationship between the RD-cost and the SAD is investigated. Secondly, a model is proposed to estimate the RD-cost of all 35 intra modes using the quadratic relation, thus avoiding the computation of entropy coding, Hadamard cost, distortion, and transform. Experimental results demonstrate that the average time saving of the proposed approach is 31-38%, while the BD-Bit Rate increment is only 0.62-1.37%, respectively. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Tariq, Junaid; Kwong, Sam; Yuan, Hui] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Yuan, Hui] Shandong Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
C3 City University of Hong Kong; Shandong University; Shenzhen Research
   Institute, City University of Hong Kong; City University of Hong Kong
RP Kwong, S (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
EM contact2jt@yahoo.com; cssamk@cityu.edu.hk; yuanhui0325@gmail.com
RI Yuan, Hui/HDO-3699-2022; Yuan, Hui/B-6738-2013; Kwong, Sam/C-9319-2012
OI Yuan, Hui/0000-0001-5212-3393; Yuan, Hui/0000-0001-5212-3393; Kwong,
   Sam/0000-0001-7484-7261
FU City University of Hong Kong Strategic Grant [7004418]; National Natural
   Science Foundation of China [61272289, 61571274]; City University of
   Hong Kong Shenzhen Research Institute, Shenzhen, China; Young Scholars
   Program of Shandong University (YSPSDU) [2015WLJH39]
FX This work is supported in part by City University of Hong Kong Strategic
   Grant 7004418, and in part by the National Natural Science Foundation of
   China under Grants 61272289, 61571274; in part by the City University of
   Hong Kong Shenzhen Research Institute, Shenzhen, China; and in part by
   the Young Scholars Program of Shandong University (YSPSDU) under Grant
   2015WLJH39.
CR Bossen F., 2011, JCTVCG1200 ITUTVCEG
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Choi K, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.3.030502
   Gergel B., 2008, P VCEG 13 M AUST TX, P69
   Hao Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P568, DOI 10.1007/978-3-642-34778-8_53
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kim J, 2011, Proceedings of the BioNLP Shared Task 2011 Workshop, P1
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Liao KY, 2010, IEEE T CIRC SYST VID, V20, P38, DOI 10.1109/TCSVT.2009.2026946
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sheng Z., 2014, MULTIMEDIA MODELING, P6
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan H.L., JCTVCH0166 ITUT VCEG
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Winken Martin, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3693, DOI 10.1109/ICIP.2011.6116521
   YAN SQ, 2012, 2012 8 INT C SIGN IM, P225
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
   Zhang YF, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), DOI 10.1109/VCIP.2012.6410739
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhu C, 2009, IEEE T CIRC SYST VID, V19, P1183, DOI 10.1109/TCSVT.2009.2020264
   Zhu J, 2013, IEEE IMAGE PROC, P1977, DOI 10.1109/ICIP.2013.6738407
NR 28
TC 28
Z9 29
U1 1
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 112
EP 119
DI 10.1016/j.jvcir.2015.11.013
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600010
DA 2024-07-18
ER

PT J
AU Wang, YX
   Sun, SX
   Ding, XM
AF Wang Yongxiong
   Sun Shuxin
   Ding Xueming
TI A self-adaptive weighted affinity propagation clustering for key frames
   extraction on human action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Key frames extraction; 3D video sequences; Energy feature; Kinetic
   energy; Potential energy; Self-adaptive weighted AP clustering; SVM;
   Human activity recognition
ID REPRESENTATION
AB In this paper, we propose a novel approach for key frames extraction on human action recognition from 3D video sequences. To represent human actions, an Energy Feature (EF), combining kinetic energy and potential energy, is extracted from 3D video sequences. A Self-adaptive Weighted Affinity Propagation (SWAP) algorithm is then proposed to extract the key frames. Finally, we employ SVM to recognize human actions on the EFs of selected key frames. The experiments show the information including whole action course can be effectively extracted by our method, and we obtain good recognition performance without losing classification accuracy. Moreover, the recognition speed is greatly improved. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang Yongxiong] Univ Shanghai Sci & Technol, Key Lab Modem Opt Syst, Shanghai 200093, Peoples R China.
   Univ Shanghai Sci & Technol, Engn Res Ctr Opt Instrument & Syst, Minist Educ, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology
RP Wang, YX (corresponding author), Univ Shanghai Sci & Technol, Key Lab Modem Opt Syst, Shanghai 200093, Peoples R China.
EM wyxiong@usst.edu.cn
RI Yuan, Yu/KBQ-0606-2024
FU National Natural Science Foundation of China [61374039, 61403254];
   Hujiang Foundation of China [C14002, B1402/D1402, D15009]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant 61374039 and 61403254 and Hujiang
   Foundation of China (C14002, B1402/D1402 and D15009).
CR [Anonymous], 2008, ACM INT C MULT INF R, DOI [10.1145/1460096.1460169, DOI 10.1145/1460096.1460169]
   [Anonymous], COMPUT ENG DES
   [Anonymous], WORKSH MOD VERS EX C
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], 2012, COMP COMM TECHN RES
   [Anonymous], INT S 3D DAT PROC VI
   [Anonymous], P 9 WORKSH MULT MET
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], COMPUTER ENG NETWORK
   Azouji N, 2013, IRAN CONF MACH, P219, DOI 10.1109/IranianMVIP.2013.6779982
   Cao XB, 2012, IEEE T IND INFORM, V8, P168, DOI 10.1109/TII.2011.2172452
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Hu Y, 2011, COMM COM INF SC, V202, P535
   Jiang F, 2015, J MACH LEARN RES, V16, P227
   Liu C, 2010, IMAGE VISION COMPUT, V28, P825, DOI 10.1016/j.imavis.2009.07.009
   Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004
   [鲁伟明 Lu Weiming], 2012, [计算机研究与发展, Journal of Computer Research and Development], V49, P1762
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Schindler K., 2008, IEEE C COMPUTER VISI, P1
   Sun CY, 2009, LECT NOTES COMPUT SC, V5552, P727
   Tang DM, 2010, COMPUT BIOL CHEM, V34, P63, DOI 10.1016/j.compbiolchem.2009.11.001
   Wang YX, 2014, CHIN CONTR CONF, P4786, DOI 10.1109/ChiCC.2014.6895749
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xing Yan, 2012, Application Research of Computers, V29, P2524, DOI 10.3969/j.issn.1001-3695.2012.07.032
   Zhang SP, 2014, INFORM SCIENCES, V281, P635, DOI 10.1016/j.ins.2013.12.052
   Zhang X, 2010, IEEE INT CON MULTI, P1184, DOI 10.1109/ICME.2010.5583081
NR 28
TC 17
Z9 21
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 193
EP 202
DI 10.1016/j.jvcir.2015.09.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700018
DA 2024-07-18
ER

PT J
AU Gao, GR
   Liu, YP
   Labate, D
AF Gao, Guorong
   Liu, Yanping
   Labate, Demetrio
TI A two-stage shearlet-based approach for the removal of random-valued
   impulse noise in images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Inpainting; Morphological component analysis;
   Random-valued impulse noise; Shearlets; Wavelets; Image restoration;
   Salt-and-pepper noise
ID SWITCHING MEDIAN FILTER; PEPPER NOISE; CORRUPTED IMAGES; SALT;
   TRANSFORM; REPRESENTATIONS
AB In this paper, we introduce a novel two-stage denoising method for the removal of random-valued impulse noise (RVIN) in images. The first stage of our algorithm applies an impulse-noise detection routine that is a refinement of the HEIND algorithm and is very accurate in identifying the location of the noisy pixels. The second stage is an image inpainting routine that is designed to restore the missing information at those pixels that have been identified during the first stage. One of the novelties of our approach is that our inpainting routine takes advantage of the shearlet representation to efficiently recover the geometry of the original image. This method is particularly effective to eliminate jagged edges and other visual artifacts that frequently affect many RVIN denoising algorithms, especially at higher noise levels. We present extensive numerical demonstrations to show that our approach is very effective to remove random-valued impulse noise without any significant loss of fine-scale detail. Our algorithm compares very favourably against state-of-the-art methods in terms of both visual quality and quantitative measurements. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Gao, Guorong; Liu, Yanping] Northwest A&F Univ, Coll Sci, Yangling 712100, Shaanxi, Peoples R China.
   [Labate, Demetrio] Univ Houston, Dept Math, Houston, TX 77204 USA.
C3 Northwest A&F University - China; University of Houston System;
   University of Houston
RP Labate, D (corresponding author), Univ Houston, Dept Math, Houston, TX 77204 USA.
EM lypggr@sina.com; ypliu0626@sina.com; dlabate@math.uh.edu
RI liu, yan/HGV-1365-2022; liu, yan/HCI-5542-2022
FU NSF-DMS [1008900, 100579, 1320910]; Division Of Mathematical Sciences;
   Direct For Mathematical & Physical Scien [1320910, 1008900] Funding
   Source: National Science Foundation
FX Guorong Gao is grateful for the hospitality of the Department of
   Mathematics of the University of Houston where this work was completed.
   Demetrio Labate acknowledges support from grants NSF-DMS 1008900, 100579
   and 1320910.
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Burger M, 2009, SIAM J IMAGING SCI, V2, P1129, DOI 10.1137/080728548
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Donoho D, 2013, COMMUN PUR APPL MATH, V66, P1, DOI 10.1002/cpa.21418
   Duan F, 2010, IEEE SIGNAL PROC LET, V17, P647, DOI 10.1109/LSP.2010.2049515
   Easley G, 2013, MATH MODEL NAT PHENO, V8, P60, DOI 10.1051/mmnp/20138104
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Gao GR, 2015, OPTIK, V126, P467, DOI 10.1016/j.ijleo.2014.11.004
   Genzel M, 2014, SIAM J IMAGING SCI, V7, P2301, DOI 10.1137/140969452
   Guo K, 2013, MATH MODEL NAT PHENO, V8, P82, DOI 10.1051/mmnp/20138106
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Guo KH, 2012, J FOURIER ANAL APPL, V18, P488, DOI 10.1007/s00041-011-9209-y
   Guo KH, 2009, SIAM J IMAGING SCI, V2, P959, DOI 10.1137/080741537
   Hsieh MH, 2013, ENG APPL ARTIF INTEL, V26, P1333, DOI 10.1016/j.engappai.2012.10.012
   King EJ, 2014, J MATH IMAGING VIS, V48, P205, DOI 10.1007/s10851-013-0422-y
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Labate D., 2012, BOSTON
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Malgouyres F, 2002, IEEE T IMAGE PROCESS, V11, P1450, DOI 10.1109/TIP.2002.806241
   Nair MS, 2013, COMPUT ELECTR ENG, V39, P663, DOI 10.1016/j.compeleceng.2012.06.004
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Schönlieb CB, 2011, COMMUN MATH SCI, V9, P413
   Serra X. G., 2014, EURASIP J ADV SIGNAL, V64
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilscy M., 2011, SIGNAL IMAGE PROCESS, V2, P173
   Wu J, 2014, SIGNAL IMAGE VIDEO P, V8, P349, DOI 10.1007/s11760-012-0297-1
   Wu J, 2012, AEU-INT J ELECTRON C, V66, P847, DOI 10.1016/j.aeue.2012.03.002
   Wu J, 2011, PATTERN RECOGN LETT, V32, P1974, DOI 10.1016/j.patrec.2011.09.025
NR 32
TC 12
Z9 13
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 83
EP 94
DI 10.1016/j.jvcir.2015.07.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300007
DA 2024-07-18
ER

PT J
AU Sener, F
   Ikizler-Cinbis, N
AF Sener, Fadime
   Ikizler-Cinbis, Nazli
TI Two-person interaction recognition via spatial multiple instance
   embedding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human interaction recognition; Activity recognition; Multiple instance
   learning; Video retrieval; Video analysis; Human actions; Human
   interactions; Spatial embedding
ID MODELS
AB In this work, we look into the problem of recognizing two-person interactions in videos. Our method integrates multiple visual features in a weakly supervised manner by utilizing an embedding-based multiple instance learning framework. In our proposed method, first, several visual features that capture the shape and motion of the interacting people are extracted from each detected person region in a video. Then, two-person visual descriptors are formed. Since the relative spatial locations of interacting people are likely to complement the visual descriptors, we propose to use spatial multiple instance embedding, which implicitly incorporates the distances between people into the multiple instance learning process. Experimental results on two benchmark datasets validate that using two-person visual descriptors together with spatial multiple instance learning offers an effective way for inferring the type of the interaction. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Sener, Fadime] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   [Ikizler-Cinbis, Nazli] Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University; Hacettepe University
RP Ikizler-Cinbis, N (corresponding author), Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM fadime.sener@cs.bilkent.edu.tr; nazli@cs.hacettepe.edu.tr
RI Ikizler-Cinbis, Nazli/E-8961-2013
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [112E149]
FX This work was supported in part by the Scientific and Technological
   Research Council of Turkey (TUBITAK) Career Development Award numbered
   112E149.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Amores J, 2013, ARTIF INTELL, V201, P81, DOI 10.1016/j.artint.2013.06.003
   Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], ICPR
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], 2000, International Conference on Machine Learning (ICML)
   [Anonymous], IEEE C COMP VIS PATT
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta A, 2002, INT C PATT RECOG, P433, DOI 10.1109/ICPR.2002.1044748
   Delaitre V., 2010, Proceedings of the British Machine Vision Conference, P1, DOI DOI 10.5244/C.24.97
   Doran G, 2014, MACH LEARN, V97, P79, DOI 10.1007/s10994-013-5429-5
   Fathi A, 2012, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2012.6247805
   Gaidon A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.30
   Gaidon A, 2014, INT J COMPUT VISION, V107, P219, DOI 10.1007/s11263-013-0677-1
   Gartner T., 2002, P 19 INT C MACH LEAR, V2, P179
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ikizler-Cinbis N., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P452, DOI 10.1109/ICPR.2010.119
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22
   Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Leistner C., 2010, ECCV
   Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7
   Marín-Jiménez MJ, 2014, MACH VISION APPL, V25, P71, DOI 10.1007/s00138-013-0521-1
   Marín-Jiménez MJ, 2013, PATTERN RECOGN LETT, V34, P1819, DOI 10.1016/j.patrec.2012.10.018
   Maron O, 1998, ADV NEUR IN, V10, P570
   Mukherjee S, 2014, MACH VISION APPL, V25, P1033, DOI 10.1007/s00138-013-0589-7
   Park S, 2006, COMPUT VIS IMAGE UND, V102, P1, DOI 10.1016/j.cviu.2005.07.011
   Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24
   Patron-Perez Alonso., 2010, BMVC, V1, P2
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prabhakar K, 2012, LECT NOTES COMPUT SC, V7576, P383, DOI 10.1007/978-3-642-33715-4_28
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Ryoo M, 2010, UT INTERACTION DATAS
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Sapienza M., 2013, INT J COMPUT VISION, P1
   Solmaz B, 2013, MACH VISION APPL, V24, P1473, DOI 10.1007/s00138-012-0449-x
   Vahdat A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   van Gemeren C, 2014, LECT NOTES COMPUT SC, V8749, P101, DOI 10.1007/978-3-319-11839-0_9
   Viola P., 2006, Proceedings of Advances in Neural Information Processing Systems, V18, P1417
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang Y, 2012, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2012.6248095
   Yao B., 2010, 23 IEEE C COMP VIS P
   Yu G, 2012, LECT NOTES COMPUT SC, V7574, P693, DOI 10.1007/978-3-642-33712-3_50
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51
   Zhou Zhi-Hua, 2009, PROC ANN INT C MACH, V382, P1249
NR 56
TC 24
Z9 26
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 63
EP 73
DI 10.1016/j.jvcir.2015.07.016
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300005
DA 2024-07-18
ER

PT J
AU Chen, HM
   Zhao, C
   Sun, MT
   Drake, A
AF Chen, Haoming
   Zhao, Chen
   Sun, Ming-Ting
   Drake, Aaron
TI Adaptive intra-refresh for low-delay error-resilient video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error-resilience; Intra-refresh coding; Low delay; Video coding; IPPP
   coding; Refresh cycle-size; Refresh order; H.264
AB Low-delay and error-resilient video coding is critical for real-time video communication over wireless networks. Intra-refresh coding, which embeds intra coded regions into inter frames can achieve a relatively smooth bit-rate and terminate the error propagation caused by the transmission loss. In this paper, we proposed a novel linear model for the intra-refresh cycle-size selection adapting to the network packet loss rates and the motions in the video content. We also analyze issues in designing the intra-refresh coding pattern and the refresh order, and propose a strategy which can adapt to different cycle-size and obtain better R-D performance compared with traditional random intra-refresh and vertical-partition intra-refresh. Experimental results show that the linear cycle-size selection model works effectively, where a 3 dB improvement can be achieved compared with a fixed cycle-size. Also, with the proposed intra-refresh order, a 2.0% bitrate reduction is obtained in average compared with the vertical-partition intra-refresh. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Haoming; Zhao, Chen; Sun, Ming-Ting] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   [Drake, Aaron] T Mobile USA, Bellevue, WA USA.
C3 University of Washington; University of Washington Seattle
RP Chen, HM (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
EM eehmchen@ee.washington.edu; zhaochen@pku.edu.cn; sun@ee.washington.edu;
   Aaron.Drake@T-Mobile.com
CR Ali I., 2011, IEEE INT CON MULTI
   Ali I., 2012, INT C CONS EL ICCE 2
   [Anonymous], 1996, 138182 ISOIEC
   Bjontegaard G., 2001, Q616 VCEGM33 ITUT
   Chen HW, 2014, TOXICOL APPL PHARM, V280, P1, DOI 10.1016/j.taap.2014.07.024
   Chen QQ, 2007, IEEE COMMUN MAG, V45, P52, DOI 10.1109/MCOM.2007.284538
   Côté G, 1999, SIGNAL PROCESS-IMAGE, V15, P25, DOI 10.1016/S0923-5965(99)00022-3
   Dhondt Y, 2007, LECT NOTES COMPUT SC, V4678, P720
   Fleury M., 2014, Recent Patents Signal Process, V4, P32, DOI DOI 10.2174/2210686304666141009230832
   Gan T, 2005, IEEE T IMAGE PROCESS, V14, P189, DOI 10.1109/TIP.2004.840692
   Gao SS, 2003, IEEE T CIRC SYST VID, V13, P182, DOI 10.1109/TCSVT.2002.808434
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Morelos-Zaragoza R. H., 2006, ART ERROR CORRECTING
   Nunes P, 2009, IEEE IMAGE PROC, P3073, DOI 10.1109/ICIP.2009.5414493
   Schreier R., 2006, P INT C CONS EL ICCE
   Schreier RM, 2006, IEEE T CONSUM ELECTR, V52, P249
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu LY, 2006, IEEE SIGNAL PROC LET, V13, P84, DOI 10.1109/LSP.2005.861594
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 22
TC 11
Z9 12
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 294
EP 304
DI 10.1016/j.jvcir.2015.06.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600026
DA 2024-07-18
ER

PT J
AU Su, PC
   Suei, PL
   Chang, MK
   Lain, J
AF Su, Po-Chyi
   Suei, Pei-Lun
   Chang, Min-Kuan
   Lain, Jie
TI Forensic and anti-forensic techniques for video shot editing in
   H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Information forensics; Anti-forensics; Video tampering
   detection; Video shot editing; Coding mode prediction; Modification of
   Quantization indices; Group of Pictures; Quantization parameter
ID DEBLOCKING; COMPRESSION
AB This research investigates the forensics and anti-forensics of video editing operations, including shot insertion and deletion, which are common practices of content tampering. The proposed methodology is based on the fact that excessive prediction residuals in the H.264/AVC encoding may appear in the inter-coded frames that were intra-coded. For the anti-forensics, the relationships of coding modes in consecutive frames are employed to determine whether the intra-prediction can be applied during the re-encoding process of the tampered video. The correspondences of coding parameters and the bit-rates are then examined to predict the targeted distribution of quantization indices. Some nonzero indices are modified for satisfying the targeted distribution and generating a video that does not seem an edited one. Next, two forensic methods are presented. The first method evaluates the energy of resulting residuals after the deblocking filtering to reveal the editing operations that have been applied. The second method makes use of the rate control mechanism to check the quantization parameters. Although there exist certain limitations, the methods deserve more discussions under appropriate conditions. (C) 2015 Published by Elsevier Inc.
C1 [Su, Po-Chyi; Lain, Jie] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
   [Suei, Pei-Lun] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei, Taiwan.
   [Chang, Min-Kuan] Natl Chung Hsing Univ, Grad Inst Commun Engn, Taichung 40227, Taiwan.
C3 National Central University; Academia Sinica - Taiwan; National Chung
   Hsing University
RP Chang, MK (corresponding author), Natl Chung Hsing Univ, Grad Inst Commun Engn, Taichung 40227, Taiwan.
EM minkuanc@dragon.nchu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022; Chang, Min-Kuan/AAM-4077-2020
OI Su, Po-Chyi/0000-0002-7457-8409; Chang, Min-Kuan/0000-0002-0979-0892
FU Ministry of Science and Technology in Taiwan [MOST 102-2221-E-008-073,
   103-2221-E-008-080]
FX This research is supported by the Ministry of Science and Technology in
   Taiwan under Grants MOST 102-2221-E-008-073 and 103-2221-E-008-080.
CR [Anonymous], INT J PATTERN RECOGN
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Avcibas I, 2004, IEEE IMAGE PROC, P2645
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Garcia-Romero D, 2010, INT CONF ACOUST SPEE, P1806, DOI 10.1109/ICASSP.2010.5495407
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Gloe T., 2007, P 15 ACM INT C MULT
   He ZH, 2008, IEEE T MULTIMEDIA, V10, P1237, DOI 10.1109/TMM.2008.2004903
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Kraetzer C, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P63
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Milani S, 2012, IEEE INT WORKSH MULT, P112, DOI 10.1109/MMSP.2012.6343425
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Yeh CH, 2012, IET IMAGE PROCESS, V6, P534, DOI 10.1049/iet-ipr.2010.0545
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Yeh CH, 2009, MULTIMED TOOLS APPL, V44, P205, DOI 10.1007/s11042-009-0278-8
NR 27
TC 16
Z9 18
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 103
EP 113
DI 10.1016/j.jvcir.2015.02.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100010
DA 2024-07-18
ER

PT J
AU Liao, X
   Shu, CW
AF Liao, Xin
   Shu, Changwen
TI Reversible data hiding in encrypted images based on absolute mean
   difference of multiple neighboring pixels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Encrypted image; Reversible data hiding; Absolute mean difference;
   Multiple neighboring pixels; Data extraction; Image recovery;
   Extracted-bit error rate; Data embedding ratio
ID WATERMARKING; EXPANSION
AB Recently, with the development of cloud computing, more and more secret data are stored in cloud. Reversible data hiding in encrypted images is a technique that makes contribution to cloud data management in privacy preserving and data security. In previous works, Zhang and Hong presented two reversible dada hiding methods in encrypted images, respectively. However, Zhang's work neglected the pixels in the borders of image blocks, and Hong et al.'s research only considered two adjacent pixels of each pixel. In addition, their works only considered that all image blocks are embedded into additional data. In this paper, we propose a novel method of evaluating the complexity of image blocks, which considers multiple neighboring pixels according to the locations of different pixels. Furthermore, data embedding ratio is considered. Experiments show that this novel method can reduce average extracted-bit error rate when the block size is appropriate. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liao, Xin; Shu, Changwen] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Liao, Xin] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
   [Liao, Xin] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Hunan University; Chinese Academy of Sciences; Institute of Software,
   CAS; Chinese Academy of Sciences; Institute of Information Engineering,
   CAS
RP Liao, X (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM xinliao@hnu.edu.cn
RI Liao, Xin/ITT-1021-2023; Liao, Xin/X-2736-2018
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [61402162]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20130161120004]; China Postdoctoral Science Foundation [2014M560123];
   Hunan Provincial Natural Science Foundation of China [14JJ7024]; Young
   Teacher Foundation of Hunan University [531107040701]
FX This work is supported by National Natural Science Foundation of China
   (Grant No. 61402162), Specialized Research Fund for the Doctoral Program
   of Higher Education (Grant No. 20130161120004), China Postdoctoral
   Science Foundation (Grant No. 2014M560123), Hunan Provincial Natural
   Science Foundation of China (Grant No. 14JJ7024), Young Teacher
   Foundation of Hunan University (Grant No. 531107040701).
CR Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2008, IET INFORM SECUR, V2, P35, DOI 10.1049/iet-ifs:20070004
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puech W., 2008, P SEC FOR STEG WAT M, V6819
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 17
TC 226
Z9 255
U1 0
U2 84
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 21
EP 27
DI 10.1016/j.jvcir.2014.12.007
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000003
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Condorovici, RG
   Florea, C
   Vertan, C
AF Condorovici, Razvan George
   Florea, Corneliu
   Vertan, Constantin
TI Automatically classifying paintings with perceptual inspired descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Painting; Perceptual image features; Genre recognition; Anchoring
   theory; Dominant Color Volume; Gabor filters; Image classification; Late
   fusion
ID FEATURES; PAINTERS; SPACE
AB We propose a framework for the automatic recognition of artistic genre in digital representations of paintings. As we aim to contribute to a better understanding of art by humans, we extensively mimic low-level and medium-level human perception by relying on perceptually inspired features. While Gabor filter energy has been used for art description, Dominant Color Volume (DCV) and frameworks extracted using anchoring theory are novel in this field. To perform the actual genre recognition, we rely on a late fusion scheme based on combining Multi-Layer Perceptron (MLP) classified data with Support Vector Machines (SVM). The performance is evaluated on an extended database containing more than 4000 paintings from 8 different genres, outperforming the reported state of the art. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Condorovici, Razvan George; Florea, Corneliu; Vertan, Constantin] Univ Politehn Bucuresti, LAPI, Bucharest, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest
RP Condorovici, RG (corresponding author), Univ Politehn Bucuresti, LAPI, Splaiul Independetei 313, Bucharest, Romania.
EM rcondorovici@imag.pub.ro; corneliu.florea@upb.ro;
   constantin.vertan@upb.ro
RI Florea, Corneliu/B-5540-2012; Li, Mengqi/AAG-6804-2021; Vertan,
   Constantin/F-4459-2015
OI Florea, Corneliu/0000-0001-9754-6795; 
FU Sectoral Operational Programme Human Resources Development of the
   Romanian Ministry of Labor, Family and Social Protection
   [POSDRU/89/1.5/S/76903]
FX The work has been co-funded by the Sectoral Operational Programme Human
   Resources Development 2007-2013 of the Romanian Ministry of Labor,
   Family and Social Protection through the Financial Agreement
   POSDRU/89/1.5/S/76903.
CR [Anonymous], P EUR COMP GRAPH FOR
   [Anonymous], P EUR SIGN PROC C
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], P CREATE 2010 C
   [Anonymous], CONVEX OPTIMIZ
   [Anonymous], ICIP
   [Anonymous], ACM INT C MULT
   [Anonymous], EMPIRICAL STUD ARTS
   [Anonymous], 2011, Art and the Senses
   Arora RS, 2012, INT C PATT RECOG, P3541
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Condorovici RG, 2013, LECT NOTES COMPUT SC, V7944, P687
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Forman G, 2004, LECT NOTES ARTIF INT, V3202, P161
   Gilchrist A, 1999, PSYCHOL REV, V106, P795, DOI 10.1037/0033-295X.106.4.795
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855
   Keren D, 2002, INT C PATT RECOG, P474, DOI 10.1109/ICPR.2002.1048341
   Kumar P, 2005, J OPTIMIZ THEORY APP, V126, P1, DOI 10.1007/s10957-005-2653-6
   Li J, 2004, IEEE T IMAGE PROCESS, V13, P338, DOI 10.1109/TIP.2003.821349
   Li XJ, 1999, PERCEPT PSYCHOPHYS, V61, P771, DOI 10.3758/BF03206896
   Martinez K, 2002, P IEEE, V90, P28, DOI 10.1109/5.982403
   Michie D., 1994, MACHINE LEARNING NEU, V29
   Novak C. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P599, DOI 10.1109/CVPR.1992.223129
   Ramachandran V. S., 1999, Journal of Consciousness Studies, V6, P15
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Stork DG, 2009, LECT NOTES COMPUT SC, V5702, P9, DOI 10.1007/978-3-642-03767-2_2
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Wallraven C, 2009, COMPUT GRAPH-UK, V33, P484, DOI 10.1016/j.cag.2009.04.003
   Widjaja I, 2003, IEEE IMAGE PROC, P845
   Zeki S., 1999, Inner Vision: An Exploration of Art and the Brain
   Zujovic J., 2009, PROC IEEE INT WORKSH, P1
NR 34
TC 15
Z9 18
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 222
EP 230
DI 10.1016/j.jvcir.2014.11.016
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000020
DA 2024-07-18
ER

PT J
AU Zhang, M
   Zhang, K
   Feng, QH
   Wang, JZ
   Kong, J
   Lu, YH
AF Zhang, Ming
   Zhang, Ke
   Feng, Qinghe
   Wang, Jianzhong
   Kong, Jun
   Lu, Yinghua
TI A novel image retrieval method based on hybrid information descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hybrid information descriptors (HIDs); Mutual information descriptors
   (MIDs); Self information descriptors (SIDs); Visual perception
   mechanism; Image feature spaces; Multi-scale analysis; Content-based
   image retrieval (CBIR); Feature fusion
ID COLOR TEXTURE CLASSIFICATION; CONTOUR-DETECTION; FEATURES;
   REPRESENTATION; ATTENTION; MODEL; SHAPE
AB In this paper, we propose a novel image retrieval method called hybrid information descriptors (HIDs) consisting of mutual information descriptors (MIDs) and self information descriptors (SIDs). Based on the physiological structure of human eyes and visual perception mechanism, HIDs are designed to explore the internal correlations among different image feature spaces with image structure and multi-scale analysis, not only characterizing the low-level features, such as color, shape and texture, but also imitating the process of visual information transfer and perception in high-level understanding with the help of the proposed visual optimization model for feature fusion. Comparing with other existing methods applied to content-based image retrieval (CBIR) on four datasets, the usefulness and effectiveness of the HIDs are shown. Extensive experimental results can also demonstrate this. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Ming; Zhang, Ke; Feng, Qinghe; Wang, Jianzhong; Kong, Jun; Lu, Yinghua] NE Normal Univ, Sch Comp Sci & Informat Technol, Changchun 130117, Peoples R China.
   [Zhang, Ming; Zhang, Ke; Feng, Qinghe; Wang, Jianzhong; Kong, Jun; Lu, Yinghua] NE Normal Univ, Key Lab Intelligent Informat Proc, Changchun 130117, Peoples R China.
C3 Northeast Normal University - China; Northeast Normal University - China
RP Kong, J (corresponding author), NE Normal Univ, Sch Comp Sci & Informat Technol, Changchun 130117, Peoples R China.
EM zhangm545@nenu.edu.cn; kongjun@nenu.edu.cn
OI Feng, Qinghe/0000-0002-9124-761X
FU Fund of Jilin Provincial Science and Technology Department
   [20130206042GX, 20140204089GX]; Young Scientific Research Fund of Jilin
   Province Science and Technology Development Project [201201070,
   201201063, 20130522115JH]
FX This work is supported by the Fund of Jilin Provincial Science and
   Technology Department (No. 20130206042GX, No. 20140204089GX), Young
   Scientific Research Fund of Jilin Province Science and Technology
   Development Project (No. 201201070, No. 201201063, No. 20130522115JH).
CR Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Cao L.H., 1999, J COMPUT RES DEV 1, V36
   Das G, 2006, LECT NOTES COMPUT SC, V4071, P193
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Desimone R, 1998, PHILOS T R SOC B, V353, P1245, DOI 10.1098/rstb.1998.0280
   Grifin G., 2007, 7694 CAL I TECHN
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Hiremath PS, 2006, INT J COMPUT SCI NET, V6, P124
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Joseph JS, 1997, NATURE, V387, P805, DOI 10.1038/42940
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Marr D., 1982, Visual perception
   Mejdoub M, 2009, J VIS COMMUN IMAGE R, V20, P145, DOI 10.1016/j.jvcir.2008.12.003
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   NIEBUR E, 1998, ATTENTION BRAIN
   Norvig P, 2010, NATURE, V463, P26, DOI 10.1038/463026a
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Papari G, 2011, PATTERN RECOGN, V44, P1999, DOI 10.1016/j.patcog.2010.08.013
   Qiu GP, 2007, PATTERN RECOGN, V40, P1711, DOI 10.1016/j.patcog.2006.09.020
   Rallabandi VPS, 2008, KNOWL-BASED SYST, V21, P89, DOI 10.1016/j.knosys.2007.02.002
   Ren FJ, 2009, ELECTRON NOTES THEOR, V225, P303, DOI 10.1016/j.entcs.2008.12.082
   Serre T, 2007, PROG BRAIN RES, V165, P33, DOI 10.1016/S0079-6123(06)65004-8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Steinman S.B., 2002, Models of the visual system, P521
   THEEUWES J, 1993, ACTA PSYCHOL, V83, P93, DOI 10.1016/0001-6918(93)90042-P
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Ursino M, 2004, NEURAL NETWORKS, V17, P719, DOI 10.1016/j.neunet.2004.03.007
   Wang H., 2013, INT C MACHINE LEARNI, P352
   Wang H, 2013, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2013.398
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wolfe J. M., 2002, LEVELS PERCEPTION, P169
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yiming Yang, 1999, Information Retrieval, V1, P69, DOI 10.1023/A:1009982220290
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 42
TC 31
Z9 37
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1574
EP 1587
DI 10.1016/j.jvcir.2014.06.016
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100008
DA 2024-07-18
ER

PT J
AU Walia, E
   Pal, A
AF Walia, Ekta
   Pal, Aman
TI Fusion framework for effective color image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content based image retrieval; Lab color space; Color Difference
   Histogram; Angular Radial Transform; Borda Count; MM-max normalization;
   Z-score normalization; Fusion
ID WAVELET
AB This paper presents a novel framework for color image retrieval through combination of all the low level features, which gives higher retrieval accuracy. The Color Difference Histogram (CDH) and Angular Radial Transform (ART) features are exploited to capture color, texture and shape information of an image. The CDH algorithm is modified in order to make the proposed system more effective. The proposed fusion framework combines the ranking results of the aforementioned descriptors through various post-classification methods i.e. Borda Count method, Min-max and Z-score normalization. The maximum retrieval accuracy attained in terms of average precision using Min-max normalization on Wang's database is 78.3% when ART is applied on non-overlapping regions of the images. The proposed fusion framework is recommended because it improves the average retrieval accuracy by approximately 16% and 14% over CDH and ART respectively. Extensive experiments are carried out on different databases to establish the efficacy of the proposed scheme. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Walia, Ekta; Pal, Aman] South Asian Univ, Dept Comp Sci, New Delhi, India.
C3 South Asian University (SAU)
RP Walia, E (corresponding author), South Asian Univ, Dept Comp Sci, New Delhi, India.
EM wekta@yahoo.com; aman.pal2610@yahoo.in
CR Amanatiadis A, 2011, IET IMAGE PROCESS, V5, P493, DOI 10.1049/iet-ipr.2009.0246
   [Anonymous], [No title captured]
   [Anonymous], INT J IMAG ROBOT
   [Anonymous], CARDIOVASC HEMATOL D
   [Anonymous], MULTIMED TOOLS APPL
   Banerjee M, 2009, FUZZY SET SYST, V160, P3323, DOI 10.1016/j.fss.2009.02.024
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Gali R., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P243, DOI 10.1109/CICSyN.2012.52
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jalab H.A., 2011, IEEE C OP SYST ICOS, V1
   Kang JY, 2012, CHIN CONT DECIS CONF, P1326, DOI 10.1109/CCDC.2012.6244213
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Qi XJ, 2005, PATTERN RECOGN, V38, P2449, DOI 10.1016/j.patcog.2005.04.005
   Rahimi M., 2013, CONTENT BASED IMAGE, P1
   Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138
   Singh C, 2012, OPT LASER TECHNOL, V44, P2249, DOI 10.1016/j.optlastec.2012.02.030
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Subrahmanyam M, 2012, EXPERT SYST APPL, V39, P5104, DOI 10.1016/j.eswa.2011.11.029
   Ting HC, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P545, DOI 10.1109/ICIP.1998.723504
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zhi-Chun Huang, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P719, DOI 10.1109/ICMLC.2010.5580566
NR 38
TC 75
Z9 81
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1335
EP 1348
DI 10.1016/j.jvcir.2014.05.005
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100005
DA 2024-07-18
ER

PT J
AU Wang, RJ
   Yang, YT
   Chang, PC
AF Wang, Ren-Jie
   Yang, Ya-Ting
   Chang, Pao-Chi
TI Content-based image retrieval using H.264 intra coding features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image/video retrieval; H.264; Intra prediction; Video
   coding; Compression domain; Geometrical verification; Image search;
   Texture features
ID SHOT CHANGE DETECTION
AB Efficient multimedia retrieval has become a vital issue because more audio and video data are now available. This paper focuses on content-based image retrieval (CBIR) in the compression domain (CPD). The retrieval features are extracted based on I-frame coding information in H.264. This paper proposes using a local mode histogram as the texture feature to match images and applying the residual coefficients to filter non-confident modes. The geometrical correspondence between two images is also considered. The experimental results show that the proposed method can substantially reduce computational and memory resource consumption, and provides similar performance compared with methods that extract features from decompressed images. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Ren-Jie; Yang, Ya-Ting; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, Jhongli 320, Taiwan.
C3 National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli 320, Taiwan.
EM pcchang@ce.ncu.edu.tw
CR [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], P IEEE COMP SOC C CO
   Bescós J, 2004, IEEE T CIRC SYST VID, V14, P475, DOI 10.1109/TCSVT.2004.825546
   Edmundson David, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P587, DOI 10.1109/ICSPCC.2012.6335725
   Fazal-e-Malik, 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P425, DOI 10.1109/ICCISci.2012.6297283
   Ferman AM, 2002, IEEE T IMAGE PROCESS, V11, P497, DOI 10.1109/TIP.2002.1006397
   Girod B, 2011, IEEE MULTIMEDIA, V18, P86, DOI 10.1109/MMUL.2011.48
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Nya P.N., 2000, ISO WG11 MPEG M GEN
   Quan X, 2005, I C WIREL COMM NETW, P1253
   Schaefer Gerald, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P318, DOI 10.1007/978-3-642-35236-2_32
   Simonea F.D., 2007, P SPIE OPTICS PHOTON, V6696
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sun Junding, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P349, DOI 10.1109/CIS.2009.67
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wang FP, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P258, DOI 10.1109/AVSS.2012.46
   Wang HL, 2003, J VIS COMMUN IMAGE R, V14, P150, DOI 10.1016/S1047-3203(03)00019-1
   Wang Y., 2011, P INT C INT SCI INF, P450
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yeo C., 2008, COMPRESSED DOMAIN VI
   Zargari F, 2010, IEEE T CONSUM ELECTR, V56, P728, DOI 10.1109/TCE.2010.5505994
   Zeng W, 2005, IEEE INT SYMP CIRC S, P3459
   Zhang XH, 2005, Fifth International Conference on Computer and Information Technology - Proceedings, P629, DOI 10.1109/CIT.2005.50
   Zhong D, 2005, PATTERN RECOGN LETT, V26, P2272, DOI 10.1016/j.patrec.2005.04.012
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
   Zhou XS, 2001, PATTERN RECOGN LETT, V22, P457, DOI 10.1016/S0167-8655(00)00124-0
   Zhu M., 2004, 9 U WAT DEP STAT ACT
   Zhuo L, 2013, SIGNAL PROCESS, V93, P2126, DOI 10.1016/j.sigpro.2012.07.003
NR 28
TC 6
Z9 6
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 963
EP 969
DI 10.1016/j.jvcir.2014.02.016
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200024
DA 2024-07-18
ER

PT J
AU Chen, CY
   Chien, HJ
AF Chen, Chia-Yen
   Chien, Hsiang-Jen
TI Geometric calibration of a multi-layer LiDAR system and image sensors
   using plane-based implicit laser parameters for textured 3-D depth
   reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sensor calibration; Multi-layer LiDAR system; Depth sensing; Light
   detection and ranging; Plane detection; Camera calibration; LiDAR
   calibration; 3-D reconstruction
AB The paper proposes the calibration of a LiDAR-camera system that consists of a multi-layer laser rangefinder device and a pair of video cameras. The method calibrates the intrinsic laser parameters and the extrinsic parameters of the integrated LiDAR-camera system. Using a linear form, the dimensionality of the calibration parameter space is reduced in the plane-based least square model. The optimal laser intrinsic parameters can be determined during the optimization of the extrinsic parameters, without being explicitly modeled. However, due to limited FOV of the cameras, the reduced model may lead to a solution that cannot be generalized to the working space. Hence, we use additional scene planes to improve the determination of intrinsic laser parameters. Overall performance is improved if calibration targets can be accurately estimated from the cameras. Results indicate a reduction of 50% in the flatness error is achievable and running time of the process is also decreased. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Chia-Yen; Chien, Hsiang-Jen] Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
C3 National University Kaohsiung
RP Chen, CY (corresponding author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, 700 Kaohsiung Univ Rd, Kaohsiung, Taiwan.
EM ayen@nuk.edu.tw
RI zhen, wang/KBA-3844-2024
OI Chien, Hsiang-Jen/0000-0003-1161-7922
FU National Science Council of Taiwan [NSC 102-2221-E-390-021]
FX We would like to thank the National Science Council of Taiwan for
   sponsoring this work under grant number NSC 102-2221-E-390-021.
CR [Anonymous], 2012, VEL HDL 64E S2 MAN
   Atanacio-Jiménez G, 2011, INT J ADV ROBOT SYST, V8, P70, DOI 10.5772/50900
   Badino H., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P405, DOI 10.1109/3DIMPVT.2011.58
   Bae K., 2007, P ISPRS WORKSH LAS S, P12
   Bileschi Stanley, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1457, DOI 10.1109/ICCVW.2009.5457439
   Glennie C., 2011, J REMOTE SENS, V2, P1610
   Glennie C, 2011, REMOTE SENS-BASEL, V3, P539, DOI 10.3390/rs3030539
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Huang LL, 2009, IEEE INT VEH SYM, P117, DOI 10.1109/IVS.2009.5164263
   John M., NY TIMES
   Mirzaei F. M., 2011, INT J ROBOT RES, P452
   Muhammad N., 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P5648, DOI 10.1109/IROS.2010.5651382
   Naroditsky Oleg, 2011, IEEE International Conference on Robotics and Automation, P3429
   Nunez P., 2009, European Conference on Mobile Robots ECMR'09, P31
   OpenCV, 2012, OP SOURC COMP VIS LI
   Pandey G., 2010, IFAC Proc., V43, P336, DOI 10.3182/20100906-3-IT-2019.00059
   Ranjith U., 2005, CMURITR0509
   Rodriguez F Sergio A., 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P214, DOI 10.1109/MFI.2008.4648067
   Zhang Q. L., 2004, 2004 IEEERSJ INT C I, P2301
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 20
TC 11
Z9 11
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 659
EP 669
DI 10.1016/j.jvcir.2013.08.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500006
DA 2024-07-18
ER

PT J
AU Huang, J
   Yang, XP
   Chen, YM
   Tang, LM
AF Huang, Jie
   Yang, Xiaoping
   Chen, Yunmei
   Tang, Liming
TI Ultrasound kidney segmentation with a global prior shape
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active contour; Super-ellipse; Fisher-Tippett; Convex relaxation;
   Kidney; Segmentation; Maximum likelihood; Split Bregman
ID ACTIVE CONTOURS; MODELS; IMAGES; APPROXIMATIONS; SPECKLE
AB In this paper, we focus on segmentation of ultrasound kidney images. Unlike previous work by using trained prior shapes, we employ a parametric super-ellipse as a global prior shape for a human kidney. The Fisher-Tippett distribution is employed to describe the grey level statistics. Combining the grey level statistics with a global character of a kidney shape, we propose a new active contour model to segment ultrasound kidney images. The proposed model involves two subproblems. One subproblem is to optimize the parameters of a super-ellipse. Another subproblem is to segment an ultrasound kidney image. An alternating minimization scheme is used to optimize the parameters of a super-ellipse and segment an image simultaneously. To segment an image fast, a convex relaxation method is introduced and the split Bregman method is incorporated to propose a fast segmentation algorithm. The efficiency of the proposed method is illustrated by numerical experiments on both simulated images and real ultrasound kidney images. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Huang, Jie; Yang, Xiaoping] Nanjing Univ Sci & Technol, Dept Appl Math, Nanjing 210094, Jiangsu, Peoples R China.
   [Chen, Yunmei] Univ Florida, Dept Math, Gainesville, FL 32611 USA.
   [Tang, Liming] PLA Nanjing Gen Hosp, Dept Med Engn, Nanjing 210002, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; State University System of
   Florida; University of Florida
RP Huang, J (corresponding author), Nanjing Univ Sci & Technol, Dept Appl Math, Nanjing 210094, Jiangsu, Peoples R China.
EM colourfulhj@163.com; yangxp@mail.njust.edu.cn; yun@math.ufl.edu;
   njtanglm@163.com
RI yang, xiao/HJI-7815-2023
FU National Natural Science Foundation of China [11101218]; Postgraduates
   Research Innovation Foundation of Jiangsu Province [CX10B-129Z]
FX Supported by National Natural Science Foundation of China (No. 11101218)
   and Postgraduates Research Innovation Foundation of Jiangsu Province
   (No. CX10B-129Z).
CR Ben Ayed I, 2004, IEEE IMAGE PROC, P2717
   BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966
   Bresson X., J MATH IMAGING VISIO, V28
   BURCKHARDT CB, 1978, IEEE T SON ULTRASON, V25, P1, DOI 10.1109/T-SU.1978.30978
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x
   Chen F, 2012, J VIS COMMUN IMAGE R, V23, P1085, DOI 10.1016/j.jvcir.2012.07.006
   Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985
   Chen YM, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P145, DOI 10.1109/VLSM.2001.938893
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cremers D, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P137, DOI 10.1109/VLSM.2001.938892
   Dogra DP, 2012, J VIS COMMUN IMAGE R, V23, P150, DOI 10.1016/j.jvcir.2011.09.005
   Dutt V, 1996, J ACOUST SOC AM, V99, P3817, DOI 10.1121/1.414999
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gong LX, 2004, IEEE T MED IMAGING, V23, P340, DOI 10.1109/TMI.2004.824237
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Lee S, 2010, J VIS COMMUN IMAGE R, V21, P665, DOI 10.1016/j.jvcir.2010.04.005
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   Leventon ME, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P4, DOI 10.1109/MMBIA.2000.852354
   Marcuzzo M, 2007, P ANN INT IEEE EMBS, P3438, DOI 10.1109/IEMBS.2007.4353070
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   Riklin-Raviv T, 2004, LECT NOTES COMPUT SC, V2034, P50
   Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93
   Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209
   Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78
   Saroul L, 2008, I S BIOMED IMAGING, P129, DOI 10.1109/ISBI.2008.4540949
   Sarti A, 2005, IEEE T ULTRASON FERR, V52, P947, DOI 10.1109/TUFFC.2005.1504017
   Shafei B, 2012, J VIS COMMUN IMAGE R, V23, P611, DOI 10.1016/j.jvcir.2012.02.006
   Shen DG, 2003, IEEE T MED IMAGING, V22, P539, DOI 10.1109/TMI.2003.809057
   SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Tao Z, 2006, IEEE T MED IMAGING, V25, P1483, DOI 10.1109/TMI.2006.881376
   THIJSSEN JM, 1988, ULTRASONIC IMAGING, V10, P171, DOI 10.1016/0161-7346(88)90113-7
   Tsai A, 2001, PROC CVPR IEEE, P463
   Udrea RM, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2713739
   VEMURI BC, 1994, ACM T GRAPHIC, V13, P177, DOI 10.1145/176579.176583
   Vizireanu N, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3134142
   WAGNER RF, 1983, IEEE T SON ULTRASON, V30, P156, DOI 10.1109/T-SU.1983.31404
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 47
TC 24
Z9 26
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 937
EP 943
DI 10.1016/j.jvcir.2013.05.013
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700018
DA 2024-07-18
ER

PT J
AU Xie, HT
   Zhang, YD
   Gao, K
   Tang, S
   Xu, KF
   Guo, L
   Li, JT
AF Xie, Hongtao
   Zhang, Yongdong
   Gao, Ke
   Tang, Sheng
   Xu, Kefu
   Guo, Li
   Li, Jintao
TI Robust common visual pattern discovery using graph matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Common visual pattern; Graph matching; Maximal clique; Quadratic
   optimization; Feature correspondence; Point set matching; Object
   recognition; Near-duplicate image retrieval
ID ALGORITHM; MODEL
AB Discovering common visual patterns (CVPs) between two images is a difficult and time-consuming task, due to the photometric and geometric transformations. The state-of-the-art methods for CVPs discovery are either computationally expensive or have complicated constraints. In this paper, we formulate CVPs discovery as a graph matching problem, depending on pairwise geometric compatibility between feature correspondences. To efficiently find all CVPs, we propose a novel framework which consists of three components: Preliminary Initialization Optimization (PIO), Guided Expansion (GE) and Post Agglomerative Combination (PAC). PIO gets the initial CVPs and reduces the search space of CVPs discovery, based on the internal homogeneity of CVPs. Then, GE anchors on the initializations and gradually explores them, to find more and more correct correspondences. Finally, to reduce false and miss detection, PAC refines the discovery result in an agglomerative way. Experiments and applications conducted on benchmark datasets demonstrate the effectiveness and efficiency of our method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Xie, Hongtao; Zhang, Yongdong; Gao, Ke; Tang, Sheng; Li, Jintao] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Adv Comp Res Lab, Beijing 100864, Peoples R China.
   [Xie, Hongtao; Xu, Kefu; Guo, Li] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing 100864, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; Institute of Information Engineering, CAS
RP Zhang, YD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Adv Comp Res Lab, Beijing 100864, Peoples R China.
EM xiehongtao@iie.ac.cn; zhyd@ict.ac.cn; kegao@ict.ac.cn; ts@ict.ac.cn;
   xukefu@iie.ac.cn; guo-li@iie.ac.cn; jtli@ict.ac.cn
FU National Nature Science Foundation of China [61271428, 61273247];
   National Key Technology Research and Development Program of China
   [2012BAH39B02]; Beijing Municipal Education Commission; Chinese Academy
   of Sciences [XDA06030200]
FX This work is supported by the National Nature Science Foundation of
   China (61271428, 61273247); National Key Technology Research and
   Development Program of China (2012BAH39B02); Co-building Program of
   Beijing Municipal Education Commission; "Strategic Priority Research
   Program" of the Chinese Academy of Sciences (Grant No. XDA06030200).
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], BINARIES AFFINE COVA
   [Anonymous], 2010, P ACM MULTIMEDIA
   Berg AC, 2005, PROC CVPR IEEE, P26
   Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28
   Cho M, 2009, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2009.5459322
   Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492
   Chu WT, 2011, J VIS COMMUN IMAGE R, V22, P93, DOI 10.1016/j.jvcir.2010.10.008
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Chum O., 2004, P AS C COMP VIS, P27
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cour T., 2006, Neural Information Processing Systems
   Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619
   Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Grauman K., 2006, CVPR 1, P19
   Hong PY, 2004, DISCRETE APPL MATH, V139, P113, DOI 10.1016/j.dam.2002.11.007
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048
   Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Leordeanu M., 2009, Neural Information Processing Systems
   Leordeanu M., 2011, P IEEE INT C COMP VI
   Leordeanu M, 2009, PROC CVPR IEEE, P864, DOI 10.1109/CVPRW.2009.5206533
   Li HS, 2010, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2010.5539776
   Liu H., 2010, INT C MACH LEARN HAI
   Liu HR, 2010, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2010.5539780
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nister David, 2006, CVPR
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Tan HK, 2009, IMAGE VISION COMPUT, V27, P1470, DOI 10.1016/j.imavis.2009.01.002
   Torki M, 2010, PROC CVPR IEEE, P3058, DOI 10.1109/CVPR.2010.5540059
   Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44
   Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8
   Weibull J. W., 1997, EVOLUTIONARY GAME TH
   Xie Hongtao, 2011, ACM INT C MULT RETR
   Yuan JS, 2007, IEEE I CONF COMP VIS, P321
   Zass Ron., 2008, CVPR
   Zhipeng Wu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P842, DOI 10.1109/ICPR.2010.212
NR 43
TC 22
Z9 24
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 635
EP 646
DI 10.1016/j.jvcir.2013.04.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900012
DA 2024-07-18
ER

PT J
AU Liu, NN
   Lu, JW
   Yang, G
   Tan, YP
AF Liu, Nini
   Lu, Jiwen
   Yang, Gao
   Tan, Yap-Peng
TI Robust gait recognition via discriminative set matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview gait recognition; Subspace distance; Set-to-set matching
ID FACE RECOGNITION; VIEW; FRAMEWORK
AB In this paper, we propose a framework for gait recognition across varying views and walking conditions based on gait sequences collected from multiple viewpoints. Different from most existing view-dependent gait recognition systems, we devise a new Multiview Subspace Representation (MSR) method which considers gait sequences collected from different views of the same subject as a feature set and extracts a linear subspace to describe the feature set. Subspace-based feature representation methods measure the variances among samples, and can handle certain intra-subject variations. To better exploit the discriminative information from these subspaces for recognition, we further propose a marginal canonical correlation analysis (MCCA) method which maximizes the margins of interclass subspaces within a neighborhood. Experimental results on a widely used multiview gait database are presented to demonstrate the effectiveness of the proposed framework. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Liu, Nini; Yang, Gao; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Lu, Jiwen] Adv Digital Sci Ctr, Singapore 138632, Singapore.
C3 Nanyang Technological University
RP Liu, NN (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM e070042@e.ntu.edu.sg
RI Tan, Yap-Peng/A-5158-2011; Lu, Jiwen/C-5291-2009
OI Lu, Jiwen/0000-0002-6121-5529
FU Agency for Science, Technology and Research (A*STAR) of Singapore
FX Jiwen Lu is supported by the research grant for the Human Sixth Sense
   Program at the Advanced Digital Sciences Center (ADSC) from the Agency
   for Science, Technology and Research (A*STAR) of Singapore.
CR Abou-Moustafa K.T., 2010, P IEEE 23 C COMP VIS
   [Anonymous], 2001, Cmu Ri Tr 01-18
   Aqmar M. R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2190, DOI 10.1109/ICPR.2010.536
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fukui K., 2003, 11 INT S ROBOTICS RE, P192
   GERBRANDS JJ, 1981, PATTERN RECOGN, V14, P375, DOI 10.1016/0031-3203(81)90082-0
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Han PY, 2011, J VIS COMMUN IMAGE R, V22, P634, DOI 10.1016/j.jvcir.2011.07.009
   Han PY, 2009, J VIS COMMUN IMAGE R, V20, P532, DOI 10.1016/j.jvcir.2009.08.003
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huang GC, 2007, LECT NOTES COMPUT SC, V4843, P462
   Huang XX, 2008, INT CONF ACOUST SPEE, P1705
   KAILATH T, 1974, IEEE T INFORM THEORY, V20, P146, DOI 10.1109/TIT.1974.1055174
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Li F, 2009, IEEE SIGNAL PROC LET, V16, P227, DOI 10.1109/LSP.2008.2010819
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li JW, 2005, LECT NOTES COMPUT SC, V3546, P229
   Liu NN, 2011, IEEE INT CON MULTI
   Liu NN, 2011, IEEE SIGNAL PROC LET, V18, P431, DOI 10.1109/LSP.2011.2157143
   Liu XM, 2003, PROC CVPR IEEE, P340
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Lu JW, 2007, PATTERN RECOGN LETT, V28, P2401, DOI 10.1016/j.patrec.2007.08.004
   Lu JW, 2010, PATTERN RECOGN LETT, V31, P382, DOI 10.1016/j.patrec.2009.11.006
   Nishiyama M, 2005, LECT NOTES COMPUT SC, V3546, P71
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Satoh S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P163, DOI 10.1109/AFGR.2000.840629
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   Sugiura K, 2007, LECT NOTES COMPUT SC, V4843, P452
   Wang F., 2007, IEEE C COMP VIS PATT, P2190
   Wang YA, 2006, LECT NOTES COMPUT SC, V3832, P605
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang D., 2010, IEEE COMP SOC IEEE B, P1
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
NR 41
TC 10
Z9 13
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 439
EP 447
DI 10.1016/j.jvcir.2013.02.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400001
DA 2024-07-18
ER

PT J
AU Zhang, Z
   Shi, YH
   Ding, WP
   Yin, BC
AF Zhang, Zhen
   Shi, Yunhui
   Ding, Wenpeng
   Yin, Baocai
TI MR images reconstruction based on TVWL2-L1 model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; MR image reconstruction; Convex optimization;
   Wavelet transform; Total variation
ID THRESHOLDING ALGORITHM
AB Compressive sensing (CS) theory, which has been widely used in magnetic resonance (MR) image processing, indicates that a sparse signal can be reconstructed by the optimization programming process from non-adaptive linear projections. Since MR Images commonly possess a blocky structure and have sparse representations under certain wavelet bases, total variation (TV) and wavelet domain norm regularization are enforced together (TV-wavelet Ll method) to improve the recovery accuracy. However, the components of wavelet coefficients are different: low-frequency components of an image, that carry the main energy of the MR image, perform a decisive impact for reconstruction quality. In this paper, we propose a TV and wavelet L2-L1 model (TVWL2-L1) to measure the low frequency wavelet coefficients with 2 norm and high frequency wavelet coefficients with l(1) norm. We present two methods to approach this problem by operator splitting algorithm and proximal gradient algorithm. Experimental results demonstrate that our method can obviously improve the quality of MR image recovery comparing with the original TV-wavelet method. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zhang, Zhen; Shi, Yunhui; Ding, Wenpeng; Yin, Baocai] Beijing Univ Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Shi, YH (corresponding author), Beijing Univ Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
EM syhzm@bjut.edu.cn
FU National Natural Science Foundation of China [61033004, 60825203,
   60973056, U0935004]; Beijing Natural Science Foundation [4102009]; 
   [2011CB302703]
FX The authors thank the authors of TVCMRI for making their excellent codes
   available on line. The authors thank the authors of FCSA for making
   their excellent codes available on line. The authors thank 973
   (2011CB302703), the National Natural Science Foundation of China (Nos.
   61033004, 60825203, 60973056, U0935004), Beijing Natural Science
   Foundation (4102009).
CR Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Donoho D., 2006, SPARSE SOLUTION UNDE
   Eckstein J, 2009, SIAM J CONTROL OPTIM, V48, P787, DOI 10.1137/070698816
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Goldfarb D., ARXIV09124570
   Gurin L. G., 1967, USSR Computational Mathematics and Physics, V7, P1, DOI DOI 10.1016/0041-5553(67)90113-9
   Huang JZ, 2011, MED IMAGE ANAL, V15, P670, DOI 10.1016/j.media.2011.06.001
   Iwen M A, 2008, 43 ANN C INF SCI SYS, P870
   LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Ma S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587391
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
NR 20
TC 7
Z9 8
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 187
EP 195
DI 10.1016/j.jvcir.2012.05.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000012
DA 2024-07-18
ER

PT J
AU Wu, XT
   Sun, W
AF Wu, Xiaotian
   Sun, Wei
TI Random grid-based visual secret sharing with abilities of OR and XOR
   decryptions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; Visual cryptography; Random grid; OR; XOR;
   Decryption; Visual quality; Contrast
ID IMAGE ENCRYPTION; PERFECT RECONSTRUCTION; COLOR IMAGES; CRYPTOGRAPHY;
   SCHEME; ALGORITHM
AB Random grid (RG) is a methodology to construct visual secret sharing (VSS) scheme without pixel expansion. In some reported RG-based VSS schemes, a secret image can be visually reconstructed only by stacking operation, even thought some light-weight computational devices are available. In this paper, a novel RG-based VSS is developed, where the secret image can be recovered in two situations: (1) when computational devices are not available, the secret image can be reconstructed by stacking the shares directly, and (2) when some light-weight computational devices are available, the secret image can be decrypted by XOR operation. Further, the decrypted secret image quality by stacking operation is approximately the same as that of conventional RG-based VSS. But better visual quality is obtained by XOR operation. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Wu, Xiaotian] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Sun, W (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM sunwei@mail.sysu.edu.cn
OI Wu, Xiaotian/0000-0002-1484-2247
FU Macao Special Administrative Region [006/2001/A1]; Sun Yat-sen
   University
FX This work was partially supported by Science and Technology Development
   Fund of Macao Special Administrative Region under Contract 006/2001/A1
   and innovative talent training program of Sun Yat-sen University. The
   authors gratefully acknowledge the helpful comments and suggestions of
   the reviewers, which have improved the presentation.
CR Alvarez G, 2008, INFORM SCIENCES, V178, P4382, DOI 10.1016/j.ins.2008.07.010
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Blaldey G. R., 1979, P NAT COMP C, V88, P317
   Blundo C, 1998, COMPUT GRAPH, V22, P449, DOI 10.1016/S0097-8493(98)00034-X
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chen SK, 2012, J VIS COMMUN IMAGE R, V23, P677, DOI 10.1016/j.jvcir.2012.03.004
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Koga H, 2006, DESIGN CODE CRYPTOGR, V40, P81, DOI 10.1007/s10623-005-6700-y
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2010, OPT COMMUN, V283, P4242, DOI 10.1016/j.optcom.2010.06.042
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
NR 24
TC 66
Z9 70
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 48
EP 62
DI 10.1016/j.jvcir.2012.11.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600006
DA 2024-07-18
ER

PT J
AU Chen, YC
   Tsai, DS
   Horng, G
AF Chen, Yu-Chi
   Tsai, Du-Shiau
   Horng, Gwoboa
TI A new authentication based cheating prevention scheme in Naor-Shamir's
   visual cryptography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret sharing; Visual cryptography; Visual secret sharing; Human vision
   system; Cheating; Cheating prevention; Authentication; Security
ID SECRET; IMAGES
AB Visual cryptography (VC), first presented by Naor and Shamir, is a variant of secret sharing, thus it also called visual secret sharing. It can be widely used in many applications such as encrypting large data efficiently. In the literature, the problem of cheating is under consideration in secret sharing. Recently, Horng et al. pointed out that cheating is possible in k-out-of-n VC schemes, and presented two kinds of the cheating prevention schemes for protecting honest participants. One of them is the authentication based cheating prevention scheme. In this paper, we analyze the definition of cheating prevention and propose a new authentication based cheating prevention scheme. This scheme is constructed with Naor-Shamir's VC scheme. Finally, we give the security analysis to prove that the proposed scheme is immune to cheating. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Chen, Yu-Chi; Horng, Gwoboa] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung, Taiwan.
C3 National Chung Hsing University
EM wycchen@ieee.org; dstsai@hust.edu.tw; gbhomg@cs.nchu.edu.tw
OI Horng, Gwoboa/0000-0002-6899-7703; Chen, Yu-Chi/0000-0002-5577-0016
FU National Science Council of the Republic of China [100-2221-E-164-010,
   101-2221-E-005-083, 101-2221-E-164-016]
FX The authors thank the anonymous reviewers for their valuable comments
   that helped to improve the presentation of the paper. This work was
   partially supported by the National Science Council of the Republic of
   China, Nos. 100-2221-E-164-010, 101-2221-E-005-083, and
   101-2221-E-164-016.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blakley G., 1979, P AFIPS 1979 NAT C
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chen Y.C., 2011, 2011631 CRYPT, V2011
   Chen Y.C., 2011, J COMPUT, V22, P57
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   De Prisco R, 2010, COMPUT J, V53, P1485, DOI 10.1093/comjnl/bxp068
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Rijmen V., 1996, P ADV CRYPT EUR 96 R
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shamir A., 1996, IMPROVING CONTRAST C
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
NR 18
TC 27
Z9 29
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1225
EP 1233
DI 10.1016/j.jvcir.2012.08.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300006
DA 2024-07-18
ER

PT J
AU Phadikar, A
   Maity, SP
   Mandal, M
AF Phadikar, Amit
   Maity, Santi P.
   Mandal, Mrinal
TI Novel wavelet-based QIM data hiding technique for tamper detection and
   correction of digital images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semi-fragile watermarking; Data hiding; Tamper detection; Tamper
   correction; Quantization index modulation; Wavelets; Integer wavelets;
   Image half-toning
ID SEMI-FRAGILE WATERMARKING; QUALITY ACCESS-CONTROL; SCHEME;
   AUTHENTICATION; RECOVERY; SYSTEM; INDEX
AB This paper proposes a tamper detection and correction technique using semi-fragile data hiding that aims to achieve high perceptual quality of images at the user-end even after malicious modifications. A binary signature and an image digest are embedded by modulating integer wavelet coefficients using dither modulation based quantization index modulation. Half-toning technique is used to obtain image digest from the low-resolution version of the host image itself. Decoder extracts the binary signature from the watermarked image for tamper detection, while the extracted image digest is used to correct the tamper region. Unlike previously proposed techniques, this novel approach distinguishes malicious changes from various common image processing operations more efficiently and also correct tapered regions effectively. Experimental results show that the proposed technique provides a superior performance in terms of probability of miss and false alarm as well as in tamper correction, compared to several existing semi-fragile watermarking techniques. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Mandal, Mrinal] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   [Phadikar, Amit] MCKV Inst Engn, Dept Informat Technol, Liluah 711204, Howrah, India.
   [Maity, Santi P.] Bengal Engn & Sci Univ, Dept Informat Technol, Sibpur 711103, Howrah, India.
C3 University of Alberta; Indian Institute of Engineering Science
   Technology Shibpur (IIEST)
RP Mandal, M (corresponding author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
EM amitphadikar@rediffmail.com; santipmaity@it.-becs.ac.in;
   mmandal@ualberta.ca
RI Phadikar, Amit/CAE-9495-2022
CR Adsumilli CB, 2005, IEEE T CIRC SYST VID, V15, P1394, DOI 10.1109/TCSVT.2005.856933
   [Anonymous], DIGITAL WATERMARKING
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bovik AC, 2010, P IEEE, V98, P1799, DOI 10.1109/JPROC.2010.2068371
   Boyer J.P., 2006, P IEEE INT C AC SPEE, pII
   Campisi P, 2003, IEEE T SIGNAL PROCES, V51, P996, DOI 10.1109/TSP.2003.809381
   Chamlawi R, 2006, PROC WRLD ACAD SCI E, V17, P217
   Che S. B., 2008, P 4 INT C WIR COMM N, P1
   Chen B, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P273, DOI 10.1109/MMSP.1998.738946
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   COSTA MHM, 1983, IEEE T INFORM THEORY, V29, P439, DOI 10.1109/TIT.1983.1056659
   Ekici Ö, 2004, J ELECTRON IMAGING, V13, P209, DOI 10.1117/1.1633285
   Floyd R., 1975, SID, P36
   Fridrich J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P404, DOI 10.1109/ICIP.1998.723401
   Hu YP, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5484
   JIN C., 2009, INT C E BUS INF SYST, P1
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Li CF, 2010, SIGNAL PROCESS-IMAGE, V25, P517, DOI 10.1016/j.image.2010.03.004
   Li CT, 2004, IEE P-VIS IMAGE SIGN, V151, P460, DOI 10.1049/ip-vis:20040812
   Lin CH, 2007, J APPL SCI ENG, V10, P57
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Maity SP, 2009, COMPUT ELECTR ENG, V35, P415, DOI 10.1016/j.compeleceng.2008.06.003
   Mendoza Jose Antonio, 2008, 2008 5th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE), P292, DOI 10.1109/ICEEE.2008.4723404
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Phadikar Amit, 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P93, DOI 10.1109/ACT.2009.33
   Phadikar A., 2010, P 23 IEEE CAN C EL C, P1
   Phadikar A, 2009, ELCVIA ELECT LETT CO, V8, P51
   Phadikar A, 2011, SIGNAL PROCESS-IMAGE, V26, P646, DOI 10.1016/j.image.2011.07.008
   Phadikar A, 2010, AEU-INT J ELECTRON C, V64, P833, DOI 10.1016/j.aeue.2009.09.004
   Phen-Lan Lin, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P146
   Qin QM, 2004, INT GEOSCI REMOTE SE, P2542
   Queluz MP, 2002, J ELECTRON IMAGING, V11, P275, DOI 10.1117/1.1455015
   Song Q, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P76, DOI 10.1109/APCIP.2009.155
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tsai MJ, 2008, IEEE INT SYMP CIRC S, P3033, DOI 10.1109/ISCAS.2008.4542097
   Voloshynovskiy S, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA477
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong P.W., 1993, INVERSE HALFTONING K, P1
   Wu X., 2005, Proceedings of the Australasian Information security workshop (AISW 2005) on Grid computing and e-research, V44, P75
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Yang HF, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P1112
   Yang SY, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2282
   Yang Z. L., 2005, THESIS NATL DONG HWA
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Zhang Hong-bin, 2004, Acta Electronica Sinica, V32, P196
   STIRMARK BENCHMARK 4
NR 52
TC 38
Z9 42
U1 0
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 454
EP 466
DI 10.1016/j.jvcir.2012.01.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800005
DA 2024-07-18
ER

PT J
AU Cerra, D
   Datcu, M
AF Cerra, Daniele
   Datcu, Mihai
TI A fast compression-based similarity measure with applications to
   content-based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data compression; Normalized Compression Distance; Similarity measure;
   Parameter-free; Data mining; Image retrieval; Image classification; Hue
   Saturation Value
ID INFORMATION
AB Compression-based similarity measures are effectively employed in applications on diverse data types with a basically parameter-free approach. Nevertheless, there are problems in applying these techniques to medium-to-large datasets which have been seldom addressed. This paper proposes a similarity measure based on compression with dictionaries, the Fast Compression Distance (FCD), which reduces the complexity of these methods, without degradations in performance. On its basis a content-based color image retrieval system is defined, which can be compared to state-of-the-art methods based on invariant color features. Through the FCD a better understanding of compression-based techniques is achieved, by performing experiments on datasets which are larger than the ones analyzed so far in literature. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Cerra, Daniele; Datcu, Mihai] EOC, German Aerosp Ctr DLR, D-82234 Wessling, Germany.
C3 Helmholtz Association; German Aerospace Centre (DLR)
RP Cerra, D (corresponding author), EOC, German Aerosp Ctr DLR, D-82234 Wessling, Germany.
EM daniele.cerra@dlr.de
RI DATCU, Mihai/G-1655-2016
OI Cerra, Daniele/0000-0003-2984-8315
CR Androutsos D, 1999, COMPUT VIS IMAGE UND, V75, P46, DOI 10.1006/cviu.1999.0767
   [Anonymous], 1999, Advances in kernel methods: Support vector learning
   [Anonymous], NISTERSTEWENIUS DATA
   [Anonymous], FAWNS MEADOWS PROJEC
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bennett CH, 2003, SCI AM, V288, P76, DOI 10.1038/scientificamerican0603-76
   Cerra D, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P509, DOI 10.1109/DCC.2008.46
   Cerra D., 2008, IGARSS, V1, P237
   Cerra D., 2010, SCC 10 SIEG
   Cerra D, 2010, IEEE GEOSCI REMOTE S, V7, P8, DOI 10.1109/LGRS.2009.2020349
   Chen X, 2004, IEEE T INFORM THEORY, V50, P1545, DOI 10.1109/TIT.2004.830793
   Cilibrasi R, 2004, COMPUT MUSIC J, V28, P49, DOI 10.1162/0148926042728449
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   Cilibrasi R., 2006, STAT INFERENCE DATA
   Daptardar AH, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P432, DOI 10.1109/DCC.2008.106
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Domingos P., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P127
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Jeong S, 2005, IEEE DATA COMPR CONF, P279
   Jeong S, 2004, COMPUT VIS IMAGE UND, V94, P44, DOI 10.1016/j.cviu.2003.10.015
   Keogh E, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P115, DOI 10.1109/ICDM.2003.1250910
   Keogh E.J., SIGKFCD 2004
   Kolmogorov A. N., 1968, International Journal of Computer Mathematics, V2, P157, DOI 10.1080/00207166808803030
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Li M, 2001, BIOINFORMATICS, V17, P149, DOI 10.1093/bioinformatics/17.2.149
   Macedonas A, 2008, J VIS COMMUN IMAGE R, V19, P464, DOI 10.1016/j.jvcir.2008.06.006
   Nister David, 2006, CVPR
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   Torralba A, 2009, VISUAL NEUROSCI, V26, P123, DOI 10.1017/S0952523808080930
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Watanabe T, 2002, IEEE T PATTERN ANAL, V24, P579, DOI 10.1109/34.1000234
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Ziv J., 1978, IEEE T INF THEORY
NR 39
TC 42
Z9 43
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 293
EP 302
DI 10.1016/j.jvcir.2011.10.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900007
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, SG
   Sun, HQ
   Zhang, X
AF Liu, Shiguang
   Sun, Hanqiu
   Zhang, Xiang
TI Selective color transferring via ellipsoid color mixture map
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Select color transferring; Source image; Target image;
   Ellipsoid hulls; Window-click interaction; Evaluation metric; Video
   color transferring
ID IMAGE
AB Color transfer among images is a natural phenomenon and important research topic in interactive graphics and augmented environments. Most of the conventional methods need complex user interactions and difficult image segmentation. Motivated for the intuitive use of color editing tools, this paper presents a simple but effective ellipsoid color mixture map to realize selective color transfers. Our approach proposes ellipsoid hulls to represent color statistics of the images. Based on the window-click input, the system computes the ellipsoid hulls of the source and target images respectively. The color mixture map is generated to determine the blending weight of pixels in the output image, according to the color and distance information instead of using image segmentation. By mixing the images using the color mixture map, the final results we produce have the source color selected realistically spreading on the structures related to the target window. Our selective color transferring approach is efficient and simple to use, and widely applicable for images and also video sequences without the need of addition interaction. Our experimental results have showed the high-quality visual effects and efficiency of image/video color transfers. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Liu, Shiguang; Zhang, Xiang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
C3 Tianjin University; Chinese University of Hong Kong
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM shgliu@126.com
FU National Science Foundation of China [61170118, 60803047]; Specialized
   Research Fund for the Doctoral Program of Higher Education of China
   [200800561045]
FX We thank authors of [2,3,21] for their kind help to make comparisons. We
   also thank the anonymous reviewers for their valuable comments. The
   research was supported by National Science Foundation of China (No.
   61170118 and 60803047), the Specialized Research Fund for the Doctoral
   Program of Higher Education of China (No. 200800561045).
CR Abadpour A, 2007, J VIS COMMUN IMAGE R, V18, P15, DOI 10.1016/j.jvcir.2006.08.001
   An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   [Anonymous], P INT S NONPH AN REN
   [Anonymous], P 2006 ACM INT C VIR
   [Anonymous], P GRAPH
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Chang YH, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P176, DOI 10.1109/CGI.2003.1214463
   CHANG YOUNGHA., 2004, Proceedings of the 1st Symposium on Applied Perception in Graphics and Visualization, P91, DOI [10.1145/1012551.1012567, DOI 10.1145/1012551.1012567]
   IRONY R, 2005, P EUR S REND, P277
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Luan Q, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P465, DOI 10.1109/PG.2007.50
   Neumann Laszlo, 2005, CAE, P111
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Tai YW, 2005, PROC CVPR IEEE, P747
   WELSH T, 2002, ACM T GRAPHIC, V22, P341
   Wen CL, 2008, COMPUT GRAPH FORUM, V27, P1765, DOI 10.1111/j.1467-8659.2008.01321.x
   Xiang Y, 2009, PATTERN RECOGN LETT, V30, P682, DOI 10.1016/j.patrec.2009.01.004
   Xiao XZ, 2009, COMPUT GRAPH FORUM, V28, P1879, DOI 10.1111/j.1467-8659.2009.01566.x
   Yang CK, 2008, IEEE COMPUT GRAPH, V28, P52, DOI 10.1109/MCG.2008.24
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 26
TC 17
Z9 20
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 173
EP 181
DI 10.1016/j.jvcir.2011.09.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100017
DA 2024-07-18
ER

PT J
AU De Cock, J
   Notebaert, S
   Lambert, P
   Van de Walle, R
AF De Cock, Jan
   Notebaert, Stijn
   Lambert, Peter
   Van de Walle, Rik
TI Motion-refined rewriting of H.264/AVC-coded video to SVC streams
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Transcoding; Rewriting; H.264/AVC; SVC; Motion refinement; Quality
   scalability; Inter-layer prediction; Multi-layer control
ID QUANTIZATION
AB In this paper, we discuss motion-refined rewriting of single-layer H.264/AVC streams to SVC streams with multiple quality layers. First, we elaborate on techniques we developed for efficient rewriting of residual data from H.264/AVC to SVC. We investigate if rate-distortion performance can further be improved by extending these architectures with motion refinement techniques, which exploit the inter-layer motion prediction mechanisms available in SVC. For optimum performance, we discuss a fast rate-distortion technique based on Lagrangian relaxation. Although motion refinement in the transform-domain leads to extra distortion in the bitstream, we show that our rate-distortion model successfully takes into account both base and enhancement layer rate and distortion during optimization. Implementation results show that motion-refined rewriting in the transform domain can increase rate-distortion performance, with gains of up to 0.5 dB for the SVC base layer. The presented rewriting architectures significantly reduce the computational complexity when compared to reencoding, with a speed-up by a factor of forty or more, even in the case of motion refinement. (C) 2011 Elsevier Inc. All rights reserved.
C1 [De Cock, Jan; Notebaert, Stijn; Lambert, Peter; Van de Walle, Rik] Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP De Cock, J (corresponding author), Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, Gaston Crommenlaan 8 B 201, B-9050 Ledeberg Ghent, Belgium.
EM jan.decock@ugent.be
RI Lambert, Peter/D-7776-2016
OI Lambert, Peter/0000-0001-5313-4158
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT-Flanders); Fund for Scientific
   Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, the Interdisciplinary Institute for
   Broadband Technology (IBBT), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT-Flanders), the
   Fund for Scientific Research-Flanders (FWO-Flanders), and the European
   Union.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2007, H264 ITUT
   BARRAU E, 2002, P IEEE INT C IM PROC
   DECOCK J, 2007, P INT S SIGN PROC IT
   DECOCK J, 2008, P IEEE INT C IM PROC
   DECOCK J, 2007, P IEEE INT C IM PROC
   Eleftheriadis A, 2004, IEEE T CIRC SYST VID, V14, P1195, DOI 10.1109/TCSVT.2004.835149
   ELEFTHERIADIS A, 1994, P IEEE INT C IM PROC
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   NOTEBAERT S, 2006, P PAC RIM C MULT PCM
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P533, DOI 10.1109/83.334987
   SCHWARZ H, 2007, P IEEE INT C IM PROC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Secker A, 2004, IEEE T IMAGE PROCESS, V13, P1029, DOI 10.1109/TIP.2004.826089
   SEGALL A, 2006, JVTT061
   SHEN H, 2006, P IEEE INT C IM PROC
   Shen HF, 2008, IEEE T CIRC SYST VID, V18, P746, DOI 10.1109/TCSVT.2008.918783
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
NR 21
TC 3
Z9 3
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 391
EP 400
DI 10.1016/j.jvcir.2011.03.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800003
OA Green Published
DA 2024-07-18
ER

PT J
AU Chen, ZF
   Wu, DP
AF Chen, Zhifeng
   Wu, Dapeng
TI Prediction of transmission distortion for wireless video communication:
   Algorithm and application
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RMPC; Distortion estimation; Wireless video; Transmission distortion;
   Clipping noise; Slice data partitioning; Unequal error protection (UEP);
   Prediction mode decision
ID ERROR CONCEALMENT; MODE SELECTION; PACKET LOSS; H.264/AVC
AB In this paper, we develop algorithms for estimating transmission distortion in wireless video communication systems. By leveraging the analytical results obtained in our previous works, we design low complexity algorithms that are capable of estimating transmission distortion accurately. We also extend our algorithm for pixel-level transmission distortion estimation to pixel-level end-to-end distortion estimation. Furthermore, we apply our pixel-level end-to-end distortion estimation algorithm to prediction mode decision in H.264 encoder. Experimental results show that (1) our transmission distortion estimation algorithm is more accurate and more robust against inaccurate channel estimation than existing distortion estimation algorithms; (2) our mode decision algorithm achieves remarkable PSNR gain over the existing algorithms for prediction mode decision in H.264 encoder, e.g., an average PSNR gain of 1.44 dB for 'foreman' sequence when Packet Error Probability (PEP) equals 5%. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Chen, Zhifeng; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Wu, DP (corresponding author), Univ Florida, Dept Elect & Comp Engn, POB 116130, Gainesville, FL 32611 USA.
EM wu@ece.ufl.edu
OI Wu, Dapeng/0000-0003-1755-0183
FU US National Science Foundation [DBI-0529012, CNS-0643731]; Div Of
   Electrical, Commun & Cyber Sys; Directorate For Engineering [1002214]
   Funding Source: National Science Foundation
FX This work was supported in part by an Intel gift, the US National
   Science Foundation under Grant DBI-0529012 and CNS-0643731. The authors
   would like to thank Peshala Pahalawatta and Alexis Michael Tourapis for
   many fruitful discussions related to this work.
CR Agrafiotis D, 2006, IEEE T CIRC SYST VID, V16, P960, DOI 10.1109/TCSVT.2006.879988
   [Anonymous], 2009, H 264 AVC REFERENCE
   [Anonymous], YUV VIDEO SEQUENCES
   [Anonymous], 2010, H 264 AVC REFERENCE
   [Anonymous], 2001, STAT INFERENCE
   BJONTEGAARD G, 13 VCEG M33 M AUST U
   Chen Z., 2010, PREDICTION TRANSMI 1
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DANI J, 2005, P IEEE GLOB TEL C GL
   GIROD B, 1987, IEEE J SEL AREA COMM, V5, P1140, DOI 10.1109/JSAC.1987.1146632
   Goldsmith A., 2005, WIRELESS COMMUNICATI
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   *ITU T, 2007, AUD MULT SYST ADV H
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Stockhammer T., 2002, P INT PACK VID WORKS
   Stockhammer T., 2002, IEEE ICIP
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Wang Y., 1998, Proceedings of the IEEE
   Wang Y, 2006, IEEE T CIRC SYST VID, V16, P716, DOI 10.1109/TCSVT.2006.875203
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu J, 2008, IEEE T CONSUM ELECTR, V54, P1880, DOI 10.1109/TCE.2008.4711249
   Yang H, 2007, IEEE T CIRC SYST VID, V17, P845, DOI 10.1109/TCSVT.2007.897116
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
   2008, H264 AVC REFERENCE S
NR 29
TC 12
Z9 13
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 948
EP 964
DI 10.1016/j.jvcir.2010.09.004
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500018
DA 2024-07-18
ER

PT J
AU Sato, T
   Yokoya, N
AF Sato, Tomokazu
   Yokoya, Naokazu
TI Efficient hundreds-baseline stereo by counting interest points for
   moving omni-directional multi-camera system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-baseline stereo; Depth estimation; Interest point;
   Omni-directional camera system; Multi-camera system; Efficient
   algorithm; Spatial consistency; TNIP-based stereo
ID SCENE
AB In this article, we propose an efficient method for estimating a depth map from long-baseline image sequences captured by a calibrated moving multi-camera system. Our concept for estimating a depth map is very simple; we integrate the counting of the total number of interest points (TNIP) in images with the original framework of multiple baseline stereo. Even by using a simple algorithm, the depth can be determined without computing similarity measures such as SSD (sum of squared differences) and NCC (normalized cross correlation) that have been used for conventional stereo matching. The proposed stereo algorithm is computationally efficient and robust for distortions and occlusions and has high affinity with omni-directional and multi-camera imaging. Although expected trade-off between accuracy and efficiency is confirmed for a naive TNIP-based method, a hybrid approach that uses both TNIP and SSD improve this with realizing high accurate and efficient depth estimation. We have experimentally verified the validity and feasibility of the TNIP-based stereo algorithm for both synthetic and real outdoor scenes. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Sato, Tomokazu; Yokoya, Naokazu] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
C3 Nara Institute of Science & Technology
RP Sato, T (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara, Japan.
EM tomoka-s@is.naist.jp
CR [Anonymous], 1977, TECHNIQUES AUTOMATIC
   BAKER HH, 1980, P ARPA IMAGE UNDERST, P168
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   Goesele M., 2007, P INT C COMP VIS ICC, P14
   GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HECKBERT P, 1994, GRAPHICS GEMS, V4, P47
   Hornung A., 2006, P EUR C COMP VIS
   Ikeda S, 2003, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P155, DOI 10.1109/MFI-2003.2003.1232649
   Kang SB, 1997, INT J COMPUT VISION, V25, P167, DOI 10.1023/A:1007971901577
   KANG SB, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P88, DOI 10.1109/ICCV.1995.466802
   Kang SB, 2001, PROC CVPR IEEE, P103
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Morris DD, 2000, PROC CVPR IEEE, P332, DOI 10.1109/CVPR.2000.855837
   NAKATUJI A, 2005, P IEEE ICCV BEIJ CHI, V2, P1148
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154
   Okutomi M, 2000, INT C PATT RECOG, P790, DOI 10.1109/ICPR.2000.905517
   OKUTOMI M, 1992, INT J COMPUT VISION, V7, P143, DOI 10.1007/BF00128133
   Pollard S, 2000, IMAGE VISION COMPUT, V18, P749, DOI 10.1016/S0262-8856(99)00078-5
   SANFOURCHE M, 2004, P BRIT MACH VIS C, V2, P697
   Sato T, 2004, LECT NOTES COMPUT SC, V3022, P326
   Sato T, 2002, INT J COMPUT VISION, V47, P119, DOI 10.1023/A:1014537706773
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Zheng W, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P764, DOI 10.1109/ICIP.2000.899821
NR 30
TC 5
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 416
EP 426
DI 10.1016/j.jvcir.2010.02.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shao, F
   Jiang, GY
   Yu, M
   Ho, YS
AF Shao, Feng
   Jiang, Gang-Yi
   Yu, Mei
   Ho, Yo-Sung
TI Fast color correction for multi-view video by modeling spatio-temporal
   variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3DTV; FVV; Multi-view imaging; Color correction; Spatial color
   discrepancy model; Temporal variation model; Linear regression;
   Time-invariant detection
ID COMPENSATION; SYSTEM
AB In multi-view video, a number of cameras capture the same scene from different viewpoints. Color variations between the camera views may deteriorate the performance of multi-view video coding or virtual view rendering. In this paper, a fast color correction method for multi-view video is proposed by modeling spatio-temporal variation. In the proposed method, multi-view keyframes are defined to establish the spatio-temporal relationships for accurate and fast implementation. For keyframes, accurate color correction is performed based on spatial color discrepancy model that disparity estimation is used to find correspondence points between views, and linear regression is performed on these sets of points to find the optimal correction coefficients. For non-keyframes, fast color correction is performed based on temporal variations model that time-invariant regions are detected to reflect the change trends of correction coefficients. Experimental results show that compared with other methods, the proposed method can promote the correction speed greatly without noticeable quality degradation, and obtain higher coding performance. Crown Copyright (C) 2010 Published by Elsevier Inc. All rights reserved.
C1 [Shao, Feng; Jiang, Gang-Yi; Yu, Mei] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Ho, Yo-Sung] Kwangju Inst Sci & Technol, Dept Inform & Comm, Kwangju 500712, South Korea.
C3 Ningbo University; Gwangju Institute of Science & Technology (GIST)
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM jianggangyi@126.com
RI jiang, gang/KII-8233-2024
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   [Anonymous], 2012, INTRO LINEAR REGRESS
   Ascher D, 2000, VISION RES, V40, P2219, DOI 10.1016/S0042-6989(00)00078-X
   CHEN Y, 2006, P PICT COD S BEIJ CH
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Fecker U, 2008, IEEE T CIRC SYST VID, V18, P1258, DOI 10.1109/TCSVT.2008.926997
   Hur JH, 2007, IEEE T CIRC SYST VID, V17, P1496, DOI 10.1109/TCSVT.2007.903774
   KAWADA R, 2004, JTC1SC29WG11 ISOIEC
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   LANRENCE T, 1986, J OPT SOC AM A, V3, P29
   Lee SH, 2008, IEEE T CONSUM ELECTR, V54, P268, DOI 10.1109/TCE.2008.4560085
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Morvan Y, 2008, IEEE T CONSUM ELECTR, V54, P925, DOI 10.1109/TCE.2008.4560180
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Sahu SK, 2005, J R STAT SOC C-APPL, V54, P223, DOI 10.1111/j.1467-9876.2005.00480.x
   Shao F, 2007, INT CONF ACOUST SPEE, P969
   Shao F, 2008, J SYST ENG ELECTRON, V19, P1115, DOI 10.1016/S1004-4132(08)60206-6
   SOHN K, 2006, JTC1SC29WG11M12879 I
   Tanimoto M., 2008, JTC1SC29WG11 ISOIEC
   Vetro A., 2008, JTC1SC29WG11 ISOIEC
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
   YEO C, 2007, P SPIE, V6508
   Zhang MJ, 2004, REAL-TIME IMAGING, V10, P23, DOI 10.1016/j.rti.2003.11.001
   Zhang Y, 2009, ETRI J, V31, P151, DOI 10.4218/etrij.09.0108.0350
NR 26
TC 23
Z9 25
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 392
EP 403
DI 10.1016/j.jvcir.2010.03.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600003
DA 2024-07-18
ER

PT J
AU Zinger, S
   Do, L
   de With, PHN
AF Zinger, S.
   Do, L.
   de With, P. H. N.
TI Free-viewpoint depth image based rendering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Free-viewpoint; 3D video; Depth image based rendering; 3DTV; View
   synthesis; Depth map; Multi-view video; Disocclusion inpainting
AB In 3D TV research, one approach is to employ multiple cameras for creating a 3D multi-view signal with the aim to make interactive free-viewpoint selection possible in 3D TV media. This paper explores a new rendering algorithm that enables to compute a free-viewpoint between two reference views from existing cameras. A unique property is that we perform forward warping for both texture and depth simultaneously. Advantages of our rendering are manyfold. First, resampling artifacts are filled in by inverse warping. Second, disocclusions are processed while omitting warping of edges at high discontinuities. Third, our disocclusion inpainting approach explicitly uses depth information. We obtain an average PSNR gain of 3 dB and 4.5 dB for the 'Breakdancers' and 'Ballet' sequences, respectively, compared recently published results. Moreover, experiments are performed using compressed video from surrounding cameras. The overall system quality is dominated by rendering quality and not by coding. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Zinger, S.; Do, L.; de With, P. H. N.] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
   [de With, P. H. N.] Cyclomedia Technol BV, NL-4180 BB Waardenburg, Netherlands.
C3 Eindhoven University of Technology
RP Zinger, S (corresponding author), Eindhoven Univ Technol, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM s.zinger@tue.nl; luat.do@gmail.com; p.h.n.de.with@tue.nl
CR [Anonymous], P SIGGRAPH
   DO L, 2009, P 3DTV C 2009 TRUE V
   MCMILLAN L, 1997, TR97013 U N CAR
   MORI Y, 2009, IMAGE COMMUNICATION, V24, P65
   MORVAN Y, 2007, P PICT COD S PCS LIS
   MORVAN Y, 2009, THESIS EINDHOVEN U T
   Nguyen HT, 2009, IEEE T IMAGE PROCESS, V18, P703, DOI 10.1109/TIP.2009.2012884
   Oh K., 2009, P PICT COD S PCS CHI
   RUIJTERS D, 2009, P 3DTV C 2009 TRUE V
   Smolic A, 2004, IEEE T CIRC SYST VID, V14, P348, DOI 10.1109/TCSVT.2004.823395
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Zinger S., 2009, P 17 INT C COMP GRAP, P35
NR 13
TC 93
Z9 104
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 533
EP 541
DI 10.1016/j.jvcir.2010.01.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600015
DA 2024-07-18
ER

PT J
AU Chiang, PY
   Kuo, MC
   Lee, J
   Kuo, CCJ
   Richmond, T
   Rosenberg, M
   Lund, J
   Haynes, K
   Armstrong, L
AF Chiang, Pei-Ying
   Kuo, May-chen
   Lee, Jessy
   Kuo, C-C Jay
   Richmond, Todd
   Rosenberg, Milton
   Lund, Jeff
   Haynes, Kip
   Armstrong, Lindsay
TI Technologies and the development of the Automated Metadata Indexing and
   Analysis (AMIA) system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Text-based indexing; Multimedia search engine; Content-based retrieval;
   Multimedia databases; DAM; Digital asset management; Metadata
   extraction; Word segmentation
ID INVERTED FILES; ONTOLOGIES
AB The Automated Metadata Indexing and Analysis (AMIA) project aims to provide an effective digital asset management (DAM) tool for large digital asset databases. We began with text-based indexing since it is still the most reliable approach as compared with other content-based media features. AMIA not only searches for the text of the file name, but also utilizes embedded information such as the metadata in Maya files. The AMIA system builds a linked map between all dependency files. We present an approach of preserving previously established metadata created by the old DAM tools, such as AlienBrain, and integrating them into the new system. Findings indicate that ANA has significantly improved search performance comparing to previous DAM tools. Finally, the ongoing and future work in the AMIA project is described. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Chiang, Pei-Ying; Kuo, May-chen; Lee, Jessy; Kuo, C-C Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Chiang, Pei-Ying; Kuo, May-chen; Lee, Jessy; Kuo, C-C Jay] Univ So Calif, Inst Signal & Image Proc, Los Angeles, CA 90089 USA.
   [Richmond, Todd; Rosenberg, Milton; Lund, Jeff; Haynes, Kip; Armstrong, Lindsay] USC Inst Creat Technol, Marina Del Rey, CA 90292 USA.
C3 University of Southern California; University of Southern California
RP Chiang, PY (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM peiyingc@usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU US Army Research, Development, and Engineering Command (RDECOM)
FX The effort depicted herein is sponsored by the US Army Research,
   Development, and Engineering Command (RDECOM), and the content of the
   information does not necessarily reflect the position or the policy of
   the Government, and no official endorsement should be inferred.
CR [Anonymous], P S GEOM PROC
   [Anonymous], SIGIR 02
   [Anonymous], SIGIR 91
   [Anonymous], Java suggester
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   BALLESTEROS L, 1998, SIGIR, P64
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   BURKE R, 2001, JCDL 01, P88
   Chandrasekaran B, 1999, IEEE INTELL SYST APP, V14, P20, DOI 10.1109/5254.747902
   Charikar Moses, 1997, P 29 ANN ACM S THEOR, P626, DOI DOI 10.1145/258533.258657
   Chirita Paul-Alexandru, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P7, DOI 10.1145/1277741.1277746
   Cho Junghoo., 2002, WWW 02, P124, DOI [DOI 10.1145/511446.511464, 10.1145/511446.511464]
   Cutting D., 1990, P 13 ANN INT ACM SIG, P405, DOI [10.1145/96749.98245, DOI 10.1145/96749.98245]
   Fensel D, 2002, COMPUTER, V35, P56, DOI 10.1109/MC.2002.1046975
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Grossman David., 1998, Information retrieval algorithms and heuristics
   Gruninger Michael., 1995, WORKSHOP BASIC ONTOL
   GUO R, 2007, CIKM 07, P751
   Heydon A., 1999, World Wide Web, V2, P219, DOI 10.1023/A:1019213109274
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jones S., 1999, Digital 99 Libraries. Fourth ACM Conference on Digital Libraries, P114, DOI 10.1145/313238.313279
   KASZKIEL M, 1998, SIGIR 98, P343
   Kobayashi M, 2000, ACM COMPUT SURV, V32, P144, DOI 10.1145/358923.358934
   MACSKASSY SA, 1998, HUMAN PERFORMANCE CL
   McCarley J.S., 1999, PROC 37 ANN M ASS CO, P208, DOI [DOI 10.3115/1034678.1034716, 10.3115/1034678.1034716]
   Moffat A, 1996, ACM T INFORM SYST, V14, P349, DOI 10.1145/237496.237497
   Nie JY, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P74
   NOVOTNI M, 2003, P SOL MOD
   PAYNTER GW, 2000, DL 00, P215
   Perkowitz M, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P264
   RAGHAVAN S, 2001, VLDB, P129
   Rasmussen E., 1992, Clustering algorithms, P419
   Salton G, 1986, Introduction to Modern Information Retrieval
   SARACEVIC T, 1997, BACKGROUND METHODOLO, P175
   Soergel D., 1985, Organizing information: principles of data base and retrieval systems
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Uschold M, 1996, KNOWL ENG REV, V11, P93, DOI 10.1017/S0269888900007797
   Uschold M., 1995, P IJCAI 95 WORKSH BA
   Witten I.H., 1999, Compressing and Indexing Documents and Images, V2nd
   Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P46, DOI 10.1145/290941.290956
   Zobel J, 1998, ACM T DATABASE SYST, V23, P453, DOI 10.1145/296854.277632
   [No title captured]
NR 42
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 200
EP 209
DI 10.1016/j.jvcir.2009.12.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400002
DA 2024-07-18
ER

PT J
AU Hahn, J
   Lee, CO
AF Hahn, Jooyoung
   Lee, Chang-Ock
TI Geometric attraction-driven flow for image segmentation and boundary
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geometric attraction-driven flow; Binary edge function; Binary balloon
   force; Image segmentation; Weak edge; Multiple junctions; Concave
   boundary; Dual level set functions
ID GEODESIC ACTIVE REGIONS; VECTOR FLOW; GRADIENT; ALGORITHMS; FRAMEWORK;
   CONTOURS; MUMFORD; MODELS; ENERGY
AB Novel forces in image segmentation based on active contours models are proposed for capturing objects in the image. Contemplating the common functionality of forces in previous active contours models, we propose the geometric attraction-driven flow (GADF), the binary edge function, and the binary balloon forces to detect objects in difficult cases such as varying illumination and complex shapes. The orientation of GADF is orthogonally aligned with the boundary of object and has the opposite direction across the boundary. It prevents the leakage through weak edges of objects, which occur due to illumination. To reduce the interference from other forces, we design the binary edge function using the property of the orientation in the GADF. We also design the binary balloon force based on the four-color theorem. Combining with initial dual level set functions, the proposed model captures holes in objects and multiple junctions from different colors. The result does not depend on positions of initial contours. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Hahn, Jooyoung] Nanyang Technol Univ, Div Math Sci, Sch Phys & Math Sci, Singapore 637371, Singapore.
   [Lee, Chang-Ock] Korea Adv Inst Sci & Technol, Dept Math Sci, Taejon 305701, South Korea.
C3 Nanyang Technological University; Korea Advanced Institute of Science &
   Technology (KAIST)
RP Hahn, J (corresponding author), Nanyang Technol Univ, Div Math Sci, Sch Phys & Math Sci, Singapore 637371, Singapore.
EM jyhahn@ntu.edu.sg; colee@kaist.edu
RI Hahn, Jooyoung/GPP-3243-2022; Lee, Chang-Ock/C-1577-2011; Hahn,
   Jooyoung/AGX-8714-2022; cai, bo/G-1491-2010
OI Hahn, Jooyoung/0000-0003-4357-1009
FU MOE (Ministry of Education) [T207N2202, NRF2007IDMIDM002-010]; 
   [KRF-2006-311-C00015]
FX This work was supported by KRF-2006-311-C00015. The research is
   supported by MOE (Ministry of Education) Tier 11 Project T207N2202 and
   IDM Project NRF2007IDMIDM002-010.
CR Abrantes AJ, 1996, IEEE T IMAGE PROCESS, V5, P1507, DOI 10.1109/83.541421
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   APPEL K, 1977, ILLINOIS J MATH, V21, P429, DOI 10.1215/ijm/1256049011
   AUBERT G, 2002, APPL MATH SCI, V147
   BOYKOV Y, 2005, MMCV05, P79
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CRANDALL MG, 1992, B AM MATH SOC, V27, P1, DOI 10.1090/S0273-0979-1992-00266-5
   Gil D, 2003, LECT NOTES COMPUT SC, V2683, P357
   Hodneland E, 2009, INT J COMPUT VISION, V82, P264, DOI 10.1007/s11263-008-0199-4
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Klodt M, 2008, LECT NOTES COMPUT SC, V5302, P332, DOI 10.1007/978-3-540-88682-2_26
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Lie J, 2006, MATH COMPUT, V75, P1155, DOI 10.1090/S0025-5718-06-01835-7
   LU T, 1991, APPL MATH LETT, V4, P25, DOI 10.1016/0893-9659(91)90161-N
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   Robertson N, 1997, J COMB THEORY B, V70, P2, DOI 10.1006/jctb.1997.1750
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rousson M, 2003, PROC CVPR IEEE, P699
   ROUSSON M, 2002, 4515 INRIA
   Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Xie XH, 2004, IEEE T IMAGE PROCESS, V13, P640, DOI 10.1109/TIP.2004.826124
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
   Yu ZY, 2002, LECT NOTES COMPUT SC, V2352, P517
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 48
TC 10
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 56
EP 66
DI 10.1016/j.jvcir.2009.10.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200007
DA 2024-07-18
ER

PT J
AU Ruppertsberg, AI
   Bloj, M
   Banterle, F
   Chalmers, A
AF Ruppertsberg, Alexa I.
   Bloj, Marina
   Banterle, Francesco
   Chalmers, Alan
TI Displaying colourimetrically calibrated images on a high dynamic range
   display
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE colour calibration; display colourimetry; high dynamic range display
AB When colourimetrically characterising a high dynamic range display (HDR) built from an LCD panel and an LED backlight one is faced with several problems: the channels may not be constant; they may not be independent and there may be a significant radiant output at the black level. But crucially, colour transforms are underdetermined, which means that the number of colourimetric dimensions is smaller than the number of device channels. While the first three problems are associated with the LCD, the fourth problem stems from the additional channel in the HDR, the backlight.
   A 37" flat-panel Brightside DR37-P HDR display was characterised. Using a spectroradiometer we recorded spectral radiance, chromaticities and luminance and estimated the true increase in gamut of the display due to the additional LED layer. We present a basic characterisation, propose a method for accurately presenting a desired luminance and chromaticity output despite the underdetermined problem and give an estimate of the available gamut. (C) 2007 Elsevier Inc. All rights reserved.
C1 Univ Bradford, Sch Life Sci, Div Optometry, Bradford Optometry Colour & Lighting Lab, Bradford BD7 1DP, W Yorkshire, England.
   Univ Warwick, Warwick Mfg Grp, Warwick Digital Lab, Warwick, England.
C3 University of Bradford; University of Warwick
RP Ruppertsberg, AI (corresponding author), Univ Bradford, Sch Life Sci, Div Optometry, Bradford Optometry Colour & Lighting Lab, Bradford BD7 1DP, W Yorkshire, England.
EM a.i.ruppertsberg@bradford.ac.uk
RI Banterle, Francesco/AAE-5953-2020; Bloj, Marina/F-1081-2010
OI Banterle, Francesco/0000-0002-6374-6657; Bloj,
   Marina/0000-0001-9251-0750
FU EPSRC [EP/D032008/1, EP/D032148/1] Funding Source: UKRI
CR Berns RS, 2003, COLOR RES APPL, V28, P379, DOI 10.1002/col.10181
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   BRAINARD DH, 1989, COLOR RES APPL, V14, P23, DOI 10.1002/col.5080140107
   Brainard DH., 2002, Encyclopedia of imaging science and technology, P172, DOI DOI 10.1002/0471443395.IMG011
   Day EA, 2004, COLOR RES APPL, V29, P365, DOI 10.1002/col.20046
   Mollon JD, 1982, CAMBRIDGE TEXTS PHYS, V3
   Reinhard E., 2006, HIGH DYNAMIC RANGE I, DOI 10.1016/B978-012585263-0/50005-1
   SEETZEN H, 2003, SOC INF DISPL S DIG
   Travis D., 1991, Computers and people series
   TRENTACOSTE M, 2006, FACULTY GRADUATE STU
   WARD G, 1994, SIGGRAPH 94
   WEISSTEIN EW, ELONGATED TRAINGULAR
   Wyble DR, 2006, J IMAGING SCI TECHN, V50, P17, DOI 10.2352/J.ImagingSci.Technol.(2006)50:1(17)
   Wyszecki G., 2000, COLOR SCI
   XIAO F, 2002, IS T SID 10 COL IM C
NR 15
TC 12
Z9 13
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 429
EP 438
DI 10.1016/j.jvcir.2007.06.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000009
DA 2024-07-18
ER

PT J
AU Chung, KL
   Huang, TH
   Liao, PH
AF Chung, Kuo-Liang
   Huang, Tzu-Huang
   Liao, Po-Hsuan
TI Efficient hybrid error concealment algorithm based on adaptive
   estimation scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bezier surface; centroid; cluster; error concealment; first-order plane;
   motion vector
ID TRANSMISSION ERRORS; RECOVERY
AB Video transmission plays an important role in multimedia communication. Due to transmission error; robust video transmission has become increasingly important in providing better quality of services. Based on our proposed novel adaptive estimation scheme, this paper presents an efficient hybrid error concealment algorithm for robust video transmission. Using the information of neighboring macroblocks (MBs) of the corrupted MBs, the corrupted MBs are first classified into three types. According to the type of the corrupted MB, our proposed adaptive estimation scheme could adopt the Bezier surface estimation, the first-order plane estimation, or the centroid of major cluster estimation to conceal the corrupted MB efficiently. Based on six testing video sequences, experimental results demonstrate that our proposed hybrid error concealment algorithm can improve the video quality and the execution-time performance over different loss rates. (c) 2007 Elsevier Inc. All rights reserved.
C1 Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   Natl Taiwan Univ Sci & Technol, Inst Automat & Control, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43 Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM k.l.chung@mail.ntust.edu.tw
RI Chung, Kuo-Liang/H-6207-2011
CR Al-Mualla M, 1999, ELECTRON LETT, V35, P215, DOI 10.1049/el:19990174
   Chen MJ, 2005, IEEE T CIRC SYST VID, V15, P1385, DOI 10.1109/TCSVT.2005.857301
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Chu WJ, 1998, IEEE T CIRC SYST VID, V8, P74, DOI 10.1109/76.660830
   Feng J, 1997, IEEE T CONSUM ELECTR, V43, P183, DOI 10.1109/30.585539
   FOLEY JD, 1996, COMPURTER GRAPHICS P
   HEARN D, 2002, COMPUTER GRAPHICS SE
   Jang SK, 2003, J VIS COMMUN IMAGE R, V14, P526, DOI 10.1016/j.jvcir.2003.07.001
   KANG KW, 1995, P SOC PHOTO-OPT INS, V2501, P19, DOI 10.1117/12.206743
   Kang LW, 2005, J VIS COMMUN IMAGE R, V16, P288, DOI 10.1016/j.jvcir.2004.11.004
   Kim CS, 2000, IEEE T IMAGE PROCESS, V9, P209, DOI 10.1109/83.821732
   Lee YC, 2001, IEEE IMAGE PROC, P990, DOI 10.1109/ICIP.2001.959214
   Park JW, 1999, IEEE T CIRC SYST VID, V9, P1003, DOI 10.1109/76.795052
   Shyu HC, 1999, IEEE T CIRC SYST VID, V9, P937, DOI 10.1109/76.785732
   SULLIVAN G, 2001, P IEEE INT C IM PROC, V3, P573
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   Wang Z, 1998, IEEE T IMAGE PROCESS, V7, P1056, DOI 10.1109/83.701166
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhao Y, 2005, IEEE INT SYMP CIRC S, P2899
   Zheng JH, 2004, IEEE T MULTIMEDIA, V6, P801, DOI 10.1109/TMM.2004.837246
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
NR 22
TC 5
Z9 5
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2007
VL 18
IS 4
BP 331
EP 340
DI 10.1016/j.jvcir.2007.04.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 200NU
UT WOS:000248770900004
DA 2024-07-18
ER

PT J
AU Brittain, NJ
   El-Sakka, MR
AF Brittain, Nathanael J.
   El-Sakka, Mahmoud R.
TI Grayscale true two-dimensional dictionary-based image compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image encoding; lossless compression; dictionary-based schemes;
   two-dimensional compression; LZ schemes; prediction
ID LINEAR ALGORITHM
AB Dictionary-based encoding methods are popular forms of data compression. These methods were initially implemented to reduce the one-dimensional correlation in data, since they are designed to compress text. Therefore, they do not take advantage of the fact that adjacent pixels in images are correlated in two dimensions. Previous attempts have been made to adapt dictionary-based compression schemes to consider the two-dimensional nature of images, but mostly for binary images. In this paper, a two-dimensional dictionary-based lossless image compression scheme for grayscale images is introduced. The proposed scheme reduces correlation in image data by finding two-dimensional blocks of pixels that are approximately matched throughout the data and replacing them with short codewords. Test results show that the compression performance of the proposed scheme outperforms and surpasses any other existing dictionary-based lossless compression scheme. The results also show that it slightly outperforms JPEG-2000s compression performance, when it operates in its lossless mode, and it is comparable to JPEG-LS's and CALIC's compression performance, where JPEG-2000 and JPEG-LS are the current image compression standards, and CALIC is a Context-based Adaptive Lossless Image Coding scheme. (c) 2006 Elsevier Inc. All rights reserved.
C1 Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.
C3 Western University (University of Western Ontario)
RP El-Sakka, MR (corresponding author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.
EM elsakka@csd.uwo.ca
CR Alzina M, 2002, IEEE T IMAGE PROCESS, V11, P318, DOI 10.1109/83.988964
   Amir A, 2003, J ALGORITHM, V49, P240, DOI 10.1016/S0196-6774(03)00088-9
   [Anonymous], IEEE J COMPUTER, DOI 10.1109/MC.1984.1659158
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   BELL TC, 1986, IEEE T COMMUN, V34, P1176, DOI 10.1109/TCOM.1986.1096485
   Bellomo R, 2004, CRIT CARE MED, V32, P1984, DOI 10.1097/01.CCM.0000139630.55968.3A
   BRENT RP, 1987, AUST COMPUT J, V19, P64
   BURROWS M, 1994, 124 SRC
   Dai V, 2000, PROC SPIE, V3997, P467, DOI 10.1117/12.390085
   FIALA ER, 1989, COMMUN ACM, V32, P490, DOI 10.1145/63334.63341
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   JAKOBSSON M, 1985, BIT, V25, P593, DOI 10.1007/BF01936138
   Mahoney M, 2005, CS200516
   Mahoney MV, 2004, PAQ6 DATA COMPRESSIO
   MILLER V, 1984, NATO ASI SER, P131
   MOFFAT A, 2002, SHCODEC
   Rizzo F, 2001, INFORM SCIENCES, V135, P107, DOI 10.1016/S0020-0255(01)00104-9
   RODEH M, 1981, J ACM, V28, P16, DOI 10.1145/322234.322237
   SCOTT D, 2002, DAVIDS SCOTTS BIJECT
   SCOTT D, 2001, D SCOTTS BIJECTIVE A
   Skibinski P, 2005, SOFTWARE PRACT EXPER, V35, P1455, DOI 10.1002/spe.678
   STORER JA, 1982, J ACM, V29, P928, DOI 10.1145/322344.322346
   Storer JA, 1997, COMPUT J, V40, P137, DOI 10.1093/comjnl/40.2_and_3.137
   TISCHER P, 1987, AUSTR COMPUTER SCI C, V9, P262
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   WU X, 1996, P 1996 DAT COMPR C S, P150
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
   ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934
NR 29
TC 7
Z9 8
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 35
EP 44
DI 10.1016/j.jvcir.2006.09.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100003
DA 2024-07-18
ER

PT J
AU Jang, SK
   Ra, JB
AF Jang, SK
   Ra, JB
TI Efficient error localization and temporal concealment based on motion
   estimation of enlarged block
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE robust video transmission; motion estimation; error localization;
   temporal error concealment; MPEG-4
ID ROBUST TRANSMISSION; MODE SELECTION; VIDEO; IMAGES; RESILIENCE;
   ALGORITHM; H.263
AB We propose a modified motion estimation algorithm that is adequate for error localization and temporal error concealment in transmitting videos over unreliable channels. In order to achieve good error concealment performance, the proposed algorithm implicitly imposes spatial correlations on motion vectors by extending the block size and overlapping blocks in motion estimation. Thereby, the obtained motion vectors can be used to improve error concealment performance while keeping the encoding efficiency with negligible overhead. In addition, the proposed motion estimation can provide a new error detection measure so that we can maximally utilize uncorrupted data rather than simply discarding all data in a defected packet. Simulation results show that the proposed motion estimation scheme provides significant improvements in error concealment performance over the existing schemes and improves the bit utility over a wide range of error conditions. (C) 2003 Elsevier Inc. All rights reserved.
C1 Korea Adv Inst Sci & Technol, Dept EECS, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ra, JB (corresponding author), Korea Adv Inst Sci & Technol, Dept EECS, 373-1 Guseongdong, Taejon 305701, South Korea.
RI Beom, Jong/C-1958-2011
CR Chu WJ, 1998, IEEE T CIRC SYST VID, V8, P74, DOI 10.1109/76.660830
   Côté G, 2000, IEEE J SEL AREA COMM, V18, P952, DOI 10.1109/49.848249
   Ducla-Soares L, 1999, SIGNAL PROCESS-IMAGE, V14, P447, DOI 10.1016/S0923-5965(98)00060-5
   Frossard P, 2001, IEEE T CIRC SYST VID, V11, P989, DOI 10.1109/76.946516
   Han YH, 1998, IEEE T CIRC SYST VID, V8, P221, DOI 10.1109/76.664106
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   *ISO MPEG, 1999, MPEG 4 VID VER MOD V
   Jang SK, 2002, P SOC PHOTO-OPT INS, V4671, P11, DOI 10.1117/12.453067
   Kim CS, 2001, IEEE T CIRC SYST VID, V11, P999, DOI 10.1109/76.946517
   Kim CS, 1999, IEEE T CIRC SYST VID, V9, P1063, DOI 10.1109/76.795059
   Kim CS, 2000, IEEE T IMAGE PROCESS, V9, P209, DOI 10.1109/83.821732
   LAM WM, 1995, IEEE T IMAGE PROCESS, V4, P533, DOI 10.1109/83.382489
   Lee YS, 2000, J MICROBIOL BIOTECHN, V10, P8
   Liao JY, 2000, IEEE T CIRC SYST VID, V10, P30, DOI 10.1109/76.825855
   Lin DW, 2000, P SOC PHOTO-OPT INS, V4067, P1317, DOI 10.1117/12.386549
   PARK CS, 1994, P IEEE INT S CIRC SY, V3, P229
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   TALLURI R, 1998, IEEE COMMUN MAG  JUN, P36
   VETRO A, 1999, VISUAL COMMUN IMAGE, V3536, P230
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wenger S, 1998, IEEE T CIRC SYST VID, V8, P867, DOI 10.1109/76.735382
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
NR 22
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 526
EP 542
DI 10.1016/j.jvcir.2003.07.001
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800009
DA 2024-07-18
ER

PT J
AU Lei, ZJ
   Georganas, ND
AF Lei, ZJ
   Georganas, ND
TI An accurate bit-rate control algorithm for video transcoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video transcoding; bit rate control; H.263+; TMN-8; bit production
   model; rate distortion theory
ID MODEL
AB In many video based applications, it is essential to-precisely control the bit rate of video streams for transmission over different networks and channel bandwidth. One critical element in a bit rate control algorithm is the bit production model that predicts the number of produced bits when a certain quantization parameter is used. In this paper, we present a novel bit allocation and rate control algorithm for compressed domain video transcoding. The specific transcoding issue mentioned is referred to as bit rate adaptation or rate shaping. We first review the architectures of different bit rate adaptation transcoders and the generic rate control problem. Then, we propose and formulate an approximate linear bit allocation model, which is based on experimental results. Based on this model, we propose an adaptive bit estimation and allocation scheme for video transcoding. Implementation results show that the proposed algorithm can provide accurate bit allocation, stable buffer occupancy and improved video quality as compared to existing approaches. This rate control scheme can be used to provide flexible video bit rate adaptation and stable transmission of video streams over heterogeneous networks. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Univ Ottawa, Sch Informat Technol & Engn, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Lei, ZJ (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Distributed & Collaborat Virtual Environm Res Lab, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM leizj@discover.uottawa.ca; georganas@discover.uottawa.ca
CR ASSUNCAO P, 1996, IEEE INT C AC SPEECH, V4, P1998
   CHANG SF, 1993, P IEEE INT C AC SPEE, V5, P421
   Cheng JB, 1997, J VIS COMMUN IMAGE R, V8, P51, DOI 10.1006/jvci.1997.0329
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   CHOI JH, 1994, IEEE T IMAGE PROCESS, V3, P546, DOI 10.1109/83.334986
   Corbera J., 1997, Q15A20 VID COD EXP G
   CORBERA JR, 1999, IEEE T CIRCUIT SYSTE, V9
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   Ghanbari M., 1999, VIDEO CODING INTRO S
   Hang HM, 1997, IEEE T CIRC SYST VID, V7, P287
   HE ZH, 2001, IEEE T CIRCUITS SYST, V11
   Hoang D. T., 2001, EFFICIENT ALGORITHMS
   *ITU T, 1998, DRAFT H 263 VID COD
   LEE J, 1994, P ICIP, V2, P962
   LIN DW, 1993, P SOC PHOTO-OPT INS, V2094, P223, DOI 10.1117/12.157940
   Lin LJ, 1998, IEEE T CIRC SYST VID, V8, P446, DOI 10.1109/76.709411
   ORTEGA A, 1994, IEEE T IMAGE PROCESS, V3, P26, DOI 10.1109/83.265978
   Pao IM, 2001, J VIS COMMUN IMAGE R, V12, P29, DOI 10.1006/jvci.2000.0461
   Puri A, 1991, IEEE T CIRC SYST VID, V1, P351, DOI 10.1109/76.120774
   RAMCHANDRAN K, 1991, IEEE T IMAGE PROCESS, V2
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   Tao B, 2000, IEEE T CIRC SYST VID, V10, P147, DOI 10.1109/76.825868
   *TMN, 1997, VERS 3 0
   Wu SW, 1991, IEEE T CIRC SYST VID, V1, P100, DOI 10.1109/TCSVT.1991.4519809
   YANG Y, 2000, IEEE T CIRCUITS SYST, V10
   Youn J, 2000, J VIS COMMUN IMAGE R, V11, P385, DOI 10.1006/jvci.2000.0449
   Zhu QF, 1999, IEEE T CIRC SYST VID, V9, P666, DOI 10.1109/76.767130
NR 27
TC 4
Z9 5
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 321
EP 339
DI 10.1016/S1047-3203(03)00018-X
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200006
DA 2024-07-18
ER

PT J
AU Zhang, DS
   Lu, GJ
AF Zhang, DS
   Lu, GJ
TI A comparative study of curvature scale space and Fourier descriptors for
   shape-based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fourier descriptors; curvature scale space; CBIR; shape
ID AUTOMATIC RECOGNITION; BIOLOGICAL SHAPES; REPRESENTATION
AB Contour shape descriptors are among the important shape description methods. Fourier descriptors (FDs) and curvature scale space descriptors (CSSDs) are widely used as contour shape descriptors for image retrieval in the literature. In MPEG-7, CSSD has been proposed as one of the contour-based shape descriptors. However, no comprehensive comparison has been made between these two shape descriptors. In this paper we study and compare FD and CSSD using standard principles and standard database. The study targets image retrieval application. Our experimental results show that FD outperforms CSSD in terms of robustness, low computation, hierarchical representation, retrieval performance, and suitability for efficient indexing. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Monash Univ, Gippsland Sch Comp & Informat Technol, Churchill, Vic 3842, Australia.
C3 Federation University Australia; Monash University
RP Monash Univ, Gippsland Sch Comp & Informat Technol, Churchill, Vic 3842, Australia.
EM dengsheng.zhang@infotech.monash.edu.au; guojun.lu@infotech.monash.edu.au
RI Rohlf, F J/A-8710-2008; Zhang, Dengsheng/W-8467-2019
OI Zhang, Dengsheng/0000-0001-8728-1746; Lu, Guojun/0000-0003-2523-7576
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Abbasi S, 2000, IMAGE VISION COMPUT, V18, P199, DOI 10.1016/S0262-8856(99)00019-0
   [Anonymous], 2001, P INT C INT MULT DIS
   [Anonymous], GEOMETRIC METHODS CO
   Daoudi M, 2000, J VISUAL LANG COMPUT, V11, P287, DOI 10.1006/jvlc.2000.0159
   Davies E.R., 1997, MACHINE VISION THEOR, V2nd
   DELBIMBO A, 1999, VISUAL INFORMATION R, P56
   Dudek G, 1997, COMPUT VIS IMAGE UND, V68, P170, DOI 10.1006/cviu.1997.0533
   Freeman H., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P701
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   JEANNIN S, 2000, JTC1SC29WG11N3321 IS
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Lu GJ, 1999, MULTIMEDIA SYST, V7, P165, DOI 10.1007/s005300050119
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Pavlidis T., 1982, Algorithms for Graphics and Image Processing, P143
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Sánchez-Marín FJ, 2000, ARTIF INTELL MED, V18, P173, DOI 10.1016/S0933-3657(99)00033-0
   Sanchez-Marin FJ, 2001, COMPUT BIOL MED, V31, P85, DOI 10.1016/S0010-4825(00)00027-5
   SONKA M, 1993, IMAGE PROCESSING ANA, P225
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   TIENG QM, 1997, IEEE T PAMI, V19
   Yang HS, 1998, J VIS COMMUN IMAGE R, V9, P171, DOI 10.1006/jvci.1998.0384
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   ZHANG DS, 2002, THESIS MONASH U AUST
   ZHANG DS, 2001, P 2 IEEE PAC RIM C M, P855
NR 31
TC 149
Z9 190
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2003
VL 14
IS 1
BP 41
EP 60
DI 10.1016/S1047-3203(03)00003-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 665TZ
UT WOS:000182138500003
DA 2024-07-18
ER

PT J
AU Li, YX
   Huang, YW
   He, NJ
   Ma, K
   Zheng, YF
AF Li, Yuexiang
   Huang, Yawen
   He, Nanjun
   Ma, Kai
   Zheng, Yefeng
TI Improving vision transformer for medical image classification via
   token-wise perturbation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Self-supervised learning; Vision transformer; Image classification
AB Transformer has achieved impressive successes for various computer vision tasks. However, most of existing studies require to pretrain the Transformer backbone on a large-scale labeled dataset (e.g., ImageNet) for achieving satisfactory performance, which is usually unavailable for medical images. Additionally, due to the gap between medical and natural images, the improvement generated by the ImageNet pretrained weights significantly degrades while transferring the weights to medical image processing tasks. In this paper, we propose Bootstrap Own Latent of Transformer (BOLT), a self-supervised learning (SSL) approach specifically for medical image classification with the Transformer backbone. Our BOLT consists of two networks, namely online and target branches, for self-supervised representation learning. Concretely, the online network is trained to predict the target network representation of the same patch embedding tokens with a different perturbation. To maximally excavate the impact of Transformer from limited medical data, we propose an auxiliary difficulty ranking task. The Transformer is enforced to identify which branch (i.e., online/target) is processing the more difficult perturbed tokens. Overall, the Transformer endeavours itself to distill the transformation -invariant features from the perturbed tokens to simultaneously achieve difficulty measurement and maintain the consistency of self-supervised representations. The proposed BOLT is evaluated on three medical image processing tasks, i.e., skin lesion classification, knee fatigue fracture grading and diabetic retinopathy grading. The experimental results validate the superiority of our BOLT for medical image classification, compared to ImageNet pretrained weights and state-of-the-art SSL approaches.
C1 [Li, Yuexiang; Zheng, Yefeng] Guangxi Med Univ, Med AI Res MARS Grp, Guangxi Collaborat Innovat Ctr Genom & Personalize, Ctr Genom & Personalized Med,Guangxi Key Lab Genom, Nanning 530021, Peoples R China.
   [Huang, Yawen; Ma, Kai; Zheng, Yefeng] Tencent Jarvis Res Ctr, YouTu Lab, Shenzhen 518000, Peoples R China.
   [He, Nanjun] OPPO, Shenzhen 518000, Peoples R China.
C3 Guangxi Medical University
RP He, NJ (corresponding author), OPPO, Shenzhen 518000, Peoples R China.
EM henanjun@oppo.com
RI Ma, kai/KSL-8338-2024
OI Ma, kai/0009-0004-3748-2549
FU Key-Area Research and Development Program of Guangdong Province, China
   [2018B0101 11001]; National Key R&D Program of China [2018YFC2000702,
   2020AAA0104100]
FX <B>Acknowledgments</B> This work was supported in part by the Key-Area
   Research and Development Program of Guangdong Province, China (No.
   2018B0101 11001) , National Key R&D Program of China (2018YFC2000702) ,
   and the Scientific and Technical Innovation 2030-"New Generation
   Artifi-cial Intelligence"Project (No. 2020AAA0104100) .
CR Ahmed S.A.A., 2021, arXiv
   Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen XL, 2021, Arxiv, DOI [arXiv:2104.02057, DOI 10.48550/ARXIV.2104.02057]
   Chen XL, 2020, Arxiv, DOI arXiv:2003.04297
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chu X., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2102.10882
   Dai ZG, 2021, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR46437.2021.00165
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Gao Y, 2021, arXiv, DOI 10.48550/arXiv.2107.00781
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han K, 2022, Arxiv, DOI arXiv:2012.12556
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hutter F., 2017, INT C LEARN REPR
   Ji GP, 2021, Arxiv, DOI arXiv:2105.08468
   Ji YF, 2021, Arxiv, DOI arXiv:2106.14385
   Kervadec H, 2019, LECT NOTES COMPUT SC, V11765, P568, DOI 10.1007/978-3-030-32245-8_63
   Khan S.H., 2021, arXiv
   Lanchantin J, 2021, PROC CVPR IEEE, P16473, DOI 10.1109/CVPR46437.2021.01621
   Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96
   Li Y., 2021, INT C MED IM COMP CO
   Li YX, 2020, IEEE J BIOMED HEALTH, V24, P2787, DOI 10.1109/JBHI.2020.3018181
   Li Z., 2020, INT C MED IM COMP CO
   Liu S., 2020, INT C MED IM COMP CO
   Liu Z, 2021, Arxiv, DOI [arXiv:2103.14030, DOI 10.48550/ARXIV.2103.14030]
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pan T, 2021, PROC CVPR IEEE, P11200, DOI 10.1109/CVPR46437.2021.01105
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Rajpurkar P., 2018, INT C MED IM DEEP LE
   Spitzer H, 2018, LECT NOTES COMPUT SC, V11072, P663, DOI 10.1007/978-3-030-00931-1_76
   Tao X., 2020, INT C MED IM COMP CO
   Tao X, 2021, I S BIOMED IMAGING, P1284, DOI 10.1109/ISBI48211.2021.9433822
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WH, 2021, Arxiv, DOI arXiv:2102.12122
   Wang XL, 2021, PROC CVPR IEEE, P3023, DOI 10.1109/CVPR46437.2021.00304
   Wang YQ, 2021, PROC CVPR IEEE, P8737, DOI 10.1109/CVPR46437.2021.00863
   Wei C, 2019, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2019.00201
   Xie X., 2020, INT C MED IM COMP CO
   Xie ZD, 2021, Arxiv, DOI arXiv:2105.04553
   Yuan L, 2021, Arxiv, DOI arXiv:2101.11986
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhan XH, 2019, PROC CVPR IEEE, P1881, DOI 10.1109/CVPR.2019.00198
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang LH, 2019, PROC CVPR IEEE, P2542, DOI 10.1109/CVPR.2019.00265
   Zhang PY, 2017, I S BIOMED IMAGING, P578, DOI 10.1109/ISBI.2017.7950587
   Zhang Y., 2021, arXiv preprint arXiv:2106.07557, DOI 10.48550/arXiv.2106.07557
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou H.-Y., 2020, INT C MED IM COMP CO
   Zhou ZW, 2019, LECT NOTES COMPUT SC, V11767, P384, DOI 10.1007/978-3-030-32251-9_42
   Zhu JW, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101746
   Zhu X., 2020, arXiv
NR 58
TC 1
Z9 1
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104022
DI 10.1016/j.jvcir.2023.104022
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FP8V2
UT WOS:001147151300001
DA 2024-07-18
ER

PT J
AU Chen, SJ
   Yang, XW
   Li, ZX
AF Chen, Shengjia
   Yang, Xiwei
   Li, Zhixin
TI Improving semantic segmentation with knowledge reasoning network?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Knowledge reasoning; Graph convolutional network;
   External knowledge; Context information
AB Most methods cannot segment the semantic regions accurately due to the lack of global-level supervision or guidance of external knowledge. To overcome this limitation, we propose a Knowledge Reasoning Network (KRNet) that consists of two crucial modules: (1) a prior knowledge mapping module that incorporates external knowledge by graph convolutional network to guide learning semantic representations and (2) a knowledge reasoning module that correlates these representations with a graph built on the external knowledge and explores their interactions via the knowledge reasoning. In the prior knowledge mapping module, we adopt an algorithm to mine knowledge from an external large-scale relational modeling dataset. In the knowledge reasoning module, we adopt an iterative mechanism to perform knowledge reasoning and explore the interaction between features. Reasoning makes the spatial distribution of categories more significant. We establish state-of-the-art results on Cityscapes and ADE20K datasets, which demonstrates the effectiveness of our methods on semantic segmentation.
C1 [Chen, Shengjia; Yang, Xiwei; Li, Zhixin] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
OI Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [62276073, 61966004];
   Guangxi Natural Science Foundation, China [2019GXNSFDA245018]; Guangxi
   "Bagui Scholar" Teams for Innovation and Research Project; Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing
FX This work is supported by National Natural Science Foundation of China
   (Nos. 62276073, 61966004) , Guangxi Natural Science Foundation, China
   (No. 2019GXNSFDA245018) , Guangxi "Bagui Scholar" Teams for Innovation
   and Research Project, and Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2340, DOI 10.1109/ICASSP39728.2021.9415022
   Chen SJ, 2020, IEEE DATA MINING, P52, DOI 10.1109/ICDM50108.2020.00014
   Chen T., 2018, arXiv
   Chen XL, 2018, PROC CVPR IEEE, P7239, DOI 10.1109/CVPR.2018.00756
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Cheng B, 2021, ADV NEUR IN, V34
   Cheng BW, 2019, IEEE I CONF COMP VIS, P5217, DOI 10.1109/ICCV.2019.00532
   Cheng L., 2021, P 30 INT JOINT C ART, P629
   Cho KYHY, 2014, Arxiv, DOI arXiv:1409.1259
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Feng ZL, 2021, AAAI CONF ARTIF INTE, V35, P1325
   Feng ZL, 2021, AAAI CONF ARTIF INTE, V35, P1334
   Feng Zunlei, 2021, Proceedings of the IEEE/CVF International Conference on Computer Vision, P4036
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Hu H., 2020, P EUR C COMP VIS, P1
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jiang CH, 2018, ADV NEUR IN, V31
   Joulin A, 2016, Arxiv, DOI [arXiv:1612.03651, DOI 10.48550/ARXIV.1612.03651, 10.48550/arXiv.1612.03651]
   Kim JH, 2017, Arxiv, DOI [arXiv:1610.04325, DOI 10.48550/ARXIV.1610.04325]
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X., 2020, P IEEE CVF C COMP VI, P8950, DOI 10.1109/CVPR42600.2020.00897
   Liang XD, 2018, 32 C NEURAL INFORM P, V31
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma YN, 2020, IEEE WINT CONF APPL, P2920, DOI [10.1109/WACV45572.2020.9093411, 10.1109/wacv45572.2020.9093411]
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Redondo-Cabrera C, 2019, IEEE T IMAGE PROCESS, V28, P3649, DOI 10.1109/TIP.2019.2901393
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Tianyi Wu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P34, DOI 10.1007/978-3-030-58520-4_3
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wang T., 2020, P IEEE C COMP VIS PA, P10760
   Xie EZ, 2021, ADV NEUR IN, V34
   Xie S., 2020, P AS C COMP VIS
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yangxin Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9077, DOI 10.1109/CVPR42600.2020.00910
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang J, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104513
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhu Y, 2022, IEEE T NEUR NET LEAR, V33, P117, DOI 10.1109/TNNLS.2020.3027575
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 70
TC 1
Z9 1
U1 5
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103923
DI 10.1016/j.jvcir.2023.103923
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S1IV2
UT WOS:001068783200001
DA 2024-07-18
ER

PT J
AU Lei, J
   Yang, GY
   Wang, SW
   Feng, ZL
   Liang, RH
AF Lei, Jie
   Yang, Guoyu
   Wang, Shuaiwei
   Feng, Zunlei
   Liang, Ronghua
TI DCAM: Disturbed class activation maps for weakly supervised semantic
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised semantic segmentation; Class activation map;
   Image-level class label; Disturbance injection
AB In the field of weakly supervised semantic segmentation (WSSS), Class Activation Maps (CAM) are typically adopted to generate pseudo masks. Yet, we find that the crux of the unsatisfactory pseudo masks is the incomplete CAM. Specifically, as convolutional neural networks tend to be dominated by the specific regions in the high-confidence channels of feature maps during prediction, the extracted CAM contains only parts of the object. To address this issue, we propose the Disturbed CAM (DCAM), a simple yet effective method for WSSS. Following CAM, we adopt a binary cross-entropy (BCE) loss to train a multi-label classification model. Then, we disturb the feature map with retraining to enhance the high-confidence channels. In addition, a softmax cross-entropy (SCE) loss branch is employed to increase the model attention to the target classes. Once converged, we extract DCAM in the same way as in CAM. The evaluation on both PASCAL VOC and MS COCO shows that DCAM not only generates high-quality masks (6.2% and 1.4% higher than the benchmark models), but also enables more accurate activation in object regions. The code is available at https://github.com/gyyang23/DCAM.
C1 [Lei, Jie; Yang, Guoyu; Wang, Shuaiwei; Liang, Ronghua] Zhejiang Univ Technol, Hangzhou 310014, Peoples R China.
   [Feng, Zunlei] Zhejiang Univ, Hangzhou 310027, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University
RP Lei, J (corresponding author), Zhejiang Univ Technol, Hangzhou 310014, Peoples R China.
EM jasonlei@zjut.edu.cn; gyyang@zjut.edu.cn; swwang@zjut.edu.cn;
   zunleifeng@zju.edu.cn; rhliang@zjut.edu.cn
OI Lei, Jie/0000-0003-2523-5810
FU National Natural Science Foundation of China [62036009, 62106226];
   National Key Research and Development Program of China [2020YFB1707700];
   Zhejiang Provincial Natural Science Foundation of China [LQ22F020013,
   LDT23F0202, LDT23F02021F02]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China (No. 62036009, No. 62106226) , the National
   Key Research and Development Program of China (No. 2020YFB1707700) , and
   Zhejiang Provincial Natural Science Foundation of China (No.
   LQ22F020013, No. LDT23F0202, No. LDT23F02021F02) .
CR Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231
   Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Bearman Amy, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LL, 2022, IEEE T CIRC SYST VID, V32, P1889, DOI 10.1109/TCSVT.2021.3086598
   Chen Z., 2022, IEEECVF C COMPUT VIS, P969
   Cheng DQ, 2022, IEEE T CIRC SYST VID, V32, P8436, DOI 10.1109/TCSVT.2022.3194169
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan JS, 2020, AAAI CONF ARTIF INTE, V34, P10762
   Feng J., 2022, PATTERN RECOGN LETT
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Z, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102957
   Huang SL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P600, DOI 10.1109/ICCV48922.2021.00066
   Jiang PT, 2019, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2019.00216
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kweon H., 2021, P IEEECVF INT C COMP, V7003, P6994
   Lee J., 2021, IEEE CVF C COMP VIS, P4071
   Lee J, 2021, PROC CVPR IEEE, P2643
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Loshchilov Ilya, 2016, arXiv
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   ZHANG D, 2020, ADV NEURAL INFORM PR, V33, P655, DOI DOI 10.5555/3495724.3495780
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang XL, 2018, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2018.00144
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 30
TC 0
Z9 0
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103852
DI 10.1016/j.jvcir.2023.103852
EA MAY 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7NL6
UT WOS:001011451700001
DA 2024-07-18
ER

PT J
AU Huang, ZQ
   Feng, BW
   Xiang, SJ
AF Huang, Ziquan
   Feng, Bingwen
   Xiang, Shijun
TI Robust reversible image watermarking scheme based on spread spectrum
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robust reversible watermarking; Spread-spectrum code; Embedding
   amplitude; Linear correlation
ID HISTOGRAMS MODIFICATION; PREDICTION; EXPANSION
AB Robust reversible watermarking can provide robustness against various attacks besides the ability to recover the cover image. However, robustness and reversibility are somewhat separate in many schemes. The original cover image cannot be recovered even if the watermarked image suffers from a tiny distortion. This paper presents a new robust reversible watermarking scheme by exploring the reversibility of spread-spectrum codes. Watermark bits are embedded by a suggested adaptive spread-spectrum code. The embedding amplitude used in the algorithms is determined by quantizing the source interference of the cover. The proposed scheme is robust to various attacks. Furthermore, since the embedding amplitude is available at the receiver, the original image can be recovered losslessly when there is no attack. Even in the presence of attacks, the original cover images can still be partially recovered. Experimental results demonstrate that the proposed scheme performs well on robustness and watermarked image quality, and provide extra reversibility that resists image distortions.
C1 [Huang, Ziquan; Feng, Bingwen; Xiang, Shijun] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Peoples R China.
C3 Jinan University
RP Feng, BW (corresponding author), Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Peoples R China.
EM huangz7@stu2020.jnu.edu.cn; bingwfeng@gmail.com; shijun_xiang@qq.com
FU Key R&D Program of Guang-dong Province [2019B010136003]; National
   Natural Science Foundation of China [61802145, 61932010]; Natural
   Science Foundation of Guangdong Province, China [2019B010137005,
   2023A1515011348]; Provincial Science and Technology Project, China
   [2021A0505030033]; Science and Technology Program of Guangzhou, China
   [202007040004]; Fundamental Research Funds for the Central Universities
FX This work was supported by the Key R & D Program of Guang-dong Province
   (Grant No. 2019B010136003), National Natural Science Foundation of China
   (Grant No. 61802145, 61932010), Natural Science Foundation of Guangdong
   Province, China (Grant No.2019B010137005, 2023A1515011348), Provincial
   Science and Technology Project, China (Grant No. 2021A0505030033),
   Science and Technology Program of Guangzhou, China (Grant No.
   202007040004),the Fundamental Research Funds for the Central
   Universities.
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Barni M, 2003, SIGNAL PROCESS, V83, P2069, DOI 10.1016/S0165-1684(03)00168-3
   C.V. Group, 2014, DAT STAND 512 X 512
   Cavagnino D, 2015, SIGNAL PROCESS, V117, P258, DOI 10.1016/j.sigpro.2015.05.020
   Chang Q, 2021, IEEE T CIRC SYST VID, V31, P4850, DOI 10.1109/TCSVT.2021.3055612
   Coltuc D, 2007, PROC SPIE, V6505
   Coltuc D, 2007, J PHYS CONF SER, V77, DOI 10.1088/1742-6596/77/1/012005
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Du Y, 2022, INFORM SCIENCES, V609, P319, DOI 10.1016/j.ins.2022.07.071
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hiary S, 2017, MULTIMED TOOLS APPL, V76, P2131, DOI 10.1007/s11042-015-3161-9
   Hu RW, 2021, IEEE T IMAGE PROCESS, V30, P318, DOI 10.1109/TIP.2020.3036727
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Kadian P, 2021, WIRELESS PERS COMMUN, V118, P3225, DOI 10.1007/s11277-021-08177-w
   Li Q, 2022, MULTIMED TOOLS APPL, P1
   Li Q., 2022, SECUR COMMUN NETW, V2022
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lim S, 2006, PROC SPIE, V6069, DOI 10.1117/12.655915
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Ni ZC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2199, DOI 10.1109/ICME.2004.1394706
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Tang YC, 2023, IEEE T CIRC SYST VID, V33, P1593, DOI 10.1109/TCSVT.2022.3216849
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   van Leest A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P731
   Wang H, 2021, INT C ART INT SEC, P312
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2020, IEEE T CIRC SYST VID, V30, P2406, DOI 10.1109/TCSVT.2019.2915116
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Xiao MY, 2021, IEEE T CIRC SYST VID, V31, P2535, DOI 10.1109/TCSVT.2020.3027391
   Yu K., 2022, SIGNAL PROCESS
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zhang XQ, 2018, PROCEEDINGS OF 2018 7TH INTERNATIONAL CONFERENCE ON SOFTWARE AND COMPUTER APPLICATIONS (ICSCA 2018), P164, DOI 10.1145/3185089.3185123
NR 43
TC 1
Z9 1
U1 3
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103808
DI 10.1016/j.jvcir.2023.103808
EA MAR 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0VC8
UT WOS:000965979400001
DA 2024-07-18
ER

PT J
AU Sun, YL
   Shi, GM
   Dong, WS
   Xie, XM
AF Sun, Yulin
   Shi, Guangming
   Dong, Weisheng
   Xie, Xuemei
TI MADPL-net: Multi-layer attention dictionary pair learning network for
   image classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-layer dictionary learning; Attention dictionary pair learning;
   Deep encoder; Image classification
ID DISCRIMINATIVE DICTIONARY; SPARSE REPRESENTATION; K-SVD
AB With the great success of deep neural networks, combining deep learning with traditional dictionary learning has become a hot issue. However, the performance of these methods is still limited for several reasons. First, some existing methods update dictionary learning and classifier as two independent modules, which limits the classification performance. Second, the non-attention dictionary is learned to represent all images, reducing the model representation flexibility. In this paper, we design a novel end-to-end model named Multi layer Attention Dictionary Pair Learning Network (MADPL-net), which integrates the learning schemes of the convolutional neural network, deep encoder learning, and attention dictionary pair learning (ADicL) into a unified framework. The encoder layer contains the ADicL block, which selects more image-attentive atoms in the dictionary pair block via the softmax function to ensure MADPL-net classification capability. In addition, ADicL schema can yield discriminative dictionary atoms and feature maps with high inter-class separation and high intra-class compactness. To improve the sparse representation learning performance, MADPL-net adds l(1)-norm constraint of the analysis dictionary to the cross-entropy loss function. Extensive experiments show that MADPL-net can achieve excellent performance over other state-of-the-arts.
C1 [Sun, Yulin; Shi, Guangming; Dong, Weisheng; Xie, Xuemei] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
C3 Xidian University
RP Shi, GM (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
EM yulinsun@stu.xidian.edu.cn; gmshi@xidian.edu.cn;
   wsdong@mail.xidian.edu.cn; xmxie@mail.xidian.edu.cn
OI Sun, Yulin/0000-0001-9917-0269
FU major key project of Peng Cheng Laboratory [PCL2021A12]; Natural Science
   Foundation (NSF) of China [61871304, 61976169]; National Key Research
   and Development Program of China [2019YFA0706604]
FX This work is supported by the major key project of Peng Cheng Laboratory
   (No. PCL2021A12), the Natural Science Foundation (NSF) of China (Nos.
   61871304, 61976169), the National Key Research and Development Program
   of China (No. 2019YFA0706604).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chu HP, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103319
   Deng J., 2009, IEEE C COMP VIS PATT
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Garcia-Cardona C, 2018, IEEE T COMPUT IMAG, V4, P366, DOI 10.1109/TCI.2018.2840334
   Gu SH, 2014, ADV NEUR IN, V27
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, NeurIPS, P396
   Liu SG, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102763
   Liu Z, 2018, J VIS COMMUN IMAGE R, V52, P159, DOI 10.1016/j.jvcir.2018.02.011
   Mahdizadehaghdam S, 2019, IEEE T IMAGE PROCESS, V28, P4790, DOI 10.1109/TIP.2019.2914376
   Montazeri A, 2021, VISUAL COMPUT, V37, P707, DOI 10.1007/s00371-020-01970-x
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal V, 2017, IEEE T GEOSCI REMOTE, V55, P5274, DOI 10.1109/TGRS.2017.2704590
   Song JQ, 2019, PATTERN RECOGN, V91, P135, DOI 10.1016/j.patcog.2019.02.018
   Sulam J, 2018, IEEE T SIGNAL PROCES, V66, P4090, DOI 10.1109/TSP.2018.2846226
   Sun YL, 2020, IEEE T NEUR NET LEAR, V31, P4303, DOI 10.1109/TNNLS.2019.2954545
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang H, 2021, IEEE T NEUR NET LEAR, V32, P2129, DOI 10.1109/TNNLS.2020.2997289
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Wang KZ, 2016, PROC CVPR IEEE, P2138, DOI 10.1109/CVPR.2016.235
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Xu ZP, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103119
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang Z, 2020, IEEE DATA MINING, P811, DOI 10.1109/ICDM50108.2020.00090
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3798, DOI 10.1109/TNNLS.2017.2740224
   Zheng HY, 2021, PROC CVPR IEEE, P630, DOI 10.1109/CVPR46437.2021.00069
NR 46
TC 3
Z9 3
U1 5
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103728
DI 10.1016/j.jvcir.2022.103728
EA DEC 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7U7WZ
UT WOS:000912340700001
DA 2024-07-18
ER

PT J
AU Lv, CT
   Zhou, XF
   Zhu, B
   Liu, DY
   Zheng, BL
   Zhang, JY
   Yan, CG
AF Lv, Chengtao
   Zhou, Xiaofei
   Zhu, Bin
   Liu, Deyang
   Zheng, Bolun
   Zhang, Jiyong
   Yan, Chenggang
TI SRI-Net: Similarity retrieval-based inference network for light field
   salient object detection?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light field; Focal slice retrieval; Similarity retrieval; Salient object
   detection
ID MODEL
AB The cutting-edge RGB saliency models are prone to fail for some complex scenes, while RGB-D saliency models are often affected by inaccurate depth maps. Fortunately, light field images can provide a sufficient spatial layout depiction of 3D scenes. Therefore, this paper focuses on salient object detection of light field images, where a Similarity Retrieval-based Inference Network (SRI-Net) is proposed. Due to various focus points, not all focal slices extracted from light field images are beneficial for salient object detection, thus, the key point of our model lies in that we attempt to select the most valuable focal slice, which can contribute more complementary information for the RGB image. Specifically, firstly, we design a focal slice retrieval module (FSRM) to choose an appropriate focal slice by measuring the foreground similarity between the focal slice and RGB image. Secondly, in order to combine the original RGB image and the selected focal slice, we design a U-shaped saliency inference module (SIM), where the two-stream encoder is used to extract multi-level features, and the decoder is employed to aggregate multi-level deep features. Extensive experiments are conducted on two widely used light field datasets, and the results firmly demonstrate the superiority and effectiveness of the proposed SRI-Net.
C1 [Lv, Chengtao; Zhou, Xiaofei; Zheng, Bolun; Zhang, Jiyong; Yan, Chenggang] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
   [Zhu, Bin] Huzhou Univ, Huzhou 313000, Peoples R China.
   [Liu, Deyang] Anqing Normal Univ, Sch Comp & Informat, Anqing 246000, Peoples R China.
C3 Hangzhou Dianzi University; Huzhou University; Anqing Normal University
RP Zhou, XF; Zhang, JY (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
EM chengtaolv@foxmail.com; zxforchid@outlook.com; 227342978@qq.com;
   deyang.liu@hotmail.com; blzheng@hdu.edu.cn; jzhang@hdu.edu.cn;
   deyang.liu@hotmail.com
RI Liu, Deyang/AAB-1184-2020; lv, chengtao/KDO-8670-2024
OI lv, chengtao/0000-0003-4928-9493
FU National Key Research and Development Program of China [2020YFB1406604];
   Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK229909299001-009]; National Natural Science Foundation of China
   [62271180, 62171002, 61901145, U21B2024, 61931008, 62071415, 61972123,
   62001146]; Zhejiang Province Nature Science Foundation of China
   [LR17F030006, LY19F030022, LZ22F020003]; Hangzhou Dianzi University
   (HDU); China Electronics Corporation DATA (CEC-DATA) Joint Research
   Center of Big Data Technologies [KYH063120009]; 111 Project [D17019]
FX This work was supported by the National Key Research and Development
   Program of China under Grants 2020YFB1406604; the Fundamental Research
   Funds for the Provincial Universities of Zhejiang under Grants
   GK229909299001-009; the National Natural Science Foundation of China
   under Grants 62271180, 62171002, 61901145, U21B2024, 61931008, 62071415,
   61972123, 62001146; the Zhejiang Province Nature Science Foundation of
   China under Grants LR17F030006, LY19F030022, LZ22F020003; the Hangzhou
   Dianzi University (HDU) and the China Electronics Corporation DATA
   (CEC-DATA) Joint Research Center of Big Data Technologies under Grants
   KYH063120009; and the 111 Project under Grants D17019.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Chen Q, 2021, AAAI CONF ARTIF INTE, V35, P1063
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Chongyi Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P225, DOI 10.1007/978-3-030-58598-3_14
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fu K, 2022, COMPUT VIS MEDIA, V8, P509, DOI 10.1007/s41095-021-0256-2
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Graves A, 2014, Arxiv, DOI arXiv:1308.0850
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Z, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102957
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang Y, 2022, NEUROCOMPUTING, V491, P78, DOI 10.1016/j.neucom.2022.03.056
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu DY, 2020, IEEE T COMPUT IMAG, V6, P1507, DOI 10.1109/TCI.2020.3037413
   Liu DY, 2020, IEEE T MULTIMEDIA, V22, P846, DOI 10.1109/TMM.2019.2934426
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Miao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P374, DOI 10.1007/978-3-030-58604-1_23
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Paszke A, 2019, ADV NEUR IN, V32
   Piao YR, 2020, AAAI CONF ARTIF INTE, V34, P11865
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Shi XJ, 2015, ADV NEUR IN, V28
   Shokri M, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102769
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang TT, 2019, IEEE I CONF COMP VIS, P8837, DOI 10.1109/ICCV.2019.00893
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yang X, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103329
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P4421, DOI 10.1109/TIP.2020.2970529
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhang M, 2019, ADV NEUR IN, V32
   Zhang M, 2020, IEEE T IMAGE PROCESS, V29, P6276, DOI 10.1109/TIP.2020.2990341
   Zhang Y., 2021, PROC BRIT MACH VIS C, P1
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou X., 2021, IEEE T INSTRUM MEAS
   Zhou XF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3091312
   Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178
   Zhu DD, 2018, J VIS COMMUN IMAGE R, V54, P1, DOI 10.1016/j.jvcir.2018.03.017
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 60
TC 0
Z9 0
U1 4
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103721
DI 10.1016/j.jvcir.2022.103721
EA DEC 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7S8ZY
UT WOS:000911042100001
DA 2024-07-18
ER

PT J
AU Zhou, YG
   Shui, S
   Cai, YJ
   Chen, CY
   Chen, YS
   Abdi-Ghaleh, R
AF Zhou, Yuanguo
   Shui, Shan
   Cai, Yijun
   Chen, Chengying
   Chen, Yingshi
   Abdi-Ghaleh, Reza
TI An improved all-optical diffractive deep neural network with less
   parameters for gesture recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Diffractive deep neural network; Gesture recognition
ID LIGHT
AB As a framework of optical machine learning, all-optical diffractive neural network (D2NN) has delivered an ideal outcome of feature detection and target classification, currently raising high interest in the optics and photonics community. In this paper, we applied an improved D2NN architecture to the field of gesture recognition, which features more complicated contour than the common MNIST handwriting recognition in the previous literature. The proposed network structure incorporates the wavelet-like phase modulation pattern technique and the highway network on the basis of all-optical neural network. Through modulating the phase of incident light, the wavelet-like pattern can substantially reduce the parameters in the network layer. In addition, a highway network is employed to address the vanishing gradient phenomenon in the training process. In the experiment, we numerically achieved blind testing accuracy of 95.6% for identifying ten different gestures, and the number of parameters is only 3% of the regular D2NN. Reliability test and analysis show that the proposed method is a high-efficiency solution with low-parameters expecting for implementation of various machine learning tasks.
C1 [Zhou, Yuanguo; Shui, Shan] Xian Univ Sci & Technol, Coll Commun & Informat Engn, Xian 710054, Peoples R China.
   [Cai, Yijun; Chen, Chengying] Xiamen Univ Technol, Smart Sensing Integrated Circuit Engn Res Ctr Univ, Xiamen 361024, Peoples R China.
   [Cai, Yijun; Chen, Chengying] Chinese Acad Sci, Inst Microelect, Key Lab Microelect Devices & Integrated Technol, Beijing 100191, Peoples R China.
   [Chen, Yingshi] Giga Design Automat Co Ltd, Shenzhen 518055, Peoples R China.
   [Abdi-Ghaleh, Reza] Univ Bonab, Dept Laser & Opt Engn, Bonab, Iran.
C3 Xi'an University of Science & Technology; Xiamen University of
   Technology; Chinese Academy of Sciences; Institute of Microelectronics,
   CAS; University of Bonab
RP Cai, YJ (corresponding author), Xiamen Univ Technol, Smart Sensing Integrated Circuit Engn Res Ctr Univ, Xiamen 361024, Peoples R China.; Cai, YJ (corresponding author), Chinese Acad Sci, Inst Microelect, Key Lab Microelect Devices & Integrated Technol, Beijing 100191, Peoples R China.
EM yijuncai@foxmail.com
RI Chen, Cheng-Ying/E-1662-2011
FU Key Laboratory of Microelectronic Devices Integrated Technology, China;
   Institute of Microelectronics, Chinese Academy of Sciences,; National
   Natural Science Foundation of China [62005232]; Natural Science
   Foundation of Fujian Province, China [2018J05115, 2020J01294]; Xiamen
   Youth Innovation Fund, China [3502Z20206074]; Natural Science Basic
   Research Plan in Shaanxi Province of China [2020JM-515]
FX This work was supported in part by the Opening Project of Key Laboratory
   of Microelectronic Devices Integrated Technology, China, Institute of
   Microelectronics, Chinese Academy of Sciences, by the National Natural
   Science Foundation of China through Grant 62005232, by the Natural
   Science Foundation of Fujian Province, China through Grant 2018J05115
   and 2020J01294, by the Xiamen Youth Innovation Fund, China Project
   through Grant 3502Z20206074, and by the Natural Science Basic Research
   Plan in Shaanxi Province of China through Grant 2020JM-515.
CR [Anonymous], 2001, GRADIENT FLOW RECURR, DOI DOI 10.1109/9780470544037.CH14
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Barbastathis G, 2019, OPTICA, V6, P921, DOI 10.1364/OPTICA.6.000921
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Bueno J, 2018, OPTICA, V5, P756, DOI 10.1364/OPTICA.5.000756
   Chakraborty I, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.014063
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Chao D., 2014, COMPUTER VISION ECCV, V1184, P199
   Chen Y., 2019, arXiv
   Deng T, 2018, IEEE ACCESS, V6, P67951, DOI 10.1109/ACCESS.2018.2878940
   Deng Y, 2017, IEEE T NEUR NET LEAR, V28, P653, DOI 10.1109/TNNLS.2016.2522401
   Dou HK, 2020, OPT LETT, V45, P2688, DOI 10.1364/OL.389696
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Hamerly R., 2019, PHYS REV X, V9, P6
   Hughes TW, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aay6946
   Hughes TW, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064014
   Jiao SM, 2019, OPT LETT, V44, P5186, DOI 10.1364/OL.44.005186
   Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044
   Khoram E, 2019, PHOTONICS RES, V7, P823, DOI 10.1364/PRJ.7.000823
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li JX, 2019, ADV PHOTONICS, V1, DOI 10.1117/1.AP.1.4.046001
   Li Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95178-1
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Luo XG, 2018, ACS PHOTONICS, V5, P4724, DOI 10.1021/acsphotonics.8b01036
   Luo Y, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0223-1
   Minzioni P, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/ab0e66
   Peurifoy J, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aar4206
   Prucnal PR, 2017, NEUROMORPHIC PHOTONICS, P1
   Robertson J, 2017, OPT LETT, V42, P1560, DOI 10.1364/OL.42.001560
   Shainline JM, 2017, PHYS REV APPL, V7, DOI 10.1103/PhysRevApplied.7.034013
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Solli DR, 2015, NAT PHOTONICS, V9, P704, DOI 10.1038/nphoton.2015.208
   Srivastava R.K., 2015, ARXIV
   Woods D, 2012, NAT PHYS, V8, P257, DOI 10.1038/nphys2283
   Yan T, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.023901
   Zhang K., 2014, IEEE T INSTRUM MEAS, V46, P4
   Zhang Q., 2019, LIGHT-SCI APPL, V81, P14
   Zhou TK, 2020, PHOTONICS RES, V8, P940, DOI 10.1364/PRJ.389553
   Zuo Y, 2019, OPTICA, V6, P1132, DOI 10.1364/OPTICA.6.001132
NR 41
TC 4
Z9 4
U1 5
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103688
DI 10.1016/j.jvcir.2022.103688
EA NOV 2022
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5HQ9
UT WOS:000975854100001
DA 2024-07-18
ER

PT J
AU Zhang, H
   Piao, Y
   Huang, BL
   Tan, BL
AF Zhang, Hao
   Piao, Yan
   Huang, Bailiang
   Tan, Baolin
TI SiamMBFAN: Siamese tracker with multi-branch feature aggregation network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Siamese network; Multi -branch network; Feature
   aggregation
ID VISUAL TRACKING; TEMPLATE
AB Siamese trackers have attracted considerable attention in the field of object tracking because of their high precision and speed. However, one of the main disadvantages of Siamese trackers is that their feature extraction network is relatively single. They often use AlexNet or ResNet50 as the backbone network. AlexNet is shallow and thus cannot easily extract abundant semantic information, whereas ResNet50 has many convolutional layers, reducing the real-time performance of Siamese trackers. We propose a multi-branch feature aggregation network with different designs in the shallow and deep convolutional layers. We use the residual module to build the shallow convolutional layers to extract textural and edge features. The deep convolution layers, designed with two independent branches, are built with residual and parallel modules to extract different semantic features. The proposed network has a depth of only nine modules, and thus it is a simple and effective network. We then apply the network to a Siamese tracker to form SiamMBFAN. We design multi-layer classification and regression subnetworks in the Siamese tracker by aggregating the last three modules of the two branches, improving the localization ability of the tracker. Our tracker achieves a better balance between performance and speed. Finally, SiamMBFAN is tested on four challenging benchmarks, including OTB100, VOT2016, VOT2018, and UAV123. Compared with other trackers, our tracker improves by 7% (OTB100).
C1 [Zhang, Hao; Piao, Yan; Huang, Bailiang] Changchun Univ Sci & Technol, Dept Informat & Commun Engn, Changchun, Peoples R China.
   [Tan, Baolin] Shenzhen Yinglun Technol Co LTD, Shenzhen, Peoples R China.
C3 Changchun University of Science & Technology
RP Piao, Y (corresponding author), Changchun Univ Sci & Technol, Dept Informat & Commun Engn, Changchun, Peoples R China.
EM zhanghao@mails.cust.edu.cn; piaoyan@cust.edu.cn; ww5171351@126.com;
   david.tan@yinglun-tech.com
RI Tan, Baolin/AAF-1117-2020
CR [Anonymous], 2017, 31 AAAI C ART INT AA
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Chen Z, 2019, IEEE ACCESS, V7, P88870, DOI 10.1109/ACCESS.2019.2926807
   Cheng SY, 2021, PROC CVPR IEEE, P4419, DOI 10.1109/CVPR46437.2021.00440
   Cui YT, 2021, Arxiv, DOI arXiv:2104.00403
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan Martin, 2014, BRIT MACH VIS C
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Goyal A, 2021, Arxiv, DOI [arXiv:2110.07641, DOI 10.48550/ARXIV.2110.07641, 10.48550/arXiv.2110.07641]
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Gupta DK, 2021, PROC CVPR IEEE, P12357, DOI 10.1109/CVPR46437.2021.01218
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li CH, 2021, VISUAL COMPUT, V37, P587, DOI 10.1007/s00371-020-01825-5
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li ZY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103107
   Maksai A, 2016, Arxiv, DOI arXiv:1612.00604
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Pang HB, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/6645629
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Shi T, 2021, IEEE ACCESS, V9, P44426, DOI 10.1109/ACCESS.2021.3066294
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sosnovik I, 2021, IEEE WINT CONF APPL, P2764, DOI 10.1109/WACV48630.2021.00281
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu CL, 2018, IEEE ACCESS, V6, P43499, DOI 10.1109/ACCESS.2018.2858853
   Wu JL, 2021, PROC CVPR IEEE, P12347, DOI 10.1109/CVPR46437.2021.01217
   Xi Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9381, DOI 10.1109/CVPR42600.2020.00940
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Yiding, 2020, ADV NEURAL INF PROCE, V33, P20286
   Yang Z, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103465
   Yu L., 2021, SIVIP, P1
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zeng F., 2021, arXiv
   Zhang F, 2021, IEEE ACCESS, V9, P27158, DOI 10.1109/ACCESS.2021.3056194
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou WZ, 2021, IEEE T IMAGE PROCESS, V30, P3597, DOI 10.1109/TIP.2021.3060905
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 60
TC 1
Z9 1
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103671
DI 10.1016/j.jvcir.2022.103671
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500001
DA 2024-07-18
ER

PT J
AU Wu, XT
   Luo, ZL
AF Wu, Xiaotian
   Luo, Zhonglin
TI Block-based progressive visual cryptography scheme with uniform
   progressive recovery and consistent background
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret sharing; Visual cryptography; Progressive recovery; Consistent
   background; Image block
ID IMAGE SHARING SCHEME; STEGANOGRAPHY; CONSTRUCTIONS
AB Block-based progressive visual cryptography scheme (BPVCS) divides a secret image into non-overlapping blocks and encodes each block as sub-shadows. The final shadows for BPVCS are created by combining the associated sub-shadows. When enough shadows are superimposed, some of the secret blocks will be exposed. More information will be revealed as more shadows are used. This is referred to as progressive recovery. Hou et al. introduced a (2, n)-BPVCS. Yang et al. further extended the (2, n) scheme to a general (k, n) scheme. However, Yang et al. (k, n)-BPVCS suffers from the non-uniform progressive recovery and inconsistent background of recovered secret blocks. In this paper, we introduce a (k, n)-BPVCS to address the mentioned two defects. Theoretical analysis and experimental results are provided to illustrate the benefits of the proposed approach.
C1 [Wu, Xiaotian; Luo, Zhonglin] Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
C3 Jinan University
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
EM wxiaotian@jnu.edu.cn
FU National Natural Science Foundation of China [61972179]; Guangdong Basic
   and Applied Basic Research Foundation [2020A1515011476]
FX Acknowledgments This work was partially supported by National Natural
   Science Foundation of China (Grant No. 61972179) , Guangdong Basic and
   Applied Basic Research Foundation (Grant No. 2020A1515011476) .
CR Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hu H, 2018, KSII T INTERNET INF, V12, P3401, DOI 10.3837/tiis.2018.07.022
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Li P, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102911
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu YX, 2021, IEEE T INTELL TRANSP, V22, P3952, DOI 10.1109/TITS.2020.2994386
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Shyu SJ, 2012, IEEE T CIRC SYST VID, V22, P769, DOI 10.1109/TCSVT.2011.2180769
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2009, IEEE SIGNAL PROC LET, V16, P659, DOI 10.1109/LSP.2009.2021334
   Wu X., ACM T MULTIM COMPUT
   Wu XT, 2022, INFORM SCIENCES, V583, P73, DOI 10.1016/j.ins.2021.11.013
   Wu XT, 2021, SIGNAL PROCESS, V186, DOI 10.1016/j.sigpro.2021.108122
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V75, P100, DOI 10.1016/j.image.2019.03.017
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Xiong L., IEEE INTERNET THINGS
   Xiong LZ, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108064
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yan XH, 2021, IEEE T CIRC SYST VID, V31, P2896, DOI 10.1109/TCSVT.2020.3025527
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102660
   Yang CN, 2015, ETRI J, V37, P979, DOI 10.4218/etrij.15.0114.0327
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2013, INT WORKSH DIG WAT, P95
NR 48
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103631
DI 10.1016/j.jvcir.2022.103631
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800003
DA 2024-07-18
ER

PT J
AU He, W
   Li, JX
   Qi, Q
   Tu, B
   Ou, XF
   Guo, LY
AF He, Wei
   Li, Jiexin
   Qi, Qi
   Tu, Bing
   Ou, Xianfeng
   Guo, Longyuan
TI SIM-MFR: Spatial interactions mechanisms based multi-feature
   representation for background modeling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Dynamic backgrounds; K-means; Multi-feature;
   Complementary notion
ID DENSITY-ESTIMATION; OBJECT DETECTION; SUBTRACTION; COLOR; PIXEL
AB Moving object detection is frequently used as a springboard for advanced computer vision analysis in complex scenes. Nevertheless, due to unstable changes in the background, most existing background model hardly maintain superior performance. To this concern, we propose a novel pixel-level background model that has three innovations. First, we introduce K-means to directly model the spatiotemporal dependencies between pixels. These dependencies are exploited to discover static core information in the high-frequency changing spatial domain, resulting in excellent property in dynamic backgrounds. Besides, the notion of complementarity is taken as a feature selection criterion. In multi-feature model, the ability to supervise each other between features is important in the ambiguity challenges, e.g., shadow. Finally, feature models recommend each other in the update mechanism, and the diffusion rate of effective information in each feature model can be maximized by finding the best candidate feature. By virtue of this mechanism, model can be updated efficiently when large background migration occurs, e.g., PTZ. Experimental results on some standard benchmarks show that SIM-MFR can achieve promising performance compared to some state-of-the-art approaches.
C1 [He, Wei; Li, Jiexin; Qi, Qi; Tu, Bing; Ou, Xianfeng; Guo, Longyuan] Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang 414006, Peoples R China.
C3 Hunan Institute of Science & Technology
RP Qi, Q (corresponding author), Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang 414006, Peoples R China.
EM hewei@hnist.edu.cn; lijiexin00@hotmail.com; qqi8315@hotmail.com;
   tubing@hnist.edu.cn; ouxf@hnist.edu.cn; guolongyuan@hnist.edu.cn
OI Li, jiexin/0000-0001-7466-3286
FU Foundation of Education Bureau of Hunan Province, China [21B0590,
   19A200]; Open Fund of Education Department of Hunan Province, China
   [20K062]; Science Foundation for Distinguished Yong Scholars of Hunan
   Province, China [2020JJ2017]; Hunan Graduate Student Research Innovation
   Project, China [CX20211189]; College Students' innovation and
   entrepreneurship training program, China [S202110543052]
FX The authors would like to acknowledge that this work was supported in
   part by the Foundation of Education Bureau of Hunan Province, China
   under Grant 21B0590, 19A200; in part by the Open Fund of Education
   Department of Hunan Province, China under Grant 20K062; in part by the
   Science Foundation for Distinguished Yong Scholars of Hunan Province,
   China under Grant 2020JJ2017; in part by the Hunan Graduate Student
   Research Innovation Project, Chinaunder Grant CX20211189; in part by
   College Students' innovation and entrepreneurship training program,
   China S202110543052
CR Ammar S, 2019, LECT NOTES COMPUT SC, V11845, P307, DOI 10.1007/978-3-030-33723-0_25
   [Anonymous], 1999, IEEE COMPUTER SOC C
   [Anonymous], 2013, 9 WORKSHOP VISAO COM
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Babaryka Anatolii, 2022, Future Intent-Based Networking: On the QoS Robust and Energy Efficient Heterogeneous Software Defined Networks. Lecture Notes in Electrical Engineering (831), P468, DOI 10.1007/978-3-030-92435-5_26
   Bao LC, 2014, PROC CVPR IEEE, P3534, DOI 10.1109/CVPR.2014.452
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   Camplani M, 2014, J VIS COMMUN IMAGE R, V25, P122, DOI 10.1016/j.jvcir.2013.03.009
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chiranjeevi P, 2012, J VIS COMMUN IMAGE R, V23, P948, DOI 10.1016/j.jvcir.2012.06.004
   Friedman N, 2013, Arxiv, DOI arXiv:1302.1539
   Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204
   Giraldo JH, 2021, COMM COM INF SC, V1405, P31, DOI 10.1007/978-3-030-81638-4_3
   Giraldozuluaga JH, 2022, IEEE T PATTERN ANAL, V44, P2485, DOI 10.1109/TPAMI.2020.3042093
   Greggio Nicola, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P983, DOI 10.1109/ISDA.2010.5687059
   Guo Lili., 2016, P IEEE C COMP VIS PA, P86
   He W, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103278
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkila Marko., 2004, BMVC, P1
   Hongxun Z, 2006, LECT NOTES COMPUT SC, V4223, P887
   Jabri S, 2000, INT C PATT RECOG, P627, DOI 10.1109/ICPR.2000.902997
   Jain V., 2007, 2007 IEEE INT C IM P
   Javed S, 2018, 2018 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P836, DOI 10.1109/SSP.2018.8450718
   López-Rubio FJ, 2015, COMPUT VIS IMAGE UND, V133, P30, DOI 10.1016/j.cviu.2014.12.007
   Jeyabharathi D, 2018, J VIS COMMUN IMAGE R, V55, P434, DOI 10.1016/j.jvcir.2018.06.024
   Ji ZJ, 2014, PATTERN RECOGN, V47, P2952, DOI 10.1016/j.patcog.2014.03.016
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Klare Brendan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P66, DOI 10.1109/CVPR.2009.5204078
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lei Shang, 2019, 2019 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS). Proceedings, P324
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lin CW, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P259, DOI 10.1109/AVSS.2014.6918678
   López-Rubio E, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065717500563
   Lu XQ, 2014, IEEE IMAGE PROC, P3268, DOI 10.1109/ICIP.2014.7025661
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Maddalena L, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050071
   Mandal M, 2022, IEEE T INTELL TRANSP, V23, P6101, DOI [10.1109/TITS.2021.3077883, 10.3233/IP-200233]
   Minematsu T, 2020, IEEE IMAGE PROC, P3229, DOI 10.1109/ICIP40778.2020.9191151
   Minematsu Tsubasa, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P1
   Miron A, 2015, INT CONF SYST SIGNAL, P273, DOI 10.1109/IWSSIP.2015.7314229
   Mittal A, 2004, PROC CVPR IEEE, P302
   Munteanu O., 2015, T ELECT COMMUN, V60, P1
   Noh SeungJong., 2012, AS C COMP VIS, P493
   Panda DK, 2018, J VIS COMMUN IMAGE R, V56, P52, DOI 10.1016/j.jvcir.2018.07.014
   Rodriguez P, 2016, J MATH IMAGING VIS, V55, P1, DOI 10.1007/s10851-015-0610-z
   Roy SM, 2018, IEEE T CIRC SYST VID, V28, P1513, DOI 10.1109/TCSVT.2017.2669362
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003
   St-Charles PL, 2014, IEEE WINT CONF APPL, P509, DOI 10.1109/WACV.2014.6836059
   Subudhi BN, 2016, INFORM SCIENCES, V366, P31, DOI 10.1016/j.ins.2016.04.049
   T H.-H., 2012, IEEE T COMPONENTS, V3, P1
   Tang P, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P530, DOI 10.1109/ICIG.2007.61
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Van Droogenbroeck M, 2014, VIBE DISRUPTIVE METH
   Varadarajan S, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P63, DOI 10.1109/AVSS.2013.6636617
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu M, 2018, NEUROCOMPUTING, V314, P120, DOI 10.1016/j.neucom.2018.03.001
   Xu M., 2001, BMVC, P1
   Yang D, 2018, IEEE T IMAGE PROCESS, V27, P1112, DOI 10.1109/TIP.2017.2768828
   [姚杰 Yao Jie], 2007, [作物杂志, Crops], P1
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 69
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103622
DI 10.1016/j.jvcir.2022.103622
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2FV
UT WOS:000859982300002
DA 2024-07-18
ER

PT J
AU Li, P
   Yin, LP
   Ma, JF
   Wang, HT
AF Li, Peng
   Yin, Liping
   Ma, Jianfeng
   Wang, Hongtao
TI XOR-based visual cryptography scheme with essential shadows
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE XOR operation; Essential shadows; Visual cryptography; Secret image
   sharing; Shadow image; Access structure partition
ID IMAGE SHARING SCHEME; SECRET; QUALITY
AB Visual cryptography scheme with essential shadows (EVCS) is of great significance since it provides different levels of the importance to shadows. In this paper, we propose a general construction method for (t, s, k, n)-VCS with essential shadows based on XOR operation ((t, s, k, n)-EXVCS), which originates from the partition of access structure. The secret image is encrypted into s essential shadows and n -s non-essential shadows. Any k shadows including at least t essentials can cooperate to decode the secret image and the decoding process is implemented by XOR operation on the involved shadows. Our scheme achieves perfectly reconstruction of secret image in the revealed image and the less size of shadows and revealed images. The experiments are conducted to testify the feasibility and practicability of the proposed scheme.
C1 [Li, Peng; Yin, Liping; Ma, Jianfeng] North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei, Peoples R China.
   [Wang, Hongtao] North China Elect Power Univ, Sch Control & Comp Engn, Baoding 071003, Hebei, Peoples R China.
C3 North China Electric Power University; North China Electric Power
   University
RP Li, P (corresponding author), North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei, Peoples R China.
EM lphit@163.com
RI Ma, Jianfeng/GZB-0110-2022
OI Li, Peng/0000-0003-1008-8934
FU Natural Science Foundation of Hebei Province [F2019502173]; National
   Natural Science Foundation of China [61802124, 61602173]; Fundamental
   Research Funds for Central Universities [2019MS116]
FX Acknowledgement This research was partially supported by Natural Science
   Foundation of Hebei Province (Grant number: F2019502173) , National
   Natural Science Foundation of China (Grant numbers: 61802124, 61602173)
   and the Fundamental Research Funds for Central Universities (Grant
   number: 2019MS116) .
CR Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chen CC, 2016, J VIS COMMUN IMAGE R, V38, P595, DOI 10.1016/j.jvcir.2016.04.004
   Chen SK, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.1.013103
   Chen YC, 2017, IEEE T INF FOREN SEC, V12, P1082, DOI 10.1109/TIFS.2016.2641378
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Ding WM, 2018, INT J DIGIT CRIME FO, V10, P120, DOI 10.4018/IJDCF.2018040107
   Guo T, 2014, LECT NOTES COMPUT SC, V8317, P56, DOI 10.1007/978-3-319-04268-8_4
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Lakshmanan R, 2017, DESIGN CODE CRYPTOGR, V82, P629, DOI 10.1007/s10623-016-0181-z
   Li P, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102911
   Li P, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8050838
   Li P, 2018, INT J DIGIT CRIME FO, V10, P78, DOI 10.4018/IJDCF.2018070107
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Liu F, 2010, LECT NOTES COMPUTER, V9023, P333
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Liu ZQ, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3418212
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2018, MULTIMED TOOLS APPL, V77, P12871, DOI 10.1007/s11042-017-4921-5
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shivani S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2935618
   Shyu SJ, 2014, IEEE SIGNAL PROC LET, V21, P1521, DOI 10.1109/LSP.2014.2344093
   Srividhya S, 2016, J VIS COMMUN IMAGE R, V38, P284, DOI 10.1016/j.jvcir.2016.03.012
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DH, 2010, IEEE PEDG 2010: THE 2ND INTERNATIONAL SYMPOSIUM ON POWER ELECTRONICS FOR DISTRIBUTED GENERATION SYSTEMS, P1, DOI 10.1109/PEDG.2010.5545769
   Wu X., 2013, P 1 ACM WORKSH INF H, P181, DOI [10.1177/1753193413497191, DOI 10.1145/2482513.2482515]
   Wu XT, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2020.102452
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Wu XT, 2018, SIGNAL PROCESS-IMAGE, V66, P42, DOI 10.1016/j.image.2018.05.001
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
NR 39
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103513
DI 10.1016/j.jvcir.2022.103513
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L9NQ
UT WOS:000799607600001
DA 2024-07-18
ER

PT J
AU Jin, X
   Su, YT
   Jing, PG
AF Jin, Xiao
   Su, Yuting
   Jing, Peiguang
TI Video frame deletion detection based on time-frequency analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital video forensics; Frame tampering detection; Nonlinear
   quantization; S transform
ID FORENSICS; FORGERY
AB With the emergence of diverse multimedia editing software, a great number of edited or tampered video resources appear on the Internet, some of which can mix with the genuine ones. Digital video authenticity is an important step to make the best use of these video resources. As a common video forgery operation, frame tampering can change the video content and confuse viewers by removing or inserting some specific frames. In this paper, we explore the traces created by compression process and propose a new method to detect frame tampering based on the high-frequency features of reconstructed DCT coefficients in the tampered sequences. Experimental results demonstrate that our proposed method can effectively detect frame tampering operation, and accurately locate the breakpoint of frame tampering in the streams.
C1 [Jin, Xiao] Nankai Univ, Coll Artificial Intelligence, Tianjin, Peoples R China.
   [Su, Yuting; Jing, Peiguang] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Nankai University; Tianjin University
RP Jin, X (corresponding author), Nankai Univ, Coll Artificial Intelligence, Tianjin, Peoples R China.; Su, YT (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM jinxiao@nankai.edu.cn; ytsu@tju.edu.cn
RI Jin, Xiao/IVV-4814-2023
FU Fundamental Research Funds for the Central Universities of Nankai
   University, China [63201192, 63211116]; National Natural Science
   Foundation of China [61572356]; Tianjin Research Program of Application
   Foun-dation and Advanced Technology, China [15JCQNJC41600]
FX Acknowledgments This work was supported in part by the Fundamental
   Research Funds for the Central Universities of Nankai University, China
   (63201192, 63211116) , the National Natural Science Foundation of China
   (61572356) , the Tianjin Research Program of Application Foun-dation and
   Advanced Technology, China (15JCQNJC41600) .
CR [Anonymous], 2011, 2011 IEEE INT WORKSH
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Bestagini P, 2013, IEEE IMAGE PROC, P4457, DOI 10.1109/ICIP.2013.6738918
   Bestagini P, 2016, IEEE T IMAGE PROCESS, V25, P2298, DOI 10.1109/TIP.2016.2541960
   Bian S, 2014, IEEE T CIRC SYST VID, V24, P2144, DOI 10.1109/TCSVT.2014.2334031
   Brown RA, 2008, IEEE ENG MED BIO, P2586, DOI 10.1109/IEMBS.2008.4649729
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Costa F. d. O., 2016, IEEE INT WORKS INFOR, P1
   Costa FO, 2015, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.2015.7350808
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Jiang XH, 2018, IEEE T INF FOREN SEC, V13, P170, DOI 10.1109/TIFS.2017.2745687
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Nguyen X.H., 2020, Int. J. Image, V3, P1
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Stockwell RG, 1996, IEEE T SIGNAL PROCES, V44, P998, DOI 10.1109/78.492555
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Su PC, 2015, J VIS COMMUN IMAGE R, V29, P103, DOI 10.1016/j.jvcir.2015.02.006
   Ulutas G, 2017, MULTIMEDIA SYST, P1
   Visentini-Scarzanella M, 2013, IEEE INT WORKSH MULT, P412, DOI 10.1109/MMSP.2013.6659324
   Wang Q., 2014, Sens. Transducers, V166, P229
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Yao H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120313
   Yuting Su, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P461, DOI 10.1109/ITAIC.2011.6030373
   Zhang Y, 2014, IEEE T IMAGE PROCESS, V23, P4112, DOI 10.1109/TIP.2014.2344296
   Zhu H., 2004, ANZIAM J, V45, P1002
NR 35
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103436
DI 10.1016/j.jvcir.2022.103436
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200003
DA 2024-07-18
ER

PT J
AU Rahman, WU
   Amin, MB
   Hossain, MD
   Hong, CS
   Huh, EN
AF Rahman, Waqas Ur
   Amin, Muhammad Bilal
   Hossain, Md Delowar
   Hong, Choong Seon
   Huh, Eui-Nam
TI QoE optimization for HTTP adaptive streaming: Performance evaluation of
   MEC-assisted and client-based methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality of experience; DASH; Fairness; HTTP adaptive streaming; Video
ID RATE ADAPTATION; BITRATE ADAPTATION; QUALITY
AB Seamless streaming of high quality video under unstable network condition is a big challenge. HTTP adaptive streaming (HAS) provides a solution that adapts the video quality according to the network conditions. Traditionally, HAS algorithm runs at the client side while the clients are unaware of bottlenecks in the radio channel and competing clients. The traditional adaptation strategies do not explicitly coordinate between the clients, servers, and cellular networks. The lack of coordination has been shown to lead to suboptimal user experience. As a response, multi-access edge computing (MEC)-assisted adaptation techniques emerged to take advantage of computing and content storage capabilities in mobile networks. In this study, we investigate the performance of both MEC-assisted and client-side adaptation methods in a multi-client cellular environment. Evaluation and comparison are performed in terms of not only the video rate and dynamics of the playback buffer but also the fairness and bandwidth utilization. We conduct extensive experiments to evaluate the algorithms under varying client, server, dataset, and network settings. Results demonstrate that the MEC-assisted algorithms improve fairness and bandwidth utilization compared to the client-based algorithms for most settings. They also reveal that the buffer-based algorithms achieve significant quality of experience; however, these algorithms perform poorly compared with throughput-based algorithms in protecting the playback buffer under rapidly varying bandwidth fluctuations. In addition, we observe that the preparation of the representation sets affects the performance of the algorithms, as does the playback buffer size and segment duration. Finally, we provide suggestions based on the behaviors of the algorithms in a multi-client environment.
C1 [Rahman, Waqas Ur] Birmingham City Univ, Fac Comp Engn & Built Environm, Digital Media Technol Lab, Birmingham, W Midlands, England.
   [Hossain, Md Delowar; Hong, Choong Seon; Huh, Eui-Nam] Kyung Hee Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Amin, Muhammad Bilal] Univ Tasmania, Sch Technol Environm & Design, Hobart, Tas, Australia.
C3 Birmingham City University; Kyung Hee University; University of Tasmania
RP Huh, EN (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Seoul, South Korea.; Huh, EN (corresponding author), Kyung Hee Univ, Elect & Informat Bldg,Room 331, Yongin 17104, Gyeonggi Do, South Korea.
EM bilal.amin@utas.edu.au; delowar@khu.ac.kr; cshong@khu.ac.kr;
   johnhuh@khu.ac.kr
RI Hong, Choong Seon/ABF-5527-2020; Amin, Muhammad/KLC-5986-2024; Rahman,
   Waqas ur/X-4387-2019
OI Amin, Muhammad/0000-0002-5079-2881; Rahman, Waqas ur/0000-0002-3849-6596
FU MSIT (Ministry of Science and ICT) , Korea, under the Grand Information
   Technology Research Center support program [IITP-2021-2015-0-00742]
FX Acknowledgement This research was supported by the MSIT (Ministry of
   Science and ICT) , Korea, under the Grand Information Technology
   Research Center support program (IITP-2021-2015-0-00742) supervised by
   the IITP (Institute for Information & communications Technology Planning
   & Evaluation) .
CR Adobe, CONFIGURE HTTP DYNAM
   Aggarwal V, 2011, 2011 18 IEEE WORKSHO, P1
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 1984, ACM Transaction on Computer Systems
   [Anonymous], 2013, 26247V1210 3GPP
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], 2019, CISCO VISUAL NETWORK
   Ayad I, 2018, COMPUT NETW, V133, P90, DOI 10.1016/j.comnet.2018.01.019
   Azumi M, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417622
   Bilal K, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P68, DOI 10.1109/FMEC.2017.7946410
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Egger Sebastian., 2014, Proceedings of the 2014 Workshop on Design, Quality and Deployment of Adaptive Video Streaming, P31
   Hossfeld Tobias, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P111, DOI 10.1109/QoMEX.2014.6982305
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Le HT, 2018, SIGNAL PROCESS-IMAGE, V65, P154, DOI 10.1016/j.image.2018.03.014
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu Y, 2013, PROC IEEE PACKET VID, P1
   Ma G, 2017, IEEE J SEL AREA COMM, V35, P1076, DOI 10.1109/JSAC.2017.2680958
   Martin A, 2019, IEEE T BROADCAST
   Mehrabi A, 2019, IEEE T MOBILE COMPUT, V18, P787, DOI 10.1109/TMC.2018.2850026
   Mehrabi M, 2019, IEEE ACCESS, V7, P166079, DOI 10.1109/ACCESS.2019.2953172
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Ni P., 2011, P 19 ACM INT C MULT, P463, DOI DOI 10.1145/2072298.2072359
   Nunna S, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P601, DOI 10.1109/ITNG.2015.155
   Pantos R., HTTP live streaming
   Qi YN, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P423
   Rahman WU, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P226, DOI [10.1109/icoin48656.2020.9016583, 10.1109/ICOIN48656.2020.9016583]
   Rahman WU, 2019, IEEE ACCESS, V7, P129082, DOI 10.1109/ACCESS.2019.2940292
   Rahman WU, 2018, IEEE ACCESS, V6, P77869, DOI 10.1109/ACCESS.2018.2884248
   Rahman WU, 2018, MULTIMEDIA SYST, V24, P509, DOI 10.1007/s00530-018-0588-7
   Rahman WU, 2017, J VIS COMMUN IMAGE R, V49, P433, DOI 10.1016/j.jvcir.2017.10.007
   Shen Y, 2015, IEICE T COMMUN, VE98B, P62, DOI 10.1587/transcom.E98.B.62
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Stohr D, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1113, DOI 10.1145/3123266.3123426
   Tran TX, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600863
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Wang DS, 2019, IEEE T SERV COMPUT, V12, P685, DOI 10.1109/TSC.2018.2828426
   Xiang Z, 2019, IEEE J SEL AREA COMM, V37, P1098, DOI 10.1109/JSAC.2019.2906788
   Yan ZS, 2017, IEEE T CIRC SYST VID, V27, P209, DOI 10.1109/TCSVT.2016.2539827
   Yang SR, 2019, IEEE T VEH TECHNOL, V68, P1888, DOI 10.1109/TVT.2018.2889196
   Yi S, 2017, P 2 ACMIEEE S EDGE C, P1
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Zambelli Alex., 2009, IIS Smooth Streaming Technical Overview
NR 52
TC 1
Z9 1
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103415
DI 10.1016/j.jvcir.2021.103415
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400007
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Fang, YZ
AF Fang, Yuzhi
TI Robust multimodal discrete hashing for cross-modal similarity search
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hashing; Robust; Cross-modal retrieval; Unsupervised learning
ID IMAGE FEATURES; RETRIEVAL
AB Hashing technology improves the search efficiency and reduces the storage space of data. However, building an effective modal with unsupervised cross modal retrieval and generating efficient binary code is still a challenging task, considering of some issues needed to be further discussed and researched for unsupervised multimodal hashing. Most of the existing methods ignore the discrete restriction, and manually or experientially determine the weights of each modality. These limitations may significantly reduce the retrieval accuracy of unsupervised cross-modal hashing methods. To solve these problems, we propose a robust hash modal that can efficiently learn binary code by employing a flexible and noise-resistant l(2,1)-loss with nonlinear kernel embedding. In addition, we introduce an intermediate state mapping that facilitate later modal optimization to measure the loss between the hash codes and the intermediate states. Experiments on several public multimedia retrieval datasets validate the superiority of the proposed method from various aspects.
C1 [Fang, Yuzhi] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Fang, Yuzhi] Shandong Management Univ, Coll Informat Engn, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Management University
RP Fang, YZ (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM abcdfangyuzhi@163.com
RI fang, yu/KCK-2014-2024
CR [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2012, Book A probabilistic model for multimodal hash function learning, DOI DOI 10.1145/2339530.2339678
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia, DOI [DOI 10.1145/2072298.2072344, 10.1145/2072298.2072344.URL, DOI 10.1145/2072298.2072344.URL]
   [Anonymous], 2016, IEEE T BIG DATA
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cai X, 2013, IEEE I CONF COMP VIS, P1737, DOI 10.1109/ICCV.2013.218
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Dong X, 2018, MULTIMED TOOLS APPL, V77, P3579, DOI 10.1007/s11042-017-5164-1
   Flores E, 2019, PATTERN RECOGN, V89, P32, DOI 10.1016/j.patcog.2018.12.019
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gao NN, 2018, PATTERN RECOGN, V75, P214, DOI 10.1016/j.patcog.2017.05.011
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Greene D., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), P722, DOI 10.1109/SFCS.1994.365720
   Pedronette DCG, 2018, PATTERN RECOGN, V75, P161, DOI 10.1016/j.patcog.2017.05.009
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   Guo YR, 2018, PATTERN RECOGN LETT, V109, P55, DOI 10.1016/j.patrec.2017.08.026
   Hannun A, 2014, ARXIV14125567V2CSCL
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Hou R, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102599
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lee SG, 2011, LINEAR ALGEBRA APPL, V435, P2097, DOI 10.1016/j.laa.2010.09.034
   Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu Hong, 2016, IJCAI, P1767, DOI DOI 10.1109/TIP.2016.2564638
   Liu L, 2017, INT J COMPUT VISION, V122, P439, DOI 10.1007/s11263-016-0931-4
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P28665, DOI 10.1007/s11042-018-6006-5
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1129, DOI 10.1145/3343031.3350999
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Ma Q, 2019, PATTERN RECOGN, V92, P156, DOI 10.1016/j.patcog.2019.03.022
   Ngo DCL, 2006, IEEE T CIRC SYST VID, V16, P771, DOI 10.1109/TCSVT.2006.873780
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen YM, 2017, IEEE I CONF COMP VIS, P4117, DOI 10.1109/ICCV.2017.441
   Singh A. P., 2008, P 14 ACM SIGKDD INT, P650
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Wang D, 2018, IEEE T CIRC SYST VID, V28, P2703, DOI 10.1109/TCSVT.2017.2723302
   Wang D, 2019, IEEE T PATTERN ANAL, V41, P2466, DOI 10.1109/TPAMI.2018.2861000
   Wang D, 2016, IEEE T IMAGE PROCESS, V25, P4540, DOI 10.1109/TIP.2016.2592800
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang Di, 2020, P INT ACM SIGIR C RE
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhou XY, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P631
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
NR 54
TC 5
Z9 6
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103256
DI 10.1016/j.jvcir.2021.103256
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100008
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Ding, LH
   Li, YX
   Lin, WY
   Zhao, MB
   Yu, XY
   Zhan, YL
AF Zhang, Yufeng
   Ding, Lianghui
   Li, Yuxi
   Lin, Weiyao
   Zhao, Mingbi
   Yu, Xiaoyuan
   Zhan, Yunlong
TI A regional distance regression network for monocular object distance
   estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular distance estimation; Object detection; Deep neural network;
   Surveillance
AB Monocular pipelines are convenient and cost-effective solutions for object distance estimation in 3D vision. Current methods for monocular object distance estimation either perform inaccurately or require heavy work on data collection. In this paper, we propose a network with R-CNN based structure to implement object detection and distance estimation simultaneously. We append an efficient branch to integrate the information of camera extrinsic parameters with RGB data in our network. Further, optimized multi-scale feature is utilized to enrich the representation power of deep feature, hence to enhance the estimation accuracy. Finally, several regression methods are explored to improve distance estimation results. We train and validate our network on KITTI object dataset, and compare with other methods to show that our method is accurate and easy to train. To prove the generality of our method under other scenarios, we construct a dataset of surveillance scenes, and conduct similar experiments on this dataset.
C1 [Zhang, Yufeng; Ding, Lianghui; Li, Yuxi; Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China.
   [Zhao, Mingbi; Yu, Xiaoyuan] Huawei Cloud, Shenzhen, Peoples R China.
   [Zhan, Yunlong] Huawei Hisilicon, Shenzhen, Peoples R China.
C3 Shanghai Jiao Tong University; Huawei Technologies; Huawei Technologies
RP Ding, LH (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China.
EM lhding@sjtu.edu.cn
RI Wang, Huiyan/JXW-9178-2024; cai, wen/JWP-4797-2024; Zhang,
   Yufeng/GZL-1973-2022; zhang, weijie/JQX-1450-2023; zhang,
   yu/HNS-5948-2023; lin, yuxi/HKF-6212-2023; liu, xq/JDW-2596-2023; sun,
   yuan/KBD-3926-2024; Guo, Lin/KFS-9366-2024
OI Lin, Weiyao/0000-0001-8307-7107
FU National Key Research and Development Program of China [2018AAA0100400];
   National Natural Science Foundation of China [61971277, 61771309]; Joint
   Fund on Advanced Space Technology [USCAST2020-26]
FX The paper is supported in part by the following grants: National Key
   Research and Development Program of China Grant (No. 2018AAA0100400) ,
   National Natural Science Foundation of China (No. 61971277, 61771309) ,
   and Joint Fund on Advanced Space Technology (No. USCAST2020-26) .
CR Abu-Haimed Husam, 2019, ABS190904182 CORR
   Ali A.A., 2016, MPRA Paper, n. 71112,, P1
   [Anonymous], 2018, ARXIV PREPRINT ARXIV, Vabs/1806.01260
   [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00487
   Bertoni L, 2019, IEEE I CONF COMP VIS, P6860, DOI 10.1109/ICCV.2019.00696
   Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Caesar H., 2019, ARXIV PREPRINT ARXIV
   Cai YJ, 2020, AAAI CONF ARTIF INTE, V34, P10478
   Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Liu ZC, 2020, IEEE COMPUT SOC CONF, P4289, DOI 10.1109/CVPRW50498.2020.00506
   Massa F., 2018, maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch
   Michels J., 2005, P 22 INT C MACHINE L, P593, DOI [10.1145/1102351.1102426, DOI 10.1145/1102351.1102426]
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2007, IEEE I CONF COMP VIS, P1
   Tang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205941
   Tuohy S., 2010, IET Irish Signals and Systems Conference (ISSC 2010), P100, DOI 10.1049/cp.2010.0495
   Weng XS, 2019, IEEE INT CONF COMP V, P857, DOI 10.1109/ICCVW.2019.00114
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Yi Hongwei, 2019, ABS191204799 CORR
   You Y., 2019, PROC BRIT MACH VIS C
   Zhou X., 2019, ABS190407850 ARXIV
NR 33
TC 9
Z9 9
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103224
DI 10.1016/j.jvcir.2021.103224
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900007
DA 2024-07-18
ER

PT J
AU Sun, MY
   Li, KQ
   Qi, XQ
   Dang, H
   Zhang, GH
AF Sun, Muyi
   Li, Kaiqi
   Qi, Xingqun
   Dang, Hao
   Zhang, Guanhong
TI Contextual information enhanced convolutional neural networks for
   retinal vessel segmentation in color fundus images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Retinal vessel segmentation; Color fundus image analysis; Semantic
   segmentation; Cascaded dilated module; Context fusion
AB Accurate retinal vessel segmentation is a challenging problem in color fundus image analysis. An automatic retinal vessel segmentation system can effectively facilitate clinical diagnosis and ophthalmological research. In general, this problem suffers from various degrees of vessel thickness, perception of details, and contextual feature fusion in technique. For addressing these challenges, a deep learning based method has been proposed and several customized modules have been integrated into the well-known U-net with encoder-decoder architecture, which is widely employed in medical image segmentation. In the network structure, cascaded dilated convolutional modules have been integrated into the intermediate layers, for obtaining larger receptive field and generating denser encoded feature maps. Also, the advantages of the pyramid module with spatial continuity have been taken for multi-thickness perception, detail refinement, and contextual feature fusion. Additionally, the effectiveness of different normalization approaches has been discussed on different datasets with specific properties. Finally, sufficient comparative experiments have been enforced on three retinal vessel segmentation datasets, DRIVE, CHASE_DB1, and the STARE dataset with unhealthy samples. As a result, the proposed method outperforms the work of predecessors and achieves state-of-the-art performance.
C1 [Sun, Muyi] Chinese Acad Sci, Inst Automat, Ctr Res Intelligent Percept & Comp, Beijing 100876, Peoples R China.
   [Sun, Muyi; Li, Kaiqi; Qi, Xingqun; Dang, Hao] Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.
   [Dang, Hao] Henan Univ Chinese Med, Sch Informat Technol, Zhengzhou 450046, Henan, Peoples R China.
   [Zhang, Guanhong] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Beijing
   University of Posts & Telecommunications; Henan University of
   Traditional Chinese Medicine; Beijing University of Posts &
   Telecommunications
RP Dang, H (corresponding author), Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.; Dang, H (corresponding author), Henan Univ Chinese Med, Sch Informat Technol, Zhengzhou 450046, Henan, Peoples R China.; Zhang, GH (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
EM muyi.sun@cripac.ia.ac.cn; Lkq1997@bupt.edu.cn; XingqunQi@bupt.edu.cn;
   danglee@bupt.edu.cn; zghzgh1779@bupt.edu.cn
RI 张, 贯虹/Y-8478-2019; Sun, Muyi/ABA-4342-2021
OI Qi, Xingqun/0000-0002-9772-5707
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Alom MZ., 2018, HIST BEGAN ALEXNET C
   [Anonymous], 2017, PYTORCH
   Baker ML, 2008, STROKE, V39, P1371, DOI 10.1161/STROKEAHA.107.496091
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen Y, 2019, MIDL
   Cinsdikici MG, 2009, COMPUT METH PROG BIO, V96, P85, DOI 10.1016/j.cmpb.2009.04.005
   Combes J.-M., 1990, IMPLEMENTATION ALGOR, P298
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Ghaderi R, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P1251
   Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Hung WC, 2017, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2017.287
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Khowaja SA, 2019, SIGNAL IMAGE VIDEO P, V13, P379, DOI 10.1007/s11760-018-1366-x
   Laibacher T, 2019, IEEE COMPUT SOC CONF, P115, DOI 10.1109/CVPRW.2019.00020
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Li Q, 2012, EXPERT SYST APPL, V39, P7600, DOI 10.1016/j.eswa.2011.12.046
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Melinscak Martina, 2015, VISAPP 2015 10 INT C
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Osareh A, 2009, IRAN J SCI TECHNOL B, V33, P191
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shah MP, 2018, LECT NOTES COMPUT SC, V11073, P379, DOI 10.1007/978-3-030-00937-3_44
   Sreejini KS, 2015, EGYPT INFORM J, V16, P253, DOI 10.1016/j.eij.2015.06.004
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Ulyanov Dmitry, 2016, arXiv
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Winder RJ, 2009, COMPUT MED IMAG GRAP, V33, P608, DOI 10.1016/j.compmedimag.2009.06.003
   Wu AR, 2016, I S BIOMED IMAGING, P1363, DOI 10.1109/ISBI.2016.7493520
   Wu BT, 2018, I S BIOMED IMAGING, P1109, DOI 10.1109/ISBI.2018.8363765
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Yang Y, 2008, INT J AP MAT COM-POL, V18, P399, DOI 10.2478/v10006-008-0036-5
   Yu FX, 2014, PR MACH LEARN RES, V32, P946
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao K., 2013, OPHTHALMOLOGY, P217
   Zhuang J.T., 2018, ARXIV PREPRINT ARXIV
NR 58
TC 11
Z9 11
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103134
DI 10.1016/j.jvcir.2021.103134
EA MAY 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, B
   Yao, Z
   Zhang, YH
   Yu, LJ
AF Sun, Bo
   Yao, Zeng
   Zhang, Yinghui
   Yu, Lejun
TI Local relation network with multilevel attention for visual question
   answering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual question answering; Relation network; Attention mechanism
AB With the tremendous success of the visual question answering (VQA) tasks, visual attention mechanisms have become an indispensable part of VQA models. However, these attention-based methods do not consider any relationship among regions, which is crucial for the thorough understanding of the image by the model. We propose local relation networks for generating context-aware image features for each image region, which contain information on the relationship among the other image regions. Furthermore, we propose a multilevel attention mechanism to combine semantic information from the LRNs and the original image regions, rendering the decision of the model more reasonable. With these two measures, we improve the region representation and achieve better attentive effect and VQA performance. We conduct numerous experiments on the COCO-QA dataset and the largest VQA v2.0 benchmark dataset. Our model achieves competitive results, proving the effectiveness of our proposed LRNs and multilevel attention mechanism through visual demonstrations. (C) 2020 Published by Elsevier Inc.
C1 [Sun, Bo; Yao, Zeng; Zhang, Yinghui; Yu, Lejun] Beijing Normal Univ, Intelligent Comp & Software Res Ctr, Sch Artificial Intelligence, Beijing, Peoples R China.
C3 Beijing Normal University
RP Yu, LJ (corresponding author), Beijing Normal Univ, Informat Sci & Technol Coll, Beijing 100875, Peoples R China.
EM tosunbo@bnu.edu.cn; yaozeng@mail.bnu.edu.cn; yulenjun@bnu.edu.cn
RI Zhang, Y J/HLG-1022-2023; z, y/HPC-0477-2023; 张, 迎辉/HHD-0706-2022;
   zhang, ying/HJB-1230-2022
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2018, IEEE T NEUR NET LEAR, DOI DOI 10.1109/TNNLS.2018.2817340
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   De Marneffe M.-C., 2006, P INT C LANG RES EV, P449
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Kim JH, 2016, ADV NEUR IN, V29
   Kim JH, 2018, ADV NEUR IN, V31
   King DB, 2015, ACS SYM SER, V1214, P1
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li R., 2016, Advances in Neural Information Processing Systems, V29, P4655
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4216
   Lu JS, 2016, ADV NEUR IN, V29
   Lu P., 32 AAAI C ART INT
   Maas A.L, 2013, ICML
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Ren M., 2015, NEURIPS, P2953
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salimans T, 2016, ADV NEUR IN, V29
   Santra A, 2017, ADV GEOSPAT TECH, P1, DOI 10.4018/978-1-5225-1814-3
   Schwartz I, 2017, ADV NEUR IN, V30
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu CF, 2018, ADV NEUR IN, V31
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhu C, 2017, IEEE I CONF COMP VIS, P1300, DOI 10.1109/ICCV.2017.145
NR 37
TC 9
Z9 9
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102762
DI 10.1016/j.jvcir.2020.102762
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200001
DA 2024-07-18
ER

PT J
AU Wang, SQ
   Kong, J
   Jiang, M
   Liu, TS
AF Wang, Shengquan
   Kong, Jun
   Jiang, Min
   Liu, Tianshan
TI Multiple depth-levels features fusion enhanced network for action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Two-stream; Multiple depth-levels features fusion;
   Group-wise spatial-channel enhance
ID HISTOGRAMS
AB As a challenging task of video classification, action recognition has become a significant topic of computer vision community. The most popular methods based on two-stream architecture up to now are still simply fusing the prediction scores of each stream. In that case, the complementary characteristics of two streams cannot be fully utilized and the effect of shallower features is often overlooked. In addition, the equal treatment to features may weaken the role of the feature contributing significantly to the classification. Accordingly, a novel network called Multiple Depth-levels Features Fusion Enhanced Network (MDFFEN) is proposed. It improves on two aspects of two-stream architecture. In terms of the two-stream interaction mechanism, multiple depth-levels features fusion (MDFF) is formed to aggregate spatial-temporal features extracted from several sub-modules of original two streams by spatial-temporal features fusion (STFF). And with respect to further refining the spatiotemporal features, we propose a group-wise spatial-channel enhance (GSCE) module to highlight the meaningful regions and expressive channels automatically by priority assignment. The competitive results are achieved after we validate MDFFEN on three public challenging action recognition datasets, HDMB51, UCF101 and ChaLearn LAP IsoGD.
C1 [Wang, Shengquan; Kong, Jun; Jiang, Min] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
   [Liu, Tianshan] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong 999077, Peoples R China.
C3 Jiangnan University; Hong Kong Polytechnic University
RP Kong, J (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
EM kongjun@jiangnan.edu.cn
RI Liu, Kai/IST-6808-2023
FU National Natural Science Foundation of China [61362030, 61201429]; China
   Postdoctoral Science Foundation [2015M581720, 2016M600360]; Jiangsu
   Postdoctoral Science Foundation, China [1601216C]; Scientific and
   Technological Aid Program of Xinjiang, China [2017E0279]; 111 Projects,
   China [B12018]
FX This work was partially supported by the National Natural Science
   Foundation of China (61362030, 61201429), China Postdoctoral Science
   Foundation (2015M581720, 2016M600360), Jiangsu Postdoctoral Science
   Foundation, China (1601216C), Scientific and Technological Aid Program
   of Xinjiang, China (2017E0279), 111 Projects, China under Grant B12018.
CR Ballester Coloma, 2013, JOINT DAGM, P31
   BILEN H, 2017, PROC CVPR IEEE, V40, P2799
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Cherian A, 2017, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR.2017.172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan JL, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131343
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando Basura, 2017, INT J COMPUT VISION, P1
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Weiming, 2018, 32 AAAI C ART INT AA
   Hu Xiaolin, 2019, ABS190509646 CORR
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang, 2019, J VIS COMMUN IMAGE R
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kwolek, 2019, J VIS COMMUN IMAGE R
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YN, 2016, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2016.7899602
   LI Z, 2018, PROC CVPR IEEE, V166, P41
   Lin W, 2017, ARXIV171107430
   LIU T, 2018, 2018 IEEE INT POW EL, P1, DOI DOI 10.1109/PEAC.2018.8590494
   Miao QG, 2017, IEEE INT CONF COMP V, P3047, DOI 10.1109/ICCVW.2017.360
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   RUI Z, 2017, IEEE RSJ INT C INT R, P4260
   Salakhutdinov, 2015, ARXIV151104119
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K., 2014, 14091556 ARXIV
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun Jin-Sheng, J VIS COMMUN IMAGE R
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   SZEGEDY C, 2016, LECT NOTES COMPUT SC, P2818
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang HG, 2017, IEEE INT CONF COMP V, P3129, DOI 10.1109/ICCVW.2017.370
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2016, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2016.7899599
   Wang Pichao, 2018, ABS180101080 CORR
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   WANG Y, 2017, 2017 IEEE COMP VIS P, P1529
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Yandong Li, 2018, 32 AAAI C ART INT AA
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhao Y, 2018, PROC CVPR IEEE, P6566, DOI 10.1109/CVPR.2018.00687
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhu GM, 2016, INT C PATT RECOG, P19, DOI 10.1109/ICPR.2016.7899601
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
   Zhu Y, 2019, LECT NOTES COMPUT SC, V11363, P363, DOI 10.1007/978-3-030-20893-6_23
NR 67
TC 3
Z9 3
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102929
DI 10.1016/j.jvcir.2020.102929
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200009
DA 2024-07-18
ER

PT J
AU Lei, JF
   Dong, YX
   Zhao, T
   Xiao, JS
   Chen, YH
   Li, BJ
AF Lei, Junfeng
   Dong, Yuxuan
   Zhao, Tao
   Xiao, Jinsheng
   Chen, Yunhua
   Li, Bijun
TI Novel shrinking residual convolutional neural network for efficient
   accurate stereo matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Matching cost; Residual convolutional neural network
AB For stereo matching based on patch comparing using convolutional neural networks (CNNs), the matching cost estimation is highly dependent on the network structure, and the patch comparing is time consuming for traditional CNNs. Accordingly, we propose a stereo matching method based on a novel shrinking residual CNN, which consists of convolutional layers and skip-connection layers, and the size of the fully connected layers decreases progressively. Firstly, a layer-by-layer shrinking size model is adopted for the full-connection layers to greatly increase the running speed. Secondly, the convolutional layer and the residual structure are fused to improve patch comparing. Finally, the Loss function is re-designed to give higher weights to hard-classified examples compared with the standard cross entropy loss. Experimental results on KITTI2012 and KITTI2015 demonstrate that the proposed method can improve the operation speed while maintaining high accuracy.
C1 [Lei, Junfeng; Dong, Yuxuan; Zhao, Tao; Xiao, Jinsheng] Wuhan Univ, Sch Elect Informat, Wuhan, Peoples R China.
   [Chen, Yunhua] Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
   [Li, Bijun] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.
C3 Wuhan University; Guangdong University of Technology; Wuhan University
RP Xiao, JS (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan, Peoples R China.; Chen, YH (corresponding author), Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
EM xiaojs@whu.edu.cn; yhchen@gdut.edu.cn
RI Xiao, Jinsheng/AAG-2392-2019
OI Xiao, Jinsheng/0000-0002-5403-1895
FU National Natural Science Foundation of China [41671441, 61471272];
   Guangdong Provincial Natural Science Foundation of China
   [2016A030313713]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 41671441, 61471272), and Guangdong Provincial Natural
   Science Foundation of China (Grant No. 2016A030313713). The numerical
   calculations in this paper have been done on the supercomputing system
   in the Supercomputing Center of Wuhan University.
CR Chai Y, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P442, DOI 10.1109/IAEAC.2018.8577495
   Chen MY, 2019, OPT LASER ENG, V122, P170, DOI 10.1016/j.optlaseng.2019.06.011
   Cheng J, 2018, IEEE T NEUR NET LEAR, V29, P4730, DOI 10.1109/TNNLS.2017.2774288
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   Güney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Lin GC, 2019, BIOSYST ENG, V186, P34, DOI 10.1016/j.biosystemseng.2019.06.019
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu DW, 2016, MACH VISION APPL, V27, P1325, DOI 10.1007/s00138-016-0775-5
   Lu WT, 2017, ASIAPAC SIGN INFO PR, P1160, DOI 10.1109/APSIPA.2017.8282203
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Ningning Yi, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P637, DOI 10.1109/ICIS.2018.8466474
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730
   Shimada T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1842, DOI 10.1109/ICASSP.2018.8461537
   Tang YC, 2019, ROBOT CIM-INT MANUF, V59, P36, DOI 10.1016/j.rcim.2019.03.001
   Xiao JS, 2020, NEUROCOMPUTING, V389, P108, DOI 10.1016/j.neucom.2020.01.007
   Xiao JS, 2018, COMPUT VIS IMAGE UND, V169, P1, DOI 10.1016/j.cviu.2017.11.012
   Xu YF, 2014, APPL OPTICS, V53, P6885, DOI 10.1364/AO.53.006885
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang YQ, 2018, INFORM SCIENCES, V462, P402, DOI 10.1016/j.ins.2018.06.028
NR 28
TC 1
Z9 1
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102872
DI 10.1016/j.jvcir.2020.102872
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400004
DA 2024-07-18
ER

PT J
AU Zhao, HW
   Li, MZ
   Zhao, HY
AF Zhao, Hongwei
   Li, Mingzhao
   Zhao, Haoyu
TI Artificial intelligence based ensemble approach for intrusion detection
   systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Artificial Intelligence; Ensembles; Pattern recognition; Internet
   attacks; Neural networks
ID EVOLUTIONARY ALGORITHMS; CLASSIFIER; DESIGN
AB Internet attacks pose a severe threat to most of the online resources and are a prime concern of security administrators these days. In spite of many efforts, the security techniques are unable to detect the intrusions accurately. Most of the methods suffer from the limitations of a high false positive rate, low detection rate and provide one solution which lacks the classification trade-offs. In this work, an effective two-stage method is proposed to produce a pool of non-dominating solutions or Pareto optimal solutions as base models and their ensembles for detecting the intrusions accurately. It generates Pareto optimal solutions to a chromosome structure in stage 1 formulating Pareto front. Whereas, another approximation to the Pareto front of optimal solutions is made to obtain non-dominating ensembles in the second stage. The final prediction ensemble solutions are computed from individual predictions using majority voting approach. Applicability of the suggested method is validated using benchmark dataset NSL-KDD dataset. The experimental results show that the recommended method provides better results than conventional ensemble techniques. The recommended method is also adequate to generate Pareto optimal solutions that address the issue of improving detection accuracy for minority as well as majority attack classes along with handling classification tradeoff problem. The proposed method resulted detection accuracy of 97% with FPR of 2% for KDD dataset respectively. The most attractive feature of the proposed method is that both generation of base classifier and their ensemble thereof are multi-objective in nature addressing the issue of low detection accuracy and classification tradeoffs. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Zhao, Hongwei; Li, Mingzhao] Jilin Univ, Dept Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhao, Hongwei; Li, Mingzhao] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Zhao, Haoyu] Jilin Univ, Editorial Dept Journal Engn & Technol Edit, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Zhao, HY (corresponding author), Jilin Univ, Editorial Dept Journal Engn & Technol Edit, Changchun 130012, Jilin, Peoples R China.
EM zhaohaoyu@jlu.edu.cn
FU Provincial Science and Technology Innovation Special Fund Project of
   Jilin Province [20190302026GX]; Jilin Province Development and Reform
   Commission Industrial Technology Research and Development Project
   [2019C054-4]; Higher Education Research Project of Jilin Association for
   Higher Education [JGJX2018D10]; Fundamental Research Funds for the
   Central Universities for JLU
FX This research was funded by the Provincial Science and Technology
   Innovation Special Fund Project of Jilin Province, grant number
   20190302026GX, the Jilin Province Development and Reform Commission
   Industrial Technology Research and Development Project, grant number
   2019C054-4, the Higher Education Research Project of Jilin Association
   for Higher Education, grant number JGJX2018D10 and the Fundamental
   Research Funds for the Central Universities for JLU.
CR Agrawal, 2000, LECT NOTES COMPUTER, P849, DOI [10.1007/3-540-45356-383, DOI 10.1007/3-540-45356-3_83, DOI 10.1007/3-540-45356-3]
   Ahmadian K, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P217, DOI 10.1109/ICIS.2007.98
   [Anonymous], THESIS
   Axelsson S., 2000, Intrusion detection systems: A survey and taxonomy
   Banerjee S, 2005, ADV SOFT COMP, P103
   Breiman L., 1996, Bias, variance, and arcing classifiers
   Brown C., 2009, P IEEE S COMPUTATION, P1
   Chawla JS, 2003, AAPS PHARMSCI, V5
   Chebrolu S, 2005, COMPUT SECUR, V24, P295, DOI 10.1016/j.cose.2004.09.008
   Chen YH, 2007, INT J INTELL SYST, V22, P337, DOI 10.1002/int.20203
   Coello CAC, 2000, ACM COMPUT SURV, V32, P109, DOI 10.1145/358923.358929
   Coello Coello C., 1999, KNOWL INF SYST, V1, P269, DOI DOI 10.1007/BF03325101
   Corne DW., 2002, P GEN EV COMP C GECC, P283, DOI [DOI 10.5555/2955239.2955289, 10.5555/2955239.2955289]
   Dargi F, 2007, P ANN INT IEEE EMBS, P319, DOI 10.1109/IEMBS.2007.4352288
   Deb K, 2002, EVOL COMPUT, V10, P371, DOI 10.1162/106365602760972767
   Deb K., 2001, WIL INT S SYS OPT
   Deb Kalyanmoy., 1999, EVOLUTIONARY ALGORIT, P135
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   DosSantos E.M., 2008, THESIS
   Elhag S, 2019, STUD COMPUT INTELL, V779, P169, DOI 10.1007/978-3-319-91341-4_9
   Erdem H., 2018, FEATURE SELECTION MU
   Fung KY, 2012, EXPERT SYST APPL, V39, P7411, DOI 10.1016/j.eswa.2012.01.065
   Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9
   Govindarajan M, 2011, COMPUT NETW, V55, P1662, DOI 10.1016/j.comnet.2010.12.008
   Gu G., 2006, ACM S INFORM COMPUTE, P90, DOI [10.1145/1128817.1128834, DOI 10.1145/1128817.1128834]
   Hu R, 2008, PATTERN RECOGN, V41, P2665, DOI 10.1016/j.patcog.2008.01.022
   Ishibuchi H., 2006, International Journal of Hybrid Intelligent Systems, V3, P129, DOI DOI 10.3233/HIS-2006-3302
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jo Taeho, 2004, ACM Sigkdd Explorations Newsletter, V6, P40, DOI DOI 10.1145/1007730.1007737
   kdd, 1999, KDD cup 1999 data
   Khreich W, 2012, PATTERN RECOGN, V45, P208, DOI 10.1016/j.patcog.2011.06.014
   Khreich W, 2010, PATTERN RECOGN, V43, P2732, DOI 10.1016/j.patcog.2010.03.006
   Kumar G., 2011, P INT C ADV COMP ART, P170
   Kumar G., 2012, INT J INTELL SCI, V2, P115, DOI [10.4236/ijis.2012.224016, DOI 10.4236/IJIS.2012.224016, DOI 10.4236/ijis.2012.224016]
   Kumar G., 2010, INT J INF TELECOMMUN, V1, P44
   Kumar G, 2012, APPL COMPUT INTELL S, V2012, DOI 10.1155/2012/850160
   Kuncheva L. I., 2007, IEEE T NEURAL NETWOR, V18, P964, DOI DOI 10.1109/TNN.2007.897478
   Lee WK, 2000, ARTIF INTELL REV, V14, P533, DOI 10.1023/A:1006624031083
   Li CC, 2022, IEEE T AFFECT COMPUT, V13, P729, DOI 10.1109/TAFFC.2019.2954394
   Lv P, 2019, IEEE T COMPUT SOC SY, V6, P377, DOI 10.1109/TCSS.2018.2878461
   McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, P262, DOI 10.1145/382912.382923
   Muda Z., 2011, Information Technology Journal, V10, P648, DOI 10.3923/itj.2011.648.655
   Parrott D, 2005, IEEE C EVOL COMPUTAT, P1141
   Patcha A, 2007, COMPUT NETW, V51, P3448, DOI 10.1016/j.comnet.2007.02.001
   Perdisci R, 2006, ENG APPL ARTIF INTEL, V19, P429, DOI 10.1016/j.engappai.2006.01.003
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Re M, 2010, NEUROCOMPUTING, V73, P1533, DOI 10.1016/j.neucom.2009.12.012
   Sabhnani M., 2003, P INT C MACH LEARN M, V1, P2009
   Sai Satyanarayana Reddy S., 2019, Computing and Network Sustainability. Proceedings of IRSCNS 2018. Lecture Notes in Networks and Systems (LNNS 75), P425, DOI 10.1007/978-981-13-7150-9_45
   Shiravi A, 2012, COMPUT SECUR, V31, P357, DOI 10.1016/j.cose.2011.12.012
   Tavallaee M., 2011, THESIS
   Tiwari S., 2008, PROC ACM GENETIC EVO, P729, DOI DOI 10.1145/1389095.1389235
   Tiwari S, 2011, ENG OPTIMIZ, V43, P377, DOI 10.1080/0305215X.2010.491549
   Toosi AN, 2007, COMPUT COMMUN, V30, P2201, DOI 10.1016/j.comcom.2007.05.002
   Tsoumakas G, 2005, INTELL DATA ANAL, V9, P511, DOI 10.3233/IDA-2005-9602
   Wang G, 2010, EXPERT SYST APPL, V37, P6225, DOI 10.1016/j.eswa.2010.02.102
   Witten IH, 2011, MOR KAUF D, P1
   Xiang C, 2008, PATTERN RECOGN LETT, V29, P918, DOI 10.1016/j.patrec.2008.01.008
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Zainal A, 2009, J INF ASSUR SECUR, V4, P217
   Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202
NR 65
TC 2
Z9 2
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102736
DI 10.1016/j.jvcir.2019.102736
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900005
DA 2024-07-18
ER

PT J
AU Zheng, Z
   Liu, Y
   Liu, Y
   Huang, BQ
   Yu, HW
AF Zheng, Zhi
   Liu, Yun
   Liu, Yun
   Huang, Baoqing
   Yu, Hongwei
TI No-reference stereoscopic images quality assessment method based on
   monocular superpixel visual features and binocular visual features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality evaluation; Superpixel visual patches; Human visual
   system; Support vector regression
ID SELF-SIMILARITY; INFORMATION; PREDICTION; EFFICIENT
AB No-reference quality assessment of images has received considerable attention. However, the accuracy of such assessment remains questionable because of its weak biological basis. In this paper, we propose a novel quality assessment model based on the superpixel index and biological binocular mechanisms. The technical contributions of our model are the introduction of local monocular superpixel features and three global binocular visual features. We utilize monocular superpixel segmentation to extract two types of entropies as the local visual features for accurate quality-aware feature extraction. In addition, natural scene statistics features are extracted from the binocular visual information to complement the local monocular features and quantify the naturalness of the stereoscopic images. Finally, a regression model is learned to evaluate the quality of the stereoscopic images. Experimental results from three popular databases demonstrate that the proposed model has a more reliable performance than earlier models in terms of prediction accuracy and generalizability. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Zheng, Zhi; Liu, Yun] Beijing Jiaotong Univ, Dept Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Liu, Yun; Huang, Baoqing; Yu, Hongwei] Liaoning Univ, Coll Informat, Shenyang 110036, Liaoning, Peoples R China.
C3 Beijing Jiaotong University; Liaoning University
RP Zheng, Z; Liu, Y (corresponding author), Beijing Jiaotong Univ, Dept Elect & Informat Engn, Beijing 100044, Peoples R China.; Liu, Y (corresponding author), Liaoning Univ, Coll Informat, Shenyang 110036, Liaoning, Peoples R China.
EM 12111006@bjtu.edu.cn; liuyun@bjtu.edu.cn; yunliu@tju.edu.cn
RI Yu, Hong-Wei/AAR-3342-2020
FU Fundamental Research Funds for the Central Universities [W17JB00060];
   Academic Discipline and Postgraduate Education Project of Beijing
   Municipal Commission of Education; National Natural Science Foundation
   of China [61901205]
FX This work supported by the Fundamental Research Funds for the Central
   Universities, No. W17JB00060 and Academic Discipline and Postgraduate
   Education Project of Beijing Municipal Commission of Education, and the
   National Natural Science Foundation of China under Grant 61901205.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bensalma R, 2013, MULTIDIM SYST SIGN P, V24, P281, DOI 10.1007/s11045-012-0178-3
   Chen L, 2019, SIGNAL PROCESS-IMAGE, V76, P1, DOI 10.1016/j.image.2019.03.011
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   COGAN AI, 1987, VISION RES, V27, P2125, DOI 10.1016/0042-6989(87)90127-1
   CURTIS DW, 1978, J EXP PSYCHOL HUMAN, V4, P132, DOI 10.1037/0096-1523.4.1.132
   Ding J, 2006, P NATL ACAD SCI USA, V103, P1141, DOI 10.1073/pnas.0509629103
   ENGEL GR, 1967, VISION RES, V7, P753, DOI 10.1016/0042-6989(67)90038-7
   Fang YM, 2018, SIGNAL PROCESS-IMAGE, V69, P1, DOI 10.1016/j.image.2018.07.009
   Gangapure V.N., 2017, IEEE T CIRCUITS SYST, P1
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Hu WJ, 2019, J VIS COMMUN IMAGE R, V59, P407, DOI 10.1016/j.jvcir.2019.01.039
   Jiang GY, 2017, J VIS COMMUN IMAGE R, V46, P269, DOI 10.1016/j.jvcir.2017.04.010
   Jiang QP, 2018, PATTERN RECOGN, V76, P242, DOI 10.1016/j.patcog.2017.11.001
   Jin XD, 2017, IEEE T GEOSCI REMOTE, V55, P4285, DOI 10.1109/TGRS.2017.2690445
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Karimi M, 2019, DIGIT SIGNAL PROCESS, V91, P91, DOI 10.1016/j.dsp.2019.03.004
   Kataoka S., 2013, ITC SCSS 2013, P639
   Kim J., 2017, P IEEE C COMP VIS PA
   Kingdom FAA, 2012, CURR BIOL, V22, pR22, DOI 10.1016/j.cub.2011.11.048
   Levelt W.J., 1965, THESIS GORCUM ASSEN, V67, P1157
   Li YF, 2019, IEEE ACCESS, V7, P46706, DOI 10.1109/ACCESS.2019.2909073
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu LX, 2018, NEUROCOMPUTING, V275, P1823, DOI 10.1016/j.neucom.2017.10.017
   Liu TJ, 2019, IEEE ACCESS, V7, P8058, DOI 10.1109/ACCESS.2018.2890304
   Liu Y, 2019, IEEE ACCESS, V7, P69283, DOI 10.1109/ACCESS.2019.2919155
   Liu Z, 2013, 2013 14TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES (WIAMIS)
   Lu T, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120947
   Lv YQ, 2016, SIGNAL PROCESS-IMAGE, V47, P346, DOI 10.1016/j.image.2016.07.003
   Ma J, 2018, SIGNAL PROCESS-IMAGE, V65, P33, DOI 10.1016/j.image.2018.03.009
   May KA, 2016, CURR BIOL, V26, P1571, DOI 10.1016/j.cub.2016.04.037
   May KA, 2012, CURR BIOL, V22, P28, DOI 10.1016/j.cub.2011.11.025
   Min XK, 2019, IEEE T INTELL TRANSP, V20, P2879, DOI 10.1109/TITS.2018.2868771
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Nafchi HZ, 2016, IEEE ACCESS, V4, P5579, DOI 10.1109/ACCESS.2016.2604042
   Pan D, 2018, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2018.00667
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Shao F, 2018, IEEE T CIRC SYST VID, V28, P573, DOI 10.1109/TCSVT.2016.2628082
   Shao F, 2016, IEEE T MULTIMEDIA, V18, P2104, DOI 10.1109/TMM.2016.2594142
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Silva H., 1953, BRIT J PSYCHOL, V20, P241
   Sporring J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P900, DOI 10.1109/ICPR.1996.546154
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Q, 2016, NEUROCOMPUTING, V173, P1798, DOI 10.1016/j.neucom.2015.09.057
   Wang X, 2018, SIGNAL PROCESS, V145, P202, DOI 10.1016/j.sigpro.2017.12.002
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Yao Y, 2018, SIGNAL PROCESS-IMAGE, V65, P128, DOI 10.1016/j.image.2018.02.014
   Yue GH, 2018, SIGNAL PROCESS, V150, P204, DOI 10.1016/j.sigpro.2018.04.019
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhang YZ, 2016, DIGIT SIGNAL PROCESS, V57, P56, DOI 10.1016/j.dsp.2016.05.012
   Zhou W, 2019, IEEE T IMAGE PROCESS, V28, P3946, DOI 10.1109/TIP.2019.2902831
   Zhou WJ, 2017, INFORM SCIENCES, V397, P1, DOI 10.1016/j.ins.2017.02.049
   Zhou WJ, 2017, PATTERN RECOGN, V71, P207, DOI 10.1016/j.patcog.2017.06.008
   Zhou WJ, 2017, NEUROCOMPUTING, V224, P128, DOI 10.1016/j.neucom.2016.10.046
NR 71
TC 1
Z9 1
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102848
DI 10.1016/j.jvcir.2020.102848
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400010
DA 2024-07-18
ER

PT J
AU Yan, MJ
   Meng, JJ
   Zhou, CL
   Tu, ZG
   Tan, YP
   Yuan, JS
AF Yan, Mengjia
   Meng, Jingjing
   Zhou, Chunluan
   Tu, Zhigang
   Tan, Yap-Peng
   Yuan, Junsong
TI Detecting spatiotemporal irregularities in videos via a 3D convolutional
   autoencoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatiotemporal irregularity detection; Autoencoder; 3D convolution;
   Anomaly detection; Unsupervised learning; Real-time
ID ANOMALY DETECTION; EVENT DETECTION; LOCALIZATION
AB Spatiotemporal irregularities (i.e., the uncommon appearance and motion patterns) in videos are difficult to detect, as they are usually not well defined and appear rarely in videos. We tackle this problem by learning normal patterns from regular videos, while treating irregularities as deviations from normal patterns. To this end, we introduce a 3D fully convolutional autoencoder (3D-FCAE) that is trainable in an end-to-end manner to detect both temporal and spatiotemporal irregularities in videos using limited training data. Subsequently, temporal irregularities can be detected as frames with high reconstruction errors, and irregular spatiotemporal patterns can be detected as blurry regions that are not well reconstructed. Our approach can accurately locate temporal and spatiotemporal irregularities thanks to the 3D fully convolutional autoencoder and the explored effective architecture. We evaluate the proposed autoencoder for detecting irregular patterns on benchmark video datasets with weak supervision. Comparisons with state-of-the-art approaches demonstrate the effectiveness of our approach. Moreover, the learned autoencoder shows good generalizability across multiple datasets. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Yan, Mengjia; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Meng, Jingjing; Zhou, Chunluan; Yuan, Junsong] SUNY Buffalo, Comp Sci & Engn Dept, Buffalo, NY USA.
   [Tu, Zhigang] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Ruoyu Rd 129, Wuhan, Peoples R China.
C3 Nanyang Technological University; State University of New York (SUNY)
   System; State University of New York (SUNY) Buffalo; Wuhan University
RP Yan, MJ (corresponding author), 3rd Floor,1 Zhongguancun St, Beijing, Peoples R China.
EM YANM0006@e.ntu.edu.sg; jmeng2@buffalo.edu; chunluan@buffalo.edu;
   tuzhigang@whu.edu.cn; eyptan@ntu.edu.sg; jsyuan@buffalo.edu
RI Tu, Zhigang/AAG-2255-2020; Yuan, Junsong/A-5171-2011; Tan,
   Yap-Peng/A-5158-2011; Meng, Jingjing/J-8756-2014
OI Tu, Zhigang/0000-0001-5003-2260; Yuan, Junsong/0000-0002-7901-8793
FU University at Buffalo
FX This work is supported in part by start-up funds from University at
   Buffalo.
CR [Anonymous], 2017, ARXIV171209867
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], ICPR
   Calderara S, 2011, COMPUT VIS IMAGE UND, V115, P1099, DOI 10.1016/j.cviu.2011.03.003
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Jiang F, 2009, IEEE T IMAGE PROCESS, V18, P907, DOI 10.1109/TIP.2008.2012070
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kozlov Y., 2015, Persistence1D: Extracting and filtering minima and maxima of 1d functions, P11
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Radford A., 2015, ARXIV151106434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
NR 33
TC 4
Z9 5
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102747
DI 10.1016/j.jvcir.2019.102747
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800011
DA 2024-07-18
ER

PT J
AU Alameer, A
   Degenaar, P
   Nazarpour, K
AF Alameer, Ali
   Degenaar, Patrick
   Nazarpour, Kianoush
TI Objects and scenes classification with selective use of central and
   peripheral image content
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual recognition; Image understanding; Visual-data reduction;
   Biological visual-systems; Visual perception; Scene analysis
ID CONVOLUTIONAL NEURAL-NETWORKS; RECOGNITION; MODEL; REPRESENTATION; AREA;
   FIXATION; VISION; GIST
AB The human visual recognition system is more efficient than any current robotic vision setting. One reason for this superiority is that humans utilize different fields of vision, depending on the recognition task. For instance, experiments on human subjects show that the peripheral vision is more useful than the central vision in recognizing scenes. We tested our recently-developed model, that is, the elastic net-regularized hierarchical MAX (En-HMAX), in recognizing objects and scenes. In various experimental conditions, images were occluded with windows and scotomas of varying sizes. With this model, classification accuracies of up to 90% for objects and scenes were possible. Modelling human experiments, window and scotoma analysis with the En-HMAX model revealed that object and scene recognition are sensitive to the availability of data in the centre and the periphery of the images, respectively. Similarly, results of deep learning models have shown that the classification accuracy diminishes dramatically in the absence of the peripheral vision. These differences led us to further analyse the performance of the En-HMAX model with the parafoveal versus peripheral areas of vision, in a second study. Results of the second study show that approximately 50% of the visual field would be sufficient to achieve 96% accuracy in the classification of unseen images. The En-HMAX model adopts a relative order of importance, similar to the human visual system, depending on the image category. We showed that utilizing the relevant regions of vision can significantly reduce the image processing time and size. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Alameer, Ali; Degenaar, Patrick; Nazarpour, Kianoush] Newcastle Univ, Sch Engn, Newcastle, NSW NE1 7RU, Australia.
   [Degenaar, Patrick; Nazarpour, Kianoush] Newcastle Univ, Inst Neurosci, Newcastle, NSW NE2 4HH, Australia.
C3 University of Newcastle; University of Newcastle
RP Alameer, A; Nazarpour, K (corresponding author), Newcastle Univ, Sch Engn, Newcastle, NSW NE1 7RU, Australia.
EM ali.alameer@newcastle.ac.uk; kianoush.nazar-pour@newcastle.ac.uk
RI Alameer, Ali/HRD-1997-2023; Nazarpour, Kianoush/F-5873-2010
OI Alameer, Ali/0000-0002-7969-3609; 
FU Newcastle University; Engineering and Physical Sciences Research
   Council, U.K. [EP/M025977/1, EP/M025594/1]; EPSRC [EP/M025594/1,
   EP/M025977/1, EP/R004242/1] Funding Source: UKRI
FX The work of A. Alameer is supported by Newcastle University. The work of
   K. Nazarpour is supported by the Engineering and Physical Sciences
   Research Council, U.K., grants EP/M025977/1 and EP/M025594/1.
CR Abolghasemi V, 2018, IEEE SIGNAL PROC LET, V25, P472, DOI 10.1109/LSP.2018.2798406
   Aditya S., 2017, Computer Vision and Image Understanding
   Alameer A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P163, DOI 10.1109/INISTA.2017.8001150
   Alameer A, 2016, 2016 INTERNATIONAL CONFERENCE FOR STUDENTS ON APPLIED ENGINEERING (ICSAE), P129, DOI 10.1109/ICSAE.2016.7810174
   Alameer A, 2016, IEEE SIGNAL PROC LET, V23, P1062, DOI 10.1109/LSP.2016.2582541
   [Anonymous], P 2 IET INT C INT SI
   [Anonymous], P NAT ACAD SCI
   [Anonymous], 2019, SCI INF C
   [Anonymous], 2015, P 2013 IEEE GLOB COM
   [Anonymous], 2001, From fragments to objects: Segmentation and grouping in vision
   [Anonymous], ENG TECHNOLOGY J
   [Anonymous], 2017, IEEE T
   [Anonymous], P 10 HELL C ART INT
   [Anonymous], J VIS
   [Anonymous], THESIS
   [Anonymous], 2018, COMPUT VIS IMAGE UND
   Arbib MA, 2016, COMPUT NEUROSCI-MIT, P1
   Bolduc M, 1997, REAL-TIME IMAGING, V3, P195, DOI 10.1006/rtim.1996.0056
   Cannici M, 2019, IEEE WINT CONF APPL, P1127, DOI 10.1109/WACV.2019.00125
   Carrasco M, 2003, NAT NEUROSCI, V6, P699, DOI 10.1038/nn1079
   Chang YF, 2019, J VIS COMMUN IMAGE R, V60, P371, DOI 10.1016/j.jvcir.2019.02.030
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Coggan DD, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02569-4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Epstein R, 1999, NEURON, V23, P115, DOI 10.1016/S0896-6273(00)80758-8
   Farzmahdi A, 2016, SCI REP-UK, V6, DOI 10.1038/srep25025
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   Geisler W. S., 1999, Society for Information Display 1999 International Symposium, P420
   Geisler W. S., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P83, DOI 10.1145/507072.507090
   Geisler WS, 2006, J VISION, V6, P858, DOI 10.1167/6.9.1
   Ghazaei G, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa6802
   Gomez J, 2015, NEURON, V85, P216, DOI 10.1016/j.neuron.2014.12.027
   Greene MR, 2009, PSYCHOL SCI, V20, P464, DOI 10.1111/j.1467-9280.2009.02316.x
   Grill-Spector K, 2004, ANNU REV NEUROSCI, V27, P649, DOI 10.1146/annurev.neuro.27.070203.144220
   Gulcehre Caglar, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P530, DOI 10.1007/978-3-662-44848-9_34
   Henderson JM, 1997, PERCEPT PSYCHOPHYS, V59, P323, DOI 10.3758/BF03211901
   Henderson JM, 1999, PSYCHOL SCI, V10, P438, DOI 10.1111/1467-9280.00183
   Holliday A, 2017, COMPUT VIS IMAGE UND, V164, P16, DOI 10.1016/j.cviu.2017.05.004
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Kaiser P., 2009, The joy of visual perception
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Kheradpisheh SR, 2016, SCI REP-UK, V6, DOI 10.1038/srep32672
   King DB, 2015, ACS SYM SER, V1214, P1
   Larson AM, 2009, J VISION, V9, DOI 10.1167/9.10.6
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee J, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P36, DOI 10.1109/IRC.2017.77
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li YL, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00123
   Loschky LC, 2007, J EXP PSYCHOL HUMAN, V33, P1431, DOI 10.1037/0096-1523.33.6.1431
   Lu XQ, 2019, NEUROCOMPUTING, V328, P135, DOI 10.1016/j.neucom.2018.03.076
   Lu XQ, 2017, IEEE T GEOSCI REMOTE, V55, P5148, DOI 10.1109/TGRS.2017.2702596
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Malach R, 2002, TRENDS COGN SCI, V6, P176, DOI 10.1016/S1364-6613(02)01870-3
   McCandliss BD, 2003, TRENDS COGN SCI, V7, P293, DOI 10.1016/S1364-6613(03)00134-7
   MCCONKIE GW, 1975, PERCEPT PSYCHOPHYS, V17, P578, DOI 10.3758/BF03203972
   O'Regan JK, 2000, VIS COGN, V7, P191, DOI 10.1080/135062800394766
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Poggio Tomaso, 2015, ARXIV151106292
   Reingold EM, 2003, HUM FACTORS, V45, P307, DOI 10.1518/hfes.45.2.307.27235
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Teichman A., 2011, 2011 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO), P35, DOI 10.1109/ARSO.2011.6301978
   Thibaut M, 2014, VISION RES, V98, P46, DOI 10.1016/j.visres.2014.03.004
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   Ullman S, 2016, P NATL ACAD SCI USA, V113, P2744, DOI 10.1073/pnas.1513198113
   van Diepen PMJ, 1998, PERCEPTION, V27, P1141, DOI 10.1068/p271141
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   Wang PQ, 2017, J VISION, V17, DOI 10.1167/17.4.9
   Yan KL, 2005, NEURAL COMPUT, V17, P397, DOI 10.1162/0899766053011474
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yin WB, 2019, J VIS COMMUN IMAGE R, V60, P59, DOI 10.1016/j.jvcir.2019.01.002
   YOUNG R A, 1987, Spatial Vision, V2, P273, DOI 10.1163/156856887X00222
   Zalluhoglu C, 2019, J VIS COMMUN IMAGE R, V60, P170, DOI 10.1016/j.jvcir.2019.02.016
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhang Y, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11010009
   Zhou BL, 2014, ADV NEUR IN, V27
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 85
TC 6
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102698
DI 10.1016/j.jvcir.2019.102698
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA KU4BZ
UT WOS:000519656200005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, JY
   Du, ZG
AF Wang, Jianyu
   Du, Zhiguo
TI A method of processing color image watermarking based on the Haar
   wavelet
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image watermarking; Discrete Wavelet Transform (DWT)
AB Despite the fact that traditional digital watermarking technology is relatively mature, there are still some areas that have not been fully involved in. For example, image watermarking technology and the certification are still in its infancy at early times. The bottleneck problem of digital product safety protection all solved theoretically with the combination of computing theory as well as traditional digital watermarking technology and point out a new direction for the research of information security industry. Inspired by the traditional algorithm of image watermarking and based on the Haar wavelet function along with algorithm of 2-D discrete wavelet transform and selection, this article presents the techniques of watermark embedding and extraction of color images. The main appraisal criteria of the watermark include invisibility and robustness, and some other standards. Image watermarking is relatively simple in the spatial domain, where it cannot resist geometrical attacks. In the transform domain, this approach can resist both geometrical attacks and image processing attacks. Only when the carrier image suffers from severe damage with the image quality hugely compromised will the extracted watermark become unrecognizable. As a result, the algorithm presented in this article can well embed the color image in the carrier image, and has good resistance to attack operations such as loss compression and adding of noise. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Jianyu; Du, Zhiguo] Southwest Univ Chongqing, Coll Business & Commerce, Rongchang Campus, Chongqing 402460, Peoples R China.
RP Du, ZG (corresponding author), Southwest Univ Chongqing, Coll Business & Commerce, Rongchang Campus, Chongqing 402460, Peoples R China.
EM duzhiguo@swu.edu.cn
FU Fundamental Research Funds for the Central Universities [XDJK2016C048]
FX The authors wish to thank Southwest University. This article supported
   by "Fundamental Research Funds for the Central Universities" (project
   number: XDJK2016C048).
CR Cao F., 2017, OPT SIN, V37
   Han S, 2012, PROC CVPR IEEE, P805, DOI 10.1109/CVPR.2012.6247752
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Meng Jun, 2002, J SE U NAT SCI ED, V6, P842
   Meng XF, 2006, APPL OPTICS, V45, P3289, DOI 10.1364/AO.45.003289
   Shi Yongfu, 2013, J CENTRAL CHINA NORM, V47, P479
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
NR 7
TC 29
Z9 29
U1 0
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102627
DI 10.1016/j.jvcir.2019.102627
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600012
DA 2024-07-18
ER

PT J
AU Zhai, MT
AF Zhai, Maotong
TI Inversion of organic matter content in wetland soil based on Landsat 8
   remote sensing image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Landsat 8; Soil organic matter; Quantitative inversion; Remote sensing
   image
ID OBJECT DETECTION
AB Using GF-1 and Landsat8 remote sensing images as data sources, combined with the experimental data of wetland soil sampling in Anyi County and Gao'an Research Area, the ability and difference of two remote sensing images in inversion of soil organic matter content were compared. The results show that the reflectivity of the two remote sensing images in the visible and near-infrared bands is significantly correlated with the soil organic matter content, and the correlation is the most in the near-infrared band. The index model established by the near-infrared band of GF-1 is more than the near-infrared band using Landsat8. The power model estimates slightly better. The multi-regression model established by introducing the blue band (dark blue band) and red band has higher inversion precision than the single-band model, especially the improvement effect of Landsat8 remote sensing image. Compared with Landsat8, GF-1 remote sensing image has higher spatial resolution and shorter revisit period, and has similar predictive ability in detecting soil organic matter content, which can replace Landsat8 remote sensing image. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhai, Maotong] Jiangxi Univ Finance & Econ, Sch Tourism & Urban Management, Nanchang 330013, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Zhai, MT (corresponding author), Jiangxi Univ Finance & Econ, Sch Tourism & Urban Management, Nanchang 330013, Jiangxi, Peoples R China.
EM zhaidi530@126.com
FU National Natural Science Foundation of China [41561049]; Jiangxi
   Outstanding Youth Science Fund [20171BCB23049]; Jiangxi Provincial
   Department of Education Science and Technology Project [GJJ150481];
   Jiangxi University of Finance and Economics 2018 Graduate Innovation
   Special Fund Project
FX This work was supported by the National Natural Science Foundation of
   China(No. 41561049); Jiangxi Outstanding Youth Science Fund (No.
   20171BCB23049); Jiangxi Provincial Department of Education Science and
   Technology Project (No. GJJ150481); Jiangxi University of Finance and
   Economics 2018 Graduate Innovation Special Fund Project.
CR Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Balcik FB, 2016, INT ARCH PHOTOGRAMM, V41, P251, DOI 10.5194/isprsarchives-XLI-B8-251-2016
   Chen HL, 2018, J PARKINSON DIS, V8, P1, DOI 10.3233/JPD-171238
   Chen RH, 2017, TRENDS ENVIRON ANAL, V15, P1, DOI 10.1016/j.teac.2017.07.001
   Fadong Peng, 2016, ASIAN AGR RES, V11
   Hamzelo M, 2015, INT ARCH PHOTOGRAMM, V41, P281, DOI 10.5194/isprsarchives-XL-1-W5-281-2015
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Jeevalakshmi D., 2016, INT C COMM SIGN PROC, P281
   Jiménez-Muñoz JC, 2014, IEEE GEOSCI REMOTE S, V11, P1840, DOI 10.1109/LGRS.2014.2312032
   Li X, 2015, INT J FUTUR GENER CO, V8, P61
   Liu HH, 2019, J MACROMOL SCI A, V56, P676, DOI 10.1080/10601325.2019.1596746
   [刘会芬 Liu Huifen], 2014, [国土资源遥感, Remote Sensing for Land & Resources], V26, P63
   Liu J., 2015, REMOTE SENS TECHNOL, P165
   Lu Z., 2015, REMOTE SENS MODEL EC, V12, P105
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Orolmaa E., 2015, INFRARED REMOTE SENS, VXXIII, P251
   Pervez W, 2017, INT ARCH PHOTOGRAMM, V42-5, P145, DOI 10.5194/isprs-archives-XLII-5-W1-145-2017
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Shams SB, 2014, INT ARCH PHOTOGRAMM, V40, P79, DOI 10.5194/isprsarchives-XL-2-W3-79-2014
   Shen K., 2016, INT C COMPUTER COMPU, P133
   Shen K., 2015, COMPUT COMPUT TECHNO, VIX, P79
   Vanhellemont Q, 2014, REMOTE SENS ENVIRON, V145, P105, DOI 10.1016/j.rse.2014.01.009
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Zhang C., 2017, REMOTE SENS LAND RES, V2017, P40
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhu J., 2016, REMOTE SENS LAND RES, P2337
NR 29
TC 17
Z9 18
U1 19
U2 99
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102645
DI 10.1016/j.jvcir.2019.102645
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600028
DA 2024-07-18
ER

PT J
AU Wang, W
   Zhu, LQ
   Guo, BQ
AF Wang, Wei
   Zhu, Liqiang
   Guo, Baoqing
TI Reliable identification of redundant kernels for convolutional neural
   network compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Network compression; Convolutional neural network; Pruning criterion;
   Channel-level pruning
AB To compress deep convolutional neural networks (CNNs) with large memory footprint and long inference time, this paper proposes a novel pruning criterion based on layer-wise L-n-norms of feature maps to identify unimportant convolutional kernels. We calculate the L-n-norm of the feature map outputted by each convolutional kernel to evaluate the importance of the kernel. Furthermore, we use different L-n-norms for different layers, e.g., L-1-norm for the first convolutional layer, L-2-norm for middle convolutional layers and L-infinity-norm for the last convolutional layer. With the ability of accurately identifying unimportant convolutional kernels in each layer, the proposed method achieves a good balance between model size and inference accuracy. Experimental results on CIFAR, SVHN and ImageNet datasets and an application example in a railway intelligent surveillance system show that the proposed method outperforms existing kernel-norm-based methods and is generally applicable to any deep neural network with convolutional operations. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Wei; Zhu, Liqiang; Guo, Baoqing] Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
   [Wang, Wei; Zhu, Liqiang; Guo, Baoqing] Beijing Jiaotong Univ, Minist Educ, Key Lab Vehicle Adv Mfg Measuring & Control Techn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Zhu, LQ (corresponding author), Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
EM lqzhu@bjtu.edu.cn
RI Huang, Liping/KIB-4430-2024; guo, baoqing/F-8799-2019; zhou,
   you/KBC-3567-2024; xu, xuan/KHX-8344-2024; Zhao, YuHan/KIE-0813-2024
OI Wang, Wei/0000-0001-8855-2819; Zhu, Liqiang/0000-0002-5436-6660
FU National Key Research and Development Program of China [2016YFB1200401]
FX This work was supported by the National Key Research and Development
   Program of China under Grant 2016YFB1200401.
CR [Anonymous], 2015, CoRR
   Chang J, 2019, J VIS COMMUN IMAGE R, V58, P316, DOI 10.1016/j.jvcir.2018.11.047
   Cheng Y., 2015, ARXIV150203436
   Courbariaux M., 2015, P ADV NEUR INF PROC, P3123
   Cun Y.L., 1989, Advances in neural information processing systems, V2, P598
   Denton E, 2014, ADV NEUR IN, V27
   Gong Y., 2014, INT C LEARN REPR ICL
   Han  S., 2015, ARXIV151000149
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hinton Geoffrey, 2014, NIPS DEEP LEARN WORK
   Howard A., 2018, CVPR
   Howard A. G., 2017, arXiv
   Hu Hengyuan, 2016, Network trimming: A data-driven neuron pruning approach towards efficient deep architectures
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Jaderberg M., 2014, CORR
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebedev V., 2014, INT C LEARNING REPRE
   Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H., 2010, INT C LEARN REPR ICL
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo J. -H., 2018, IEEE T PATTERN ANAL
   Lyu HL, 2015, CHIN CONT DECIS CONF, P2885
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Netzer Y., 2011, ADV NEURAL INF PROCE, P1
   Oymak S, 2017, INT CONF ACOUST SPEE, P6359, DOI 10.1109/ICASSP.2017.7953380
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ren YZ, 2018, J VIS COMMUN IMAGE R, V55, P131, DOI 10.1016/j.jvcir.2018.05.019
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sau B. B., 2016, ARXIV161009650
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan WR, 2017, NEUROCOMPUTING, V251, P1, DOI 10.1016/j.neucom.2017.04.023
   Wang B, 2019, J VIS COMMUN IMAGE R, V58, P102, DOI 10.1016/j.jvcir.2018.11.014
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
NR 43
TC 10
Z9 12
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102582
DI 10.1016/j.jvcir.2019.102582
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sreeja, MU
   Kovoor, BC
AF Sreeja, M. U.
   Kovoor, Binsu C.
TI Towards genre-specific frameworks for video summarisation: A survey
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video summarisation; Video summary; Genre-specific; Skim; Keyframe
ID SPORTS VIDEO; EXTRACTION; ALGORITHM; FRAMES
AB Video summarisation is characterised as the process of extracting meaningful frames or segments from a video that best represents the content of the whole video. The proposed framework surveys and categorizes the existing video summarisation models in the recent research works on the basis of genre. The most important phase of video summarisation is the detection of key frames or segments in the video. The strategy for identifying key frames or segments vary for each genre. The various genre analysed are user generated videos, movies and documentary, sports, surveillance, egocentric and informational talk videos with a total of more than 25 varying parameters significant to the respective genre. Comprehensive evaluations of the results obtained from the models are also included based on quantitative and qualitative parameters. The framework will help the user in deciding the technology to be adopted for video summarisation in a particular domain. The framework also aids in deciding the type of summary suitable for each genre and the available datasets in each genre for experimental analysis. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Sreeja, M. U.; Kovoor, Binsu C.] Cochin Univ Sci & Technol, Div Informat Technol, Kochi, Kerala, India.
C3 Cochin University Science & Technology
RP Kovoor, BC (corresponding author), Cochin Univ Sci & Technol, Div Informat Technol, Kochi, Kerala, India.
EM binsu.kovoor@gmail.com
RI U, Sreeja M/AAW-2444-2021; Kovoor, Binsu C/AAZ-4952-2021
CR Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   Al Nahian M, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P24, DOI 10.1109/ICTCS.2017.13
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 2002, D LIB MAG
   [Anonymous], IEEE T INTELL TRANSP
   [Anonymous], INT RES J ENG TECHNO
   [Anonymous], 2016, IEEE T IND INFORM
   [Anonymous], 2018, INT J RES APPL SCI E
   [Anonymous], INT J SCI ADV RES TE
   [Anonymous], AUTOMATIC SOCCER VID
   [Anonymous], 2014, ICMR 2014 P ACM INT, DOI DOI 10.1145/2578726.2578800
   [Anonymous], ARXIV12120402
   [Anonymous], ARXIV150401639
   [Anonymous], 1981, 7 INT JOINT C ARTIFI
   [Anonymous], 2008, PROGRAMME WORKSHOP M
   [Anonymous], ARXIV170704021
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 2014, INT J COMPUT VIS ROB, DOI DOI 10.1504/IJCVR.2014.062936
   [Anonymous], 2017 7 INT C IM PROC
   [Anonymous], INT S 3D DAT PROC VI
   [Anonymous], 2017, IEEE T HUM-MACH SYST, DOI DOI 10.1109/THMS.2016.2616296
   [Anonymous], 2015, COMPUT VIS MEDIA, DOI DOI 10.1007/S41095-015-0015-3
   Aparício M, 2016, PATTERN RECOGN LETT, V73, P7, DOI 10.1016/j.patrec.2015.12.016
   Bajaj J, 2011, 2011 IEEE 22ND INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P531, DOI 10.1109/PIMRC.2011.6140018
   Barhoumi W, 2013, AASRI PROC, V4, P78, DOI 10.1016/j.aasri.2013.10.013
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Boukadida H, 2017, IEEE T CIRC SYST VID, V27, P920, DOI 10.1109/TCSVT.2015.2513678
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Damnjanovic Uros, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P63, DOI 10.1109/WIAMIS.2008.53
   del Molino AG, 2017, IEEE T HUM-MACH SYST, V47, P65, DOI 10.1109/THMS.2016.2623480
   Delis S, 2017, IEEE T CIRC SYST VID, V27, P977, DOI 10.1109/TCSVT.2015.2511518
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Evangelopoulos G, 2008, IEEE IMAGE PROC, P2528, DOI 10.1109/ICIP.2008.4712308
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   Fei MJ, 2018, NEUROCOMPUTING, V275, P1911, DOI 10.1016/j.neucom.2017.10.030
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   Fisher R., 2011, CAVIAR Test Case Scenarios
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo Z, 2016, NEUROCOMPUTING, V208, P299, DOI 10.1016/j.neucom.2016.03.083
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hansung Kim, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P202, DOI 10.1109/3DV.2014.51
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Hesham M, 2018, PROCEEDINGS OF 2018 FIRST INTERNATIONAL WORKSHOP ON DEEP AND REPRESENTATION LEARNING (IWDRL), P26, DOI 10.1109/IWDRL.2018.8358211
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Ide I, 2017, IEEE INT SYM MULTIM, P193, DOI 10.1109/ISM.2017.33
   Jadhav PS, 2015, PROCEDIA COMPUT SCI, V45, P275, DOI 10.1016/j.procs.2015.03.140
   Jain S, 2017, LECT NOTES COMPUT SC, V10425, P428, DOI 10.1007/978-3-319-64698-5_36
   Jeong DJ, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0122-9
   Ji Z, 2018, SIGNAL PROCESS, V148, P114, DOI 10.1016/j.sigpro.2018.01.028
   Jodoin JP, 2014, IEEE WINT CONF APPL, P885, DOI 10.1109/WACV.2014.6836010
   Kalaivani P, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON RECENT TRENDS AND CHALLENGES IN COMPUTATIONAL MODELS (ICRTCCM), P61, DOI 10.1109/ICRTCCM.2017.84
   Kannan R, 2015, INFORM PROCESS MANAG, V51, P286, DOI 10.1016/j.ipm.2014.12.001
   Katayama N, 2004, LECT NOTES COMPUT SC, V3332, P489
   Kavitha J, 2015, PROCEDIA COMPUT SCI, V47, P292, DOI 10.1016/j.procs.2015.03.209
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Kopf S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2067, DOI 10.1109/ICME.2004.1394672
   Kuanar SK, 2015, IEEE T MULTIMEDIA, V17, P1166, DOI 10.1109/TMM.2015.2443558
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kuncheva LI, 2018, J VIS COMMUN IMAGE R, V52, P118, DOI 10.1016/j.jvcir.2018.02.010
   Lai PK, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P286, DOI 10.1109/AVSS.2016.7738018
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Li XW, 2012, PHYSCS PROC, V24, P2360, DOI 10.1016/j.phpro.2012.02.350
   Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887
   Loui Alexander., 2007, MIR 07, P245
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Mademlis I, 2017, IEEE IMAGE PROC, P625, DOI 10.1109/ICIP.2017.8296356
   Mademlis I, 2016, IEEE T IMAGE PROCESS, V25, P5828, DOI 10.1109/TIP.2016.2615289
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Meng JJ, 2018, IEEE T IMAGE PROCESS, V27, P2134, DOI 10.1109/TIP.2017.2789332
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Moses TM, 2017, 2017 INTERNATIONAL CONFERENCE ON ALGORITHMS, METHODOLOGY, MODELS AND APPLICATIONS IN EMERGING TECHNOLOGIES (ICAMMAET)
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Ouyang JQ, 2013, IET IMAGE PROCESS, V7, P324, DOI 10.1049/iet-ipr.2012.0495
   Panda R, 2017, IEEE I CONF COMP VIS, P3677, DOI 10.1109/ICCV.2017.395
   Panda R, 2017, IEEE T IMAGE PROCESS, V26, P4712, DOI 10.1109/TIP.2017.2708902
   Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Sheena CV, 2015, PROCEDIA COMPUT SCI, V70, P36, DOI 10.1016/j.procs.2015.10.021
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Song XH, 2016, NEUROCOMPUTING, V187, P66, DOI 10.1016/j.neucom.2015.07.131
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Srinivas M, 2016, PROCEDIA COMPUT SCI, V89, P812, DOI 10.1016/j.procs.2016.06.065
   Sun M, 2017, IEEE T PATTERN ANAL, V39, P2256, DOI 10.1109/TPAMI.2016.2623699
   Tejero-de-Pablos A, 2018, IEEE T MULTIMEDIA, V20, P2000, DOI 10.1109/TMM.2018.2794265
   Thomas S.A., 2017, 2017 IEEE Symposium Series on Computational Intelligence (SSCI), P1, DOI [10.1109/TENCONSpring.2017.8070003, DOI 10.1109/SSCI.2017.8285223]
   Thomas SS, 2017, IEEE T CIRC SYST VID, V27, P1790, DOI 10.1109/TCSVT.2016.2556558
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Varini P, 2017, IEEE T MULTIMEDIA, V19, P2832, DOI 10.1109/TMM.2017.2705915
   Vivekraj VK, 2017, TENCON IEEE REGION, P775, DOI 10.1109/TENCON.2017.8227964
   Vivekraj VK, 2016, INT C PATT RECOG, P871, DOI 10.1109/ICPR.2016.7899745
   Wang J.R., 2004, Proceedings of the Pan-Sydney area workshop on Visual information processing, VIP '05, P87
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Xu JF, 2007, IEICE T INF SYST, VE90D, P1430, DOI 10.1093/ietisy/e90-d.9.1430
   Yang JC, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2601069
   Yin YF, 2018, IEEE T CIRC SYST VID, V28, P181, DOI 10.1109/TCSVT.2016.2602832
   Yodel Web., 2011, The consumer digital video library
   Zawbaa HM, 2011, COMM COM INF SC, V263, P19
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang YZ, 2017, IEEE T CIRC SYST VID, V27, P1340, DOI 10.1109/TCSVT.2016.2539638
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu XT, 2016, INT J COMPUT VISION, V117, P247, DOI 10.1007/s11263-015-0864-3
   Zhu XT, 2013, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2013.17
NR 114
TC 17
Z9 17
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 340
EP 358
DI 10.1016/j.jvcir.2019.06.004
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600032
DA 2024-07-18
ER

PT J
AU Zhong, BJ
   Ma, KK
   Lu, ZF
AF Zhong, Baojiang
   Ma, Kai-Kuang
   Lu, Zhifang
TI Predictor-corrector image interpolation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image interpolation; Predictor-corrector; Edge-guided; Contrast-guided;
   Directional filtering
AB A novel image interpolation methodology is proposed in this paper, called the predictor-corrector interpolation (PCI). Given a low-resolution (LR) image, our PCI scheme begins with the prediction stage, aiming to interpolate the LR-sized input image to a high-resolution (HR) image which is of the same size as the final interpolated image. In the subsequent correction stage, those salient pixels (e.g., edge pixels) of the predicted image are identified and then necessary corrections are made to them for further improving the image quality. To demonstrate the effectiveness of this PCI methodology, the sparse mixing estimator (SME) interpolation is selected as the predictor, and a modified version of the contrast-guided interpolation (CGI) is developed and exploited as the corrector. Hence, the proposed PCI algorithm is denoted as PCI(sme,HR-CGI), which shows a superior performance over a number of comparable state-of-the-art image interpolation algorithms in both objective and subjective image quality assessment. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhong, Baojiang; Lu, Zhifang] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
   [Zhong, Baojiang] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215006, Peoples R China.
   [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Soochow University - China; Soochow University - China; Nanyang
   Technological University
RP Zhong, BJ (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
EM bjzhong@suda.edu.cn
RI Ma, Kai-Kuang/KBA-9411-2024
OI Zhong, Baojiang/0000-0002-9899-524X
FU National Science Foundation of China [61572341]
FX This research is funded by the National Science Foundation of China
   under Grant 61572341.
CR Al-Jarro A, 2012, IEEE T ANTENN PROPAG, V60, P5203, DOI 10.1109/TAP.2012.2207691
   Butcher J. C., 2016, NUMERICAL METHODS OR, DOI DOI 10.1002/9781119121534
   Chaudhuri NR, 2012, IEEE T CONTR SYST T, V20, P223, DOI 10.1109/TCST.2010.2096817
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kirshner H, 2014, IEEE T IMAGE PROCESS, V23, P413, DOI 10.1109/TIP.2013.2285597
   Li MD, 2015, IEEE T CIRC SYST VID, V25, P200, DOI 10.1109/TCSVT.2014.2347531
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Simonetto A, 2017, IEEE T SIGNAL PROCES, V65, P5481, DOI 10.1109/TSP.2017.2728498
   Simonetto A, 2016, IEEE T SIGNAL PROCES, V64, P4576, DOI 10.1109/TSP.2016.2568161
   Wang Q, 2007, IEEE T IMAGE PROCESS, V16, P889, DOI 10.1109/TIP.2007.891794
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Yang WH, 2018, IEEE T CIRC SYST VID, V28, P1071, DOI 10.1109/TCSVT.2016.2638864
   Ye W, 2016, IEEE SIGNAL PROC LET, V23, P1260, DOI 10.1109/LSP.2016.2571738
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhu SY, 2017, IEEE SIGNAL PROC LET, V24, P1178, DOI 10.1109/LSP.2017.2711609
   Zwart CM, 2013, IEEE T IMAGE PROCESS, V22, P2960, DOI 10.1109/TIP.2012.2228493
NR 28
TC 6
Z9 7
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 50
EP 60
DI 10.1016/j.jvcir.2019.03.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100006
DA 2024-07-18
ER

PT J
AU Nguyen, KD
   Nguyen, K
   Le, DD
   Duong, DA
   Nguyen, TV
AF Khanh-Duy Nguyen
   Khang Nguyen
   Duy-Dinh Le
   Duc Anh Duong
   Tam V. Nguyen
TI You always look again: Learning to detect the unseen objects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Dual-level deep networks; Object detection
AB Object detection has always attracted a lot of attention in computer vision due to its practical applications, i.e., robotics engineering, autonomous vehicles, and surveillance systems. Recently deep learning approaches have successfully improved the performance of object detection by a significant amount. However, there exist many challenging objects in the images that state-of-the-art approaches still fail to detect. In this paper, we propose an efficient approach that intentionally learns to detect the unseen (missing) objects. In particular, we utilize a dual-level of deep networks to efficiently detect difficult objects in images. The extensive experiments on three benchmarking datasets, PASCAL VOC, KITTI, and MS-COCO, show the superiority of our approach over the state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Khanh-Duy Nguyen; Khang Nguyen; Duy-Dinh Le; Duc Anh Duong] Univ Informat Technol, VNU HCM, Ho Chi Minh City, Vietnam.
   [Tam V. Nguyen] Univ Dayton, Dayton, OH 45469 USA.
C3 Vietnam National University Hochiminh City; University System of Ohio;
   University of Dayton
RP Nguyen, KD (corresponding author), Univ Informat Technol, VNU HCM, Ho Chi Minh City, Vietnam.
EM khanhnd@uit.edu.vn
RI Nguyen, Tam/HSG-3007-2023; Nguyen, Tam/AAU-6504-2020
OI Nguyen, Tam/0000-0003-0236-7992
FU Viet Nam National University Ho Chi Minh City (VNU-HCM) [B2017-26-01]
FX This research is funded by Viet Nam National University Ho Chi Minh City
   (VNU-HCM) under Grant No. B2017-26-01.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.376
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], 2014, CoRR
   [Anonymous], CORR
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2015, CORR
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen Q, 2015, IEEE T PATTERN ANAL, V37, P13, DOI 10.1109/TPAMI.2014.2343217
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb P.F., 2008, IEEE C COMPUT VIS PA, P1
   Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ouyang WL, 2017, IEEE I CONF COMP VIS, P1956, DOI 10.1109/ICCV.2017.214
   Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XY, 2015, IEEE T PATTERN ANAL, V37, P2071, DOI 10.1109/TPAMI.2015.2389830
   Wu TF, 2016, IEEE T PATTERN ANAL, V38, P1829, DOI 10.1109/TPAMI.2015.2497699
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
   Zhu Y, 2015, PROC CVPR IEEE, P4703, DOI 10.1109/CVPR.2015.7299102
NR 38
TC 6
Z9 6
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 206
EP 216
DI 10.1016/j.jvcir.2019.02.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000023
DA 2024-07-18
ER

PT J
AU Liu, YG
   Song, N
   Han, YH
AF Liu, Yongge
   Song, Nan
   Han, Yahong
TI Multi-cue fusion: Discriminative enhancing for person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Fusion strategy; Re-identification
AB Person re-identification is an emerging research field in computer vision. Our paper aims to study how to improve the discrimination of person features. We find that some peculiarities of people have not been better attention in the semantic features of deep learning. However, some features obtained by traditional methods can better express the color, and these features are an important clue for re-identification. Therefore, in this paper, we combine traditional Gaussian features with deep semantic features to enhance the discrimination of overall features. At last, we have achieved good performance on two public datasets (Market1501 and VIPeR) in three main distance method learning (DML). In addition, we applied this model to the task of vehicle re-identification. Experiments show that our method has a great improvement on the VeRi vehicle dataset. We compare the results with the current high level results, which indicates the effectiveness of our model. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Yongge] Anyang Normal Univ, Sch Comp & Informat Engn, Anyang, Peoples R China.
   [Song, Nan; Han, Yahong] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
   [Liu, Yongge] Anyang Normal Univ, Henan Key Lab Oracle Bone Inscript Informat Proc, Anyang, Peoples R China.
   [Liu, Yongge] Collaborat Innovat Ctr Int Disseminat Chinese Lan, Anyang, Peoples R China.
C3 Anyang Normal University; Tianjin University; Anyang Normal University
RP Han, YH (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
EM yahong@tju.edu.cn
OI Han, Yahong/0000-0003-2768-1398
FU NSFC [U1509206, 61472276, 61876130]; Tianjin Natural Science Foundation
   [15JCYBJC15400]
FX This work is supported by the NSFC (under Grant U1509206, 61472276,
   61876130) and Tianjin Natural Science Foundation (No. 15JCYBJC15400).
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2016, Scientific Programming
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], ARXIV170700408
   [Anonymous], ARXIV161105244
   [Anonymous], ARXIV170107732
   [Anonymous], ARXIV161105666
   [Anonymous], ARXIV160107255
   Barbosa I. B., ARXIV170103153
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Davis J. V., 2007, ICML, P209
   Feris RS, 2012, IEEE T MULTIMEDIA, V14, P28, DOI 10.1109/TMM.2011.2170666
   Han J., 2018, IEEE T CIRC SYST VID, V28
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Song XM, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P239, DOI 10.1145/3240508.3240563
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Sun Y., ARXIV PREPRINT ARXIV
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang HY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1519, DOI 10.1145/3240508.3240677
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Xie L., 2017, IICAI
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2014, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2014.252
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 47
TC 6
Z9 6
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 46
EP 52
DI 10.1016/j.jvcir.2018.11.023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100005
DA 2024-07-18
ER

PT J
AU Nasiri, M
   Behrad, A
AF Nasiri, Morteza
   Behrad, Alireza
TI Using Expectation-Maximization for exposing image forgeries by revealing
   inconsistencies in shadow geometry
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Forgery detection; Shadow geometry; EM algorithm; Image
   tampering
ID DIGITAL CAMERA IDENTIFICATION; DETECTION ALGORITHM; PRNU
AB In this study, a new approach and mathematical framework are proposed for exposing image forgeries by detecting inconsistencies in the geometry of cast shadows. The main difficulty in detecting shadow inconsistencies is the precise establishment of correspondences between object points and their corresponding shadow points. To counter the problem, a mathematical framework is proposed to formulate the geometric transformation between the object points and their corresponding shadow points. We assume a rough correspondence between the object and shadow points and use Expectation-Maximization (EM) algorithm to simultaneously calculate the transformation parameters and categorize rough correspondences as inliers or outliers. To enhance the efficiency of the proposed algorithm, we extend the proposed algorithm to handle the ambiguity in initial correspondence by using the one-tomany correspondence strategy. Experimental results on the provided database comprising forged and authentic images showed the accuracy of 84% and 98% for one-to-one and one-to-many correspondence strategies, respectively. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Nasiri, Morteza; Behrad, Alireza] Shahed Univ, Elect Engn Dept, Tehran, Iran.
C3 Shahed University
RP Behrad, A (corresponding author), Shahed Univ, Elect Engn Dept, Tehran, Iran.
EM mo.nasiri@shahed.ac.ir; behrad@shahed.ac.ir
RI Behrad, Alireza/F-8795-2018
OI Behrad, Alireza/0000-0002-1990-6668
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Akshatha KR, 2016, DIGIT INVEST, V19, P69, DOI 10.1016/j.diin.2016.10.002
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], 2014, APSIPA T SIGNAL INF
   [Anonymous], IMAGE FORENSIC ANAL
   [Anonymous], 2010, IEEE T INF FOREN SEC, DOI DOI 10.1109/TIFS.2010.2078506
   [Anonymous], COMPUTER VISION MULT
   [Anonymous], 2017, DIGITAL IMAGE PROCES
   Bayram S., 2008, IEEE Western New York Image Processing Workshop, P538
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bishop C, 2007, RECOGNITION PATTERN
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   Cao X., 2015, Science China Information Sciences, V58, P1
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chang TY, 2014, J VIS COMMUN IMAGE R, V25, P1289, DOI 10.1016/j.jvcir.2014.04.010
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Choi CH, 2013, FORENSIC SCI INT, V226, P94, DOI 10.1016/j.forsciint.2012.12.014
   Farid H, 2017, AM SCI, V105, P77
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Ge HY, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P116, DOI 10.1109/ICCSS.2015.7281160
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Ke Y., 2014, THESCIENTIFICWORLDJO, P1
   Kee E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629646
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Malviya P, 2014, LECT NOTES COMPUT SC, V8880, P437, DOI 10.1007/978-3-319-13841-1_25
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   Mayer O, 2016, INT CONF ACOUST SPEE, P2024, DOI 10.1109/ICASSP.2016.7472032
   Meij C, 2018, DIGIT INVEST, V24, P142, DOI 10.1016/j.diin.2018.02.005
   Milani S, 2013, INT CONF ACOUST SPEE, P3053, DOI 10.1109/ICASSP.2013.6638219
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Riess C, 2017, MULTIMED TOOLS APPL, V76, P4747, DOI 10.1007/s11042-016-3655-0
   Singh N, 2017, ADV ELECTR ELECTRON, V15, P509, DOI 10.15598/aeee.v15i3.2189
   Singh N, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P413, DOI 10.1109/ICSPCom.2015.7150688
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Stork DG, 2006, INT C PATT RECOG, P255
   Wu L, 2010, COMPUT VIS IMAGE UND, V114, P915, DOI 10.1016/j.cviu.2010.04.003
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Zhang W, 2009, IEEE INT CON MULTI, P1042, DOI 10.1109/ICME.2009.5202676
NR 51
TC 3
Z9 3
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 323
EP 333
DI 10.1016/j.jvcir.2018.12.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100032
DA 2024-07-18
ER

PT J
AU Shen, JQ
   Yu, YZ
   Zhang, CB
   Xu, YM
   Li, FW
   Yao, YY
AF Shen, Jinqing
   Yu, Yunzhong
   Zhang, Chongbiao
   Xu, Yongming
   Li, Feiwei
   Yao, Yiyang
TI Multi-task multimodal feature refinement for emotional speech animation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimodal feature refinement; Emotional speech animation
AB Emotional human facial animation has become an indispensable technique in a series of multimedia systems. The technique first generates the phoneme and emotion sequences. Then, the viseme/expression sequences are calculated accordingly, which are further converted into a coherent facial animation video. In this work, a completely automatic system is designed by selecting acoustic features discriminative to both emotion and phoneme tags. More specifically, acoustic features highly representative to both emotion and phoneme tags are selected under a multi-task learning framework. Based on this, speech phoneme and emotion sequences are effectively calculated. Then, an active learning algorithm is developed to discover the key facial frames representative to both the phoneme and emotion tags. Finally, we associate each phoneme + emotion tuple with a key facial frame. And a popular morphing algorithm is employed to fit them into a coherent animation video. Experimental results have demonstrated that our generated facial animation video is natural, coherent, and highly synchronized with the input speech. (C) 2018 Published by Elsevier Inc.
C1 [Shen, Jinqing; Yu, Yunzhong; Zhang, Chongbiao; Xu, Yongming; Li, Feiwei] State Grid Jiaxing Elect Power Supply Co, Hangzhou, Zhejiang, Peoples R China.
   [Yao, Yiyang] State Grid Zhejiang Elect Power co Ltd, Informat & Telecommun Co, Quzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Yao, YY (corresponding author), State Grid Zhejiang Elect Power co Ltd, Informat & Telecommun Co, Quzhou, Zhejiang, Peoples R China.
EM shen_jinqing@zj.sgcc.com.cn; yu_yunzhong@zj.sgcc;
   zhang_chongbiao@zj.sgcc.com.cn; xu_yongming@zj.sgcc;
   li_feiwei@zj.sgcc.com.cn; yao_yiyang@zj.sgcc.com.cn
RI ARSLAN, Okan/AAA-3232-2020
CR [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], P NIPS
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   BLANZ V, 2003, EUROGRAPHICS, V22
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen Jingyuan, 2016, MICROTELLS MACROPRED
   Cheng Z., 2016, EXPLORING USER SPECI
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Cheng Zhou, 2018, IJCAI
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   Duda R., 1973, Pattern Classification and Scene Analysis
   Hofer G, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2314
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kim Yelin, 2013, EMOTION CLASSIFICATI
   Kshirsagar S, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P38, DOI 10.1109/CGI.2001.934656
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Schuller Bjorn, 2003, HIDDEN MARKOV MODEL
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tao J., 2005, INT C AFF COMP INT I
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Yang Yi, 2010, P IJCAI, P1813
   Zhang J, 2018, IEEE SIGNAL PROC LET, V25, P333, DOI 10.1109/LSP.2017.2748604
   Zhang Luming, 2009, FEATURE SELECTION FA, P753
   Zoric G, 2011, MULTIMED TOOLS APPL, V54, P165, DOI 10.1007/s11042-010-0526-y
NR 27
TC 0
Z9 0
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 712
EP 716
DI 10.1016/j.jvcir.2018.11.043
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100067
DA 2024-07-18
ER

PT J
AU Dai, B
   Mei, F
   Xu, LJ
   Ji, DL
   Shi, J
AF Dai, Bo
   Mei, Feng
   Xu, Liujing
   Ji, Deliang
   Shi, Jia
TI RETRACTED: A new deep representation for large-scale scene
   classification (Retracted article. See vol. 62, pg. 418, 2019)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Scene classification; Graphlets; Finished bag; Region adjacency graph
ID RECOGNITION
AB Large scale scene classification based on image is an important problem in computer vision. In this paper, we propose a method to fuse the local features of scene images into a geometric feature that can reflect both the geometric features of the scene image and the color intensity distribution. First, each scene image is segmented into a set of individually connected regions according to their color intensity distribution. A region adjacency graph is constructed to encode the geometric properties and color intensity of scene images. Later, a 5 tier CNN architecture was constructed to study regional features. Then, a thinning process is carried out to obtain a discriminant and compact template set from the training rag. These templates are used to extract graphlets finished bag (r-bogs) images represented by each scene. Finally, the strategy of boosting development is to classify the extracted r-bogs scenes. Experimental results on different datasets demonstrate the effectiveness and effectiveness of the proposed method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Dai, Bo; Mei, Feng; Xu, Liujing] State Grid Zhejiang Elect Power Co Informat & Tel, Hangzhou, Zhejiang, Peoples R China.
   [Ji, Deliang; Shi, Jia] Zhejiang Huayun Elect Power Ind Grp, Hangzhou, Zhejiang, Peoples R China.
RP Dai, B (corresponding author), State Grid Zhejiang Elect Power Co Informat & Tel, Hangzhou, Zhejiang, Peoples R China.
EM 553641039@qq.com
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2016, ARXIV161001708
   [Anonymous], 2015, ICML
   [Anonymous], FCV
   [Anonymous], ARXIV160407528
   [Anonymous], LARGE MARGIN LOCAL M
   [Anonymous], 2009, BMVC
   [Anonymous], ARXIV15120056
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Davis J. V., 2007, ICML, P209
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
NR 38
TC 2
Z9 2
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 761
EP 765
DI 10.1016/j.jvcir.2018.08.005
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100066
DA 2024-07-18
ER

PT J
AU Yung, CP
   Choi, GPT
   Chen, K
   Lui, LM
AF Yung, Chun Pang
   Choi, Gary P. T.
   Chen, Ke
   Lui, Lok Ming
TI Efficient feature-based image registration by mapping sparsified
   surfaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Triangulated image; Image registration; Coarse triangulation; Map
   interpolation
ID LANDMARK; PARAMETERIZATION; OPTIMIZATION; MAP
AB With the advancement in the digital camera technology, the use of high resolution images and videos has been widespread in the modern society. In particular, image and video frame registration is frequently applied in computer graphics and film production. However, conventional registration approaches usually require long computational time for high resolution images and video frames. This hinders the application of the registration approaches in the modern industries. In this work, we first propose a new image representation method to accelerate the registration process by triangulating the images effectively. For each high resolution image or video frame, we compute an optimal coarse triangulation which captures the important features of the image. Then, we apply a surface registration algorithm to obtain a registration map which is used to compute the registration of the high resolution image. Experimental results suggest that our overall algorithm is efficient and capable to achieve a high compression rate while the accuracy of the registration is well retained when compared with the conventional grid-based approach. Also, the computational time of the registration is significantly reduced using our triangulation-based approach.
C1 [Yung, Chun Pang; Lui, Lok Ming] Chinese Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China.
   [Choi, Gary P. T.] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Chen, Ke] Univ Liverpool, Dept Math Sci, Liverpool, Merseyside, England.
C3 Chinese University of Hong Kong; Harvard University; University of
   Liverpool
RP Yung, CP; Lui, LM (corresponding author), Chinese Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China.
EM lmlui@math.cuhk.edu.hk
RI Chen, Ke/A-1965-2012; Lui, Ronald Lok Ming/IVV-5042-2023; Choi, Gary P.
   T./KFQ-0789-2024
OI Choi, Gary P. T./0000-0001-5407-9111; Lui, Lok Ming/0000-0002-9152-0743;
   Chen, Ke/0000-0002-6093-6623
FU HKRGC GRF [402413]; EPSRC [EP/N014499/1, EP/K036939/1] Funding Source:
   UKRI
FX Lok Ming Lui is supported by HKRGC GRF (Project ID: 402413).
CR [Anonymous], COMPUTER GRAPHICS VI
   [Anonymous], 2000, MATH SURVEYS MONOGR
   Bookstein F., 1997, MORPHOMETRIC TOOLS L
   Bookstein F.L., 1978, Lecture Notes in Biomathematics, V24, P1
   Bookstein F.L., 1999, Brain Warping, P157
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Choi PT, 2015, SIAM J IMAGING SCI, V8, P67, DOI 10.1137/130950008
   Crum WR, 2004, BRIT J RADIOL, V77, pS140, DOI 10.1259/bjr/25329214
   GEE JC, 1994, P SOC PHOTO-OPT INS, V2167, P327, DOI 10.1117/12.175067
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Glaunés J, 2004, J MATH IMAGING VIS, V20, P179, DOI 10.1023/B:JMIV.0000011326.88682.e5
   Glaunès J, 2008, INT J COMPUT VISION, V80, P317, DOI 10.1007/s11263-008-0141-9
   Harris C., 1988, Proc. of the 4th Alvey Vision Conference, P189
   Johnson HJ, 2002, IEEE T MED IMAGING, V21, P450, DOI 10.1109/TMI.2002.1009381
   Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431
   Kaufmann P, 2013, COMPUT GRAPH FORUM, V32, P31, DOI 10.1111/cgf.12023
   Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037
   Lam KC, 2014, SIAM J IMAGING SCI, V7, P2364, DOI 10.1137/130943406
   Lehner B, 2007, LECT NOTES COMPUT SC, V4841, P351
   Lombaert H, 2014, INT J COMPUT VISION, V107, P254, DOI 10.1007/s11263-013-0681-5
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lui LM, 2007, APPL NUMER MATH, V57, P847, DOI 10.1016/j.apnum.2006.07.031
   Lui LM, 2014, SIAM J IMAGING SCI, V7, P391, DOI 10.1137/120900186
   Lui LM, 2013, SIAM J IMAGING SCI, V6, P1880, DOI 10.1137/120866129
   Lui LM, 2010, SIAM J IMAGING SCI, V3, P52, DOI 10.1137/080738386
   Meng TW, 2016, SIAM J IMAGING SCI, V9, P1922, DOI 10.1137/15M1049117
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D., 2007, IEEE COMPUTER SOC C
   Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497
   Shi R, 2013, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2013.327
   Wang YL, 2007, IEEE T MED IMAGING, V26, P853, DOI 10.1109/TMI.2007.895464
   Wang YL, 2005, LECT NOTES COMPUT SC, V3750, P675, DOI 10.1007/11566489_83
   Wei Zeng, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2457, DOI 10.1109/CVPR.2011.5995410
   Yun Y.H., 2013, DMESH TRIANGULATION
   Zeng W, 2014, PROC CVPR IEEE, P4169, DOI 10.1109/CVPR.2014.531
   Zhang J, 2017, E ASIAN J APPL MATH, V7, P125, DOI 10.4208/eajam.200816.031216a
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 39
TC 12
Z9 13
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 561
EP 571
DI 10.1016/j.jvcir.2018.07.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100049
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Kou, F
   Li, ZG
   Wen, CY
   Chen, WH
AF Kou, Fei
   Li, Zhengguo
   Wen, Changyun
   Chen, Weihai
TI Edge-preserving smoothing pyramid based multi-scale exposure fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Exposure fusion; High dynamic range; Image pyramid; Gradient domain
   guided image filter; Edge-preserving smoothing
ID IMAGE FUSION
AB Multi-scale exposure fusion is an efficient approach to fuse multiple differently exposed images of a high dynamic range (HDR) scene directly for displaying on a conventional low dynamic range (LDR) display device without generating an intermediate HDR image. It can produce images with higher quality than single-scale exposure fusion, but has a risk of producing halo artifacts and cannot preserve details in brightest or darkest regions well in the fused image. In this paper, an edge-preserving smoothing pyramid is introduced for the multi-scale exposure fusion. Benefiting from the edge-preserving property of the filter used in the algorithm, the details in the brightest/darkest regions are preserved well and no halo artifacts are produced in the fused image. The complexity of the proposed edge-preserving smoothing pyramid could be an issue. A hybrid smoothing pyramid is proposed to obtain a good trade-off between the complexity of algorithm and the quality of fused images. The experimental results prove that the proposed algorithms produce better fused images than the state-of-the-art algorithms both qualitatively and quantitatively.
C1 [Kou, Fei; Chen, Weihai] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
   [Kou, Fei] Vivo Mobile Commun Co Ltd, New Tech Inst, Hangzhou 310012, Zhejiang, Peoples R China.
   [Li, Zhengguo] Inst Infocomm Res, Robot Dept, Singapore 639798, Singapore.
   [Wen, Changyun] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 138632, Singapore.
C3 Beihang University; Agency for Science Technology & Research (A*STAR);
   A*STAR - Institute for Infocomm Research (I2R); Nanyang Technological
   University
RP Chen, WH (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
EM whchenbuaa@126.com
RI KOU, Fei/T-6048-2019; Chen, Wei/GZK-7348-2022; Wen, Changyun/A-5018-2011
OI Wen, Changyun/0000-0001-9530-360X; /0009-0006-1337-808X
FU National Nature Science Foundation of China [61620106012, 61573048,
   61603020]; International Scientific and Technological Cooperation
   Projects of China [2015DFG12650]
FX This work has been supported by National Nature Science Foundation of
   China under the research project 61620106012, 61573048, 61603020 and by
   the International Scientific and Technological Cooperation Projects of
   China under Grant No. 2015DFG12650.
CR [Anonymous], ACM T GRAPH P SIGGRA
   [Anonymous], ACM T GRAPH
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jinno T, 2012, IEEE T IMAGE PROCESS, V21, P358, DOI 10.1109/TIP.2011.2160953
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Kou F, 2017, IEEE INT CON MULTI, P1105, DOI 10.1109/ICME.2017.8019529
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li H, 2018, COMPUT VIS IMAGE UND, V168, P37, DOI 10.1016/j.cviu.2017.11.001
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Li ZG, 2014, IEEE T IND ELECTRON, V61, P7076, DOI 10.1109/TIE.2014.2314066
   Li ZG, 2014, IEEE T IMAGE PROCESS, V23, P4372, DOI 10.1109/TIP.2014.2349432
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Ma KD, 2015, IEEE IMAGE PROC, P1717, DOI 10.1109/ICIP.2015.7351094
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Song M., 2012, IEEE T IMAGE PROCESS, V21, P256
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wei Z, 2018, IEEE T CIRC SYST VID, V28, P550, DOI 10.1109/TCSVT.2016.2611944
   Wu SQ, 2014, IEEE SIGNAL PROC LET, V21, P885, DOI 10.1109/LSP.2014.2318302
   Yao W, 2012, INT CONF ACOUST SPEE, P917, DOI 10.1109/ICASSP.2012.6288034
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
NR 33
TC 39
Z9 47
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 235
EP 244
DI 10.1016/j.jvcir.2018.03.020
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800022
DA 2024-07-18
ER

PT J
AU Wang, XF
   Zhou, DD
   Zeng, NL
   Yu, XN
   Hu, SL
AF Wang, Xiaofeng
   Zhou, Didong
   Zeng, Nengliang
   Yu, Xina
   Hu, Shaolin
TI Super-resolution image reconstruction using surface fitting with
   hierarchical structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution image reconstruction; Neighborhood expansion;
   Multi-surface fitting; Hierarchical structure; MAP estimation
ID SPARSE; RESOLUTION
AB We propose a super-resolution image reconstruction method using multi-source low resolution images. The proposed method includes a hierarchical structure that combines a neighborhood expansion process with the surface fitting technique. In the proposed method, a series of nested neighborhoods are created to collect LR pixels, and a purification algorithm is put forward to remove the outliers. Then we fit with a surface in each neighborhood to obtain a value at the location of estimated high resolution grid site. These values are pooled to a MAP frame to reconstruct high resolution pixels. Therefore, a reconstructed pixel is associated with the pixel correlation, pixel intensity and the spatial structure. Moreover, our method is non-iterative and does not suffer from convergence problem. Comparing with the state-of-the-art schemes, the proposed method provides superior effect and computational efficiency. Experimental results demonstrate the superiority of the proposed method in both visual fidelity and numerical measures.
C1 [Wang, Xiaofeng; Zhou, Didong; Zeng, Nengliang; Yu, Xina] Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
   [Hu, Shaolin] Foshan Univ, Automat Sch, Foshan 528000, Guangdong, Peoples R China.
C3 Xi'an University of Technology; Foshan University
RP Wang, XF (corresponding author), Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
EM xfwang66@sina.com.cn
RI Hu, Shaolin/N-1791-2018; li, ye/GWN-2672-2022; Li, Ye/JBS-2949-2023; Hu,
   Shaolin/AAN-5168-2021
FU National Natural Science Foundation of China [61772416, 91646108,
   61473222]; Key Laboratory Project of the Education Department of Shaanxi
   Province, China [17JS098]; State Key Laboratory of Astronautic Dynamics,
   China
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61772416, 91646108, and 61473222; the Key
   Laboratory Project of the Education Department of Shaanxi Province,
   China, under Grant No. 17JS098; The Scientific Researching Fund of the
   State Key Laboratory of Astronautic Dynamics, China.
CR Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belekos SP, 2010, IEEE T IMAGE PROCESS, V19, P1451, DOI 10.1109/TIP.2010.2042115
   Camponez MO, 2012, IEEE T IMAGE PROCESS, V21, P3491, DOI 10.1109/TIP.2012.2197016
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Hu YT, 2016, IEEE T IMAGE PROCESS, V25, P4091, DOI 10.1109/TIP.2016.2580942
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Ilovitsh A, 2012, APPL OPTICS, V51, P5863, DOI 10.1364/AO.51.005863
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kennedy JA, 2006, IEEE T MED IMAGING, V25, P137, DOI 10.1109/TMI.2005.861705
   Kidera S, 2011, IEEE T ANTENN PROPAG, V59, P1606, DOI 10.1109/TAP.2011.2123059
   Li F, 2008, IEEE IMAGE PROC, P333, DOI 10.1109/ICIP.2008.4711759
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ng M.K., 2007, J ADV SIG PROCESS, V2007, P230
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   Robinson M.D., 2011, SUPER RESOLUTION IMA, P383
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Wang HJ, 2017, SIGNAL PROCESS, V134, P52, DOI 10.1016/j.sigpro.2016.11.006
   Wang HJ, 2016, IEEE T IMAGE PROCESS, V25, P935, DOI 10.1109/TIP.2015.2512104
   Wang N., 2017, IEEE T IMAGE PROCESS, V26
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Weber A., USC SIPI IM DAT
   Xue W., 2013, P IEEE C COMP VIS PA
   Yang JH, 2008, CRYST RES TECHNOL, V43, P999, DOI 10.1002/crat.200800010
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JS, 2011, SPINE, V36, P1639, DOI 10.1097/BRS.0b013e31822a982f
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Zhang KB, 2017, IEEE T NEUR NET LEAR, V28, P1109, DOI 10.1109/TNNLS.2015.2511069
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou F, 2014, IEEE T CIRC SYST VID, V24, P2013, DOI 10.1109/TCSVT.2014.2344513
   Zhou F, 2012, IEEE T IMAGE PROCESS, V21, P3312, DOI 10.1109/TIP.2012.2189576
   Zhu XX, 2012, IEEE T GEOSCI REMOTE, V50, P3150, DOI 10.1109/TGRS.2011.2177843
NR 39
TC 3
Z9 3
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 65
EP 75
DI 10.1016/j.jvcir.2018.03.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800007
DA 2024-07-18
ER

PT J
AU Sanaee, P
   Moallem, P
   Razzazi, F
AF Sanaee, Payam
   Moallem, Payman
   Razzazi, Farbod
TI A structural post-processing method for enhancing intensity restoration
   of low-density impulse-noise for decision based filters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Impulse-noise; Image denoising; Image restoration; Decision based
   filters; Edge and detail preserving
ID NONLOCAL MEANS FILTER; PEPPER NOISE; DIGITAL IMAGES; MEDIAN FILTER; MEAN
   FILTER; REMOVAL; SALT; ALGORITHM
AB Intensity restoration of pixels corrupted by impulse-noise contributes greatly to the quality of decision based filters (DBF). In this paper, we present an efficient structural post-processing method, which is based on directional-correlation, linear-regression-analysis, and inverse-distance-weighted-mean techniques. The proposed method is adopted as a complementary part after DBFs to enhance the quality of the final restored image. We assume that by adopting the preliminary DBF, noisy-pixels are detected by noise-detection unit and afterwards their intensities are estimated by the noise-restoration unit. In our method for each detected noisy-pixel, the intensity variation of adjacent pixels of restored image on different directions are analyzed in the corresponding local window and based on this structural information, the intensity of the previously-restored noisy-pixel is modified more accurately. Since the structures in images are more recognizable for low-density impulse-noise, our method is more effective in this case however a gradual improvement is achieved for high density impulse-noise.
C1 [Sanaee, Payam; Razzazi, Farbod] Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Moallem, Payman] Univ Isfahan, Dept Elect Engn, Fac Engn, Esfahan, Iran.
   [Moallem, Payman] Univ Isfahan, Appl Image & Signal Proc Res Grp, Res Ctr Signal Proc & Intelligent Syst, Esfahan, Iran.
C3 Islamic Azad University; University of Isfahan; University of Isfahan
RP Moallem, P (corresponding author), Univ Isfahan, Dept Elect Engn, Fac Engn, Esfahan, Iran.
EM p.sanaee@pel.iaun.ac.ir; p_moallem@eng.ui.ac.ir; razzazi@srbiau.ac.ir
RI Razzazi, Farbod/AAO-8522-2021; Sanaee, Payam/AAM-6199-2020; sanaee,
   payam/AAN-6212-2021
OI Sanaee, Payam/0000-0002-5109-2879; Razzazi, Farbod/0000-0003-4970-8117
CR Bai T, 2014, SIGNAL PROCESS, V102, P247, DOI 10.1016/j.sigpro.2014.03.023
   Balasubramanian G, 2016, AEU-INT J ELECTRON C, V70, P471, DOI 10.1016/j.aeue.2016.01.013
   Bovik Alan C, 2010, Handbook of image and video processing
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Chen PY, 2008, IEEE SIGNAL PROC LET, V15, P833, DOI 10.1109/LSP.2008.2005047
   Chou HH, 2015, J VIS COMMUN IMAGE R, V30, P363, DOI 10.1016/j.jvcir.2015.05.007
   Faragallah OS, 2016, AEU-INT J ELECTRON C, V70, P1034, DOI 10.1016/j.aeue.2016.04.018
   Gao GR, 2015, OPTIK, V126, P467, DOI 10.1016/j.ijleo.2014.11.004
   Gellert A, 2016, IET IMAGE PROCESS, V10, P429, DOI 10.1049/iet-ipr.2015.0702
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Kalyoncu C, 2013, IET IMAGE PROCESS, V7, P777, DOI 10.1049/iet-ipr.2013.0146
   Kandemir C, 2015, DIGIT SIGNAL PROCESS, V46, P164, DOI 10.1016/j.dsp.2015.08.012
   Li ZY, 2014, PATTERN RECOGN LETT, V40, P113, DOI 10.1016/j.patrec.2013.12.022
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Lu CT, 2016, PATTERN RECOGN LETT, V80, P188, DOI 10.1016/j.patrec.2016.06.026
   Meher SK, 2014, AEU-INT J ELECTRON C, V68, P1173, DOI 10.1016/j.aeue.2014.06.006
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Wu J, 2011, PATTERN RECOGN LETT, V32, P1974, DOI 10.1016/j.patrec.2011.09.025
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang CB, 2015, OPTIK, V126, P956, DOI 10.1016/j.ijleo.2015.02.085
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhang XQ, 2015, AEU-INT J ELECTRON C, V69, P307, DOI 10.1016/j.aeue.2014.09.018
   Zhang XM, 2013, SIGNAL PROCESS, V93, P517, DOI 10.1016/j.sigpro.2012.08.022
NR 24
TC 0
Z9 0
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 40
EP 55
DI 10.1016/j.jvcir.2017.12.014
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500005
DA 2024-07-18
ER

PT J
AU Pramanik, R
   Bag, S
AF Pramanik, Rahul
   Bag, Soumen
TI Shape decomposition-based handwritten compound character recognition for
   Bangla OCR
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bangla OCR; Chain code histogram; Handwritten compound character; MLP;
   Segmentation; Shape decomposition
AB Proper recognition of complex-shaped handwritten compound characters is still a big challenge for Bangla OCR systems. In this paper, we propose a novel shape decomposition-based segmentation technique to decompose the compound characters into prominent shape components. This shape decomposition reduces the classification complexity in terms of less number of classes to recognize, and at the same time improves the recognition accuracy. The decomposition is done at the segmentation area where the two basic shapes are joined to form a compound character. We use chain code histogram feature set with multi-layer perceptron (MLP) based classifier with backpropagation learning for classification. On experimentation, the proposed method is observed to provide good recognition accuracy comparing with other existing methods.
C1 [Pramanik, Rahul; Bag, Soumen] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Pramanik, R (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM rahul.wbsu@gmail.com; bagsoumen@gmail.com
RI Pramanik, Rahul/AAE-2516-2019
OI Pramanik, Rahul/0000-0002-1410-9950
CR AlKhateeb JH, 2011, PATTERN RECOGN LETT, V32, P1081, DOI 10.1016/j.patrec.2011.02.006
   [Anonymous], 1982, Digital Picture Processing
   [Anonymous], 2009, IICAI
   [Anonymous], 2011, 2011 INT C IMAGE INF
   [Anonymous], 2010, HANDWRITTEN BANGLA B
   Bag S., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P21, DOI 10.1109/NCVPRIPG.2011.12
   Bag S., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P265, DOI 10.1109/EAIT.2011.44
   Bag S, 2014, PATTERN RECOGN, V47, P1187, DOI 10.1016/j.patcog.2013.08.026
   Bag S, 2013, SADHANA-ACAD P ENG S, V38, P133, DOI 10.1007/s12046-013-0121-9
   Bhattacharya U, 2012, PATTERN ANAL APPL, V15, P445, DOI 10.1007/s10044-012-0278-6
   Bunke H, 2007, ADV PATTERN RECOGNIT, P165, DOI 10.1007/978-1-84628-726-8_8
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Das N, 2012, ADV INTEL SOFT COMPU, V132, P145
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Garain U, 1998, P SOC PHOTO-OPT INS, V3305, P90, DOI 10.1117/12.304622
   Huang L, 2003, PROC INT CONF DOC, P780
   Li Fuliang, 2010, Proceedings of the 2010 International Conference on Machine Vision and Human-Machine Interface (MVHI 2010), P393, DOI 10.1109/MVHI.2010.185
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal U., 2007, Proceedings of 10th International Conference on Information Technology (ICIT), P208, DOI [DOI 10.1109/ICIT.2007.62, 10.1109/ICIT.2007.43, DOI 10.1109/ICIT.2007.43]
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Rahman Mahbubar, 2015, International Journal of Image, Graphics and Signal Processing, V7, P42, DOI 10.5815/ijigsp.2015.08.05
   Rashad M., 2012, Proceedings 2012 Japan-Egypt Conference on Electronics, Communications and Computers (JEC-ECC), P68, DOI 10.1109/JEC-ECC.2012.6186959
   Roy PP, 2014, INT CONF FRONT HAND, P661, DOI 10.1109/ICFHR.2014.116
   Sarkar R., 2008, P INT C FRONT HANDWR, P403
   Sobu Y., 2010, 25 INT C IM VIS COMP, P1
   Stamatopoulos N, 2013, PROC INT CONF DOC, P1402, DOI 10.1109/ICDAR.2013.283
   Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
   Zhou XD, 2013, IEEE T PATTERN ANAL, V35, P2413, DOI 10.1109/TPAMI.2013.49
NR 30
TC 52
Z9 53
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 123
EP 134
DI 10.1016/j.jvcir.2017.11.016
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700013
DA 2024-07-18
ER

PT J
AU He, WG
   Zhou, K
   Cai, J
   Wang, L
   Xiong, GQ
AF He, Wenguang
   Zhou, Ke
   Cai, Jie
   Wang, Long
   Xiong, Gangqiang
TI Reversible data hiding using multi-pass pixel value ordering and
   prediction-error expansion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Multi-pass pixel value ordering;
   Prediction-error expansion; Optimal combined embedding
ID DIFFERENCE EXPANSION; IMAGE WATERMARKING
AB Pixel value ordering (PVO) prediction has become the most efficient method for high-fidelity reversible data hiding (RDH). In this approach, only the maximum and minimum of pixel block are predicted and modified to embed data and the preservation of pixel value order guarantees the reversibility. To achieve larger embedding capacity and superior performance, more blocks suitable for RDH are utilized in recent improved schemes. However, their performance is still unsatisfactory. In this paper, a novel RDH scheme is proposed by extending original PVO into multi-pass PVO embedding. Specially, the k largest or smallest pixels are taken as independent data bit carriers to fulfill k-pass PVO embedding. Although the pixel value order may change after data embedding, reversibility still can be guaranteed and image redundancy can be far better exploited. Moreover, embedding performance can be further enhanced by optimal combined embedding. Experimental results verify that the proposed scheme outperforms previous PVO-based schemes and some other state-of-the-art works.
C1 [He, Wenguang; Zhou, Ke; Cai, Jie; Wang, Long; Xiong, Gangqiang] Guangdong Med Univ, Sch Informat Engn, Guangzhou 524023, Guangdong, Peoples R China.
C3 Guangdong Medical University
RP Xiong, GQ (corresponding author), Guangdong Med Univ, Sch Informat Engn, Guangzhou 524023, Guangdong, Peoples R China.
EM xionggq@aliyun.com
OI he, wenguang/0000-0003-1051-389X
FU National Scientific Fund of China [61170320]
FX This work is supported by the National Scientific Fund of China (No.
   61170320).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pei QQ, 2013, J SYST SOFTWARE, V86, P2841, DOI 10.1016/j.jss.2013.06.055
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
NR 36
TC 53
Z9 58
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 351
EP 360
DI 10.1016/j.jvcir.2017.10.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800029
DA 2024-07-18
ER

PT J
AU Li, HR
   Zhang, JS
   Liu, JM
AF Li, Huirong
   Zhang, Jiangshe
   Liu, Junmin
TI Graph-regularized CF with local coordinate for image representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Concept factorization; Graph regularization; Local coordinate
   constraint; Image representation
ID NONNEGATIVE MATRIX FACTORIZATION; CONSTRAINED CONCEPT FACTORIZATION;
   PARTS; MODEL
AB Concept factorization (CF) has been a powerful data representation method, which has been widely applied in image processing and document clustering. However, traditional CF cannot guarantee the decomposition results of CF to be sparse in theory and do not consider the geometric structure of the databases. In this paper, we propose a graph-regularized CF with local coordinate (LGCF) method, which enforces the learned coefficients to be sparse by using the local coordinate constraint meanwhile preserving the intrinsic geometric structure of the data space by incorporating graph regularization. An iterative optimization method is also proposed to solve the objective function of LGCF. By comparing with the state-of-the-arts algorithms (Kmeans, NMF, CF, LCCF, LCF), experimental results on four popular databases show that the proposed LGCF method has better performance in terms of average accuracy and mutual information.
C1 [Li, Huirong; Zhang, Jiangshe; Liu, Junmin] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.
   [Li, Huirong] Shangluo Univ, Sch Math & Comp Applicat, Shangluo 726000, Peoples R China.
C3 Xi'an Jiaotong University; Shangluo University
RP Zhang, JS (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.
EM jszhang@mail.xjtu.edu.cn
FU National Basic Research Program of China (973 Program) [2013CB329404];
   National Natural Science Foundation of China [61572393, 11671317,
   11131006]; Natural Science Basic Research Plan in Shaanxi Province of
   China [2014JM2-6098]
FX This work was supported by the National Basic Research Program of China
   (973 Program) under Grant No. 2013CB329404, the National Natural Science
   Foundation of China under Grant Nos. 61572393, 11671317, 11131006, and
   the Project Supported by Natural Science Basic Research Plan in Shaanxi
   Province of China No. 2014JM2-6098.
CR [Anonymous], ARXIV160405449
   [Anonymous], ARXIV170107194
   [Anonymous], P ICML ATL GA US 16
   [Anonymous], REGIONAL C SERIES MA
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101
   Cai D, 2011, IEEE T KNOWL DATA EN, V23, P902, DOI 10.1109/TKDE.2010.165
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chen Y, 2013, IEEE T IMAGE PROCESS, V22, P969, DOI 10.1109/TIP.2012.2224357
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Guan NY, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P404, DOI 10.1109/ICMLA.2012.73
   He YC, 2014, NEURAL NETWORKS, V52, P1, DOI 10.1016/j.neunet.2013.12.007
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hua W, 2011, NEUROCOMPUTING, V74, P3800, DOI 10.1016/j.neucom.2011.07.020
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kalman D., 1996, Coll. Math. J, V27, P2, DOI [DOI 10.1080/07468342.1996.11973744, 10.1080/07468342.1996.11973744]
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li HR, 2017, KNOWL-BASED SYST, V118, P70, DOI 10.1016/j.knosys.2016.11.012
   Li HR, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023023
   Li HR, 2016, NEUROCOMPUTING, V190, P197, DOI 10.1016/j.neucom.2016.01.017
   Li SZ, 2001, PROC CVPR IEEE, P207
   Liao Q, 2016, SIGNAL PROCESS, V124, P103, DOI 10.1016/j.sigpro.2015.09.038
   Liu HF, 2014, IEEE T CYBERNETICS, V44, P1214, DOI 10.1109/TCYB.2013.2287103
   Liu HF, 2014, IEEE T NEUR NET LEAR, V25, P1071, DOI 10.1109/TNNLS.2013.2286093
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Liu TL, 2017, IEEE T NEUR NET LEAR, V28, P2129, DOI 10.1109/TNNLS.2016.2574748
   Liu TL, 2016, IEEE T NEUR NET LEAR, V27, P1851, DOI 10.1109/TNNLS.2015.2458986
   Long XZ, 2014, MULTIMED TOOLS APPL, V72, P2679, DOI 10.1007/s11042-013-1572-z
   Lu M, 2016, KNOWL-BASED SYST, V102, P127, DOI 10.1016/j.knosys.2016.04.003
   Lu M, 2016, INFORM SCIENCES, V331, P86, DOI 10.1016/j.ins.2015.10.038
   Lu N, 2016, NEUROCOMPUTING, V171, P400, DOI 10.1016/j.neucom.2015.06.049
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005
   Shu ZQ, 2015, NEUROCOMPUTING, V158, P1, DOI 10.1016/j.neucom.2015.02.014
   Sun FM, 2016, NEUROCOMPUTING, V173, P233, DOI 10.1016/j.neucom.2015.01.103
   Sun M, 2015, PATTERN RECOGN LETT, V54, P97, DOI 10.1016/j.patrec.2015.01.002
   Wang D, 2016, IEEE T CYBERNETICS, V46, P233, DOI 10.1109/TCYB.2015.2399533
   Wei Xu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P202
   Xu C, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1275, DOI 10.1145/2939672.2939798
   Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yu Hsiang- Fu, 2016, NIPS 2016, V29, P847, DOI 10.5555/3157096.3157191
   Yu Kai., 2009, P ADV NEUR INF PROC, V9, P1
   Zeng K, 2014, NEUROCOMPUTING, V138, P209, DOI 10.1016/j.neucom.2014.01.043
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 47
TC 9
Z9 10
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 392
EP 400
DI 10.1016/j.jvcir.2017.10.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800033
DA 2024-07-18
ER

PT J
AU Mary, NAB
   Dharma, D
AF Mary, N. Ani Brown
   Dharma, Dejey
TI Coral reef image classification employing Improved LDP for feature
   extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Classification; Coral reef; Feature extraction; Euclidean distance; KNN;
   SVM; CLAHE; Contrast stretching
AB This paper presents a scheme for feature extraction that can be applied for classification of corals in submarine coral reef images. In coral reef image classification, texture features are extracted using the proposed Improved Local Derivative Pattern (ILDP). ILDP determines diagonal directional pattern features based on local derivative variations which can capture full information. For classification, three classifiers, namely Convolutional Neural Network (CNN), K-Nearest Neighbor (KNN) with four distance metrices, namely Euclidean distance, Manhattan distance, Canberra distance and Chi-Square distance, and Support Vector Machine (SVM) with three kernel functions, namely Polynomial, Radial basis function, Sigmoid kernel are used. The accuracy of the proposed method is compared with Local Binary pattern (LBP), Local Tetra Pattern (LTrP), Local Derivative Pattern (LDP) and Robust Local Ternary Pattern (RLTP) on five coral data sets and four texture data sets. Experimental results indicate that ILDP feature extraction method when tested with five coral data sets, namely EILAT, RSMAS, EILAT2, MLC2012 and SDMRI and four texture data sets, namely KTH-TIPS, UIUCTEX, CURET and LAVA achieves the highest overall classification accuracy, minimum execution time when compared to the other methods.
C1 [Mary, N. Ani Brown; Dharma, Dejey] Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli Region 627007, Tirunelveli, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Mary, NAB (corresponding author), Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli Region 627007, Tirunelveli, India.
EM anibrownvimalraj@gmail.com
RI Mary, Ani Brown/AAZ-5896-2020
OI Dharma, Dejey/0000-0002-5173-4878
CR Agrawal Shikha, 2016, NEURAL COMPUTING APP
   [Anonymous], MTS IEEE C EXH IEEE
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P 2004 IEEE COMP SOC
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2008, OCEANS
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], STATUS CORAL REEFS W
   Badri Hicham, 2014, EUR C COMP VIS
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bellwood D.R., 2004, CONFRONTING CORAL RE, V429
   Bewley MS, 2015, SPRINGER TRAC ADV RO, V105, P3, DOI 10.1007/978-3-319-07488-7_1
   Bewley M.S., 2012, P AUSTR C ROB AUT 3
   Blanchet Jean-Nicola, 2016, PEERJ PREPRINTS
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Caputo Barbara, 2005, 10 IEEE INT C COM VI
   Clement R., 2005, C ROB AUT
   da Costa Botelho Silvia Silva, 2009, Journal of the Brazilian Computer Society, V15, P47, DOI 10.1007/BF03194505
   Diaz JA, 2006, MIDWEST SYMP CIRCUIT, P610, DOI 10.1109/MWSCAS.2006.381804
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Hedley JD, 2004, CORAL REEFS, V23, P60, DOI 10.1007/s00338-003-0354-x
   Kohler KE, 2006, COMPUT GEOSCI-UK, V32, P1259, DOI 10.1016/j.cageo.2005.11.009
   Leutenegger R.Y, 2011, BRISK BINARY ROBUST
   Lin Tsung-Yu, 2016, VISUALIZING UNDERSTA
   Loya Y, 2004, CORAL HEALTH AND DISEASE, P1
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Marcos MSA, 2008, ENVIRON MONIT ASSESS, V145, P177, DOI 10.1007/s10661-007-0027-2
   Marcos S.A., 2003, SCI DILIMAN, V15, P45
   Mehta A, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P302
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Omranpour Hesam, 2015, NEURAL COMPUTING APP
   Padmavathi G., 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P983, DOI 10.1109/CISP.2010.5646932
   Pandolfi JM, 2011, SCIENCE, V333, P418, DOI 10.1126/science.1204794
   Petie Ronald, 2016, VISUAL ORIENTATION C
   Pican N., 2002, OCEANS C P, V1, P424
   Quan Yuhui, 2014, IEEE C COMP VIS PATT
   Radha, 2011, INT J COMPUT SCI INF, V2, P836
   Ren Huorong, 2013, J SIGNAL PROCESS SYS
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677
   Shakoor MH, 2017, MULTIMEDIA TOOLS APP
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Sifre Laurent, 2013, ROTATION SCALING DEF
   Singh R.P., 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition, V8, P345, DOI DOI 10.14257/IJSIP.2015.8.8.35
   Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
   Tusa Eduardo, SENSOR SYSTEMS CHANG, P1
   Voravuthikunchai W, 2014, PROC CVPR IEEE, P224, DOI 10.1109/CVPR.2014.36
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Xiao T., 2015, Learning from massive noisy labeled data for image classification. Paper presented at: IEEE Conference on Computer Vision and Pattern Recognition, Boston
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhou F., 2015, FINE GRAINED IMAGE C
NR 57
TC 34
Z9 36
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 225
EP 242
DI 10.1016/j.jvcir.2017.09.008
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800019
DA 2024-07-18
ER

PT J
AU Asif, MR
   Chun, Q
   Hussain, S
   Fareed, MS
   Khan, S
AF Asif, Muhammad Rizwan
   Chun, Qi
   Hussain, Sajid
   Fareed, Muhanimad Sadiq
   Khan, Subhan
TI Multinational vehicle license plate detection in complex backgrounds
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE License plate detection; Traffic surveillance; Intelligent transport
   systems; Color space conversion; Adaptive thresholding; Vehicle
   identification
ID PARALLEL FRAMEWORK; RECOGNITION; ALGORITHM
AB Many methods for multinational License Plate Detection (LPD) have been proposed in recent times but most of them are not sophisticated enough to handle complex backgrounds. Moreover, their ability to handle various environmental and illumination conditions has been limited and still needs improvement. In this paper, we propose a novel technique to detect license plates of vehicles regardless of their color, size, and content. As the rear vehicle lights are an essential part of any vehicle, we reduce the image processing area to eliminate the complex background by detecting the rear-lights as the license plates are in a certain range of these lights. Heuristic Energy Map (HEM) of the vertical edge information in the Region of Interest (ROI) is calculated and area with the dense edges is selected using a unique histogram approach which is considered to be the license plate. The proposed algorithm is tested on 855 images from various countries including China, Pakistan, Serbia, Italy and various states of America. Experimental results show that the proposed method is able to detect license plates 90.4% of times despite of complex backgrounds in 0.25 s on average that can achieve real time performance. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Asif, Muhammad Rizwan; Chun, Qi; Hussain, Sajid; Fareed, Muhanimad Sadiq] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Asif, Muhammad Rizwan; Khan, Subhan] COMSATS Inst Informat Technol, Dept Elect Engn, Lahore 54000, Pakistan.
   [Hussain, Sajid] Roshni Recycle Inst Res & Technol, Gilgit Baltistan 15100, Pakistan.
C3 Xi'an Jiaotong University; COMSATS University Islamabad (CUI)
RP Chun, Q (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qichun@mail.xjtu.edu.cn
RI Khan, Subhan/AFL-0450-2022
OI Khan, Subhan/0000-0002-0979-3751; Asif, Muhammad
   Rizwan/0000-0003-1385-8041
FU National Natural Science Foundation of China [61572395, 61675161]
FX This research is supported by the National Natural Science Foundation of
   China (Grant Nos. 61572395 and 61675161).
CR Al-Ghaili AM, 2013, IEEE T VEH TECHNOL, V62, P26, DOI 10.1109/TVT.2012.2222454
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   [Anonymous], 2015, 2015 INT C PERVASIVE
   [Anonymous], 2014, International Journal of Computer Science and Information Technologies (IJCSIT)
   [Anonymous], ICIIEC 2015
   [Anonymous], OPTIK INT J LIGHT EL
   [Anonymous], INT C SEC AUTH SAPIE
   Asif MR, 2016, IET INTELL TRANSP SY, V10, P535, DOI 10.1049/iet-its.2016.0008
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Chen ZX, 2009, IEEE T VEH TECHNOL, V58, P3781, DOI 10.1109/TVT.2009.2013139
   Gazcón NF, 2012, PATTERN RECOGN LETT, V33, P1066, DOI 10.1016/j.patrec.2012.02.004
   Ghaziani M, 2013, COMM SIGN PROC THEIR, P1
   Gonzales R.C., 2002, Digital Image Processing By Gonzalez, V2nd, P66
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   Hu Hongping, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P2291, DOI 10.1109/EMEIT.2011.6023021
   Ktata S, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON SCIENCES OF ELECTRONICS, TECHNOLOGIES OF INFORMATION AND TELECOMMUNICATIONS (SETIT), P735, DOI 10.1109/SETIT.2012.6482006
   Lalimi MA, 2013, COMPUT ELECTR ENG, V39, P834, DOI 10.1016/j.compeleceng.2012.09.015
   LEE ER, 1994, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.1994.413580
   Massoud MA, 2013, ALEX ENG J, V52, P319, DOI 10.1016/j.aej.2013.02.005
   Matas J, 2005, 2005 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC), P572
   Miyamoto K., 1991, Proceedings IECON '91. 1991 International Conference on Industrial Electrlnics, Control and Instrumentation (Cat. No.91CH2976-9), P1734, DOI 10.1109/IECON.1991.239253
   Prabhakar P, 2014, I C CURR TRENDS ENG, P7, DOI 10.1109/ICCTET.2014.6966255
   Sharma J, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P347, DOI 10.1109/ICROIT.2014.6798352
   Shi XF, 2005, LECT NOTES COMPUT SC, V3483, P1159
   Tadic V., 2011, Proceedings of the 2011 IEEE 9th International Symposium on Intelligent Systems and Informatics (SISY 2011), P381, DOI 10.1109/SISY.2011.6034357
   Tadic V, 2016, ENG APPL ARTIF INTEL, V48, P40, DOI 10.1016/j.engappai.2015.09.009
   Tan JL, 2013, IEEE IMAGE PROC, P4549, DOI 10.1109/ICIP.2013.6738937
   Le TS, 2014, PROC INT CONF ADV, P326, DOI 10.1109/ATC.2014.7043406
   Wang A., 2012, PROC IEEE CUSTOM INT, P1, DOI [10.1109/IFOST.2012.6357669, DOI 10.1109/IFOST.2012.6357669]
   Wang F, 2008, PATTERN RECOGN LETT, V29, P1007, DOI 10.1016/j.patrec.2008.01.026
   Xiao Jiang, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P15, DOI 10.1109/ICWAPR.2012.6294747
   Xu HK, 2005, PDCAT 2005: Sixth International Conference on Parallel and Distributed Computing, Applications and Technologies, Proceedings, P1055
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yingjun Wu, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P361, DOI 10.1109/ICSESS.2013.6615324
NR 35
TC 23
Z9 24
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 176
EP 186
DI 10.1016/j.jvcir.2017.03.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500016
DA 2024-07-18
ER

PT J
AU He, WG
   Cai, J
   Zhou, K
   Xiong, GQ
AF He, Wenguang
   Cai, Jie
   Zhou, Ke
   Xiong, Gangqiang
TI Efficient PVO-based reversible data hiding using multistage blocking and
   prediction accuracy matrix
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Pixel value ordering; Multistage blocking;
   Prediction accuracy matrix
ID WATERMARKING; IMAGE; EXPANSION
AB In recent years, pixel value ordering based reversible data hiding has become a hot research topic for its high-fidelity. In this approach, only the maximum and minimum of pixel block are predicted and modified to embed data and the preservation of pixel values order guarantees the reversibility. So far, the optimal block size can only be exhaustively searched until Wang et al. propose the dynamic blocking strategy which enables the combination of two various-sized blocks. By further dividing flat block into four sub-blocks to retain larger embedding capacity, dynamic blocking can employ less high complexity blocks for a given embedding capacity. However, the lack of host image dependent automatic block classification mechanism still exposes the fact that their work is far from efficient and comprehensive. In this paper, to address this drawback and to better exploit image redundancy, a really efficient and more comprehensive blocking strategy namely multistage blocking is proposed. High efficiency lies in prediction accuracy matrix based thresholds determination, which enables infinitely extended multistage blocking in theory. The superiority of the proposed scheme is also experimentally verified. (C) 2017 Elsevier Inc. All rights reserved.
C1 [He, Wenguang; Cai, Jie; Zhou, Ke; Xiong, Gangqiang] Guangdong Med Univ, Sch Informat Engn, Zhanjiang 524023, Guangdong, Peoples R China.
C3 Guangdong Medical University
RP He, WG (corresponding author), Guangdong Med Univ, Sch Informat Engn, Zhanjiang 524023, Guangdong, Peoples R China.
EM 56207403@qq.com
OI he, wenguang/0000-0003-1051-389X
FU National Scientific Fund of China [61170320, 81201763]
FX This work is supported by the National Scientific Fund of China (Nos.
   61170320, 81201763).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fu DS, 2014, AEU-INT J ELECTRON C, V68, P933, DOI 10.1016/j.aeue.2014.04.015
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li X., IEEE T IMAGE PROCESS, V20
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B., SIGNAL PROCESS IMAGE, V29
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Pei QQ, 2013, J SYST SOFTWARE, V86, P2841, DOI 10.1016/j.jss.2013.06.055
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 33
TC 43
Z9 43
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 58
EP 69
DI 10.1016/j.jvcir.2017.03.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500006
DA 2024-07-18
ER

PT J
AU Ye, S
   Liu, CC
   Li, ZW
   Al-Ahmari, A
AF Ye, Shuang
   Liu, Chuancai
   Li, Zhiwu
   Al-Ahmari, Abdulrahman
TI Iterative optimization for frame-by-frame object pose tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Frame-by-frame tracking; Pose estimation; Iterative
   optimization; Probabilistic voting
ID HEVC MOTION ESTIMATION; PARALLEL FRAMEWORK; HOUGH
AB Joint object tracking and pose estimation is an important issue in Augmented Reality (AR), interactive systems, and robotic systems. Many studies are based on object detection methods that only focus on the reliability of the features. Other methods combine object detection with frame-by-frame tracking using the temporal redundancy in the video. However, in some mixed methods, the interval between consecutive detection frames is usually too short to take the full advantage of the frame-by-frame tracking, or there is no appropriate switching mechanism between detection and tracking. In this paper, an iterative optimization tracking method is proposed to alleviate the deviations of the tracking points and prolong the interval, and thus speed up the pose estimation process. Moreover, an adaptive detection interval algorithm is developed, which can make the switch between detection and frame-by-frame tracking automatically according to the quality of frames so as to improve the accuracy in a tough tracking environment. Experimental results on the benchmark dataset manifest that the proposed algorithms, as an independent part, can be combined with some inter-frame tracking methods for optimization. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Ye, Shuang; Liu, Chuancai] Nanjing niv Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Ye, Shuang] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Li, Zhiwu] Macau Univ Sci & Technol, Inst Syst Engn, Taipa, Macau, Peoples R China.
   [Li, Zhiwu] Xidian Univ, Sch Elect Mech Engn, Xian 710071, Peoples R China.
   [Al-Ahmari, Abdulrahman] King Saud Univ, Adv Mfg Inst, Riyadh 11421, Saudi Arabia.
   [Al-Ahmari, Abdulrahman] King Saud Univ, Coll Engn, Dept Ind Engn, Riyadh, Saudi Arabia.
C3 Huaqiao University; Macau University of Science & Technology; Xidian
   University; King Saud University; King Saud University
RP Liu, CC (corresponding author), Nanjing niv Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM chcailiu@l63.com
RI Al-Ahmari, Abdulrahman/E-6000-2017; Li, Zhiwu/A-7884-2010
OI Al-Ahmari, Abdulrahman/0000-0002-3079-0141; Li,
   Zhiwu/0000-0003-1547-5503
CR Ali S, 2016, COMPUT VIS IMAGE UND, V145, P95, DOI 10.1016/j.cviu.2015.12.003
   Aly M., 2011, BAG WORDS LARGE SCAL
   [Anonymous], 2015, LEARNING MULTIDOMAIN
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], 2001, Pyramidal implementation of the affine lucas kanade feature tracker description of the algorithm5.1-10
   [Anonymous], 2008, Conference on Computer Vision and Pattern Recognition
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Black MJ, 1997, PROC CVPR IEEE, P561, DOI 10.1109/CVPR.1997.609381
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Chen HY, 2013, PROC CVPR IEEE, P2762, DOI 10.1109/CVPR.2013.356
   Chi Y. M., 2007, SPEECH SIGN PROC ICA, V1, P1
   Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701
   Dosovitskiy A., 2015, FLOWNET LEARNING OPT
   Duy-Nguyen Ta, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2937, DOI 10.1109/CVPRW.2009.5206831
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Ke Y., 2004, P 2004 IEEE COMP SOC, V2, pII
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makar M, 2013, INT J SEMANT COMPUT, V7, P5, DOI 10.1142/S1793351X13400011
   Makar M, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P50, DOI 10.1109/ISM.2012.18
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mooser J., 2007, P 2007 6 IEEE ACM IN, P1, DOI [10.1109/ISMAR.2007.4538839, DOI 10.1109/ISMAR.2007.4538839]
   Mooser J, 2008, INT S 3D DAT PROC VI
   Muller Thomas, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P236, DOI 10.1007/978-3-642-23123-0_24
   Pal M, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1138, DOI 10.1109/CCAA.2015.7148546
   Pauwels K, 2014, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2014.510
   Pauwels K, 2013, PROC CVPR IEEE, P2347, DOI 10.1109/CVPR.2013.304
   Rosenbaum Dan., 2013, Advances in Neural Information Processing Systems, P2373
   Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83
   Takacs G, 2010, PROC CVPR IEEE, P934, DOI 10.1109/CVPR.2010.5540116
   Tao R., 2016, SIAMESE INSTANCE SEA
   Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30
   Thachasongtham D, 2013, LECT NOTES COMPUT SC, V7944, P512
   Xiao F., 2016, COMP VIS PATT REC CV, V5, P9
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zach C, 2015, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.2015.7298615
   Zheng AM, 2015, IEEE IMAGE PROC, P4371, DOI 10.1109/ICIP.2015.7351632
NR 41
TC 3
Z9 3
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 72
EP 81
DI 10.1016/j.jvcir.2017.01.017
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600007
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, KK
AF Singh, Akansha
   Singh, Krishna Kant
TI Satellite image classification using Genetic Algorithm trained radial
   basis function neural network, application to the detection of flooded
   areas
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Radial basis function; Genetic Algorithm; Landsat 8; Classification;
   Change detection
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; MODEL
AB In this paper, a semi supervised method for classification of satellite images based on Genetic Algorithm (GA) and Radial Basis Function Neural Network (RBFNN) is proposed. Satellite image classification problem has two major concerns to be addressed. The first issue is mixed pixel problem and the second issue is handling large amount of data present in these images. RBFNN function is an efficient network with a large set of tunable parameters. This network is able to generalize the results and is immune to noise. A RBFNN has learning ability and can appropriately react to unseen data. This makes the network a good choice for satellite images. The efficiency of RBFNN is greatly influenced by the learning algorithm and seed point selection. Therefore, in this paper spectral indices are used for seed selection and GA is used to train the network. The proposed method is used to classify the Landsat 8 OLI images of Dongting Lake in South China. The application of this method is shown for detection of flooded area over this region. The performance of the proposed method was analyzed and compared with three existing methods and the error matrix was computed to test the performance of the method. The method yields high producer's accuracy, consumer's accuracy and kappa coefficient value which indicated that the proposed classifier is highly effective and efficient. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Singh, Akansha] NorthCap Univ, Gurgaon, India.
   [Singh, Krishna Kant] Dronacharya Coll Engn, Gurgaon, India.
C3 The Northcap University
RP Singh, A (corresponding author), NorthCap Univ, Gurgaon, India.
EM akanshasing@gmail.com
RI Singh, Akansha/W-4033-2019; Singh, Krishna Kant/V-3003-2019
OI Singh, Akansha/0000-0002-5520-8066; Singh, Krishna
   Kant/0000-0002-6510-6768
CR [Anonymous], P IEEE 2013 STUDENTS
   [Anonymous], 2008, ASSESSING ACCURACY R, DOI DOI 10.1201/9781420055139
   Bezdek James C., 1981, PATTERN RECOGN
   BILLINGS SA, 1995, NEURAL NETWORKS, V8, P877, DOI 10.1016/0893-6080(95)00029-Y
   Chang GW, 2010, IEEE T IND ELECTRON, V57, P2171, DOI 10.1109/TIE.2009.2034681
   Höppner F, 2003, INT J APPROX REASON, V32, P85, DOI 10.1016/S0888-613X(02)00078-6
   Hoque R, 2011, NAT HAZARDS, V57, P525, DOI 10.1007/s11069-010-9638-y
   Hu YX, 2015, REMOTE SENS-BASEL, V7, P7494, DOI 10.3390/rs70607494
   Ji ZX, 2016, J VIS COMMUN IMAGE R, V40, P611, DOI 10.1016/j.jvcir.2016.08.001
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Landgrebe D.A., 2003, Signal Theory Methods in Multispectral Remote Sensing, P508, DOI [10.1002/0471723800, DOI 10.1002/0471723800]
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Mehrotra A, 2015, NAT HAZARDS, V77, P367, DOI 10.1007/s11069-015-1595-z
   Mori N, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL049210
   Pradhan B, 2009, DISASTER ADV, V2, P7
   Singh A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P495
   Singh K. K., 2016, EGYPT J REMOTE SENS
   Singh KK, 2016, NAT HAZARDS, V83, P1027, DOI 10.1007/s11069-016-2361-6
   Singh KK, 2014, EUR J REMOTE SENS, V47, P461, DOI 10.5721/EuJRS20144726
   Singh KK, 2014, IETE TECH REV, V31, P75, DOI 10.1080/02564602.2014.891375
   Stancalie G., 2004, FLOOD RISK MANAGEMEN
   Wang C, 2008, INT J REMOTE SENS, V29, P6811, DOI 10.1080/01431160802270115
   WATSON JP, 1991, REMOTE SENS ENVIRON, V35, P1, DOI 10.1016/0034-4257(91)90061-A
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 25
TC 40
Z9 44
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 173
EP 182
DI 10.1016/j.jvcir.2016.11.017
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200014
DA 2024-07-18
ER

PT J
AU Ramasamy, K
   Mani, G
AF Ramasamy, Krishnamoorthy
   Mani, Ganesh
TI A simple computational framework for defect detection system with
   orthogonal polynomials transcoded coefficients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Block classification; Defect detection; Defect measurement matrix; Group
   distribution model; Orthogonal polynomials transcoded coefficients
ID SURFACE-DEFECTS; INSPECTION; IMAGES; IDENTIFICATION; DECOMPOSITION;
   RECOGNITION; SELECTION; FUSION
AB In this paper, a simple computational framework to propose a generic defect detection system based on orthogonal polynomials transcoded coefficients, with a statistical procedure is presented. Initially, the defective input image is partitioned into blocks and subjected to orthogonal polynomials transformation. The resulting coefficients are then applied with a modified lifting scheme, to produce transcoded coefficients with reduced block size. These coefficients are modeled as a probability distribution to propose a block classification scheme that classifies the block under investigation to have dominantly either texture or edge or smooth with total number of transcoded coefficients that are above the mean of the sample. With simple statistical procedure, we then introduce a new defect detection technique on each of these block classification result. The proposed defect detection technique employs homogeneity among variance of transcoded coefficients with Box's M Test, and group distribution model to verify the presence of defect in texture and edge block respectively. By analyzing the magnitude of transcoded coefficients, defective blocks in a smooth region are identified. The proposed defect detection system, an application independent, is experimented with natural images and few measures are introduced with a simple Defect Measurement Matrix (DMM) to analyze the performance of the proposed system. The applicability of the proposed scheme is also extended to identify defects in fabrics. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ramasamy, Krishnamoorthy; Mani, Ganesh] Anna Univ, Univ Coll Engn, Dept Comp Sci & Engn, BIT Campus, Tiruchirappalli, Tamil Nadu, India.
C3 Anna University; Anna University of Technology Tiruchirappalli
RP Ramasamy, K (corresponding author), Anna Univ, Univ Coll Engn, Dept Comp Sci & Engn, BIT Campus, Tiruchirappalli, Tamil Nadu, India.
EM rkrish07@yahoo.com; ganesh.mecse@gmail.com
RI Ramasamy, Krishnamoorthy/AAS-8240-2021
CR [Anonymous], 2008, ELCVIA Electron. Lett. Comput. Vis. Image Anal, DOI DOI 10.5565/REV/ELCVIA.268
   Anwar SA, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-15
   Asha V, 2011, COMM COM INF SC, V157, P548
   Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Bai XL, 2014, IEEE T IND INFORM, V10, P2135, DOI 10.1109/TII.2014.2359416
   Bennedsen BS, 2005, COMPUT ELECTRON AGR, V48, P92, DOI 10.1016/j.compag.2005.01.003
   Bi-hui Wang, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P269, DOI 10.1109/ICCASM.2010.5619388
   BOX GEP, 1949, BIOMETRIKA, V36, P317, DOI 10.2307/2332671
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Chao SM, 2008, IMAGE VISION COMPUT, V26, P187, DOI 10.1016/j.imavis.2007.03.003
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   Cho CS, 2005, IEEE T IND ELECTRON, V52, P1073, DOI 10.1109/TIE.2005.851648
   Choonjong Kwak, 2001, Intelligent Data Analysis, V5, P355
   DARWISH AM, 1988, IEEE T PATTERN ANAL, V10, P56, DOI 10.1109/34.3867
   Dhanasekar B, 2010, TRIBOL INT, V43, P268, DOI 10.1016/j.triboint.2009.05.030
   Eldessouki M, 2015, EXPERT SYST APPL, V42, P2098, DOI 10.1016/j.eswa.2014.10.013
   Fu Z, 2004, 2004 INTERNATIONAL CONFERENCE ON THE BUSINESS OF ELECTRONIC PRODUCT RELIABILITY AND LIABILITY, PROCEEDINGS, P77, DOI 10.1109/BEPRL.2004.1308153
   Fuyuki T, 2009, APPL PHYS A-MATER, V96, P189, DOI 10.1007/s00339-008-4986-0
   Gai S, 2016, NEUROCOMPUTING, V196, P133, DOI 10.1016/j.neucom.2015.12.112
   Ghazvini M., 2009, WORLD ACAD SCI ENG T, V37, P901, DOI [10.5281/zenodo.1328348,901-904, DOI 10.5281/ZENODO.1328348]
   Ghorai S, 2013, IEEE T INSTRUM MEAS, V62, P612, DOI 10.1109/TIM.2012.2218677
   Groth Samuel R., 2013, INT J DIG APPL CONT, V1, P65
   He ZY, 2015, APPL OPTICS, V54, P9823, DOI 10.1364/AO.54.009823
   Hong-Dar Lin, 2008, WSEAS Transactions on Computers Research, V3, P193
   Jian QP, 2015, INSIGHT, V57, P85, DOI 10.1784/insi.2014.57.2.85
   Karimi MH, 2014, ISA T, V53, P834, DOI 10.1016/j.isatra.2013.11.015
   Kim WS, 2004, KEY ENG MATER, V270-273, P808, DOI 10.4028/www.scientific.net/KEM.270-273.808
   Ko J, 2016, INT J ADV MANUF TECH, V82, P1753, DOI 10.1007/s00170-015-7498-z
   Krishnamoorthi R, 2007, PATTERN RECOGN LETT, V28, P771, DOI 10.1016/j.patrec.2006.10.009
   Krishnamoorthi R, 2012, J VIS COMMUN IMAGE R, V23, P18, DOI 10.1016/j.jvcir.2011.07.011
   Krishnamoorthi R., 2009, INT J SIGNAL PROCESS, V5, P67
   Kumar A., 2005, IEEE T IND ELECTRON, V55, P348
   Landgrebe TCW, 2008, IEEE T PATTERN ANAL, V30, P810, DOI 10.1109/TPAMI.2007.70740
   Lee Y, 2014, IEEE T SEMICONDUCT M, V27, P223, DOI 10.1109/TSM.2014.2303473
   Li PF, 2015, J TEXT I, V106, P587, DOI 10.1080/00405000.2014.929790
   Li WC, 2011, IEEE T IND INFORM, V7, P136, DOI 10.1109/TII.2009.2034844
   Louban R, 2009, SPRINGER SER MATER S, V123, P9
   Ma MD, 2010, IEEE T IND INFORM, V6, P18, DOI 10.1109/TII.2009.2030793
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mandriota C, 2004, MACH VISION APPL, V15, P179, DOI 10.1007/s00138-004-0148-3
   Moshou D, 2004, COMPUT ELECTRON AGR, V44, P173, DOI 10.1016/j.compag.2004.04.003
   Ng HF, 2006, PATTERN RECOGN LETT, V27, P1644, DOI 10.1016/j.patrec.2006.03.009
   Ordaz MA, 2000, P SOC PHOTO-OPT INS, V3966, P238, DOI 10.1117/12.380078
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petcher PA, 2015, NDT&E INT, V74, P58, DOI 10.1016/j.ndteint.2015.05.005
   Ping Jiang, 2011, International Journal of Advanced Pervasive and Ubiquitous Computing, V3, P24, DOI 10.4018/japuc.2011070103
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   Ravanidi SAH, 2011, J TEXT I, V102, P315, DOI 10.1080/00405001003737540
   Ren JC, 2007, SIGNAL PROCESS, V87, P541, DOI 10.1016/j.sigpro.2006.06.013
   Seiler D., 2010, PHOTONIC SPECTRA, V44, P238
   Serdaroglu A., 2006, Pattern Recognition and Image Analysis, V16, P61, DOI 10.1134/S1054661806010196
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Su Z., 2007, J INFORM COMPUT SCI, V3, P527
   Tabassian M, 2011, EXPERT SYST APPL, V38, P5259, DOI 10.1016/j.eswa.2010.10.032
   TAKEDA F, 1995, IEEE T NEURAL NETWOR, V6, P73, DOI 10.1109/72.363448
   Tang B., 2016, J MANUF SCI E-T ASME, V138, P1
   Tolba AS, 2010, TEXT RES J, V80, P2094, DOI 10.1177/0040517510371861
   Trumpy G, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2597894
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2525, DOI 10.1016/S0167-8655(03)00098-9
   Tsai DM, 2011, IEEE T IND INFORM, V7, P125, DOI 10.1109/TII.2010.2092783
   TSAI IS, 1995, TEXT RES J, V65, P123, DOI 10.1177/004051759506500301
   Tsang CSC, 2016, PATTERN RECOGN, V51, P378, DOI 10.1016/j.patcog.2015.09.022
   Tsneg YH, 2010, PATTERN RECOGN, V43, P1129, DOI 10.1016/j.patcog.2009.09.006
   Wang DQ, 2015, LECT NOTES COMPUT SC, V9377, P248, DOI 10.1007/978-3-319-25393-0_28
   Wang XS, 2010, LECT NOTES COMPUT SC, V6315, P478, DOI 10.1007/978-3-642-15555-0_35
   Xie YH, 2015, OPTIK, V126, P2231, DOI 10.1016/j.ijleo.2015.05.101
   Xiong CY, 2007, IEEE T IMAGE PROCESS, V16, P607, DOI 10.1109/TIP.2007.891069
   Yang M. D., 2001, INT J WAVELETS MULTI, V9, P211
   Yarmchuk EJ, 2005, IBM J RES DEV, V49, P677, DOI 10.1147/rd.494.0677
   Yeh C.H., 2010, IEEE T SEMICONDUCTOR, V23, P154
   Zahran O, 2013, NDT&E INT, V57, P26, DOI 10.1016/j.ndteint.2012.11.005
   Zavorin I, 2005, IEEE T IMAGE PROCESS, V14, P770, DOI 10.1109/TIP.2005.847287
   Zhai M, 2010, SIGNAL PROCESS, V90, P2319, DOI 10.1016/j.sigpro.2010.02.012
   Zhang XW, 2011, EXPERT SYST APPL, V38, P5930, DOI 10.1016/j.eswa.2010.11.030
   Zhang YZ, 2015, J FORESTRY RES, V26, P745, DOI 10.1007/s11676-015-0066-4
NR 77
TC 1
Z9 1
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 31
EP 46
DI 10.1016/j.jvcir.2016.09.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000004
DA 2024-07-18
ER

PT J
AU Kamal, AHM
   Islam, MM
AF Kamal, A. H. M.
   Islam, Mohammad Mahfuzul
TI Boosting up the data hiding rate through multi cycle embedment process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Multi-layer embedding; Multi-cycle embedding; Reversible
   data hiding; Prediction error histogram; Steganography
ID HISTOGRAM-MODIFICATION; IMAGE STEGANOGRAPHY; PREDICTION; SCHEME;
   WATERMARKING; ALGORITHM; MECHANISM; CAPACITY
AB Prediction error based multi-layer data embedment schemes conceal secrets into several high frequency errors by modifying their prediction error histogram (PEH). It is investigated that k-times data embedment into n/k errors of PEH produces higher embedding payload, while maintaining better stego-image quality compared to those for embedding into n distinct errors for a single time only. This paper proposes a novel multi-cycle embedment scheme in which data is embedded into the errors of a defined range in each of its k cycles. Experiments were conducted to examine the performance of the proposed scheme comparing the multi-layer vs. multi-cycle embedding schemes individually and jointly. The scheme explores the points at which significantly better payloads can be obtained at the lower image distortions. Substantial improved performance were obtained during investigations, especially while large volume data embedment. The proposed scheme can embed massive and hybrid data of type text, numeric, image and audio. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kamal, A. H. M.] Jatiya Kabi Kazi Nazrul Islam Univ, Dept Comp Sci & Engn, Trishal, Bangladesh.
   [Kamal, A. H. M.; Islam, Mohammad Mahfuzul] Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 Bangladesh University of Engineering & Technology (BUET)
RP Kamal, AHM (corresponding author), Jatiya Kabi Kazi Nazrul Islam Univ, Dept Comp Sci & Engn, Trishal, Bangladesh.
EM kamal@jkkniu.edu.bd; mahfuz@cse.buet.ac.bd
RI KAMAL, A H M/Q-9923-2016
OI KAMAL, A H M/0000-0001-8031-666X
FU Ministry of Post, Telecommunication and Information Technology of the
   Government of Bangladesh through Information and Communication
   Technology Fellowship program
FX The research work is done by the support of Ministry of Post,
   Telecommunication and Information Technology of the Government of
   Bangladesh through the Information and Communication Technology
   Fellowship program. Hence, the authors are happy to acknowledge that
   remarkable support.
CR Abduallah WM, 2014, COMPUT ELECTR ENG, V40, P1390, DOI 10.1016/j.compeleceng.2014.02.007
   Andriotis P, 2013, DIGIT INVEST, V9, P246, DOI 10.1016/j.diin.2013.01.005
   Chan HT, 2015, J DISP TECHNOL, V11, P193, DOI 10.1109/JDT.2014.2367528
   Chung KL, 2012, APPL MATH COMPUT, V218, P5819, DOI 10.1016/j.amc.2011.10.056
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu D., 2007, ELECT IMAGING 2007
   Fu DS, 2014, AEU-INT J ELECTRON C, V68, P933, DOI 10.1016/j.aeue.2014.04.015
   Govind PVS, 2015, PROCEDIA COMPUT SCI, V46, P491, DOI 10.1016/j.procs.2015.02.073
   Gujjunoori S, 2013, J INF SECUR APPL, V18, P157, DOI 10.1016/j.istr.2013.01.002
   Hong W, 2012, J SYST SOFTWARE, V85, P1166, DOI 10.1016/j.jss.2011.12.045
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong WE, 2010, J SYST SOFTWARE, V83, P2653, DOI 10.1016/j.jss.2010.08.047
   Islam S, 2014, NEUROCOMPUTING, V137, P136, DOI 10.1016/j.neucom.2013.03.072
   Kamal AHM, 2014, HEALTHC TECHNOL LETT, V1, P74, DOI 10.1049/htl.2013.0026
   Kamal A.H.M., 2015, P IEEE INT C ADV NET, P7
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Leung HY, 2013, J SYST SOFTWARE, V86, P2204, DOI 10.1016/j.jss.2013.04.020
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ong SY, 2014, SIGNAL PROCESS-IMAGE, V29, P135, DOI 10.1016/j.image.2013.09.001
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Wang WJ, 2011, IEEE SYST J, V5, P528, DOI 10.1109/JSYST.2011.2165603
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yang WJ, 2013, J SYST SOFTWARE, V86, P567, DOI 10.1016/j.jss.2012.09.041
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 33
TC 5
Z9 5
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 574
EP 588
DI 10.1016/j.jvcir.2016.07.023
PN B
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600015
DA 2024-07-18
ER

PT J
AU Liu, TT
   Chen, ZZ
   Liu, SY
   Zhang, ZL
   Shu, JB
AF Liu, Tingting
   Chen, Zengzhao
   Liu, Sanyan
   Zhang, Zhaoli
   Shu, Jiangbo
TI Blind image restoration with sparse priori regularization for passive
   millimeter-wave images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Millimeter wave imaging; Blind image restoration; Sparse priori;
   Regularization; Image processing
ID CONCEALED-OBJECT DETECTION; HIGHLY PARALLEL FRAMEWORK; HEVC MOTION
   ESTIMATION; SPECTRAL DECONVOLUTION; REGISTRATION; ALGORITHM; MODEL
AB Passive millimeter wave imaging often suffers from issues such as low resolution, noise, and blurring. In this study, a blind image restoration method for the passive millimeter-wave images (PMMW) is proposed. The purpose of the proposed method is to simultaneously solve the point spread function (PSF) and restoration image. In this method, the data fidelity item is constructed based on Gaussian noise assuming, and the regularization item is constructed as the hyper-Laplace function parallel to x parallel to(0.6), which is fitted according to the high-resolution PMMW images. Moreover, a data-selected matrix is proposed to select the regions that are helpful for estimating the accurate PSF. The proposed method has been applied to simulated and real PMMW image experiments. Comparative results demonstrate that the proposed method significantly outperforms the state-of-the-art deblurring methods on both qualitative and quantitative assessments. The proposed method improves the resolution of the PMMW image and makes it more preferable for object recognition. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Tingting; Chen, Zengzhao; Liu, Sanyan; Zhang, Zhaoli; Shu, Jiangbo] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan 430079, Peoples R China.
C3 Central China Normal University
RP Liu, SY; Shu, JB (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan 430079, Peoples R China.
EM lsy5918@mail.ccnu.edu.cn; hailiu0204@gmail.com
RI liu, ting/GZM-3326-2022; Zhang, Zhaoli/IWD-8445-2023
OI Zhang, Zhaoli/0000-0002-0844-0719
FU National Natural Science Foundation of China [61505064]; National Social
   Science Fund of China [14BGL131]; Project of the Program for National
   Key Technology Research and Development Program [2013BAH18F01,
   2014BAH22F01, 2015BAK07B03, 2013BAH72B01, 2013BAH18F02, 2015BAH33F02];
   Self-Determined Research Funds of CCNU from the Colleges' Basic Research
   and Operation of MOE [CCNU15A05009]
FX The authors thank the editor and anonymous reviewers for their valuable
   suggestions. This research was partially funded by the National Natural
   Science Foundation of China under Grant (No. 61505064), the National
   Social Science Fund of China (14BGL131), the Project of the Program for
   National Key Technology Research and Development Program (2013BAH18F01,
   2014BAH22F01, 2015BAK07B03), the Self-Determined Research Funds of CCNU
   from the Colleges' Basic Research and Operation of MOE (CCNU15A05009),
   and the Project of the Program for National Key Technology Research and
   Development Program (2013BAH72B01, 2013BAH18F02, 2015BAH33F02). The
   authors would like to thank Dr. Peter R Coward for providing the real
   experiment data of PMMW image.
CR Alexander NE, 2005, J MOD OPTIC, V52, P1893, DOI 10.1080/09500340500141854
   BERTERO M, 1981, OPT ACTA, V28, P1635, DOI 10.1080/713820513
   BORDEN B, 1992, IEEE T SIGNAL PROCES, V40, P969, DOI 10.1109/78.127968
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Deng YS, 2015, INFORM SCIENCES, V305, P146, DOI 10.1016/j.ins.2015.01.028
   Fang HZ, 2014, OPTIK, V125, P1454, DOI 10.1016/j.ijleo.2013.09.010
   FISH DA, 1995, J OPT SOC AM A, V12, P58, DOI 10.1364/JOSAA.12.000058
   Haiying Tian, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3357, DOI 10.1109/ICIP.2011.6116392
   HELSTROM CW, 1967, J OPT SOC AM, V57, P297, DOI 10.1364/JOSA.57.000297
   Hong H., 2012, OPT ENG, V51
   Hyoung Lee, 2011, 2011 Proceedings of the 3rd International Conference on Data Mining and Intelligent Information Technology Applications (ICMIA 2011), P98
   Lee DS, 2010, OPT EXPRESS, V18, P10659, DOI 10.1364/OE.18.010659
   Lettington AH, 2001, OPT ENG, V40, P268, DOI 10.1117/1.1339875
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Liao HY, 2011, IEEE T IMAGE PROCESS, V20, P670, DOI 10.1109/TIP.2010.2073474
   Liu H, 2016, APPL OPTICS, V55, P2813, DOI 10.1364/AO.55.002813
   Liu H, 2015, MEAS SCI TECHNOL, V26, DOI 10.1088/0957-0233/26/8/085502
   Liu H, 2015, INFRARED PHYS TECHN, V71, P481, DOI 10.1016/j.infrared.2015.06.008
   Liu H, 2014, PHOTONICS RES, V2, P168, DOI 10.1364/PRJ.2.000168
   Liu H, 2015, APPL OPTICS, V54, P1770, DOI 10.1364/AO.54.001770
   Liu H, 2014, APPL OPTICS, V53, P8240, DOI 10.1364/AO.53.008240
   Liu H, 2013, IEEE T INSTRUM MEAS, V62, P315, DOI 10.1109/TIM.2012.2217636
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Pan MC, 2010, INT J IMAG SYST TECH, V20, P308, DOI 10.1002/ima.20254
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xia WZ, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.12.123107
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yeom S, 2012, OPT EXPRESS, V20, DOI 10.1364/OE.20.009371
   Young SS, 2007, APPL OPTICS, V46, P744, DOI 10.1364/AO.46.000744
   Yuasa K., 1996, Proceedings IWISPO '96. Third International Workshop on Image and Signal Processing on the Theme of Advances in Computational Intelligence, P321, DOI 10.1016/B978-044482587-2/50071-9
   Yujiri L, 2003, IEEE MICROW MAG, V4, P39, DOI 10.1109/MMW.2003.1237476
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 37
TC 29
Z9 31
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 58
EP 66
DI 10.1016/j.jvcir.2016.06.007
PN A
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500007
DA 2024-07-18
ER

PT J
AU Ruan, Y
   Wei, ZZ
AF Ruan, Yang
   Wei, Zhenzhong
TI Discriminative descriptors for object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Correlation filter; Color descriptors; Computer vision;
   Scale variation; Target representation; Model-free tracking; Real-time
   processing
ID VISUAL TRACKING
AB Object tracking is one of the most challenging problems in computer vision. Only Fast trackers can satisfy the real-time requirements and can be used in many artificial intelligence applications. Due to the impressive high-speed, correlation filters have received much attention within the field of object tracking. Recently, trackers using luminance information or color names for image description have been performed in a correlation filters framework. In this paper, we propose the usage of discriminative color descriptors to improve the tracking performance of the traditional correlation filters tracker. Discriminative color descriptors are compact and efficient. Moreover, our tracker incorporates scale estimation into the traditional correlation filters, which results in increased tracking performance. Extensive experiments demonstrate that the proposed tracker can obtain superior results compared to existing trackers using correlation filters and it is also able to outperform state-of-the-art trackers on the CVPR2013 object tracking benchmark. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ruan, Yang; Wei, Zhenzhong] Beihang Univ, Key Lab Precis Optomechatron Technol, Minist Educ, XueYuan Rd 37, Beijing 100083, Peoples R China.
C3 Beihang University
RP Wei, ZZ (corresponding author), Beihang Univ, Key Lab Precis Optomechatron Technol, Minist Educ, XueYuan Rd 37, Beijing 100083, Peoples R China.
RI ruan, yang/HTM-5751-2023
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Boddeti V. N., 2013, P IEEE C COMP VIS PA, P23
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mojsilovic A, 2005, IEEE T IMAGE PROCESS, V14, P690, DOI 10.1109/TIP.2004.841201
   Oron S, 2014, LECT NOTES COMPUT SC, V8693, P142, DOI 10.1007/978-3-319-10602-1_10
   Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 29
TC 12
Z9 13
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 146
EP 154
DI 10.1016/j.jvcir.2015.12.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600013
DA 2024-07-18
ER

PT J
AU Turkmen, I
AF Turkmen, Ilke
TI The ANN based detector to remove random-valued impulse noise in images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Noise detector; Random-valued impulse noise; Artificial
   neural networks; Noise detection; Noise removal; Neural noise detector;
   Edge-preserving regularization
ID SWITCHING MEDIAN FILTER; DIGITAL IMAGES; EFFICIENT REMOVAL; REDUCTION;
   RESTORATION
AB This paper presents an artificial neural network (ANN) based method to detect random-valued impulse noise (RVIN) in images. The proposed method employs the ANN to decide whether a pixel is corrupted or not with RVIN. The inputs of the ANN are the rank ordered absolute differences (ROAD) and the rank-ordered logarithmic difference (ROLD) values. After the detection process is completed, the corrupted pixels are restored by the edge-preserving regularization (EPR) method which allows edges and noise-free pixels to be preserved. The performance of the proposed method is evaluated on different test images and compared with ten different comparison filters from the literature. Simulation results indicate that the proposed method provides significant improvement over comparison filters especially for high noise densities. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Turkmen, Ilke] Erciyes Univ, Dept Aircraft Elect & Elect, Fac Aeronaut & Astronaut, TR-38039 Kayseri, Turkey.
C3 Erciyes University
RP Turkmen, I (corresponding author), Erciyes Univ, Dept Aircraft Elect & Elect, Fac Aeronaut & Astronaut, TR-38039 Kayseri, Turkey.
EM titi@erciyes.edu.tr
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   [Anonymous], P INT C COMP GRAPH V
   [Anonymous], P IEEE INT C NEUR NE
   Apalkov I.V., 2005, P EUROCON, P22
   Besdok E, 2005, AEU-INT J ELECTRON C, V59, P105, DOI 10.1016/j.aeue.2004.11.002
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Chen T, 2001, IEEE T CIRCUITS-II, V48, P784, DOI 10.1109/82.959870
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Gao GR, 2015, J VIS COMMUN IMAGE R, V32, P83, DOI 10.1016/j.jvcir.2015.07.014
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gupta V, 2015, J VIS COMMUN IMAGE R, V26, P296, DOI 10.1016/j.jvcir.2014.10.004
   HARDIE RC, 1993, IEEE T SIGNAL PROCES, V41, P1061, DOI 10.1109/78.205713
   Haykin S., 1994, NEURAL NETWORKS COMP
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Ibrahim H, 2008, IEEE T CONSUM ELECTR, V54, P1920, DOI 10.1109/TCE.2008.4711254
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Kaliraj G, 2010, IMAGE VISION COMPUT, V28, P458, DOI 10.1016/j.imavis.2009.07.007
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   KONG H, 1998, IEEE T CIRC SYST 1, V45
   Lee C.-S., 2000, Fuzzy Techniques in Image Processing, P172
   Luo WB, 2006, IEEE T CONSUM ELECTR, V52, P523, DOI 10.1109/TCE.2006.1649674
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   NODES TA, 1984, IEEE T COMMUN, V32, P532, DOI 10.1109/TCOM.1984.1096099
   Paul M.E., 1991, C LANGUAGE ALGORITHM
   Russo F, 1996, IEEE SIGNAL PROC LET, V3, P168, DOI 10.1109/97.503279
   Sa PK, 2010, AEU-INT J ELECTRON C, V64, P322, DOI 10.1016/j.aeue.2009.01.005
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Toh KKV, 2010, IEEE T CONSUM ELECTR, V56, P2560, DOI 10.1109/TCE.2010.5681141
   Toh KKV, 2008, IEEE T CONSUM ELECTR, V54, P1956, DOI 10.1109/TCE.2008.4711258
   Turkmen I, 2011, AEU-INT J ELECTRON C, V65, P132, DOI 10.1016/j.aeue.2010.02.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P2428, DOI 10.1109/TIP.2011.2131664
   Yildirim MT, 2008, IEEE T FUZZY SYST, V16, P920, DOI 10.1109/TFUZZ.2008.924358
   Yu HC, 2008, IEEE SIGNAL PROC LET, V15, P922, DOI 10.1109/LSP.2008.2005051
   Yüksel ME, 2006, AEU-INT J ELECTRON C, V60, P628, DOI 10.1016/j.aeue.2005.12.005
   Yüksel ME, 2003, AEU-INT J ELECTRON C, V57, P214, DOI 10.1078/1434-8411-54100164
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
   Zhang JJ, 2010, DIGIT SIGNAL PROCESS, V20, P1010, DOI 10.1016/j.dsp.2009.11.003
   Zhang XF, 2013, IEEE T IMAGE PROCESS, V22, P4613, DOI 10.1109/TIP.2013.2274386
NR 49
TC 38
Z9 47
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 28
EP 36
DI 10.1016/j.jvcir.2015.10.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400003
DA 2024-07-18
ER

PT J
AU Zou, BJ
   Liu, Q
   Chen, ZL
   Fu, HP
   Zhu, CZ
AF Zou, Beiji
   Liu, Qing
   Chen, Zailiang
   Fu, Hongpu
   Zhu, Chengzhang
TI Surroundedness based multiscale saliency detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Figure-ground segregation; The Gestalt principles;
   Image decomposition; Homogeneous region extraction; Surroundedness;
   Multiscale; Contour confidence
ID VISUAL-ATTENTION; REGION DETECTION; OBJECT DETECTION; IMAGE; MODEL;
   FIGURE; MAP
AB In this paper, a surroundedness-based multiscale saliency method is proposed based on the Gestalt principles for figure-ground segregation, which states that (1) surrounded regions are more likely to be perceived as figures, (2) the humans understand the external stimuli as whole rather than the sum of their parts. First, an image is characterized by a set of binary images, which is generated by a simple and effective homogeneous region extraction method with well contour preservation. And the contour confidence map is obtained by a fast contour detection method. Then for each connect homogeneous region in a binary map, surroundedness is defined by the average outer contour confidence. Finally, integrating the background priors, multiscale saliency maps are generated and combined to the final saliency map. The proposed method is evaluated on two widely used public datasets with pixel accurate salient region annotations using both precision and recall analysis and ROC analysis. And the experimental results show that the proposed method outperforms 14 alternative methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zou, Beiji; Liu, Qing; Chen, Zailiang; Fu, Hongpu; Zhu, Chengzhang] Cent South Univ, Sch Informat Sci & Engn, Minist Educ, China Mobile Joint Lab Mobile Hlth, Beijing, Peoples R China.
RP Chen, ZL (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Minist Educ, China Mobile Joint Lab Mobile Hlth, Beijing, Peoples R China.
EM qing.liu.411@gmail.com; zailiangchencs@gmail.com
OI Liu, Qing/0000-0002-5797-8179
FU National Natural Science Foundation of China [61173122, 61262032,
   61440055]; Fundamental Research Funds for the Central Universities of
   Central South University [2013zzts046]
FX We would like to thank the anonymous reviewers for their comments. This
   research was supported in part by the National Natural Science
   Foundation of China under Grant No. 61173122, No. 61262032 and No.
   61440055 and the Fundamental Research Funds for the Central Universities
   of Central South University under Grant No. 2013zzts046.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2006, P CVPR
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huo L., 2015, PATTERN RECOGN
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu Y, 2012, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2012.6247785
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   MUMFORD D, 1987, P NATL ACAD SCI USA, V84, P7354, DOI 10.1073/pnas.84.20.7354
   Palmer S., 1999, VISION SCI PHOTONS P
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Poort J, 2012, NEURON, V75, P143, DOI 10.1016/j.neuron.2012.04.032
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhao QY, 2014, COMM COM INF SC, V483, P455
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou B., 2015, MULTIMEDIA SYST, P1
NR 50
TC 8
Z9 8
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 378
EP 388
DI 10.1016/j.jvcir.2015.09.017
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700034
DA 2024-07-18
ER

PT J
AU Fareed, MMS
   Ahmed, G
   Chun, Q
AF Fareed, Mian Muhammad Sadiq
   Ahmed, Gulnaz
   Chun, Qi
TI Salient region detection through sparse reconstruction and graph-based
   ranking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-pixels; Sparse saliency; Separation saliency; Graph-based ranking;
   Bayesian integration; Location prior; PR curve; F-measure
ID VISUAL-ATTENTION; RANDOM-WALKS; IMAGE; VIDEO; MODEL
AB In this paper, we propose a salient region detection algorithm from the point of view of unique and compact representation of individual image. In first step, the original image is segmented into super-pixels. In second step, the sparse representation measure and uniqueness of the features are computed. Then both are ranked on the basis of the background and foreground seeds respectively. Thirdly, a location prior map is used to enhance the foci of attention. We apply the Bayes procedure to integrate computed results to produce smooth and precise saliency map. We compare our proposed algorithm against the state-of-the-art saliency detection methods using four of the largest widely available standard databases, experimental results specify that the proposed algorithm outperforms. We also show that how the saliency map of the proposed method is used to discover outline of object, furthermore using this outline our method produce the saliency cut of the desired object. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Fareed, Mian Muhammad Sadiq; Ahmed, Gulnaz; Chun, Qi] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Chun, Q (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qichun@mail.xjtu.edu.cn
RI Fareed, Mian Muhammad Sadiq/AAE-9299-2020
FU National Natural Science Foundation of China [60972124]; National
   High-tech Research and Development Program of China [2009AA01Z321];
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China [20110201110012]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 60972124), in part by the National
   High-tech Research and Development Program of China (Grant No.
   2009AA01Z321) and in part by the Specialized Research Fund for the
   Doctoral Program of Higher Education of China (Grant No.
   20110201110012).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], VISUAL SALIENCY ATTE
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chiang HF, 2015, J VIS COMMUN IMAGE R, V30, P252, DOI 10.1016/j.jvcir.2015.04.012
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Gao D., 2007, IEEE 11 INT C COMP V, P16
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Gopalakrishnan V, 2009, PROC CVPR IEEE, P1698, DOI 10.1109/CVPRW.2009.5206767
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Guttmann M, 2011, COMPUT VIS IMAGE UND, V115, P1662, DOI 10.1016/j.cviu.2011.05.010
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Li Jian, 2013, IEEE T PATTERN ANAL, V35
   Li X, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060338
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qian XL, 2013, PATTERN RECOGN LETT, V34, P1270, DOI 10.1016/j.patrec.2013.04.009
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren Z., 2010, Proceedings of the 18th ACM international conference on Multimedia, P1099
   Rutishauser U., 2004, PROCEEDINGS OF THE 2, P1137
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Setlur V, 2007, IEEE COMPUT GRAPH, V27, P80, DOI 10.1109/MCG.2007.133
   Sun J, 2012, IEEE IMAGE PROC, P1085, DOI 10.1109/ICIP.2012.6467052
   Sun XS, 2013, J VIS COMMUN IMAGE R, V24, P171, DOI 10.1016/j.jvcir.2012.01.014
   Sun XS, 2010, IEEE IMAGE PROC, P1101, DOI 10.1109/ICIP.2010.5653713
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   Tian YH, 2015, INT J COMPUT VISION, V111, P153, DOI 10.1007/s11263-014-0737-1
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 62
TC 16
Z9 17
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 144
EP 155
DI 10.1016/j.jvcir.2015.08.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300012
DA 2024-07-18
ER

PT J
AU Chen, HS
   Wang, CY
   Song, Y
   Li, ZH
AF Chen, Huasong
   Wang, Chunyong
   Song, Yang
   Li, Zhenhua
TI Split Bregmanized anisotropic total variation model for image deblurring
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anisotropic; Total variation; Split Bregman iteration; Image deblurring;
   Texture protection; Edge enhancement; Stair-casing effect; Image
   restoration
ID TOTAL VARIATION MINIMIZATION; DECOMPOSITION; RESTORATION
AB In this paper, an effective image deblurring model is proposed to preserve sharp image edges by suppressing the stair-casing arising in the total variation (TV) based method by using the anisotropic total variation. To solve the difficult L1 norm problems, the split Bregman iteration is employed. Several synthetic degraded images are used for experiments. Comparison results are also made with total variation and nonlocal total variation based method. Experimental results show that the proposed method not only is robust to noise and different blur kernels, but also performs well on blurring images with more detailed textures, and the stair-casing effect is well suppressed. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Huasong; Wang, Chunyong; Song, Yang; Li, Zhenhua] Nanjing Univ Sci & Technol, Dept Informat Phys & Engn, Nanjing 210091, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Chen, HS (corresponding author), Nanjing Univ Sci & Technol, Dept Informat Phys & Engn, Nanjing 210091, Jiangsu, Peoples R China.
EM sheagullli20@163.com; wangcyong@mail.njust.edu.cn
RI Chen, Huasong/ABF-1382-2021; Song, Yang/N-9290-2018
FU National Natural Science Fund of China [61371167]
FX The authors would like to thank Associate Professor J.C. Lai due to his
   assistance with language help and Associate Professor Q.H. Wang due to
   his help on the experiments. This work is supported by the National
   Natural Science Fund of China (No. 61371167).
CR [Anonymous], 1977, SOLUTION ILL POSED P
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Cai JF, 2009, MATH COMPUT, V78, P2127, DOI 10.1090/S0025-5718-09-02242-X
   Cai JF, 2009, MATH COMPUT, V78, P1515, DOI 10.1090/S0025-5718-08-02189-3
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan RH, 2008, SIAM J IMAGING SCI, V1, P273, DOI 10.1137/070711499
   Choksi R, 2011, INVERSE PROBL IMAG, V5, P591, DOI 10.3934/ipi.2011.5.591
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Denis L, 2009, IEEE T IMAGE PROCESS, V18, P1588, DOI 10.1109/TIP.2009.2019302
   Dobson DC, 1996, SIAM J APPL MATH, V56, P1181, DOI 10.1137/S003613999427560X
   Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045
   Foi A., 2004, P 6 IMA INT C MATH S, V5685, P79
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Grasmair M, 2010, APPL MATH OPT, V62, P323, DOI 10.1007/s00245-010-9105-x
   Katkovnik Vladimir, 2005, P EL IM IM PROC ALG, P5672
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Moll JS, 2005, MATH ANN, V332, P177, DOI 10.1007/s00208-004-0624-0
   Nikolova M, 2000, SIAM J APPL MATH, V61, P633, DOI 10.1137/S0036139997327794
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ring W, 2000, ESAIM-MATH MODEL NUM, V34, P799, DOI 10.1051/m2an:2000104
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2008, NUMER ALGORITHMS, V48, P49, DOI 10.1007/s11075-008-9182-y
   Shi Y, 2013, J APPL MATH, DOI 10.1155/2013/431794
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Usher S, 2005, SIAM MULTISCALE MODE, V4, P460, DOI DOI 10.1137/040605412
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wang Y., 2007, 0710 CAAM RIC U
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
NR 36
TC 43
Z9 48
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 282
EP 293
DI 10.1016/j.jvcir.2015.07.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600025
DA 2024-07-18
ER

PT J
AU Jun, D
   Yap-Peng, T
AF Jun, Deng
   Yap-Peng, Tan
TI Motion-compensated orthonormal expansion
   <i>l</i><sub>1</sub>-minimization for reference-driven MRI
   reconstruction using Augmented Lagrangian methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed Sensing; Reference-driven MRI reconstruction; Motion
   estimation; Motion compensation; Convex optimization; l1 minimization;
   Cardiac MRI; Augmented Lagrangian multiplier; Alternating direction
   minimization
ID IMAGE-RECONSTRUCTION; VIDEO COMPRESSION; DYNAMIC MRI; ALGORITHMS;
   FRAMEWORK; FOCUSS
AB Compressed Sensing theory has been found with successful reconstructions of MR images from incomplete measurements by prompting sparsity in MR images. Research works have shown even better reconstructions by taking advantage of prior information from a reference image which has anatomical similarity with the target image.
   In this work, a novel method for motion-compensated reference-driven MR image reconstruction is presented. The target image is directly reconstructed by solving a convex minimization problem which prompts l(1)-norm sparsity of the target and the motion-compensated difference images. An efficient algorithm is proposed to solve the minimization problem with joint application of Augmented Lagrangian method and alternating direction minimization method. Numerical experiments demonstrate that the proposed framework provides more accurate reconstructions especially in high under-sampling ratios when comparing with commonly used and state-of-the-art methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jun, Deng; Yap-Peng, Tan] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Jun, D (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM de0001un@e.ntu.edu.sg; eyptan@ntu.edu.sg
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   [Anonymous], WAVELAB 850 SOFTWARE
   Asif M., MAGNET RESON MED
   Babacan SD, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P314, DOI 10.1109/ISBI.2012.6235547
   BERTSEKAS DP, 1976, AUTOMATICA, V12, P133, DOI 10.1016/0005-1098(76)90077-7
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chen C, 2014, LECT NOTES COMPUT SC, V8673, P138, DOI 10.1007/978-3-319-10404-1_18
   Chen C, 2013, LECT NOTES COMPUT SC, V8151, P106, DOI 10.1007/978-3-642-40760-4_14
   Deng J., 2013, 20 IEEE INT IN PRESS
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du H., MAGNET RESON IMAG
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   GORODNITSKY IF, 1995, ELECTROEN CLIN NEURO, V95, P231, DOI 10.1016/0013-4694(95)00107-A
   Hale E.T., TR0707 CAAM RIC U
   Hedley M., 1992, Journal of Visual Communication and Image Representation, V3, P325, DOI 10.1016/1047-3203(92)90036-S
   Huang JZ, 2011, MED IMAGE ANAL, V15, P670, DOI 10.1016/j.media.2011.06.001
   Ji J, 2008, I S BIOMED IMAGING, P1613
   Jun Deng, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2297, DOI 10.1109/ICIP.2011.6116098
   Jung H, 2010, INT J IMAG SYST TECH, V20, P81, DOI 10.1002/ima.20231
   Jung H, 2009, MAGN RESON MED, V61, P103, DOI 10.1002/mrm.21757
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Lam F., THESIS U ILLINOIS UR
   Lam F, 2011, I S BIOMED IMAGING, P73, DOI 10.1109/ISBI.2011.5872357
   Liang D, 2009, MAGN RESON MED, V62, P1574, DOI 10.1002/mrm.22161
   LIANG ZP, 1994, IEEE T MED IMAGING, V13, P677, DOI 10.1109/42.363100
   Lingala SG, 2011, I S BIOMED IMAGING, P1280, DOI 10.1109/ISBI.2011.5872635
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Lustig M., 2006, P INT SOC MAG RESON, V14, P2420
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Ma S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587391
   Magarey J, 1998, IEEE T SIGNAL PROCES, V46, P1069, DOI 10.1109/78.668557
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   Peng X, 2011, I S BIOMED IMAGING, P89, DOI 10.1109/ISBI.2011.5872361
   Ramani S, 2011, IEEE T MED IMAGING, V30, P694, DOI 10.1109/TMI.2010.2093536
   Rockafellar RT, 1973, J OPTIMIZ THEORY APP, V12, P555, DOI 10.1007/BF00934777
   Samsonov A., 2010, P 18 ANN M ISMRM STO, P4876
   Song T, 2010, J VIS COMMUN IMAGE R, V21, P1, DOI 10.1016/j.jvcir.2009.09.003
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Sun DF, 2008, MATH PROGRAM, V114, P349, DOI 10.1007/s10107-007-0105-9
   Trzasko J, 2009, IEEE T MED IMAGING, V28, P106, DOI 10.1109/TMI.2008.927346
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
   Yang Z, 2011, IEEE T SIGNAL PROCES, V59, P6285, DOI 10.1109/TSP.2011.2168216
   Zhang Z., J VIS COMMUN IMAGE R
NR 48
TC 0
Z9 0
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 112
EP 124
DI 10.1016/j.jvcir.2015.05.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600010
DA 2024-07-18
ER

PT J
AU Chen, CC
   Hsieh, SL
AF Chen, Chun-Che
   Hsieh, Shang-Lin
TI Using binarization and hashing for efficient SIFT matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Image hashing; SIFT feature; Feature extraction;
   Feature binarization; Binary descriptor; Feature matching; Hashing
ID IMAGE; FEATURES; BINARY
AB The well-known SIFT is capable of extracting distinctive features for image retrieval. However, its matching is time consuming and slows down the entire process. In the SIFT matching, the Euclidean distance is used to measure the similarity of two features, which is expensive because it involves taking square root. Moreover, the scale of the image database is usually too large to adopt linear search for image retrieval. To improve the SIFT matching, this paper proposes a fast image retrieval scheme transforms the SIFT features to binary representations. The complexity of the distance calculation is reduced to bit-wise operation and the retrieval time is greatly decreased. Moreover, the proposed scheme utilizes hashing for retrieving similar images according to the binarized features and further speeds up the retrieval process. The experiment results show the proposed scheme can retrieve images efficiently with only a little sacrifice of accuracy as compared to SIFT. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Chun-Che; Hsieh, Shang-Lin] Tatung Univ, Dept Comp Sci & Engn, 40,Sec 3,Zhongshan N Rd, Taipei 10452, Taiwan.
   [Chen, Chun-Che] Taipei Coll Maritime Technol, New Taipei City 25172, Taiwan.
C3 Tatung University
RP Chen, CC (corresponding author), Tatung Univ, Dept Comp Sci & Engn, 40,Sec 3,Zhongshan N Rd, Taipei 10452, Taiwan.
EM chelanceg@yahoo.com.tw; slhsieh@ttu.edu.tw
FU Tatung University, Taipei, Taiwan [B100-107-036]
FX Financial support of this study by Tatung University, Taipei, Taiwan,
   under grant B100-107-036 is gratefully acknowledged.
CR Alitappeh R. J., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P906, DOI 10.1109/ISSPA.2012.6310683
   Chen WH, 2013, CHIN CONT DECIS CONF, P3755
   d'Angelo E, 2014, IEEE T PATTERN ANAL, V36, P874, DOI 10.1109/TPAMI.2013.228
   Jiang XD, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 1, P1, DOI 10.1109/ICCSIT.2009.5235014
   Jianhui Li, 2013, Web-Age Information Management. WAIM 2013 International Workshops: HardBD, MDSP, BigEM, TMSN, LQPM, BDMS. Proceedings. LNCS 7901, P187, DOI 10.1007/978-3-642-39527-7_20
   Jie Zhao, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P258, DOI 10.1109/ICMLC.2010.5581057
   Karimi V, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P1725, DOI 10.1109/TELFOR.2012.6419560
   Ke Y, 2004, PROC CVPR IEEE, P506
   Khamankar SM, 2014, INT CONF COMM SYST, P924, DOI 10.1109/CSNT.2014.190
   Khan N. Y., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P501, DOI 10.1109/DICTA.2011.90
   Liu W, 2016, MULTIMED TOOLS APPL, V75, P1481, DOI 10.1007/s11042-014-2004-4
   Liu W, 2013, IEEE T IMAGE PROCESS, V22, P872, DOI 10.1109/TIP.2012.2219544
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Ni Zhen-Sheng, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P117, DOI 10.1109/ICDH.2012.69
   Park U., IEEE SIGNAL PROCESS, V21
   Usui Y, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P517, DOI 10.1109/ISPACS.2009.5383787
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150
   Yang Y, 2013, IEEE T GEOSCI REMOTE, V51, P818, DOI 10.1109/TGRS.2012.2205158
   Yao Jinliang, 2011, 2011 International Conference of Soft Computing and Pattern Recognition, P258, DOI 10.1109/SoCPaR.2011.6089117
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Zhu D., 2009, P 2009 2 INT C IM SI, P1
NR 26
TC 25
Z9 30
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 86
EP 93
DI 10.1016/j.jvcir.2015.02.014
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900008
DA 2024-07-18
ER

PT J
AU Chiang, HF
   Hsieh, JW
   Chuang, CH
   Chuang, KT
   Yan, YL
AF Chiang, Hui-Fen
   Hsieh, Jun-Wei
   Chuang, Chi-Hung
   Chuang, Kai-Ting
   Yan, Yilin
TI Modeling and recognizing action contexts in persons using sparse
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse coding; Sparse reconstruction error; Occlusions; R transform;
   Interaction action analysis; Behavior analysis; Person-to-person action
   recognition; Person-to-object action recognition
ID TRACKING
AB This paper proposes a novel dynamic sparsity-based classification scheme to analyze various interaction actions between persons. To address the occlusion problem, this paper represents an action in an over-complete dictionary to makes errors (caused by lighting changes or occlusions) sparsely appear in the training library if the error cases are well collected. Because of this sparsity, it is robust to occlusions and lighting changes. In addition, a novel Hamming distance classification (HDC) scheme is proposed to classify action events to various types. Because the nature of Hamming code is highly tolerant to noise, the HDC scheme is also robust to environmental changes. The difficulty of complicated action modeling can be easily tackled by adding more examples to the over-complete dictionary. More importantly, the HDC scheme is very efficient and suitable for real-time applications because no minimization process is involved to calculate the reconstruction error. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chiang, Hui-Fen; Hsieh, Jun-Wei; Chuang, Kai-Ting; Yan, Yilin] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
   [Chiang, Hui-Fen] Taipei CSU ST, Dept DM Des, Taipei 112, Taiwan.
   [Chuang, Chi-Hung] Fo Guang Univ, Dept Learning & Digital Technol, Jiaosi 26247, Yilan, Taiwan.
C3 National Taiwan Ocean University; Fo Guang University
RP Hsieh, JW (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Beining Rd, Keelung 202, Taiwan.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], INT C GRAPH IM PROC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2 INT WORKSH SEM LEA
   [Anonymous], IEEE C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2010, BRIT MACH VIS C
   [Anonymous], INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], INT C COMP VIS ICCV
   Chen F, 2011, IMAGE VISION COMPUT, V29, P787, DOI 10.1016/j.imavis.2011.08.006
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fathi A., 2008, IEEE COMPUTER SOC C, P1
   Feng Lu, 2007, IEEE Internatonal Conference on Mobile Adhoc and Sensor Systems, 2007. MASS 2007, P1
   Filipovych R., 2008, IEEE C COMPUTER VISI, P1
   Gaidon A, 2011, PROC CVPR IEEE
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Karthikeyan S, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   LAPTEV I, 2007, INT C COMP VIS
   Lu ZW, 2013, PATTERN RECOGN, V46, P1799, DOI 10.1016/j.patcog.2012.09.027
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Maji S., 2011, IEEE C COMP VIS PATT
   Nguyen NT, 2003, PROC CVPR IEEE, P620
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Park S, 2003, LECT NOTES COMPUT SC, V2728, P394
   Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ptucha R, 2013, IMAGE VISION COMPUT, V31, P365, DOI 10.1016/j.imavis.2013.03.003
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Shang L, 2008, IMAGE VISION COMPUT, V26, P1137, DOI 10.1016/j.imavis.2007.12.006
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Weinland D., 2008, CVPR, P1
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
   Zhang HC, 2012, PATTERN RECOGN, V45, P1290, DOI 10.1016/j.patcog.2011.09.009
   Zhang XR, 2013, PATTERN RECOGN, V46, P1819, DOI 10.1016/j.patcog.2012.10.011
   Zhao B, 2011, PROC CVPR IEEE
   Zhao M, 2010, IMAGE VISION COMPUT, V28, P1590, DOI 10.1016/j.imavis.2010.04.002
   Zhou HY, 2013, PATTERN RECOGN, V46, P1748, DOI 10.1016/j.patcog.2013.01.026
NR 56
TC 2
Z9 3
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 252
EP 265
DI 10.1016/j.jvcir.2015.04.012
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900023
DA 2024-07-18
ER

PT J
AU Ibrahim, MZ
   Mulvaney, DJ
AF Ibrahim, M. Z.
   Mulvaney, D. J.
TI Geometrical-based lip-reading using template probabilistic
   multi-dimension dynamic time warping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lip reading; Lip geometry; Mouth detection; Skin segmentation; Convex
   hull; Multi dimension dynamic time warping; Template probabilistic;
   OpenCV
ID SPEECH; RECOGNITION; EXTRACTION; FACE; INFORMATION; FEATURES; EYE
AB By identifying lip movements and characterizing their associations with speech sounds, the performance of speech recognition systems can be improved, particularly when operating in noisy environments. In this paper, we present a geometrical-based automatic lip reading system that extracts the lip region from images using conventional techniques, but the contour itself is extracted using a novel application of a combination of border following and convex hull approaches. Classification is carried out using an enhanced dynamic time warping technique that has the ability to operate in multiple dimensions and a template probability technique that is able to compensate for differences in the way words are uttered in the training set. The performance of the new system has been assessed in recognition of the English digits 0 to 9 as available in the CUAVE database. The experimental results obtained from the new approach compared favorably with those of existing lip reading approaches, achieving a word recognition accuracy of up to 71% with the visual information being obtained from estimates of lip height, width and their ratio. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ibrahim, M. Z.] Univ Malaysia Pahang, Fac Elect & Elect Engn, Pahang 26300, Malaysia.
   [Mulvaney, D. J.] Univ Loughborough, Sch Elect Elect & Syst Engn, Loughborough LE11 3TU, Leics, England.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA); Loughborough
   University
RP Ibrahim, MZ (corresponding author), Univ Malaysia Pahang, Fac Elect & Elect Engn, Pahang 26300, Malaysia.
EM zamri@ump.edu.my; d.j.mulvaney@lboro.ac.uk
RI Ibrahim, Mohd Zamri/HNQ-2755-2023
OI Ibrahim, Mohd Zamri/0000-0003-0795-4096
CR Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   Aleksic P.S., 2005, HDB IMAGE VIDEO PROC
   [Anonymous], MPEG 4 FACIAL ANIMAT
   [Anonymous], 1993, PRENTICE HALL SIGNAL
   [Anonymous], 2007, INFORM RETRIEVAL MUS
   [Anonymous], 2003, PROC GRAPHICON
   Aron J., 2011, NEW SCI, V212, P24, DOI DOI 10.1016/S0262-4079(11)62647-X
   Balasubramanian M, 2009, EXPERT SYST APPL, V36, P6879, DOI 10.1016/j.eswa.2008.08.001
   Benhaim E., 2013, INT C AC SPEECH SIGN
   Benhaim E, 2013, INT CONF ACOUST SPEE, P2420, DOI 10.1109/ICASSP.2013.6638089
   BERRY CR, 2009, IMPERFECT UNION REPR, P1
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bradski G., 2008, LEARNING OPENCV
   Bregler C., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P557, DOI 10.1109/ICASSP.1993.319179
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan MT, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P9, DOI 10.1109/MMSP.2001.962703
   Chen TH, 2001, IEEE SIGNAL PROC MAG, V18, P9
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   de Berg M., 2008, COMPUTATIONAL GEOMET, V3rd ed., P386
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   Eveno N, 2004, IEEE T CIRC SYST VID, V14, P706, DOI 10.1109/TCSVT.2004.826754
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gillick L., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P532, DOI 10.1109/ICASSP.1989.266481
   Gordan M, 2002, EURASIP J APPL SIG P, V2002, P1248, DOI 10.1155/S1110865702207039
   Gurban M, 2009, IEEE T SIGNAL PROCES, V57, P4765, DOI 10.1109/TSP.2009.2026513
   Gurbuz S, 2001, INT CONF ACOUST SPEE, P177, DOI 10.1109/ICASSP.2001.940796
   Ibrahim M., 2012, IEEE INT C VIS COMM, P1, DOI [10.1109/ECCE.2012.6342536, DOI 10.1109/ECCE.2012.6342536]
   Jin Z, 2007, NEUROCOMPUTING, V70, P794, DOI 10.1016/j.neucom.2006.10.043
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim W, 2012, DIGITAL SIGNAL PROCESSING FOR IN-VEHICLE SYSTEMS AND SAFETY, P175, DOI 10.1007/978-1-4419-9607-7_11
   Kuo P., 2005, IEE International Conference on Visual Information Engineering (VIE 2005) (CP No.509), P251, DOI 10.1049/cp:20050097
   Li H, 2011, PATTERN RECOGN, V44, P1614, DOI 10.1016/j.patcog.2010.12.014
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu H.F., 2010, MABS, V2, P1
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Matthews I., 2001, P INT C MULT EXP, P2
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Neti C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P619, DOI 10.1109/MMSP.2001.962801
   Papandreou G, 2009, IEEE T AUDIO SPEECH, V17, P423, DOI 10.1109/TASL.2008.2011515
   Patterson EK, 2002, EURASIP J APPL SIG P, V2002, P1189, DOI 10.1155/S1110865702206101
   Petajan ED., 1988, P SIGCHI C HUM FACT, P19, DOI DOI 10.1145/57167.57170
   Potamianos G, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P777
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Potamianos G, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P250, DOI 10.1109/ICIP.2001.958098
   Potamianos G, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1097, DOI 10.1109/ICME.2000.871552
   Potamianos G, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P173, DOI 10.1109/ICIP.1998.999008
   Potamianos G., 2004, ISSUES AUDIO VISUAL
   Rurainsky J, 2003, LECT NOTES COMPUT SC, V2849, P23
   Ryu YS, 2001, PATTERN RECOGN, V34, P2459, DOI 10.1016/S0031-3203(00)00173-4
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Shaikh A. A., 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P327, DOI 10.1109/CISP.2010.5646264
   Sharp John., 2010, Microsoft Visual C# 2010 Step by Step
   Stork D. G., 1992, IJCNN International Joint Conference on Neural Networks (Cat. No.92CH3114-6), P289, DOI 10.1109/IJCNN.1992.226994
   Stork D.G., 1996, SPEECHREADING HUMANS, V1
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Theodoridis S, 2003, PATTERN RECOGN, V2nd
   TIAN Y, 2000, P 4 AS C COMP VIS
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   YAU WC, 2006, HCSNET WORKSH US VIS
   Yin P, 2004, PROC CVPR IEEE, P755
   Yokogawa Y., 2007, Systems and Computers in Japan, V38, P80, DOI 10.1002/scj.10668
   Zhang C., 2010, A survey of recent advances in face detection
   Zhang XZ, 2002, EURASIP J APPL SIG P, V2002, P1228, DOI 10.1155/S1110865702206137
NR 67
TC 14
Z9 14
U1 1
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 219
EP 233
DI 10.1016/j.jvcir.2015.04.013
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900020
DA 2024-07-18
ER

PT J
AU Vyas, JP
   Joshi, MV
   Raval, MS
AF Vyas, Jaladhi P.
   Joshi, Manjunath V.
   Raval, Mehul S.
TI Automatic target image detection for morphing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D texton; K means clustering; Chi-square distance measure; Facial
   features extraction; Control points detection; Target image detection;
   Delaunay triangulation; Image morphing
ID TEXTURE CLASSIFICATION; FACE; EXTRACTION; METAMORPHOSIS; SEGMENTATION;
   RECOGNITION
AB In this paper, we propose a novel approach for automatic target image detection for morphing based on 3D textons and contrast. Given the source image of a human frontal face and training images with human and animal faces, our algorithm automatically finds the target image from the database of animal images. There are three major advantages of our approach: (1) it solves the problem of manual target selection as done by the researchers in morphing; (2) automatic target detection achieves smooth transition from source to destination image; and (3) control points are automatically detected for morphing because the algorithm detects the target based on the matching features. The experiments were conducted with images of six different animals viz, cheetah, lion, deer, red fox, snow leopard and rhesus monkey. For a subjective verification, a large number of human annotations are used. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Vyas, Jaladhi P.; Joshi, Manjunath V.] Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar 382007, Gujarat, India.
   [Raval, Mehul S.] Inst Engn & Technol, Ahmadabad 380009, Gujarat, India.
C3 Dhirubhai Ambani Institute of Information & Communication Technology
RP Vyas, JP (corresponding author), Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar 382007, Gujarat, India.
EM vyasjaladhi@gmail.com; manjunath.joshi@gmail.com; mehul.raval@gmail.com
RI Raval, Mehul S/IWM-4799-2023; Raval, Mehul S/Y-7493-2019
OI Raval, Mehul S/0000-0002-3895-1448; Raval, Mehul S/0000-0002-3895-1448;
   IICT, DA/0000-0002-2456-1721
CR Asteriadis S, 2009, PATTERN RECOGN, V42, P1388, DOI 10.1016/j.patcog.2009.01.009
   Baskan S, 2002, PATTERN RECOGN LETT, V23, P1623, DOI 10.1016/S0167-8655(02)00037-5
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Bichsel M, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P128, DOI 10.1109/AFGR.1996.557254
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Hamada T, 2000, PATTERN RECOGN LETT, V21, P407, DOI 10.1016/S0167-8655(00)00009-X
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jain V., 2002, The Indian Face Database
   Latha YM, 2007, INT J COMPUT SCI NET, V7, P38
   Lee AWF, 1999, COMP GRAPH, P343, DOI 10.1145/311535.311586
   Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502
   Lee S, 1998, IEEE COMPUT GRAPH, V18, P58, DOI 10.1109/38.637304
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Luo Y, 2008, INT J PATTERN RECOGN, V22, P555, DOI 10.1142/S0218001408006399
   Milborrow S., The MUCT Landmarked Face Database
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Papakostas GA, 2013, NEUROCOMPUTING, V99, P358, DOI 10.1016/j.neucom.2012.06.031
   Peer P., 2010, CVL FACE DATABASE
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   Qian ZM, 2010, PATTERN RECOGN LETT, V31, P1633, DOI 10.1016/j.patrec.2010.05.012
   RUPRECHT D, 1995, IEEE COMPUT GRAPH, V15, P37, DOI 10.1109/38.365004
   Seitz SM, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P17, DOI 10.1109/ICCV.1998.710696
   Seung-Yong Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P439
   Shih FY, 2004, INFORM SCIENCES, V158, P117, DOI 10.1016/j.ins.2003.03.002
   Solina Franc., 2003, P MIRAGE 2003, P38
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Varma M, 2004, IMAGE VISION COMPUT, V22, P1175, DOI 10.1016/j.imavis.2004.03.012
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang LF, 2005, IEEE T VIS COMPUT GR, V11, P25
   Wolberg G., 1989, Visual Computer, V5, P95, DOI 10.1007/BF01901485
   Wolberg G, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P64, DOI 10.1109/CGI.1996.511788
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Yilmaz MB, 2012, SIGNAL PROCESS-IMAGE, V27, P678, DOI 10.1016/j.image.2012.03.003
   Zanella V, 2009, LECT NOTES COMPUT SC, V5495, P600, DOI 10.1007/978-3-642-04921-7_61
   Zhang CZ, 2002, IEEE T IMAGE PROCESS, V11, P1249, DOI 10.1109/TIP.2002.804277
NR 38
TC 3
Z9 3
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2015
VL 27
BP 28
EP 43
DI 10.1016/j.jvcir.2014.12.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CA5SI
UT WOS:000348967700003
DA 2024-07-18
ER

PT J
AU Hong, S
   Khim, S
   Rhee, PK
AF Hong, Sungjin
   Khim, Sarang
   Rhee, Phil Kyu
TI Efficient facial landmark localization using spatial-contextual AdaBoost
   algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial landmark localization; Global detector; Local detector;
   SC-AdaBoost; Coarse-to-fine strategy; Gabor wavelet; Haar-like
   feature-based boosting method; Weak classifier
ID MODELS; ROBUST; FEATURES
AB Facial landmark detectors can be categorized into global and local detectors. Global facial landmark detectors rely on global statistical relations between landmarks, but do not sufficiently utilize local appearance information, whereas local detectors mainly focus on local appearance attributes of landmarks. Although the AdaBoost algorithm has been successfully employed in object localization, it cannot take advantage of geometric facial feature distribution very well. We propose an AdaBoost algorithm called SC-AdaBoost, which efficiently combines the global knowledge of landmark distribution, the regional shape model, and the local landmark attributes based on a coarse-to-fine strategy. The global prior distribution of landmarks is estimated using a face image set with landmark annotations. First, the face region is detected as a rectangular bounding box using a Haar-like feature-based boosting method, and the global distribution of landmarks is used to determine the facial component regions. Facial landmark localization is roughly performed by regional shape modeling. Posteriors of individual weak classifiers are determined by Gabor wavelet analysis at landmark candidate positions constrained by the regional shape model. SC-AdaBoost is established by empirical risk minimization, which decides the weights for the weak classifiers, and is used for the precise localization. The strength of the proposed approach is shown by extensive experiments using standard face datasets. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Hong, Sungjin; Khim, Sarang; Rhee, Phil Kyu] Inha Univ, Inchon, South Korea.
C3 Inha University
RP Rhee, PK (corresponding author), Inha Univ, 235 Yong Hyun Dong, Inchon, South Korea.
EM sjhong0117@gmail.com; sarang.khim@gmail.com; pkrhee@inha.ac.kr
RI Rhee, Phill Kyu/AAP-5810-2021
FU Inha University research grant
FX This work was supported by an Inha University research grant.
CR Akakin HC, 2009, LECT NOTES COMPUT SC, V5707, P105, DOI 10.1007/978-3-642-04391-8_14
   Salah AA, 2007, ANN TELECOMMUN, V62, P83
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Çeliktutan O, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-13
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cootes TF, 1999, IMAGE VISION COMPUT, V17, P567, DOI 10.1016/S0262-8856(98)00175-9
   Cristinacce D., 2004, BMVC, P231
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32
   Dibeklioglu H, 2012, IEEE T IMAGE PROCESS, V21, P844, DOI 10.1109/TIP.2011.2163162
   Eckhardt M, 2009, INT J PATTERN RECOGN, V23, P379, DOI 10.1142/S0218001409007247
   Everingham M., 2006, P BRIT MACH VIS C, P899, DOI [DOI 10.5244/C.20.92, 10.5244/C.20.92]
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Ge YX, 2013, J VIS COMMUN IMAGE R, V24, P627, DOI 10.1016/j.jvcir.2013.04.011
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Gourier N, 2004, IEEE SYS MAN CYBERN, P617
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kozakaya T, 2010, IMAGE VISION COMPUT, V28, P772, DOI 10.1016/j.imavis.2009.09.008
   Liu K, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P933, DOI 10.1109/ICME.2008.4607589
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Milborrow S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P378, DOI 10.1109/ICCVW.2013.57
   Monzo David, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1330, DOI 10.1109/ICPR.2010.1145
   Nishii R, 2005, IEEE T GEOSCI REMOTE, V43, P2547, DOI 10.1109/TGRS.2005.848693
   Pears N, 2010, INT J COMPUT VISION, V89, P152, DOI 10.1007/s11263-009-0297-y
   Sangineto E, 2013, IEEE T PATTERN ANAL, V35, P624, DOI 10.1109/TPAMI.2012.87
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Senaratne R, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P120
   Shi Wenzhong, 2010, PRINCIPLES MODELING
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
NR 44
TC 4
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1366
EP 1377
DI 10.1016/j.jvcir.2014.05.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100007
DA 2024-07-18
ER

PT J
AU Yuen, CH
   Lui, OY
   Wong, KW
AF Yuen, Ching Hung
   Lui, Oi Yan
   Wong, Kwok Wo
TI Hybrid fractal image coding with quadtree-based progressive structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fractal image coding; Progressive image transmission; Image compression;
   Quadtree partitioning; Iterated function system; No-search encoding;
   Domain block and range block; SSIM measure
ID COMPRESSION; SEARCH; ALGORITHM; QUALITY; TRANSFORM
AB A progressive structure which takes the quadtree depth into consideration is proposed for fractal image coding. Simulation results show that its image quality at different received data rates is better than that without considering the quadtree level. Then, a hybrid fractal image coding scheme based on traditional and no-search fractal image coding with the proposed progressive structure is suggested. The image quality and compression ratio can be controlled by a threshold, which makes it downward compatible to the no-search fractal image coding. Experimental results justify that the progressive performance of the proposed scheme is better than that of traditional fractal image coding. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yuen, Ching Hung; Lui, Oi Yan; Wong, Kwok Wo] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Yuen, CH (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM chyuen@student.cityu.edu.hk; oiyanlui2@student.cityu.edu.hk;
   itkwwong@cityu.edu.hk
RI Wong, Kwok-Wo/K-9442-2015
FU CityU [7002839]
FX The work described in this paper was fully supported by a Grant from
   CityU [Project No. 7002839].
CR [Anonymous], JASPER PROJECT
   BARNSLEY MF, 1988, BYTE, V13, P215
   Belloulata K, 2005, J VIS COMMUN IMAGE R, V16, P55, DOI 10.1016/j.jvcir.2004.02.001
   Curtis KM, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1337, DOI 10.1109/ICDSP.2002.1028341
   Drakopoulos V, 2006, FRACTALS, V14, P259, DOI 10.1142/S0218348X06003271
   Ebrahimi T, 1998, P IEEE, V86, P1109, DOI 10.1109/5.687832
   Egger O, 1999, P IEEE, V87, P976, DOI 10.1109/5.763312
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   Hamzaoui R, 2001, J VIS COMMUN IMAGE R, V12, P450, DOI 10.1006/jvci.2001.0492
   He C, 2004, IEE P-VIS IMAGE SIGN, V151, P207, DOI 10.1049/ip-vis:20040316
   He CJ, 2006, CHAOS SOLITON FRACT, V27, P1178, DOI 10.1016/j.chaos.2005.04.006
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang XQ, 2013, J VIS COMMUN IMAGE R, V24, P42, DOI 10.1016/j.jvcir.2012.10.005
   Jacquin A.E., 1989, THESIS GEORGIA I TEC, P2225
   JACQUIN AE, 1993, P IEEE, V81, P1451, DOI 10.1109/5.241507
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kamaci N., 2012, P SPIE VISUAL INFORM, V8305
   Kopilovic I, 2001, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.2001.958959
   Kuo CJ, 1999, J VIS COMMUN IMAGE R, V10, P307, DOI 10.1006/jvci.1999.0422
   Chung KL, 2006, J VIS COMMUN IMAGE R, V17, P1209, DOI 10.1016/j.jvcir.2006.01.002
   Li MD, 2013, J VIS COMMUN IMAGE R, V24, P509, DOI 10.1016/j.jvcir.2013.03.006
   Lian SG, 2009, FRACTALS, V17, P149, DOI 10.1142/S0218348X09004405
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lin YL, 2012, J INF SCI ENG, V28, P17
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Roma N, 2011, SIGNAL PROCESS, V91, P2443, DOI 10.1016/j.sigpro.2011.04.015
   Salarian M, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P62, DOI 10.1109/ICMV.2007.4469274
   Shen FR, 2004, SIGNAL PROCESS-IMAGE, V19, P393, DOI 10.1016/j.image.2004.02.002
   Shi YQ, 2008, IMAGE PROCESS SER, P3
   Tse FW, 2002, IEE P-VIS IMAGE SIGN, V149, P272, DOI 10.1049/ip-vis:20020613
   Wang HQ, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P613
   Wang JJ, 2011, IEEE IMAGE PROC, P241, DOI 10.1109/ICIP.2011.6116131
   Wang W, 2012, IEEJ T ELECTR ELECTR, V7, P521, DOI 10.1002/tee.21768
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wang XY, 2010, IMAGE VISION COMPUT, V28, P1303, DOI 10.1016/j.imavis.2010.01.008
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yuen CH, 2012, CHINESE PHYS B, V21, DOI 10.1088/1674-1056/21/1/010502
   Zhang Y, 2012, NONLINEAR ANAL-REAL, V13, P106, DOI 10.1016/j.nonrwa.2011.07.017
   Zhou YM, 2009, CHAOS SOLITON FRACT, V39, P1823, DOI 10.1016/j.chaos.2007.06.089
NR 42
TC 8
Z9 9
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1328
EP 1341
DI 10.1016/j.jvcir.2013.09.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700010
DA 2024-07-18
ER

PT J
AU Yu, CC
   Cheng, HY
   Lee, CC
AF Yu, Chih-Chang
   Cheng, Hsu-Yung
   Lee, Chien-Cheng
TI Mixture models with skin and shadow probabilities for fingertip input
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving skin region detection; Shadow detection; Mixture models; Human
   computer interface; Video-based fingertip input; Virtual touch keyboard;
   Mandarin phonetic symbol; Feature extraction
ID TRACKING; CLASSIFICATION; COMMUNICATION
AB This paper proposes an accurate moving skin region detection method for video-based human-computer interface using gestures or fingertips. Using Gaussian mixture models as groundwork, the proposed method expresses the features of skins in a probability form and incorporates them into the mixture-based framework. Moreover, to alleviate the influence of shadows, the properties of shadows are also formulated as probabilities and used for shadow detection and elimination. In addition to moving skin region detection, this paper also develops two practical fingertip input applications to demonstrate the accuracy of the proposed detection method. The two applications are Mandarin Phonetic Symbol combination recognition system and single fingertip virtual keyboard implementation. Experimental results have shown the advantages of the proposed detection method and the effectiveness of the two application implementations. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yu, Chih-Chang] Vanung Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Cheng, Hsu-Yung] Natl Cent Univ, Dept Comp Sci & Informat Engn, Tao Yuan 320, Taiwan.
   [Lee, Chien-Cheng] Yuan Ze Univ, Dept Commun Engn, Taipei, Taiwan.
C3 National Central University; Yuan Ze University
RP Cheng, HY (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Jung Da Rd, Tao Yuan 320, Taiwan.
EM tacoyu@mail.vnu.edu.tw; chengsy@csie.ncu.edu.tw; cclee@saturn.yzu.edu.tw
OI Cheng, Hsu-Yung/0000-0002-8342-7450
FU National Science Council of Taiwan
FX This work was supported in part by the National Science Council of
   Taiwan.
CR Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   Chaves-González JM, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI 10.1016/j.dsp.2009.10.008
   Cheng HY, 2011, J VIS COMMUN IMAGE R, V22, P673, DOI 10.1016/j.jvcir.2011.07.001
   Dominguez SM, 2006, IEEE T MULTIMEDIA, V8, P956, DOI 10.1109/TMM.2006.879872
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guan C, 2007, J VIS COMMUN IMAGE R, V18, P141, DOI 10.1016/j.jvcir.2006.11.006
   Gupta L, 2001, IEEE T SYST MAN CY C, V31, P114, DOI 10.1109/5326.923274
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Lee CC, 2011, J SIGNAL PROCESS SYS, V64, P291, DOI 10.1007/s11265-010-0490-9
   Martel-Brisson N, 2007, IEEE T PATTERN ANAL, V29, P1133, DOI 10.1109/TPAMI.2007.1039
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Quek FKH, 1996, IEEE MULTIMEDIA, V3, P36, DOI 10.1109/93.556459
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schmugge SJ, 2007, J VIS COMMUN IMAGE R, V18, P487, DOI 10.1016/j.jvcir.2007.04.008
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Storring M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P64, DOI 10.1109/AFGR.2000.840613
   Yang DD, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4991
   Yu C.C., 2011, 17 INT C MULTIMEDIA
NR 20
TC 2
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 819
EP 828
DI 10.1016/j.jvcir.2013.05.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700008
DA 2024-07-18
ER

PT J
AU Schwartz, S
   Wong, A
   Clausi, DA
AF Schwartz, Shimon
   Wong, Alexander
   Clausi, David A.
TI Saliency-guided compressive sensing approach to efficient laser range
   measurement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Range measurement; Range data acquisition; Compressed sampling;
   Compressive sensing; 3-D data reconstruction; Laser measurements;
   Saliency; Sparse measurements model
ID ROBUST UNCERTAINTY PRINCIPLES; RESTRICTED ISOMETRY PROPERTY; BASES
AB The acquisition of laser range measurements can be a time consuming process for situations where high spatial resolution is required. As such, optimizing the acquisition mechanism is of high importance for many range measurement applications. Acquiring such data through a dynamically small subset of measurement locations can address this problem. In such a case, the measured information can be regarded as incomplete, which necessitates the application of special reconstruction tools to recover the original data set. The reconstruction can be performed based on the concept of sparse signal representation. Recovering signals and images from their sub-Nyquist measurements forms the core idea of compressive sensing (CS). A new saliency-guided CS-based algorithm for improving the reconstruction of range image from sparse laser range measurements has been developed. This system samples the object of interest through an optimized probability density function derived based on saliency rather than a uniform random distribution. Particularly, we demonstrate a saliency-guided sampling method for simultaneously sensing and coding range image, which requires less than half the samples needed by conventional CS while maintaining the same reconstruction performance, or alternatively reconstruct range image using the same number of samples as conventional CS with a 16 dB improvement in signal-to-noise ratio. For example, to achieve a reconstruction SNR of 30 dB, the saliency-guided approach required 30% of the samples in comparison to the standard CS approach that required 90% of the samples in order to achieve similar performance. Crown Copyright (C) 2012 Published by Elsevier Inc. All rights reserved.
C1 [Schwartz, Shimon; Wong, Alexander; Clausi, David A.] Univ Waterloo, Dept Syst Design Engn, Vis & Image Proc Lab Res Grp, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Schwartz, S (corresponding author), Univ Waterloo, Dept Syst Design Engn, Vis & Image Proc Lab Res Grp, Waterloo, ON N2L 3G1, Canada.
EM tsschwar@uwaterloo.ca; a28wong@uwaterloo.ca; dclausi@uwaterloo.ca
RI Wong, Alexander/GZM-2929-2022; Clausi, David A/J-4613-2013
OI Wong, Alexander/0000-0002-5295-2797; 
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   Geomatics for Informed Decisions (GEOIDE)
FX This research has been sponsored by the Natural Sciences and Engineering
   Research Council of Canada (NSERC) and Geomatics for Informed Decisions
   (GEOIDE). The authors would also like to thank National Research Council
   Canada (NRC) and The Brown University pattern theory group for the test
   laser range data.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blais F, 2004, J ELECTRON IMAGING, V13, P231, DOI 10.1117/1.1631921
   *BROWN U PATT THEO, BROWN RANG IM DAT
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen F, 2000, OPT ENG, V39, P10, DOI 10.1117/1.602438
   Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755
   Donoho DL, 2009, J AM MATH SOC, V22, P1
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031
   JALKIO JA, 1985, OPT ENG, V24, P966, DOI 10.1117/12.7973609
   JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365
   Mendelson S, 2008, CONSTR APPROX, V28, P277, DOI 10.1007/s00365-007-9005-8
   Rioux M., 1988, 29077 CNRC NAT RES C
   Rudelson M, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P207, DOI 10.1109/CISS.2006.286463
   Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
NR 27
TC 10
Z9 11
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 160
EP 170
DI 10.1016/j.jvcir.2012.02.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000009
DA 2024-07-18
ER

PT J
AU Sun, QH
   Bao, FX
   Zhang, YF
   Duan, Q
AF Sun, Qinghua
   Bao, Fangxun
   Zhang, Yunfeng
   Duan, Qi
TI A bivariate rational interpolation based on scattered data on parallel
   lines
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rational spline; Scattered data; Triangulation; Bivariate interpolation;
   Computer-aided geometric design; Shape control
ID NURBS
AB In many practical problems, such as geological exploration, forging technology and medical imaging, among others, it has been detected that the scattered data are usually arranged in parallel lines. In this paper, a new approach to construct a bivariate rational interpolation over triangulation is presented, based on scattered data in parallel lines. The main advantage of this method comparing with the present interpolation methods have two points: (1) the interpolation function is carried out by a simple and explicit mathematical representation through the parameter alpha; (2) the shape of the interpolating surface can be modified by using the parameter for the unchanged interpolating data. Moreover, a local shape control method is employed to control the shape of surfaces. In the special case, the method of "Barycenter Value Control" is studied, and numerical examples are presented to show the performance of the method. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Sun, Qinghua; Bao, Fangxun; Duan, Qi] Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
   [Zhang, Yunfeng] Shandong Econ Univ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
C3 Shandong University; Shandong University of Finance & Economics
RP Bao, FX (corresponding author), Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
EM fxbao@sdu.edu.cn
FU National Nature Science Foundation of China [61070096]; Independent
   Innovation Foundation of Shandong University [2012TS018]
FX The authors thank the anonymous referees whose valuable and healthy
   comments made this manuscript more useful. The authors also acknowledge
   supports provided by the National Nature Science Foundation of China
   (No. 61070096) and the Independent Innovation Foundation of Shandong
   University (No. 2012TS018).
CR Bao FX, 2010, COMPUT GRAPH-UK, V34, P119, DOI 10.1016/j.cag.2010.01.002
   Bao FX, 2009, J VIS COMMUN IMAGE R, V20, P275, DOI 10.1016/j.jvcir.2009.03.003
   Bezier P., 1986, The mathematical basis of the UNISURF CAD system
   Chui C.K., 1988, Multivariate Splines
   Davydov O, 2001, CONSTR APPROX, V17, P181, DOI 10.1007/s003650010034
   De Boor C., 1987, Geometric Modeling: Algorithms and New Trends, P131
   DEBOOR C, 1993, J APPROX THEORY, V72, P24, DOI 10.1006/jath.1993.1003
   DELBOURGO R, 1989, IMA J NUMER ANAL, V9, P123, DOI 10.1093/imanum/9.1.123
   Dierckx P., 1989, Computer-Aided Geometric Design, V6, P279, DOI 10.1016/0167-8396(89)90029-0
   Duan Q, 2004, INFORM SCIENCES, V166, P181, DOI 10.1016/j.ins.2003.12.001
   Duan Q, 2005, APPL MATH COMPUT, V168, P990, DOI 10.1016/j.amc.2004.09.041
   Duan Q, 1999, INT J COMPUT MATH, V72, P155, DOI 10.1080/00207169908804842
   Duan Q, 2008, APPL MATH COMPUT, V198, P59, DOI 10.1016/j.amc.2007.08.050
   Duan Q, 2006, COMPUT MATH APPL, V52, P975, DOI 10.1016/j.camwa.2006.04.021
   Duan Q, 2006, APPL MATH COMPUT, V179, P190, DOI 10.1016/j.amc.2005.11.094
   Duan Q, 2009, COMPUT AIDED DESIGN, V41, P825, DOI 10.1016/j.cad.2009.05.002
   Farin G., 1986, Computer-Aided Geometric Design, V3, P83, DOI 10.1016/0167-8396(86)90016-6
   Farin G., 2002, CURVES SURFACES COMP
   GREGORY JA, 1994, COMPUT GRAPH, V18, P153, DOI 10.1016/0097-8493(94)90089-2
   Han X., 2008, SIAM J NUMER ANAL, V46
   Hering-Bertram M, 2009, COMPUTING, V86, P89, DOI 10.1007/s00607-009-0061-8
   Huang WX, 2011, APPL MATH COMPUT, V217, P4644, DOI 10.1016/j.amc.2010.11.016
   Hussain MZ, 2008, J COMPUT APPL MATH, V218, P446, DOI 10.1016/j.cam.2007.05.023
   Konno K, 1996, COMPUT AIDED GEOM D, V13, P825, DOI 10.1016/S0167-8396(96)00012-X
   Müller R, 2002, COMPUT AIDED GEOM D, V19, P479, DOI 10.1016/S0167-8396(02)00125-5
   PIEGL L, 1991, IEEE COMPUT GRAPH, V11, P55, DOI 10.1109/38.67702
   Sarfraz M., 1994, ANN U SCI BUDAP, V37, P53
   Schultz M.H., 1973, Spline Analysis
   Tan JQ, 2002, J COMPUT APPL MATH, V144, P263, DOI 10.1016/S0377-0427(01)00566-0
   Wang R-H., 2001, MULTIVARIATE SPLINE
   Zhang YF, 2007, COMPUT GRAPH-UK, V31, P679, DOI 10.1016/j.cag.2007.04.009
NR 31
TC 7
Z9 14
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 75
EP 80
DI 10.1016/j.jvcir.2012.11.003
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600008
DA 2024-07-18
ER

PT J
AU Chen, HT
   Chou, CL
   Fu, TS
   Lee, SY
   Lin, BSP
AF Chen, Hua-Tsung
   Chou, Chien-Li
   Fu, Tsung-Sheng
   Lee, Suh-Yin
   Lin, Bao-Shuh P.
TI Recognizing tactic patterns in broadcast basketball video using player
   trajectory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sports video analysis; Object tracking; Camera calibration; Multimedia
   system; Tactic analysis; Kalman filter; Pattern recognition; Broadcast
   basketball video
ID SHOT CLASSIFICATION; FRAMEWORK; TRACKING
AB The explosive growth of the sports fandom inspires much research on manifold sports video analyses and applications. The audience, sports fans, and even professionals require more than traditional highlight extraction or semantic summarization. Computer-assisted sports tactic analysis is inevitably in urging demand. Recognizing tactic patterns in broadcast basketball video is a challenging task due to its complicated scenes, varied camera motion, frequently occlusions between players, etc. In basketball games, the action screen means that an offensive player perform a blocking move via standing beside or behind a defender for freeing a teammate to shoot, to receive a pass, or to drive in for scoring. In this paper, we propose a screen-strategy recognition system capable of detecting and classifying screen patterns in basketball video. The proposed system automatically detects the court lines for camera calibration, tracks players, and discriminates the offensive/defensive team. Player trajectories are calibrated to the real-world court model for screen pattern recognition. Our experiments on broadcast basketball videos show promising results. Furthermore, the extracted player trajectories and the recognized screen patterns visualized on a court model indeed assist the coach/players or the fans in comprehending the tactics executed in basketball games informatively and efficiently. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Chen, Hua-Tsung; Lin, Bao-Shuh P.] Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
   [Chou, Chien-Li; Fu, Tsung-Sheng; Lee, Suh-Yin] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Chen, HT (corresponding author), Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
EM huatsung@cs.nctu.edu.tw
FU [ICTL-100-Q707];  [ATU-100-W958];  [NSC 98-2221-E-009-091-MY3];  [NSC
   101-2218-E-009-004]
FX This research is supported in part by projects ICTL-100-Q707,
   ATU-100-W958, NSC 98-2221-E-009-091-MY3, and NSC 101-2218-E-009-004.
   Many thanks to Dr. Hu Min-Chun for providing us with their system for
   performance comparison.
CR [Anonymous], 2008, P 2008 INT C CONT IM
   [Anonymous], 1995, INTRO KALMAN FILTER
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2007, P 15 ACM INT C MULTI
   [Anonymous], P ACM INT C MULT
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Chu WT, 2008, MULTIMED TOOLS APPL, V38, P27, DOI 10.1007/s11042-007-0145-4
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Farin D, 2004, PROC SPIE, V5307, P80
   FLEISCHMAN M, 2007, P 15 INT C MULT, P333
   Fu T.S., 2011, IEEE Conf. Visual Communications and Image Processing, P1
   Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373
   Liu S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/32135
   Liu Y, 2005, INT CONF ACOUST SPEE, P421
   Tien MC, 2007, INT CONF ACOUST SPEE, P1085
   Wang J. R., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P186
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1543
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
   Zhang YF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2190
   Zhu G., 2009, STUDY FUNCTION KINES, P1
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
   Zhu GY, 2009, IEEE T MULTIMEDIA, V11, P49, DOI 10.1109/TMM.2008.2008918
NR 29
TC 26
Z9 31
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 932
EP 947
DI 10.1016/j.jvcir.2012.06.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900010
DA 2024-07-18
ER

PT J
AU Junejo, IN
   Al Aghbari, Z
AF Junejo, Imran N.
   Al Aghbari, Zaher
TI Using SAX representation for human action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Computer vision; Pattern recognition; Image
   understanding; SAX representation; Data mining; Intelligent systems;
   Video surveillance
AB Human action recognition is an important problem in Computer Vision. Although most of the existing solutions provide good accuracy results, the methods are often overly complex and computationally expensive, hindering practical application. In this regard, we introduce Symbolic Aggregate approximation (SAX) to address the problem of human action recognition. Given motion trajectories of reference points on an actor, SAX efficiently converts this time-series data to a symbolic representation. Moreover, the distance between two time series is approximated by the distance between their SAX representation, which is straight-forward and very simple. Requiring only trajectories of reference points, our method requires neither structure recovery nor silhouette extraction. The proposed method is validated on two public datasets. It has an accuracy comparable to related works and it performs well even in varying conditions, in addition to being faster compared to the existing methods. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Junejo, Imran N.; Al Aghbari, Zaher] Univ Sharjah, Sharjah, U Arab Emirates.
C3 University of Sharjah
RP Junejo, IN (corresponding author), Univ Sharjah, POB 27272, Sharjah, U Arab Emirates.
EM ijunejo@sharjah.ac.ae; zaher@sharjah.ac.ae
RI Junejo, Imran/ABA-2975-2020
CR Ali S., 2007, P ICCV, P1
   [Anonymous], P ICCV
   [Anonymous], EUR C COMP VIS 2010
   [Anonymous], P CVPR
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Carlsson S, 2003, INT J ROBOT RES, V22, P359, DOI 10.1177/0278364903022006002
   Chan KP, 1999, PROC INT CONF DATA, P126, DOI 10.1109/ICDE.1999.754915
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Faloutsos C., 1994, SIGMOD Record, V23, P419, DOI 10.1145/191843.191925
   Gilbert A, 2008, LECT NOTES COMPUT SC, V5302, P222, DOI 10.1007/978-3-540-88682-2_18
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Grundmann M., 2008, P ICPR, P1
   Ikizler N, 2007, LECT NOTES COMPUT SC, V4814, P271
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531
   Keogh E, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P226, DOI 10.1109/ICDM.2005.79
   Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P285, DOI 10.1145/347090.347153
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li R., 2007, P ICCV, P1
   Lin J., 2003, 8THACM SIGMOD WORKSH, DOI [10.1145/882082. 882086, DOI 10.1145/882082.882086]
   Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Niebles J.C., 2006, P BMVC
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Popivanov I, 2002, PROC INT CONF DATA, P212, DOI 10.1109/ICDE.2002.994711
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Shen YP, 2009, IEEE T PATTERN ANAL, V31, P1898, DOI 10.1109/TPAMI.2009.41
   Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Yilmaz A, 2005, IEEE I CONF COMP VIS, P150
   Yilmaz A, 2005, PROC CVPR IEEE, P984
NR 36
TC 22
Z9 27
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 853
EP 861
DI 10.1016/j.jvcir.2012.05.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900003
DA 2024-07-18
ER

PT J
AU Gallegos-Funes, FJ
   Rosales-Silva, AJ
   Toledo-Lopez, A
AF Gallegos-Funes, Francisco J.
   Rosales-Silva, Alberto J.
   Toledo-Lopez, Antonio
TI Multichannel image processing by using the Rank M-type L-filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vector Rank M-type L-filter; Median M-type estimator;
   Ansari-Bradley-Siegel-Tukey M-type estimator; L-filter; Noise
   suppression; Impulsive noise; Impulsive noise detector; Color images;
   Color video sequences; Robustness
ID IMPULSIVE NOISE
AB In this paper, we introduce the Vector Rank M-type L (VRML)-filter to remove impulsive noise from color images and video sequences. The proposed filter uses the Median M-type (MM) and Ansari-Bradley-Siegel-Tukey M-type (AM) estimators into L-filter to provide robustness to proposed filtering scheme. We also introduce the use of impulsive noise detectors to improve the properties of noise suppression and detail preservation in the proposed filtering scheme in the case of low and high densities of impulsive noise. Simulation results indicate that the proposed filter consistently outperforms other color image filters by balancing the trade-off between noise suppression, detail preservation, and color retention. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Gallegos-Funes, Francisco J.; Rosales-Silva, Alberto J.; Toledo-Lopez, Antonio] UPALM SEPI Elect, Mech & Elect Engn Higher Sch, Natl Polytech Inst Mexico, Mexico City 07738, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Gallegos-Funes, FJ (corresponding author), UPALM SEPI Elect, Mech & Elect Engn Higher Sch, Natl Polytech Inst Mexico, Av IPN S-N,Edif Z,Acceso 3,3Er Piso, Mexico City 07738, DF, Mexico.
EM fgallegosf@ipn.mx; arosaless@ipn.mx
RI Ponomaryov, Volodymyr/AAK-1537-2021; Rosales, Alberto/S-6146-2019;
   Gallegos-Funes, Francisco J./ABC-1160-2020
OI Ponomaryov, Volodymyr/0000-0003-4477-4676; Rosales,
   Alberto/0000-0001-8436-3025; Gallegos-Funes, Francisco
   J./0000-0002-4854-6438
FU National Polytechnic institute of Mexico
FX The authors would thank National Polytechnic institute of Mexico for
   their support to realize this work.
CR Aizenberg I, 2003, PROC SPIE, V5014, P419, DOI 10.1117/12.477716
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Barni M, 1998, SIGNAL PROCESS, V71, P45, DOI 10.1016/S0165-1684(98)00133-9
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Gallegos-Funes F, 2005, IEICE T FUND ELECTR, VE88A, P798, DOI 10.1093/ietfec/e88-a.3.798
   Gallegos-Funes F, 2008, IEICE T FUND ELECTR, VE91A, P3817, DOI 10.1093/ietfec/e91-a.12.3817
   GALLEGOSFUNES FJ, 2004, REAL-TIME IMAGING, V8, P78
   Hampel FR, 1986, Robust statistics. The approach based on influence functions
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2006, ADV IMAG ELECT PHYS, V140, P187, DOI 10.1016/S1076-5670(05)40004-X
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Plataniotis KN, 1997, IEEE T IMAGE PROCESS, V6, P933, DOI 10.1109/83.597269
   Ponomaryov V, 2005, J MATH IMAGING VIS, V23, P315, DOI 10.1007/s10851-005-2025-8
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Toledo-Lopez A, 2008, LECT NOTES COMPUT SC, V5197, P54, DOI 10.1007/978-3-540-85920-8_7
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
NR 18
TC 7
Z9 9
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 323
EP 330
DI 10.1016/j.jvcir.2011.11.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900010
DA 2024-07-18
ER

PT J
AU Chai, DF
   Peng, QS
AF Chai, Dengfeng
   Peng, Qunsheng
TI Bilayer representation for three dimensional visual communication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bilayer representation; 3D Visual communication; Stereo matching; View
   synthesis; Foreground/background separation
ID BAYESIAN-APPROACH; STEREO; OCCLUSIONS
AB This paper proposes a bilayer representation of scene consisting of foreground and background. It uses two layers to represent foreground and background, respectively. Unlike previous layer-based approaches, both layers cover the whole region instead of interested regions. Based on the bilayer representation, bilayer stereo matching, view synthesis approach and foreground/background separation algorithm are developed for three dimensional visual communication. They all consist of two steps: recovery of disparity fields of both layers and composition of these disparity fields; synthesis of images of both layers and composition of these images; computation of two layer costs and separation of foreground and background. Experimental results demonstrate that both high quality and high efficiency are achieved by above approaches. They meet the requirements of desktop-based three dimensional visual communication. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Chai, Dengfeng] Zhejiang Univ, Inst Spatial Informat Tech, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chai, Dengfeng; Peng, Qunsheng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Chai, DF (corresponding author), Zhejiang Univ, Inst Spatial Informat Tech, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM chaidf@cad.zju.edu.cn
CR [Anonymous], P INT C COMP VIS OCT
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642
   Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146
   BELHUMEUR PN, 1992, P IEEE C COMP VIS PA
   Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Criminisi A, 2007, INT J COMPUT VISION, V71, P89, DOI 10.1007/s11263-006-8525-1
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Felzenszwalb PR, 2004, PROC CVPR IEEE, P261
   Gemmell J., 2000, IEEE Multimedia, V7, P26, DOI 10.1109/93.895152
   KOLLARITS R, SID
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193
   Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54
   Liu J., 1995, Proc. Int. Workshop on Stereoscopic and Three Dimensional Imaging (IWS3DI), P229
   MHLBACH L, 1985, P 11 INT S HUM FACT
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   OTT M, 1993, INTERCHI 93
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sun J, 2005, PROC CVPR IEEE, P399
   Sun J, 2002, LECT NOTES COMPUT SC, V2351, P510
   Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807
   Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882
   Yang RG, 2004, IEEE T PATTERN ANAL, V26, P956, DOI 10.1109/TPAMI.2004.27
NR 26
TC 1
Z9 1
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 552
EP 562
DI 10.1016/j.jvcir.2009.08.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400006
DA 2024-07-18
ER

PT J
AU Mejdoub, M
   Fonteles, L
   BenAmar, C
   Antonini, M
AF Mejdoub, Mahmoud
   Fonteles, Leonardo
   BenAmar, Chokri
   Antonini, Marc
TI Embedded lattices tree: An efficient indexing scheme for content based
   retrieval on image databases
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia databases; Content based image retrieval; Indexing structure;
   Wavelets; Lattice; Vector quantization; Salient points; Feature
   extraction
AB One of the challenges in the development of a content-based multimedia indexing and retrieval application is to achieve an efficient indexing scheme. To retrieve a particular image from a large scale image database, users can be frustrated by the long query times. Conventional indexing structures cannot usually cope with the presence of a large amount of feature vectors in high-dimensional space. This paper addresses such problems and presents a novel indexing technique, the embedded lattices tree, which is designed to bring an effective solution especially for realizing the trade off between the retrieval speed up and precision.
   The embedded lattices tree is based on a lattice vector quantization algorithm that divides the feature vectors progressively into smaller partitions using a finer scaling factor. The efficiency of the similarity queries is significantly improved by using the hierarchy and the good algebraic and geometric properties of the lattice. Furthermore, the dimensionality reduction that we perform on the feature vectors, translating from an upper level to a lower one of the embedded tree, reduces the complexity of measuring similarity between feature vectors. In addition, it enhances the performance on nearest neighbor queries especially for high dimensions. Our experimental results show that the retrieval speed is significantly improved and the indexing structure shows no sign of degradations when the database size is increased. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Mejdoub, Mahmoud] CNRS, Lab I3S, UMR 6070, F-06034 Nice, France.
   Univ Nice, Nice, France.
   Engn Natl Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite Cote d'Azur; Centre National de la Recherche Scientifique
   (CNRS); Universite Cote d'Azur; Universite de Sfax; Ecole Nationale
   dIngenieurs de Sfax (ENIS)
RP Mejdoub, M (corresponding author), CNRS, Lab I3S, UMR 6070, F-06034 Nice, France.
EM mejdoub@i3s.unice.fr; fonteles@i3s.unice.fr; am@i3s.unice.fr;
   Chokri.BenAmar@enis.mu.tn
RI Chokri, BEN AMAR/K-5237-2012
OI Mejdoub, Mahmoud/0000-0002-9442-5784
CR Andrews G.E., 1998, THEORY PARTITIONS
   [Anonymous], INT C SIGN SYST DES
   [Anonymous], P 3 INT WORKSH CONT
   [Anonymous], ICCV
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Ben Amar C, 2005, ADV ENG SOFTW, V36, P459, DOI 10.1016/j.advengsoft.2005.01.013
   BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200
   Bilenko M., 2004, P INT C MACH LEARN, P11
   BOUTELDJA N, 2006, IST SPIE C MULT CONT
   GAEDE V, 1998, ACM COMPUT SURV, V30, P2
   Grira N, 2005, 7 ACM SIGMM INT WORK
   HIDD FL, 2007, IEEE INT S INF THEOR
   HOPPNER F, 1999, DATA ANAL IMAGE RECO, P41
   KASKI S, 1998, NEURAL COMPUTING SUR, P1981
   KIRANYAZ S, 2005, C IM PROC ICIP
   LEIBE B, 2006, BRIT MACH VIS C
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   LOUPIAS E, 1999, 9911 TR INSA
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MEJDOUB M, 2007, 15 EUR SIGN PROC C E, P1799
   Mejdoub M, 2007, INT C SIGN SYST DEV
   MEJDOUB M, 2007, TRAITEMENT ANAL IMAG
   Moosmann F., 2006, NIPS
   Moureaux JM, 1998, IEEE T COMMUN, V46, P1602, DOI 10.1109/26.737398
   Nister David, 2006, CVPR
   PRAKS P, 2003, SIAM LIN ALG P, P697
   Ren J, 2003, P IM VIS COMP NZ IVC, P102
   Shi R, 2004, LECT NOTES COMPUT SC, V3115, P545
   Tran LV, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P697, DOI 10.1109/ICIP.2001.958589
   TUYTELAARS T, 2007, P INT C COMP VIS
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
NR 31
TC 24
Z9 26
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 145
EP 156
DI 10.1016/j.jvcir.2008.12.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800008
DA 2024-07-18
ER

PT J
AU Wang, D
   Wang, ZK
   Li, JM
   Zhang, B
   Li, XR
AF Wang, Dong
   Wang, Zhikun
   Li, Jianmin
   Zhang, Bo
   Li, Xirong
TI Query representation by structured concept threads with application to
   interactive video retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive video retrieval; Query concept mapping; Concept thread;
   Structured query formulation; Concept tf-idf; Semantic feedback; Query
   representation; TRECVID
AB In this paper, we provide a new formulation for video queries as structured combination of concept threads, contributing to the general query-by-concept paradigm. Occupying a low-dimensional region in the concept space, concept thread defines a ranked list of video documents ordered by their combined concept predictions. This localized representation incorporates the previous concept based formulation as a special case and extends the restricted AND concept combination logic to a two-level concept inference network. We apply this new formulation to interactive video retrieval and utilize abundant feedback information to mine the latent semantic concept threads for answering complex query semantics. Simulative experiments which are conducted on two years' TRECVID data sets with two sets of concept lexicons demonstrate the advantage of the proposed formulation. The proposed query formulation offers some 60% improvements over the simple browsing search baseline in nearly real time. It has clear advantages over c-tf-idf and achieves better results over the state-of-the-art online ordinal reranking approach. Meanwhile, it not only alleviates user's workload significantly but also is robust to user mislabeling errors. (C) 2008 Elsevier Inc. All rights reserved
C1 [Wang, Dong; Wang, Zhikun; Li, Jianmin; Zhang, Bo] Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Li, Xirong] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 SJ Amsterdam, Netherlands.
C3 Tsinghua University; University of Amsterdam
RP Wang, D (corresponding author), Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM dwang97@gmail.com
RI Li, Jianmin/AFP-4454-2022; Li, Xirong/AAD-3347-2019
OI Li, Xirong/0000-0002-0220-8310
FU National Natural Science Foundation of China [60621062, 60605003];
   National Key Foundation [2003CB317007, 2004CB318108, 2007CB311003];
   Basic Research Foundation of Tsinghua National Laboratory for
   Information Science and Technology (TNList)
FX This work is supported by the National Natural Science Foundation of
   China under the Grant Nos. 60621062 and 60605003, the National Key
   Foundation R&D Projects under the Grant Nos. 2003CB317007, 2004CB318108
   and 2007CB311003, and the Basic Research Foundation of Tsinghua National
   Laboratory for Information Science and Technology (TNList).
CR ADCOCK J, 2008, P TRECVID WORKSH
   Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Amir A., 2005, P TRECVID WORKSH
   [Anonymous], P INT WORKSH MULT IN
   [Anonymous], 2007, ACM INT C MULT MM 07
   [Anonymous], 22220068 ADVENT COL
   [Anonymous], P 13 ACM INT C MULT
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   CAMPBELL M, 2006, P TRECVID
   Cao Z., 2007, P 24 INT C MACHINE L, P129, DOI DOI 10.1145/1273496.1273513
   CHANG SF, 2007, P TRECVID WORKSH
   Christel MG, 2005, LECT NOTES COMPUT SC, V3568, P134
   CHRISTEL MG, 2007, P ACM MULT U AUGSB G, P707
   DONALD KM, 2005, P CIVR, P1330
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   HAUBOLD A, 2006, P ICME, P1761
   Hauptmann A.G., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P385, DOI DOI 10.1145/1180639.1180721
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   Kennedy L.S., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P333
   Li Xirong., 2007, P 6 ACM INT C IMAGE, P603
   Li X, 2008, PROCEEDINGS OF THE 2008 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE, AND STORAGE, P28, DOI 10.1109/NAS.2008.44
   Nah FFH, 2004, BEHAV INFORM TECHNOL, V23, P153, DOI 10.1080/01449290410001669914
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   Neo SY, 2006, LECT NOTES COMPUT SC, V4071, P143
   SMEATON AF, 2006, P INT MIR WORKSH
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SNOEK C, 2007, P TRECVID WORKSH
   Snoek CGM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1966
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P280, DOI 10.1109/TMM.2006.886275
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   SNOEK CG, 2006, P TRECVID
   WANG D, 2007, P ICSC
   Wang Dong., 2007, the 15th ACM International Conference on Multimedia, P285
   WANG Z, 2008, P CIVR, P57
   WEI XY, 2007, P 15 INT C MULT AUGS, P981
   ZHENG W, 2006, P CIVR, P370
NR 39
TC 4
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 104
EP 116
DI 10.1016/j.jvcir.2008.12.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800005
DA 2024-07-18
ER

PT J
AU Ascenso, J
   Pereira, F
AF Ascenso, Joao
   Pereira, Fernando
TI Advanced side information creation techniques and framework for
   Wyner-Ziv video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Wyner-Ziv video coding; Distributed video coding; Side information
   creation; Frame interpolation
ID MOTION ESTIMATION
AB Recently, several distributed video coding (DVC) solutions based on the distributed source coding (DSC) paradigm have appeared in the literature. Wyner-Ziv (WZ) video coding, a particular case of DVC where side information is made available at the decoder, enable to achieve a flexible distribution of the computational complexity between the encoder and decoder, promising to fulfill novel requirements from applications such as video surveillance, sensor networks and mobile camera phones. The quality of the side information at the decoder has a critical role in determining the WZ video coding rate-distortion (RD) performance, notably to raise it to a level as close as possible to the RD performance of standard predictive video coding schemes. Towards this target, efficient motion search algorithms for powerful frame interpolation are much needed at the decoder. In this paper, the RD performance of a Wyner-Ziv video codec is improved by using novel, advanced motion compensated frame interpolation techniques to generate the side information. The development of these type of side information estimators is a difficult problem in WZ video coding, especially because the decoder only has available some reference, decoded frames. Based on the regularization of the motion field, novel side information creation techniques are proposed in this paper along with a new frame interpolation framework able to generate higher quality side information at the decoder. To illustrate the RD performance improvements, this novel side information creation framework has been integrated in a transform domain turbo coding based Wyner-Ziv video codec. Experimental results show that the novel side information creation solution leads to better RD performance than available state-of-the-art side information estimators, with improvements up to 2 dB: moreover, it allows outperforming H.264/AVC Intra by up to 3 dB with a lower encoding complexity. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Ascenso, Joao] Inst Super Engn Lisboa, Inst Telecomunicacoes, P-1959007 Lisbon, Portugal.
   [Pereira, Fernando] Univ Tecn Lisboa, Inst Telecomunicacoes, Inst Super Tecn, P-1049001 Lisbon, Portugal.
C3 Polytechnic Institute of Lisbon; Instituto de Telecomunicacoes;
   Universidade de Lisboa; Instituto de Telecomunicacoes
RP Ascenso, J (corresponding author), Inst Super Engn Lisboa, Inst Telecomunicacoes, R Conselheiro Emidio Navarro 1, P-1959007 Lisbon, Portugal.
EM joao.ascenso@lx.it.pt; fp@lx.it.pt
RI Pereira, Fernando/K-4046-2012; Pereira, Fernando/HNR-7786-2023; Ascenso,
   Joao/B-9024-2008
OI Bernardo Pereira, Fernando Manuel/0000-0001-6100-947X; Ascenso,
   Joao/0000-0001-9902-5926
CR AARON A, 2004, PICTURE CODING S
   [Anonymous], IEEE INT C IM PROC A
   [Anonymous], IEEE INT C IM PROC A
   [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 2005, PROC 5 EURASIP C SPE
   ASCENSO J, 2007, IEEE INT C IM PROC S
   ASCENSO J, 2006, IEEE INT C IM PROC A
   Brites C., 2006, IEEE INT C IM PROC A
   BRITES C, 2007, IEEE INT C PROC SAN
   BRITES C, 2006, IEEE INT C AC SPEECH
   Chan YL, 2001, IEEE T IMAGE PROCESS, V10, P1223, DOI 10.1109/83.935038
   Chen MC, 1998, IEEE T CIRC SYST VID, V8, P147, DOI 10.1109/76.664100
   Chien WJ, 2006, IEEE INT SYMP CIRC S, P5415
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Jing X, 2003, SIGNAL PROCESS, V83, P677, DOI 10.1016/S0165-1684(02)00482-6
   Kim H, 2005, IEEE T CIRC SYST VID, V15, P823, DOI 10.1109/TCSVT.2005.848354
   KLOMP S, 2006, INT C SIGN PROC MULT
   Kubasov D., 2007, IEEE INT WORKSH MULT
   Li Z, 2006, IEEE T CIRC SYST VID, V16, P1430, DOI 10.1109/TCSVT.2006.883511
   Li ZQ, 2006, T NONFERR METAL SOC, V16, P98, DOI 10.1016/S1003-6326(06)60017-4
   MACCHIAVELLO B, 2007, IEEE INT C IM PROC S
   MARTINIAN F, 2006, IEEE WORKSH MULT SIG
   NATARIO L, 2005, INT WORKSH VER LOW B
   PEDRO J, 2007, 6 C TEL PEN PORT MAY
   PEREIRA F, 2007, PAC RIM S IM VID TEC
   PURI R, 2003, IEEE INT C IM PROC B
   *REF SOFTW, 1964, H264AVC REF SOFTW
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   TAGLIASACCHI M, 2007, IEEE INT C AC SPEECH
   TAGLIASACCHI M, 2006, IEEE INT C AC SPEECH
   Tourapis AM, 2005, IEEE T CIRC SYST VID, V15, P119, DOI 10.1109/TCSVT.2004.837021
   TSENG IH, 2005, AS C SIGN SYST PAC G
   WU M, 2006, IEEE INT C MULT EXP
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
NR 35
TC 11
Z9 18
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 600
EP 613
DI 10.1016/j.jvcir.2008.06.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300012
DA 2024-07-18
ER

PT J
AU Song, D
   Chen, CW
AF Song, Daewon
   Chen, Chang Wen
TI Maximum-throughput delivery of SVC-based video over MIMO systems with
   time-varying channel capacity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive channel selection; Adaptive modulation; Scalable video coding;
   SVD-MIMO; Power reallocation; QoS; Channel state information;
   Time-varying channel
ID TRANSMISSION
AB In this paper, we present a novel scalable video transmission strategy over multi-input multi-output (MIMO) wireless systems with time-varying channel capacity. It is a great challenge to simultaneously guarantee the QoS for video delivery and maximize the system throughput over time-varying MIMO channel. We demonstrate that, by making full use of estimated channel state information (CSI) through feedback, a cascade of adaptive operations can be designed to satisfy maximum throughput for scalable video over MIMO systems. These operations include power allocation based on water-filling (WF), adaptive channel selection (ACS), and novel throughput maximizing power reallocation (PR). The proposed ACS transmission scheme enables overall increase in data throughput among enhancement layers by adaptively launching base layer bit-stream to proper sub-channel. Then, after initial power allocation with WF and proper adaptive mode selection, we obtain the surplus power across enhancement layer sub-channels which can be reallocated to some sub-channels by the proposed PR scheme. With such power reallocation, certain enhancement layers will be able to reach new level of QAM modulation through PR so as to maximize the system data throughput. We present in this paper some detailed analysis on these adaptive operations. We also present some simulation results to demonstrate that maximum throughput video transmission over MIMO wireless systems indeed can be achieved based on scalable video coding (SVC) and a sequence of appropriately designed adaptive operations. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Song, Daewon] LG Dacom, Res Inst Technol, IPTV Team, Taejon 305350, South Korea.
   [Chen, Chang Wen] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Song, D (corresponding author), LG Dacom, Res Inst Technol, IPTV Team, Taejon 305350, South Korea.
EM dsong@lgdacom.net; chencw@buffalo.edu
CR Alamouti SM, 1998, IEEE J SEL AREA COMM, V16, P1451, DOI 10.1109/49.730453
   Farshchian M, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P1140, DOI 10.1109/CISS.2006.286637
   Foschini G. J., 1996, Bell Labs Technical Journal, V1, P41, DOI 10.1002/bltj.2015
   Goldsmith AJ, 1997, IEEE T COMMUN, V45, P1218, DOI 10.1109/26.634685
   Gore D., 2003, INTRO SPACE TIME WIR
   *ITU T REC, 2003, 1449610 ISOIEC ITU T
   Ji Z, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P3398
   JI Z, 2003, P IEEE ISCAS, V2
   Kuo CH, 2002, IEEE WCNC, P931, DOI 10.1109/WCNC.2002.993396
   Lin S., 1983, Error Control Coding: Fundamentals and Applications
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Sklar B., 2003, DIGITAL COMMUNICATIO, V2nd
   SONG D, 2006, P IEEE ICIP OCT, P3057
   SONG D, 2006, P SPIE COMMUN NETWOR
   Song DW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1215
   Song D, 2007, IEEE T CIRC SYST VID, V17, P1218, DOI 10.1109/TCSVT.2007.905531
   Song H, 2002, IEEE T MULTIMEDIA, V4, P394, DOI 10.1109/TMM.2002.802845
   TAROKH V, 1990, SELECT AREAS COMMUN, V17, P451
   Telatar E, 1999, EUR T TELECOMMUN, V10, P585, DOI 10.1002/ett.4460100604
   VANZELST A, 2002, P URSI GEN ASSEMBLY
   Vieron J., 2006, JVTT203
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WIEGAND T, 2007, JVTW20I
   Wolniansky P. W., 1998, P IEEE ISSSE
   ZHENG H, 2000, P IEEE ISCAS
NR 26
TC 26
Z9 30
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 520
EP 528
DI 10.1016/j.jvcir.2008.06.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300006
DA 2024-07-18
ER

PT J
AU Lien, CC
   Chiang, CL
   Lee, CH
AF Lien, Cheng-Chang
   Chiang, Chiu-Lung
   Lee, Chang-Hsing
TI Scene-based event detection for baseball videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video shot; semantic scene; baseball event; hidden Markov model
AB A lot of research has lately been focusing on scene analysis in sport videos. By extracting the semantics of successive frames or segmented shots, various kinds of video scenes may be identified. However, general baseball events, e.g., strikeout and ground outs, are hard to be detected because a general baseball event is composed of a series of video scenes and each scene is further composed of several video shots. Hence, the detection of general baseball events has to be developed in terms of scenes to facilitate the retrieval of the required video clips. To do this, the baseball video is firstly segmented into many video shots. Then, various visual features including the image-based features, object-based features, and global motion are extracted to analyze the semantics for each video shot. Each video shot is then classified into the predefined semantic scenes according to its semantics. Finally, the hidden Markov model (HMM) is applied to detect the general baseball events by regarding the classified scenes as observation symbols. The accuracy analysis for the scene classification and event detection are illustrated with a large amount of video data consisting of several hours of video frames. Experimental results show that the proposed system detects the four kinds of general baseball events with reasonable accuracy. (c) 2006 Elsevier Inc. All rights reserved.
C1 Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
C3 Chung Hua University
RP Lien, CC (corresponding author), Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
EM cclien@chu.edu.tw
OI Lee, Chang-Hsing/0000-0002-5761-421X
CR CHEN CH, 2003, CHUNG HUA J SCI ENG, V1, P9
   CHENG F, 2001, P 11 INT C IM AN PRO, P16
   Davies E.R., 2005, MACHINE VISION THEOR, V3rd
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Foresti GL, 2002, IEEE T MULTIMEDIA, V4, P459, DOI 10.1109/TMM.2002.802024
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   Han M., 2002, Proc. ACM Multimedia, P347, DOI [DOI 10.1145/641007.641081, 10.1145/641007.641081]
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Heng WJ, 2002, IEEE T MULTIMEDIA, V4, P434, DOI 10.1109/TMM.2002.806532
   Hua W, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P821, DOI 10.1109/ICME.2002.1035908
   JONES MJ, 1999, P IEEE INT C COMP VI, V1, P3
   Ju SX, 1998, IEEE T CIRC SYST VID, V8, P686, DOI 10.1109/76.718513
   Kwok SH, 1997, IEEE T IMAGE PROCESS, V6, P328, DOI 10.1109/83.551705
   Li BX, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P132, DOI 10.1109/IVL.2001.990867
   LU H, 2001, P IEEE 4 WORKSH MULT, P3
   MIYAUCHI S, 2002, P 16 INT C PATT REC, V2, P11
   MORRIS OJ, 1986, IEE PROC-F, V133, P146, DOI 10.1049/ip-f-1.1986.0025
   Pan H., 2002, P IEEE ICASSP, V4, P13
   PEI SC, 2003, P 16 IPPR C COMP VIS
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang Y., 2002, VIDEO PROCESSING COM
NR 24
TC 30
Z9 30
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 1
EP 14
DI 10.1016/j.jvcir.2006.09.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100001
DA 2024-07-18
ER

PT J
AU Brox, T
   Weickert, J
AF Brox, Thomas
   Weickert, Joachim
TI A TV flow based local scale estimate and its application to texture
   discrimination
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE scale; texture; nonlinear diffusion; segmentation
ID GEODESIC ACTIVE REGIONS; SEGMENTATION; DIFFUSION; EQUIVALENCE; CONTOURS
AB This paper presents a local region based scale measure, which exploits properties of a certain type of nonlinear diffusion, the so-called total variation (TV) flow. During the signal evolution by means of TV flow, pixels change their value with a speed that is inversely proportional to the size of the region they belong to. From this evolution speed, one can derive a local scale estimate based on regions instead of derivative filters. The main motivation for such a scale measure is its application to texture discrimination, in particular the construction of an alternative to Gabor filters. When the scale estimate is combined with the components of the structure tensor, which provides orientation information, it yields a texture feature space of only four dimensions. Like Gabor features, this sparse feature space discriminates textures by means of their orientation and scale, yet the representation of orientation and scale is less redundant. The quality of the feature space containing the new scale measure is evaluated in texture segmentation experiments by comparing results to those achieved with Gabor filters. It turns out that one can gain a total speedup of a factor 2 without loosing any quality concerning the discrimination of textures. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, D-66041 Saarbrucken, Germany.
C3 Saarland University
RP Brox, T (corresponding author), Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, Bldg 27-1, D-66041 Saarbrucken, Germany.
EM brox@mia.uni-saarland.de; weickert@mia.uni-saarland.de
CR ACAR R, 1994, INVERSE PROBL, V10, P1217, DOI 10.1088/0266-5611/10/6/003
   Andreu F, 2002, J FUNCT ANAL, V188, P516, DOI 10.1006/jfan.2001.3829
   Andreu F., 2001, DIFFERENTIAL INTEGRA, V14, P321
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   Bellettini G, 2002, J DIFFER EQUATIONS, V184, P475, DOI 10.1006/jdeq.2001.4150
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Brox T, 2003, LECT NOTES COMPUT SC, V2756, P353
   Brox T, 2003, LECT NOTES COMPUT SC, V2695, P86
   BROX T, 2004, 113 SAARL U
   BROX T, 2004, LECT NOTES COMPUTER, V3022
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DUNN D, 1994, IEEE T PATTERN ANAL, V16, P130, DOI 10.1109/34.273736
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Galun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P716
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   GOMEZ G, 2000, P ICPR, V3, P798
   JEONG H, 1992, IEEE T PATTERN ANAL, V14, P579, DOI 10.1109/34.134062
   JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   KOEPFLER G, 1994, SIAM J NUMER ANAL, V31, P282, DOI 10.1137/0731015
   LINDBERG T, 1994, SCALE THEORY COMPUTE
   Lindeberg T., 1999, HDB COMPUTER VISION, V2, P239
   Malina H Z, 2001, BMC Physiol, V1, P7, DOI 10.1186/1472-6793-1-7
   Mammen E, 1997, ANN STAT, V25, P387
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Meyer Y., 2001, U LECT SERIES AMS, V22
   Morel J.-M., 1994, VARIATIONAL METHODS
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   Pollak I, 2005, IEEE T SIGNAL PROCES, V53, P484, DOI 10.1109/TSP.2004.840786
   Portilla J, 1996, OPT ENG, V35, P2403, DOI 10.1117/1.600814
   RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S
   Rousson M, 2003, PROC CVPR IEEE, P699
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sagiv C, 2001, LECT NOTES COMPUT SC, V2106, P344
   SPORRING J, 1999, 264 FDN RES TECHN
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   STRONG DM, 2005, CAM0502 U CAL
   TAI XC, 1992, NUMER ALGORITHMS, V3, P427
   Tschumperlé D, 2001, PROC CVPR IEEE, P948
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   VANDENBOOMGAARD J, 2002, P TEXTURE 2002
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J., 2002, CONT MATH, P251
   YIP AM, 2003, CAM0359 U CAL
   Zhu SC, 2002, LECT NOTES COMPUT SC, V2353, P793
NR 52
TC 29
Z9 30
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1053
EP 1073
DI 10.1016/j.jvcir.2005.06.001
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, S
   Bovik, AC
AF Liu, Shizhong
   Bovik, Alan C.
TI Foveation embedded DCT domain video transcoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DCT domain; foveation; MPEG video; video transcoding; video composition
ID ALGORITHMS
AB Video transcoding is a key technology to support video communications over heterogeneous networks. Although quite a bit of research effort has been made in video transcoding due to its wide applications, most video transcoding techniques proposed in the literature are optimized based on the simple mean squared error (MSE) metric which does not correlate well with the human visual perception. In this paper, foveation, a property of the HVS, is exploited in video transcoding. The proposed foveation embedded DCT domain video trans, coding can reduce the bit rate without compromising visual quality or achieve better subjective quality for a given bit rate by shaping the compression distortion according to the foveated contrast sensitivity function of the HVS. In addition, fast algorithms for video foveation filtering and DCT domain inverse motion compensation are developed, which significantly improve the efficiency of video transcoding. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Texas, Dept Elect & Comp Engn, Lab Image & Video Engn, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin
RP Bovik, AC (corresponding author), Univ Texas, Dept Elect & Comp Engn, Lab Image & Video Engn, Austin, TX 78712 USA.
EM shizhongL@yahoo.com; bovik@ece.utexas.edu
RI Bovik, Alan/B-6717-2012
OI Bovik, Alan/0000-0001-6067-710X
CR ACHARYA S, 1998, P INT C MULT COMP SY, V4, P25
   [Anonymous], THESIS U TEXAS AUSTI
   Arnow TL, 1996, P SOC PHOTO-OPT INS, V2674, P119, DOI 10.1117/12.237500
   Assunçao PAA, 1998, IEEE T CIRC SYST VID, V8, P953, DOI 10.1109/76.736724
   BANKS MS, 1991, J OPT SOC AM A, V8, P1775, DOI 10.1364/JOSAA.8.001775
   Bors AG, 2000, IEEE T IMAGE PROCESS, V9, P1441, DOI 10.1109/83.855440
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Caelli T., 1981, Visual Perception: Theory and practice
   CHANG EC, 1998, THESIS NEW YORK U NE
   CHANG SF, 1995, IEEE J SEL AREA COMM, V13, P1, DOI 10.1109/49.363151
   CHEN WH, 1976, IMAGE SCI MATH S MON
   CHITPRASERT B, 1990, P IEEE INT C AC SPEE, V3, P1281
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Eng HL, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P758, DOI 10.1109/ICIP.2000.899565
   ENG HL, 1999, P IEEE INT C IM PROC, V3, P284
   Favalli L, 2000, IEEE T CIRC SYST VID, V10, P427, DOI 10.1109/76.836288
   GEISLER WS, 1998, SPIE P, V3299, P294
   Hayes MH., 1996, STAT DIGITAL SIGNAL
   Kan KS, 1998, SIGNAL PROCESS, V67, P223, DOI 10.1016/S0165-1684(98)00039-5
   KEESMAN G, 1996, IMAGE COMMUN, V8, P481
   Kim HY, 1997, IEEE T CONSUM ELECTR, V43, P1074, DOI 10.1109/30.642374
   LEE JB, 1992, IEEE T SIGNAL PROCES, V40, P2061, DOI 10.1109/78.150006
   Lee S, 2001, IEEE T IMAGE PROCESS, V10, P977, DOI 10.1109/83.931092
   Merhav N, 1997, IEEE T CIRC SYST VID, V7, P468, DOI 10.1109/76.585926
   Mitchell J.L., 1997, MPEG VIDEO COMPRESSI
   NGAN KN, 1980, P IEEE INT C COMM SE
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   SHEIKH HR, 2001, P IEEE INT C AC SPEE
   SHEIKH HR, 2001, THESIS U TEXAS AUSTI
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Sikora T, 1996, IEEE T CIRC SYST VID, V6, P157, DOI 10.1109/76.488823
   Song JH, 2000, IEEE T CIRC SYST VID, V10, P767, DOI 10.1109/76.856453
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   WANDELL BA, 1994, FDN VISION
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   WEIMAN CFR, 1990, SPIE P REAL TIME IMA, V1295, P266
   Youn J, 1999, IEEE T MULTIMEDIA, V1, P30, DOI 10.1109/6046.748169
   ZEN H, 1999, P IEEE INT C IM PROC, V4, P25
NR 41
TC 5
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2005
VL 16
IS 6
BP 643
EP 667
DI 10.1016/j.jvcir.2005.04.001
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JQ
UT WOS:000242026600002
DA 2024-07-18
ER

PT J
AU Xie, J
   Chia, LT
AF Xie, J
   Chia, LT
TI Enhancement layer rate control for high bitrate SNR scalable video
   coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE rate control; SNR scalable coding; bit allocation; MPEG-2; video coding
   and transmission
ID BIT ALLOCATION; INTERNET; MODEL
AB Signal-to-noise ratio (SNR) scalability has been incorporated into the MPEG-2 video-coding standard to allow for the delivery of two services with the same spatial and temporal resolution but different levels of quality. Scalable video coding has many advantages, such as its capability of coping with bandwidth variations, high flexibility and so on. However, few accurate rate control schemes for enhancement layer coding have been proposed. In this paper, we will present a novel enhancement layer rate control scheme for MPEG-2 SNR scalable video coding. First, we will address the current necessity and problem of rate control for layered coding. Then through analyzing characteristics of compressed data in the enhancement layer, we will derive our rate control model. The proposed rate control model is applied to a drift-free SNR scalable encoder and we show that it performs well for coding of the enhancementlayer bitstream. (c) 2004 Elsevier Inc. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Div Comp Commun, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chia, LT (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Div Comp Commun, Singapore 639798, Singapore.
EM asltchia@ntu.edu.sg
RI Chia, Liang-Tien/A-9874-2008
CR Arnold JE, 2000, IEEE T CIRC SYST VID, V10, P70, DOI 10.1109/76.825862
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   Gallant M, 2001, IEEE T CIRC SYST VID, V11, P357, DOI 10.1109/76.911161
   GALLANT M, 1999, P 1999 IEEE CAN C EL, V2, P9
   Gersho A., 2003, Vector Quantization and Signal Compression
   Ghanbari M., 1999, VIDEO CODING INTRO S
   Hang HM, 1997, IEEE T CIRC SYST VID, V7, P287
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P970, DOI 10.1109/TCSVT.2002.805511
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   *INF TECH ISO IEC, 1995, GEN COD MOV PICT ASS
   *ISO IEC, 1993, JTC1SC29WG11 ISOIEC
   *ISO IEC, 2001, JTC1SC29WG11N3908 IS
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee BR, 1997, IEEE T CONSUM ELECTR, V43, P614, DOI 10.1109/30.628684
   Miloslavsky E., 1999, P IM PROC ICIP 99, V2, P357
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   RIBASCORBERA J, 1996, P IS T SPIE DIG VID, P302
   Tao B, 2000, IEEE T CIRC SYST VID, V10, P147, DOI 10.1109/76.825868
   WANG L, 2000, SPIE, V2501
   Wang Y, 2001, DIGITAL VIDEO PROCES
   Wilson D, 1999, IEEE T IMAGE PROCESS, V8, P1435, DOI 10.1109/83.791968
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
NR 25
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2005
VL 16
IS 2
BP 159
EP 179
DI 10.1016/j.jvcir.2004.07.001
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 915VY
UT WOS:000228340700003
DA 2024-07-18
ER

PT J
AU Cai, JF
   Chen, CW
AF Cai, JF
   Chen, CW
TI Joint source-channel coding of GGD sources with allpass filtering source
   reshaping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE joint source-channel coding; source reshaping; bit allocation
ID ROBUST QUANTIZATION
AB An optimal joint source-channel coding (OJSCC) scheme is developed for encoding memoryless generalized Gaussian distribution (GGD) sources and transmission over noisy channels, including memoryless channels and bursty channels. In particular; we are able to incorporate both transition probability and bit error rate of a bursty channel model into an end-to-end rate-distortion (R-D) function. This R-D function results in an optimum tradeoff between source coding accuracy and channel error protection under a fixed transmission rate. Based on the results of OJSCC, we further proposed a robust joint source-channel coding (RJSCC) scheme based on a combination of OJSCC with allpass filtering source reshaping. Experimental results based on a broad class of GGD sources suggest that the RJSCC scheme consistently outperforms the OJSCC scheme when the shape factor, a parameter of GGD, is less than 2.0. The comparison of RJSCC with the state-of-the-art robust quantization (RQ) [IEEE Trans. Image Process. 7 (1998) 406-505] shows that RJSCC is comparable with RQ at low bit rate and significantly better than RQ at high bit rate. In addition, an image transmission system using RJSCC demonstrates that the RJSCC system can be efficiently employed in practical applications. (C) 2004 Elsevier Inc. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   Florida Inst Technol, Dept Elect & Comp Engn, Melbourne, FL 32901 USA.
C3 Nanyang Technological University; Florida Institute of Technology
RP Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM asjfcai@ntu.edu.sg; cchen@fit.edu
RI Cai, Jianfei/A-3691-2011
OI Cai, Jianfei/0000-0002-9444-3763
CR Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   CAI J, 1998, P IEEE ISCAS98 JUN M
   Cai JF, 2000, IEEE T CIRC SYST VID, V10, P962, DOI 10.1109/76.867934
   Chande V, 2000, IEEE J SEL AREA COMM, V18, P850, DOI 10.1109/49.848239
   Chen Q, 1998, IEEE T IMAGE PROCESS, V7, P496, DOI 10.1109/83.663494
   FARVARDIN N, 1987, IEEE T INFORM THEORY, V33, P827, DOI 10.1109/TIT.1987.1057373
   GIROD B, 2002, P 2002 TYRRH INT WOR
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Kim J, 2003, IEEE T IMAGE PROCESS, V12, P121, DOI 10.1109/TIP.2003.809006
   LI H, 1999, P SPIE VIS COMM IM P, P63
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Nosratinia A, 2003, IEEE T COMMUN, V51, P186, DOI 10.1109/TCOMM.2003.809256
   POPAT K, 1992, IEEE T COMMUN, V40, P1670, DOI 10.1109/26.179928
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   Ruf MJ, 1999, IEEE T IMAGE PROCESS, V8, P305, DOI 10.1109/83.748887
   Sherwood PG, 1997, IEEE SIGNAL PROC LET, V4, P189, DOI 10.1109/97.596882
   Shin J, 2001, IEEE T MULTIMEDIA, V3, P219, DOI 10.1109/6046.923821
   SHOHAM Y, 1988, IEEE T ASSP, V36
   STANKOVIC V, 2003, P IEEE WCNC 03 NEW O
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   STUHLMULLER K, 1999, PACK VID WORKSH, P99
   TANABE N, 1992, IEEE J SELECT AREAS, V10
   WANG HS, 1995, IEEE T VEH TECHNOL, V44, P163, DOI 10.1109/25.350282
   WANG S, 2000, P SPIE EL IM 2000 JA
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   WESTERINK PH, 1988, P ICASSP 88, P757
   ZHENG H, 1998, P IEEE ICIP98
NR 28
TC 2
Z9 3
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2005
VL 16
IS 1
BP 19
EP 37
DI 10.1016/j.jvcir.2004.01.003
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 885SN
UT WOS:000226177300002
DA 2024-07-18
ER

PT J
AU Hasler, D
   Süsstrunk, S
AF Hasler, D
   Süsstrunk, S
TI Mapping colour in image stitching applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE digital panoramic photography; scene-referred image encoding; motion
   estimation; pose estimation; colour correction; Laguerre OECF;
   polynomial OECF; white-balancing; mosaicing; vignetting
AB Digitally, panoramic pictures can be assembled from several individual, overlapping photographs. While the geometric alignment of these photographs has retained a lot of attention from the computer vision community, the mapping of colour, i.e., the correction of colour mismatches, has not been studied extensively. In this paper, we analyze the colour rendering of today's digital photographic systems, and propose a method to correct for colour differences. The colour correction consists in retrieving linearized relative scene referred data from uncalibrated images by estimating the opto-electronic conversion function (OECF) and correcting for exposure, white-point, and vignetting variations between the individual pictures. Different OECF estimation methods are presented and evaluated in conjunction with motion estimation. The resulting panoramas, shown on examples using slides and digital photographs, yield much-improved visual quality compared to stitching using only motion estimation. Additionally, we show that colour correction can also improve the geometrical alignment. (C) 2003 Elsevier Inc. All rights reserved.
C1 Swiss Fed Inst Technol, Audiovisual Commun Lab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Swiss Fed Inst Technol, Audiovisual Commun Lab, CH-1015 Lausanne, Switzerland.
EM david.hasler@bluewin.ch; sabine.susstrunk@epfl.ch
RI cai, bo/G-1491-2010; Süsstrunk, Sabine/I-2466-2013
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], OPTICAL SYSTEMS DESI
   [Anonymous], 1997, SIGGRAPH, DOI DOI 10.1145/258734.258884
   Guestrin C, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P19, DOI 10.1109/IROS.1998.724590
   Hanna KJ, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P38, DOI 10.1109/MMCS.1999.779117
   HASLER D, 2001, THESIS SWISS FEDERAL
   HOLM J, 2002, COLOUR ENG ACHIEVING, P179
   HUNT R.W. G., 1995, REPROD COLOUR PHOTOG
   Hunt RW G., 1998, MEASURING COLOUR
   *IEC, 1999, 6196621 ISO
   Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P234, DOI 10.1109/IM.1997.603871
   Majumder A, 2000, IEEE VISUAL, P117, DOI 10.1109/VISUAL.2000.885684
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434
   Robertson M. A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P159, DOI 10.1109/ICIP.1999.817091
   Rushmeier H., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P99, DOI 10.1109/IM.1999.805339
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Seber G. A. F., 1989, Non-linear Regression
   Süsstrunk S, 2001, PROC SPIE, V4300, P172
   VONKRIES J, 1993, SPIE MILESTONE SE MS, V77
   Yu YZ, 1999, COMP GRAPH, P215
   1999, ISO16067 WD
NR 22
TC 24
Z9 29
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2004
VL 15
IS 1
BP 65
EP 90
DI 10.1016/j.jvcir.2003.06.001
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 772PV
UT WOS:000188851200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Han, G
   Wang, YF
   Liu, JX
   Zeng, FY
AF Han, Guang
   Wang, Yingfan
   Liu, Jixin
   Zeng, Fanyu
TI Low-light images enhancement and denoising network based on unsupervised
   learning multi-stream feature modeling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low-light enhancement; Generative adversarial network; Multi-stream
   modeling; Multi-scale feature fusion
ID HISTOGRAM EQUALIZATION; REPRESENTATION; RETINEX; GAP
AB Inspired by the generative adversarial networks EnlightenGAN, this paper proposes a novel low-light images Enhancement and Denoising model based on unsupervised learning Multi-Stream feature modeling (MSED). The model has two stages: generator network and discriminator network. Generator network includes global and local feature modeling network. First, Swin Transformer Block is innovatively introduced in the global feature modeling of generator network stage. It makes the interaction between the image and the convolutional kernel related to the image content. Its shift window mechanism can model the global feature dependency of the input image with less memory consumption, and extract the color, texture, and shape features of the image, thereby effectively suppressing noise and artifacts. Second, in the local feature modeling, a multi-scale image and feature fusion branch is added. It not only extracts reduced features from large-scale low-light images, but also extracts features from multiple downsampled low-light images, and then combines the two through attention and DSFF. By utilizing the complementary information of the reduced features and downsampled images, various underexposure/ overexposure phenomena caused by low-light images can be effectively avoided. In the discriminator network stage, the deep/shallow feature aggregation module is added to enhance the discrimination ability, and the inconsistencies are suppressed by learning the contradictory information of spatial filter, so that the shallow representation of information and the deep semantic information can guide each other. Thanks to the synergy of the above three innovative work, compared with many existing advanced low-light images enhancement models, MSED can achieve SOTA level performance on several public datasets. However, when dealing with low-light images with blurry content caused by rapid motion, MSED still cannot effectively restore their detailed information.
C1 [Han, Guang; Wang, Yingfan; Liu, Jixin; Zeng, Fanyu] Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Han, G (corresponding author), Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
EM hanguang8848@njupt.edu.cn; 1020010527@njupt.edu.net;
   liujixin@njupt.edu.cn; zengfanyu@njupt.edu.cn
RI xiao, wei/KCK-6954-2024; LIU, Jixin/AHC-0596-2022
FU Natural Science Foundation of China NSFC [61871445, 61302156]; Key R
   amp; D Foundation Project of Jiangsu province [BE2016001-4]
FX This work was supported by the Natural Science Foundation of China NSFC
   under Grants 61871445, 61302156; Key R & D Foundation Project of Jiangsu
   province under Grant BE2016001-4
CR Ao Yueyuan, 2021, 2021 18th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP), P184, DOI 10.1109/ICCWAMTIP53232.2021.9674147
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen MY, 2022, IEEE SENS J, V22, P17646, DOI 10.1109/JSEN.2021.3066200
   Cotogni M, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109249
   Cui YD, 2022, IEEE T INTELL TRANSP, V23, P722, DOI 10.1109/TITS.2020.3023541
   Dang-Nguyen D.T., 2015, IEEE Trans. Multimedia, P73
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elsayed G., 2020, P INT C MACH LEARN, P2868
   Fan CM, 2022, IEEE IMAGE PROC, P3878, DOI 10.1109/ICIP46576.2022.9897503
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Fu QX, 2020, Arxiv, DOI arXiv:2004.10447
   Fu XY, 2021, INT J COMPUT VISION, V129, P1691, DOI 10.1007/s11263-020-01428-6
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo X., 2020, IJCV, P4513
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hou YK, 2011, IEEE T IMAGE PROCESS, V20, P268, DOI 10.1109/TIP.2010.2052281
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiang HY, 2019, IEEE I CONF COMP VIS, P7323, DOI 10.1109/ICCV.2019.00742
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jolicoeur-Martineau A, 2018, Arxiv, DOI arXiv:1807.00734
   Khalid R, 2015, 2015 FIFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION AND COMMUNICATION TECHNOLOGY AND ITS APPLICATIONS (DICTAP), P86, DOI 10.1109/DICTAP.2015.7113176
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361
   Liu YJ, 2020, IEEE ACCESS, V8, P145740, DOI 10.1109/ACCESS.2020.3014910
   Lu K, 2021, IEEE T MULTIMEDIA, V23, P4093, DOI 10.1109/TMM.2020.3037526
   Lyu S, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Minyan Zheng, 2021, 2021 IEEE 7th International Conference on Cloud Computing and Intelligent Systems (CCIS), P403, DOI 10.1109/CCIS53392.2021.9754604
   Moran Sean, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12823, DOI 10.1109/CVPR42600.2020.01284
   Naik D. A., 2021, ETI 4.0 2021, P1
   Naik SK, 2003, IEEE T IMAGE PROCESS, V12, P1591, DOI 10.1109/TIP.2003.819231
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P7518, DOI 10.1109/TCSVT.2022.3188991
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P6347, DOI 10.1109/TCSVT.2022.3161103
   Pan ZQ, 2022, IEEE T MULTIMEDIA, V24, P519, DOI 10.1109/TMM.2021.3054509
   Pang YW, 2019, PROC CVPR IEEE, P7328, DOI 10.1109/CVPR.2019.00751
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Shashipreeth Racherla Balaji, 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1124, DOI 10.1109/ICCES51350.2021.9489104
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A., 2017, Adv. Neural Inf. Proces. Syst., P145
   Vaswani A, 2021, PROC CVPR IEEE, P12889, DOI 10.1109/CVPR46437.2021.01270
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2015, DOI 10.1145/3343031.3350983
   Yang J, 2016, INT C PATT RECOG, P751, DOI 10.1109/ICPR.2016.7899725
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P3461, DOI 10.1109/TIP.2021.3062184
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yu W., 2022, P AAAI C ART INT, V36
   Yuan Y., 2019, arXiv
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zhu AQ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102962
   Zhu C., 2021, IEEE Trans. Multimedia, P685
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou C, 2021, PROC CVPR IEEE, P11820, DOI 10.1109/CVPR46437.2021.01165
NR 71
TC 1
Z9 1
U1 8
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103932
DI 10.1016/j.jvcir.2023.103932
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S8LW4
UT WOS:001073638600001
DA 2024-07-18
ER

PT J
AU Ding, R
   Zeng, HQ
   Wen, H
   Huang, HL
   Cheng, S
   Hou, JH
AF Ding, Rui
   Zeng, Huanqiang
   Wen, Hao
   Huang, Hailiang
   Cheng, Shan
   Hou, Junhui
TI Screen content video quality assessment based on spatiotemporal sparse
   feature
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Screen content video; Spatiotemporal sparse feature; Three dimensional
   Difference of Gaussian; Dictionary learning
ID IMAGE; SIMILARITY; REPRESENTATION
AB In recent years, the explosive growth of application scenarios have occurred in screen content videos (SCVs), in which the SCVs are unavoidably suffered from the quality degradation and the video quality assessment (VQA) of the SCVs becomes very essential. In view of this, a full-reference VQA algorithm, called the spatiotemporal sparse feature-based model (SSFM) is proposed in this paper, aiming to give a precise and efficient quality evaluation about the distorted SCVs. Note that the SCVs are full of edge information which the human eyes are highly sensitive to, and the sparse coding can provide accurate quantitative predictions which are consistent with the perception resulted from the cerebral cortex in various receptive field models of the visual cortex. With these considerations, three dimensional Difference of Gaussian (3D-DOG) filter and 3D Sparse Dictionary are developed to extract multi-scale spatiotemporal features and obtain spatiotemporal sparse features respectively, from the reference and distorted SCVs. Based on these features, the spatiotemporal sparse feature similarity can be measured and followed by generating the quality scores of the distorted SCVs under evaluation. Compared to other classic and state-of-the-art image/video quality evaluation metrics, the experimental results of the proposed SSFM on the screen content video database (SCVD) are more consistent with the perceived evaluation of SCVs according to the human visual system (HVS).
C1 [Ding, Rui; Zeng, Huanqiang; Wen, Hao; Cheng, Shan] Huaqiao Univ, Sch Engn, Quanzhou, Peoples R China.
   [Huang, Hailiang] Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
   [Hou, Junhui] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Huaqiao University; Xiamen University; City University of Hong Kong
RP Zeng, HQ (corresponding author), Huaqiao Univ, Sch Engn, Quanzhou, Peoples R China.
EM zeng0043@hqu.edu.cn
RI Ding, Rui/JSL-0652-2023; Ding, Rui/AAL-7714-2021; Zeng,
   Huanqiang/U-2017-2018
OI Ding, Rui/0000-0003-2880-9736; Hou, Junhui/0000-0003-3431-2021
FU National Key R&D Program of China [2021YFE0205400]; National Natural
   Science Foundation of China [61976098]; Key Program of National Natural
   Science Foundation of Fujian Province [2023J02022]; Natural Science
   Foundation for Outstanding Young Scholars of Fujian Province
   [2022J06023]; Natural Science Foundation of Fujian Province [2022J01294,
   2022J05065]; Collaborative Innovation Platform Project of
   Fuzhou-Xiamen-Quanzhou National Independent Innovation Demonstration
   Zone [2021FX03]; Key Science and Technology Project of Xiamen City
   [3502Z20231005]; Natural Science Foundation of Xiamen City
   [3502Z20227028]
FX This work was supported in part by the National Key R&D Program of China
   under the grant 2021YFE0205400, in part by the National Natural Science
   Foundation of China under the grant 61976098, in part by Key Program of
   National Natural Science Foundation of Fujian Province under the grant
   2023J02022, in part by the Natural Science Foundation for Outstanding
   Young Scholars of Fujian Province under the grant 2022J06023, in part by
   the Natural Science Foundation of Fujian Province under the grants
   2022J01294 and 2022J05065, in part by the Collaborative Innovation
   Platform Project of Fuzhou-Xiamen-Quanzhou National Independent
   Innovation Demonstration Zone under the grant 2021FX03, in part by the
   Key Science and Technology Project of Xiamen City under the grant
   3502Z20231005, and in part by the Natural Science Foundation of Xiamen
   City under the grant 3502Z20227028.
CR Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Cheng S, 2020, IEEE T IMAGE PROCESS, V29, P8636, DOI 10.1109/TIP.2020.3018256
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Fu Y, 2018, IEEE T CIRC SYST VID, V28, P2428, DOI 10.1109/TCSVT.2018.2854176
   Gu K, 2018, IEEE T VIS COMPUT GR, V24, P2689, DOI 10.1109/TVCG.2017.2771284
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Li DQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2351, DOI 10.1145/3343031.3351028
   Li T, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102030
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mather G., 2016, FDN SENSATION PERCEP
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pearson D, 1998, P SOC PHOTO-OPT INS, V3299, P16, DOI 10.1117/12.320109
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Varga D, 2019, NEURAL PROCESS LETT, V50, P2595, DOI 10.1007/s11063-019-10036-6
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Vu PV, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013016
   WALD G, 1945, SCIENCE, V101, P653, DOI 10.1126/science.101.2635.653
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu HN, 2022, LECT NOTES COMPUT SC, V13666, P538, DOI 10.1007/978-3-031-20068-7_31
   Wu JJ, 2019, IEEE T MULTIMEDIA, V21, P2738, DOI 10.1109/TMM.2019.2908377
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang JC, 2021, IEEE T IND INFORM, V17, P2204, DOI 10.1109/TII.2020.2998818
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Zeng HQ, 2022, IEEE T IMAGE PROCESS, V31, P6175, DOI 10.1109/TIP.2022.3206621
   Zhang Z, 2015, ARXIV
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhou M., 2009, Adv. Neural Inf. Process. Syst., V22
NR 35
TC 1
Z9 1
U1 12
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103912
DI 10.1016/j.jvcir.2023.103912
EA AUG 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S1GL7
UT WOS:001068721000001
DA 2024-07-18
ER

PT J
AU Ren, MJ
   Huang, XD
   Li, WH
   Liu, J
AF Ren, Minjie
   Huang, Xiangdong
   Li, Wenhui
   Liu, Jing
TI Multi-loop graph convolutional network for multimodal conversational
   emotion recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Conversational emotion recognition; Multi-modal sentiment analysis;
   Graph convolutional network
AB Emotion recognition in conversations (ERC) has gained increasing research attention in recent years due to its wide applications in a surge of emerging tasks, such as social media analysis, dialog generation, and recommender systems. Since constituent utterances in a conversation are closely semantic-related, the constituent utterances' emotional states are also closely related. In our consideration, this correlation could serve as a guide for the emotion recognition of constituent utterances. Accordingly, we propose a novel approach named Semantic-correlation Graph Convolutional Network (SC-GCN) to take advantage of this correlation for the ERC task in multimodal scenario. Specifically, we first introduce a hierarchical fusion module to model the dynamics among the textual, acoustic and visual features and fuse the multimodal information. Afterward, we construct a graph structure based on the speaker and temporal dependency of the dialog. We put forward a novel multi-loop architecture to explore the semantic correlations by the self-attention mechanism and enhance the correlation information via multiple loops. Through the graph convolution process, the proposed SC-GCN finally obtains a refined representation of each utterance, which is used for the final prediction. Extensive experiments are conducted on two benchmark datasets and the experimental results demonstrate the superiority of our SC-GCN.
C1 [Ren, Minjie; Huang, Xiangdong; Li, Wenhui; Liu, Jing] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Li, WH (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM liwenhui@tju.edu.cn
RI Wh, Lee/HSG-1021-2023; LI, Wenhui/JCD-9947-2023; lu, lala/GQQ-3784-2022
OI lu, lala/0000-0002-6080-8074
FU National Key Research and Development Program of China [2021YFF0901600];
   National Nat-ural Science Foundation of China [62101325, U21B2024,
   U22A2068]; China Postdoctoral Science Foundation [2022M712369]
FX Acknowledgments This work was supported in part by the National Key
   Research and Development Program of China (2021YFF0901600) , the
   National Nat-ural Science Foundation of China (62101325, U21B2024,
   U22A2068) , the China Postdoctoral Science Foundation (2022M712369) .
CR Baffour AA, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103368
   Bradbury James, 2017, INT C LEARN REPR
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Caramalau R, 2021, PROC CVPR IEEE, P9578, DOI 10.1109/CVPR46437.2021.00946
   Chang T.-Y., 2020, P 1 WORKSH KNOWL EXT, P74
   Chang WY, 2021, IEEE INT CONF COMP V, P1468, DOI 10.1109/ICCVW54120.2021.00170
   Chen SY, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1597
   Ding W., 2022, J VIS COMMUN IMAGE R
   Ghosal D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2470
   Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P154
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2594
   Hazarika Devamanyu, 2018, Proc Conf, V2018, P2122, DOI 10.18653/v1/n18-1193
   He JW, 2021, PROC CVPR IEEE, P5295, DOI 10.1109/CVPR46437.2021.00526
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hu Jingwen, 2021, ACLIJCNLP, V1, P5666
   Hu LM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P754
   Kingma D. P., 2014, arXiv
   Li W, 2022, NEUROCOMPUTING, V467, P73, DOI 10.1016/j.neucom.2021.09.057
   Lian Z, 2021, IEEE-ACM T AUDIO SPE, V29, P985, DOI 10.1109/TASLP.2021.3049898
   Lin ZJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P121
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Ma H, 2021, NEURAL COMPUT APPL, V33, P2685, DOI 10.1007/s00521-020-05063-7
   Ma QW, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3855
   Mai SJ, 2020, AAAI CONF ARTIF INTE, V34, P164
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Nguyen BX, 2021, IEEE COMPUT SOC CONF, P3487, DOI 10.1109/CVPRW53098.2021.00388
   Pan LM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1463
   Parikh AP., 2016, EMNLP
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P527
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Sankar A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2535, DOI 10.1145/3442381.3450120
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Shang YM, 2022, INFORM SCIENCES, V584, P269, DOI 10.1016/j.ins.2021.10.047
   Shen WZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1551
   Shen WZ, 2021, AAAI CONF ARTIF INTE, V35, P13789
   Sun JH, 2020, PROC CVPR IEEE, P657, DOI 10.1109/CVPR42600.2020.00074
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XZ, 2021, INFORM SCIENCES, V545, P223, DOI 10.1016/j.ins.2020.08.017
   Wen HL, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103178
   Xia Y, 2021, PROC CVPR IEEE, P11343, DOI 10.1109/CVPR46437.2021.01119
   Xing SL, 2022, IEEE T AFFECT COMPUT, V13, P1426, DOI 10.1109/TAFFC.2020.3005660
   Yan JJ, 2016, IEEE T MULTIMEDIA, V18, P1319, DOI 10.1109/TMM.2016.2557721
   Yang ZL, 2019, ADV NEUR IN, V32
   Young T, 2018, AAAI CONF ARTIF INTE, P4970
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zadeh Amir, 2017, P 2017 C EMP METH NA, P1103
   Zhang D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5415
   Zhang Y, 2019, IEEE IJCNN, P1, DOI DOI 10.1109/ijcnn.2019.8851942
NR 50
TC 1
Z9 1
U1 4
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103846
DI 10.1016/j.jvcir.2023.103846
EA MAY 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J5FF9
UT WOS:001009868300001
DA 2024-07-18
ER

PT J
AU Wu, LT
   Zhang, X
   Zhu, DJ
   Yang, WK
AF Wu, Letian
   Zhang, Xian
   Zhu, Dejun
   Yang, Wankou
TI BFANet: Effective segmentation network for low altitude high-resolution
   urban scene image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Urban scene segmentation; Real-time semantic segmentation; Bi-lateral
   network; Convolutional neural network
ID SEMANTIC SEGMENTATION
AB The semantic segmentation of low altitude high-resolution urban scene images taken by UAV plays an important role in city management. However, such images have the characteristics of inter-class homogeneity and intra-class heterogeneity. How to segment these images quickly and accurately is still challenging. In this paper, we propose a novel double-branch network. For the challenge of inter-class homogeneity, a boundary flow module is designed to enhance the flow of latent semantic information between two branches by imposing boundary constraints between classes. To alleviate intra-class heterogeneity, a context extraction module based on adaptive dynamic fusion is designed, which effectively captures the long-term relationship of features with very low parameters. Experiments on two typical datasets show that our approach achieves the best balance between accuracy and speed. Specifically, we achieve 65.8% mIoU and 74.1% mIoU on UAVid test set and UDD validation set respectively, and 60FPS on an NVIDIA TITAN Xp.
C1 [Wu, Letian; Zhang, Xian; Yang, Wankou] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Zhu, Dejun] Tsinghua Univ, Dept Hydraul Engn, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
C3 Southeast University - China; Tsinghua University
RP Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Zhu, DJ (corresponding author), Tsinghua Univ, Dept Hydraul Engn, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
EM wkyang@seu.edu.cn
OI Yang, Wankou/0000-0002-6385-6776
FU National Natural Science Founda-tion of China [62276061, 62006041]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Nosnos. 62276061 and 62006041.
CR [Anonymous], 2021, ARXIV
   Audebert N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040368
   Audebert Nicolas, 2017, ARXIV
   Chen LC, 2018, Arxiv, DOI arXiv:1802.02611
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen Y., 2018, PRCV
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong YD, 2021, Arxiv, DOI [arXiv:2101.06085, DOI 10.48550/ARXIV.2101.06085]
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li E, 2015, IEEE T GEOSCI REMOTE, V53, P4483, DOI 10.1109/TGRS.2015.2400462
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li R, 2021, ISPRS J PHOTOGRAMM, V181, P84, DOI 10.1016/j.isprsjprs.2021.09.005
   Li XT, 2021, Arxiv, DOI arXiv:2002.10120
   Li XT, 2020, Arxiv, DOI arXiv:2007.10035
   Li XT, 2021, PROC CVPR IEEE, P4215, DOI 10.1109/CVPR46437.2021.00420
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu Y., 2018, ARXIV
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P7092, DOI 10.1109/TGRS.2017.2740362
   Matikainen L, 2011, REMOTE SENS-BASEL, V3, P1777, DOI 10.3390/rs3081777
   Mingmin Zhen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13663, DOI 10.1109/CVPR42600.2020.01368
   Orsic M, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107611
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Sherrah J, 2016, Arxiv, DOI arXiv:1606.02585
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Tambe RG, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103141
   Wang D, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102852
   Wang L., 2021, SANET SCALE AWARE NE
   Wang LB, 2022, Arxiv, DOI arXiv:2106.12413
   Wei YN, 2017, IEEE GEOSCI REMOTE S, V14, P709, DOI 10.1109/LGRS.2017.2672734
   Wen Y, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103311
   Yang M.Y., 2021, ISPRS J PHOTOGRAMM
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu C., 2018, arXiv, DOI DOI 10.48550/ARXIV.1808.00897
   Zhang G, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8120582
   Zhang W., 2022, arXiv, DOI 10.48550/arXiv.2204.05525
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2018, Arxiv, DOI [arXiv:1704.08545, DOI 10.48550/ARXIV.1704.08545]
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhuang JT, 2019, IEEE INT CONF COMP V, P847, DOI 10.1109/ICCVW.2019.00113
NR 44
TC 0
Z9 0
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103847
DI 10.1016/j.jvcir.2023.103847
EA MAY 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J1DT8
UT WOS:001007087800001
DA 2024-07-18
ER

PT J
AU Cao, F
   Wang, TJ
   Guo, DD
   Li, J
   Qin, C
AF Cao, Fang
   Wang, Tianjun
   Guo, Daidou
   Li, Jian
   Qin, Chuan
TI Screen-shooting resistant image watermarking based on lightweight neural
   network in frequency domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robust watermarking; Screen -shooting; Lightweight neural network;
   Frequency domain; Efficiency
ID ROBUST
AB Currently, digital mobile devices, especially smartphones, can be used to acquire information conveniently through photograph taking. To protect information security in this case, we propose an efficient screen-shooting resistant watermarking scheme via deep neural network (DNN) in the frequency domain to achieve additional information embedding and source tracing. Specifically, we enhance the imperceptibility of watermarked images and the robustness against various attacks in real scene by computing the residual watermark message and encoding it with the original image using a lightweight neural network in the DCT domain. In addition, a noise layer is designed to simulate the photometric and radiometric effects of screen-shooting transfer. During the training process, the enhancing network is used to highlight the coding features of distorted images and improve the accuracy of extracted watermark message. Experimental results demonstrate that our scheme not only effectively ensures the balance between the imperceptibility of watermark embedding and the robustness of watermark extraction, but also significantly improves computational efficiency compared with some state-of-theart schemes.
C1 [Cao, Fang; Wang, Tianjun] Shanghai Maritime Univ, Coll Informat Engn, Shanghai 200135, Peoples R China.
   [Guo, Daidou; Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Li, Jian] Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Shandong Prov Key Lab Comp Networks, Jinan 250353, Peoples R China.
   [Cao, Fang] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Shanghai Maritime University; University of Shanghai for Science &
   Technology; Qilu University of Technology; Guangxi Normal University
RP Li, J (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Shandong Prov Key Lab Comp Networks, Jinan 250353, Peoples R China.
EM fangcao@shmtu.edu.cn; 202030310009@stu.shmtu.edu.cn;
   211240061@st.usst.edu.cn; lijian20@gmail.com; qin@usst.edu.cn
FU National Natural Science Foundation of China [61902239]; Natural Science
   Foundation of Shandong [ZR2020MF054]; Research Fund of Guangxi Key Lab
   of Multi-source Information Mining amp; Security [MIMS20-03]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61902239, in part by the Natural Science
   Foundation of Shandong under Grant ZR2020MF054, and in part by Research
   Fund of Guangxi Key Lab of Multi-source Information Mining & Security
   under Grant MIMS20-03. The authors would like to thank anonymous
   reviewers for their valuable suggestions which helped to improve this
   article.
CR Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Chaurasia A, 2017, Arxiv, DOI arXiv:1707.03718
   Deng B, 2022, MULTIMED TOOLS APPL, V81, P32841, DOI 10.1007/s11042-022-12738-x
   Dong LX, 2023, PROD OPER MANAG, V32, P1112, DOI 10.1111/poms.13915
   Fan YC, 2009, IEEE T INSTRUM MEAS, V58, P2026, DOI 10.1109/TIM.2008.2006722
   Fang H, 2022, IEEE T MULTIMEDIA, V24, P955, DOI 10.1109/TMM.2021.3061801
   Fang H, 2019, IEEE T INF FOREN SEC, V14, P1403, DOI 10.1109/TIFS.2018.2878541
   Ge S., 2022, arXiv, DOI [10.1007/s11042-023-15048-y, DOI 10.1007/S11042-023-15048-Y]
   Geng LF, 2020, J REAL-TIME IMAGE PR, V17, P631, DOI 10.1007/s11554-020-00941-8
   Gugelmann D, 2018, INT CONF CYBER CONFL, P391, DOI 10.23919/CYCON.2018.8405027
   Jia J, 2022, IEEE T CYBERNETICS, V52, P7094, DOI 10.1109/TCYB.2020.3037208
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kingma D. P., 2014, arXiv
   Li L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196554
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Pramila A, 2017, MULTIMED TOOLS APPL, V76, P16063, DOI 10.1007/s11042-016-3895-z
   press.liacs.nl, MIRFLICKR
   Qin C, 2023, IEEE MULTIMEDIA, V30, P28, DOI 10.1109/MMUL.2022.3213004
   Schaber P, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700295
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Sun YJ, 2018, IEEE T IMAGE PROCESS, V27, P4160, DOI 10.1109/TIP.2018.2834737
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tancik M., 2019, P IEEE CVF C COMP VI, P2117
   Thongkor K, 2018, J VIS COMMUN IMAGE R, V53, P146, DOI 10.1016/j.jvcir.2018.03.005
   Wang J.Y., 2019, J VIS COMMUN IMAGE R, V64, P1
   Wengrowski E., 2016, P IEEE WINT C APPL C, DOI [10.1109/WACV.2016.7477721, DOI 10.1109/WACV.2016.7477721]
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Xiong Cheng, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P2881, DOI 10.1145/3503161.3548247
   Xu K, 2020, PROC CVPR IEEE, P1737, DOI 10.1109/CVPR42600.2020.00181
   Yin ZX, 2022, IEEE IMAGE PROC, P3958, DOI 10.1109/ICIP46576.2022.9897413
   Yu C, 2020, AAAI CONF ARTIF INTE, V34, P1120
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zheng BL, 2020, IEEE T CIRC SYST VID, V30, P3982, DOI 10.1109/TCSVT.2019.2931045
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 37
TC 7
Z9 7
U1 3
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103837
DI 10.1016/j.jvcir.2023.103837
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7SO2
UT WOS:001018403200001
DA 2024-07-18
ER

PT J
AU da Silva, VL
   Lérida, JL
   Sarret, M
   Valls, M
   Giné, F
AF da Silva, Vitor Luiz
   Lerida, Josep Luis
   Sarret, Marta
   Valls, Magda
   Gine, Francesc
TI Residual spatiotemporal convolutional networks for face anti-spoofing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face anti-spoofing; Residual networks; Channel-separated networks;
   Spoofing detection; Biometrics
AB Previous deep learning studies on Face Anti-Spoofing (FAS) systems have exploited many aspects of spatial data for face anti-spoofing detection, but few have used end-to-end spatiotemporal approaches to solving FAS problems. This paper aims to provide new perspectives for end-to-end spatiotemporal systems to deal with FAS problems, using five residual spatiotemporal convolutional models. This work analyzes and detects which network is the most appropriate for identifying spoofing on video-based identification systems. These five models were adapted to specific features of the FAS problem and its performance (accuracy and computational cost) were tested with OULU-NPU and SiW datasets. In addition, a cross-dataset validation was carried out. The experimentation shows the strengths and weaknesses of each model against the dependency on the temporal dimension, data initialization and different FAS environment conditions. According to experimentation, residual networks outperform the state-of-the-art, being the model based on decomposing spatial and temporal flow the best option.
C1 [da Silva, Vitor Luiz; Lerida, Josep Luis; Valls, Magda; Gine, Francesc] Univ Lleida, Polytech Sch, Lleida 25001, Spain.
   [da Silva, Vitor Luiz; Sarret, Marta] LleidaNetworks Serv Telemat, Lleida 25003, Spain.
C3 Universitat de Lleida
RP da Silva, VL (corresponding author), Univ Lleida, Polytech Sch, Lleida 25001, Spain.
EM vitor.dasilva@udl.cat
RI Gine, Francesc/I-5446-2012; Silva, Vitor/KMY-8281-2024; da Silva Verbel,
   Vitor Luiz/D-5102-2015
OI da Silva Verbel, Vitor Luiz/0000-0002-3296-2752
FU [PID2021-124613OB-I00];  [PID2020-113614RB-C22]; 
   [MCIN/AEI/10.13039/501100011033]
FX Acknowledgments This work was supported by the projects
   PID2021-124613OB-I00 and PID2020-113614RB-C22 funded by
   MCIN/AEI/10.13039/501100011033.
CR [Anonymous], 2021, MODEL ZOO VIDEO MODE
   [Anonymous], 2021, TORCHVISION PYTORCH
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bary E., 2020, MARKETWATCH B ZOOM M
   Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688, DOI 10.1109/BTAS.2017.8272758
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chen BL, 2021, IEEE T INF FOREN SEC, V16, P2477, DOI 10.1109/TIFS.2021.3055018
   Chen HN, 2020, IEEE T INF FOREN SEC, V15, P578, DOI 10.1109/TIFS.2019.2922241
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   Cho JH, 2019, IEEE I CONF COMP VIS, P4793, DOI 10.1109/ICCV.2019.00489
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dean J., 2015, NIPS DEEP LEARNING R
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Finances Online, 2021, 54 BAS VID WEB CONF
   Gan JY, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P1, DOI 10.1109/ICMIP.2017.9
   George A, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI 10.1109/IJCB52358.2021.9484333
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jobanputra C, 2019, PROCEDIA COMPUT SCI, V155, P698, DOI 10.1016/j.procs.2019.08.100
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Kay W., 2017, CORR, V06950
   Kim T, 2019, IEEE INT CONF COMP V, P494, DOI 10.1109/ICCVW.2019.00062
   Komulainen Jukka, 2013, 2013 IEEE 6 INT C BI
   Kondratyuk D, 2021, PROC CVPR IEEE, P16015, DOI 10.1109/CVPR46437.2021.01576
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li X, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304873
   Lin WY, 2021, Arxiv, DOI arXiv:2005.04490
   Lin WY, 2018, AAAI CONF ARTIF INTE, P7130
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Marcel Sebastien., 2019, Advances in Computer Vision and Pattern Recognition, VSecond
   Nagpal C, 2019, IEEE IJCNN
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484
   Qin YX, 2022, IEEE T PATTERN ANAL, V44, P6311, DOI 10.1109/TPAMI.2021.3091167
   Qin YX, 2020, AAAI CONF ARTIF INTE, V34, P11916
   Sun WY, 2020, IEEE T INF FOREN SEC, V15, P3181, DOI 10.1109/TIFS.2020.2985530
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509
   Wang Z, 2022, IEEE T INF FOREN SEC, V17, P1254, DOI 10.1109/TIFS.2022.3158062
   Xu ZQ, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P141, DOI 10.1109/ACPR.2015.7486482
   Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362
   Yu ZT, 2022, Arxiv, DOI [arXiv:2106.14948, DOI 10.48550/ARXIV.2106.14948]
   Yu ZT, 2021, IEEE SIGNAL PROC LET, V28, P1290, DOI 10.1109/LSP.2021.3089908
   Yu ZT, 2021, IEEE T PATTERN ANAL, V43, P3005, DOI 10.1109/TPAMI.2020.3036338
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zheng WY, 2021, IEEE T SMART GRID, V12, P2685, DOI 10.1109/TSG.2020.3048957
   Zitong Yu, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P285, DOI 10.1109/TBIOM.2021.3065526
   Zitong Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P557, DOI 10.1007/978-3-030-58571-6_33
NR 61
TC 2
Z9 2
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103744
DI 10.1016/j.jvcir.2022.103744
EA JAN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8M0SS
UT WOS:000924185700001
DA 2024-07-18
ER

PT J
AU Wang, Q
   Piao, Y
AF Wang, Qi
   Piao, Yan
TI Depth estimation of supervised monocular images based on semantic
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular depth estimation; Semantic segmentation; Shared parameters;
   Multi-scale feature fusion
AB In recent years, the research method of depth estimation of target images using Convolutional Neural Networks (CNN) has been widely recognized in the fields of artificial intelligence, scene understanding and three-dimensional (3D) reconstruction. The fusion of semantic segmentation information and depth estimation will further improve the quality of acquired depth images. However, how to deeply combine image semantic in-formation with image depth information and use image edge information more accurately to improve the ac-curacy of depth image is still an urgent problem to be solved. For this purpose, we propose a novel depth estimation model based on semantic segmentation to estimate the depth of monocular images in this paper. Firstly, a shared parameter model of semantic segmentation information and depth estimation information is built, and the semantic segmentation information is used to guide depth acquisition in an auxiliary way. Then, through the multi-scale feature fusion module, the feature information contained in the neural network on different layers is fused, and the local feature information and global feature information are effectively used to generate high-resolution feature maps, so as to achieve the goal of improving the quality of depth image by optimizing the semantic segmentation model. The experimental results show that the model can fully extract and combine the image feature information, which improves the quality of monocular depth vision estimation. Compared with other advanced models, our model has certain advantages.
C1 [Wang, Qi; Piao, Yan] Changchun Univ Sci & Technol, Coll Elect & Informat Engn, Changchun 130022, Peoples R China.
C3 Changchun University of Science & Technology
RP Piao, Y (corresponding author), Changchun Univ Sci & Technol, Coll Elect & Informat Engn, Changchun 130022, Peoples R China.
EM piaoyan@cust.edu.cn
RI Wang, Qi/B-9602-2012
FU Jilin Provincial Science and Technology Department [20220201062GX]
FX This work was supported in part by the Project of the Jilin Provincial
   Science and Technology Department under Grant 20220201062GX.
CR Bai L., 2022, J JILIN U ENG TECHNO, DOI [10.13229/j.cnki.jdxbgxb20220126, DOI 10.13229/J.CNKI.JDXBGXB20220126]
   Bian D., 2022, J CHENGDU TECHNOLOGI, P2095, DOI j.Cnki.51-1747/tn.2022.01.004
   Burge J, 2014, J VISION, V14, DOI 10.1167/14.2.1
   Cao ZY, 2022, NEUROCOMPUTING, V492, P34, DOI 10.1016/j.neucom.2022.04.006
   Chen W, 2016, ADV NEUR IN, V29
   Eigen D, 2014, ADV NEUR IN, V27
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Gan YK, 2018, LECT NOTES COMPUT SC, V11207, P232, DOI 10.1007/978-3-030-01219-9_14
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Hambarde P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3120130
   Hambarde P, 2020, IEEE IMAGE PROC, P1441, DOI 10.1109/ICIP40778.2020.9190985
   Hambarde P, 2020, IEEE T COMPUT IMAG, V6, P806, DOI 10.1109/TCI.2020.2981761
   Hambarde P, 2019, IEEE IMAGE PROC, P989, DOI [10.1109/icip.2019.8803027, 10.1109/ICIP.2019.8803027]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Horn B. K., 1970, SHAPE SHADING METHOD
   [胡云峰 Hu Yunfeng], 2019, [自动化学报, Acta Automatica Sinica], V45, P1261
   Johnston A, 2020, PROC CVPR IEEE, P4755, DOI 10.1109/CVPR42600.2020.00481
   Kline J, 2020, PROCEEDINGS OF THE 2020 32ND INTERNATIONAL TELETRAFFIC CONGRESS (ITC 32), P1, DOI [10.1109/ITC3249928.2020.00009, 10.1007/978-3-030-58565-5_35]
   Konrad J., 2012, Proc. 3D Cinematography Workshop (3DCINE'12) at IEEE CVPR, P16, DOI DOI 10.1109/CVPRW.2012.6238903
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar ACS, 2018, IEEE COMPUT SOC CONF, P396, DOI 10.1109/CVPRW.2018.00066
   Kuznietsov Y, 2021, IEEE WINT CONF APPL, P2906, DOI 10.1109/WACV48630.2021.00295
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Lee Jin Han, 2019, arXiv
   Lei ZY, 2021, NEUROCOMPUTING, V423, P343, DOI 10.1016/j.neucom.2020.11.002
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024
   Masoumian A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145353
   Moukari M, 2018, IEEE IMAGE PROC, P2940, DOI 10.1109/ICIP.2018.8451408
   Mousavian A, 2016, INT CONF 3D VISION, P611, DOI 10.1109/3DV.2016.69
   Patil V, 2020, IEEE ROBOT AUTOM LET, V5, P6813, DOI 10.1109/LRA.2020.3017478
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Sener O, 2018, ADV NEUR IN, V31
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Snavely N, 2008, PROC CVPR IEEE, P2617
   Song CX, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185389
   Wang LJ, 2020, PROC CVPR IEEE, P538, DOI 10.1109/CVPR42600.2020.00062
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Watson J, 2019, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2019.00225
   Wu FP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247045
   Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yang N, 2018, LECT NOTES COMPUT SC, V11212, P835, DOI 10.1007/978-3-030-01237-3_50
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Yiyi Liao, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5059, DOI 10.1109/ICRA.2017.7989590
   Yu ZH, 2020, PROC CVPR IEEE, P1946, DOI 10.1109/CVPR42600.2020.00202
   Yuan H., 2019, RES MONOCULAR DEPTH, DOI [10.27426/d.cnki.gxtdu.2019.000592, DOI 10.27426/D.CNKI.GXTDU.2019.000592]
   Yun Jingyang, 2022, Computer Engineering and Applications, P215, DOI 10.3778/j.issn.1002-8331.2009-0061
   Zhang JJ, 2020, SCI CHINA TECHNOL SC, V63, P2028, DOI 10.1007/s11431-020-1632-x
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang Y., 2022, SCI TECHNOLOGY ENG, V22, P2761
   Zhang Y, 2022, SCI CHINA TECHNOL SC, V65, P1098, DOI 10.1007/s11431-021-1948-3
   Zhang Z, 2020, SCI CHINA TECHNOL SC, V63, P2011, DOI 10.1007/s11431-020-1692-3
NR 61
TC 8
Z9 8
U1 15
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103753
DI 10.1016/j.jvcir.2023.103753
EA JAN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H1MW9
UT WOS:000993683400001
DA 2024-07-18
ER

PT J
AU Li, GH
   Yao, H
   Le, YF
   Qin, C
AF Li, Guihao
   Yao, Heng
   Le, Yanfen
   Qin, Chuan
TI Recaptured screen image identification based on vision transformer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Recaptured screen images; Image forensics; Demoir?ing operation; Vision
   transformer; Recapture identification
ID CAMERA MODEL; FORENSICS
AB Due to the copyright issues often involved in the recapture of LCD screen content, recaptured screen image identification has received lots of concerns in image source forensics. This paper analyzes the characteristics of convolutional neural network (CNN) and vision transformer (ViT) in extracting features and proposes a cascaded network structure that combines local-feature and global-feature extraction modules to detect the recaptured screen image from original images with or without demoireing operation. We first extract the local features of the input images with five convolutional layers and feed the local features into the ViT to enhance the local perception capability of the ViT module, and further extract the global features of the input images. Through thorough experiments, our method achieves a detection accuracy rate of 0.9691 in our generated dataset and 0.9940 in the existing mixture dataset, both showing the best performance among the compared methods.
C1 [Li, Guihao; Yao, Heng; Le, Yanfen; Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Yao, H (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM aufelgh@126.com; hyao@usst.edu.cn; leyanfen@usst.edu.cn; qin@usst.edu.cn
RI Yao, Heng/J-9457-2019
OI Yao, Heng/0000-0002-3784-4157
CR Amerini I., 2017, 2017 IEEE WORKSH INF, P1
   Anjum A, 2020, MULTIMED TOOLS APPL, V79, P6965, DOI 10.1007/s11042-019-08418-y
   [Anonymous], 2017, ELECT IMAGING
   Cao H, 2010, INT CONF ACOUST SPEE, P1790, DOI 10.1109/ICASSP.2010.5495419
   Chen BJ, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102967
   Chen ML, 2022, IEEE T INF FOREN SEC, V17, P457, DOI 10.1109/TIFS.2022.3142993
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fanfani M, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102586
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2022, PROCEEDING 36 AAAI C
   Kingma D. P., 2014, arXiv
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu BL, 2018, Arxiv, DOI arXiv:1804.03809
   Lyu QY, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103057
   Marra F, 2018, SIGNAL PROCESS-IMAGE, V65, P240, DOI 10.1016/j.image.2018.04.007
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Mayer O, 2020, IEEE J-STSP, V14, P1049, DOI 10.1109/JSTSP.2020.3001516
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Radford A, 2021, PR MACH LEARN RES, V139
   Ruihan Li, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P107, DOI 10.1007/978-3-319-31960-5_10
   Shullani D, 2022, IEEE SIGNAL PROC LET, V29, P1112, DOI 10.1109/LSP.2022.3167631
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YJ, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420540117
   Sun YJ, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540034
   Sun YJ, 2018, IEEE T IMAGE PROCESS, V27, P4160, DOI 10.1109/TIP.2018.2834737
   Thongkamwitoon T, 2015, IEEE T INF FOREN SEC, V10, P953, DOI 10.1109/TIFS.2015.2392566
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tsai MJ, 2013, IEEE INT SYMP CIRC S, P2347, DOI 10.1109/ISCAS.2013.6572349
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JW, 2019, IEEE T CIRC SYST VID, V29, P2775, DOI 10.1109/TCSVT.2018.2867786
   Wang K, 2017, DIGIT INVEST, V23, P75, DOI 10.1016/j.diin.2017.10.001
   Yang PP, 2017, LECT NOTES COMPUT SC, V10082, P119, DOI 10.1007/978-3-319-53465-7_9
   Yao H, 2022, IEEE T MULTIMEDIA, V24, P640, DOI 10.1109/TMM.2021.3056879
   Yao H, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102795
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107430
   Yin J., 2012, P 20 ACM INT C MULT, P1113
   Yu IJ, 2017, IEEE IMAGE PROC, P4093, DOI 10.1109/ICIP.2017.8297052
   Yue HJ, 2021, NEUROCOMPUTING, V456, P352, DOI 10.1016/j.neucom.2021.05.099
   Yue HJ, 2021, IEEE T CIRC SYST VID, V31, P49, DOI 10.1109/TCSVT.2020.2969984
   Zhao W., 2018, INT WORKSH DIT WAT
   Zhao W, 2018, IEICE T INF SYST, VE101D, P3263, DOI 10.1587/transinf.2018EDL8091
   Zheng Y, 2020, IEEE T INF FOREN SEC, V15, P620, DOI 10.1109/TIFS.2019.2926777
   Zhu N., 2022, IMAGE COMMUN, V104
   Zhuang PY, 2021, IEEE T INF FOREN SEC, V16, P2986, DOI 10.1109/TIFS.2021.3070444
NR 47
TC 4
Z9 4
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103692
DI 10.1016/j.jvcir.2022.103692
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200010
DA 2024-07-18
ER

PT J
AU Huang, L
   Kuang, D
   Li, CL
   Zhuang, YJ
   Duan, SH
   Zhou, XY
AF Huang, Li
   Kuang, Da
   Li, Cheng-long
   Zhuang, Yu-jian
   Duan, Shao-hua
   Zhou, Xiao-yi
TI A self-embedding secure fragile watermarking scheme with high quality
   recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fragile watermarking; Tamper detection and localization; Image recover;
   Cloud storage
ID IMAGE TAMPERING DETECTION; POB NUMBER SYSTEM; LOCALIZATION
AB In recent years, with the development of cloud storage, more and more people upload images to the cloud for storage. However, confidentiality and integrity issues may arise during transmission and storage to the cloud. Aiming at these security problems, a fragile watermarking scheme based on the encrypted domain is proposed. A watermark is divided into two types, one is for detection, the other is for recovery. After embedding the two types of watermarks into the host image, the watermarked image will be transferred to the cloud for storage. A threelevel tamper detection mechanism is used in the detection process, and the first-level tamper detection can be processed in the cloud. While in recovery process, a mechanism of "block-level detection, pixel-level recovery" is proposed to recover the tampered area. The experimental results show that the watermarked image has greatly changed the original image and guarantees the confidentiality. The three-level tamper detection mechanism can accurately detect the tampered area, the image can be effectively restored in different situations, when the tampering rate is as high as 80%, the average PSNR reaches 34.62 dB, and the average SSIM is higher than 0.93.
C1 [Huang, Li; Kuang, Da; Li, Cheng-long; Zhuang, Yu-jian; Duan, Shao-hua; Zhou, Xiao-yi] Hainan Univ, Sch Cyberspace Secur, Sch Cryptol, 58 Renmin Ave, Haikou 570228, Hainan, Peoples R China.
C3 Hainan University
RP Zhou, XY (corresponding author), Hainan Univ, Sch Cyberspace Secur, Sch Cryptol, 58 Renmin Ave, Haikou 570228, Hainan, Peoples R China.
EM xy.zhou.xy@gmail.com
OI Duan, Shaohua/0000-0002-1847-3864; Zhuang, Yujian/0009-0002-0597-8430; ,
   xiaoyi/0000-0003-3777-9479
CR Abdelhakim A, 2019, MULTIMED TOOLS APPL, V78, P32523, DOI 10.1007/s11042-019-07986-3
   AlShehri L, 2020, MULTIMED TOOLS APPL, V79, P29199, DOI 10.1007/s11042-020-09441-0
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Feng B, 2020, MOBILE NETW APPL, V25, P82, DOI 10.1007/s11036-018-1186-9
   Gul E, 2020, MULTIMED TOOLS APPL, V79, P31239, DOI 10.1007/s11042-020-09548-4
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Haghighi BB, 2019, INFORM SCIENCES, V486, P204, DOI 10.1016/j.ins.2019.02.055
   Hemida O, 2020, MULTIMED TOOLS APPL, V79, P18695, DOI 10.1007/s11042-020-08727-7
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Huang R, 2019, MULTIMED TOOLS APPL, V78, P26701, DOI 10.1007/s11042-019-07802-y
   Lee CF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102267
   Li M, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103166
   Li YW, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7100955
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Meng LZ, 2021, MULTIMED TOOLS APPL, V80, P711, DOI 10.1007/s11042-020-09686-9
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Puteaux P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103085
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rajput V, 2020, MULTIMED TOOLS APPL, V79, P35519, DOI 10.1007/s11042-019-07971-w
   Rhayma H, 2019, MULTIMED TOOLS APPL, V78, P14067, DOI 10.1007/s11042-019-7244-x
   Sarkar D, 2020, MULTIMED TOOLS APPL, V79, P17761, DOI 10.1007/s11042-020-08669-0
   Shen JJ, 2020, MULTIMED TOOLS APPL, V79, P25969, DOI 10.1007/s11042-020-09254-1
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010036
   Singh P, 2018, IEEE T CIRC SYST VID, V28, P2116, DOI 10.1109/TCSVT.2017.2716828
   Singh P, 2018, MULTIMED TOOLS APPL, V77, P12581, DOI 10.1007/s11042-017-4906-4
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Sreekumar A., 2009, Hack, V2009, P33
   Su QT, 2020, MULTIMED TOOLS APPL, V79, P30023, DOI 10.1007/s11042-020-09436-x
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040548
   Weng SW, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2020.102932
   Xiang YP, 2019, SIGNAL PROCESS, V162, P282, DOI 10.1016/j.sigpro.2019.04.022
   Xie X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153020
NR 39
TC 7
Z9 7
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103437
DI 10.1016/j.jvcir.2022.103437
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200008
DA 2024-07-18
ER

PT J
AU Golts, A
   Schechner, YY
AF Golts, Alex
   Schechner, Yoav Y.
TI Image compression optimized for 3D reconstruction by utilizing deep
   neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compression; 3D reconstruction; Deep learning; Recurrent neural
   networks
AB Computer vision tasks are often expected to be executed on compressed images. Classical image compression standards like JPEG 2000 are widely used. However, they do not account for the specific end-task at hand. Motivated by works on recurrent neural network (RNN)-based image compression and three-dimensional (3D) reconstruction, we propose unified network architectures to solve both tasks jointly. These joint models provide image compression tailored for the specific task of 3D reconstruction. Images compressed by our proposed models, yield 3D reconstruction performance superior as compared to using JPEG 2000 compression. Our models significantly extend the range of compression rates for which 3D reconstruction is possible. We also show that this can be done highly efficiently at almost no additional cost to obtain compression on top of the computation already required for performing the 3D reconstruction task.
C1 [Golts, Alex] Rafael Adv Def Syst LTD, Haifa, Israel.
   [Schechner, Yoav Y.] Technion Israel Inst Technol, Viterbi Fac Elect Engn, Haifa, Israel.
C3 RAFAEL ADVANCED DEFENSE SYSTEMS; Technion Israel Institute of Technology
RP Golts, A (corresponding author), Rafael Adv Def Syst LTD, Haifa, Israel.
EM alex@golts.net; yoav@ee.technion.ac.il
FU Taub Foundation; BMBF; European Research Council (ERC) under the
   European Union [810370]; Technion Autonomous Systems Program (TASP);
   European Research Council (ERC) [810370] Funding Source: European
   Research Council (ERC)
FX We would like to thank Christopher Choy for his responsiveness to our
   questions about his work, as well as Alona Golts for her helpful
   insights. Yoav Schechner is the Mark and Diane Seiden Chair in Science
   at the Technion. He is a Landau Fellow-supported by the Taub Foundation.
   His work is conducted in the Ollendorff Minerva Center. Minvera is
   funded through the BMBF. This project is funded by the European Research
   Council (ERC) under the European Union's Horizon 2020 research and
   innovation program (grant agreement No 810370: CloudCT) and the Technion
   Autonomous Systems Program (TASP) .
CR Alain G., 2014, ARXIV14062989
   [Anonymous], 2016, P INT C LEARN REPR
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 1997, NEURAL COMPUT
   Ball e J., 2016, ARXIV PREPRINT ARXIV
   Ball e J., 2018, ARXIV PREPRINT ARXIV
   Bayer J.S, 2015, THESIS TU MUNCHEN
   Bellard Fabrice, 2018, Bpg image format
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Facciolo G, 2017, IEEE COMPUT SOC CONF, P1542, DOI 10.1109/CVPRW.2017.198
   Fuhrmann Simon, 2014, P WORKSH GRAPH CULT, P11, DOI [10.1016/j.cag.2015.09.003, DOI 10.2312/GCH.20141299]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Indradjad A., 2019, IOP Conference Series: Earth and Environmental Science, V280, DOI 10.1088/1755-1315/280/1/012031
   Karpathy A, 2015, UNREASONABLE EFFECIV
   Liu J, 2019, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2019.00323
   Minnen D, 2018, ADV NEUR IN, V31
   Olah C., 2015, colah. github. io
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8
   Renwick JD, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P729, DOI 10.1109/WF-IoT.2016.7845501
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi XJ, 2015, ADV NEUR IN, V28
   Shyam P., 2017, P INT C MACH LEARN, P3173
   Sukthankar R., 2015, INT C LEARN REPR
   Theis L., 2017, ICLR
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   Vetrivel A, 2015, ISPRS J PHOTOGRAMM, V105, P61, DOI 10.1016/j.isprsjprs.2015.03.016
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391
NR 31
TC 6
Z9 7
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103208
DI 10.1016/j.jvcir.2021.103208
EA JUL 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Brito, AD
   Vieira, MB
   Villela, SM
   Tacon, H
   Chaves, HD
   Maia, HD
   Concha, DT
   Pedrini, H
AF Brito, Andre de Souza
   Vieira, Marcelo Bernardes
   Villela, Saulo Moraes
   Tacon, Hemerson
   Chaves, Hugo de Lima
   Maia, Helena de Almeida
   Concha, Darwin Ttito
   Pedrini, Helio
TI Weighted voting of multi-stream convolutional neural networks for
   video-based action recognition using optical flow rhythms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural networks; Action recognition; Optical flow rhythm
ID LSTM
AB Two of the most important premises of an ensemble are the diversity of its components and how to combine their votes. In this paper, we propose a multi-stream architecture based on the weighted voting of convolutional neural networks to deal with the problem of recognizing human actions in videos. A major challenge is how to include temporal aspects into this kind of approach. A key step in this direction is the selection of features that characterize the complexity of human actions in time. In this context, we propose a new stream, Optical Flow Rhythm, besides using other streams for diversity. To combine the streams, a voting system based on a new weighted average fusion method is introduced. In this scheme, the weights of classifiers are defined by an optimization process led by a metaheuristic. Experiments conducted on the UCF101 and HMDB51 datasets demonstrate that our method is comparable to state-of-the-art approaches.
C1 [Brito, Andre de Souza; Vieira, Marcelo Bernardes; Villela, Saulo Moraes; Tacon, Hemerson; Chaves, Hugo de Lima] Univ Fed Juiz de Fora, Dept Comp Sci, Juiz De Fora, Brazil.
   [Maia, Helena de Almeida; Concha, Darwin Ttito; Pedrini, Helio] Univ Estadual Campinas, Inst Comp, Campinas, Brazil.
C3 Universidade Federal de Juiz de Fora; Universidade Estadual de Campinas
RP Villela, SM (corresponding author), Univ Fed Juiz de Fora, Dept Comp Sci, Juiz De Fora, Brazil.
EM andre.brito@ice.ufjf.br; marcelo.bernardes@ufjf.edu.br;
   saulo.moraes@ufjf.edu.br; hemerson@ice.ufjf.br;
   marcelo.bernardes@ufjf.edu.br; helena.maia@liv.ic.unicamp.br;
   darwin.ttito@liv.ic.unicamp.br; helio@ic.unicamp.br
RI Villela, Saulo Moraes/X-8342-2019
OI Villela, Saulo Moraes/0000-0001-5958-4766; de Souza Brito,
   Andre/0000-0002-8518-6849; Maia, Helena/0000-0002-8253-9004
FU CAPES; FAPEMIG [CEX-APQ-01744-15]; FAPESP [2017/09160-1, 2017/12646-3];
   CNPq [305169/2015-7]
FX The authors would like to thank CAPES, FAPEMIG (grant CEX-APQ-01744-15)
   , FAPESP (grants #2017/09160-1 and #2017/12646-3) and CNPq (grant
   #305169/2015-7) for their financial support, as well as NVIDIA
   Corporation for the donation of two Titan Xp graphical cards (GPU Grant
   Program) .
CR ACEVEDO J, 2007, 9 INT WORK C ART NEU, P284
   [Anonymous], 2015, CORR
   [Anonymous], 2015, J MOBILE MULTIMEDIA
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], 2016, VISUAL COMPUT
   [Anonymous], 2012, CoRR
   Arif S, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11020042
   Aslani S., 2013, INT J EL COMP ENG SY, V7, P1252
   Bai S, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102759
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chernbumroong S, 2015, IEEE J BIOMED HEALTH, V19, P282, DOI 10.1109/JBHI.2014.2313473
   Chollet F, 2015, KERAS
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Concha DT, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P473, DOI 10.1109/ICMLA.2018.00077
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Kahani R, 2019, MULTIMED TOOLS APPL, V78, P21673, DOI 10.1007/s11042-019-7429-3
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Khalid MU, 2018, INT C PATT RECOG, P3210, DOI 10.1109/ICPR.2018.8546131
   Khani N., 4 INT C PATT REC IM, P80
   Kim H, 2001, MULTIMED TOOLS APPL, V15, P227, DOI 10.1023/A:1012452131892
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kong Y., 2018, ARXIV180611230
   KOULMAS C, 1994, OMEGA-INT J MANAGE S, V22, P41, DOI 10.1016/0305-0483(94)90006-X
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Ravanbakhsh M., 2015, ARXIV PREPRINT ARXIV
   Sevilla-Lara L, 2016, PROC CVPR IEEE, P3889, DOI 10.1109/CVPR.2016.422
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Souza M.R., 2018, THESIS U CAMPINAS CA
   Sun L, 2017, IEEE I CONF COMP VIS, P2166, DOI 10.1109/ICCV.2017.236
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tacon H, 2019, LECT NOTES COMPUT SC, V11619, P351, DOI 10.1007/978-3-030-24289-3_26
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Valio FB, 2011, LECT NOTES COMPUT SC, V7042, P157, DOI 10.1007/978-3-642-25085-9_18
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang H, 2017, MULTIMED TOOLS APPL, V76, P15065, DOI 10.1007/s11042-017-4514-3
   Wang J, 2018, PROC CVPR IEEE, P1149, DOI 10.1109/CVPR.2018.00126
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang Y., 2017, ARXIV PREPRINT ARXIV, P1
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   Wu Z., 2015, ABS150906086 CORR
   Ye, 2015, P 5 ACM INT C MULT R
   Yuan Y, 2019, AAAI CONF ARTIF INTE, P9167
   Zhu JG, 2018, INT C PATT RECOG, P645, DOI 10.1109/ICPR.2018.8545710
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
NR 68
TC 6
Z9 6
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103112
DI 10.1016/j.jvcir.2021.103112
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700013
DA 2024-07-18
ER

PT J
AU Chu, WT
   Huang, SH
AF Chu, Wei-Ta
   Huang, Si-Heng
TI Multi-label image recognition by using semantics consistency, object
   correlation, and multiple samples
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-label image recognition; Object correlation; Semantics
   consistency; Multiple samples
ID CLASSIFICATION
AB An image can be annotated from the local perspective, based on objects visually present. An image can also be annotated from the global perspective, based on implicit emotion or meanings derived from it. We propose three points relatively little studied before. First, semantics remain the same even if the image is manipulated by some geometric processes. Second, object correlation is important in image labelling. We propose to use a standard recurrent neural network to take object sequences in random orders. Third, we observe that some entity can be represented by multiple image samples, and multiple samples can be jointly considered to improve recognition performance. These three points are implemented in a network that jointly considers global and local information. With comprehensive evaluation studies, we verify that a simple network with these points is effective and is able to achieve competitive performance compared to the state of the arts.
C1 [Chu, Wei-Ta] Natl Cheng Kung Univ, Tainan, Taiwan.
   [Huang, Si-Heng] Natl Chung Cheng Univ, Chiayi, Taiwan.
C3 National Cheng Kung University; National Chung Cheng University
RP Chu, WT (corresponding author), Natl Cheng Kung Univ, Tainan, Taiwan.
EM wtchu@gs.ncku.edu.tw
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU Qualcomm through a Taiwan University Research Collaboration Project;
   Ministry of Science and Technology, Taiwan [108-2221-E-006-227MY3,
   107-2923-E-194-003-MY3, 109-2218-E-002-015]
FX This work was funded in part by Qualcomm through a Taiwan University
   Research Collaboration Project and in part by the Ministry of Science
   and Technology, Taiwan, under grant 108-2221-E-006-227MY3,
   107-2923-E-194-003-MY3, and 109-2218-E-002-015.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.37
   [Anonymous], 2014, ICLR
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Chen TS, 2018, AAAI CONF ARTIF INTE, P6730
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Chu W. -T., 2017, MUSA2 2017 PROC WORK, P39, DOI DOI 10.1145/3132515.3132516
   Ding XM, 2016, IEEE T MULTIMEDIA, V18, P1616, DOI 10.1109/TMM.2016.2572000
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang Y, 2015, IEEE T MULTIMEDIA, V17, P1923, DOI 10.1109/TMM.2015.2476658
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Lin, 2019, P IEEE INT C COMP VI
   Liu H, 2018, IEEE T PATTERN ANAL, V40, P2546, DOI 10.1109/TPAMI.2017.2734779
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Liu YC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P700, DOI 10.1145/3240508.3240567
   Mikec, 2014, P INT CONV INF COMM
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shah RR, 2016, KNOWL-BASED SYST, V108, P102, DOI 10.1016/j.knosys.2016.05.022
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MK, 2015, PROC CVPR IEEE, P4100, DOI 10.1109/CVPR.2015.7299037
   Tao, 2018, P AAAI C ART INT
   Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wu ZX, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P791, DOI 10.1145/2964284.2964328
   Xiao Y, 2016, 2016 IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (CEFC)
   Xu LL, 2014, IEEE DATA MINING, P1067, DOI 10.1109/ICDM.2014.125
   Yu Y, 2019, IEEE T NEUR NET LEAR, V30, P1250, DOI 10.1109/TNNLS.2018.2856253
   Yuille, 2017, P BRIT MACH VIS C
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
NR 34
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103067
DI 10.1016/j.jvcir.2021.103067
EA MAR 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400003
DA 2024-07-18
ER

PT J
AU Zhou, JZ
   Zhang, XM
   Lin, YB
   Liu, Y
AF Zhou, Jinzhao
   Zhang, Xingming
   Lin, Yubei
   Liu, Yang
TI Facial expression recognition using frequency multiplication network
   with uniform rectangular features?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Uniform rectangular features; Frequency
   multiplication network
ID EMOTION RECOGNITION; CLASSIFICATION; UNIT
AB Facial expression recognition (FER) is a popular research field in cognitive interaction systems and artificial intelligence. Many deep learning methods achieve outstanding performances at the expense of enormous computation workload. Limiting their application in small devices or offline scenarios. To cope with this drawback, this paper proposes the Frequency Multiplication Network (FMN), a deep learning method operating in the frequency domain that significantly reduces network capacity and computation workload. By taking advantage of the frequency domain conversion, this novel deep learning method utilizes multiplication layers for effective feature extraction. In conjunction with the Uniform Rectangular Features (URF), our method further improves the performance and reduces the training effort. On three publicly available datasets (CK+, Oulu, and MMI), our method achieves substantial improvements in comparison to popular approaches.
C1 [Zhou, Jinzhao; Zhang, Xingming; Liu, Yang] South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp Sci & Engn, B3 Bldg, Guangzhou 510006, Peoples R China.
   [Lin, Yubei] South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Software Engn, B7 Bldg, Guangzhou 510006, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Lin, YB (corresponding author), South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Software Engn, B7 Bldg, Guangzhou 510006, Peoples R China.
EM cszhou_jinzhao@mail.scut.edu.cn; cszxm@scut.edu.cn; yupilin@scut.edu.cn;
   cs_yangliu@mail.scut.edu.cn
CR Amiriparian S, 2017, INTERSPEECH, P3512, DOI 10.21437/Interspeech.2017-434
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], 2014, DISCRETE COSINE TRAN
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen JX, 2013, PATTERN RECOGN LETT, V34, P1964, DOI 10.1016/j.patrec.2013.02.002
   Chen Z., 2015, ARXIV PREPRINT ARXIV
   Chengbin Zeng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2069, DOI 10.1109/ICPR.2010.509
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Ekman P., 2002, FACIAL ACTION CODING
   Fu Y., 2008, P 2008 INT C CONT BA, P127, DOI DOI 10.1145/1386352.1386373
   Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   Hassan MM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0948-z
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu M, 2019, IEEE ACCESS, V7, P118435, DOI 10.1109/ACCESS.2019.2936976
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Jiang L, 2019, AAAI CONF ARTIF INTE, P8521
   Jung H., 2015, ARXIV PREPRINT ARXIV
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kingma D. P., 2014, arXiv
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Li HB, 2017, IEEE T MULTIMEDIA, V19, P2816, DOI 10.1109/TMM.2017.2713408
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liliana DY, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (ICECOS), P231, DOI 10.1109/ICECOS.2018.8605222
   Lin XD, 2016, IEEE T MULTIMEDIA, V18, P1480, DOI 10.1109/TMM.2016.2571999
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu Y, 2020, IEEE T COGN DEV SYST, V12, P311, DOI 10.1109/TCDS.2019.2917711
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   MARTUCCI SA, 1994, IEEE T SIGNAL PROCES, V42, P1038, DOI 10.1109/78.295213
   Mita T, 2008, IEEE T PATTERN ANAL, V30, P1257, DOI 10.1109/TPAMI.2007.70767
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paisitkriangkrai S., 2010, Computer Vision-ACCV 2010, P460, DOI DOI 10.1007/978-3-642-19318-7_36
   Pal M, 2014, INT CO SIG PROC COMM
   Pramerdorfer C, 2016, ARXIV
   Sajjanhar A, 2018, 2018 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P583
   Samadiani N, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5764
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sikka K, 2016, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2016.602
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SY, 2018, IEEE INT CONF AUTOMA, P158, DOI 10.1109/FG.2018.00032
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang Y, 2018, IEEE ACCESS, V6, P42532, DOI 10.1109/ACCESS.2018.2858278
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Trabelsi C., 2019, RETRIEVING SIGNALS D
   Uddin MZ, 2017, COMPUT ELECTR ENG, V63, P114, DOI 10.1016/j.compeleceng.2017.04.019
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Valstar MF, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, pJ65
   Vuilleumier P, 2003, NAT NEUROSCI, V6, P624, DOI 10.1038/nn1057
   Xie ZH, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P81
   Ye YS, 2019, J VIS COMMUN IMAGE R, V62, P1, DOI 10.1016/j.jvcir.2019.04.009
   Yu ZB, 2018, NEUROCOMPUTING, V317, P50, DOI 10.1016/j.neucom.2018.07.028
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhou F, 2010, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2010.5539966
NR 63
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103018
DI 10.1016/j.jvcir.2020.103018
EA JAN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BX
UT WOS:000633494400001
DA 2024-07-18
ER

PT J
AU Wang, M
   Lang, CY
   Feng, SH
   Wang, T
   Jin, Y
   Li, YD
AF Wang, Min
   Lang, Congyan
   Feng, Songhe
   Wang, Tao
   Jin, Yi
   Li, Yidong
TI Text to photo-realistic image synthesis via chained deep recurrent
   generative adversarial network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Text-to-image synthesis; Logic relationships; Computational bottlenecks;
   Parameters sharing
AB Despite the promising progress made in recent years, automatically generating high-resolution realistic images from text descriptions remains a challenging task due to semantic gap between human-written descriptions and diversities of visual appearance. Most existing approaches generate the rough images with the given text descriptions, while the relationship between sentence semantics and visual content is not holistically exploited. In this paper, we propose a novel chained deep recurrent generative adversarial network (CDRGAN) for synthesizing images from text descriptions. Our model uses carefully designed chained deep recurrent generators that simultaneously recovers global image structures and local details. Specially, our method not only considers the logic relationships of image pixels, but also removes computational bottlenecks through parameters sharing. We evaluate our method on three public benchmarks: CUB, Oxford-102 and MS COCO datasets. Experimental results show that our method significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics.
C1 [Wang, Min; Lang, Congyan; Feng, Songhe; Wang, Tao; Jin, Yi; Li, Yidong] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Wang, M (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM 16112071@bjtu.edu.cn; cylang@bjtu.edu.cn; shfeng@bjtu.edu.cn;
   twang@bjtu.edu.cn; yjin@bjtu.edu.cn; ydli@bjtu.edu.cn
FU Fundamental Research Funds for the Central Universities [2018YJS034,
   2020JBM403]; Beijing Natural Science Foundation [4202057, 4202058,
   4202060]; National Natural Science Foundation of China [62072027,
   61872032]; Ministry of Education -China Mobile Communications
   Corporation Foundation [MCM20170201]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (2018YJS034, 2020JBM403), the Beijing Natural
   Science Foundation (4202057, 4202058, 4202060), National Natural Science
   Foundation of China (62072027, 61872032), and the Ministry of Education
   -China Mobile Communications Corporation Foundation (MCM20170201).
CR Nguyen A, 2017, PROC CVPR IEEE, P3510, DOI 10.1109/CVPR.2017.374
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2017, ICLR
   [Anonymous], CALTECH UCSD BIRDS 2
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Cao Y, 2018, ASIA PAC CONF POSTGR, P1, DOI 10.1109/PRIMEASIA.2018.8597626
   Denton Emily, 2015, Advances in Neural Information Processing Systems
   Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D.P., 2014, 2 INT C LEARN REPR I
   Kingma D. P., 2014, arXiv
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mathieu M., ENERGY BASED GENERAT
   Metz Luke, 2017, Unrolled generative adversarial networks
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Odena A, 2017, PR MACH LEARN RES, V70
   Oh J., 2015, Advances in neural information processing systems, P2863
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Radford A., 2015, ARXIV
   Reed S., 2015, Advances in neural information processing systems
   Reed S. E., 2016, Generating interpretable images with controllable structure
   Reed S. E., 2016, ADV NEURAL INFORM PR, V29, P217
   Reed S, 2016, PR MACH LEARN RES, V48
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Salimans T, 2016, ADV NEUR IN, V29
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van den Oord A, 2016, ADV NEUR IN, V29
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47
   Yang J., 2015, Advances in Neural Information Processing Systems, P1099
   Zhang H, 2019, IEEE ACCESS, V7, P65103, DOI 10.1109/ACCESS.2019.2914725
   Zhang HP, 2018, IEEE ACCESS, V6, P7987, DOI 10.1109/ACCESS.2018.2798625
NR 42
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102955
DI 10.1016/j.jvcir.2020.102955
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I2ON
UT WOS:000779264200004
DA 2024-07-18
ER

PT J
AU Xie, YR
   Song, TC
   Li, W
AF Xie, Yurui
   Song, Tiecheng
   Li, Wei
TI Semantic-aware visual attributes learning for zero-shot recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero-shot learning; Human-designed attributes; Visual attributes;
   Semantic representation
ID OBJECT
AB Zero-shot learning (ZSL) aims to recognize unseen image classes without requiring any training samples of these specific classes. The ZSL problem is typically achieved by building up a semantic embedding space like attributes to bridge the visual features and class labels of images. Currently, most ZSL approaches focus on learning a visual-semantic alignment from seen classes using only the human-designed attributes, and then ZSL problem is solved by transferring semantic knowledge from seen classes to the unseen classes. However, few works indicate if the human-designed attributes are discriminative enough for image class prediction. To address this issue, we propose a semantic-aware dictionary learning (SADL) framework to explore these discriminative visual attributes across seen and unseen classes. Furthermore, the semantic cues are elegantly integrated into the feature representations via learned visual attributes for recognition task. Experiments conducted on two challenging benchmark datasets show that our approach outweighs other state-of-the-art ZSL methods.
C1 [Xie, Yurui] Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
   [Song, Tiecheng] Chongqing Univ Posts & Telecommun, 2 Chongwen Rd, Chongqing, Peoples R China.
   [Li, Wei] Southwest Jiaotong Univ, 999 Xi An Rd, Chengdu, Peoples R China.
C3 Chengdu University of Information Technology; Chongqing University of
   Posts & Telecommunications; Southwest Jiaotong University
RP Xie, YR (corresponding author), Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
EM gloriousxyr@163.com; songtc@cqupt.edu.cn; liwei@swjtu.edu.cn
FU National Natural Science Foundation of China [61806028, 61702065];
   Program for Educational Foundation of Sichuan Province, China [18ZB0125]
FX This work was supported by The National Natural Science Foundation of
   China (No. 61806028, No. 61702065), and in part by the Program for
   Educational Foundation of Sichuan Province, China (No. 18ZB0125).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2014, ICLR
   Ashual O, 2019, IEEE I CONF COMP VIS, P4560, DOI 10.1109/ICCV.2019.00466
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Jiang HJ, 2018, LECT NOTES COMPUT SC, V11214, P121, DOI 10.1007/978-3-030-01249-6_8
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Ren YZ, 2017, J VIS COMMUN IMAGE R, V42, P192, DOI 10.1016/j.jvcir.2016.11.004
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song J, 2020, PROC CVPR IEEE, P3921, DOI 10.1109/CVPR42600.2020.00398
   Song J, 2019, ADV NEUR IN, V32
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Song J, 2018, LECT NOTES COMPUT SC, V11213, P474, DOI 10.1007/978-3-030-01240-3_29
   Thomas SS, 2016, J VIS COMMUN IMAGE R, V38, P367, DOI 10.1016/j.jvcir.2016.03.015
   Tong B, 2019, PROC CVPR IEEE, P11459, DOI 10.1109/CVPR.2019.01173
   Verma VK, 2017, LECT NOTES ARTIF INT, V10535, P792, DOI 10.1007/978-3-319-71246-8_48
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V59, P563, DOI 10.1016/j.jvcir.2019.02.006
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 38
TC 0
Z9 0
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500008
DA 2024-07-18
ER

PT J
AU Wu, ZQ
   Jiang, W
   Yu, HY
AF Wu, Zaiqiang
   Jiang, Wei
   Yu, Hongyan
TI Analytical derivatives for differentiable renderer: 3D pose estimation
   by silhouette consistency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inverse graphics; Differentiable renderer; 3D pose estimation
AB Differentiable renderer is widely used in optimization-based 3D reconstruction which requires gradients for optimization. The existing differentiable renderers obtain gradients via numerical techniques. However, these methods are inaccurate and inefficient. Motivated by this fact, we propose a differentiable renderer with analytical gradients. The main obstacle of traditional renderer being differentiable is the discrete sampling operation of rasterization. To obtain a differentiable rasterization renderer, we define pixel intensity as a double integral over the pixel grid, and then derive the analytical gradients with respect to vertices. 3D pose estimation by multi-viewpoint silhouettes is conducted to reveal the effectiveness and efficiency of the proposed method. Experimental results show that 3D pose estimation without 3D and 2D joint supervision can produce competitive results. The findings also indicate that the proposed method has higher accuracy and efficiency than previous differentiable renderers.
C1 [Wu, Zaiqiang; Jiang, Wei] Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.
   [Yu, Hongyan] Beijing Electromech Engn Inst, Beijing 100074, Peoples R China.
C3 Zhejiang University
RP Jiang, W (corresponding author), Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.
EM jiangwei_zju@zju.edu.cn
RI jiang, wei/J-6317-2018
OI jiang, wei/0000-0002-9240-5851
FU National Natural Science Foundation of China [61633019]; Science
   Foundation of Chinese Aerospace Industry [JCKY2018204B053]; Autonomous
   Research Project of the State Key Laboratory of Industrial Control
   Technology, China [ICT1917]
FX This research was funded by the National Natural Science Foundation of
   China under Grant 61633019, the Science Foundation of Chinese Aerospace
   Industry under Grant JCKY2018204B053 and the Autonomous Research Project
   of the State Key Laboratory of Industrial Control Technology, China
   (Grant No. ICT1917).
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2013, Advances in Neural Information Processing Systems
   [Anonymous], 2015, Fundamentals of Computer Graphics
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Eigen D, 2014, ADV NEUR IN, V27
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fu MY, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/3512098
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Gkioulekas I, 2016, LECT NOTES COMPUT SC, V9907, P685, DOI 10.1007/978-3-319-46487-9_42
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   King DB, 2015, ACS SYM SER, V1214, P1
   Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Li TM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275109
   LIANG YD, 1984, ACM T GRAPHIC, V3, P1, DOI 10.1145/357332.357333
   Liu GL, 2017, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2017.248
   Liu S., 2019, ARXIV PREPRINT ARXIV
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Robinette K.M., 2002, Civilian American and European surface anthropometry resource (CAESAR), V1, DOI DOI 10.21236/ADA406704
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Tan V., 2018, INDIRECT DEEP STRUCT
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Thu NP, 2018, ADV NEUR IN, V31
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Whitted T., 2005, ACM SIGGRAPH 2005 CO, P4, DOI [10.1145/1198555.1198743, DOI 10.1145/1198555.1198743]
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu ZQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030400
   Zienkiewicz J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4280, DOI 10.1109/IROS.2016.7759630
NR 38
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102960
DI 10.1016/j.jvcir.2020.102960
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QO
UT WOS:000598558100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jia, W
   Li, L
   Li, Z
   Zhao, S
   Liu, S
AF Jia, Wei
   Li, Li
   Li, Zhu
   Zhao, Shuai
   Liu, Shan
TI Scalable Hash From Triplet Loss Feature Aggregation For Video
   De-duplication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binary hash; Binary tree; Fisher vector; Triplet loss; Video
   de-duplication
AB The producing, sharing and consuming life cycle of video content creates massive amount of duplicates in video segments due to variable bit rate representation and fragmentation in the playbacks. The inefficiency of this duplicates to storage and communication motivate researchers in both academia and industry to come up with computationally efficient video deduplication solutions for storage and CDN providers. Moreover, the increasing demands of high resolution and quality aggravate the status of heavy burden of cluster storage side and restricted bandwidth resources. Hence, video de-duplication in storage and transmission is becoming an important feature for video cloud storage and Content Delivery Network (CDN) service providers. Despite of the necessity of optimizing the multimedia data de-duplication approach, it is a challenging task because we should match as many as possible duplicated videos under not removing videos by mistake. The current video de-duplication schemes mostly relies on the URL based solution, which is not able to deal with noncacheable content like video, which the same piece of content may have totally different URL identification and fragmentation and different quality representations further complicate the problem. In this paper, we propose a novel content based video segmentation identification scheme that is invariant to the underlying codec and operational bit rates, it computes robust features from a triplet loss deep learning network that captures the invariance of the same content under different coding tools and strategy, while a scalable hashing solution is developed based on Fisher Vector aggregation of the convolutional features from the Triplet loss network. Our simulation results demonstrate the great improvement in terms of large scale video repository de-duplication compared with state-of-the-art methods.
C1 [Jia, Wei; Li, Li; Li, Zhu] Univ Missouri, Dept Comp Sci & Elect Engn, 5110 Rockhill Rd, Kansas City, MO 64110 USA.
   [Zhao, Shuai; Liu, Shan] Tencent Media Lab, 2747 Pk Blvd, Palo Alto, CA 94306 USA.
C3 University of Missouri System; University of Missouri Kansas City
RP Li, Z (corresponding author), Univ Missouri, Dept Comp Sci & Elect Engn, 5110 Rockhill Rd, Kansas City, MO 64110 USA.
EM wj3wr@umsystem.edu; lil1@umkc.edu; zhu.li@ieee.org; shuai.zhao@ieee.org;
   shanl@tencent.com
RI Li, Zhu/AAD-8182-2021; huang, shan/JVN-1240-2024
OI Li, Zhu/0000-0002-8246-177X; Jia, Wei/0000-0003-0053-6959; ,
   Shan/0000-0002-1442-1207
FU NSF [1747751]
FX The work is partially supported by a grant from NSF under award 1747751.
CR [Anonymous], 2016, ARXIV160906782
   [Anonymous], 2015, INT S COMP INT INT S
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2467315
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Di Rienzo JA, 2002, J AGRIC BIOL ENVIR S, V7, P129, DOI 10.1198/10857110260141193
   Feng Shan, 2017, 2017 IEEE 19 INT WOR, P1
   Gonzalez Emmanuel Barajas, 2017, US Patent, Patent No. [9,646,017, 9646017]
   Gosselin PH, 2014, PATTERN RECOGN LETT, V49, P92, DOI 10.1016/j.patrec.2014.06.011
   Greene Spencer, Google Patents, Patent No. [US Patent 7, 770, 198, 7770198]
   Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280
   Jia W, 2020, INT CONF ACOUST SPEE, P1918, DOI [10.1109/ICASSP40776.2020.9053908, 10.1109/icassp40776.2020.9053908]
   JOLLIFFE I., 2011, International Encyclopedia of Statistical Science, DOI DOI 10.1007/978-3-642-04898-2_455
   Katiyar, 2011, HOTSTORAGE
   Li J, 2005, HEREDITY, V95, P221, DOI 10.1038/sj.hdy.6800717
   Liu B, 2011, IEEE MULTIMEDIA, V18, P22, DOI 10.1109/MMUL.2011.37
   Malli RC, 2016, IEEE COMPUT SOC CONF, P714, DOI 10.1109/CVPRW.2016.94
   Matze John Edward Gerard, 2012, US Patent, Patent No. [8,205,065, 8205065]
   Min J, 2011, IEEE T COMPUT, V60, P824, DOI 10.1109/TC.2010.263
   Norouzi M.E., 2011, ICML
   Paisitktiangkrai S., 2010, P ACM INT C IM VID R, P121
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Radford A., 2015, ARXIV151106434
   Rashid F, 2015, IEEE INT CONGR BIG, P499, DOI 10.1109/BigDataCongress.2015.79
   Rashid F, 2015, 2015 IEEE FIRST INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2015), P138, DOI 10.1109/BigDataService.2015.15
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Rivest Ronald, 1992, TECHNICAL REPORT
   Rotello CM, 2015, PSYCHON B REV, V22, P944, DOI 10.3758/s13423-014-0759-2
   Rubinstein R. Y., 2004, The cross-entropy method: A unified approach to combinatorial optimization, monte-carlo simulation and machine learning
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Wang X., 2016, AS C COMP VIS ACCV
   Xia W, 2016, P IEEE, V104, P1681, DOI 10.1109/JPROC.2016.2571298
   Xu MW, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P129, DOI 10.1145/3241539.3241563
   Yan HY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061814
   Zambelli A., 2009, MICROSOFT CORPORATIO, V3, P40
   Zheng X., 2015, P 10 ACM S INF COMP, P63
   Zheng YF, 2017, IEEE T MULTIMEDIA, V19, P251, DOI 10.1109/TMM.2016.2612760
NR 39
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102908
DI 10.1016/j.jvcir.2020.102908
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400018
OA Bronze
DA 2024-07-18
ER

PT J
AU Su, Y
   An, SM
   Feng, ZY
   Xing, M
   Zhang, JH
AF Su, Yong
   An, Simin
   Feng, Zhiyong
   Xing, Meng
   Zhang, Jianhai
TI Spatio-temporal metric learning for individual recognition from
   locomotion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Individual recognition; Riemannian motion features; Spatio-Temporal
   Large Margin Nearest; Neighbor (ST-LMNN); Spatio-Temporal Multi-Metric
   Learning (STMM)
ID GAIT-BASED RECOGNITION; IMAGE; REPRESENTATION; IDENTITY
AB Individual recognition from locomotion is a challenging task owing to large intra-class and small inter-class variations. In this article, we present a novel metric learning method for individual recognition from skeleton sequences. Firstly, we propose to model articulated body on Riemannian manifold to describe the essence of human motion, which can reflect biometric signatures of the enrolled individuals. Then two spatia-temporal metric learning approaches are proposed, namely Spatio-Temporal Large Margin Nearest Neighbor (ST-LMNN) and Spatio-Temporal Multi-Metric Learning (STMM), to learn discriminant bilinear metrics which can encode the spatio-temporal structure of human motion. Specifically, the STLMNN algorithm extends the bilinear model into classical Large Margin Nearest Neighbor method, which learns a low-dimensional local linear embedding in the spatial and temporal domain, respectively. To further capture the unique motion pattern for each individual, the proposed STMM algorithm learns a set of individual-specific spatio-temporal metrics, which make the projected features of the same person closer to its class mean than that of different classes by a large margin. Beyond that, we present a new publicly available dataset for locomotion recognition to evaluate the influence of both internal and external covariant factors. According to the experimental results from the three public datasets, we believe that the proposed approaches are both able to achieve competitive results in individual recognition. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Su, Yong] Tianjin Univ Technol & Educ, Sch Informat Technol Engn, Tianjin, Peoples R China.
   [An, Simin] Tianjin Univ, Coll Management & Econ, Tianjin, Peoples R China.
   [Feng, Zhiyong; Xing, Meng; Zhang, Jianhai] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
C3 Tianjin University of Technology & Education; Tianjin University;
   Tianjin University
RP Su, Y (corresponding author), Tianjin Univ Technol & Educ, Sch Informat Technol Engn, Tianjin, Peoples R China.
EM suyong@tju.edu.cn
RI Feng, Zhi-Yong/I-7541-2016; su, yong/JEO-5411-2023
OI su, yong/0000-0002-6851-4142; An, Simin/0000-0001-7316-336X; Meng,
   Xing/0000-0001-6082-4675; Zhang, Jianhai/0000-0002-0330-6908
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Ahmed M, 2014, PROC SPIE, V9139, DOI 10.1117/12.2052588
   Andersson V., 2014, PROC ACM S APPL COMP, DOI DOI 10.1145/2554850.2555147
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2003, STAT PATTERN RECOGNI
   Ansari MN, 2012, 2012 XXTH INTERNATIONAL CONFERENCE ON ELECTRICAL MACHINES (ICEM), P2002, DOI 10.1109/ICElMach.2012.6350156
   Ariyanto Gunawan, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P354, DOI 10.1109/ICB.2012.6199832
   Nguyen B, 2017, PATTERN RECOGN, V64, P215, DOI 10.1016/j.patcog.2016.11.010
   Bak S, 2017, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR.2017.171
   Balazia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152124
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Frome A., 2007, NIPS, V19, P417
   Gemulla Rainer, 2011, P ACM SIGKDD INT C K, P69
   Globerson A, 2006, ADV NEURAL INFORM PR, P451
   Goldberger J., 2004, P INT C NEUR INF PRO, V17, P513
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hill H, 2000, PSYCHOL SCI, V11, P223, DOI 10.1111/1467-9280.00245
   Jiang SM, 2015, LECT NOTES COMPUT SC, V9008, P46, DOI 10.1007/978-3-319-16628-5_4
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Kastaniotis D, 2016, PATTERN RECOGN LETT, V84, P245, DOI 10.1016/j.patrec.2016.10.012
   Kastaniotis D, 2015, PATTERN RECOGN LETT, V68, P327, DOI 10.1016/j.patrec.2015.06.020
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lewis DavidK., 1971, Journal of Philosophy, V68, P203, DOI DOI 10.2307/2024902
   Li Q., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YC, 2011, J MED BIOL ENG, V31, P255, DOI 10.5405/jmbe.806
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Makihara Y, 2017, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR.2017.718
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Su Y, 2018, IEEE INT CON MULTI
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Theodorakopoulos I, 2014, J VIS COMMUN IMAGE R, V25, P12, DOI 10.1016/j.jvcir.2013.03.008
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Wang ZX, 2010, LECT NOTES COMPUT SC, V6311, P706, DOI 10.1007/978-3-642-15549-9_51
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xing E.P., Advances in neural information processing systems, 2003, P521
   Yang K, 2016, J VIS COMMUN IMAGE R, V39, P209, DOI 10.1016/j.jvcir.2016.05.020
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zhan D.-C., 2009, Proceedings of the Twenty-Sixth International Conference on Machine Learning, P1225, DOI DOI 10.1145/1553374.1553530
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812
   Zhou Xingyi, 2017, ICCV
NR 56
TC 0
Z9 0
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102753
DI 10.1016/j.jvcir.2020.102753
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800007
DA 2024-07-18
ER

PT J
AU Wang, H
   Li, C
AF Wang, Hua
   Li, Cong
TI Quality guided image recognition towards industrial materials diffusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image recognition; Image quality
ID MOLECULAR-SIEVE; GAS-ADSORPTION
AB Ordered porous materials, especially mesoporous materials, molecular sieves and organometallic framework materials, are widely used in the fields of adsorption, membrane separation and catalytic reaction processes due to their unique properties. Molecular sieve porous material is a new type of engineering material with excellent performance, and its microstructure is one of the key factors affecting macroscopic physical properties and use effect. At present, in order to further broaden its application in the fields of separation, catalysis, sensors and micro-devices, at present, microscopic molecular level control of porous material composition and structure, macroscopically controlling its appearance and appearance has become a research of porous materials. An important development direction. However, the quantitative characterization of the molecular structure of molecular sieve porous materials and its influence on physical properties has always been the focus and difficulty in the field of materials science and engineering. At the same time, the microstructure of porous materials of molecular sieves is the key factor affecting its macroscopic physical properties, and the analysis of spatial structure characteristics. Has important research significance. Based on this paper, a method for predicting effective diffusion coefficient in porous materials by convolutional neural network is proposed. The training samples of porous material microstructure are generated by computer stochastic simulation, and the corresponding effective diffusion coefficients are calculated by finite element method. The image quality subjective evaluation model is used to control the microscopic picture precision of the molecular sieve porous material. The combination of the two methods can quickly and accurately calculate the effective diffusion coefficient. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Hua] Yulin Univ, Yulin, Shanxi, Peoples R China.
   [Li, Cong] China Merchants Chongqing Commun Res & Design Ins, Chongqing, Peoples R China.
C3 Yulin University
RP Li, C (corresponding author), China Merchants Chongqing Commun Res & Design Ins, Chongqing, Peoples R China.
EM 79911975sd@sina.cn
FU research foundation for Yulin University Advanced Talents [17JK11];
   Natural Science Foundation of Shaanxi Provincial Department of Education
   [18JK0903]; National Natural Science Foundation of China [51508496]
FX This work was supported by research foundation for Yulin University
   Advanced Talents (No. 17JK11), Natural Science Foundation of Shaanxi
   Provincial Department of Education (No. 18JK0903) and National Natural
   Science Foundation of China (Grant No. 51508496).
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   BOK K, 2017, MULTIMED TOOLS APPL, V76, P1
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dai W., 2017, CATAL SCI TECHNOL, V7
   Ding F, 2015, PETROL SCI TECHNOL, V33, P1846, DOI 10.1080/10916466.2012.671401
   García L, 2017, J CHEM ENG DATA, V62, P1550, DOI 10.1021/acs.jced.7b00061
   Kobori R, 2009, ADSORPTION, V15, P114, DOI 10.1007/s10450-009-9162-0
   Le Ouay B, 2017, J AM CHEM SOC, V139, P7886, DOI 10.1021/jacs.7b02402
   Liu W, 2018, NPG ASIA MATER, V10, P293, DOI 10.1038/s41427-018-0029-2
   Musa M, 2017, MICROPOR MESOPOR MAT, V239, P336, DOI 10.1016/j.micromeso.2016.09.045
   Park GT, 2017, INORG CHEM, V56, P8504, DOI 10.1021/acs.inorgchem.7b01194
   PETROVIC I, 1993, CHEM MATER, V5, P1805, DOI 10.1021/cm00036a019
   Rapti S., 2017, J MAT CHEM A, V5
   Sigman J. B., 2017, IEEE T GEOSCI REMOTE, P1
   Silva AF, 2018, J MOL MODEL, V24, DOI 10.1007/s00894-018-3717-5
   Sun T, 2017, IEEE T IMAGE PROCESS, V26, P5632, DOI 10.1109/TIP.2017.2745200
   Vekariya RL, 2018, IONICS, V24, P1, DOI 10.1007/s11581-017-2338-9
   [王健 Wang Jian], 2017, [真空科学与技术学报, Chinese Journal of Vacuum Science and Technology], V37, P449
   [王楠 Wang Nan], 2017, [石油学报. 石油加工, Acta Petrolei Sinica. Petroleum Processing Section], V33, P1089
   Xia YJ, 2017, IEEE T INTELL TRANSP, V18, P2629, DOI 10.1109/TITS.2017.2653103
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Yadav A., 2017, Electronic Imaging, V2017, P21
   Yao JC, 2018, IET IMAGE PROCESS, V12, P872, DOI 10.1049/iet-ipr.2017.0209
   Zhang HY, 2017, J ELECTROANAL CHEM, V807, P37, DOI 10.1016/j.jelechem.2017.10.065
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhou B.Y., 2018, COMPUT FLUIDS
   Zhou EH, 2018, RUSS J COORD CHEM+, V44, P173, DOI 10.1134/S1070328418030077
   Zhou Y B., 2017, MODERN FOOD SCI TECH, V33, P155
NR 28
TC 2
Z9 2
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102608
DI 10.1016/j.jvcir.2019.102608
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600007
DA 2024-07-18
ER

PT J
AU Zhang, WY
   Fu, XH
   Wang, CY
AF Zhang, Wanyi
   Fu, Xiuhua
   Wang, Chunyang
TI Image quality optimization towards lidar registration based on iterative
   termination
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Laser radar; Registration image; Quality optimization; Image processing
ID OBJECT DETECTION; RECONSTRUCTION
AB Image quality optimization is a key technique in image processing, whose goal is to improve image quality by image enhancement or image format transform. This paper aims at optimizing image acquisition using Lidar registration, which can cope with disadvantages of conventional algorithms such as low-resolution. Specifically, we propose an iterative termination optimization strategy based on image quality perception features and local mean estimation. First, fuzzy images with different types and degrees of distortion are incorporated to form a representative natural image set, and feature maps of fuzzy images are extracted by the natural scene statistical method in the spatial domain. Noticeably, the proposed algorithm which performs iterative deblurring operation records the optimal iteration point based on recording the quality value FSIM of the restored image, and calibrates the corresponding feature vector in the sample library with the optimal iteration point (step number). Afterwards, we leverage LME method to implement an estimate of the number of iteration steps. Based on these two steps, the estimation of the initial iterative monitoring point is completed, so that the subsequent adaptive iterative termination work is more purposeful to monitor the defuzzification metric. The optimization operation can be completed faster effectively. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Wanyi; Fu, Xiuhua; Wang, Chunyang] Changchun Univ Sci & Technol, Sch OptoElect Engn, Changchun, Jilin, Peoples R China.
C3 Changchun University of Science & Technology
RP Fu, XH (corresponding author), Changchun Univ Sci & Technol, Sch OptoElect Engn, Changchun, Jilin, Peoples R China.
EM goptics@126.com
RI Fu, Xiuhua/GWV-7918-2022
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Blair J.B., 2015, AGU FALL M, P7
   Deng CJ, 2017, PHOTONICS RES, V5, P431, DOI 10.1364/PRJ.5.000431
   Gao J, 2015, OPTIK, V126, P3084, DOI 10.1016/j.ijleo.2015.07.098
   Gao J, 2014, OPTIK, V125, P5199, DOI 10.1016/j.ijleo.2014.05.005
   Guo Liang, 2011, Infrared Laser Engineering, V40, P637
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Henry SC, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.9.091603
   Huang HC, 2016, APPL OPTICS, V55, pA43, DOI 10.1364/AO.55.000A43
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Liu L.R., 2009, ACTA OPT SINICA, V29, P2030
   Liu YW, 2000, OPT COMMUN, V181, P47, DOI 10.1016/S0030-4018(00)00751-3
   Muttini A., 2015, SPIE REMOTE SENSING, P13
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Qu F.Q., 2014, APPL MECH MAT, V721, P468
   Sun JF, 2015, OPTIK, V126, P3181, DOI 10.1016/j.ijleo.2015.07.077
   Tian ZS, 2014, CHIN OPT LETT, V12, DOI 10.3788/COL201412.060015
   Wang CL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050732
   Wang CH, 2016, APPL OPTICS, V55, P1559, DOI 10.1364/AO.55.001559
   Xiang W., 2015, COMMUN COMPUT INFORM, V482, P117
   Xu L., 2015, INFRAR LASER ENG, V44
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Ye GC, 2016, OPT COMMUN, V360, P7, DOI 10.1016/j.optcom.2015.10.020
   Ye L, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2625801
   Yu H, 2015, OPT EXPRESS, V23, P14541, DOI 10.1364/OE.23.014541
   Yuan L, 2014, CHIN J LASERS, V41
   Zhang YT, 2012, J INFRARED MILLIM TE, V33, P1052, DOI 10.1007/s10762-012-9924-8
   Zurk L.M., 2013, P SPIE INT SOC OPT E, V8846, P49
NR 36
TC 0
Z9 0
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102634
DI 10.1016/j.jvcir.2019.102634
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600016
DA 2024-07-18
ER

PT J
AU Chen, GB
   Zhai, MT
AF Chen, Guobin
   Zhai, Maotong
TI Quality assessment on remote sensing image based on neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Remote sensing image; Deep learning;
   Information entropy
ID REPRESENTATION
AB Image quality assessment is of great significance for the designment and application of remote sensing systems. CNN based method is proposed for image quality assessment on remote sensing image in this paper. Specifically, we first introduce the convolutional neural network and deep learning method. Then a deep CNN architecture is constructed to automatically extract image features to evaluate image quality. Afterward, the information entropy threshold is used to remove the image blocks with less information content. Finally, a deep network model with two convolutional layers is used to achieve feature extraction and image quality scoring. The experimental results show that the quality score of this method has good subjective and objective consistency for multi-distortion remote sensing images and common multi-distortion images. Evaluation of distorted images does not depend on a specific database and has database independence. In addition, our proposed method is simple to achievement. (C) 2019 Published by Elsevier Inc.
C1 [Chen, Guobin] Chongqing Technol & Business Univ, Rongzhi Coll, Chongqing Key Lab Spatial Data Min & Big Data Int, Chongqing 401320, Peoples R China.
   [Zhai, Maotong] Jiangxi Univ Finance & Econ, Sch Tourism & Urban Management, Nanchang, Jiangxi, Peoples R China.
C3 Chongqing Technology & Business University; Jiangxi University of
   Finance & Economics
RP Zhai, MT (corresponding author), Jiangxi Univ Finance & Econ, Sch Tourism & Urban Management, Nanchang, Jiangxi, Peoples R China.
EM zhaidi530@126.com
FU Chongqing Municipal Education Commission Science and Technology Project
   [KJQN201802101]; Doctoral high school talent training project
   [RC2016003]; Chongqing Graduate Scientific Research Innovation Project
   [CYB17131]; National Natural Science Foundation of China [41561049];
   Jiangxi Outstanding Youth Science Fund [20171BCB23049]; Jiangxi
   Provincial Department of Education Science and Technology Project
   [GJJ150481]; Jiangxi University of Finance and Economics 2018 Graduate
   Innovation Special Fund Project
FX This work supported by Chongqing Municipal Education Commission Science
   and Technology Project (KJQN201802101); Doctoral high school talent
   training project (RC2016003); Chongqing Graduate Scientific Research
   Innovation Project (CYB17131); National Natural Science Foundation of
   China(No. 41561049); Jiangxi Outstanding Youth Science Fund (No.
   20171BCB23049); Jiangxi Provincial Department of Education Science and
   Technology Project (No. GJJ150481); Jiangxi University of Finance and
   Economics 2018 Graduate Innovation Special Fund Project.
CR [Anonymous], 2009, NETWORK COMPUT NEURA, DOI DOI 10.1088/0954-898X_5_4_006
   [Anonymous], DATA DRIVEN STAT FRA
   [Anonymous], DETECTING UNEXPECTED
   [Anonymous], P INT C MACH LEARN
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Du YY, 2011, ENTERP INF SYST-UK, V5, P449, DOI 10.1080/17517575.2010.541943
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Huang X, 2016, NEUROCOMPUTING, V218, P296, DOI 10.1016/j.neucom.2016.08.078
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jiang W, 2019, FORESTS, V10, DOI 10.3390/f10030215
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Liu L, 2015, COMPUT GEOSCI-UK, V83, P27, DOI 10.1016/j.cageo.2015.06.017
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu W, 2012, ENTERP INF SYST-UK, V6, P95, DOI 10.1080/17517575.2011.617472
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pang ZH, 2016, IEEE T CYBERNETICS, V46, P1400, DOI 10.1109/TCYB.2015.2448031
   Pingping Zhu, 2017, 2017 IEEE 56th Annual Conference on Decision and Control (CDC), P2724, DOI 10.1109/CDC.2017.8264055
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Song BY, 2017, COGN COMPUT, V9, P5, DOI 10.1007/s12559-016-9442-4
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun YM, 2016, INFORM SCIENCES, V369, P748, DOI 10.1016/j.ins.2016.06.010
   Tian ZW, 2016, COMPUT GEOSCI-UK, V86, P15, DOI 10.1016/j.cageo.2015.10.002
   Wang F, 2018, IEEE T CYBERNETICS, V48, P1839, DOI 10.1109/TCYB.2017.2715980
   Wang MB, 2013, APPL MATH COMPUT, V219, P4185, DOI 10.1016/j.amc.2012.11.009
   Wang Z, 2012, NEUROCOMPUTING, V83, P83, DOI 10.1016/j.neucom.2011.11.018
   Wang ZG, 2015, NEUROCOMPUTING, V149, P100, DOI 10.1016/j.neucom.2014.03.072
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zeng QT, 2009, COMPUT EDUC, V53, P809, DOI 10.1016/j.compedu.2009.04.019
   Zhang WH, 2008, INT J INNOV COMPUT I, V4, P689
   Zhang XM, 2017, NEUROCOMPUTING, V235, P182, DOI 10.1016/j.neucom.2017.01.011
NR 41
TC 4
Z9 4
U1 3
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102580
DI 10.1016/j.jvcir.2019.102580
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200007
DA 2024-07-18
ER

PT J
AU Kong, WQ
   Wu, JJ
   Hu, ZJ
   Jeon, G
AF Kong, Wanqiu
   Wu, Jiaji
   Hu, Zejun
   Jeon, Gwanggil
TI Lossless compression codec of aurora spectral data using hybrid
   spatial-spectral decorrelation with outlier recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lossless compression; Aurora spectral data; Hyperspectral data;
   Prediction; Range coding; Outlier recognition
ID IMAGE COMPRESSION; ALGORITHM
AB Aurora spectral data, the particular hyperspectral data of auroral spectra, have an irreplaceable research value in bridging the gap between solar activity and terrestrial evolution. Their requirement for high volume storage and real-time transmission had been a great challenge until we proposed a CPU paralleled and online-biprediction-based method. As it is no longer applicable because of the recent spectrograph reassembling, this paper presents a replacement strategy combines the unidirectional predictor with the entropy coder of the other dimension, as well as with using smoothing and outlier recognition. The hybrid encoders of Spat-SPCC and Spec-SPCC are developed distinguished by their respective prediction direction. Spat-SPCC tuned on one-day trial data is used for its better capability for compression, in the further comparison with various classical algorithms, it achieves the top-ranking compression performance and has the average processing time of 1 s per file so that its availability for the practical applications is validated. (C) 2019 Published by Elsevier Inc.
C1 [Kong, Wanqiu; Wu, Jiaji; Jeon, Gwanggil] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Kong, Wanqiu; Hu, Zejun] Polar Res Inst China, SOA Key Lab Polar Sci, Shanghai 200136, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
C3 Xidian University; Polar Research Institute of China; Incheon National
   University
RP Wu, JJ (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM wanqiukong@stu.xidian.edu.cn; wujj@mail.xidian.edu.cn;
   huzejun@pric.org.cn
RI Hu, Ze-Jun/X-8090-2019; kong, wanqiu/E-4341-2016
OI Hu, Ze-Jun/0000-0003-2448-2094; kong, wanqiu/0000-0002-9814-2028
FU National Natural Science Foundation of China (NSFC) [61775175, 61771378,
   41874195, 41831072]; National Key RAMP;D Program of China
   [2018YFC1407303, 2016YFC1400301]; Chinese Polar Environment
   Comprehensive Investigation and Assessment Program (CHINARE-2017);
   Top-Notch Young Talents Program of China
FX This work was funded by National Natural Science Foundation of China
   (NSFC) under Grant 61775175, 61771378, 41874195, 41831072; National Key
   R&D Program of China under Grant 2018YFC1407303 and 2016YFC1400301;
   Chinese Polar Environment Comprehensive Investigation and Assessment
   Program (CHINARE-2017); Top-Notch Young Talents Program of China.
CR [Anonymous], 2007, ANDOR IXON USERS GUI
   Bilgin A, 2000, APPL OPTICS, V39, P1799, DOI 10.1364/AO.39.001799
   Hu ZJ, 2017, POLAR SCI, V14, P1, DOI 10.1016/j.polar.2017.09.001
   Huffman DA, 2006, RESONANCE, V11, P91, DOI 10.1007/BF02837279
   Karaca AC, 2018, REMOTE SENS LETT, V9, P31, DOI 10.1080/2150704X.2017.1375612
   Kong WQ, 2017, PROC SPIE, V10430, DOI 10.1117/12.2278844
   Kong WQ, 2017, INFORM SCIENCES, V381, P33, DOI 10.1016/j.ins.2016.11.008
   Liu FY, 2019, IEEE T GEOSCI REMOTE, V57, P803, DOI 10.1109/TGRS.2018.2860686
   Magli E, 2009, IEEE T GEOSCI REMOTE, V47, P1168, DOI 10.1109/TGRS.2008.2009316
   Martin GNN, 1979, P I EL RAD ENG INT C, V2
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P157, DOI 10.1109/LSP.2005.862604
   Mielikainen J, 2003, IEEE T GEOSCI REMOTE, V41, P2943, DOI 10.1109/TGRS.2003.820885
   Mielikainen J, 2012, IEEE GEOSCI REMOTE S, V9, P1118, DOI 10.1109/LGRS.2012.2191531
   Omholt A., 1971, OPTICAL AURORA, DOI [10.1007/978-3-642-46269-6, DOI 10.1007/978-3-642-46269-6]
   Penna B, 2006, IEEE GEOSCI REMOTE S, V3, P125, DOI 10.1109/LGRS.2005.859942
   Pickering MR, 2001, IEEE T GEOSCI REMOTE, V39, P1536, DOI 10.1109/36.934084
   PLACKETT RL, 1950, BIOMETRIKA, V37, P149, DOI 10.2307/2332158
   Qin C, 2019, IEEE T CIRC SYST VID, V29, P3341, DOI 10.1109/TCSVT.2018.2878026
   Rao AK, 1996, IEEE T GEOSCI REMOTE, V34, P385, DOI 10.1109/36.485116
   Shkarin D, 2002, IEEE DATA COMPR CONF, P202, DOI 10.1109/DCC.2002.999958
   Taubman DS, 2002, P IEEE, V90, P1336, DOI 10.1109/JPROC.2002.800725
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Witten I. H., 2002, P IEEE, V82, P857
   Wu H, 2016, IEEE T IMAGE PROCESS, V25, P2684, DOI 10.1109/TIP.2016.2551366
   Wu JJ, 2015, IEEE SIGNAL PROC LET, V22, P2194, DOI 10.1109/LSP.2015.2443913
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zhang L, 2009, J PHYS B ATOM MOL PH, V42, P2327
   Zhu W, 2011, IEEE GEOSCI REMOTE S, V8, P416, DOI 10.1109/LGRS.2010.2081661
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
   ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934
NR 30
TC 3
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 174
EP 181
DI 10.1016/j.jvcir.2019.05.006
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600016
DA 2024-07-18
ER

PT J
AU Bribiesca, E
   Bribiesca-Contreras, F
   Carrillo-Bermejo, A
   Bribiesca-Correa, G
   Hevia-Montiel, N
AF Bribiesca, Ernesto
   Bribiesca-Contreras, Fernanda
   Carrillo-Bermejo, Angel
   Bribiesca-Correa, Graciela
   Hevia-Montiel, Nidiyare
TI A chain code for representing high definition contour shapes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Slope chain code; Extended slope chain code; High definition contour
   shapes; Reconfigurable chain code; Bird wings
ID TORTUOSITY; 2D
AB The biggest disadvantage of using chain code techniques is the generation of low definition contour shapes, in this paper we present the Extended Slope Chain Code (ESCC) which is an improvement on the Slope Chain Code (SCC). The ESCC is focused on the representation of high definition contour shapes. Generally speaking, most chain codes hold the length of the straight-line segments which represent the contour shape as a constant. In this case, the contour shapes represented by ESCC are composed of variable segments, which allow us to have a better description of the contour shape. Thus, the length of the segments are a function of the slope changes, i.e. the length of the next segment depends on the value of the slope change at that point. Therefore, the ESCC is continuously adjusting to the curvature requirements of contour shapes, in order to have a better description of contour shapes. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Bribiesca, Ernesto] Univ Nacl Autonoma Mexico, Dept Ciencias Comp, Inst Invest Matemat Aplicadas & Sistemas, Apdo 20-726, Cdmx 01000, Mexico.
   [Bribiesca-Contreras, Fernanda] Univ Manchester, Fac Sci & Engn, Manchester, Lancs, England.
   [Carrillo-Bermejo, Angel] Univ Nacl Autonoma Mexico, Ciencia & Ingn Comp, Cdmx, Mexico.
   [Bribiesca-Correa, Graciela] Univ Nacl Autonoma Mexico, Div Invest, Fac Contaduria & Adm, Cdmx, Mexico.
   [Hevia-Montiel, Nidiyare] UNAM, Unidad Acad Ciencias & Tecnol, Inst Invest Matemat Aplicadas & Sistemas, Cdmx, Mexico.
C3 Universidad Nacional Autonoma de Mexico; University of Manchester;
   Universidad Nacional Autonoma de Mexico; Universidad Nacional Autonoma
   de Mexico; Universidad Nacional Autonoma de Mexico
RP Bribiesca, E (corresponding author), Univ Nacl Autonoma Mexico, Dept Ciencias Comp, Inst Invest Matemat Aplicadas & Sistemas, Apdo 20-726, Cdmx 01000, Mexico.
EM bribiesca@iimas.unam.mx; fernanda.bribiesca@postgrad.manchester.ac.uk;
   gbribies@fca.unam.mx; nidiyare.hevia@iimas.unam.mx
RI Bribiesca, Ernesto/AAH-6842-2021
OI Bribiesca, Ernesto/0000-0001-6663-9438; Bribiesca Contreras,
   Fernanda/0000-0001-6408-6833; Carrillo-Bermejo,
   Angel/0000-0002-2068-7431; Bribiesca, Graciela/0000-0002-5453-2382
FU IIMAS-UNAM; SNI-CONACyT; CONACYT
FX This research work was supported by IIMAS-UNAM and SNI-CONACyT. F.
   Bribiesca-Contreras thanks CONACYT for her scholarship. We acknowledge
   Dan Sykes for his revision of the paper's English.
CR BAEZAYATES R, 1992, COMMUN ACM, V35, P74, DOI 10.1145/135239.135243
   BLUMENKRANS A, 1991, PATTERN RECOGN, V24, P879, DOI 10.1016/0031-3203(91)90007-R
   Bondy J. A., 1976, GRAPH THEORY APPL, V290
   BRIBIESCA E, 1992, PATTERN RECOGN, V25, P483, DOI 10.1016/0031-3203(92)90047-M
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   Bribiesca E, 2008, PATTERN RECOGN, V41, P543, DOI 10.1016/j.patcog.2007.06.029
   Bribiesca E, 2014, PATTERN RECOGN, V47, P3242, DOI 10.1016/j.patcog.2014.04.010
   Bribiesca E, 2013, PATTERN RECOGN, V46, P716, DOI 10.1016/j.patcog.2012.09.017
   Bullitt E, 2003, IEEE T MED IMAGING, V22, P1163, DOI 10.1109/TMI.2003.816964
   Cayley A., 1889, A theorem of trees, V23, P376
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Grisan E, 2008, IEEE T MED IMAGING, V27, P310, DOI 10.1109/TMI.2007.904657
   HARALICK RM, 1991, PATTERN RECOGN, V24, P69, DOI 10.1016/0031-3203(91)90117-N
   Hart WE, 1999, INT J MED INFORM, V53, P239, DOI 10.1016/S1386-5056(98)00163-4
   Hopcroft J.E., 1979, Introduction to Automata Theory, Languages, and Computation
   Karush William., 1989, Webster's New World Dictionary of Mathematics
   Le LH, 2010, ULTRASONICS, V50, P1, DOI 10.1016/j.ultras.2009.07.011
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Sanchez-Cruz H, 2010, J VIS COMMUN IMAGE R, V21, P311, DOI 10.1016/j.jvcir.2010.02.002
   Sterling L., 1986, THE ART OF PROLOG
NR 22
TC 4
Z9 4
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 93
EP 104
DI 10.1016/j.jvcir.2019.03.015
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100010
DA 2024-07-18
ER

PT J
AU Liu, QL
   Jin, L
   Li, ZC
   Tang, JH
AF Liu, Qiuli
   Jin, Lu
   Li, Zechao
   Tang, Jinhui
TI Multimedia retrieval by deep hashing with multilevel similarity learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia retrieval; Deep neural networks; Hashing and multilevel
   similarity; correlation measurement
AB Deep multimodal hashing has received increasing research attention in recent years due to its superior performance for large-scale multimedia retrieval. However, limited e orts have been made to explore the complex multilevel semantic structure for deep multimodal hashing. In this paper, we propose a novel deep multimodal hashing method, termed as Deep Hashing with Multilevel Similarity Learning (DHMSL), for learning compact and discriminative hash codes, which explores multilevel semantic similarity correlations of multimedia data. In DHMSL, multilevel similarity correlation is explored to learn the unified binary hash codes by exploiting the local structure and semantic label information simultaneously. Meanwhile, the bit balance and quantization constraints are taken into account to further make the unified hash codes compact. With the unified binary codes learned, two deep neural networks are jointly trained to simultaneously learn feature representations and two sets of nonlinear hash functions. Specifically, the well-designed loss functions are introduced to minimize the prediction errors of the feature representations as well as the errors between the unified binary codes and outputs of the networks. Extensive experiments on two widely-used multimodal datasets demonstrate that the proposed method can achieve the state-of-the-art performance for both image-query-text and text-query-image tasks. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Qiuli] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Jin, Lu; Li, Zechao; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Liu, Qiuli] Beijing Normal Univ, Beijing 100875, Peoples R China.
C3 University of Electronic Science & Technology of China; Nanjing
   University of Science & Technology; Beijing Normal University
RP Jin, L (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM lujin505@gmail.com
RI Tang, Jinhui/KBR-0891-2024; ARSLAN, Okan/AAA-3232-2020
OI Tang, Jinhui/0000-0001-9008-222X
FU National Key Research and Development Program of China [2017YFC0820601];
   National Natural Science Foundation of China [61772275, 61732007,
   61720106004]; Natural Science Foundation of Jiangsu Province
   [BK20170033]
FX This work was partially supported by the National Key Research and
   Development Program of China under Grant 2017YFC0820601, the National
   Natural Science Foundation of China (Grant Nos. 61772275, 61732007 and
   61720106004) and the Natural Science Foundation of Jiangsu Province
   (Grant BK20170033).
CR [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2007, MIR
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2018, IEEE T PATTERN ANAL
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Grauman K., 2013, Machine Learning for Computer Vision, V411, P49, DOI 10.1007/978-3-642-28661-2_3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Jin  L., 2018, ICIMCS
   Jin L, 2019, IEEE T NEUR NET LEAR, V30, P1429, DOI 10.1109/TNNLS.2018.2869601
   Jin L, 2018, IEEE T IMAGE PROCESS, V27, P1405, DOI 10.1109/TIP.2017.2776745
   Jing  P., 2018, IEEE T CIRCUITS SYST
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li K., 2016, IEEE T PATTERN ANAL
   Li W.-J., 2015, ARXIV151103855
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tang JH, 2018, IEEE T NEUR NET LEAR, V29, P6154, DOI 10.1109/TNNLS.2018.2816743
   Tang JH, 2018, IEEE T CIRC SYST VID, V28, P2730, DOI 10.1109/TCSVT.2017.2715227
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 49
TC 5
Z9 5
U1 3
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 150
EP 158
DI 10.1016/j.jvcir.2018.11.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600015
DA 2024-07-18
ER

PT J
AU Chen, CP
   Min, WQ
   Li, X
   Jiang, SQ
AF Chen, Chengpeng
   Min, Weiqing
   Li, Xue
   Jiang, Shuqiang
TI Hybrid incremental learning of new data and new classes for hand-held
   object recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Incremental learning; Object recognition; SVM; Human-machine interaction
ID CLASSIFICATION; MECHANISMS; ONLINE
AB Intelligence technology is an important research area. As a very special yet important case of object recognition, hand-held object recognition plays an important role in intelligence technology for its many applications such as visual question-answering and reasoning. In real-world scenarios, the datasets are open-ended and dynamic: new object samples and new object classes increase continuously. This requires the intelligence technology to enable hybrid incremental learning, which supports both data-incremental and class-incremental learning to efficiently learn the new information. However, existing work mainly focuses on one side of incremental learning, either data-incremental or class-incremental learning while do not handle two sides of incremental learning in a unified framework. To solve the problem, we present a Hybrid Incremental Learning (HIL) method based on Support Vector Machine (SVM), which can incrementally improve its recognition ability by learning new object samples and new object concepts during the interaction with humans. In order to integrate data-incremental and class-incremental learning into one unified framework, HIL adds the new classification-planes and adjusts existing classification-planes under the setting of SVM. As a result, our system can simultaneously improve the recognition quality of known concepts by minimizing the prediction error and transfer the previous model to recognize unknown objects. We apply the proposed method into hand-held object recognition and the experimental results demonstrated its advantage of HIL. In addition, we conducted extensive experiments on the subset of ImageNet and the experimental results further validated the effectiveness of the proposed method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chen, Chengpeng] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Min, Weiqing; Li, Xue; Jiang, Shuqiang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Min, Weiqing] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Liaoning, Peoples R China.
   [Chen, Chengpeng; Jiang, Shuqiang] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Jiang, SQ (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.; Jiang, SQ (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM sqjiang@ict.ac.cn
FU Beijing Natural Science Foundation [4174106]; National Natural Science
   Foundation of China [61532018, 61602437]; Lenovo Outstanding Young
   Scientists Program; National Program for Special Support of Eminent
   Professionals; National Program for Support of Top-notch Young
   Professionals; China Postdoctoral Science Foundation [2017T100110];
   State Key Laboratory of Robotics
FX This work was supported in part by the Beijing Natural Science
   Foundation (4174106), in part by the National Natural Science Foundation
   of China under Grant (61532018 and 61602437), in part by the Lenovo
   Outstanding Young Scientists Program, in part by National Program for
   Special Support of Eminent Professionals and National Program for
   Support of Top-notch Young Professionals, in part by the China
   Postdoctoral Science Foundation (2017T100110) and in part by the State
   Key Laboratory of Robotics.
CR Bordes A, 2005, J MACH LEARN RES, V6, P1579
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doan TN, 2014, ADV KNOWLEDGE DISCOV, P155
   Engelbrecht AP, 2001, IEEE IJCNN, P2019, DOI 10.1109/IJCNN.2001.938474
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Gobet F, 2001, TRENDS COGN SCI, V5, P236, DOI 10.1016/S1364-6613(00)01662-4
   Grippo, IEEE T NEURAL NETWOR, V11
   GROSSBERG S, 1988, NEURAL NETWORKS, V1, P17, DOI 10.1016/0893-6080(88)90021-4
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuzborskij I, 2013, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2013.431
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li WH, 2018, IEEE ACCESS, V6, P44211, DOI 10.1109/ACCESS.2018.2863943
   Littlestone N., 1991, Proceedings of the twenty-third annual ACM symposium on Theory of computing, STOC '91, P465
   Lomonaco V, 2016, LECT NOTES ARTIF INT, V9896, P175, DOI 10.1007/978-3-319-46182-3_15
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P765, DOI 10.1145/2733373.2807990
   Lv X, 2015, J COMPUT SCI TECH-CH, V30, P340, DOI 10.1007/s11390-015-1527-0
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Morisset Benoit., 2009, Robotics and Automation (ICRA), P3786
   Murata N, 2002, NEURAL NETWORKS, V15, P743, DOI 10.1016/S0893-6080(02)00060-6
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Pratama M, 2017, IEEE T FUZZY SYST, V25, P1175, DOI 10.1109/TFUZZ.2016.2599855
   Qi G. -J., COMPUT RES REPOSITOR
   Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191
   Qi GJ, 2011, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.2011.5995312
   Qi GJ, 2009, IEEE T PATTERN ANAL, V31, P1880, DOI 10.1109/TPAMI.2008.218
   Rajendran P., COMPUTING RES REPOSI
   Ren XF, 2010, PROC CVPR IEEE, P3137, DOI 10.1109/CVPR.2010.5540074
   Ristin M., 2015, IEEE T PATTERN ANAL, P1
   ROCKAFELLAR RT, 1993, SIAM REV, V35, P183, DOI 10.1137/1035044
   Rüping S, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P641, DOI 10.1109/ICDM.2001.989589
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tang JH, 2015, IEEE T MULTIMEDIA, V17, P1899, DOI 10.1109/TMM.2015.2476660
   Vapnik V., 1999, NATURE STAT LEARNING
   VO MT, 1994, INT CONF ACOUST SPEE, P629
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Wang E. H. -C., 1992, P IEEE INT JOINT C N, VIII
   Wen J, 2009, IEEE SYS MAN CYBERN, P3688, DOI 10.1109/ICSMC.2009.5346874
   Xiao TJ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P177, DOI 10.1145/2647868.2654926
   ZHANG BT, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P215, DOI 10.1109/ICNN.1994.374165
NR 48
TC 6
Z9 7
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 138
EP 148
DI 10.1016/j.jvcir.2018.11.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100015
DA 2024-07-18
ER

PT J
AU Hu, LQ
   He, CF
   Cai, ZQ
   Wen, L
   Ren, T
AF Hu, Li-Qiang
   He, Chao-Feng
   Cai, Zhao-Quan
   Wen, Long
   Ren, Teng
TI Track circuit fault prediction method based on grey theory and expert
   system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Track circuit; Fault prediction; Grey theory; Expert system
ID PARTICLE SWARM OPTIMIZATION; LEARNING-BASED OPTIMIZATION; FROG-LEAPING
   ALGORITHM; INCIPIENT FAULTS; DIAGNOSIS; PROGNOSTICS; WAVELET; DESIGN;
   STRATEGY; SEARCH
AB Due to the lack of accurate state judgment and health analysis of equipment operation, track circuit implements the repair and maintenance strategy of fault repair or planned repair. For this reason, a novel track circuit fault prediction method is proposed based on grey theory and expert system. In the proposed method, the feature of grey prediction model is to establish dynamic differential equation and then predict its own development according to its own data. The dynamic prediction model with equal dimension is applied to improve original grey model. Based on the gray models, the expert system is used to simulate human experts to solve the problems in a professional field. It contains man-computer interface, inference engine, knowledge library, knowledge management system, interpretation module and dynamic database. The measurement data show this system can effectively predict several typical faults of HVAP track circuit, and prove the proposed system structure is effective. Such condition-based fault prognostic maintenance mechanism provides an effective solution to improve equipment maintenance efficiency, reduce maintenance cost and reduce equipment fault rate. (C) 2018 Published by Elsevier Inc.
C1 [Hu, Li-Qiang; He, Chao-Feng] Shijiazhuang Tiedao Univ, Sch Elect & Elect Engn, Shijiazhuang 050043, Hebei, Peoples R China.
   [Cai, Zhao-Quan] Huizhou Univ, Dept Informat Sci & Technol, Huizhou 516007, Peoples R China.
   [Wen, Long] Xian Satellite Monitoring & Control Ctr, Ground Stn Network Management Ctr, Xian 710043, Shaanxi, Peoples R China.
   [Ren, Teng] Cent South Univ Forestry & Technol, Sch Transportat & Logist, Changsha 410004, Hunan, Peoples R China.
C3 Shijiazhuang Tiedao University; Huizhou University; Central South
   University of Forestry & Technology
RP Cai, ZQ (corresponding author), Huizhou Univ, Dept Informat Sci & Technol, Huizhou 516007, Peoples R China.; Ren, T (corresponding author), Cent South Univ Forestry & Technol, Sch Transportat & Logist, Changsha 410004, Hunan, Peoples R China.
EM 13502279833@126.com
RI 任, 腾/HGA-2531-2022
OI 任, 腾/0000-0003-2867-5918
FU National Natural Science Foundation of China [61772225, 51678239,
   61773120]; Foundation for Distinguished Young Talents in Higher
   Education of Guangdong, China [2015KQNCX153]; Science and Technology
   Program of Huizhou, China [201513010002002]; Science and Technology
   Program of Huizhou [2016X0431046, 2016X0432047, 2016X0434049]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61772225, 51678239 and 61773120). This research is also
   supported by the Foundation for Distinguished Young Talents in Higher
   Education of Guangdong, China under Grant 2015KQNCX153, Science and
   Technology Program of Huizhou, China under Grant 201513010002002, and
   Science and Technology Program of Huizhou (2016X0431046, 2016X0432047,
   2016X0434049).
CR Ahandani MA, 2015, INFORM SCIENCES, V291, P19, DOI 10.1016/j.ins.2014.08.031
   Akay B, 2012, J INTELL MANUF, V23, P1001, DOI 10.1007/s10845-010-0393-4
   Al-Tabtabai H., 1999, ENG CONSTR ARCHIT MA, V6, P121, DOI [10.1108/eb021105, DOI 10.1108/EB021105]
   ALIREZA RV, 2008, INT J ADV MANUF TECH, V41, P1227
   Aminian F, 2002, IEEE T INSTRUM MEAS, V51, P544, DOI 10.1109/TIM.2002.1017726
   Aminian F, 2001, J ELECTRON TEST, V17, P471, DOI 10.1023/A:1012864504306
   Aminian M, 2000, IEEE T CIRCUITS-II, V47, P151, DOI 10.1109/82.823545
   Amy H.I.L., 2008, EXPERT SYSTEMS APPL, V36, P7917
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Auger A, 2005, IEEE C EVOL COMPUTAT, P1777
   Brajevic I, 2013, J INTELL MANUF, V24, P729, DOI 10.1007/s10845-011-0621-6
   Chakaravarthy GV, 2013, J INTELL MANUF, V24, P175, DOI 10.1007/s10845-011-0552-2
   Chen A. Z., 2011, J INT TRADE, V4, P115
   CHEN AZ, 2008, J NANJING U PHILOS H, V1, P36
   Deng Y, 2012, METROL MEAS SYST, V19, P203, DOI 10.2478/v10178-012-0018-7
   Ding JL, 2014, NEUROCOMPUTING, V137, P261, DOI 10.1016/j.neucom.2013.03.075
   Elbeltagi E, 2007, STRUCT INFRASTRUCT E, V3, P53, DOI 10.1080/15732470500254535
   Eslami M, 2012, INT J ELEC POWER, V43, P1467, DOI 10.1016/j.ijepes.2012.07.028
   Eusuff MM, 2003, J WATER RES PLAN MAN, V129, P210, DOI 10.1061/(ASCE)0733-9496(2003)129:3(210)
   Guo C. Y., 2012, RES FINANCIAL EC ISS, V6, P17
   Guo LH, 2014, NEUROCOMPUTING, V138, P392, DOI 10.1016/j.neucom.2014.01.023
   He Y, 2004, IEE P-CIRC DEV SYST, V151, P379, DOI 10.1049/ip-cds:20040495
   He Y., 2013, SCI SCI MANAG S T, V34, P13, DOI [10.13502/j.cnki.issn1000-7636.2020.12.003, DOI 10.13502/J.CNKI.ISSN1000-7636.2020.12.003]
   Hu Z. H., 2011, SCI SCI MANAGEMENT S, V7, P104
   Huynh T. -H., 2008, P INT C INF TECHN IC, P21
   Ikewelugo C., 2012, OPEN J STAT, V12, P172, DOI [10.4236/ojs.2012.22019, DOI 10.4236/OJS.2012.22019]
   Jin YX, 2011, ADV INTEL SOFT COMPU, V106, P493
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kumar S, 2010, IEEE T INSTRUM MEAS, V59, P2055, DOI 10.1109/TIM.2009.2032884
   Lakshmi K, 2013, COMPUT STRUCT, V125, P200, DOI 10.1016/j.compstruc.2013.05.004
   Lee K, 2001, RES POLICY, V30, P459, DOI 10.1016/S0048-7333(00)00088-3
   Li F.C., 2013, INT EC TRADE RES, P95
   Li GQ, 2012, APPL SOFT COMPUT, V12, P320, DOI 10.1016/j.asoc.2011.08.040
   Li M, 2013, J ELECTRON TEST, V29, P567, DOI 10.1007/s10836-013-5383-y
   Li MQ, 2012, APPL SOFT COMPUT, V12, P975, DOI 10.1016/j.asoc.2011.11.032
   Li X, 2012, INFORM SCIENCES, V192, P143, DOI 10.1016/j.ins.2010.07.016
   Li X, 2011, INTELL AUTOM SOFT CO, V17, P219, DOI 10.1080/10798587.2011.10643144
   Liu Si-feng, 2010, Systems Engineering and Electronics, V32, P313
   Long B, 2014, NEUROCOMPUTING, V133, P237, DOI 10.1016/j.neucom.2013.11.012
   Long B, 2013, CIRC SYST SIGNAL PR, V32, P2683, DOI 10.1007/s00034-013-9614-3
   Long B, 2012, J ELECTRON TEST, V28, P291, DOI 10.1007/s10836-011-5275-y
   Lu XF, 2014, NEUROCOMPUTING, V146, P2, DOI 10.1016/j.neucom.2014.04.071
   Luo Xue-hui, 2009, Journal on Communications, V30, P130
   Mahmood IP, 2004, J ECON BEHAV ORGAN, V54, P513, DOI 10.1016/j.jebo.2002.12.003
   Matsumura T, 2009, J ECON, V98, P203, DOI 10.1007/s00712-009-0091-x
   Niknam T, 2011, EXPERT SYST APPL, V38, P13301, DOI 10.1016/j.eswa.2011.04.151
   Pan QK, 2014, KNOWL-BASED SYST, V62, P69, DOI 10.1016/j.knosys.2014.02.021
   PAVITT K, 1984, RES POLICY, V13, P343, DOI 10.1016/0048-7333(84)90018-0
   Purwoharjono, 2013, Journal of Theoretical and Applied Information Technology, V47, P460
   Rahimi-Vahed A, 2008, SOFT COMPUT, V12, P435, DOI 10.1007/s00500-007-0210-y
   Rahimi-Vahed A, 2007, COMPUT IND ENG, V53, P642, DOI 10.1016/j.cie.2007.06.007
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rao RV, 2013, SCI IRAN, V20, P710, DOI 10.1016/j.scient.2012.12.005
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Roy P, 2013, APPL SOFT COMPUT, V13, P4244, DOI 10.1016/j.asoc.2013.07.006
   Seçkiner SU, 2013, APPL MATH COMPUT, V219, P4163, DOI 10.1016/j.amc.2012.10.097
   Shi YB, 2013, CIRC SYST SIGNAL PR, V32, P2151, DOI 10.1007/s00034-013-9589-0
   Stanarevic N., 2011, International Journal of Mathematical Models and Methods in applied Sciences, V5, P644
   Tang B., 2012, MACROECONOMIC MANAGE, V7, P67
   Tanweer MR, 2015, INFORM SCIENCES, V294, P182, DOI 10.1016/j.ins.2014.09.053
   Tarique A., 2013, INTELL CONTROL AUTOM, V4, P126, DOI [10.4236/ica.2013.42018, DOI 10.4236/ICA.2013.42018]
   Tomaru Y, 2007, RES ECON, V61, P224, DOI 10.1016/j.rie.2007.05.003
   Vasan ASS, 2013, IEEE T IND ELECTRON, V60, P5277, DOI 10.1109/TIE.2012.2224074
   Vichare NM, 2006, IEEE T COMPON PACK T, V29, P222, DOI [10.1109/TCAPT.2006, 10.1109/TCAPT.2006.]
   Wang Y, 2013, IEEE T RELIAB, V62, P136, DOI 10.1109/TR.2013.2241204
   Wu F. F., 2015, SOFT SCI, V11, P11
   Xu, 2011, J COMPUT INF SYST, V7, P1582
   Xu L, 2010, CIRCUIT SYST SIGNAL, V29, P277
   Yang J. Q., 2007, EC MANAGEMENT, V19, P29
   Yu KJ, 2016, J INTELL MANUF, V27, P831, DOI 10.1007/s10845-014-0918-3
   Yu X. Z., 2010, FINANCE EC, P58
   Yuan LF, 2010, IEEE T INSTRUM MEAS, V59, P586, DOI 10.1109/TIM.2009.2025068
   Zakic N., 2008, Economics and Organization, V5, P17, DOI DOI 10.1080/09523987.2012.738015
   Zhang CL, 2014, J ELECTRON TEST, V30, P343, DOI 10.1007/s10836-014-5454-8
   Zhang S., 2014, J INTELL MANUF, DOI [10.1007/510845-014-1023-3, DOI 10.1007/510845-014-1023-3]
   Zhang W., 2016, J SYST MANAGE, V4, P705
   Zhang XD, 2012, AEU-INT J ELECTRON C, V66, P448, DOI 10.1016/j.aeue.2011.10.004
   Zhang XL, 2015, J INTELL MANUF, V26, P359, DOI 10.1007/s10845-013-0789-z
   Zhang Z. Q., 2013, MANAGEMENT WORLD, V1, P115
   Zhou Jingyu, 2014, ScientificWorldJournal, V2014, P530942, DOI 10.1155/2014/530942
   Zou F, 2014, INFORM SCIENCES, V273, P112, DOI 10.1016/j.ins.2014.03.038
   Zuo Lei, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P75, DOI 10.1109/ETCS.2010.255
NR 82
TC 24
Z9 25
U1 5
U2 68
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 37
EP 45
DI 10.1016/j.jvcir.2018.10.024
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HK1MD
UT WOS:000457668100004
DA 2024-07-18
ER

PT J
AU Li, S
   Chen, JP
   Xiang, J
   Pan, Y
   Huang, ZY
   Wu, YL
AF Li, Shi
   Chen, Jianping
   Xiang, Jie
   Pan, Yun
   Huang, Zhiyong
   Wu, Yongliang
TI Water level changes of Hulun Lake in Inner Mongolia derived from Jason
   satellite data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Jason satellite; Hulun Lake; Water level; Landsat; GRACE
ID SEA-LEVEL; TIBETAN PLATEAU; ALTIMETRY DATA; TOPEX/POSEIDON; CHINA;
   RETRACKING
AB Water levels in lakes can reflect changes in such bodies. Therefore, there is value in identifying the variations in water levels using observations from altimetry satellites and analyzing the possible causes. In this work, the water-level changes of Hulun Lake in Inner Mongolia during the period from 2002 to 2015 are monitored by the use of Jason satellite data, the results of which are compared with historical data. Landsat TW/ETM/OLI_TRIS remote sensing images are analyzed, and the surface area of the lake extracted from them and converted to the corresponding water level to verify the values obtained from the Jason observations. The results show a downward trend after 2000 (-0.98 mm/year) and a sharp increase after 2012 (3.07 mm/year). The root mean square error (RMSE) between the two methods was 0.2369 m, and the correlation coefficient was 0.986. By analyzing the various influencing factors, we draw the conclusion that the water level of Hulun Lake is affected by both natural factors (e.g., rainfall, runoff, evapotranspiration etc.) and anthropogenic influences (e.g., water consumption in coal mining, overgrazing, etc.). These are the main causes of the decrease in the area of Hulun Lake and other lakes in the Inner Mongolia Autonomous Region. By comparing the lake storage anomalies of Hulun Lake with the terrestrial Total Water Storage anomalies (TWSA) inverted from GRACE satellite data and the Surface Water Storage anomalies (SWSA) from WaterGAP Global Hydrology Model (WGHM) within the Hulun Basin, we find that not only do Hulun Lake and basin interact with each other, but also that Hulun Lake has an important function with regards to the changes within the basin as a whole. This work therefore provides a method for monitoring the dynamic changes of lake water levels, while analyzing the influencing factors based on multi-scale data. Such a method shows potential for being applied to efforts to ensure environmental protection. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Li, Shi; Chen, Jianping] China Univ Geosci Beijing, Sch Earth Sci & Resources, Beijing 100083, Peoples R China.
   [Xiang, Jie] CAGS, MNR Key Lab Metallogeny & Mineral Assessment, Inst Mineral Resources, Beijing 100037, Peoples R China.
   [Pan, Yun] Capital Normal Univ, Beijing Lab Water Resources Secur, Beijing 100048, Peoples R China.
   [Pan, Yun] Capital Normal Univ, State Key Lab Base Urban Environm Proc & Digital, Beijing 100048, Peoples R China.
   [Huang, Zhiyong] Univ Hong Kong, Dept Earth Sci, Hong Kong, Peoples R China.
   [Wu, Yongliang] China Astronaut Stand Inst, Beijing 100071, Peoples R China.
C3 China University of Geosciences; Capital Normal University; Capital
   Normal University; University of Hong Kong
RP Chen, JP (corresponding author), China Univ Geosci, 29 Xueyuan Rd, Beijing 100083, Peoples R China.; Xiang, J (corresponding author), Chinese Acad Geol Sci, 37 Baiwanzhuang St, Beijing 100037, Peoples R China.
EM 1176629242@qq.com; 3s@cugb.edu.cn; xiangjie@cugb.edu.cn
RI Pan, Yun/AAF-1060-2020; Huang, Zhiyong/IAR-0341-2023
OI Huang, Zhiyong/0000-0001-7497-5036; Xiang, Jie/0000-0001-5437-1884
FU National Natural Science Foundation of China [41490634]; Ministry of
   Science and Technology of the People's Republic of China [2015FY210500]
FX This research was financially supported by National Natural Science
   Foundation of China (No. 41490634) and the Ministry of Science and
   Technology of the People's Republic of China (No. 2015FY210500).
CR Birkett CM, 1995, J GEOPHYS RES-OCEANS, V100, P25179, DOI 10.1029/95JC02125
   Chen JL, 2017, J GEOPHYS RES-SOL EA, V122, P2274, DOI 10.1002/2016JB013595
   Cheng YC, 2014, INT J REMOTE SENS, V35, P4329, DOI 10.1080/01431161.2014.916050
   [褚永海 Chu Yonghai], 2005, [大地测量与地球动力学, Journal of Geodesy and Geodynamics], V25, P11
   Duan Z, 2013, REMOTE SENS ENVIRON, V134, P403, DOI 10.1016/j.rse.2013.03.010
   Feng L, 2016, REMOTE SENS ENVIRON, V176, P43, DOI 10.1016/j.rse.2016.01.011
   [高永刚 GAO Yonggang], 2008, [测绘科学, Science of Surveying and Mapping], V33, P73
   Han G, 2008, INT J REMOTE SENS, V29, P265, DOI 10.1080/01431160701271982
   Huang ZY, 2015, GEOPHYS RES LETT, V42, P1791, DOI 10.1002/2014GL062498
   Hwang CW, 2005, GEOPHYS J INT, V161, P1, DOI 10.1111/j.1365-246X.2005.02518.x
   Idris NH, 2014, INT J REMOTE SENS, V35, P1729, DOI 10.1080/01431161.2014.882032
   [蒋涛 Jiang Tao], 2010, [测绘学报, Acta Geodetica et Cartographica Sinica], V39, P135
   Jiang Weiping, 2008, Geomatics and Information Science of Wuhan University, V33, P64
   [李建成 LI Jiancheng], 2007, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V32, P144
   [李静 Li Jing], 2015, [河海大学学报. 自然科学版, Journal of Hohai University. Natural Sciences], V43, P163
   [李景刚 Li Jinggang], 2010, [自然资源学报, Journal of Natural Resources], V25, P502
   Li X. R., 2014, METEOR J INNER MONGO, V6, P26
   Liu JS, 2009, GLOBAL PLANET CHANGE, V67, P209, DOI 10.1016/j.gloplacha.2009.03.010
   Liu Y, 2017, ENVIRON MONIT ASSESS, V189, DOI 10.1007/s10661-017-6346-z
   Masters D, 2012, MAR GEOD, V35, P20, DOI 10.1080/01490419.2012.717862
   Medina CE, 2008, REMOTE SENS ENVIRON, V112, P3604, DOI 10.1016/j.rse.2008.05.001
   Mercier F, 2002, GLOBAL PLANET CHANGE, V32, P141, DOI 10.1016/S0921-8181(01)00139-4
   Ni SN, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080842
   Ponchaut F, 1998, CR ACAD SCI II A, V326, P13, DOI 10.1016/S1251-8050(97)83198-9
   Schmalz B, 2015, ECOHYDROLOGY, V8, P1119, DOI 10.1002/eco.1569
   Tao SL, 2015, P NATL ACAD SCI USA, V112, P2281, DOI 10.1073/pnas.1411748112
   Troitskaya Y, 2012, INT J REMOTE SENS, V33, P7559, DOI 10.1080/01431161.2012.685972
   Phan VH, 2012, INT J APPL EARTH OBS, V17, P12, DOI 10.1016/j.jag.2011.09.015
   Wang XW, 2013, REMOTE SENS ENVIRON, V132, P131, DOI 10.1016/j.rse.2013.01.005
   [闫立娟 Yan Lijuan], 2012, [地球学报, Acta Geoscientia Sinica], V33, P65
   Ye QH, 2008, J GLACIOL, V54, P933, DOI 10.3189/002214308787779997
   Zhang GQ, 2011, REMOTE SENS ENVIRON, V115, P1733, DOI 10.1016/j.rse.2011.03.005
   [张继群 Zhang Jiqun], 2004, [地理学报, Acta Geographica Sinica], V59, P95
   Zhao F., 1992, HULUNBEIR LEAGUE HYD, P107
   Zhu WB, 2014, REMOTE SENS-BASEL, V6, P10457, DOI 10.3390/rs61110457
NR 35
TC 34
Z9 39
U1 4
U2 72
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 565
EP 575
DI 10.1016/j.jvcir.2018.12.031
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100055
DA 2024-07-18
ER

PT J
AU Xu, YJ
   Chen, JG
   Meng, PY
AF Xu, Yuanjin
   Chen, Jianguo
   Meng, Pengyan
TI Detection of alteration zones using hyperspectral remote sensing data
   from Dapingliang skarn copper deposit and its surrounding area, Shanshan
   County, Xinjiang Uygur autonomous region, China
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral remote sensing; Detection of alteration zones; Dapingliang
   skarn copper deposit; Spectral matching
ID HYDROTHERMAL ALTERATION ZONES; ALTERED ROCKS; EO-1 HYPERION; LUDWIG
   SKARN; NEVADA; EXPLORATION; YERINGTON; MINERALS; PROVINCE; SPECTRA
AB In application of hyperspectral remote sensing, alteration zones are primarily detected by identifying alteration mineral assemblages, but the interpretation of alteration mineral maps is often complicated by surface materials and by minerals not directly associated with alteration. This study was conducted in the Dapingliang skarn copper deposit and its surrounding area, the Shanshan County of the Xinjiang Uygur autonomous region, China. In order to successfully detect alteration zones associated with skarns, this study identified skarns rather than alteration minerals using field spectra of skarn outcrops. In this study, skarn in pixels was identified from spectral overall shape and spectral shapes of absorption-bands; SAM (spectral angle mapper) was applied in the identification. When SAM scores of spectral overall shape were less than 0.022 rad, the identified skarns were mainly distributed in the contact zones of intrusive rocks and carbonates; in particular, the three identified skarns areas (R1, R2 and R3) were consistent with the skarn areas in the geological map of the study area. The field inspection of skarns showed that the identified objects of the three marked targets (A, B and C) were almost consistent with the ground objects. These obtained results demonstrated that using the field spectra, it was possible to identify skarns in the hyperspectral image. To evaluate the identified skarn zones for use in mineral exploration, the end-member spectra extracted from the image were analysed, and alteration zones were detected using these end-member spectra. Compared with these alteration zones, the identified skarn zones were more reliable for mineral exploration of the study area. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Xu, Yuanjin; Chen, Jianguo] China Univ Geosci, Fac Earth Resources, Inst Math Geol & Remote Sensing Geol, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
   [Meng, Pengyan] Hubei Inst Land Surveying & Mapping, 199 Aomen Rd, Wuhan 430010, Hubei, Peoples R China.
C3 China University of Geosciences
RP Xu, YJ; Chen, JG (corresponding author), China Univ Geosci, Fac Earth Resources, Inst Math Geol & Remote Sensing Geol, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
EM yuanjinzu@163.com; jgchen@cug.edu.cn
RI Chen, Jianguo/P-6979-2019
OI Chen, Jianguo/0000-0001-5009-578X
FU National Key R&D Program of China [2017YFC0601504, 2017YFC0601500];
   National Natural Science Foundation of China [41872252]
FX This project is supported by the National Key R&D Program of China (No.
   2017YFC0601504 and 2017YFC0601500), and the National Natural Science
   Foundation of China (No. 41872252).
CR Baugh WM, 1998, REMOTE SENS ENVIRON, V65, P292, DOI 10.1016/S0034-4257(98)00039-X
   Bedini E, 2009, INT J REMOTE SENS, V30, P327, DOI 10.1080/01431160802282854
   Bishop CA, 2011, INT J REMOTE SENS, V32, P2409, DOI 10.1080/01431161003698336
   Cao X. F., 2012, THESIS, P96
   Cudahy T.J., 2008, Exploration and Mining Report P2007/364
   Debba P, 2005, REMOTE SENS ENVIRON, V99, P373, DOI 10.1016/j.rse.2005.05.005
   Duke EF, 2010, AM MINERAL, V95, P908, DOI 10.2138/am.2010.3281
   Galvao LS, 2005, INT J APPL EARTH OBS, V7, P107, DOI 10.1016/j.jag.2004.12.003
   Gersman R, 2008, INT J REMOTE SENS, V29, P3911, DOI 10.1080/01431160701874587
   Hecker C, 2008, IEEE T GEOSCI REMOTE, V46, P4162, DOI 10.1109/TGRS.2008.2001035
   Hubbard BE, 2003, IEEE T GEOSCI REMOTE, V41, P1401, DOI 10.1109/TGRS.2003.812906
   Kruse FA, 2003, IEEE T GEOSCI REMOTE, V41, P1388, DOI 10.1109/TGRS.2003.812908
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   Kruse FA, 2006, ANN GEOPHYS-ITALY, V49, P83
   Kruse FA, 2012, GEOMORPHOLOGY, V137, P41, DOI 10.1016/j.geomorph.2010.09.032
   Laukamp C, 2011, GEOCHEM-EXPLOR ENV A, V11, P3, DOI 10.1144/1467-7873/09-231
   Lei J. H., 2004, XINJIANG GEOPHYSICAL, P1
   Liu L, 2017, ORE GEOL REV, V81, P280, DOI 10.1016/j.oregeorev2016.10.007
   Pour AB, 2013, ORE GEOL REV, V54, P181, DOI 10.1016/j.oregeorev.2013.03.010
   Qin KZ, 2002, RESOUR GEOL, V52, P291, DOI 10.1111/j.1751-3928.2002.tb00140.x
   Rowan LC, 2003, REMOTE SENS ENVIRON, V84, P350, DOI 10.1016/S0034-4257(02)00127-X
   Rowan LC, 2000, J GEOCHEM EXPLOR, V68, P145, DOI 10.1016/S0375-6742(99)00081-3
   van der Meer F, 2006, INT J APPL EARTH OBS, V8, P3, DOI 10.1016/j.jag.2005.06.001
   Van der Meer F., 2004, INT J APPL EARTH OBS, V5, P55, DOI DOI 10.1016/J.JAG.2003.09.001
   van der Meer FD, 2012, INT J APPL EARTH OBS, V14, P112, DOI 10.1016/j.jag.2011.08.002
   Wang JB, 2004, ACTA GEOL SIN-ENGL, V78, P337
   WINDELER DS, 1993, PHOTOGRAMM ENG REM S, V59, P1277
   WINDELER DS, 1991, PHOTOGRAMM ENG REM S, V57, P1171
   Xu YJ, 2010, J INDIAN SOC REMOTE, V38, P169, DOI 10.1007/s12524-010-0016-8
NR 29
TC 8
Z9 8
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 67
EP 78
DI 10.1016/j.jvcir.2018.11.032
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100008
DA 2024-07-18
ER

PT J
AU Wang, SK
   Zhang, XY
   Chen, L
   Zhou, HY
   Dong, JY
AF Wang, Shengke
   Zhang, Xiaoyan
   Chen, Long
   Zhou, Huiyu
   Dong, Junyu
TI Asymmetric filtering-based dense convolutional neural network for person
   re-identification combined with Joint Bayesian and re-ranking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Joint Bayesian; Deep convolutional neural
   networks; Multimodal features
AB Person re-identification aims at matching individuals across multiple camera views under surveillance systems. The major challenges lie in the lack of spatial and temporal cues, which makes it difficult to cope with large variations of lighting conditions, viewing angles, body poses and occlusions. How to extract multimodal features including facial features, physical features, behavioral features, color features, etc is still a fundamental problem in person re-identification. In this paper, we propose a novel Convolutional Neural Network, called Asymmetric Filtering-based Dense Convolutional Neural Network (AF D-CNN) to learn powerful features, which can extract different levels' features and take advantage of identity information. Moreover, instead of using typical metric learning methods, we obtain the ranking lists by merging Joint Bayesian and re-ranking techniques which do not need dimensionality reduction. Finally, extensive experiments show that our proposed architecture performs well on four popular benchmark datasets (CUHK01, CUHK03, Market-1501, DukeMTMC-reID). (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Shengke; Zhang, Xiaoyan; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Chen, Long; Zhou, Huiyu] Univ Leicester, Dept Informat, Leicester, Leics, England.
C3 Ocean University of China; University of Leicester
RP Wang, SK (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
EM neverme@ouc.edu.cn
RI ARSLAN, Okan/AAA-3232-2020; Zhou, Huiyu/O-2692-2014
OI Zhou, Huiyu/0000-0003-1634-9840; Dong, Junyu/0000-0001-7012-2087
FU National Natural Science Foundation of China (NSFC) [U1706218, 61602229,
   41606198, 61501417, 41706010]; Natural Science Foundation of Shandong
   Provincial [ZR2016FM13, ZR2016FB02]; European Union [720325
   FoodSmartphone]; UK EPSRC [EP/N011074/1]; Royal Society-Newton Advanced
   Fellowship [NA160342]; EPSRC [EP/N011074/1] Funding Source: UKRI
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) Grants U1706218, 61602229, 41606198, 61501417 and 41706010,
   Natural Science Foundation of Shandong Provincial ZR2016FM13,
   ZR2016FB02. H. Zhou was supported in part by the European Union's
   Horizon 2020 research and innovation program nder the
   Marie-Sklodowska-Curie grant agreement No 720325 FoodSmartphone, the UK
   EPSRC under Grant EP/N011074/1 and the Royal Society - Newton Advanced
   Fellowship under Grant NA160342.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], LEARNING DEEP EMBEDD
   [Anonymous], COMPUT SCI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2013, IEEE INT C IM PROC D
   [Anonymous], 2009, DISTANCE METRIC LEAR
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 2014, PERSON RE IDENTIFICA
   [Anonymous], P 27 INT JOINT C ART
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2012, STOCHASTIC GRADIENT
   [Anonymous], ACM INT C MULT
   [Anonymous], SOFT COMPUTING PATTE
   [Anonymous], ASPECT AWARE LATENT
   [Anonymous], 2017, CVPR
   [Anonymous], 2018, NEURAL COMPATIBILITY
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Davis J. V., 2007, ICML, P209
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   García J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154
   Globerson A., 2005, ADV NEURAL INFORM PR
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li Dangwei, 2017, CVPR, P384
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin J, 2017, IEEE PAC RIM CONF CO
   Liu Hao, 2016, ARXIV160604404
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma AJ, 2015, LECT NOTES COMPUT SC, V9007, P397, DOI 10.1007/978-3-319-16814-2_26
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Mang Ye, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P105, DOI 10.1007/978-3-319-14445-0_10
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Ustinova E., 2017, AVSS, P1
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang Y, 2016, AAAI CONF ARTIF INTE, P3655
   Ye M., 2016, IEEE Trans. Multimedia PP, P1
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L., 2016, Person Re-identification: Past, Present and Future
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou SP, 2017, PROC CVPR IEEE, P5028, DOI 10.1109/CVPR.2017.534
NR 65
TC 2
Z9 2
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 262
EP 271
DI 10.1016/j.jvcir.2018.11.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400031
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, Y
   Chung, K
AF Kim, Yunho
   Chung, Kwangsue
TI Multipath-based transmission scheme for improving the QoE of HTTP
   adaptive streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HTTP adaptive streaming; Quality of experience; Multipath
ID EXPERIENCE; QUALITY
AB The number of users using multimedia streaming services in various environments is increasing. Accordingly, HyperText Transfer Protocol (HTTP) adaptive streaming has attracted attention. Recently, there have been many studies on schemes for improving the Quality of Experience (QoE) by using multipaths in HTTP adaptive streaming. Downloading segments at the same time using multipaths can take up a high amount of bandwidth and make the transmission robust to data loss. However, when the bandwidths of the multipaths are aggregated, the variation of the bandwidth fluctuation increases, so quality changes occur more frequently. Additionally, it takes time to reorder the segments due to different segment download times received through the multipath. To this end, we propose a multipath-based transmission scheme to improve the QoE of HTTP adaptive streaming in the multipath environment. The proposed scheme improves the QoE by increasing the average video quality and reducing the frequency of video quality changes.
C1 [Kim, Yunho; Chung, Kwangsue] Kwangwoon Univ, Dept Elect & Commun Engn, Chambit 809,447-1 Wolgye Dong, Seoul, South Korea.
C3 Kwangwoon University
RP Chung, K (corresponding author), Kwangwoon Univ, Dept Elect & Commun Engn, Chambit 809,447-1 Wolgye Dong, Seoul, South Korea.
EM kchung@kw.ac.kr
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government (MSIT) [2017-0-00224]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government (MSIT)
   (No. 2017-0-00224, Development of generation, distribution and
   consumption technologies of dynamic media based on UHD broadcasting
   contents).
CR [Anonymous], HTTP DYN STREAM
   [Anonymous], 2011, ACM IMC 11
   [Anonymous], P 4 WORKSH MOB VID C
   [Anonymous], SMOOTH STRESM
   Apple, HTTP Live Streaming Overview
   Begen AC, 2011, IEEE INTERNET COMPUT, V15, P54, DOI 10.1109/MIC.2010.155
   Chen YC, 2016, IEEE J SEL AREA COMM, V34, P2198, DOI 10.1109/JSAC.2016.2577322
   Cisco, 2017, Cisco7 Feb.
   Evensen Kristian., 2011, Proceedings of the second annual ACM conference on Multimedia systems, P57
   Go Y, 2015, IEEE T MULTIMEDIA, V17, P1646, DOI 10.1109/TMM.2015.2451951
   Gouache S, 2011, IEEE INT CON MULTI
   Han B, 2016, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'16), P129, DOI 10.1145/2999572.2999606
   Hesmans B, 2013, PROCEEDINGS OF THE 2013 WORKSHOP ON HOT TOPICS IN MIDDLEBOXES AND NETWORK FUNCTION VIRTUALIZATION (HOTMIDDLEBOX'13), P37, DOI 10.1145/2535828.2535830
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Koo J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P934, DOI 10.1145/3123266.3123368
   Kuschnig R., 2011, MMSYS, P245
   Oyman O, 2012, IEEE COMMUN MAG, V50, P20, DOI 10.1109/MCOM.2012.6178830
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Zhou C, 2014, IEEE T CIRC SYST VID, V24, P681, DOI 10.1109/TCSVT.2013.2290580
NR 21
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 12
EP 20
DI 10.1016/j.jvcir.2018.05.017
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100002
DA 2024-07-18
ER

PT J
AU Wu, HM
   Weng, J
   Chen, X
   Lu, W
AF Wu, Huimin
   Weng, Jian
   Chen, Xin
   Lu, Wei
TI Feedback weight convolutional neural network for gait recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; Deep learning; Convolutional neural network; Weighted
   receptive field
ID VIEW TRANSFORMATION MODEL; IMAGE
AB Gait recognition is an important issue currently. In this paper, we propose to combine deep features and hand-crafted representations into a globally trainable deep model. Specifically, a set of deep feature vectors are firstly extracted by a pre-trained CNN model from the input sequences. Then, a kernel function with respect to the fully connected vector is trained as the guiding weight of the respective receptive fields of the input sequences. Therefore, the hand-crafted features are extracted based on the guiding weight. Finally, the hand-crafted features and the deep features are combined into a unified deep network to complete classification. The optimized gait descriptor, termed as deep convolutional location weight descriptor (DLWD), is capable of effectively revealing the importance of different body parts to gait recognition accuracy. Experiments on two gait data sets (i.e., CASIA-B, OU-ISIR) show that our method outperforms the other existing methods for gait recognition.
C1 [Wu, Huimin; Weng, Jian; Chen, Xin] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
   [Lu, Wei] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
C3 Jinan University; Sun Yat Sen University
RP Weng, J (corresponding author), Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
EM wuhuiminchn@sina.com; cryptjweng@gmail.com; chenxin@stu.jnu.edu.cn;
   luwei3@mail.sysu.edu.cn
OI Weng, Jian/0000-0003-4067-8230
FU National Key RD Plan of China [2017YFB0802203, 2018YFB1003701]; National
   Natural Science Foundation of China [U1736203, U1736118, 61732021,
   61472165, 61373158]; Guangdong Provincial Engineering Technology
   Research Center on Network Security Detection and Defence
   [2014B090904067]; Guangdong Provincial Special Funds for Applied
   Technology Research and Development and Transformation of Important
   Scientific and Technological Achieve [2016B010124009]; Zhuhai Top
   Discipline-Information Security; Guangzhou Key Laboratory of Data
   Security and Privacy Preserving; Guangdong Key Laboratory of Data
   Security and Privacy Preserving; National Joint Engineering Research
   Center of Network Security Detection and Protection Technology; Natural
   Science Foundation of Guangdong [2016A030313350]; Special Funds for
   Science and Technology Development of Guangdong [2016KZ010103]; Key
   Project of Scientific Research Plan of Guangzhou [201804020068];
   Fundamental Research Funds for the Central Universities [16lgjc83,
   17lgjc45]
FX This work was supported by National Key R&D Plan of China (Grant No.
   2017YFB0802203 and 2018YFB1003701), National Natural Science Foundation
   of China (Grant Nos. U1736203, U1736118, 61732021, 61472165 and
   61373158), Guangdong Provincial Engineering Technology Research Center
   on Network Security Detection and Defence (Grant No. 2014B090904067),
   Guangdong Provincial Special Funds for Applied Technology Research and
   Development and Transformation of Important Scientific and Technological
   Achieve (Grant No. 2016B010124009), the Zhuhai Top
   Discipline-Information Security, Guangzhou Key Laboratory of Data
   Security and Privacy Preserving, Guangdong Key Laboratory of Data
   Security and Privacy Preserving, National Joint Engineering Research
   Center of Network Security Detection and Protection Technology, the
   Natural Science Foundation of Guangdong (No. 2016A030313350), the
   Special Funds for Science and Technology Development of Guangdong (No.
   2016KZ010103), the Key Project of Scientific Research Plan of Guangzhou
   (No. 201804020068), the Fundamental Research Funds for the Central
   Universities (No. 16lgjc83 and No. 17lgjc45).
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ICPR 2006 18 INT C P
   [Anonymous], 2017, IEEE C COMP VIS PATT
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bouchrika I, 2009, LECT NOTES COMPUT SC, V5558, P990, DOI 10.1007/978-3-642-01793-3_100
   Bouchrika I., 2008, 8th IEEE International Conference on Automatic Face Gesture Recognition, P1, DOI [10.1109/AFGR.2008.4813395., DOI 10.1109/AFGR.2008.4813395]
   Boulgouris NV, 2007, IEEE T IMAGE PROCESS, V16, P731, DOI 10.1109/TIP.2007.891157
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Chen X, 2014, J VIS COMMUN IMAGE R, V25, P1842, DOI 10.1016/j.jvcir.2014.09.002
   Chen X, 2018, IEEE T NEUR NET LEAR, V29, P3938, DOI 10.1109/TNNLS.2017.2740318
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Chen X, 2017, MACH VISION APPL, V28, P117, DOI 10.1007/s00138-016-0810-6
   Chen X, 2016, MULTIMED TOOLS APPL, V75, P6505, DOI 10.1007/s11042-015-2585-6
   Chen X, 2016, PATTERN RECOGN, V53, P116, DOI 10.1016/j.patcog.2015.11.016
   Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fu D, 2016, ENERGY, V113, P1, DOI 10.1016/j.energy.2016.07.049
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P1489, DOI 10.1016/j.jvcir.2014.05.006
   Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618
   Lin L, 2016, INT J COMPUT VISION, V118, P256, DOI 10.1007/s11263-015-0876-z
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Martín-Félez R, 2014, PATTERN RECOGN, V47, P3793, DOI 10.1016/j.patcog.2014.06.010
   Muramatsu D., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P85, DOI 10.1109/BTAS.2012.6374561
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Muramatsu D, 2015, IET BIOMETRICS, V4, P62, DOI 10.1049/iet-bmt.2014.0042
   Padole C, 2017, PATTERN ANAL APPL, V20, P73, DOI 10.1007/s10044-015-0468-0
   Rida I, 2017, SIGNAL PROC SEC TEC, P141, DOI 10.1007/978-3-319-47301-7_6
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Shi BG, 2016, PATTERN RECOGN, V52, P448, DOI 10.1016/j.patcog.2015.11.005
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Singh S, 2016, PROC CVPR IEEE, P2620, DOI 10.1109/CVPR.2016.287
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 56
TC 26
Z9 28
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 424
EP 432
DI 10.1016/j.jvcir.2018.06.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100035
DA 2024-07-18
ER

PT J
AU Ghosh, P
   Mali, K
   Das, SK
AF Ghosh, Partha
   Mali, Kalyani
   Das, Sitansu Kumar
TI Chaotic firefly algorithm-based fuzzy C-means algorithm for segmentation
   of brain tissues in magnetic resonance images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FCM; FAFCM; En-FAOFCM; Bias field; Spatial information; Total variation;
   PVE; Tanimoto coefficient and dice similarity
ID GAUSSIAN MIXTURE MODEL; BIAS FIELD ESTIMATION; CLUSTERING-ALGORITHM;
   SPATIAL INFORMATION; MRI SEGMENTATION; NEURAL-NETWORK
AB Image segmentation with clustering approach is widely used in biomedical application. Accurate brain Magnetic Resonance (MR) image segmentation is a challenging task due to the complex anatomical structure of brain tissues in addition to the existence of intensity inhomogeneity, partial volume effects and noise. In this study, a spatial modified bias corrected FCM algorithm is applied to brain MRI for the purpose of segmentation into White Matter (WM), Gray Matter (GM) and Cerebrospinal fluid (CSF) in MR images. So to overcome the uncertainty caused by the above effects, a modified Fuzzy C-Means (m-FCM) algorithm for MR brain image segmentation is presented in this paper. Also FCM suffers from initialization sensitivity, to overcome this we have used chaos theory based firefly algorithm. This paper presents a novel application of FCM clustering by using Firefly algorithm with a chaotic map to initialize the population of fireflies and tune the absorption coefficient (A), for increasing the global search mobility. This algorithm is called chaotic firefly integrated Fuzzy C-means (C-FAFCM) algorithm, which embeds chaos map in the Firefly Algorithm. The proposed technique is applied to several simulated and real Tl-weighted for normal magnetic resonance brain images, taken from IBSR and BrainWeb database. The algorithm is realized by incorporating the spatial neighborhood information into the standard FCM algorithm and modifying the membership weighting of each cluster by regularizing it by Total Variation (TV) denoising. The experimental results on both simulated and real brain MRI datasets demonstrate that our proposed method (C-FAFCM) has satisfactory outputs in comparison with some other state of the art, based on FCM and non FCM based algorithms.
C1 [Ghosh, Partha] Govt Coll Engn & Ceram Technol, Dept Comp Sc & Engn, Kolkata, India.
   [Mali, Kalyani] Univ Kalyani, Dept Comp Sc & Engn, Kalyani, W Bengal, India.
   [Das, Sitansu Kumar] Chittaranjan Coll, Dept Comp Sci, Kolkata, India.
C3 Kalyani University
RP Ghosh, P (corresponding author), Govt Coll Engn & Ceram Technol, Dept Comp Sc & Engn, Kolkata, India.
EM parth_ghos@rediffmail.com
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Alia OM, 2009, TENCON IEEE REGION, P59
   Alia OM, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P335, DOI 10.1109/SoCPaR.2009.73
   ALOMOUSH WK, 2014, J APPL SCI, V14, P66, DOI DOI 10.3923/jas.2014.66.71
   Alsmadi Mutasem K., 2014, American Journal of Applied Sciences, V11, P1676, DOI 10.3844/ajassp.2014.1676-1691
   [Anonymous], DIAGNOST PATHOL
   [Anonymous], CHAOS FRACTALS ELEMT
   [Anonymous], 1996, ADV KNOWLEDGE DISCOV
   [Anonymous], 2013, CHAOS NATURE
   [Anonymous], N3 BIAS FIELD CORREC, DOI DOI 10.1007/978-3-319-12289-2_1
   [Anonymous], 1981, ADV APPL PATTERN REC
   [Anonymous], 3 INT C BIOINF BIOM
   [Anonymous], EFFICIENT PRIMAL DUA
   [Anonymous], 2007, 40 CIRP INT MAN SYST
   Arora S., 2013, Int. J. Comput. Appl., V69, DOI 10.5120/11826-7528
   Awate SP, 2006, MED IMAGE ANAL, V10, P726, DOI 10.1016/j.media.2006.07.002
   Balafar MA, 2014, ARTIF INTELL REV, V41, P441, DOI 10.1007/s10462-012-9318-2
   Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L
   Coelho LDS, 2008, EXPERT SYST APPL, V34, P1905, DOI 10.1016/j.eswa.2007.02.002
   Diplaros A, 2007, IEEE T NEURAL NETWOR, V18, P798, DOI 10.1109/TNN.2007.891190
   Dong FF, 2014, J VIS COMMUN IMAGE R, V25, P827, DOI 10.1016/j.jvcir.2014.01.014
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Fister I., 2014, Cuckoo Search and Firefly Algorithm, P27, DOI 10.1007/978-3-319-02141-6_2
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Ghosh P., 2016, J IMAGE PROCESS PATT, V3, P32
   Gupta L, 1998, PATTERN RECOGN, V31, P315, DOI 10.1016/S0031-3203(97)00045-9
   HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057
   He YY, 2012, PATTERN RECOGN, V45, P3463, DOI 10.1016/j.patcog.2012.03.009
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Ji ZX, 2014, NEUROCOMPUTING, V134, P60, DOI 10.1016/j.neucom.2012.12.067
   Ji ZX, 2014, PATTERN RECOGN, V47, P2454, DOI 10.1016/j.patcog.2014.01.017
   Kanade PM, 2007, IEEE T SYST MAN CY A, V37, P758, DOI 10.1109/TSMCA.2007.902655
   Kapur T, 1996, Med Image Anal, V1, P109, DOI 10.1016/S1361-8415(96)80008-9
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lefohn AE, 2003, LECT NOTES COMPUT SC, V2878, P564
   Li CM, 2009, PROC CVPR IEEE, P218, DOI 10.1109/CVPRW.2009.5206553
   Li CM, 2009, LECT NOTES COMPUT SC, V5636, P288
   Liew AWC, 2003, IEEE T MED IMAGING, V22, P1063, DOI 10.1109/TMI.2003.816956
   Luo S., 2003, APRS Workshop on Digital Image Computing, P9
   Masutani Y, 1998, LECT NOTES COMPUT SC, V1496, P1242, DOI 10.1007/BFb0056314
   Mayer A, 2009, IEEE T MED IMAGING, V28, P1238, DOI 10.1109/TMI.2009.2013850
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Shen S, 2005, IEEE T INF TECHNOL B, V9, P459, DOI 10.1109/TITB.2005.847500
   Sikka K, 2009, MAGN RESON IMAGING, V27, P994, DOI 10.1016/j.mri.2009.01.024
   Siyal MY, 2005, PATTERN RECOGN LETT, V26, P2052, DOI 10.1016/j.patrec.2005.03.019
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Tang LM, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/145780
   Tavazoei MS, 2007, APPL MATH COMPUT, V187, P1076, DOI 10.1016/j.amc.2006.09.087
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Tilahun SL, 2012, J APPL MATH, DOI 10.1155/2012/467631
   Tu Z, 2008, IEEE T MED IMAGING, V27, P495, DOI 10.1109/TMI.2007.908121
   Valverde S, 2015, J MAGN RESON IMAGING, V41, P93, DOI 10.1002/jmri.24517
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wang YT, 2014, IEEE INT FUZZY SYST, P2511, DOI 10.1109/FUZZ-IEEE.2014.6891755
   Wang ZM, 2013, COMPUT VIS IMAGE UND, V117, P1412, DOI 10.1016/j.cviu.2013.05.001
   Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Xue JH, 2003, PATTERN RECOGN LETT, V24, P2549, DOI 10.1016/S0167-8655(03)00100-4
   Yang X.S., 2019, Mathematical Foundations of Nature-Inspired Methods
   Yang XF, 2011, MED PHYS, V38, P2879, DOI 10.1118/1.3584199
   Yang XS, 2015, ADV COMPU INTELL ROB, P36, DOI 10.4018/978-1-4666-6328-2.ch002
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 71
TC 24
Z9 26
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 63
EP 79
DI 10.1016/j.jvcir.2018.04.007
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800007
DA 2024-07-18
ER

PT J
AU Hou, DD
   Qin, C
   Yu, NH
   Zhang, WM
AF Hou, Dongdong
   Qin, Chuan
   Yu, Nenghai
   Zhang, Weiming
TI Reversible visual transformation via exploring the correlations within
   color images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible visual transformation; Image camouflage; Image encryption;
   Reversible data hiding
ID PREDICTION; WATERMARKING; DIFFERENCE; EXPANSION; ALGORITHM
AB Reversible visual transformation reversibly transforms a secret image to a freely-selected target image and gets a camouflage image similar to the target image, which has been proved to be very useful in such two applications: privacy protection of images and reversible data hiding in encrypted images. Now, a new reversible transformation technique for color images is proposed by exploring and utilizing the correlations among three color channels and inside each color channel. The amount of the accessorial information for recording transformation parameters is largely reduced. Therefore, the visual quality of the created camouflage image is much improved by dividing the secret image and the target image into even smaller blocks for transformation.
C1 [Hou, Dongdong; Qin, Chuan; Yu, Nenghai; Zhang, Weiming] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
EM houdd@mail.ustc.edu.cn; qc94@mail.ustc.edu.cn; ynh@ustc.edu.cn;
   zhangwm@ustc.edu.cn
OI Qin, Chuan/0000-0002-5841-8210
FU Natural Science Foundation of China [61572452, U1636201]
FX This work was supported in part by the Natural Science Foundation of
   China under 61572452, Grant U1636201.
CR Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hou DD, 2016, J VIS COMMUN IMAGE R, V40, P225, DOI 10.1016/j.jvcir.2016.06.018
   Lai IJ, 2011, IEEE T INF FOREN SEC, V6, P936, DOI 10.1109/TIFS.2011.2135853
   Lee YL, 2014, IEEE T CIRC SYST VID, V24, P695, DOI 10.1109/TCSVT.2013.2283431
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lu TC, 2014, SIGNAL PROCESS, V104, P152, DOI 10.1016/j.sigpro.2014.04.001
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 23
TC 11
Z9 12
U1 2
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 134
EP 145
DI 10.1016/j.jvcir.2017.11.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800013
DA 2024-07-18
ER

PT J
AU Jian, MW
   Qi, Q
   Dong, JY
   Yin, YL
   Lam, KM
AF Jian, Muwei
   Qi, Qiang
   Dong, Junyu
   Yin, Yilong
   Lam, Kin-Man
TI Integrating QDWD with pattern distinctness and local contrast for
   underwater saliency detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image; Saliency detection; QDWD; Pattern distinctness; Local
   contrast
ID VISUAL-ATTENTION; MODEL
AB In this paper, we propose a novel framework for underwater image saliency detection by exploiting Quaternionic Distance Based Weber Descriptor (QDWD), pattern distinctness, and local contrast. Our proposed algorithm incorporates quaternion number system and principal components analysis (PCA) simultaneously, so as to achieve superior performance. In our algorithm, QDWD, which was initially designed for detecting outliers in color images, is used to represent the directional cues in an underwater image. Then, PCA coordinate system is employed to compute pattern distinctness. Meanwhile, we utilize local contrast to further highlight salient regions and suppress background regions. Finally, by integrating QDWD, pattern distinctness, and local contrast, a reliable saliency map for underwater images can be computed and estimated. Experimental results, based on the publicly available OUC-VISION underwater image database, show that the proposed method can produce reliable and promising results, compared to other state-of-the-art saliency-detection models.
C1 [Jian, Muwei; Yin, Yilong] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Jian, Muwei; Qi, Qiang; Dong, Junyu; Lam, Kin-Man] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Shandong University of Finance & Economics; Ocean University of China;
   Hong Kong Polytechnic University
RP Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
EM 20173016@sdufe.edu.cn
RI Jian, Muwei/Q-8319-2018
OI Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China (NSFC) [61601427,
   61602229]; Applied Basic Research Project of Qingdao [16-5-1-4-jch];
   Natural Science Foundation of Shandong Province [ZR2015FQ011]; China
   Postdoctoral Science Foundation [2016M590659]; Postdoctoral Science
   Foundation of Shandong Province [201603045]; Technology Cooperation
   Program of China (ISTCP) [2014DFA10410]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61601427, 61602229); Applied Basic Research Project of Qingdao
   (16-5-1-4-jch); Natural Science Foundation of Shandong Province
   (ZR2015FQ011); China Postdoctoral Science Foundation funded project
   (2016M590659); Postdoctoral Science Foundation of Shandong Province
   (201603045); & Technology Cooperation Program of China (ISTCP)
   (2014DFA10410).
CR [Anonymous], J SHANDONG U
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Cai CH, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P816, DOI 10.1109/ICIP.2000.899834
   Chen X, 2017, J VIS COMMUN IMAGE R, V45, P147, DOI 10.1016/j.jvcir.2017.02.005
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cholakkal H., 2015, BMVC
   Dong L, 2014, J VIS COMMUN IMAGE R, V25, P525, DOI 10.1016/j.jvcir.2013.11.009
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fang YM, 2015, INFORM SCIENCES, V309, P1, DOI 10.1016/j.ins.2015.03.004
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Gao V.M. D., 2007, NIPS, P497
   Geng X, 2012, SIGNAL PROCESS, V92, P150, DOI 10.1016/j.sigpro.2011.06.015
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hati A, 2017, J VIS COMMUN IMAGE R, V43, P212, DOI 10.1016/j.jvcir.2017.01.007
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian M, 2017, MULTIMED TOOLS APPL, P1
   Jian MW, 2017, IEEE INT CON MULTI, P1297, DOI 10.1109/ICME.2017.8019324
   Jian MW, 2016, ASIAPAC SIGN INFO PR
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jin LH, 2007, IEEE SIGNAL PROC LET, V14, P397, DOI 10.1109/LSP.2006.887840
   Jin LH, 2013, IEEE T CIRC SYST VID, V23, P741, DOI 10.1109/TCSVT.2012.2207272
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Lee SH, 2016, J VIS COMMUN IMAGE R, V35, P169, DOI 10.1016/j.jvcir.2015.12.011
   Li Y, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P269
   Li Y, 2010, LECT NOTES COMPUT SC, V6313, P790
   Liu TJ, 2017, IEEE T NEUR NET LEAR, V28, P107, DOI 10.1109/TNNLS.2015.2500268
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Oliva A., 2003, INT C IM PROC, V1
   Park Y, 2006, P C N AM CHAPT ASS C, P109
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   SHARON A, 2012, IEEE T PATTERN ANAL, V34, P315
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wu L, 2010, IEEE GEOSCI REMOTE S, V7, P362, DOI 10.1109/LGRS.2009.2035455
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhong SH, 2016, NEUROCOMPUTING, V207, P178, DOI 10.1016/j.neucom.2016.04.048
NR 55
TC 77
Z9 84
U1 2
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 31
EP 41
DI 10.1016/j.jvcir.2018.03.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800004
DA 2024-07-18
ER

PT J
AU Chen, JZ
   Chen, J
   Ling, HF
   Cao, H
   Sun, WP
   Fan, YB
   Wu, WM
AF Chen, Jiazhong
   Chen, Jie
   Ling, Hefei
   Cao, Hua
   Sun, Weiping
   Fan, Yebin
   Wu, Weimin
TI Salient object detection via spectral graph weighted low rank matrix
   recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Spectral graph; Low rank matrix recovery; Sparse
   decomposition; Feature matrix
ID VISUAL SALIENCY; DETECTION MODEL; IMAGE; OPTIMIZATION; ATTENTION;
   CONTRAST
AB A novel saliency detection method via spectral graph (SG) weighted low rank matrix recovery (LR) is presented in this paper. The location, color, and boundary priors are exploited in many LR-based saliency detection methods. However, these priors do not work well when the salient objects are far away from image center, especially when the background is complicated and has low contrast with objects. Because spectral graph contains rich image contrast, it is used as an efficient weight to obtain a much reasonable high-level prior in the proposed LR-based saliency model. Compared with previous LR-based methods, low rank matrix and sparse matrix rather than only sparse matrix are used to calculate the final saliency by an integration function and an activation function. The numerical and visual results on four challenging salient object datasets show that our method performs competitively for salient object detection task against some recent state-of-the-art algorithms.
C1 [Chen, Jiazhong; Ling, Hefei; Cao, Hua; Sun, Weiping; Fan, Yebin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Chen, Jie] Jinan Univ, Int Sch, Guangzhou 510660, Guangdong, Peoples R China.
   [Wu, Weimin] Fujian Chuanzheng Commun Coll, Dept Informat Technol, Fuzhou 350001, Fujian, Peoples R China.
C3 Huazhong University of Science & Technology; Jinan University; Fujian
   Chuanzheng Communications College
RP Chen, JZ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM chenjz70@163.com
FU Natural Science Foundation of China [U1536203, 61300140]; Major
   Scientific and Technological Innovation Project of Hubei Province
   [2015AAA013]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203 and Grant 61300140, and in part by the Major
   Scientific and Technological Innovation Project of Hubei Province under
   Grant 2015AAA013.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], 1998, Gabor Analysis and Algorithms
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Fu H, 2006, PATTERN RECOGN, V39, P1604, DOI 10.1016/j.patcog.2005.12.015
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim W, 2014, IEEE T CIRC SYST VID, V24, P646, DOI 10.1109/TCSVT.2013.2290579
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Niu YZ, 2010, PROC CVPR IEEE, P537, DOI 10.1109/CVPR.2010.5540169
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang JX, 2014, IEEE IMAGE PROC, P1175, DOI 10.1109/ICIP.2014.7025234
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78
NR 60
TC 6
Z9 8
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 270
EP 279
DI 10.1016/j.jvcir.2017.12.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700027
DA 2024-07-18
ER

PT J
AU Wang, GY
   Zhuo, L
   Li, JF
   Ren, DY
   Zhang, J
AF Wang, Guanyao
   Zhuo, Li
   Li, Jiafeng
   Ren, Dongyue
   Zhang, Jing
TI An efficient method of content-targeted online video advertising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Advertising insertion; Content-targeted; Key frame extraction; Scene
   boundary detection; Similarity measurement
AB With the rapid development of Internet, the views of the online video have increased dramatically. Meanwhile, the corresponding online video advertising market showed a momentum of rapid and sustained development. In order to attract more potential purchasers and reduce the interference on the ordinary video browsers, many researchers and enterprises have conducted the research of video online advertising. At present, the insertion methods of most video advertising are always position-fixed, mandatory timing, quantitative, and the relevance of advertisement content and the video content is usually ignored. These methods will inevitably reduce the advertising effect because of browsers' dissatisfaction and resistance. In order to overcome the shortages of the existing methods of video advertisement insertion, this paper proposed an effective content-targeted method for online video advertising. The insertion of advertisement is determined by comparing the content of the videos and the advertisements. At the same time, the characteristics of the scene switching in the video are taken into account to select the appropriate position of the advertisement insertion. Experimental results show that our method can provide a better user experience than existing methods, and its attractiveness and comfortableness is greatly improved.
C1 [Wang, Guanyao; Zhuo, Li; Li, Jiafeng; Ren, Dongyue; Zhang, Jing] Beijing Univ Technol, Signal & Informat Proc Lab, Beijing, Peoples R China.
   [Zhuo, Li] Collaborat Innovat Ctr Elect Vehicles Beijing, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Zhuo, L (corresponding author), Beijing Univ Technol, Signal & Informat Proc Lab, Beijing, Peoples R China.
EM 18311287577@163.com; zhuoli@bjut.edu.cn
RI li, jiafeng/KVY-4468-2024
OI ZHANG, JING/0000-0003-1290-0738
FU National Natural Science Foundation of China [61531006, 61372149,
   61370189, 61471013, 61602018]; Importation and Development of High
   Caliber Talents Project of Beijing Municipal Institutions
   [CITTCD20150311]; Funding Project for Academic Human Resources.
   Development in Institutions of Higher Learning Under the Jurisdiction of
   Beijing Municipality
FX The work in this paper is supported by the National Natural Science
   Foundation of China (Nos. 61531006, 61372149, 61370189, 61471013, and
   61602018), the Importation and Development of High Caliber Talents
   Project of Beijing Municipal Institutions (No. CIT&TCD20150311), Funding
   Project for Academic Human Resources. Development in Institutions of
   Higher Learning Under the Jurisdiction of Beijing Municipality.
CR [Anonymous], P NIST TRECVID WORKS
   [Anonymous], 2007, P 15 ACM INT C MULT
   [Anonymous], 2009, P 18 INT C WORLD WID
   Chatterjee P, 2003, MARKET SCI, V22, P520, DOI 10.1287/mksc.22.4.520.24906
   Guo JL, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P628, DOI 10.1145/1571941.1572049
   Lacerda A., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P549, DOI 10.1145/1148170.1148265
   Li HR, 2002, J ADVERTISING, V31, P37, DOI 10.1080/00913367.2002.10673665
   Li T, 2009, SIGNAL PROCESS, V89, P2354, DOI 10.1016/j.sigpro.2009.03.023
   Li Teng, 2015, IEEE T CYBERNET, V45
   Liao Wei-Shing., 2008, P 31 ANN INT ACM SIG, P767, DOI [10.1145/1390334.1390494, DOI 10.1145/1390334.1390494]
   Malheiros M., 2012, the SIGCHI conference on human factors in computing systems, P579, DOI [10.1145/2207676.2207758, DOI 10.1145/2207676.2207758]
   Mei Tao., 2007, Proceedings of the 15th International Conference on Multimedia, P1075
   Qin YY, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P204, DOI 10.1109/PIC.2014.6972325
   Ribeiro-Neto B., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P496, DOI 10.1145/1076034.1076119
   Ribeiro-Neto Berthier., 2011, MODERN INFORM RETRIE
   Rijsbergen C, 1980, NEW MODELS PROBABILI
   Rossholm A, 2014, IEEE IFIP NETW OPER
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shatnawi M., 2012, Proceedings of the 27th Annual Symposium on Applied Computing, Association for Computing Machinery, P680
   Tavanapong W, 2004, IEEE T MULTIMEDIA, V6, P517, DOI 10.1109/tmm.2004.830810
   Wan KW, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1893, DOI 10.1109/ICME.2006.262925
   Wang C., 2002, P 8 AMERICAS C INFOR, P1143
   [王学军 WANG Xuejun], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P2127
   Wu X., 2011, J COMPUT AIDED DES C, V11
   Xu B.H., 2007, RES USABILITY INTERN
   Yih Wen-tau., 2006, WWW'06, P213
   [俞淑平 Yu Shuping], 2011, [计算机应用与软件, Computer Applications and Software], V28, P4
NR 27
TC 17
Z9 22
U1 1
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 40
EP 48
DI 10.1016/j.jvcir.2017.11.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700005
DA 2024-07-18
ER

PT J
AU Han, BJ
   Sim, JY
AF Han, Byeong-Ju
   Sim, Jae-Young
TI Saliency detection for panoramic landscape images of outdoor scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Panoramic image; Wide fields of view; Background
   estimation; Saliency refinement
ID VISUAL-ATTENTION; REGION DETECTION; MODEL
AB Saliency detection has been researched for conventional images with standard aspect ratios, however, it is a challenging problem for panoramic images with wide fields of view. In this paper, we propose a saliency detection algorithm for panoramic landscape images of outdoor scenes. We observe that a typical panoramic image includes several homogeneous background regions yielding horizontally elongated distributions, as well as multiple foreground objects with arbitrary locations. We first estimate the background of panoramic images by selecting homogeneous superpixels using geodesic similarity and analyzing their spatial distributions. Then we iteratively refine an initial saliency map derived from background estimation by computing the feature contrast only within local surrounding area whose range and shape are changed adaptively. Experimental results demonstrate that the proposed algorithm detects multiple salient objects faithfully while suppressing the background successfully, and it yields a significantly better performance of panorama saliency detection compared with the recent state-of-the-art techniques. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Han, Byeong-Ju; Sim, Jae-Young] Ulsan Natl Inst Sci & Technol, Sch Elect & Comp Engn, Ulsan, South Korea.
C3 Ulsan National Institute of Science & Technology (UNIST)
RP Sim, JY (corresponding author), Ulsan Natl Inst Sci & Technol, Sch Elect & Comp Engn, Ulsan, South Korea.
EM bjhan@unist.ac.kr; jysim@unist.ac.kr
FU National Research Foundation of Korea (NRF) within Ministry of Science
   and ICT [2017R1A2B4011970]; National Research Foundation of Korea (NRF)
   within Ministry of Education [2013R1A1A2011920, 2016R1D1A1A09919618]
FX This work was supported by the National Research Foundation of Korea
   (NRF) within the Ministry of Science and ICT under Grant
   2017R1A2B4011970, and within the Ministry of Education under Grants
   2013R1A1A2011920 and 2016R1D1A1A09919618.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2009.5413815
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383017
   Chakraborty S, 2015, J VIS COMMUN IMAGE R, V33, P20, DOI 10.1016/j.jvcir.2015.08.016
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Luo Y, 2011, IEEE T CIRC SYST VID, V21, P1822, DOI 10.1109/TCSVT.2011.2147230
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yang B, 2015, J VIS COMMUN IMAGE R, V31, P125, DOI 10.1016/j.jvcir.2015.06.006
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yang LJ, 2011, IEEE T MULTIMEDIA, V13, P1295, DOI 10.1109/TMM.2011.2162399
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
   Zhou B, 2016, J VIS COMMUN IMAGE R, V41, P21, DOI 10.1016/j.jvcir.2016.09.002
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 38
TC 8
Z9 9
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 27
EP 37
DI 10.1016/j.jvcir.2017.08.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800003
DA 2024-07-18
ER

PT J
AU Jiang, B
   Yang, JC
   Lv, ZH
   Tian, K
   Meng, QG
   Yan, Y
AF Jiang, Bin
   Yang, Jiachen
   Lv, Zhihan
   Tian, Kun
   Meng, Qinggang
   Yan, Yan
TI Internet cross-media retrieval based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-media retrieval; Deep learning; Feature extracting; Multimedia
   information
ID CANONICAL CORRELATION-ANALYSIS; IMAGE RETRIEVAL
AB With the development of Internet, multimedia information such as image and video is widely used. Therefore, how to find the required multimedia data quickly and accurately in a large number of resources, has become a research focus in the field of information process. In this paper, we propose a real time internet cross-media retrieval method based on deep learning. As an innovation, we have made full improvement in feature extracting and distance detection. After getting a large amount of image feature vectors, we sort the elements in the vector according to their contribution and then eliminate unnecessary features. Experiments show that our method can achieve high precision in image-text cross media retrieval, using less retrieval time. This method has a great application space in the field of cross media retrieval. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Jiang, Bin; Yang, Jiachen] Tianjin Univ, Sch Elect Automat & Informat Engn, Tianjin, Peoples R China.
   [Lv, Zhihan] UCL, Dept Comp Sci, London WC1E 6EA, England.
   [Tian, Kun] Natl Key Lab Sci & Technol Aerosp Intelligence Co, Beijing, Peoples R China.
   [Meng, Qinggang] Loughborough Univ, Sch Sci, Dept Comp Sci, Loughborough, Leics, England.
   [Yan, Yan] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
C3 Tianjin University; University of London; University College London;
   Loughborough University; University of Trento
RP Yang, JC; Lv, ZH (corresponding author), UCL, Dept Comp Sci, London WC1E 6EA, England.
EM yangjiachen@tju.edu.cn; Z.Lu@cs.ucl.ac.uk
RI Lyu, Zhihan/I-3187-2014; Yang, Jiachen/ABH-5032-2020; Lv,
   Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Yang, Jiachen/0000-0003-2558-552X; Lv,
   Zhihan/0000-0003-2525-3074
FU National Natural Science Foundation of China [61471260, 61271324];
   Natural Science Foundation of Tianjin [16JCYBJC16000]
FX This research is partially supported by National Natural Science
   Foundation of China (Nos. 61471260 and 61271324), and Natural Science
   Foundation of Tianjin (No. 16JCYBJC16000).
CR Ahmad I, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P33
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Andrew G., 2013, P ICML, P1247
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cai X., 2013, P 23 INT JOINT C ART
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Eaton E, 2014, KNOWL INF SYST, V38, P231, DOI 10.1007/s10115-012-0577-7
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Guo JM, 2015, IEEE T CIRC SYST VID, V25, P466, DOI 10.1109/TCSVT.2014.2358011
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Gupta S.K., 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, P1169, DOI DOI 10.1145/1835804.1835951
   Hao S, 2009, IEEE I CONF COMP VIS, P213, DOI 10.1109/ICCV.2009.5459168
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Ji S., 2010, ACM T KNOWL DISCOV D, V4, P890
   Koço S, 2011, LECT NOTES ARTIF INT, V6912, P209, DOI 10.1007/978-3-642-23783-6_14
   Kong XN, 2013, IEEE T KNOWL DATA EN, V25, P704, DOI 10.1109/TKDE.2011.141
   Lewis D.P., 2006, Proc. of Int. Conference on Machine Learning, P553, DOI DOI 10.1145/1143844.1143914
   Li W, 2011, IEEE I CONF COMP VIS, P2049, DOI 10.1109/ICCV.2011.6126478
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu J., 2013, MULTIVIEW CLUSTERING
   Mohamed A.R., DEEP BELIEF NETWORKS, V4
   Mohamed AR, 2012, INT CONF ACOUST SPEE, P4273, DOI 10.1109/ICASSP.2012.6288863
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Piedra-Fernández JA, 2014, IEEE T GEOSCI REMOTE, V52, P5422, DOI 10.1109/TGRS.2013.2288732
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Roux NL, 1989, NEURAL COMPUT, V20, P1631
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang YF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P307, DOI 10.1145/2647868.2654901
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xu Z., 2010, P 27 INT C MACHINE L, P1175
   Yu SP, 2006, IEEE T KNOWL DATA EN, V18, P1600, DOI 10.1109/TKDE.2006.194
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang ZX, 2013, IEEE T INF FOREN SEC, V8, P1632, DOI 10.1109/TIFS.2013.2265089
   Zhuang Y, 2013, AAAI C ART INT
NR 42
TC 30
Z9 35
U1 0
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 356
EP 366
DI 10.1016/j.jvcir.2017.02.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700029
OA Green Published, Green Accepted
DA 2024-07-18
ER

PT J
AU Yuan, L
   Jin, X
   Li, YG
   Yuan, C
AF Yuan, Liang
   Jin, Xin
   Li, Yangguang
   Yuan, Chun
TI Depth map super-resolution via low-resolution depth guided joint
   trilateral up-sampling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Joint trilateral upsampling; Super-resolution; De-noising; Texture
   copying
ID IMAGE; INTERPOLATION
AB In this paper, a new method is proposed to address the depth map super resolution (SR) and denoising problems simultaneously. Unlike the existing methods, the proposed approach uses LR depth map as a guidance in each filtering iteration during the whole process to fully exploit the geometric information in it. A joint trilateral upsampling model is proposed to fuse the projected spatial distance measured from the LR depth map, the intensity variance extracted from the associated color image and the HR depth map generated in the last iteration to refine the HR depth map iteratively. Compared with the existing approaches, the proposed approach presents superior results in avoiding texture copying artifacts as misalignments existing between the depth map and color image. Also, for the depth with noises, it can provide stronger de-noising effects with much clearer edges in the processed results. On average, it only requires 7.67 iterations to reach convergence, which is very efficient and outperforms the representative approaches in terms of computational complexity, objective quality and subjective quality. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yuan, Liang; Jin, Xin; Li, Yangguang; Yuan, Chun] Tsinghua Univ, Grad Sch Shenzhen, Beijing, Peoples R China.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University
RP Jin, X (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Beijing, Peoples R China.
EM yuanliang06@gmail.com; jin.xin@sz.tsinghua.edu.cn;
   liyg12@mails.tsinghua.edu.cn; yuanc@sz.tsinghua.edu.cn
RI jin, xin/GQZ-5811-2022
FU NSFC [61371138]; National Science Foundation of Guangdong, China
   [2014A030313733]
FX This work was supported in part by the project of NSFC 61371138 and
   National Science Foundation of Guangdong 2014A030313733, China.
CR [Anonymous], 2012, INT C INT MULT COMP
   [Anonymous], 2008, WORKSH MULT MULT SEN
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Diebel J., 2005, P 18 INT C NEUR INF, V18, P291
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   Guo K, 2012, IEEE T IMAGE PROCESS, V21, P615, DOI 10.1109/TIP.2011.2165290
   Guo K, 2011, OPT ENG, V50, DOI 10.1117/1.3572137
   Ham B, 2015, IEEE T IMAGE PROCESS, V24, P1524, DOI 10.1109/TIP.2015.2405342
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hu K., 2013, P IEEE VLSI TEST S, P1
   Huhle B, 2010, COMPUT VIS IMAGE UND, V114, P1336, DOI 10.1016/j.cviu.2009.11.004
   Jin X, 2016, SIGNAL PROCESS-IMAGE, V47, P56, DOI 10.1016/j.image.2016.05.006
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kiechle M, 2013, IEEE I CONF COMP VIS, P1545, DOI 10.1109/ICCV.2013.195
   Kim J, 2014, SIGNAL PROCESS-IMAGE, V29, P506, DOI 10.1016/j.image.2014.01.011
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li J, 2014, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2014.431
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Plaziac N, 1999, IEEE T IMAGE PROCESS, V8, P1647, DOI 10.1109/83.799893
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Riemens A. K., 2009, P SOC PHOTO-OPT INS, P336
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Q, 2007, IEEE T IMAGE PROCESS, V16, P889, DOI 10.1109/TIP.2007.891794
   Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211
   Xiang XQ, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P319, DOI 10.1109/CW.2010.58
   Xie J, 2014, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2014.7025766
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yanjie Li, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P152, DOI 10.1109/ICME.2012.30
NR 43
TC 6
Z9 10
U1 2
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 280
EP 291
DI 10.1016/j.jvcir.2017.04.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500025
OA Bronze
DA 2024-07-18
ER

PT J
AU Hao, BB
   Zhu, JG
AF Hao, Binbin
   Zhu, Jianguang
TI Fast <i>L</i><sub>1</sub> regularized iterative forward backward
   splitting with adaptive parameter selection for image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE L-1 regularization; Regularization parameter; Splitting methods; Image
   restoration
ID THRESHOLDING ALGORITHM; PARALLEL FRAMEWORK; MINIMIZATION; HEVC; RECOVERY
AB We consider the L-1 regularized iterative forward backward splitting (IFBS) algorithm for image restoration. The main aim of the paper is to develop a fast and adaptive method with an automatic selection of regularization parameter. The regularization parameter is updated in each iteration without requiring the initial value of the parameter. We establish analytically monotonicity results of the adaptive parameter. Such an algorithm corresponds to solving an adaptive iterative thresholding process. Experimental results demonstrate that the adaptive parameter method is efficient and provide competitive performance. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Hao, Binbin] China Univ Petr, Coll Sci, Qingdao 266580, Peoples R China.
   [Zhu, Jianguang] Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao 266590, Peoples R China.
C3 China University of Petroleum; Shandong University of Science &
   Technology
RP Zhu, JG (corresponding author), Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao 266590, Peoples R China.
EM bbhao981@163.com; jgzhu980@163.com
FU National Science Foundation of China [61101208, 11326186]; Shandong
   Provincial Natural Science Foundation, China [ZR2015AQ001]; Qindao
   Postdoctoral Science Foudation, China [2016114]; Innovative Center for
   Safe and Effective Mining Technology and Equipment of Coal Resources;
   Shandong Province of China; SDUST Research Fund [2014TDJH102]
FX This work was supported by the National Science Foundation of China
   under Grant 61101208 and Grant 11326186, by Shandong Provincial Natural
   Science Foundation, China (No. ZR2015AQ001), by Qindao Postdoctoral
   Science Foudation, China (2016114), by Joint Innovative Center for Safe
   and Effective Mining Technology and Equipment of Coal Resources,
   Shandong Province of China and SDUST Research Fund (2014TDJH102).
CR Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   [Anonymous], IEEE T CYBERN
   [Anonymous], 2002, COMPUTATIONAL METHOD
   [Anonymous], IMAGE PROCESSING ANA
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Cai JF, 2009, MATH COMPUT, V78, P1515, DOI 10.1090/S0025-5718-08-02189-3
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chen K, 2014, NUMER ALGORITHMS, V67, P73, DOI 10.1007/s11075-013-9775-y
   Combettes P.L., 2010, FIXED POINT ALGORITH, P1
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Dong YS, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2738050
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751
   HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086
   Hao BB, 2008, SIGNAL PROCESS-IMAGE, V23, P433, DOI 10.1016/j.image.2008.04.006
   He C, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2360133
   Lin YZ, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P89, DOI 10.1109/SSIAI.2008.4512292
   Montefusco LB, 2012, IEEE T IMAGE PROCESS, V21, P1676, DOI 10.1109/TIP.2011.2173205
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Yan C, 2013, DAT COMPR C DCC
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zhang JP, 2012, SIAM J NUMER ANAL, V50, P983, DOI 10.1137/110829209
NR 35
TC 23
Z9 23
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 139
EP 147
DI 10.1016/j.jvcir.2017.01.016
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600013
OA hybrid
DA 2024-07-18
ER

PT J
AU Ma, L
   Li, HL
   Meng, FM
   Wu, QB
   Xu, LF
AF Ma, Lei
   Li, Hongliang
   Meng, Fanman
   Wu, Qingbo
   Xu, Linfeng
TI Manifold-ranking embedded order preserving hashing for image semantic
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Manifold ranking; Hashing; Image semantic retrieval
ID PATTERNS; CODES
AB Due to the storage and computational efficiency of hashing technology, it has proven a valuable tool for large scale similarity search. In many cases, the large scale data in real-world lie near some (unknown) low-dimensional and non-linear manifold. Moreover, Manifold Ranking approach can preserve the global topological structure of the data set more effectively than Euclidean Distance-based Ranking approach, which fails to preserve the semantic relevance degree. However, most existing hashing methods ignore the global topological structure of the data set. The key issue is how to incorporate the global topological structure of data set into learning effective hashing function. In this paper, we propose a novel unsupervised hashing approach, namely Manifold-Ranking Embedded Order Preserving Hashing (MREOPH). A manifold ranking loss is introduced to solve the issue of global topological structure preserving. An order preserving loss is introduced to ensure the consistency between manifold ranking and hamming ranking. A hypercubic quantization loss is introduced to learn discrete binary codes. The information theoretic regularization term is taken into consideration for preserving desirable properties of hash codes. Finally, we integrate them in a joint optimization framework for minimizing the information loss in each processing. Experimental results on three datasets for semantic search clearly demonstrate the effectiveness of the proposed method.(C) 2017 Elsevier Inc. All rights reserved.
C1 [Ma, Lei; Li, Hongliang; Meng, Fanman; Wu, Qingbo; Xu, Linfeng] Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Ma, L (corresponding author), Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
EM leima_uestc@163.com; hlli@uestc.edu.cn; fmmeng@uestc.edu.cn;
   qbwu@uestc.edu.cn; lfxu@uestc.edu.cn
RI Xu, Linfeng/HME-1913-2023; Wu, Qingbo/AAF-6872-2019
OI Xu, Linfeng/0000-0002-9934-0958; Wu, Qingbo/0000-0003-2936-6340
FU National Natural Science Foundation of China [61525102, 61601102,
   61502084]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61525102, 61601102, 61502084).
CR [Anonymous], 2006, Book Annosearch: Image auto-annotation by search, DOI DOI 10.1109/CVPR.2006.58
   [Anonymous], 2012, NIPS
   [Anonymous], 2016, IJCAI
   [Anonymous], 2009, NIPS
   [Anonymous], 2009, NEURIPS
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gu SM, 2013, INT CONF MACH LEARN, P108, DOI 10.1109/ICMLC.2013.6890453
   He X., 2003, ADV NEURAL INFORM PR, P153
   Jiang K, 2015, PROC CVPR IEEE, P4933, DOI 10.1109/CVPR.2015.7299127
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151
   Lin GS, 2014, LECT NOTES COMPUT SC, V8691, P613, DOI 10.1007/978-3-319-10578-9_40
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Norouzi M.E., 2011, ICML
   SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205
   Song DJ, 2015, IEEE DATA COMPR CONF, P353, DOI 10.1109/DCC.2015.85
   Song DJ, 2015, IEEE I CONF COMP VIS, P1922, DOI 10.1109/ICCV.2015.223
   Song TC, 2015, PATTERN RECOGN, V48, P2621, DOI 10.1016/j.patcog.2015.03.003
   Song TC, 2014, IEEE SIGNAL PROC LET, V21, P93, DOI 10.1109/LSP.2013.2293335
   Song TC, 2013, PATTERN RECOGN LETT, V34, P1323, DOI 10.1016/j.patrec.2013.04.020
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang D, 2015, NEUROCOMPUTING, V167, P230, DOI 10.1016/j.neucom.2015.04.072
   Wang J., 2013, ACM MULT C, P133
   Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang Jun., 2010, ICML, P1127
   Wang QF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3911
   Weiss A., 2008, NIPS, P1753
   Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Zhou DY, 2004, ADV NEUR IN, V16, P169
NR 42
TC 14
Z9 14
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 29
EP 39
DI 10.1016/j.jvcir.2017.01.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600003
DA 2024-07-18
ER

PT J
AU Lin, GS
   Huang, JF
   Lie, WN
AF Lin, Guo-Shiang
   Huang, Jian-Fa
   Lie, Wen-Nung
TI Key-frame-based depth propagation for semi-automatic stereoscopic video
   conversion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 2D-to-3D stereo video conversion; Depth propagation; Key-frame; Error
   correction; Depth image based rendering (DIBR)
ID 3D VIDEO; 2D
AB In this paper, we propose a key-frame-based bi-directional depth propagation algorithm for semiautomatic 2D-to-3D stereoscopic video conversion. First, key-frames are identified from each video shot based on color motion-compensation errors to prevent high-motion content between any pair of consecutive key frames. Depths for key-frames are manually assigned or rendered by popular computer tools, and then bi-directionally propagated to non-key-frames there between. Our depth propagation algorithm is featured of a multi-pass error correcting procedure for each frame to prevent depth artifacts from being further propagated to adjacent frames. Our proposed algorithm is advantageous in solving the background occlusion/dis-occlusion problem that degrades the performances of traditional depth propagation algorithms. Experimental results show that our scheme is capable of achieving better results against three prior algorithms in view of the qualities of the estimated depth map (e.g., dis-occluded background and object boundaries) and the synthesized stereo views. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lin, Guo-Shiang] Dayeh Univ, Dept Comp Sci & Informat Engn, Dacun 51591, Changhua, Taiwan.
   [Huang, Jian-Fa; Lie, Wen-Nung] Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
C3 Da Yeh University; National Chung Cheng University
RP Lie, WN (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
EM khlin@mail.dyu.edu.tw; ieewnl@ccu.edu.tw
RI Lie, Wen-Nung/AFP-1266-2022
CR [Anonymous], 2009, INT C CONS EL
   [Anonymous], P INT S BROADB MULT
   [Anonymous], ACM C MULT
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], IEEE SIGN INF PROC A
   [Anonymous], BT50011 ITUR
   Cao X, 2011, IEEE T BROADCAST, V57, P491, DOI 10.1109/TBC.2011.2127650
   Chang YL, 2008, PROC SPIE, V6805, DOI 10.1117/12.766630
   Cheng CM, 2011, IEEE T BROADCAST, V57, P523, DOI 10.1109/TBC.2011.2139090
   Chenglei Wu, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P65
   Cuenca P, 1997, 1997 CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, CONFERENCE PROCEEDINGS, VOLS I AND II, P118, DOI 10.1109/CCECE.1997.614804
   Daribo I, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/258920
   Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158
   Harman P, 2002, PROC SPIE, V4660, P78, DOI 10.1117/12.468020
   Hewage CTER, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P485, DOI 10.1109/ICME.2008.4607477
   Huang WC, 2013, 2013 IEEE 11TH IVMSP WORKSHOP: 3D IMAGE/VIDEO TECHNOLOGIES AND APPLICATIONS (IVMSP 2013)
   Ideses I, 2007, J REAL-TIME IMAGE PR, V2, P3, DOI 10.1007/s11554-007-0038-9
   Jung C, 2015, IEEE IMAGE PROC, P3515, DOI 10.1109/ICIP.2015.7351458
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lie WN, 2011, ELECTRON LETT, V47, P319, DOI 10.1049/el.2010.2912
   Lie WN, 2015, J VIS COMMUN IMAGE R, V32, P237, DOI 10.1016/j.jvcir.2015.08.012
   Lin GS, 2013, IEEE IMAGE PROC, P2202, DOI 10.1109/ICIP.2013.6738454
   Lin GS, 2012, INT C PATT RECOG, P2013
   Lin GS, 2009, INT J PATTERN RECOGN, V23, P1179, DOI 10.1142/S0218001409007521
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Varekamp C., 2007, European Conference on Visual Media Production, P1, DOI DOI 10.1049/CP:20070061
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Wang D., 2012, Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on Measurement and Modeling of Computer Systems, SIGMETRICS'12, P187, DOI DOI 10.1049/CP.2012.1749
   Wang H, 2013, PROCEEDINGS OF THE 5TH (2013) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS I AND II, P1, DOI 10.1109/ijcnn.2013.6706812
   Wang L, 2014, IEEE T MULTIMEDIA, V16, P1905, DOI 10.1109/TMM.2014.2341599
   Wang Y., 2002, VIDEO PROCESSING COM
   Zhang L, 2011, IEEE T BROADCAST, V57, P372, DOI 10.1109/TBC.2011.2122930
NR 32
TC 2
Z9 2
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 127
EP 137
DI 10.1016/j.jvcir.2016.12.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400013
DA 2024-07-18
ER

PT J
AU Pratondo, A
   Chui, CK
   Ong, SH
AF Pratondo, Agus
   Chui, Chee-Kong
   Ong, Sim-Heng
TI Integrating machine learning with region-based active contour models in
   medical image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Machine learning; Active contour; Medical images; Segmentation
ID LEVEL SET EVOLUTION; CLASSIFICATION; HEVC; MOTION
AB Region-based active contour models are effective in segmenting images with poorly defined boundaries but often fail when applied to images containing intensity inhomogeneity. The traditional models utilize pixel intensity and are very sensitive to parameter tuning. On the other hand, machine learning algorithms are highly effective in handling inhomogeneities but often result in noise from misclassified pixels. In addition, there is no objective function. We propose a framework which integrates machine learning with a region-based active contour model. Classification probability scores from machine learning algorithm, which are regularized using a non-linear function, are used to replace the pixel intensity values during energy minimization. In our experiments, we integrate the k-nearest neighbours and the support vector machine with the Chan-Vese method and compare the results obtained with the traditional methods of Chan-Vese and Li et al. The proposed framework gives better accuracy and less sensitive to parameter tuning. (C) 2016 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license.
C1 [Pratondo, Agus] Telkom Univ, Dept Informat Syst, Bandung, Indonesia.
   [Pratondo, Agus; Ong, Sim-Heng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.
   [Chui, Chee-Kong] Natl Univ Singapore, Dept Mech Engn, Singapore, Singapore.
C3 Telkom University; National University of Singapore; National University
   of Singapore
RP Pratondo, A (corresponding author), Telkom Univ, Sch Appl Sci, Selaru It 3,J1 Telekomunikasi 1,Terusan Buah Batu, Bandung 40257, West Java, Indonesia.
EM pratondo@gmail.com
RI Ong, Sim-Heng/R-9244-2019; Agus, pratondo/AAC-9787-2021
OI Ong, Sim-Heng/0000-0003-2766-8150; Agus, pratondo/0000-0002-6976-7459
FU National University of Singapore FRC Tier 1 Grant [WBS:
   R265-000-446-112]; Telkom University Publication Grant
FX This work is supported in part by National University of Singapore FRC
   Tier 1 Grant (WBS: R265-000-446-112) and Telkom University Publication
   Grant.
CR Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Cai XC, 2009, 2009 24TH INTERNATIONAL CONFERENCE IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2009), P310, DOI 10.1109/IVCNZ.2009.5378391
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YT, 2008, LECT NOTES COMPUT SC, V4987, P25
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dervieux A., 1980, Approximation Methods for Navier-Stokes Problems, P145, DOI DOI 10.1007/BFB0086904
   Flannery B. P., 1992, NUMERICAL RECIPES C, DOI DOI 10.2277/052143064X
   Folkesson J, 2008, IEEE T INF TECHNOL B, V12, P328, DOI 10.1109/TITB.2007.912179
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P214, DOI 10.5201/ipol.2012.g-cv
   Haykin S., 2004, Neural Networks, V2
   Józwik A, 1983, PATTERN RECOGN LETT, V1, P287, DOI 10.1016/0167-8655(83)90064-8
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Liu YG, 2012, IEEE T VIS COMPUT GR, V18, P202, DOI 10.1109/TVCG.2011.77
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mukherjee S, 2015, IEEE SIGNAL PROC LET, V22, P298, DOI 10.1109/LSP.2014.2346538
   Mylona EA, 2014, IEEE T CYBERNETICS, V44, P2757, DOI 10.1109/TCYB.2014.2315293
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Platt JC, 2000, ADV NEUR IN, P61
   Pratondo A., 2014, 15 INT C BIOMEDICAL, P112, DOI [10.1007/978-3-319-02913-9_29, DOI 10.1007/978-3-319-02913-9_29]
   Pratondo A., 2014, P 10 ASIAN C COMPUTE, P40
   Pratondo A, 2016, IEEE SIGNAL PROC LET, V23, P222, DOI 10.1109/LSP.2015.2508039
   Rogowska J, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P73
   Steenwijk MD, 2013, NEUROIMAGE-CLIN, V3, P462, DOI 10.1016/j.nicl.2013.10.003
   Wang Y, 2013, PATTERN RECOGN, V46, P1734, DOI 10.1016/j.patcog.2012.12.006
   Wang YQ, 2010, IEEE SIGNAL PROC LET, V17, P875, DOI 10.1109/LSP.2010.2060482
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 35
TC 79
Z9 82
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 1
EP 9
DI 10.1016/j.jvcir.2016.11.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Jung, CK
   Yang, Q
   Sun, TT
   Fu, QT
   Song, H
AF Jung, Cheolkon
   Yang, Qi
   Sun, Tingting
   Fu, Qingtao
   Song, Hyoseob
TI Low light image enhancement with dual-tree complex wavelet transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; Dual-tree complex wavelet transform; Noise
   reduction; Wavelet coefficient
ID HISTOGRAM EQUALIZATION
AB In low light condition, low dynamic range of the captured image distorts the contrast and results in high noise levels. In this paper, we propose an effective contrast enhancement method based on dual-tree complex wavelet transform (DT-CWT) which operates on a wide range of imagery without noise amplification. In terms of enhancement, we employ a logarithmic function for global brightness enhancement based on the nonlinear response of human vision to luminance. Moreover, we enhance the local contrast by contrast limited adaptive histogram equalization (CLAHE) in low-pass subbands to make image structure clearer. In terms of noise reduction, based on the direction selective property of DT-CWT, we perform content-based total variation (TV) diffusion which controls the smoothing degree according to noise and edges in high-pass subbands. Experimental results demonstrate that the proposed method achieves a good performance in low light image enhancment and outperforms state-of-the-art ones in terms of contrast enhancement and noise reduction. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Jung, Cheolkon; Yang, Qi; Sun, Tingting; Fu, Qingtao] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Song, Hyoseob] Samsung SDS, VA Lab, Seoul 130240, South Korea.
C3 Xidian University; Samsung
RP Jung, CK (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM zhengzk@xidian.edu.cn; yangqimaya@gmail.com;
   2013suntingting@iiip.xidian.edu.cn; qtfu@stu.xidian.edu.cn;
   hyoseob.song@samsung.com
FU National Natural Science Foundation of China [61271298]; International
   S&T Cooperation Program of China [2014DFG12780]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61271298) and the International S&T Cooperation Program of
   China (No. 2014DFG12780).
CR [Anonymous], EDEN PROJECT MULTISE
   [Anonymous], P EUR SIGN PROC C EU
   [Anonymous], OPT ENG
   [Anonymous], SHUTTER SPEED GREENW
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Berkner K, 2002, APPL COMPUT HARMON A, V12, P1, DOI 10.1006/acha.2001.0366
   Bilcu RC, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P268
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P554, DOI 10.1109/LGRS.2010.2041324
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen YZ, 2013, IEEE T CIRC SYST VID, V23, P74, DOI 10.1109/TCSVT.2012.2203198
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang TH, 2013, IEEE T IMAGE PROCESS, V22, P4587, DOI 10.1109/TIP.2013.2272517
   Jiaji Cheng, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P605, DOI 10.1109/CISP.2010.5647250
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Lee CH, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033007
   Loza A, 2010, IEEE IMAGE PROC, P3553, DOI 10.1109/ICIP.2010.5651173
   Malm H, 2007, P IEEE INT C COMPUTE, P1
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rao YB, 2010, OPT ENG, V49, DOI 10.1117/1.3520553
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Süsstrunk S, 2004, PROC SPIE, V5304, P118, DOI 10.1117/12.537804
   Tsai PS, 2009, IEEE T CIRC SYST VID, V19, P574, DOI 10.1109/TCSVT.2009.2014022
   Wang C, 2008, IET IMAGE PROCESS, V2, P249, DOI 10.1049/iet-ipr:20070198
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wenshuai Yin, 2011, Proceedings of the 2011 3rd International Conference on Awareness Science and Technology (iCAST), P20, DOI 10.1109/ICAwST.2011.6163088
   Wu XL, 2011, IEEE T IMAGE PROCESS, V20, P1262, DOI 10.1109/TIP.2010.2092438
   Zhang XD, 2012, INT C PATT RECOG, P2034
NR 35
TC 35
Z9 36
U1 0
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 28
EP 36
DI 10.1016/j.jvcir.2016.11.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200003
DA 2024-07-18
ER

PT J
AU Abdelsamea, MM
AF Abdelsamea, Mohammed M.
TI A semi-automated system based on level sets and invariant spatial
   interrelation shape features for <i>Caenorhabditis elegans</i>
   phenotypes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Level sets; Sign pressure force; Axis of least inertia; Image-based
   feature classification; Shape-based invariant feature; C. elegans
   phenotypes
ID ACTIVE CONTOURS; C. ELEGANS; AUTOMATED-ANALYSIS; SEGMENTATION;
   RESOLUTION; TRACKING
AB Caenorhabditis elegans shares several molecular and physiological homologies with humans and thus plays a key role in studying biological processes. As a consequence, much progress has been made in automating the analysis of C. elegans. However, there is still a strong need to achieve more progress in automating the analysis of static images of adult worms. In this paper, a three-phase semi-automated system has been proposed. As a first phase, a novel segmentation framework, based on variational level sets and local pressure force function, has been introduced to handle effectively images corrupted with intensity inhomogeneity. Then, a set of robust invariant symbolic features for high-throughput screening of image-based C elegans phenotypes are extracted. Finally, a classification model is applied to discriminate between the different subsets. The proposed system demonstrates its effectiveness in measuring morphological phenotypes in individual worms of C elegans. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Abdelsamea, Mohammed M.] Assiut Univ, Dept Math, Fac Sci, Assiut 71516, Egypt.
   [Abdelsamea, Mohammed M.] Univ Nottingham, Sch Comp Sci, Nottingham NG8 1BB, England.
C3 Egyptian Knowledge Bank (EKB); Assiut University; University of
   Nottingham
RP Abdelsamea, MM (corresponding author), Assiut Univ, Dept Math, Fac Sci, Assiut 71516, Egypt.; Abdelsamea, MM (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham NG8 1BB, England.
EM m.abdelsamea@aun.edu.eg
RI Abdelsamea, Mohammed/AAF-1031-2019
OI Abdelsamea, Mohammed/0000-0002-2728-1127
CR Abdelsamea M. M., 2015, COMPUT INTEL NEUROSC, V2015, P34
   Abdelsamea MM, 2014, ADV INTELL SYST COMP, V295, P293, DOI 10.1007/978-3-319-07695-9_28
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2008, PATTERN RECOGNIT
   [Anonymous], 2013, IEEE POW EN SOC GEN
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Buckingham Steven D., 2008, Invertebrate Neuroscience, V8, P121, DOI 10.1007/s10158-008-0077-3
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Green RA, 2011, CELL, V145, P470, DOI 10.1016/j.cell.2011.03.037
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li C, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P1, DOI 10.1145/1329125.1329187
   Lindeberg T., 2012, SCHOLARPEDIA, V7, P10491, DOI [10.4249/scholarpedia.10491, DOI 10.4249/SCHOLARPEDIA.10491]
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Long FH, 2009, NAT METHODS, V6, P667, DOI [10.1038/nmeth.1366, 10.1038/NMETH.1366]
   Moy TI, 2009, ACS CHEM BIOL, V4, P527, DOI 10.1021/cb900084v
   Murray JI, 2008, NAT METHODS, V5, P703, DOI 10.1038/nmeth.1228
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Raviv TR, 2010, LECT NOTES COMPUT SC, V6363, P634
   Shi YG, 2005, PROC CVPR IEEE, P34
   Sönnichsen B, 2005, NATURE, V434, P462, DOI 10.1038/nature03353
   Wählby C, 2012, NAT METHODS, V9, P714, DOI [10.1038/NMETH.1984, 10.1038/nmeth.1984]
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhu GP, 2007, OPT ENG, V46, DOI 10.1117/1.2740762
NR 28
TC 5
Z9 5
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 314
EP 323
DI 10.1016/j.jvcir.2016.10.011
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000028
DA 2024-07-18
ER

PT J
AU Hu, YX
   Ma, BZ
   Hao, HW
   Li, LM
AF Hu, Yuxing
   Ma, Bozhi
   Hao, Hongwei
   Li, Luming
TI Intermediate multimedia node: Implantable spinal cord stimulator
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intermediate; Multimedia node; Implantable device; Stimulator; Wireless
   communication
ID IMAGE; CUES; PAIN
AB Advanced wireless technology in multimedia devices that is used widely in daily life can be applied to medical devices, such as spinal cord stimulator (SCS), for functioning as a multimedia node. This paper describes a SCS prototype that functions as a sensor and actuator for scientific research and potential clinical applications. The SCS is able to generate voltage/current outputs in 4 channels (with 16 electrodes selection) and has the capacity to sense tissue impedance in real-time. Furthermore, the SCS allows for wireless communication with high power efficiency at a long range (up to 2 m). Benefiting from its novel designs for high power efficiency and wireless signal/power transmission, the SCS also satisfies the longterm animal/clinical test requirements for maintaining multimedia link. Our experiments also indicate that the SCS has better performance, such as in electrical parameters and versatility, to relevant studies. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hu, Yuxing; Ma, Bozhi; Hao, Hongwei; Li, Luming] Tsinghua Univ, Sch Aerosp Engn, Beijing, Peoples R China.
C3 Tsinghua University
RP Li, LM (corresponding author), Tsinghua Univ, Sch Aerosp Engn, Beijing, Peoples R China.
EM thuyuxinghu@gmail.com; mbz@tsinghua.edu.cn; haohw@tsinghua.edu.cn;
   lilm@tsinghua.edu.cn
FU National Key Technology Research and Development Program
   [2011BAI121307]; National Natural Science Foundation of China [51125028]
FX This study has been supported by National Key Technology Research and
   Development Program (No. 2011BAI121307) and National Natural Science
   Foundation of China (No. 51125028).
CR [Anonymous], 2014, P INT ACM SIGIR WORK
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Liu X, 2013, IEEE INT SYMP CIRC S, P1881, DOI 10.1109/ISCAS.2013.6572233
   Mayfield Clinic, 2010, SPIN CORD STIM
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Merrill DR, 2005, J NEUROSCI METH, V141, P171, DOI 10.1016/j.jneumeth.2004.10.020
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   SHEALY CN, 1967, ANESTH ANAL CURR RES, V46, P489
   Shimoji K, 1971, Masui, V20, P444
   Tan J, 2011, 2011 SECOND INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATION AND EDUCATION APPLICATION (ICEA 2011), P197, DOI 10.1109/ASSCC.2011.6123636
   Yin YF, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2658981
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 23
TC 4
Z9 4
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 15
EP 20
DI 10.1016/j.jvcir.2016.09.001
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000002
DA 2024-07-18
ER

PT J
AU Qu, Y
   Koschan, A
   Abidi, M
AF Qu, Ying
   Koschan, Andreas
   Abidi, Mongi
TI Robust penalty-weighted deblurring via kernel adaption using single
   image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind deconvolution; Motion blur; Defocus blur; Regularization; Split
   Bregman
ID BLIND DECONVOLUTION; CAMERA SHAKE; QUALITY; REGULARIZATION; RESTORATION;
   NOISY
AB Image blind deconvolution is well known as a challenging, ill-posed problem due to the uncertainty of the blur kernel and the noise condition. Based on our observations, blind deconvolution algorithms tend to generate disconnected and noisy blur kernels, which would yield a serious ringing effect in the restored image if the input image is noisy. Therefore, there is still room for further improvement, especially for noisy images captured under poor illumination conditions. In this paper, we propose a robust blind deconvolution algorithm by adopting a penalty-weighted anisotropic diffusion prior. On one hand, the anisotropic diffusion prior effectively eliminates the discontinuity in the blur kernel caused by the noisy input image during the process of kernel estimation. On the other hand, the weighted penalizer reduces the speckle noise of the blur kernel, thus improving the quality of the restored image. The effectiveness of the proposed algorithm is verified by both synthetic and real images with defocused or motion blur. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Qu, Ying; Koschan, Andreas; Abidi, Mongi] Univ Tennessee, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.
C3 University of Tennessee System; University of Tennessee Knoxville
RP Qu, Y (corresponding author), Univ Tennessee, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.
EM yqu3@vols.utk.edu
RI Qu, Ying/U-1935-2019
FU NPRP grant from the Qatar National Research Fund (Qatar Foundation)
   [4-1165-2-453]
FX We would like to thank all the authors [24,8,6,19,45,50,17], who kindly
   offer source code or executable files so that we were able to do the
   comparisons. Thanks to Dr. Peyr Gabriel who kindly offer the toolbox
   [10] for tensor structure. This publication was made possible by NPRP
   grant #4-1165-2-453 from the Qatar National Research Fund (a member of
   Qatar Foundation). The statements made herein are solely the
   responsibility of the authors.
CR [Anonymous], IPSJ T COMPUT VIS AP
   Campisi P., 2007, Blindimagedeconvolution:theoryandapplications
   Cao WF, 2013, J VIS COMMUN IMAGE R, V24, P31, DOI 10.1016/j.jvcir.2012.10.006
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen FE, 2013, J VIS COMMUN IMAGE R, V24, P1349, DOI 10.1016/j.jvcir.2013.09.006
   Chen J, 2008, LECT NOTES COMPUT SC, V5018, P1, DOI 10.1007/978-3-540-79723-4_1
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho W, 2015, J OPT SOC AM A, V32, P733, DOI 10.1364/JOSAA.32.000733
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gabarda S, 2006, J VIS COMMUN IMAGE R, V17, P1040, DOI 10.1016/j.jvcir.2005.07.005
   Gabriel P., NUMERICAL TOURS
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gunturk Bahadir Kursat, 2012, Image Restoration: Fundamentals and Advances, DOI DOI 10.1201/B12693
   Guo YP, 1997, IMAGE VISION COMPUT, V15, P399, DOI 10.1016/S0262-8856(96)01143-2
   JEFFERIES SM, 1993, ASTROPHYS J, V415, P862, DOI 10.1086/173208
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Lee JH, 2011, J VIS COMMUN IMAGE R, V22, P653, DOI 10.1016/j.jvcir.2011.07.010
   Levin A., 2006, P NEURAL INFORM PROC, V19, P841
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li F, 2012, J VIS COMMUN IMAGE R, V23, P1041, DOI 10.1016/j.jvcir.2012.07.002
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Li W, 2013, J VIS COMMUN IMAGE R, V24, P1394, DOI 10.1016/j.jvcir.2013.09.008
   Liu YM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508391
   Reeves S. J., 1992, Journal of Visual Communication and Image Representation, V3, P433, DOI 10.1016/1047-3203(92)90044-T
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Son CH, 2013, J VIS COMMUN IMAGE R, V24, P1303, DOI 10.1016/j.jvcir.2013.09.001
   Sroubek F, 2003, IEEE T IMAGE PROCESS, V12, P1094, DOI 10.1109/TIP.2003.815260
   Sroubek F., MULTICHANNEL BLIND D
   Sroubek F, 2012, IEEE T IMAGE PROCESS, V21, P1687, DOI 10.1109/TIP.2011.2175740
   Sun L, 2012, INT C COMP PHOT, P1, DOI DOI 10.1109/ICCPHOT.2012.6215221
   Sun L., SUPER RESOLUTION INT
   Tai YW, 2012, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2012.6247653
   Tao MW, 2013, COMPUT GRAPH FORUM, V32, P489, DOI 10.1111/cgf.12069
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yin M, 2014, J VIS COMMUN IMAGE R, V25, P814, DOI 10.1016/j.jvcir.2014.02.003
   Zanella R., 2009, INVERSE PROB, V25
   Zhao H. K., 2013, MATH IMAGE PROCESSIN, V19
   Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85
   Zhou X, 2015, IEEE T IMAGE PROCESS, V24, P5127, DOI 10.1109/TIP.2015.2478407
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 51
TC 1
Z9 2
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 109
EP 122
DI 10.1016/j.jvcir.2016.09.010
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000011
DA 2024-07-18
ER

PT J
AU Chen, ZY
   Lin, WC
   Tsai, CF
   Ke, SW
AF Chen, Zong-Yao
   Lin, Wei-Chao
   Tsai, Chih-Fong
   Ke, Shih-Wen
TI 3D model retrieval by sample based alignment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia; Retrieval; 3D model; Continuous Principal Component Analysis
   (CPCA); LightField Descriptors (LFD)
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION
AB In 3D model retrieval, preprocessing of 3D models is needed, in which alignment is a key factor that significantly affects retrieval performance. In particular, the anti-rotation image feature can obtain the alignment effect of 3D model views. In practice, the focus of many users of 3D models is not just on retrieval performance, but the use of aligned models for different purposes. In this paper, we propose a method, namely Sample Based Alignment (SBA) for better 3D model alignment and retrieval. In SBA, given a class, a sample model is used as the target for alignment, after which each 3D model in this class is then aligned one by one, i.e., the 3D model is actually rotated. Our experimental results, based on two 3D model data sets and performance comparisons with other methods, demonstrate the superiority of the SBA method over state-of-the-art methods in terms of 3D model retrieval and classification. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Zong-Yao; Tsai, Chih-Fong] Natl Cent Univ, Dept Informat Management, Taoyuan, Taiwan.
   [Lin, Wei-Chao] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Ke, Shih-Wen] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Taoyuan, Taiwan.
C3 National Central University; Asia University Taiwan; Chung Yuan
   Christian University
RP Tsai, CF (corresponding author), Natl Cent Univ, Dept Informat Management, Taoyuan, Taiwan.
EM cftsai@mgt.ncu.edu.tw
CR Akgul C., 2009, 30 INT C EUROGRAPHIC
   Aldoma A., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P374, DOI 10.1109/3DIMPVT.2011.54
   Axenopoulos A., 2011, ICMR 11 P 1 ACM INT
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaouch M, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P187, DOI 10.1109/SMI.2008.4547969
   Chaouch M, 2009, GRAPH MODELS, V71, P63, DOI 10.1016/j.gmod.2008.12.006
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P., 2009, IEEE 7 INT WORKSH CO
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P374, DOI 10.1109/TMM.2011.2176111
   Dutagaci H., 2011, 4 EUR WORKSH 3D OBJ
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Furuya T., 2009, P ACM CIVR 2009
   Gao B., 2009, IEEE INT C MULT EXP, P599
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Kazhdan M, 2007, IEEE T PATTERN ANAL, V29, P1221, DOI 10.1109/TPAMI.2007.1032
   Lai K., 2010, 2010 IEEE 19 INT WOR
   Lian Z., 2010, P SMI
   Lian ZH, 2010, INT J COMPUT VISION, V89, P130, DOI 10.1007/s11263-009-0295-0
   Liu W., 2006, INNOVATIVE COMPUTING, V3, P463
   Nuchter A., 2004, Proc. 8th Conf. Intelligent Autonomous Systems, P963
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Paquet E, 1999, IMAGE VISION COMPUT, V17, P157, DOI 10.1016/S0262-8856(98)00119-X
   Qian Zhang, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P212, DOI 10.1109/ISM.2010.38
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Vanamali T.P., 2010, EUR WORKSH 3D OBJ RE
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   Vranic DV, 2004, THESIS
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
NR 33
TC 2
Z9 4
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 721
EP 731
DI 10.1016/j.jvcir.2016.08.017
PN B
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600026
DA 2024-07-18
ER

PT J
AU Jin, RC
   Zhao, SR
   Xu, XY
   Song, EM
AF Jin, Renchao
   Zhao, Shengrong
   Xu, Xiangyang
   Song, Enmin
TI Multiframe super-resolution based on half-quadratic prior with artifacts
   suppress
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Variational Bayesian inference; Regularization;
   Discontinuity-preserving; Artifacts-suppressing
ID ROBUST; RESOLUTION; SPARSE
AB The multiframe super-resolution (SR) technique aims to obtain a high-resolution (HR) image by using a set of observed low-resolution (LR) images. In the reconstruction process, artifacts may be possibly produced due to the noise, especially in presence of stronger noise. In order to suppress artifacts while preserving discontinuities of images, in this paper a multiframe SR method is proposed by involving the reconstruction properties of the half-quadratic prior model together with the quadratic prior model using a convex combination. Moreover, by analyzing local features of the underlined HR image, these two prior models are combined by using an automatically calculated weight function, making both smooth and discontinuous pixels handled properly. A variational Bayesian inference (VBF) based algorithm is designed to efficiently and effectively seek the solution of the proposed method. With the VBF framework, motion parameters and hyper-parameters are all determined automatically, leading to an unsupervised SR method. The efficiency of the hybrid prior model is demonstrated theoretically and practically, which shows that our SR method can obtain better results from LR images even with stronger noise. Extensive experiments on several visual data have demonstrated the efficacy and superior performance of the proposed algorithm, which can not only preserve image details but also suppress artifacts. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Jin, Renchao; Zhao, Shengrong; Xu, Xiangyang; Song, Enmin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Zhao, Shengrong] Qilu Univ Technol, Sch Informat, Jinan 250353, Peoples R China.
C3 Huazhong University of Science & Technology; Qilu University of
   Technology
RP Song, EM (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM enmin_song@126.com
RI Xu, Xiangyang/N-9292-2014; Jin, Renchao/F-4880-2018
OI Xu, Xiangyang/0000-0002-9713-0535; Jin, Renchao/0000-0002-1591-3510;
   Zhao, Shengrong/0000-0003-0965-0918
FU NSFC [61370179, 71271125, 61502260]; Fundamental Research Funds for the
   Central Universities, HUST [2015YGYL012, 2016YXMS086]
FX This research was supported by NSFC Grant No. 61370179, 71271125,
   61502260, the Fundamental Research Funds for the Central Universities,
   HUST No. 2015YGYL012 and No. 2016YXMS086.
CR Babacan SD, 2011, IEEE T IMAGE PROCESS, V20, P984, DOI 10.1109/TIP.2010.2080278
   Ceccarelli M, 2007, IMAGE VISION COMPUT, V25, P792, DOI 10.1016/j.imavis.2006.05.021
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Guo K, 2012, IET IMAGE PROCESS, V6, P337, DOI 10.1049/iet-ipr.2010.0430
   Guo K, 2012, IEEE T IMAGE PROCESS, V21, P615, DOI 10.1109/TIP.2011.2165290
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Ng M., 2007, EURASIP J ADV SIG PR, V2007, P298
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Shao WZ, 2014, J SCI COMPUT, V60, P60, DOI 10.1007/s10915-013-9784-y
   Shekarforoush H., 1996, IEEE INT C IM PROC, V2, P300
   Suresh KV, 2007, IEEE T INTELL TRANSP, V8, P321, DOI 10.1109/TITS.2007.895291
   Suresh KV, 2007, J OPT SOC AM A, V24, P984, DOI 10.1364/JOSAA.24.000984
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Villena S, 2013, DIGIT SIGNAL PROCESS, V23, P530, DOI 10.1016/j.dsp.2012.10.002
   Villena S, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P156
   Wang Z., 2015, 2015 IEEE C COMP VIS, P5224
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Yuan QQ, 2012, IEEE T CIRC SYST VID, V22, P379, DOI 10.1109/TCSVT.2011.2163447
   Zeng XY, 2013, DIGIT SIGNAL PROCESS, V23, P98, DOI 10.1016/j.dsp.2012.06.013
   Zhang DX, 2015, IEEE SIGNAL PROC LET, V22, P2279, DOI 10.1109/LSP.2015.2477079
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zhang X, 2008, LECT NOTES COMPUT SC, V4987, P51
   Zhao S., 2015, MATH PROBLEMS ENG
NR 30
TC 5
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 656
EP 670
DI 10.1016/j.jvcir.2016.08.006
PN B
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600021
DA 2024-07-18
ER

PT J
AU Ma, HJ
   Nie, YF
AF Ma, Hongjin
   Nie, Yufeng
TI An edge fusion scheme for image denoising based on anisotropic diffusion
   models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Edge fusion scheme; Enhanced denoising model;
   Anisotropic diffusion
ID PERONA-MALIK MODEL; NONLINEAR DIFFUSION; NOISE REMOVAL; ENHANCEMENT;
   ALGORITHM; FILTER
AB In this paper, we propose an enhanced anisotropic diffusion model. The improved model can classify finely image information as smooth regions, edges, corners and isolated noises by characteristic parameters and gradient variance parameter. And for different image information the eigenvalues of diffusion tensor are designed to conduct adaptive diffusion. Moreover, an edge fusion scheme is posed to preserve edges after denoising by combing different denoising and edge detection methods. Firstly, different denoising methods are applied for noisy image to obtain denoised images, and the best method among them is selected as main method. Then edge images of denoised images are obtained by edge detection methods. Finally, by fusing edge images together more integrated edges can be achieved to replace edges of denoised image obtained by main method. The experimental results show the proposed model can denoise meanwhile preserve edges and corners, and the edge fusion scheme is accurate and effective. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ma, Hongjin; Nie, Yufeng] Northwestern Polytech Univ, Sch Sci, Dept Appl Math, Xian 710129, Peoples R China.
C3 Northwestern Polytechnical University
RP Ma, HJ (corresponding author), Northwestern Polytech Univ, Sch Sci, Dept Appl Math, Xian 710129, Peoples R China.
EM Hjma@mail.nwpu.edu.cn
RI Nie, Yufeng/JGE-5446-2023; Nie, Yufeng/ABF-7629-2021
OI Nie, Yufeng/0000-0001-7881-5806
FU National Natural Science Foundation of China [11471262]
FX The authors are grateful to the anonymous reviewers and the associate
   editor for their valuable comments. This work has been supported by
   National Natural Science Foundation of China (No. 11471262).
CR [Anonymous], COMP SUPPL
   Bogdanova I, 2007, IEEE T IMAGE PROCESS, V16, P1888, DOI 10.1109/TIP.2007.899008
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Chen HS, 2015, J VIS COMMUN IMAGE R, V31, P282, DOI 10.1016/j.jvcir.2015.07.004
   Ellmauthaler A, 2013, IEEE T IMAGE PROCESS, V22, P1005, DOI 10.1109/TIP.2012.2226045
   Fung YH, 2013, IEEE T IMAGE PROCESS, V22, P413, DOI 10.1109/TIP.2012.2211370
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Guo ZC, 2012, IEEE T IMAGE PROCESS, V21, P958, DOI 10.1109/TIP.2011.2169272
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Hu J, 2013, OPTIK, V124, P5639, DOI 10.1016/j.ijleo.2013.04.009
   Krissian K, 2009, IEEE T IMAGE PROCESS, V18, P2265, DOI 10.1109/TIP.2009.2025553
   Maggioni M., 2013, IEEE T IMAGE PROCESS, V66, p2376C
   Oh S, 2013, J VIS COMMUN IMAGE R, V24, P332, DOI 10.1016/j.jvcir.2013.01.010
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prasath VBS, 2015, IEEE T IMAGE PROCESS, V24, P5220, DOI 10.1109/TIP.2015.2479471
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Sun J, 2010, PATTERN RECOGN, V43, P2630, DOI 10.1016/j.patcog.2010.02.019
   Taal CH, 2013, IEEE SIGNAL PROC LET, V20, P225, DOI 10.1109/LSP.2013.2240297
   Talebi H, 2014, IEEE T IMAGE PROCESS, V23, P755, DOI 10.1109/TIP.2013.2293425
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   XIE MH, 2006, CHINESE J ELECTRON, V34, P59
   Yang M, 2013, NEUROCOMPUTING, V120, P262, DOI 10.1016/j.neucom.2012.08.063
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhao L, 2015, MATH METHOD APPL SCI, V38, P937, DOI 10.1002/mma.3119
   Zhou YY, 2013, J VIS COMMUN IMAGE R, V24, P283, DOI 10.1016/j.jvcir.2013.01.004
NR 28
TC 9
Z9 9
U1 3
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 406
EP 417
DI 10.1016/j.jvcir.2016.06.027
PN B
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600002
DA 2024-07-18
ER

PT J
AU Wang, LL
   Li, RF
   Fang, YJ
AF Wang, Liangliang
   Li, Ruifeng
   Fang, Yajun
TI Gradient-layer feature transform for action detection and recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action detection; Action recognition; Gaussian convolution; Frame
   difference projection; Sequence correspondence fusion
ID REPRESENTATION; LOCALIZATION; HISTOGRAMS; BAG
AB Exploring action feature representation in consecutive video frames is a basic but critical issue in the area of computer vision. This paper presents a principled technique transforming gradient-based features into coherent spatial-temporal descriptors for action detection and recognition. Specifically, Gaussian convolution based technique is first applied to extract spatial features of each image frame on gradient layer, based on which the spatial features are further processed according to the forward-backward frame difference and correspondence fusion between frames for frame sequence representation. Furthermore, region of actions is labeled via thresholding the projection of difference features in horizontal-vertical direction while action types are classified via learning the fused features. We evaluate our approach on samples from KTH, Weizmann, UCF Sports dataset and ChangeDetection.NET dataset 2014, which demonstrates its applicability and effectiveness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Liangliang; Li, Ruifeng] Harbin Inst Technol, State Key Lab Robot & Syst, Harbin 150001, Peoples R China.
   [Fang, Yajun] MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 Harbin Institute of Technology; Massachusetts Institute of Technology
   (MIT)
RP Wang, LL (corresponding author), Harbin Inst Technol, State Key Lab Robot & Syst, Harbin 150001, Peoples R China.
EM yueyangmeng@163.com
FU National Natural Science Foundation of China [661273339]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No: 661273339). The author also would like to thank
   Berthold K.P. Horn for his good ideas during author's visit study at MIT
   CSAIL.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Ballas N, 2013, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2013.336
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cao XC, 2014, MACH VISION APPL, V25, P159, DOI 10.1007/s00138-013-0545-6
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Derpanis KG, 2013, IEEE T PATTERN ANAL, V35, P527, DOI 10.1109/TPAMI.2012.141
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Iosifidis A, 2014, PATTERN RECOGN LETT, V49, P185, DOI 10.1016/j.patrec.2014.07.011
   Iosifidis A, 2012, IEEE T NEUR NET LEAR, V23, P412, DOI 10.1109/TNNLS.2011.2181865
   Jiang ZL, 2013, COMPUT VIS IMAGE UND, V117, P1345, DOI 10.1016/j.cviu.2012.09.008
   Junejo IN, 2012, J VIS COMMUN IMAGE R, V23, P853, DOI 10.1016/j.jvcir.2012.05.001
   Kaâniche MB, 2010, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2010.5539999
   Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0
   Khan R, 2015, COMPUT VIS IMAGE UND, V132, P102, DOI 10.1016/j.cviu.2014.09.005
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Liu DT, 2015, INT J MULTIMED DATA, V6, P1, DOI 10.4018/ijmdem.2015010101
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma SG, 2013, IEEE I CONF COMP VIS, P2744, DOI 10.1109/ICCV.2013.341
   Mahmoudi SA, 2014, B POL ACAD SCI-TECH, V62, P139, DOI 10.2478/bpasts-2014-0016
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Rekik W, 2015, INFORM SCIENCES, V306, P132, DOI 10.1016/j.ins.2015.01.039
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shao ZP, 2015, PATTERN RECOGN, V48, P2418, DOI 10.1016/j.patcog.2015.02.029
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Suksompong P, 2010, IEEE T INFORM THEORY, V56, P838, DOI 10.1109/TIT.2009.2037042
   Wang HR, 2014, IEEE T IMAGE PROCESS, V23, P570, DOI 10.1109/TIP.2013.2292550
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wang ZH, 2014, IEEE SIGNAL PROC LET, V21, P1403, DOI 10.1109/LSP.2014.2338056
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 41
TC 5
Z9 5
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 159
EP 167
DI 10.1016/j.jvcir.2016.06.023
PN A
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500016
DA 2024-07-18
ER

PT J
AU Liu, M
   Fan, QB
AF Liu, Min
   Fan, Qibin
TI A modified convex variational model for multiplicative noise removal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiplicative noise; Convexity; Variational model; Primal-dual methods;
   Linearization; I-divergence; Statistical property; Regularization
ID PARALLEL FRAMEWORK; IMAGES; OPTIMIZATION; MINIMIZATION; ALGORITHMS
AB In this paper, a convex variational model for multiplicative noise removal is studied. Accelerating primal dual method and proximal linearized alternating direction method are also discussed. An improved primal-dual method is proposed. Algorithms above produce more desired results than primal-dual algorithm when we solve the convex variational model. Inspired by the statistical property of the Gamma multiplicative noise and I-divergence, a modified convex variational model is proposed, for which the uniqueness of solution is also provided. Moreover, the property of the solution is presented. Without inner iterations, primal-dual method is efficient to the modified model, and running time can be reduced dramatically also with good restoration. When we set parameter alpha to 0, the convex variational model we proposed turns into the model in Steidl and Teuber (2010). By altering alpha, our model can be used for different noise level. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Min; Fan, Qibin] Wuhan Univ, Sch Math & Stat, Wuhan, Peoples R China.
C3 Wuhan University
RP Fan, QB (corresponding author), Wuhan Univ, Sch Math & Stat, Wuhan, Peoples R China.
EM mliuf@whu.edu.cn; qbfan@whu.edu.cn
FU National Science Fundation of China [61179039]; National Key Basic
   Research Development Program (973 Program) of China [2011CB707100]
FX This work is supported by the National Science Fundation of China under
   Grant 61179039 and by the National Key Basic Research Development
   Program (973 Program) of China under Grant 2011CB707100.
CR [Anonymous], 2008, UCLA CAM REP
   [Anonymous], 2006, Mathematical problems in image processing: Partial differential equations and the calculus of variations
   [Anonymous], 2000, Oxford Mathematical Monographs
   [Anonymous], 1968, APPL MATH SER
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chen DQ, 2014, J COMPUT APPL MATH, V257, P29, DOI 10.1016/j.cam.2013.08.012
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Darbon J., 2006, NOTE NICE LEVELABLE
   Dong FF, 2012, MATH COMPUT MODEL, V55, P939, DOI 10.1016/j.mcm.2011.09.021
   Dong YQ, 2013, SIAM J IMAGING SCI, V6, P1598, DOI 10.1137/120870621
   Esser E., 2009, 0967 CAM UCLA
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Fan QB, 2014, IEEE T SIGNAL PROCES, V62, P6276, DOI 10.1109/TSP.2014.2362880
   [樊启斌 Fan Qibin], 2012, [数学进展, Advances in Mathematics], V41, P531
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hintermüller M, 2013, SIAM J IMAGING SCI, V6, P2134, DOI 10.1137/120894130
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Kornprobst P, 1999, J MATH IMAGING VIS, V11, P5, DOI 10.1023/A:1008318126505
   Li F, 2010, SIAM J IMAGING SCI, V3, P1, DOI 10.1137/090748421
   LOUPAS T, 1989, IEEE T CIRCUITS SYST, V36, P129, DOI 10.1109/31.16577
   Pock T, 2009, IEEE I CONF COMP VIS, P1133, DOI 10.1109/ICCV.2009.5459348
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Woo H, 2013, SIAM J SCI COMPUT, V35, pB336, DOI 10.1137/11083811X
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yin W., 2007, 37 UCLA CAM, V37
   Zhang XQ, 2011, J SCI COMPUT, V46, P20, DOI 10.1007/s10915-010-9408-8
   Zhao XL, 2014, SIAM J IMAGING SCI, V7, P456, DOI 10.1137/13092472X
NR 37
TC 12
Z9 12
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 187
EP 198
DI 10.1016/j.jvcir.2016.01.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200016
DA 2024-07-18
ER

PT J
AU Guo, JM
   Prasetyo, H
   Wong, K
AF Guo, Jing-Ming
   Prasetyo, Heri
   Wong, KokSheik
TI Halftoning-based Block Truncation Coding image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Halftoning; Error diffusion; Ordered dithering; Block truncation coding;
   Image restoration; Sparse representation; Image compression; Vector
   quantization
ID SPARSE REPRESENTATION; DICTIONARIES
AB This paper presents a new image restoration method for improving the quality of halftoning-Block Truncation Coding (BTC) decoded image in a patch-based manner. The halftoning-BTC decoded image suffers from the halftoning impulse noise which can be effectively reduced and suppressed using the Vector Quantization (VQ)-based and sparsity-based approaches. The VQ-based approach employs the visual codebook generated from the clean image, whereas the sparsity-based approach utilizes the double learned dictionaries in the noise reduction. The sparsity-based approach assumes that the halftoningBTC decode image and clean image share the same sparsity coefficient. In the sparse coding stage, it uses the halftoning-BTC dictionary, while in the reconstruction stage, it exploits the clean image dictionary. As suggested by the experimental results, the proposed method outperforms in the halftoning-BTC image reconstructed when compared to that of the filtering approaches. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Guo, Jing-Ming; Prasetyo, Heri] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
   [Wong, KokSheik] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
C3 National Taiwan University of Science & Technology; Universiti Malaya
RP Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jmguo@seed.net.tw; heri_inf_its_02@yahoo.co.id; koksheik@um.edu.my
RI Prasetyo, Heri/AAD-2388-2022; Wong, KokSheik/B-9796-2011
OI Prasetyo, Heri/0000-0002-1257-4832; Wong, KokSheik/0000-0002-4893-2291
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2010, IEEE T IMAGE PROCESS
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Guo J.M., 2008, ELECT LETT, V44
   Guo J.M., 2011, INT C SYST SCI ENG I, P593
   Guo JM, 2015, IEEE T CIRC SYST VID, V25, P466, DOI 10.1109/TCSVT.2014.2358011
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2010, IEEE T IMAGE PROCESS, V19, P2056, DOI 10.1109/TIP.2010.2045709
   Guo JM, 2010, DIGIT SIGNAL PROCESS, V20, P97, DOI 10.1016/j.dsp.2009.04.007
   Guo JM, 2009, SIGNAL PROCESS, V89, P1864, DOI 10.1016/j.sigpro.2009.03.013
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Xu M, 2014, IEEE T CIRC SYST VID, V24, P1743, DOI 10.1109/TCSVT.2014.2317886
NR 13
TC 7
Z9 7
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 193
EP 197
DI 10.1016/j.jvcir.2015.12.016
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600017
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Mitra, P
AF Chakraborty, Souradeep
   Mitra, Pabitra
TI A site entropy rate and degree centrality based algorithm for image
   co-segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Site entropy rate; Degree centrality; Co-segmentation; Co-saliency;
   Markov chain; Object proposal; k-partite graph; Stationary distribution
ID SALIENCY DETECTION; VISUAL SALIENCY; COSEGMENTATION
AB In this paper, we propose a graph based algorithm that efficiently segments common objects from multiple images. We first generate a number of object proposals from each image. Then, an undirected graph is constructed based on proposal similarities and co-saliency maps. Two different methods are followed to extract the proposals containing common objects. They are: (1) degree centrality of nodes obtained after graph thresholding and (2) site entropy rate of nodes calculated on the stationary distribution of Markov chain constructed on the graph. Finally, we obtain the co-segmented image region by selecting the more salient of the object proposals obtained by the two methods, for each image. Multiple instances of the common object are also segmented efficiently. The proposed method has been compared with many existing co-segmentation methods on three standard co-segmentation datasets. Experimental results show its effectiveness in co-segmentation, with larger IoU values as compared to other co-segmentation methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chakraborty, Souradeep] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
   [Mitra, Pabitra] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Chakraborty, S (corresponding author), Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
EM sourachakra@gmail.com; pabitra@gmail.com
CR [Anonymous], P VIS COMM IM PROC V
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borenstein E, 2004, IEEE C COMP VIS PATT
   Boykov Y.Y., P INT C COMP VIS, V1, P105
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Fu H., IEEE T IMAGE PROCESS, V22, P3766
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Jing F, 2004, IEEE T CIRC SYST VID, V14, P672, DOI 10.1109/TCSVT.2004.826775
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Meng F., 2013, IEEE T CYBERN, V43
   Meng FM, 2014, IEEE INT SYMP CIRC S, P353, DOI 10.1109/ISCAS.2014.6865138
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal R, 2010, IET COMPUT VIS, V4, P218, DOI 10.1049/iet-cvi.2009.0067
   Qingshan Li, 2011, 2011 International Conference on Multimedia Technology, P5068
   Rantalankila Pekka, 2014, P IEEE C COMP VIS PA, P2
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Tao WB, 2015, IEEE T IMAGE PROCESS, V24, P943, DOI 10.1109/TIP.2014.2387384
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang JY, 2010, PROC CVPR IEEE, P2125, DOI 10.1109/CVPR.2010.5539891
NR 35
TC 2
Z9 2
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 20
EP 30
DI 10.1016/j.jvcir.2015.08.016
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700003
DA 2024-07-18
ER

PT J
AU Wang, T
   Ji, ZX
   Sun, QS
   Chen, Q
   Han, SD
AF Wang, Tao
   Ji, Zexuan
   Sun, Quansen
   Chen, Qiang
   Han, Shoudong
TI Image segmentation based on weighting boundary information via graph cut
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Graph cut; Weighting parameter; Image patch; Color
   image; Region information; Boundary information; Parameter learning
ID GAUSSIAN MIXTURE MODEL
AB The graph cut model has been widely used in image segmentation, in which both the region and boundary information play important roles for accurate segmentation. However, how to effectively model and combine these two information is still a challenge. In this paper, we improve the conventional graph cut methods by combining the region and boundary information with an effective and straightforward way. When modeling the region information, the component-wise expectation-maximization for Gaussian mixtures algorithm is used to learn the parameters of the prior knowledge. When modeling the boundary information, the weighting patch is used to represent the similarities of the neighboring pixels. Then the region and boundary information are combined by a weighting parameter, where the weight is small for boundary pixels and is large for non-boundary pixels. Finally, experiments on various images from the Berkeley and MSRC data sets were conducted to demonstrate the effectiveness of the proposed method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Tao; Ji, Zexuan; Sun, Quansen; Chen, Qiang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Han, Shoudong] Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Peoples R China.
C3 Nanjing University of Science & Technology; Huazhong University of
   Science & Technology
RP Sun, QS (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM wangtaoatnjust@163.com; jizexuan@njust.edu.cn; sunquansen@njust.edu.cn
RI chen, qiang/GWZ-7308-2022; chen, qiang/HGU-5418-2022
FU Graduate Innovation Project of Jiangsu Province [KYZZ15_0125,
   KYZZ15_0124]; National Science Foundation of China [61401209, 61273251,
   61105006]; Natural Science Foundation of Jiangsu Province, China
   [BK20140790]; China Postdoctoral Science Foundation [2013M531364];
   Fundamental Research Funds for the Central Universities [30920140111004]
FX This work was supported in part by the Graduate Innovation Project of
   Jiangsu Province under Grants KYZZ15_0125 and KYZZ15_0124, in part by
   the National Science Foundation of China under Grants 61401209, 61273251
   and 61105006, in part by the Natural Science Foundation of Jiangsu
   Province, China under Grant BK20140790, in part by China Postdoctoral
   Science Foundation under Grant 2013M531364, and in part by the
   Fundamental Research Funds for the Central Universities under Grant
   30920140111004.
CR [Anonymous], 2007, CVPR, DOI DOI 10.1109/CVPR.2007.383203
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Candemir S, 2010, LECT NOTES COMPUT SC, V6111, P117, DOI 10.1007/978-3-642-13772-3_13
   Coupé P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Gorelick L, 2014, PROC CVPR IEEE, P1154, DOI 10.1109/CVPR.2014.151
   Han Shou-Dong, 2011, Acta Automatica Sinica, V37, P11, DOI 10.3724/SP.J.1004.2011.00011
   Han SD, 2011, PATTERN RECOGN, V44, P503, DOI 10.1016/j.patcog.2010.09.006
   Han SD, 2009, IEEE T IMAGE PROCESS, V18, P2289, DOI 10.1109/TIP.2009.2025560
   Ji ZX, 2011, PATTERN RECOGN, V44, P999, DOI 10.1016/j.patcog.2010.11.017
   Ji ZX, 2012, IEEE T INF TECHNOL B, V16, P339, DOI 10.1109/TITB.2012.2185852
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031
   Li CM, 2005, PROC CVPR IEEE, P430
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   PENG B, 2008, P INT C PATT REC, P1
   Peng B, 2011, PATTERN RECOGN, V44, P2527, DOI 10.1016/j.patcog.2011.03.024
   Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sonka M., 2014, Image processing, analysis, and machine vision
   Tang M, 2014, LECT NOTES COMPUT SC, V8693, P691, DOI 10.1007/978-3-319-10602-1_45
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang T, 2015, NEUROCOMPUTING, V158, P13, DOI 10.1016/j.neucom.2015.02.010
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611
   Zhou HL, 2013, PATTERN RECOGN, V46, P1719, DOI 10.1016/j.patcog.2012.12.005
NR 28
TC 20
Z9 21
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 10
EP 19
DI 10.1016/j.jvcir.2015.08.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700002
DA 2024-07-18
ER

PT J
AU Lin, JY
   Song, R
   Wu, CH
   Liu, TJ
   Wang, HQ
   Kuo, CCJ
AF Lin, Joe Yuchieh
   Song, Rui
   Wu, Chi-Hao
   Liu, TsungJung
   Wang, Haiqiang
   Kuo, C. -C. Jay
TI MCL-V: A streaming video quality assessment database
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video quality; Quality assessment; Quality database; Video streaming;
   Compression distortion; Video re-sizing; Video coding; Perceptual
   quality
ID PERCEPTUAL QUALITY; FRAME RATE; INFORMATION; LOSSES
AB A high-definition video quality assessment (VQA) database that captures two typical video distortion types in video services (namely, "compression" and "compression followed by scaling") is presented in this work. The VQA database, called MCL-V, contains 12 source video clips and 96 distorted video clips with subjective assessment scores. The source video clips are selected from a large pool of public-domain high-definition (HD) video sequences with representative and diversified contents. Both distortion types are perceptually adjusted to yield distinguishable distortion levels. An improved pairwise comparison method is adopted for subjective evaluation to save evaluation time. Several existing image and video quality assessment (IQA and VQA) algorithms are evaluated against the MCL-V database. The MCL-V database is publicly accessible in the link - http://mcLusc.edu/mcl-v-database/ to facilitate future video quality assessment research of the community. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lin, Joe Yuchieh; Wu, Chi-Hao; Liu, TsungJung; Wang, Haiqiang; Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA USA.
   [Song, Rui] Xidian Univ, Xian 710071, Shaanxi, Peoples R China.
C3 University of Southern California; Xidian University
RP Song, R (corresponding author), Xidian Univ, POB 103,2nd Taibai South Rd, Xian 710071, Shaanxi, Peoples R China.
EM rsong@xidian.edu.cn
RI Liu, Tsung-Jung/AAH-5125-2021; Wu, chihao/G-3512-2011; Kuo, C.-C.
   Jay/A-7110-2011
OI Liu, Tsung-Jung/0000-0003-4296-0942; Kuo, C.-C. Jay/0000-0001-9474-5035
FU Netflix; NSFC - China [61401337]; Fundamental Research Funds for the
   Central Universities; China Scholarship Council; University of Southern
   California Center
FX This project is funded by Netflix. The authors are grateful to Mr. David
   Ronca and Dr. Anne Aaron of Netflix for their valuable suggestions in
   various stages of this research. This work is supported by NSFC - China
   Grant No. 61401337, Fundamental Research Funds for the Central
   Universities, and China Scholarship Council. Computation for the work
   described in this paper was supported by the University of Southern
   California Center for High-Performance Computing and Communications
   (hpcc.usc.edu).
CR [Anonymous], 2011, IVP Subjective Quality Video Database
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 2013, EVID-BASED COMPL ALT
   Bird S.Elizabeth., 2013, The Audience in Everyday Life: Living in a Media World
   Boujut H., 2011, P SOC PHOTO-OPT INS
   Boulos F, 2009, IEEE IMAGE PROC, P3109, DOI 10.1109/ICIP.2009.5414458
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   BRADLEY RA, 1954, BIOMETRIKA, V41, P502, DOI 10.2307/2332730
   Brotherton MD, 2006, IEICE T FUND ELECTR, VE89A, P2920, DOI 10.1093/ietfec/e89-a.11.2920
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   De Simone F, 2010, INT CONF ACOUST SPEE, P2430, DOI 10.1109/ICASSP.2010.5496296
   De Simone F, 2009, INT WORK QUAL MULTIM, P204, DOI 10.1109/QOMEX.2009.5246952
   Ebrahimi T., 2009, P 17 ACM INT C MULTI, P3
   Gaubatz M., 2011, METRIX MUX VISUAL QU
   Goedegebure S., 2008, BIG BUCK BUNNY
   Goldmann L., 2010, P SOC PHOTO-OPT INS
   GULLIKSEN H, 1956, PSYCHOMETRIKA, V21, P125, DOI 10.1007/BF02289093
   Gupta M.R., 2011, ANAL PAIRED COMP DAT
   Haglund L., SVT HIGH DEFINITION
   Hastie T., 2009, The Elements of Statistical Learning
   Keimel C, 2012, INT WORK QUAL MULTIM, P97, DOI 10.1109/QoMEX.2012.6263865
   Khan A, 2010, IEEE INT CON MULTI, P702, DOI 10.1109/ICME.2010.5583033
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Lee J.-S., IEEE T MULTIMEDIA, V13
   Lee JS, 2013, MULTIMED TOOLS APPL, V67, P31, DOI 10.1007/s11042-012-1011-6
   Li J, 2012, IEEE IMAGE PROC, P629, DOI 10.1109/ICIP.2012.6466938
   Li SN, 2012, IEEE T CIRC SYST VID, V22, P1100, DOI 10.1109/TCSVT.2012.2190473
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu T, 2009, IEEE J-STSP, V3, P280, DOI 10.1109/JSTSP.2009.2015069
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Ou YF, 2010, INT CONF ACOUST SPEE, P2446, DOI 10.1109/ICASSP.2010.5496300
   Ou YF, 2008, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2008.4711848
   Pechard S., 2008, P 3 INT WORKSH IM ME
   Pitrey Y., 2011, 2011 3rd European Workshop on Visual Information Processing, P180, DOI 10.1109/EuVIP.2011.6045538
   Pitrey Y., 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P86, DOI 10.1109/EUVIP.2010.5699138
   Pitrey Y., SUBJECTIVE QUALITY E
   Pitrey Y., ALIGNING SUBJECTIVE
   Pitrey Y., 2010, P SOC PHOTO-OPT INS
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Silverstein DA, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P242
   Silverstein DA, 2001, J ELECTRON IMAGING, V10, P394, DOI 10.1117/1.1344187
   Staelens N, 2013, INT WORK QUAL MULTIM, P130, DOI 10.1109/QoMEX.2013.6603225
   Tice D., 2013, PEOPLE USE MEDIA OVE
   Tominaga Toshiko, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P82, DOI 10.1109/QOMEX.2010.5517948
   Video Qual. Experts Group Mountain View CA USA, 2010, Report on theValidation of Video Quality Models for High Definition Video Content
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Xin F, 2008, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2008.4712316
   Xu Qianqian., 2011, ACM INT C MULTIMEDIA, P393
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   You J., 2011, Proceedings of the 19th ACM International Conference on Multimedia (ACM MM), P1293
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 59
TC 75
Z9 86
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 1
EP 9
DI 10.1016/j.jvcir.2015.02.012
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900001
DA 2024-07-18
ER

PT J
AU Huang, L
   Ji, W
   Wei, ZQ
   Chen, BW
   Yan, CC
   Nie, J
   Yin, J
   Jiang, BC
AF Huang, Lei
   Ji, Wen
   Wei, Zhiqiang
   Chen, Bo-Wei
   Yan, Chenggang Clarence
   Nie, Jie
   Yin, Jian
   Jiang, Baochen
TI Robust skin detection in real-world images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skin detection; Skin color map (SCM); Skin texture map (STM); Skin color
   and texture based graph cuts (SCTGC); Skin seed determination; Color
   property; Texture property; Region property
ID EFFICIENT PARALLEL FRAMEWORK; MODELS
AB Human skin detection in images is desirable in many practical applications, e.g., human-computer interaction and adult-content filtering. However, existing methods are mainly suffer from confusing backgrounds in real-world images. In this paper, we try to address this issue by exploring and combining several human skin properties, i.e. color property, texture property and region property. First, images are divided into superpixels, and robust skin seeds and background seeds are acquired through color property and texture property of skin. Then we combining color, region and texture properties of skin by proposing a novel skin color and texture based graph cuts (SCTGC) to acquire the final skin detection results. Comprehensive and comparative experiments show that the proposed method achieves promising performance and outperforms many state-of-the-art methods over publicly available challenging datasets with a great part of hard images. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Huang, Lei; Wei, Zhiqiang] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
   [Ji, Wen] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Chen, Bo-Wei] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
   [Yan, Chenggang Clarence] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Nie, Jie] Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
   [Yin, Jian; Jiang, Baochen] Shandong Univ, Dept Comp, Weihai, Peoples R China.
C3 Ocean University of China; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Princeton University; Tsinghua University;
   Tsinghua University; Shandong University
RP Yan, CC (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
EM andy.cg.yan@gmail.com
RI Nie, Jie/ABG-9228-2021
OI Nie, Jie/0000-0003-4952-7666; Jiang, Baochen/0000-0002-6055-2355
FU National Nature Science Foundation of China [61402428, 61472203,
   61202208]; Fundamental Research Funds for the Central Universities
   [201413021, 201513016]; Hunan Provincial Natural Science Foundation of
   China [2015JJ2056]
FX This work is supported by the National Nature Science Foundation of
   China (No. 61402428, 61472203, 61202208); the Fundamental Research Funds
   for the Central Universities (No. 201413021, 201513016); the Hunan
   Provincial Natural Science Foundation of China (No. 2015JJ2056).
CR Abin AA, 2009, MULTIMEDIA SYST, V15, P309, DOI 10.1007/s00530-009-0165-1
   [Anonymous], 2002, P 2002 ASIAN C COMPU
   [Anonymous], P ACM INT C MULT NEW
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Chenaoua K, 2006, IEEE IMAGE PROC, P2673, DOI 10.1109/ICIP.2006.313060
   Dadgostar F, 2006, PATTERN RECOGN LETT, V27, P1342, DOI 10.1016/j.patrec.2006.01.007
   Greenspan H, 2001, PATTERN RECOGN LETT, V22, P1525, DOI 10.1016/S0167-8655(01)00086-1
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hu ZL, 2008, PATTERN RECOGN, V41, P1581, DOI 10.1016/j.patcog.2007.10.005
   Huang L, 2013, NEUROCOMPUTING, V118, P191, DOI 10.1016/j.neucom.2013.03.003
   Huang L, 2011, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2011.6115661
   Jedynak B, 2003, LECT NOTES COMPUT SC, V2683, P180
   Jiang ZW, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P366, DOI 10.1109/FSKD.2007.518
   Jie Yang, 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P687
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kovac J., 2003, P EUROCON 2003 COMP, P8
   Kruppa H., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P109
   Kukharev G., 2004, Machine Graphics & Vision, V13, P377
   Lee JS, 2007, PATTERN RECOGN, V40, P2261, DOI 10.1016/j.patcog.2006.11.016
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liu Q., J VIS COMMUN IMAGE R, V22
   Nalepa J, 2014, ADV INTEL SOFT COMPU, V242, P79, DOI 10.1007/978-3-319-02309-0_8
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   Schmugge SJ, 2007, J VIS COMMUN IMAGE R, V18, P487, DOI 10.1016/j.jvcir.2007.04.008
   Soriano M., PATTERN RECOGN, V36
   Sun HM, 2010, PATTERN RECOGN, V43, P1413, DOI 10.1016/j.patcog.2009.09.022
   Van C., 2013, DAT COMPR C
   Xiaohua Wang, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P1985
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
NR 36
TC 12
Z9 13
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 147
EP 152
DI 10.1016/j.jvcir.2015.02.004
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100014
DA 2024-07-18
ER

PT J
AU Kristo
   Seng, CC
AF Kristo
   Seng, Chua Chin
TI Cost effective window arrangement for spatial pyramid matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatial pyramid matching; Classification; Recognition; Image
   representation; Overlapping windows; Object recognition; Optimization;
   Optimized spatial window
ID SPARSE
AB In object recognition, Spatial Pyramid Matching (SPM) has been the most popular framework to incorporate spatial information into the bag-of-words model. Dividing each layer of the pyramid into 2(l) x 2(l) spatial windows, SPM extracts histograms from each and concatenate them to create image representation. SPM offers an approximate spatial arrangement to the previously unordered collection of codeword histogram. This paper presents a detailed investigation on the optimality of the traditional SPM model and simultaneously offers a framework to obtain the most optimal spatial window arrangement from the set of possible spatial windows. Using such model, we are able to consistently achieve significant increase in recognition performance, up to 4.38%. With nearly 40% less memory cost, it shows that the traditional spatial window arrangement of SPM is indeed inefficient. We tested our proposed model using 15 Scene, Caltech 101, Caltech 256, MIT-Indoor, UIUC-Sport, and STL-10. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kristo; Seng, Chua Chin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639789, Singapore.
C3 Nanyang Technological University
RP Kristo (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639789, Singapore.
EM kkristo1@e.ntu.edu.sg; ecschua@ntu.edu.sg
CR [Anonymous], MACH VIS APPL MVA P
   [Anonymous], IM PROC ICIP P 20 IE
   [Anonymous], 2008, 2008 2 INT S SYSTEMS
   [Anonymous], 2006, P IEEE C COMPUTER VI
   [Anonymous], 2010, P NIPS
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], COMP VIS ICCV P 9 IE
   [Anonymous], 2012, P 29 INT COFERENCE I
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ergul Emrah, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3603, DOI 10.1109/ICPR.2010.879
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Kong S, 2012, LECT NOTES COMPUT SC, V7572, P186, DOI 10.1007/978-3-642-33718-5_14
   Koniusz P, 2013, COMPUT VIS IMAGE UND, V117, P479, DOI 10.1016/j.cviu.2012.10.010
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li L-J., 2007, COMPUTER VISION ICCV, P1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Quack T., 2007, COMPUTER VISION ICCV, P1
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sohn K, 2011, IEEE I CONF COMP VIS, P2643, DOI 10.1109/ICCV.2011.6126554
   Wang G., 2006, CVPR, P1597
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yan SY, 2012, LECT NOTES COMPUT SC, V7575, P473, DOI 10.1007/978-3-642-33765-9_34
   Yang JC, 2010, LECT NOTES COMPUT SC, V6315, P113, DOI 10.1007/978-3-642-15555-0_9
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435
   Zou W., 2012, ADV NEURAL INFORM PR, V25, P3203, DOI DOI 10.5555/2999325.2999492
NR 35
TC 3
Z9 3
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 79
EP 88
DI 10.1016/j.jvcir.2015.02.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100008
DA 2024-07-18
ER

PT J
AU Zalik, B
   Mongus, D
   Lukac, N
AF Zalik, Borut
   Mongus, Domen
   Lukac, Niko
TI A universal chain code compression method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; 2D shapes; Contours; Chain codes; Compression; Run
   length encoding; Dictionary coding; Data modelling
ID ALGORITHM; REPRESENTATION
AB This paper introduces a new approach for lossless chain code compression. Firstly, the chain codes are converted into the binary stream, independent on the input chain code. Then, the compression is done using three modes: RLE0, LZ77(0) and COPY. RLE0 compresses the runs of the 0-bits, LZ77(0) is a simplified version of LZ77 and handles the repetitions within the bit stream, whilst COPY is an escape mode used, when the other two methods are unsuccessful. This method has been tested on the Freeman chain code in eight and four directions, the Vertex chain code, the Three OrThogonal chain code, and the Normalized angle difference chain code. The experiments confirmed better compression ratios on various benchmark datasets in comparison to the state-of-the-art lossless chain code compression methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zalik, Borut; Mongus, Domen; Lukac, Niko] Univ Maribor, Fac Elect Engn & Comp Sci, SI-2000 Maribor, Slovenia.
C3 University of Maribor
RP Zalik, B (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SI-2000 Maribor, Slovenia.
EM borut.zalik@um.si
RI Lukač, Niko/IVV-5895-2023; Lukač, Niko/B-7524-2014; Žalik,
   Borut/X-1320-2019
OI Lukač, Niko/0000-0002-9517-1157; 
FU Slovenian Research Agency [J2-5479, 1000-13-0552]; European Regional
   Development Fund
FX This work was supported by the Slovenian Research Agency under Grants
   J2-5479 and 1000-13-0552. This paper was produced within the framework
   of the operation entitled Centre of Open innovation and ResEarch UM. The
   operation is co-funded by the European Regional Development Fund and
   conducted within the framework of the Operational Programme for
   Strengthening Regional Development Potentials for the period 2007 2013,
   development priority 1: Competitiveness of companies and research
   excellence, priority axis 1.1: Encouraging competitive potential of
   enterprises and research excellence.
CR Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   Dai XL, 1999, IEEE T GEOSCI REMOTE, V37, P2351, DOI 10.1109/36.789634
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Ge N, 2011, IEEE T PLASMA SCI, V39, P2884, DOI 10.1109/TPS.2011.2159132
   Globacnik T, 2010, PATTERN RECOGN, V43, P4137, DOI 10.1016/j.patcog.2010.07.018
   Gupta RK, 2012, COMPUT AIDED DESIGN, V44, P99, DOI 10.1016/j.cad.2011.09.012
   Hampel H., 1992, Signal Processing: Image Communication, V4, P103, DOI 10.1016/0923-5965(92)90017-A
   Jain J., 2012, ADV COMPUTER SCI INF, P611
   Lemus E, 2014, PATTERN RECOGN, V47, P1721, DOI 10.1016/j.patcog.2013.11.002
   Li K, 2013, PETROL SCI, V10, P347, DOI 10.1007/s12182-013-0283-4
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Liu YK, 2012, SIGNAL PROCESS-IMAGE, V27, P973, DOI 10.1016/j.image.2012.07.008
   Nunes P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P114, DOI 10.1109/ICIP.1997.632008
   Ren M, 2009, T GIS, V13, P197, DOI 10.1111/j.1467-9671.2009.01147.x
   Sánchez-Cruz H, 2005, OPT ENG, V44, DOI 10.1117/1.2052793
   Sanchez-Cruz Hermilo, 2008, Proceedings of the Tenth IASTED International Conference on Computer Graphics and Imaging, P6
   Sanchez-Cruz H., 2014, J ELECTRON IMAGING, V23, P13
   Sánchez-Cruz H, 2009, LECT NOTES COMPUT SC, V5856, P45, DOI 10.1007/978-3-642-10268-4_5
   Sanchez-Cruz H, 2010, J VIS COMMUN IMAGE R, V21, P311, DOI 10.1016/j.jvcir.2010.02.002
   Sun H, 2005, PATTERN RECOGN LETT, V26, P1266, DOI 10.1016/j.patrec.2004.11.007
   Wang CQ, 2012, APPL SOFT COMPUT, V12, P423, DOI 10.1016/j.asoc.2011.08.028
   Zalik B, 2014, SIGNAL PROCESS-IMAGE, V29, P96, DOI 10.1016/j.image.2013.09.002
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 24
TC 11
Z9 15
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 8
EP 15
DI 10.1016/j.jvcir.2015.01.013
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100002
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Chang, J
   Hu, RM
   Zhong, R
AF Wang, Zhongyuan
   Chang, Jun
   Hu, Ruimin
   Zhong, Rui
TI Generating algorithm for integer DST radixes in video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.265; Integer transform; Integer DST; Transform radix; Video coding;
   Intra coding; Type-7 DST; Chinese AVS2
AB Recently released H.265 is the new generation video coding standard established by ITU and ISO jointly. H.265 is the first to apply discrete sine transform (DST) to transform unit in intra prediction block, with it implemented in an integer transform approach. Given that the integer transform radixes of DST are not unique, it is a key task to seek for them possessing strong de-correlation capability and simple arithmetic calculation as well. This paper presents a generic generating algorithm for integer DST transform radixes through a deep insight into the principle of integer DST transform. Subject to three essential constraints on integer transform matrix, this method establishes a cost function comprising orthogonality metric and accuracy metric with respect to entries of a 4 x 4 matrix, and then seeks transform radixes via a heuristic search strategy. Experimental results show that our method can find out a set of DST radixes after dozens of search steps. The revealed DST radixes not only cover the one used by H.265 but also include a basis superior over H.265's in terms of orthogonality and precision. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Zhongyuan; Hu, Ruimin; Zhong, Rui] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Wang, Zhongyuan; Chang, Jun; Hu, Ruimin; Zhong, Rui] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University
RP Wang, ZY (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
EM wzy_hope@163.com; changmy0@163.com; hrm1964@163.com;
   zhongrui0824@126.com
RI Wang, Zhongyuan/ABD-2189-2020; zhong, rui/HSZ-2549-2023
FU National Natural Science Foundation of China [61070080, 61172173,
   61231015 3D, 61170023, 61302111, U1404618]; Major National Science and
   Technology Special Project [2010ZX03004-003-03]; Fundamental Research
   Funds for the Central Universities [2042014kf0286, 2042014kf0212,
   2042014kf0025, 2042014kf0250]
FX The research was supported by the National Natural Science Foundation of
   China (61070080, 61172173, 61231015 3D, 61170023, 61302111, U1404618),
   the Major National Science and Technology Special Project
   (2010ZX03004-003-03) and the Fundamental Research Funds for the Central
   Universities (2042014kf0286, 2042014kf0212, 2042014kf0025,
   2042014kf0250).
CR [Anonymous], [No title captured]
   AVS Proposal, 2012, N1924 AVS
   Han JN, 2010, INT CONF ACOUST SPEE, P726, DOI 10.1109/ICASSP.2010.5495043
   Saxena A., 2010, JCTVCC108 ITUT
   Saxena A., 2011, JCTVCE125
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Saxena A, 2011, IEEE IMAGE PROC, P1685, DOI 10.1109/ICIP.2011.6115780
NR 7
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1918
EP 1921
DI 10.1016/j.jvcir.2014.08.008
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300011
DA 2024-07-18
ER

PT J
AU Semsarzadeh, M
   Hashemi, MR
   Shirmohammadi, S
AF Semsarzadeh, Mehdi
   Hashemi, Mahmoud Reza
   Shirmohammadi, Shervin
TI A generic, comprehensive and granular decoder complexity model for the
   H.264/AVC standard
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Decoder complexity modeling; H.264/AVC decoder; Receiver aware encoding;
   Power consumption; Video streaming; Power adjustment; Resource
   allocation; Video compression algorithms
ID DISTORTION OPTIMIZATION; MOTION ESTIMATION; COMPUTATIONAL-COMPLEXITY;
   POWER; ENCODER; ALGORITHM; DESIGN
AB With recent advances in computing and communication technologies, ubiquitous access to high quality multimedia content such as high definition video using smartphones, netbooks, or tablets is a fact of our daily life. However, power consumption is still a major concern for portable devices. One approach to address this concern is to control and optimize power consumption using a power model for each multimedia application, such as a video decoder. In this paper, a generic, comprehensive and granular decoder complexity model for the baseline profile of H.264/AVC decoder has been proposed. The modeling methodology was designed to ensure a platform and implementation independent complexity model. Simulation results indicate that the proposed model estimates decoder complexity with an average accuracy of 92.15% for a wide range of test sequences using both the JM reference software and the x264 software implementation of H.264/AVC, and 89.61% for a dedicated hardware implementation of the motion compensation module. It should be noted that in addition to power consumption control, the proposed model can be used for designing a receiver-aware H.264/AVC encoder, where the complexity constraints of the receiver side are taken into account during compression. To further evaluate the proposed model, a receiver-aware encoder has been designed and implemented. Our simulation results indicate that using the proposed model the designed receiver aware encoder performs similar to the original encoder, while still being able to satisfy the complexity constraints of various decoders. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Semsarzadeh, Mehdi; Hashemi, Mahmoud Reza; Shirmohammadi, Shervin] Univ Tehran, Sch Elect & Comp Engn, Multimedia Proc Lab, Tehran, Iran.
   [Semsarzadeh, Mehdi; Shirmohammadi, Shervin] Univ Ottawa, Sch Elect Engn & Comp Sci, Distributed Collaborat Virtual Environm Res Lab, Ottawa, ON K1N 6N5, Canada.
C3 University of Tehran; University of Ottawa
RP Hashemi, MR (corresponding author), Univ Tehran, Sch Elect & Comp Engn, Multimedia Proc Lab, Tehran, Iran.
EM m.semsar@ece.ut.ac.ir; rhashemi@ut.ac.ir; sshirmohammadi@ut.ac.ir
RI Shirmohammadi, Shervin/E-6945-2012; Hashemi, Mahmoud Reza/H-2172-2011
OI Shirmohammadi, Shervin/0000-0002-3973-4445; Hashemi, Mahmoud
   Reza/0000-0002-3518-9195
CR [Anonymous], X264 REFERENCE SOFTW
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], ADV VIDEO CODING GEN
   [Anonymous], INT VTUNE PERF AN VE
   [Anonymous], P SPIE
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], H 264 AVC JM REFEREN
   Bjntegaard G., 2001, ITU-T SG16/Q6, VCEG-M33
   Burd TD, 1996, J VLSI SIG PROC SYST, V13, P203, DOI 10.1007/BF01130406
   Chen YW, 2008, J VIS COMMUN IMAGE R, V19, P256, DOI 10.1016/j.jvcir.2008.01.002
   Chen YH, 2009, IEEE T CIRC SYST VID, V19, P1118, DOI 10.1109/TCSVT.2009.2020323
   Chien MC, 2012, IET IMAGE PROCESS, V6, P60, DOI 10.1049/iet-ipr.2010.0149
   Chiu MY, 2010, IEEE T CONSUM ELECTR, V56, P895, DOI 10.1109/TCE.2010.5506017
   Gao XJ, 2010, SIGNAL PROCESS, V90, P2468, DOI 10.1016/j.sigpro.2010.01.029
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   Hu Y, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P1949, DOI 10.1109/ICME.2006.262939
   Ji W, 2012, FUTURE GENER COMP SY, V28, P427, DOI 10.1016/j.future.2011.04.002
   Ji W, 2011, J NETW COMPUT APPL, V34, P1489, DOI 10.1016/j.jnca.2010.06.011
   Jin X, 2011, SIGNAL PROCESS-IMAGE, V26, P130, DOI 10.1016/j.image.2011.01.002
   Kaminsky E, 2008, J VIS COMMUN IMAGE R, V19, P56, DOI 10.1016/j.jvcir.2007.05.002
   Kang LW, 2012, J VIS COMMUN IMAGE R, V23, P569, DOI 10.1016/j.jvcir.2012.02.001
   Kannangara CS, 2008, IEEE T CIRC SYST VID, V18, P1191, DOI 10.1109/TCSVT.2008.928881
   Kim Jong-In., 2011, 2011 IEEE Custom Integrated Circuits Conference (CICC), P1
   Kim J, 2010, IEEE INT CON MULTI, P7, DOI 10.1109/ICME.2010.5583856
   Kim W, 2010, IEEE T CONSUM ELECTR, V56, P1137, DOI 10.1109/TCE.2010.5506050
   Kontorinis N, 2009, IEEE T CIRC SYST VID, V19, P1000, DOI 10.1109/TCSVT.2009.2020256
   Lee H., 2009, IEEE INT WORKSHOP MU, P1
   Lee SW, 2011, J VIS COMMUN IMAGE R, V22, P557, DOI 10.1016/j.jvcir.2011.03.004
   Lee SW, 2011, J VIS COMMUN IMAGE R, V22, P61, DOI 10.1016/j.jvcir.2010.10.004
   Lee SW, 2010, IEEE T CIRC SYST VID, V20, P706, DOI 10.1109/TCSVT.2010.2045913
   Li X, 2011, IEEE T CIRC SYST VID, V21, P957, DOI 10.1109/TCSVT.2011.2133750
   Liang YF, 2009, IEEE T CIRC SYST VID, V19, P1436, DOI 10.1109/TCSVT.2009.2026810
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Ma Z, 2011, IEEE T MULTIMEDIA, V13, P1240, DOI 10.1109/TMM.2011.2165056
   Ma Z, 2008, IEEE IMAGE PROC, P2784, DOI 10.1109/ICIP.2008.4712372
   Nam HM, 2010, IEEE T CONSUM ELECTR, V56, P1025, DOI 10.1109/TCE.2010.5506035
   Pu W, 2006, IEEE ICC, P441
   Rhee CE, 2010, IEEE T CIRC SYST VID, V20, P1848, DOI 10.1109/TCSVT.2010.2087834
   Semsarzadeh M., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P925, DOI 10.1109/ICME.2012.91
   Semsarzadeh M, 2013, SIGNAL PROCESS-IMAGE, V28, P441, DOI 10.1016/j.image.2013.02.003
   Su L, 2009, IEEE T CIRC SYST VID, V19, P477, DOI 10.1109/TCSVT.2009.2014017
   Tan YH, 2009, IEEE IMAGE PROC, P3397, DOI 10.1109/ICIP.2009.5413872
   Tan YH, 2010, IEEE T CIRC SYST VID, V20, P1271, DOI 10.1109/TCSVT.2010.2058480
   van der Schaar M, 2005, IEEE T MULTIMEDIA, V7, P471, DOI 10.1109/TMM.2005.846790
   Vanam R, 2007, IEEE DATA COMPR CONF, P303
   Vanam R, 2008, IEEE DATA COMPR CONF, P372, DOI 10.1109/DCC.2009.53
   Wiegand T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958171
   Xiang Li, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P214, DOI 10.1109/PCS.2010.5702467
NR 49
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1686
EP 1703
DI 10.1016/j.jvcir.2014.07.008
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100018
DA 2024-07-18
ER

PT J
AU Chuang, CH
   Cheng, SC
   Chang, CC
   Chen, YPP
AF Chuang, Chi-Han
   Cheng, Shyi-Chyi
   Chang, Chin-Chun
   Chen, Yi-Ping Phoebe
TI Model-based approach to spatial-temporal sampling of video clips for
   video object detection by classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic video objects; Spatial-temporal sampling; Human action
   detection; Video object model; Dynamic programming; Multiple alignment;
   Model-based tracking; Video object detetcion
ID RECOGNITION; FRAMEWORK
AB For a variety of applications such as video surveillance and event annotation, the spatial-temporal boundaries between video objects are required for annotating visual content with high-level semantics. In this paper, we define spatial-temporal sampling as a unified process of extracting video objects and computing their spatial-temporal boundaries using a learnt video object model. We first :provide a computational approach for learning an optimal key-object codebook sequence from a set of training video clips to characterize the semantics of the detected video objects. Then, dynamic programming with the learnt codebook sequence is used to locate the video objects with spatial-temporal boundaries in a test video clip. To verify the performance of the proposed method, a human action detection and recognition system is constructed. Experimental results show that the proposed method gives good performance on several publicly available datasets in terms of detection accuracy and recognition rate. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Chuang, Chi-Han; Cheng, Shyi-Chyi; Chang, Chin-Chun] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
   [Chen, Yi-Ping Phoebe] La Trobe Univ, Dept Comp Sci & Comp Engn, Bundoora, Vic 3086, Australia.
C3 National Taiwan Ocean University; La Trobe University
RP Cheng, SC (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Pei Ning Rd, Keelung 202, Taiwan.
EM csc@mail.ntou.edu.tw; phoebe.chen@latrobe.edu.au
RI Cataldi, Antonio/AAM-7411-2021; Chen, Yi-Ping Phoebe/B-8844-2008
OI Chen, Yi-Ping Phoebe/0000-0002-4122-3767
FU National Science Council Taiwan [NSC 100-2221-E-019-054-MY3,
   101-2918-1-019-003]
FX This work was supported in part by National Science Council Taiwan under
   Grant Nos. NSC 100-2221-E-019-054-MY3 and 101-2918-1-019-003.
CR Ali K., 2011, P IEEE C COMP VIS PA
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], P 18 INT C MULT FIR
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2007, P ACM INT C MULT
   [Anonymous], P 20 BRIT MACH VIS C
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Blaschko M., 2010, P INT C NEUR INF PRO
   BOSER BE, 1992, P ACM INT WORKSH COM
   Brendel W., 2009, P INT C COMP VIS ICC
   Brox T., 2010, P EUR C COMP VIS ECC
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Changsheng Xu, 2009, Journal of Multimedia, V4, P69
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jungling K., 2011, P INT C IM PROC COMP
   Kalal Y., 2010, P IEEE C COMP VIS PA
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Lee Y. J., 2011, P IEEE C COMP VIS PA
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Liu J., 2009, IEEE COMPUT VISION P
   Liu TC, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230813
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Nicolescu M, 2005, IEEE T PATTERN ANAL, V27, P739, DOI 10.1109/TPAMI.2005.91
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oikonomopoulos A., 2009, P IEEE C COMP VIS PA
   Ommer B, 2009, INT J COMPUT VISION, V83, P57, DOI 10.1007/s11263-009-0211-7
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prest A., 2012, P IEEE C COMP VIS PA
   Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Schindler K, 2008, PROC CVPR IEEE, P3025
   Shang LM, 2007, IEEE T PATTERN ANAL, V29, P976, DOI 10.1109/TPAMI.2007.1088
   Shawe-Taylor John, 2004, KERNEL METHODS PATTE
   Teodosio L, 2005, ACM T MULTIM COMPUT, V1, P16, DOI 10.1145/1047936.1047940
   Tsai W.-H., 1984, COMPUT VIS GRAPH IMA, V19, P377
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Vijayanarasimhan S., 2011, P IEEE C COMP VIS
   Wang L, 1994, J Comput Biol, V1, P337, DOI 10.1089/cmb.1994.1.337
   Wu X., 2011, P IEEE C COMP VIS PA
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zhang Ya-Ping, 2010, Zoological Research, V31, P1
NR 52
TC 10
Z9 10
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1018
EP 1030
DI 10.1016/j.jvcir.2014.02.014
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200029
DA 2024-07-18
ER

PT J
AU Chattopadhyay, P
   Roy, A
   Sural, S
   Mukhopadhyay, J
AF Chattopadhyay, Pratik
   Roy, Aditi
   Sural, Shamik
   Mukhopadhyay, Jayanta
TI Pose Depth Volume extraction from RGB-D streams for frontal gait
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Frontal gait recognition; Microsoft Kinect; Depth registered silhouette;
   Pose Depth Volume; RGB-D stream; Silhouette; Voxel volume; Key pose
AB We explore the applicability of Kinect RGB-D streams in recognizing gait patterns of individuals. Gait energy volume (GEV) is a recently proposed feature that performs gait recognition in frontal view using only depth image frames from Kinect. Since depth frames from Kinect are inherently noisy, corresponding silhouette shapes are inaccurate, often merging with the background. We register the depth and RGB frames from Kinect to obtain smooth silhouette shape along with depth information. A partial volume reconstruction of the frontal surface of each silhouette is done and a novel feature termed as Pose Depth Volume (PDV) is derived from this volumetric model. Recognition performance of the proposed approach has been tested on a data set captured using Microsoft Kinect in an indoor environment. Experimental results clearly demonstrate the effectiveness of the approach in comparison with other existing methods. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chattopadhyay, Pratik; Roy, Aditi; Sural, Shamik; Mukhopadhyay, Jayanta] Indian Inst Technol, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Chattopadhyay, P (corresponding author), Indian Inst Technol, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
EM pratikc@sit.iitkgp.ernet.in; aditi.roy@sit.iitkgp.ernet.in;
   shamik@cse.iitkgp.ernet.in; jay@cse.iitkgp.ernet.in
OI Sural, Shamik/0000-0002-4315-7329
FU Council of Scientific and Industrial Research, Govt. of India
   [22(0554)/11/EMR-II]
FX This work is partially funded by project Grant No. 22(0554)/11/EMR-II
   sponsored by the Council of Scientific and Industrial Research, Govt. of
   India. The authors thank the anonymous reviewers for their constructive
   suggestions.
CR [Anonymous], 2001, Cmu Ri Tr 01-18
   Ariyanto G., 2011, INT JOINT C BIOM, P11
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Jegoon Ryu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3209, DOI 10.1109/ICIP.2011.6116351
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Lee S., 2007, Celebrity Fandom and its Relationship to Tourism and Leisure Behaviors: The Case of Korean Wave, Texas AM Repository, P1
   Liu JY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P663
   Ma QY, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 2, PROCEEDINGS, P606, DOI 10.1109/SNPD.2007.307
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 22
TC 50
Z9 53
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 53
EP 63
DI 10.1016/j.jvcir.2013.02.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900006
DA 2024-07-18
ER

PT J
AU Li, W
   Zhang, J
   Dai, QH
AF Li, Wen
   Zhang, Jun
   Dai, Qiong-hai
TI Robust blind motion deblurring using near-infrared flash image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion blur; NIR-flash; Multispectral image; Gradient constraint;
   Uniform deblurring; Projective blur model; Non-uniform deblurring; Flash
   artifacts detection
ID DECONVOLUTION; ALGORITHM; CAMERA
AB In light-limited situations, camera motion blur is one of the prime causes for poor image quality. Recovering the blur kernel and latent image from the blurred observation is an inherently ill-posed problem. In this paper, we introduce a hand-held multispectral camera to capture a pair of blurred image and Near-InfraRed (NIR) flash image simultaneously and analyze the correlation between the pair of images. To utilize the high-frequency details of the scene captured by the NIR-flash image, we exploit the NIR gradient constraint as a new type of image regularization, and integrate it into a Maximum-A-Posteriori (MAP) problem to iteratively perform the kernel estimation and image restoration. We demonstrate our method on the synthetic and real images with both spatially invariant and spatially varying blur. The experiments strongly support the effectiveness of our method to provide both accurate kernel estimation and superior latent image with more details and fewer ringing artifacts. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Li, Wen; Zhang, Jun] Beihang Univ, Sch Elect & Informat Engn, Natl Key Lab CNS ATM, Beijing 100191, Peoples R China.
   [Dai, Qiong-hai] Tsinghua Univ, TNList, Beijing 100084, Peoples R China.
   [Dai, Qiong-hai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
C3 Beihang University; Tsinghua University; Tsinghua University
RP Li, W (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Natl Key Lab CNS ATM, Beijing 100191, Peoples R China.
EM tina_lee@ee.buaa.edu.cn; buaazhangjun@vip.sina.com;
   qhdai@tsinghua.edu.cn
RI Dai, Qionghai/ABD-5298-2021
OI Dai, Qionghai/0000-0001-7043-3061
FU National Basic Research Program of China [2010CB731800]; Foundation for
   Innovative Research Groups of the National Natural Science Foundation of
   China [60921001]; NSFC [61120106003]
FX This research is supported by the National Basic Research Program of
   China (Grant No. 2010CB731800), the Foundation for Innovative Research
   Groups of the National Natural Science Foundation of China (Grant No.
   60921001), and the Key Project of NSFC (No. 61120106003).
CR [Anonymous], P DIG PHOT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2010, NIPS
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], SID INT S
   [Anonymous], 165527 EPFL
   [Anonymous], 2007, P IEEE C COMP VIS PA
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Cai JF, 2009, PROC CVPR IEEE, P1566, DOI 10.1109/CVPRW.2009.5206711
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Chen J, 2008, LECT NOTES COMPUT SC, V5018, P1, DOI 10.1007/978-3-540-79723-4_1
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   diaeresis>sstrunk Sabine Su<spacing, 2010, P INT C MULT OCT, P1693, DOI DOI 10.1145/1873951.1874324
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fredembach C., 2008, COL IM C, P176
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13
   Hirsch Marianne., 2011, INTRO RITES RETURN D, P1
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731050
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Lee JH, 2011, J VIS COMMUN IMAGE R, V22, P653, DOI 10.1016/j.jvcir.2011.07.010
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Matsui Sosuke, 2010, IPSJ Transactions on Computer Vision and Applications, V2, P215, DOI 10.2197/ipsjtcva.2.215
   Money JH, 2008, IMAGE VISION COMPUT, V26, P302, DOI 10.1016/j.imavis.2007.06.005
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Salamati N, 2009, SEVENTEENTH COLOR IMAGING CONFERENCE - COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P216
   Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shor Y, 2008, COMPUT GRAPH FORUM, V27, P577, DOI 10.1111/j.1467-8659.2008.01155.x
   Simon M.K., 2006, Probability Distributions Involving Gaussian Random Variables: A Handbook for Engineers and Scientists
   Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222
   Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wiener N., 1964, Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Yuan L., 2007, P IEEE INT C BIOMETR, P1
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673
   Zhang X, 2008, IEEE C COMPUTER VISI, P1
   Zhuo SJ, 2010, IEEE IMAGE PROC, P2537, DOI 10.1109/ICIP.2010.5652900
   Zhuo SJ, 2010, PROC CVPR IEEE, P2440, DOI 10.1109/CVPR.2010.5539941
NR 50
TC 20
Z9 20
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1394
EP 1413
DI 10.1016/j.jvcir.2013.09.008
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700015
DA 2024-07-18
ER

PT J
AU Hu, KT
   Leou, JJ
   Hsiao, HH
AF Hu, Kang-Ting
   Leou, Jin-Jang
   Hsiao, Han-Hui
TI Spatiotemporal saliency detection and salient region determination for
   H.264 videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatial saliency; Temporal saliency; Phase spectrum of Fourier
   transform; Spatiotemporal saliency detection; Salient region
   determination; Gaussian filtering; Adaptive fusion; H.264 video
ID VISUAL-ATTENTION; MODEL; FRAMEWORK; COLOR; IMAGE
AB In this study, a spatiotemporal saliency detection and salient region determination approach for H.264 videos is proposed. After Gaussian filtering in Lab color space, the phase spectrum of Fourier transform is used to generate the spatial saliency map of each video frame. On the other hand, the motion vector fields from each H.264 compressed video bitstream are backward accumulated. After normalization and global motion compensation, the phase spectrum of Fourier transform for the moving parts is used to generate the temporal saliency map of each video frame. Then, the spatial and temporal saliency maps of each video frame are combined to obtain its spatiotemporal saliency map using adaptive fusion. Finally, a modified salient region determination scheme is used to determine salient regions (SRs) of each video frame. Based on the experimental results obtained in this study, the performance of the proposed approach is better than those of two comparison approaches. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hu, Kang-Ting; Leou, Jin-Jang; Hsiao, Han-Hui] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM hwc97m@cs.ccu.edu.tw; jjleou@cs.ccu.edu.tw; hhh95p@cs.ccu.edu.tw
FU National Science Council, Taiwan, Republic of China [NSC
   99-2221-E-194-032-MY3, NSC 101-2221-E-194-031]
FX This work was supported in part by National Science Council, Taiwan,
   Republic of China under Grants NSC 99-2221-E-194-032-MY3 and NSC
   101-2221-E-194-031.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], P INT C PATT REC
   [Anonymous], 2008, PROC INT CONF PATTER
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Chen DY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1085, DOI 10.1109/ICME.2008.4607627
   Chen HY, 2012, J VIS COMMUN IMAGE R, V23, P343, DOI 10.1016/j.jvcir.2011.11.006
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Cheng WH, 2005, IEICE T INF SYST, VE88D, P1578, DOI 10.1093/ietisy/e88-d.7.1578
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hasan MA, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P2044
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jing Zhang, 2008, 2008 International Conference on Neural Networks and Signal Processing, P375, DOI 10.1109/ICNNSP.2008.4590375
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Laptev I, 2003, LECT NOTES COMPUT SC, V2695, P372
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li S, 2007, INT CONF ACOUST SPEE, P1073
   Li S, 2007, IEEE T CIRC SYST VID, V17, P1383, DOI 10.1109/TCSVT.2007.903798
   Li Tan, 2008, 2008 Third International Conference on Pervasive Computing and Applications (ICPCA08), P692, DOI 10.1109/ICPCA.2008.4783698
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Z, 2007, J VIS COMMUN IMAGE R, V18, P275, DOI 10.1016/j.jvcir.2007.02.002
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Ma YF, 2002, IEEE IMAGE PROC, P129
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Qiu GP, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1806
   Rapantzikos K, 2007, IET IMAGE PROCESS, V1, P237, DOI 10.1049/iet-ipr:20060040
   Rath GB, 1999, IEEE T CIRC SYST VID, V9, P1075, DOI 10.1109/76.795060
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sonka M., 2008, IMAGE PROCESSING ANA
   Su YB, 2005, IEEE T CIRC SYST VID, V15, P232, DOI 10.1109/TCSVT.2004.841656
   Sun XS, 2013, J VIS COMMUN IMAGE R, V24, P171, DOI 10.1016/j.jvcir.2012.01.014
   Vizireanu N, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3452321
   Vizireanu N, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3134142
   Wang Y, 2008, CELL POLYM, V27, P1
   Wei-Song Lin, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P1250, DOI 10.1109/ICIEA.2009.5138402
   Wu HS, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866185
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P1158, DOI 10.1016/j.jvcir.2012.07.010
   Yang KC, 2006, IEEE INT SYM MULTIM, P525
   Yu Y., 2009, P IEEE INT C DEV LEA, P1
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang QR, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P1100, DOI 10.1109/IITA.2008.372
   Zhao ZC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P198
NR 48
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 760
EP 772
DI 10.1016/j.jvcir.2013.05.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700003
DA 2024-07-18
ER

PT J
AU Wu, QB
   Xu, LF
   Zeng, LY
   Xiong, J
AF Wu, Qingbo
   Xu, Linfeng
   Zeng, Liaoyuan
   Xiong, Jian
TI Mode dependent loop filter for intra prediction coding in H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Loop filter; Wiener filter; Artifact; H.264/AVC;
   Deblocking filter; Intra prediction mode; Texture combination
ID EDGE CLASSIFICATION; VIDEO; ALGORITHM
AB In this paper, a high performance and low complexity loop filter is proposed for intra prediction coding. Although the deblocking loop filter (DLF) has achieved outstanding performance on suppressing quantization noise, it also induces details information loss because of the smoothing operation. To achieve better restoration performance, we propose a filter set named mode dependent loop filter (MDLF) which adaptively select the filter coefficients according to various local characteristics. In the homogeneous areas, the task of the filter emphasizes on smoothing the noise. In the heterogeneous areas, the proposed filter concentrates on preserving the details. Based on the spatial correlation assumption and statistical analysis, the intra mode combination is used to classify the training samples with different local characteristics. Then the classical least mean square error framework is employed to solve the coefficients for the proposed filter set. In this way, a more efficient adaptive loop filter scheme can be achieved for specific intra mode combination. Experiment results show that the proposed loop filter achieves superior coding gains compared to the H.264/AVC High Profile. Furthermore, relative to QALF+DLF, a comparable performance also can be achieved by the proposed MDLF with far less complexity increase. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wu, Qingbo; Xu, Linfeng; Zeng, Liaoyuan; Xiong, Jian] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Wu, QB (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM wqb.uestc@gmail.com; lfxu@uestc.edu.cn; lyzeng@uestc.edu.cn;
   jxiong86@yahoo.cn
RI Wu, Qingbo/AAF-6872-2019; Xu, Linfeng/HME-1913-2023; Wu,
   Qingbo/M-5065-2015
OI Wu, Qingbo/0000-0003-2936-6340; Xu, Linfeng/0000-0002-9934-0958; Xiong,
   Jian/0000-0002-8346-178X
FU National Natural Science Foundation of China [61179060]; National High
   Technology Research and Development Program of China (863 Program)
   [2012AA011503]; Fundamental Research Funds for the Central Universities
   [ZYGX2012YB007, ZYGX2012J019]
FX This work was partially supported by National Natural Science Foundation
   of China (No. 61179060), National High Technology Research and
   Development Program of China (863 Program, No. 2012AA011503) and the
   Fundamental Research Funds for the Central Universities (ZYGX2012YB007
   and ZYGX2012J019).
CR [Anonymous], 2012, HEVC SOFTWARE REPOSI
   [Anonymous], 2005, ITU T REC H 264 ISO
   [Anonymous], 1999, 144962 ISOIEC
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Chatterjee S., 2006, Regression Analysis by Example, V4th, P317
   Chen Q., 2011, VEHICULAR TECHNOLOGY, P1
   Chujoh T., 2009, QUADTREE BASED ADAPT
   Chujoh T., 2008, ITU T SG16 CONTRIB C
   ITU-T, 1995, ITU T VID COD LOW BI
   Itu-T, 2011, VCEG KTA REF SOFTW
   ITU-T and ISO/IEC JTC 1, 1994, ITU T ISO IEC JTC 1
   Joint Collaborative Team on Video Coding, 2012, HIGH EFF VID COD HEV
   Li HL, 2004, IEEE T MULTIMEDIA, V6, P624, DOI [10.1109/TMM.2004.830812, 10.1109/tmm.2004.830812]
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2008, IEEE T CIRC SYST VID, V18, P756, DOI 10.1109/TCSVT.2008.918778
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu Y, 2010, IEEE T CIRC SYST VID, V20, P1378, DOI 10.1109/TCSVT.2010.2077570
   Narroschke M., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P314, DOI 10.1109/PCS.2010.5702496
   Pan F, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1147, DOI 10.1109/ICME.2004.1394420
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tan T.K., 2007, VCEG AE010 RECOMMEND
   Watanabe T, 2009, IEEE IMAGE PROC, P1013, DOI 10.1109/ICIP.2009.5413819
   Wei ZY, 2008, SIGNAL PROCESS-IMAGE, V23, P699, DOI 10.1016/j.image.2008.08.002
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zhang XF, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P437, DOI 10.1109/PCS.2012.6213380
NR 29
TC 0
Z9 0
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 988
EP 1001
DI 10.1016/j.jvcir.2013.06.016
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700023
DA 2024-07-18
ER

PT J
AU Park, SU
   Lee, YY
   Kim, CS
   Lee, SU
AF Park, Sang-Uk
   Lee, Young-Yoon
   Kim, Chang-Su
   Lee, Sang-Uk
TI CDV-DVC: Transform-domain distributed video coding with multiple channel
   division
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding; Wyner-Ziv coding; Side information generation;
   Motion-compensated frame interpolation; Channel division; Hierarchical
   motion estimation; Key frame-based estimate; Syndrome-based estimate
ID SIDE INFORMATION; PRISM
AB This paper proposes an efficient distributed coding system based on multiple channel division. We develop the hierarchical motion refinement scheme using DC syndrome bits to generate high quality side information (SI) for Wyner-Ziv (WZ) frames. Moreover, we estimate local distortion characteristics of an SI frame and encode the SI frame in three coding modes: skip mode for the reliable channel, WZ mode for the medium channel, and intra mode for the unreliable channel. No bit is transmitted in the skip mode. Syndrome bits in the WZ mode are adaptively allocated based on the local distortion characteristics. The H.264 intra coding is performed in the intra mode to recover severely erroneous blocks. Experimental results show that the proposed algorithm provides significantly better rate-distortion performance than the state-of-the-art DISCOVER codec. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Park, Sang-Uk; Lee, Sang-Uk] Seoul Natl Univ, Sch Elect Engn, Seoul, South Korea.
   [Park, Sang-Uk; Lee, Sang-Uk] Seoul Natl Univ, INMC, Seoul, South Korea.
   [Lee, Young-Yoon] Samsung Elect Co Ltd, Multimedia Platform Lab, Suwon, South Korea.
   [Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU);
   Samsung; Samsung Electronics; Korea University
RP Lee, YY (corresponding author), Samsung Elect Co Ltd, Multimedia Platform Lab, Suwon, South Korea.
EM supark05@snu.ac.kr; yy77lee@gmail.com; changsukim@korea.ac.kr;
   sanguk@snu.ac.kr
RI lee, Young Yoon/AAJ-2933-2020
OI Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [593 2012-0005410, NRF-M1AXA003-2011-0031648]; Global Frontier R&D
   Program on Human-centered Interaction for Coexistence; NRF of Korea
FX This work was supported partly by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MEST) (No. 593
   2012-0005410) and partly by the Global Frontier R&D Program on
   Human-centered Interaction for Coexistence, funded by the NRF of Korea
   grant funded by the Korean Government (MEST)
   (NRF-M1AXA003-2011-0031648).
CR Aaron A, 2004, IEEE IMAGE PROC, P3097
   Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Aaron A, 2002, CONF REC ASILOMAR C, P240
   Adikari ABB, 2006, IEEE IMAGE PROC, P597, DOI 10.1109/ICIP.2006.312406
   Alparone L, 1996, INT CONF ACOUST SPEE, P2267, DOI 10.1109/ICASSP.1996.545874
   [Anonymous], 2009, IEEE P PCS
   Artigas J.A.X., 2007, P IEEE INT C AC SPEE, P83
   Ascenso Joao, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P29
   Ascenso J., 2005, P EURASIP C SPEECH I, P856
   Bernardini R, 2006, IEEE IMAGE PROC, P245, DOI 10.1109/ICIP.2006.313171
   Chien WJ, 2009, IET IMAGE PROCESS, V3, P340, DOI 10.1049/iet-ipr.2008.0207
   Chien W.J., 2008, P IEEE INT C IM PROC, P597
   Chien WJ, 2009, IEEE IMAGE PROC, P1417, DOI 10.1109/ICIP.2009.5414621
   Du BG, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P9, DOI 10.1109/MUE.2009.12
   Feng Y., 2006, P PICT COD S PCS, P3458
   Gastpar M, 2003, IEEE DATA COMPR CONF, P283
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Hua GG, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P777, DOI 10.1109/ICME.2008.4607550
   Li Z, 2007, IEEE T IMAGE PROCESS, V16, P98, DOI 10.1109/TIP.2006.884934
   Martinez JL, 2008, IEEE IMAGE PROC, P1140, DOI 10.1109/ICIP.2008.4711961
   Martins R, 2010, IET IMAGE PROCESS, V4, P28, DOI 10.1049/iet-ipr.2008.0133
   Maugey T., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P298, DOI 10.1109/MMSP.2010.5662036
   Moon TK, 2005, ERROR CORRECTION CODING: MATHEMATICAL METHODS AND ALGORITHMS
   Morbee M., 2007, P IEEE INT C AC SPEE, P13
   Mys S, 2009, SIGNAL PROCESS-IMAGE, V24, P200, DOI 10.1016/j.image.2008.12.004
   Park SU, 2009, IEEE IMAGE PROC, P1401, DOI 10.1109/ICIP.2009.5414625
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P626, DOI 10.1109/TIT.2002.808103
   Puri R, 2003, INT CONF ACOUST SPEE, P856
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Sheinin V, 2007, INT CONF ACOUST SPEE, P513
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2012, IEEE T CIRC SYST VID, V22, P1014, DOI 10.1109/TCSVT.2012.2189669
   Slowack J, 2010, SIGNAL PROCESS-IMAGE, V25, P660, DOI 10.1016/j.image.2010.06.002
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wang AH, 2008, IEICE ELECTRON EXPR, V5, P650, DOI 10.1587/elex.5.650
   Wang DM, 2005, IEEE T CIRC SYST VID, V15, P1019, DOI 10.1109/TCSVT.2005.852414
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Woods J. W., 2006, MULTIDIMENSIONAL SIG
   Wu B., 2008, P IEEE INT S CIRC SY, P401
   Wu B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P165, DOI 10.1109/ICME.2006.262595
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   WYNER AD, 1975, IEEE T INFORM THEORY, V21, P294, DOI 10.1109/TIT.1975.1055374
   WYNER AD, 1974, IEEE T INFORM THEORY, V20, P2, DOI 10.1109/TIT.1974.1055171
NR 43
TC 0
Z9 0
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 534
EP 543
DI 10.1016/j.jvcir.2013.03.016
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900003
DA 2024-07-18
ER

PT J
AU Lee, KH
   Chung, PC
AF Lee, Kuan-Hui
   Chung, Pau-Choo
TI An attention emphasized bit arrangement in 3-D SPIHT video coding for
   human vision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video compression; 3-D SPIHT; Bit rearrangement; Foveation-based HVS
   model
ID WAVELET; EFFICIENT
AB In recent years, Set Partitioning in Hierarchical Trees (SPIHT) algorithm has performed efficiently on image and video coding. However, in low bit rate situations, on the whole the videos usually have relatively low visual quality while attention is paid on the videos. To improve the problem, this paper proposes Attention Emphasis bit arrangement in 3-D SPIHT video coding algorithm (AE-SPIHT) to rearrange bits efficiently from eye-insensitive regions to eye-sensitive regions, so that the whole video can obtain a better visual condition. AE-SPIHT properly exploits a bit-arrangement method rearranging bits foveately from eye-insensitive regions, according to texture content and bit-rate, to eye-sensitive ones. Experiments show that AE-SPIHT algorithm improves the visual quality of attention regions in conventional 3-D SPIHT in most cases. Compared with other bit arrangement methods, the proposed method also achieves a better visual condition in arranging the bits. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Lee, Kuan-Hui; Chung, Pau-Choo] Natl Cheng Kung Univ, Dept Elect Engn, Inst Comp & Commun Engn, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Chung, PC (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, Inst Comp & Commun Engn, Tainan 70101, Taiwan.
EM younglee0201@gmail.com; pcchung@ee.ncku.e-du.tw
RI Chung, Pau-Choo/ABB-3574-2021
FU National Science Council Taiwan [NSC93-2213-E-006-049]
FX This work was supported by National Science Council Taiwan, under Grant
   NSC93-2213-E-006-049.
CR [Anonymous], 1995, 138182 ISOIEC
   [Anonymous], VID COD LOW BIT RAT
   Arnow TL, 1996, P SOC PHOTO-OPT INS, V2674, P119, DOI 10.1117/12.237500
   BANKS MS, 1991, J OPT SOC AM A, V8, P1775, DOI 10.1364/JOSAA.8.001775
   Burns TJ, 1996, IEEE T AERO ELEC SYS, V32, P628, DOI 10.1109/7.489507
   Chen Z., 2005, P SPIE MULTIMEDIA SY
   Geisler W. S., 1998, P SPIE, V3299
   He C, 2003, IEEE T CIRC SYST VID, V13, P961, DOI 10.1109/TCSVT.2003.816514
   International Telecommunication Union Telecommunication Standardization Sector (ITU-T), 2000, VID COD LOW BIT RAT, V263
   International Telecommunication Union Telecommunication Standardization Sector (ITU-T), 2000, VID COD LOW BIT RAT, V263
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Martucci SA, 1997, IEEE T CIRC SYST VID, V7, P109, DOI 10.1109/76.554422
   Mehrseresht N, 2006, IEEE T IMAGE PROCESS, V15, P740, DOI 10.1109/TIP.2005.860619
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Secker A, 2003, IEEE T IMAGE PROCESS, V12, P1530, DOI 10.1109/TIP.2003.819433
   Secker A, 2004, IEEE T IMAGE PROCESS, V13, P1029, DOI 10.1109/TIP.2004.826089
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sullivan J., 2010, P SOC PHOTO-OPT INS, V7798, P7798
   TANG C, 2007, IEEE T MULTIMEDIA, V9
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   Wheeler F.W., 2000, IEEE INT C IM PROC I
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu J., 2000, WAVELET VIDEO CODER
   Xu JZ, 2002, IEEE T CIRC SYST VID, V12, P812, DOI 10.1109/TCSVT.2002.803231
NR 33
TC 2
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 255
EP 269
DI 10.1016/j.jvcir.2013.01.006
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200005
DA 2024-07-18
ER

PT J
AU Oh, S
   Woo, H
   Yun, S
   Kang, M
AF Oh, Seungmi
   Woo, Hyenkyun
   Yun, Sangwoon
   Kang, Myungjoo
TI Non-convex hybrid total variation for image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-convex TV; Non-convex HOTV; Non-convex hybrid TV; Iterative
   reweighted algorithm; Image denoising; Total Variation (TV); The
   alternating direction method of multiplier (ADMM); Staircase artifacts
ID TOTAL VARIATION MINIMIZATION; RESTORATION; ALGORITHM
AB Image restoration problems, such as image denoising, are important steps in various image processing method, such as image segmentation and object recognition. Due to the edge preserving property of the convex total variation (TV), variational model with TV is commonly used in image restoration. However, staircase artifacts are frequently observed in restored smoothed region. To remove the staircase artifacts in smoothed region, convex higher-order TV (HOTV) regularization methods are introduced. But the valuable edge information of the image is also attenuated. In this paper, we propose non-convex hybrid TV regularization method to significantly reduce staircase artifacts while well preserving the valuable edge information of the image. To efficiently find a solution of the variation model with the proposed regularizer, we use the iterative reweighted method with the augmented Lagrangian based algorithm. The proposed model shows the best performance in terms of the signal-to-noise ratio (SNR) and the structure similarity index measure (SSIM) with comparable computational complexity. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Oh, Seungmi; Woo, Hyenkyun; Kang, Myungjoo] Seoul Natl Univ, Dept Math Sci, Seoul 151747, South Korea.
   [Woo, Hyenkyun] Georgia Inst Technol, Sch Computat Sci & Engn, Atlanta, GA 30332 USA.
   [Yun, Sangwoon] Sungkyunkwan Univ, Dept Math Educ, Seoul, South Korea.
C3 Seoul National University (SNU); University System of Georgia; Georgia
   Institute of Technology; Sungkyunkwan University (SKKU)
RP Kang, M (corresponding author), Seoul Natl Univ, Dept Math Sci, 1 Gwanak Ro, Seoul 151747, South Korea.
EM uliana.oh@gmail.com; hyenkyun@gmail.com; yswmathedu@skku.edu;
   mkang@snu.ac.kr
RI Woo, Hyenkyun/R-2951-2019; Yun, Sangwoon/AAT-2559-2021
FU Basic Science Research Program through the National Research Foundation
   of Korea [2010-0510-1-3, 2012-001766]; Ministry of Education, Science
   and Technology [2012R1A1A1006406]; Ministry of Culture, Sports and
   Tourism (MCST); Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program [R2011050089]; Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF)
FX Hyenkyun Woo was supported by the Basic Science Research Program
   (2010-0510-1-3) through the National Research Foundation of Korea.
   Sangwoon Yun was supported in part by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) Funded by the
   Ministry of Education, Science and Technology (2012R1A1A1006406).
   Myungjoo Kang was supported in part by Basic Science Research Program
   (2012-001766) through the National Research Foundation of Korea and by
   the Ministry of Culture, Sports and Tourism (MCST) and Korea Creative
   Content Agency (KOCCA) in the Culture Technology (CT) Research &
   Development Program (R2011050089).
CR [Anonymous], PREPRINT
   [Anonymous], 1202 CAM UCLA
   [Anonymous], ARXIV11101804V1CSCV
   [Anonymous], ARXIV12026341V1MATHN
   [Anonymous], 1202 CAM UCLA LOS AN
   Blomgren P, 1997, P SOC PHOTO-OPT INS, V3162, P367, DOI 10.1117/12.279496
   Bollt EM, 2009, ADV COMPUT MATH, V31, P61, DOI 10.1007/s10444-008-9082-7
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   BUCKLEY MJ, 1994, BIOMETRIKA, V81, P247, DOI 10.2307/2336955
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   CHARTRAND R, 2008, P 33 IEEE INT C AC S
   Chartrand R, 2007, IEEE IMAGE PROC, P293
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Chartrand R, 2008, INVERSE PROBL, V24, DOI 10.1088/0266-5611/24/3/035020
   Chen X., 2010, TECHNICAL REPORT
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Krishnan D., 2009, P ADV NEUR INF PROC, P1
   Lefkimmiatis S, 2012, IEEE T IMAGE PROCESS, V21, P983, DOI 10.1109/TIP.2011.2168232
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Michailovich OV, 2011, IEEE T IMAGE PROCESS, V20, P1281, DOI 10.1109/TIP.2010.2090532
   Ng MK, 1999, SIAM J SCI COMPUT, V21, P851, DOI 10.1137/S1064827598341384
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yuan J, 2009, LECT NOTES COMPUT SC, V5567, P552, DOI 10.1007/978-3-642-02256-2_46
   Zhu W, 2012, SIAM J IMAGING SCI, V5, P1, DOI 10.1137/110822268
NR 41
TC 79
Z9 80
U1 0
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 332
EP 344
DI 10.1016/j.jvcir.2013.01.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200011
DA 2024-07-18
ER

PT J
AU Lee, C
   Lee, C
   Kim, CS
AF Lee, Chul
   Lee, Chulwoo
   Kim, Chang-Su
TI An MMSE approach to nonlocal image denoising: Theory and practical
   implementation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Nonlocal means filter; Minimum mean square error (MMSE)
   denoising; Bayesian estimation; Noisy nonlocal neighbors; Probabilistic
   tree search; External database; Image restoration
ID SPARSE; ALGORITHM; DICTIONARIES
AB A nonlocal minimum mean square error (MMSE) image denoising algorithm is proposed in this work. Based on the Bayesian estimation theory, we first derive that the conventional nonlocal means filter is an MMSE estimator in the special case of noise-free nonlocal neighbors. Then, we develop the nonlocal MMSE denoising filter that can minimize the mean square error (MSE) of a denoised block in more general cases of noisy nonlocal neighbors. Furthermore, the proposed algorithm searches nonlocal neighbors from an external database as well as the entire input image to improve the performance even when a noisy block may not have similar blocks within the image. Since the extended search range demands a higher computational burden, we develop a probabilistic tree-based search method to reduce the computational complexity. Simulation results show that the proposed algorithm provides significantly better denoising performance than the conventional nonlocal means filter. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Lee, Chul; Lee, Chulwoo; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM kayne@korea.ac.kr; wiserain@korea.ac.kr; changsukim@korea.ac.kr
RI Lee, Chul/W-3762-2019
OI Lee, Chul/0000-0001-9329-7365; Kim, Chang-Su/0000-0002-4276-1831
FU Global Frontier R&D Program on Human-centered Interaction for
   Coexistence; NRF of Korea; Korean Government (MEST)
   [NRF-M1AXA003-2011-0031648]; NRF; MEST [2011- 0001271]
FX This work was supported partly by the Global Frontier R&D Program on
   Human-centered Interaction for Coexistence, funded by the NRF of Korea
   grant funded by the Korean Government (MEST)
   (NRF-M1AXA003-2011-0031648), and partly by Basic Science Research
   Program through the NRF funded by the MEST (2011- 0001271).
CR Adams A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531327
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2012, VECTOR QUANTIZATION
   Awate SP, 2005, PROC CVPR IEEE, P44
   Azzabou N., 2007, Proc. Int. Conf. Image Processing, VIII, P109
   Barbu A, 2009, PROC CVPR IEEE, P1574, DOI 10.1109/CVPRW.2009.5206811
   Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Buades A, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P70
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chao P., 2009, P IEEE INT WORKSH MU, P1
   Chatterjee P., IEEE T IMAG IN PRESS
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Dabov Kostadin, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P145
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2010, IEEE IMAGE PROC, P801, DOI 10.1109/ICIP.2010.5653394
   Duval V., 2010, HAL00468856
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Levin A., 2011, P IEEE CVPR
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mood A.M., 1974, Introduction to the theory of statistics
   Moon T.K., 2000, Mathematical Methods and Algorithms for Signal Processing
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Protter M, 2010, IEEE T SIGNAL PROCES, V58, P3471, DOI 10.1109/TSP.2010.2046596
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Roth S, 2005, PROC CVPR IEEE, P860
   Salmon J, 2010, IEEE IMAGE PROC, P1929, DOI 10.1109/ICIP.2010.5650780
   Salmon J, 2010, IEEE SIGNAL PROC LET, V17, P269, DOI 10.1109/LSP.2009.2038954
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Tappen M. F., 2007, P IEEE C COMP VIS PA, P1
   Tasdizen T, 2009, IEEE T IMAGE PROCESS, V18, P2649, DOI 10.1109/TIP.2009.2028259
   Tico M, 2007, PROC SPIE, V6502, DOI 10.1117/12.703494
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zhang L, 2009, PROC CVPR IEEE, P1542, DOI 10.1109/CVPRW.2009.5206836
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
NR 48
TC 11
Z9 13
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 476
EP 490
DI 10.1016/j.jvcir.2012.01.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800007
DA 2024-07-18
ER

PT J
AU Lin, WS
   Kuo, CCJ
AF Lin, Weisi
   Kuo, C-C Jay
TI Perceptual visual quality metrics: A survey
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human visual system (HVS); Vision-based model; Signal-driven model;
   Signal decomposition; Just-noticeable distortion; Visual attention;
   Common feature and artifact detection; Full reference; No reference;
   Reduced reference
ID JUST-NOTICEABLE-DISTORTION; FIDELITY-CRITERION; BLOCKING ARTIFACTS;
   NEURAL MECHANISMS; VIDEO; MODEL; CONTRAST; EDGE; DIFFERENCE; SHARPNESS
AB Visual quality evaluation has numerous uses in practice, and also plays a central role in shaping many visual processing algorithms and systems, as well as their implementation, optimization and testing. In this paper, we give a systematic, comprehensive and up-to-date review of perceptual visual quality metrics (PVQMs) to predict picture quality according to human perception. Several frequently used computational modules (building blocks of PVQMs) are discussed. These include signal decomposition, just-noticeable distortion, visual attention, and common feature and artifact detection. Afterwards, different types of existing PVQMs are presented, and further discussion is given toward feature pooling, viewing condition, computer-generated signal and visual attention. Six often-used image metrics (namely SSIM, VSNR, IFC, VIF, MSVD and PSNR) are also compared with seven public image databases (totally 3832 test images). We highlight the most significant research work for each topic and provide the links to the extensive relevant literature. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Kuo, C-C Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Kuo, C-C Jay] Univ So Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
C3 Nanyang Technological University; University of Southern California;
   University of Southern California
RP Lin, WS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM wslin@ntu.edu.sg; cckuo@sipi.usc.edu
RI Liu, Anmin/A-4730-2012; Lin, Weisi/A-8011-2012; Lin, Weisi/A-3696-2011;
   Kuo, C.-C. Jay/A-7110-2011
OI Lin, Weisi/0000-0001-9866-1947; Kuo, C.-C. Jay/0000-0001-9474-5035
FU MoE AcRF, Singapore [T20881218]
FX The authors are grateful to Mr. Manish Narwaria and Mr. Yuming Fang, in
   the CemNet Lab, Nanyang Technological University, Singapore, for the
   help in preparing the experimental data for Section 5, and reproducing
   Figs. 1 and 3, respectively. This work is partially supported by MoE
   AcRF Tire 2 Grant, Singapore, Grant No.: T20881218. The authors
   appreciate the editor and anonymous reviewers' constructive advice that
   has prompted us for two new rounds of re-thinking of our work and toward
   clearer presentation of the technical content in this paper.
CR AHUMADA AJ, 2001, P SPIE HUMAN VISION, V6, P4299
   AHUMADA AJ, 1992, SPIE P HUMAN VISION, V3, P365
   [Anonymous], 2002, IEEE INT C AC SPEECH
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], A57 DATASET
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], 1988, Eye, brain, and vision
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 37 IEEE AS C SIGN SY
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2002, 50011 ITUR BT
   [Anonymous], 2006, Digital Video Image Quality and Perceptual Coding
   [Anonymous], 1999, P910 ITUT
   [Anonymous], EUROGRAPHICS STATE A
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Barkowsky M, 2009, IEEE J-STSP, V3, P266, DOI 10.1109/JSTSP.2009.2015375
   Benzie P, 2007, IEEE T CIRC SYST VID, V17, P1647, DOI 10.1109/TCSVT.2007.905377
   BLAKEMORE C, 1969, J PHYSIOL-LONDON, V200, pP11
   Bolin MR, 1999, PROC SPIE, V3644, P106, DOI 10.1117/12.348431
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   BRADLEY AP, 2003, J VISUAL COMMUN IMAG
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   CAMPBELL FW, 1966, J PHYSIOL-LONDON, V187, P437, DOI 10.1113/jphysiol.1966.sp008101
   Cater K., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P270
   Caviedes J, 2004, SIGNAL PROCESS-IMAGE, V19, P147, DOI 10.1016/j.image.2003.08.002
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   CHEN J, 2007, IEEE T SYSTEMS MAN C, V37
   Cheng I, 2007, IEEE T MULTIMEDIA, V9, P386, DOI 10.1109/TMM.2006.886291
   CHIU K, 1994, P 5 EUR REND WORKSH, P19
   Chiu YJ, 1999, IEEE T CIRC SYST VID, V9, P438, DOI 10.1109/76.754773
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Chun M.M., 2001, BLACKWELL HDB SENSAT, P272
   Cliff N., 1987, ANAL MULTIVARIATE DA
   Coudoux FX, 2001, J ELECTRON IMAGING, V10, P498, DOI 10.1117/1.1344184
   DALY S, 2001, VISION MODELS APPL I
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Dijk J, 2003, LECT NOTES COMPUT SC, V2756, P149
   DOSSELMANN R, 2010, SIGNAL IMAGE VIDEO P
   EBERT DS, 2002, SIGGRAPH
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Engelke U., WIRELESS IMAGING QUA
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   FAUGERAS OD, 1979, IEEE T ACOUST SPEECH, V27, P380, DOI 10.1109/TASSP.1979.1163262
   Fehn C, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P23
   Ferwerda JA, 2001, IEEE COMPUT GRAPH, V21, P22, DOI 10.1109/38.946628
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Fredericksen RE, 1998, VISION RES, V38, P1023, DOI 10.1016/S0042-6989(97)00239-3
   Frossard P, 2001, IEEE T IMAGE PROCESS, V10, P1815, DOI 10.1109/83.974566
   Gaubatz M., MeTriX MuX visual quality assessment package
   Ghanbari M., 2003, STANDARD CODES IMAGE
   Ghinea G, 2008, IEEE T BROADCASTING, V54
   Girod Bernd, 1993, P207
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   Hopfinger JB, 2000, NAT NEUROSCI, V3, P284, DOI 10.1038/72999
   Horita Y, 2003, PROC SPIE, V5150, P1601, DOI 10.1117/12.502638
   Horita Y., IMAGE QUALITY EVALUA
   Iacovoni G., 2005, Proc. IEEE International Conference on Multimedia and Expo, P1452
   Irisa GR, 2004, INT CONF QUANT EVAL, P110
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   *ITU, 1998, BT11292 ITUR
   *ITU T, 2002, J147 ITUT
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Kaiser P., 1996, Human Color Vision
   Karam L, 2009, IEEE J SEL TOP SIGNA, V3
   KARUNASEKERA SA, 1995, IEEE T IMAGE PROCESS, V4, P713, DOI 10.1109/83.388074
   Keelan B., 2002, Handbook of image quality
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   KELLY DH, 1979, J OPT SOC AM, V69, P1266, DOI 10.1364/JOSA.69.001266
   Kolb B., 1996, FUNDAMENTALS HUMAN N, V4th
   KUFFLER SW, 1953, J NEUROPHYSIOL, V16, P37, DOI 10.1152/jn.1953.16.1.37
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Lai YK, 2000, J VIS COMMUN IMAGE R, V11, P17, DOI 10.1006/jvci.1999.0433
   LAMBRECHT CJV, 1996, THESIS SWISS FEDERAL
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Larson EC, 2008, IEEE IMAGE PROC, P2572, DOI 10.1109/ICIP.2008.4712319
   Le Callet P., Subjective quality assessment IRCCyN/IVC database
   Lee S, 2009, IEEE T VIS COMPUT GR, V15, P6, DOI 10.1109/TVCG.2008.82
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   LEMEUR O, 2010, SIGNAL PROCESS I JUN
   LIANG L, 2010, SIGNAL PROCESS IMAGE
   LIMB JO, 1979, IEEE T SYST MAN CYB, V9, P778, DOI 10.1109/TSMC.1979.4310129
   Lin W., 2006, DIGITAL VIDEO IMAGE
   LIN W, 2008, ADV COMPUTATIONAL IN
   Lin WS, 2006, IEE P-VIS IMAGE SIGN, V153, P215, DOI 10.1049/ip-vis:20050110
   Lin WS, 2005, IEEE T CIRC SYST VID, V15, P900, DOI 10.1109/TCSVT.2005.848345
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   LIU H, 2009, IEEE INT C IM PROC
   LU Z, 2007, IEEE INT C IM PROC
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Lubin Jeffrey., 1995, Vision Models for Target Detection and Recognition, chapter A visual discrimination model for imaging system design and evaluation
   LUKAS FXJ, 1982, IEEE T COMMUN, V30, P1679, DOI 10.1109/TCOM.1982.1095616
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Maisonneuve J, 2009, IEEE T BROADCAST, V55, P315, DOI 10.1109/TBC.2009.2020451
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Marichal X., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P386, DOI 10.1109/ICIP.1999.822923
   Marr D., 1982, Vision
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   MASRY MA, 2006, IEEE T CIRCUIT SYST, V16
   Meesters LMJ, 2004, IEEE T CIRC SYST VID, V14, P381, DOI 10.1109/TCSVT.2004.823398
   Mei T, 2007, IEEE T CIRC SYST VID, V17, P699, DOI 10.1109/TCSVT.2007.896640
   MITRA SK, 2004, SIGNAL PROCESS IMAGE, V19
   Miyahara M, 1998, IEEE T COMMUN, V46, P1215, DOI 10.1109/26.718563
   Mohamed S, 2002, IEEE T CIRC SYST VID, V12, P1071, DOI 10.1109/TCSVT.2002.806808
   MONTENOVO M, 2006, P 3 INT WORSH VID PR
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   MULLEN KT, 1985, J PHYSIOL-LONDON, V359, P381, DOI 10.1113/jphysiol.1985.sp015591
   NARWARIA M, 2009, P IEEE WORKSH MULT S
   Navalpakkam V, 2006, J VISION, V6, P1180, DOI 10.1167/6.11.4
   Netravali A.N., 1988, DIGITAL PICTURES REP
   Ninassi A, 2007, IEEE IMAGE PROC, P733
   Ninassi A, 2009, IEEE J-STSP, V3, P253, DOI 10.1109/JSTSP.2009.2014806
   Oelbaum T, 2009, IEEE J-STSP, V3, P294, DOI 10.1109/JSTSP.2009.2015473
   Ong E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P545
   Ong EP, 2006, J VIS COMMUN IMAGE R, V17, P717, DOI 10.1016/j.jvcir.2005.11.002
   Ong EP, 2004, IEEE T CIRC SYST VID, V14, P559, DOI 10.1109/TCSVT.2004.825574
   *OPTICOM GMBH, PERC VOIC AUD VID QU
   Ou YF, 2008, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2008.4711848
   Pappas T.N., 2000, HDB IMAGE VIDEO PROC
   Parker J.R., 1996, Algorithms for Image Processing and Computer Vision
   Pashler H, 1998, PSYCHOL ATTENTION
   PASTRANAVIDAL R, 2004, P SPIE INT SOC OPT E, V5292
   PASTRANAVIDAL R, 2006, P 3 INT WORKSH VID P
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   PHILLIPS GC, 1984, J OPT SOC AM A, V1, P226, DOI 10.1364/JOSAA.1.000226
   Poirson AB, 1996, VISION RES, V36, P515, DOI 10.1016/0042-6989(96)89251-0
   Ponomarenko N, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P407
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   *QOMEX COMM, 2010, INT WORKSH QUAL MULT
   QUAN HT, 2008, IEEE T BROADCAST, V54
   Ramanarayanan G, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276472, 10.1145/1239451.1239527]
   Ramasubramanian M, 1999, COMP GRAPH, P73, DOI 10.1145/311535.311543
   Rodieck R. W., 1998, The First Steps in Seeing
   *SARN CORP, 1997, IEEE G 2 1 6 COMPR P
   Sheikh H. R., IMAGE VIDEO QUALITY
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   SURESH N, 2006, 3 INT WORKSH VID PRO
   SYLVAIN T, 2008, IEEE INT C IM PROC
   Tan KT, 2000, IEEE T CIRC SYST VID, V10, P1208, DOI 10.1109/76.875525
   Tan KT, 2000, IEEE SIGNAL PROC LET, V7, P213, DOI 10.1109/97.855443
   *TEKTR INC, PICT QUAL AN SYST PQ
   Tian Dihong, 2004, P 12 ANN ACM INT C M
   TONG HY, 1998, P IEEE INT C IM PROC, V3
   Tong X, 1999, P SOC PHOTO-OPT INS, V3644, P185, DOI 10.1117/12.348439
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TUMBLIN J, 2001, IEEE COMPUT GRAPH AP, V21
   VANNES FL, 1967, J OPT SOC AM, V57, P401, DOI 10.1364/JOSA.57.000401
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   *VPQM COMM, INT WORKSH VID PROC
   Vu CT, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P73, DOI 10.1109/SSIAI.2008.4512288
   WANDELL B, 1995, FOUNDAMENTIONS VISIO
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wang Z, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P89, DOI 10.1109/ICIP.2001.958431
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, The SSIM Index for Image Quality Assessment
   WANG Z, 2009, IEEE SIGNAL PRO JAN
   WANG Z, 2000, P IEEE INT C IM PROC, V3, P981, DOI DOI 10.1109/ICIP.2000.899622
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Watson A.B., 1993, SOC INFORM DISPLAY D, Vxxiv, P946
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
   WATSON AB, 1987, COMPUT VISION GRAPH, V39, P311, DOI 10.1016/S0734-189X(87)80184-6
   Watson AB, 1997, J OPT SOC AM A, V14, P2379, DOI 10.1364/JOSAA.14.002379
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Winkler S, 2003, PROC SPIE, V5150, P593, DOI 10.1117/12.509910
   Winkler S, 2003, PROC SPIE, V5007, P104, DOI 10.1117/12.477766
   Winkler S., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P420, DOI 10.1109/ICIP.1999.819627
   Winkler S, 2001, PROC SPIE, V4299, P114, DOI 10.1117/12.429540
   Winkler S, 2000, PROC SPIE, V3959, P37, DOI 10.1117/12.387175
   WINKLER S, 2000, THESIS SWISS FEDERAL
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wolf S, 1997, IEEE T BROADCAST, V43, P320, DOI 10.1109/11.632940
   Wolf S., 2002, 02392 NTIA
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Wu SQ, 2009, J VIS COMMUN IMAGE R, V20, P231, DOI 10.1016/j.jvcir.2009.03.002
   XU S, 2008, C APPL DIG IM PROC 3
   YANG KC, 2007, IEEE T MULTIMEDIA, P9
   YANG S, 2004, P 12 ANN ACM INT C M
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   YOU J, 2010, P IEEE INT C MULT EX
   Yu ZH, 2002, P IEEE, V90, P154, DOI 10.1109/5.982412
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
   ZHAI G, 2008, SIGNAL PROCESS IMAGE
   ZHANG L, 2009, ACM C MULT
   Zhang N., 2003, Proceedings of Section of Physical and Engineering Sciences of American Statistical Society, P4730
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
   Zhang XH, 2008, J VIS COMMUN IMAGE R, V19, P30, DOI 10.1016/j.jvcir.2007.06.001
   Zhang XM, 1998, SIGNAL PROCESS, V70, P201, DOI 10.1016/S0165-1684(98)00125-X
   2009, ANN TELECOMMUNICATIO
NR 204
TC 687
Z9 763
U1 0
U2 145
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2011
VL 22
IS 4
BP 297
EP 312
DI 10.1016/j.jvcir.2011.01.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 751AG
UT WOS:000289589100001
DA 2024-07-18
ER

PT J
AU Shao, L
   Wang, JN
   Kirenko, I
   de Haan, G
AF Shao, Ling
   Wang, Jingnan
   Kirenko, Ihor
   de Haan, Gerard
TI Quality adaptive least squares trained filters for video compression
   artifacts removal using a no-reference block visibility metric
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compression artifacts removal; Adaptive filtering; Least squares filter;
   No-reference quality metric; Noise reduction; Image enhancement;
   Blocking artifact reduction; Picture quality improvement
AB Compression artifacts removal is a challenging problem because videos can be compressed at different qualities. In this paper, a least squares approach that is self-adaptive to the visual quality of the input sequence is proposed. For compression artifacts, the visual quality of an image is measured by a no-reference block visibility metric. According to the blockiness visibility of an input image, an appropriate set of filter coefficients that are trained beforehand is selected for optimally removing coding artifacts and reconstructing object details. The performance of the proposed algorithm is evaluated on a variety of sequences compressed at different qualities in comparison to several other de-blocking techniques. The proposed method outperforms the others significantly both objectively and subjectively. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Shao, Ling] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S10 2TN, S Yorkshire, England.
   [Wang, Jingnan] Northwestern Univ, Dept EECS, Evanston, IL 60208 USA.
   [Kirenko, Ihor; de Haan, Gerard] Philips Res Labs, Eindhoven, Netherlands.
C3 University of Sheffield; Northwestern University; Philips; Philips
   Research
RP Shao, L (corresponding author), Univ Sheffield, Dept Elect & Elect Engn, Sheffield S10 2TN, S Yorkshire, England.
EM ling.shao@sheffield.ac.uk
RI Shao, Ling/D-3535-2011
OI Shao, Ling/0000-0002-8264-6117
CR DAMKAT C, 2004, POSTPROCESSING TECHN
   Kim SD, 1999, IEEE T CIRC SYST VID, V9, P156, DOI 10.1109/76.744282
   KIRENKO I, 2008, P 33 IEEE INT C AC S
   KIRENKO I, 2007, P 14 IEEE INT C IM P
   KONDO T, Patent No. 63232001905
   KONDO T, Patent No. 54441995487
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Muijs R., 2005, P 13 EUR SIGN PROC C
   SHAO L, 2007, P 14 IEEE INT C IM P
   SHAO L, 2009, P 34 IEEE INT C AC S
   Shao L, 2008, IEEE T IMAGE PROCESS, V17, P1772, DOI 10.1109/TIP.2008.2002162
   Shao L, 2007, IEEE T CONSUM ELECTR, V53, P691, DOI 10.1109/TCE.2007.381747
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
NR 14
TC 14
Z9 16
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 23
EP 32
DI 10.1016/j.jvcir.2010.09.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Berg, M
   Kojo, I
   Laarni, J
AF Berg, Mikko
   Kojo, Ilpo
   Laarni, Jari
TI Object displays for identifying multidimensional outliers within a
   crowded visual periphery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object display; Peripheral vision; Eye movements; Acuity; Crowding;
   Multidimensional; Visual search; Eccentricity
ID EYE-MOVEMENTS; CONJUNCTION SEARCH; CORTICAL MAGNIFICATION; SELECTIVE
   ATTENTION; COVERT SHIFTS; PARALLEL; VISION; TARGET; SERIAL; PERCEPTION
AB This article discusses the human ability to detect, locate, or identify objects and their features using peripheral vision. The potential of peripheral vision is underused with user interfaces probably due to the limits of visual acuity. Peripheral preview can guide focused attention to informative locations, if the visual objects are large enough and otherwise within the limits of discrimination. Our experiments focused on the task of identifying an outlier and implicated another limiting factor, crowding, for integration of object features. The target object and the corresponding data dimension were located from an object display representation used for integrating multidimensional data. We measured performance on a peripheral vision task in terms of reaction times and eye movements. Subjects identified the target item from 480 alternatives within 100 ms. Therefore, the identification process would not slow down the natural gaze sequence and focused attention during monitoring and data mining tasks. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Berg, Mikko; Kojo, Ilpo] Helsinki Sch Econ, Ctr Knowledge & Innovat Res, Helsinki 00101, Finland.
   [Laarni, Jari] VTT Tech Res Ctr Finland VTT, Espoo 02044, Finland.
   [Berg, Mikko] Aalto Univ, Dept Media Technol, Espoo 02015, Finland.
C3 Aalto University; VTT Technical Research Center Finland; Aalto
   University
RP Berg, M (corresponding author), Helsinki Sch Econ, Ctr Knowledge & Innovat Res, POB 1210, Helsinki 00101, Finland.
EM mikko.j.berg@helsinki.fi; ilpo.ko-jo@helsinki.fi; jari.laarni@vtt.fi
FU Academy of Finland [210676]; Foundation of Ella and Georg Ehrnrooth;
   Academy of Finland (AKA) [210676] Funding Source: Academy of Finland
   (AKA)
FX We would like to thank Lari Karkkainen for his help in conducting the
   experiments. This work has been supported by Academy of Finland
   (#210676) and by the foundation of Ella and Georg Ehrnrooth.
CR Aaltonen A., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P132, DOI 10.1145/274644.274664
   [Anonymous], 2005, Cognitive processes in eye guidance
   Anstis S, 1998, PERCEPTION, V27, P817, DOI 10.1068/p270817
   ANTES JR, 1984, PSYCHOL RES-PSYCH FO, V46, P247, DOI 10.1007/BF00308887
   Bartram L, 2003, INT J HUM-COMPUT ST, V58, P515, DOI 10.1016/S1071-5819(03)00021-1
   Bennett KB, 2000, HUM FACTORS, V42, P287, DOI 10.1518/001872000779656462
   BERG M, 2010, BEHAV INF TECHNOL
   BERG M, 2006, E SERVICE J, V4, P47
   Bertera JH, 2000, PERCEPT PSYCHOPHYS, V62, P576, DOI 10.3758/BF03212109
   BIEDERMA.I, 1972, SCIENCE, V177, P77, DOI 10.1126/science.177.4043.77
   BOUMA H, 1970, NATURE, V226, P177, DOI 10.1038/226177a0
   BOYCE SJ, 1992, J EXP PSYCHOL LEARN, V18, P531, DOI 10.1037/0278-7393.18.3.531
   BRAVO MJ, 1992, PERCEPT PSYCHOPHYS, V51, P465, DOI 10.3758/BF03211642
   BULLIER J, 1995, CURR OPIN NEUROBIOL, V5, P497, DOI 10.1016/0959-4388(95)80011-5
   Card S K., 1999, READINGS INFORM VISU
   Carpenter PA, 1998, J EXP PSYCHOL-APPL, V4, P75, DOI 10.1037/1076-898X.4.2.75
   Carrasco M, 1998, VISION RES, V38, P347, DOI 10.1016/S0042-6989(97)00152-1
   CARSWELL CM, 1987, ERGONOMICS, V30, P511, DOI 10.1080/00140138708969741
   Castelhano MS, 2009, J VISION, V9, DOI 10.1167/9.3.6
   Chambers J.M., 1983, Graphical Methods for Data Analysis
   CHMIEL N, 1989, PSYCHOL RES-PSYCH FO, V51, P117, DOI 10.1007/BF00309306
   COHEN A, 1991, J EXP PSYCHOL HUMAN, V17, P891, DOI 10.1037/0096-1523.17.4.891
   Curcio C., 1991, Distribution and morphology of human cone photoreceptors staind with anti-blue opsin, V312, P610
   CZERWINSKI M, 2000, OZCHI 2000
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   DUNCAN J, 1984, J EXP PSYCHOL GEN, V113, P501, DOI 10.1037/0096-3445.113.4.501
   Duncan RO, 2003, NEURON, V38, P659, DOI 10.1016/S0896-6273(03)00265-4
   Eckstein MP, 2007, J NEUROSCI, V27, P1266, DOI 10.1523/JNEUROSCI.3975-06.2007
   Eckstein MP, 2001, PERCEPTION, V30, P1389, DOI 10.1068/p3128
   FARADAY P, 1997, SIGCHI 97, P272
   Findlay J.M., 2004, INTERFACE LANGUAGE V, P135
   Findlay JM, 1997, VISION RES, V37, P617, DOI 10.1016/S0042-6989(96)00218-0
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Gattis M, 1996, J EXP PSYCHOL LEARN, V22, P231, DOI 10.1037/0278-7393.22.1.231
   Geisler WS, 2006, J VISION, V6, P858, DOI 10.1167/6.9.1
   GEISLER WS, 1995, PSYCHOL REV, V102, P356, DOI 10.1037/0033-295X.102.2.356
   Gibson J., 1979, The ecological approach to visual perception
   Gilchrist ID, 1999, VISION RES, V39, P1373, DOI 10.1016/S0042-6989(98)00242-9
   GILLIE T, 1989, PSYCHOL RES-PSYCH FO, V50, P243, DOI 10.1007/BF00309260
   Greene HH, 2006, PERCEPTION, V35, P303, DOI 10.1068/p5329
   GUTHRIE JT, 1993, CONTEMP EDUC PSYCHOL, V18, P186, DOI 10.1006/ceps.1993.1017
   Healey CG, 1999, IEEE T VIS COMPUT GR, V5, P145, DOI 10.1109/2945.773807
   Higgins KE, 1998, HUM FACTORS, V40, P224, DOI 10.1518/001872098779480415
   HILLSTROM AP, 1994, PERCEPT PSYCHOPHYS, V55, P399, DOI 10.3758/BF03205298
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Interrante V, 2000, IEEE COMPUT GRAPH, V20, P6, DOI 10.1109/MCG.2000.888001
   JACOBS AM, 1986, PERCEPT PSYCHOPHYS, V39, P47, DOI 10.3758/BF03207583
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kosara R, 2003, IEEE COMPUT GRAPH, V23, P20, DOI 10.1109/MCG.2003.1210860
   KRAMER AF, 1985, J EXP PSYCHOL HUMAN, V11, P393, DOI 10.1037/0096-1523.11.4.393
   Land M.F., 2004, VISUAL NEUROSCIENCES, P1357
   LAPPIN JS, 1967, J EXP PSYCHOL, V75, P321, DOI 10.1037/h0025044
   Levi DM, 2008, VISION RES, V48, P635, DOI 10.1016/j.visres.2007.12.009
   Loschky LC, 2002, J EXP PSYCHOL-APPL, V8, P99, DOI 10.1037/1076-898X.8.2.99
   Luo G, 2008, J VISION, V8, DOI 10.1167/8.14.25
   Mack Arien, 1998, Inattentional Blindness
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   Maglio P. P., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P241, DOI 10.1145/332040.332438
   MCCRICKARD DS, 2001, INT 2001 IFIP C HUM, P148
   McFarlane DC, 1999, HUMAN-COMPUTER INTERACTION - INTERACT '99, P295
   MILLER J, 1988, J EXP PSYCHOL HUMAN, V14, P453, DOI 10.1037/0096-1523.14.3.453
   Milner AD., 1995, The visual brain in action
   Motter BC, 2007, VISION RES, V47, P1261, DOI 10.1016/j.visres.2007.02.006
   Motter BC, 1998, VISION RES, V38, P1007, DOI 10.1016/S0042-6989(97)00252-6
   Najemnik J, 2005, NATURE, V434, P387, DOI 10.1038/nature03390
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   Neisser U., 1979, PERCEPTION ITS DEV T, P201
   Norman J, 2002, BEHAV BRAIN SCI, V25, P73, DOI 10.1017/S0140525X0200002X
   OSHEA RP, 1991, PERCEPTION, V20, P415, DOI 10.1068/p200415
   Oulasvirta A, 2004, BEHAV INFORM TECHNOL, V23, P53, DOI 10.1080/01449290310001644859
   Palmer J, 2000, VISION RES, V40, P1227, DOI 10.1016/S0042-6989(99)00244-8
   PELI E, 1991, J OPT SOC AM A, V8, P1762, DOI 10.1364/JOSAA.8.001762
   Peli E, 2001, J OPT SOC AM A, V18, P294, DOI 10.1364/JOSAA.18.000294
   Pelli DG, 2004, J VISION, V4, P1136, DOI 10.1167/4.12.12
   Peterson MS, 2004, PERCEPT PSYCHOPHYS, V66, P398, DOI 10.3758/BF03194888
   POMERANTZ JR, 1989, J EXP PSYCHOL HUMAN, V15, P635, DOI 10.1037/0096-1523.15.4.635
   POTTER MC, 1975, SCIENCE, V187, P965, DOI 10.1126/science.1145183
   POTTER MC, 1993, MEM COGNITION, V21, P156, DOI 10.3758/BF03202727
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   SAGI D, 1985, SCIENCE, V228, P1217, DOI 10.1126/science.4001937
   Scialfa CT, 1998, PERCEPT PSYCHOPHYS, V60, P1067, DOI 10.3758/BF03211940
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Summala H, 1996, HUM FACTORS, V38, P442, DOI 10.1518/001872096778701944
   SWELLER J, 1990, J EXP PSYCHOL GEN, V119, P176, DOI 10.1037/0096-3445.119.2.176
   Thibos LN, 1998, OPTOMETRY VISION SCI, V75, P399, DOI 10.1097/00006324-199806000-00024
   Thornton TL, 2007, PSYCHOL REV, V114, P71, DOI 10.1037/0033-295X.114.1.71
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   TOWNSEND JT, 1990, PSYCHOL SCI, V1, P46, DOI 10.1111/j.1467-9280.1990.tb00067.x
   TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TVERSKY B, 1989, J EXP PSYCHOL GEN, V118, P387, DOI 10.1037/0096-3445.118.4.387
   Ungerleider L.G., 1982, ANAL VISUAL BEHAV, P549, DOI DOI 10.2139/SSRN.1353746
   Van den Berg R, 2008, ACM T APPL PERCEPT, V4, DOI 10.1145/1278760.1278763
   VECERA SP, 1994, J EXP PSYCHOL GEN, V123, P146, DOI 10.1037/0096-3445.123.2.146
   VIRSU V, 1979, EXP BRAIN RES, V37, P475
   VIVIANI P, 1982, J EXP PSYCHOL HUMAN, V8, P113, DOI 10.1037/0096-1523.8.1.113
   Wainer H., 1988, Chance, V1, P10
   Ware C, 2008, IEEE COMPUT GRAPH, V28, P6, DOI 10.1109/MCG.2008.39
   Wickens C.D., 1999, Engineering Psychology and Human Performance, V3rd
   Williams DE, 1997, CAN J EXP PSYCHOL, V51, P151, DOI 10.1037/1196-1961.51.2.151
   Williams DE, 2001, PSYCHON B REV, V8, P476, DOI 10.3758/BF03196182
   WILLIAMS LG, 1966, PERCEPT PSYCHOPHYS, V1, P315, DOI 10.3758/BF03215795
   Wolfe JM, 1998, PSYCHOL SCI, V9, P33, DOI 10.1111/1467-9280.00006
   WONG E, 1981, ACTA PSYCHOL, V48, P123, DOI 10.1016/0001-6918(81)90054-8
   YANTIS S, 1984, J EXP PSYCHOL HUMAN, V10, P601, DOI 10.1037/0096-1523.10.5.601
   Zelinsky GJ, 1997, J EXP PSYCHOL HUMAN, V23, P244, DOI 10.1037/0096-1523.23.1.244
NR 106
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 880
EP 888
DI 10.1016/j.jvcir.2010.08.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 675JV
UT WOS:000283827500012
DA 2024-07-18
ER

PT J
AU Fu, CH
   Lee, TK
   Chan, YL
   Siu, WC
AF Fu, Chang-Hong
   Lee, Tsz-Kwan
   Chan, Yui-Lam
   Siu, Wan-Chi
TI An efficient motion vector composition algorithm for fast-forward
   playback in a video streaming system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital video browsing; Digital video cassette recording; Fast-forward
   playback; Frame-skipping video transcoding; Forward dominant vector
   selection; Motion re-estimation; Digital video coding; Motion vector
   composition
ID FRAME-SKIPPING TRANSCODER; MPEG VIDEO; VCR FUNCTIONALITIES;
   ARCHITECTURE; SUPPORT
AB Fast-forward playback enables viewers to scan through the video scene of interest efficiently. One approach to realize fast-forward playback is to employ a frame-skipping transcoder which transcodes only the frames required for playback at the desired fast speed. Various motion vector composition algorithms are used to compose the new motion vectors with reduced complexity. These algorithms do not work well for dropping a large number of frames, which is very common in fast-forward playback. In this paper, a new multiple-candidate vector selection algorithm (MCVS) is proposed to select a composed motion vector from a set of candidate motion vectors, which utilizes relevant areas in the target macroblock to ensure a reliable tracking process for motion vector composition. Experimental results show that the proposed MCVS can provide fast-forward playback through video transcoding with significant gain, in terms of rate-distortion performance, especially when a large speed-up factor is required. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Fu, Chang-Hong; Lee, Tsz-Kwan; Chan, Yui-Lam; Siu, Wan-Chi] Hong Kong Polytech Univ, Ctr Signal Proc, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Chan, YL (corresponding author), Hong Kong Polytech Univ, Ctr Signal Proc, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
EM enylchan@polyu.edu.hk
RI Fu, Chang-Hong/AAR-7176-2021; Chan, Yui-Lam/C-3799-2014
OI Fu, Chang-Hong/0000-0001-8221-2311; Lee, Tsz-Kwan/0000-0003-4176-2215;
   Chan, Yui-Lam/0000-0002-1473-094X
FU Centre for Signal Processing, Department of Electronic and Information
   Engineering, Hong Kong Polytechnic University; Research Grants Council
   of the Hong Kong Special Administrative Region, China [PolyU 5120/07E]
FX The work described in this paper is partially supported by the Centre
   for Signal Processing, Department of Electronic and Information
   Engineering, Hong Kong Polytechnic University and a grant from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China (PolyU 5120/07E). Tsz-Kwan Lee acknowledges the research
   studentships provided by the University.
CR [Anonymous], 1996, 138182 ISOIEC
   [Anonymous], 2003, 1499610 ISOIEC
   Fu CH, 2006, IEEE T CIRC SYST VID, V16, P19, DOI 10.1109/TCSVT.2005.856901
   Fu CH, 2007, IEEE T IMAGE PROCESS, V16, P2169, DOI 10.1109/TIP.2007.902330
   Fung KT, 2004, IEEE T MULTIMEDIA, V6, P31, DOI 10.1109/TMM.2003.819761
   Fung KT, 2002, IEEE T IMAGE PROCESS, V11, P886, DOI 10.1109/TIP.2002.800890
   Huang CM, 2005, IEEE T CIRCUITS-II, V52, P384, DOI 10.1109/TCSII.2005.850407
   Huang SY, 2003, IEEE T CONSUM ELECTR, V49, P1153, DOI 10.1109/TCE.2003.1261211
   Hwang JN, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P616, DOI 10.1109/MMSP.1998.739049
   Ip TP, 2008, IEEE T BROADCAST, V54, P412, DOI 10.1109/TBC.2008.2000289
   *ISO IEC, 2001, 149962 ISO IEC
   *ISO IEC, 1993, 111722 ISOIEC
   *ITU T, 1997, H263 ITUT
   *JVT, JVT REF SOFTW JM9 2
   Lin CW, 2001, IEEE T CIRC SYST VID, V11, P415, DOI 10.1109/76.911165
   McManus JM, 1996, IEEE J SEL AREA COMM, V14, P1087, DOI 10.1109/49.508280
   Omoigui N., 1999, P SIGCHI C HUMAN FAC, P136
   Tan YP, 2002, IEEE IMAGE PROC, P713
   TAN YP, 2003, IEEE T CONSUM ELECTR, V29, P1098
   WEE SJ, 1998, P SPIE C MULT SYST A, P237
   YANG S, 2005, P INT C IM PROC ICIP
   YOUN J, 1999, ISCAS 99, V4, P243
   Youn J, 1999, IEEE T MULTIMEDIA, V1, P30, DOI 10.1109/6046.748169
NR 23
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 939
EP 947
DI 10.1016/j.jvcir.2010.09.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500017
DA 2024-07-18
ER

PT J
AU Li, XG
   Lam, KM
   Qiu, GP
   Shen, LS
   Wang, SY
AF Li, Xiaoguang
   Lam, Kin Man
   Qiu, Guoping
   Shen, Lansun
   Wang, Suyu
TI Example-based image super-resolution with class-specific predictors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Example-based super-resolution; Human face magnification; Content-based
   encoding; Class-specific predictor; Self-specific training set;
   Domain-specific training set; General-purpose training set; Vector
   quantization
ID MAGNIFICATION; ALGORITHM
AB Example-based super-resolution is a promising approach to solving the image super-resolution problem. However, the learning process can be slow and prediction can be inaccurate. In this paper, we present a novel learning-based algorithm for image super-resolution to improve the computational speed and prediction accuracy. Our new method classifies image patches into several classes, for each class, a class-specific predictor is designed. A class-specific predictor takes a low-resolution image patch as input and predicts a corresponding high-resolution patch as output. The performances of the class-specific predictors are evaluated using different datasets formed by face images and natural-scene images. We present experimental results which demonstrate that the new method provides improved performances over existing methods. (C) 2009 Published by Elsevier Inc.
C1 [Li, Xiaoguang; Lam, Kin Man] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
   [Li, Xiaoguang; Shen, Lansun; Wang, Suyu] Beijing Univ Technol, Signal & Informat Proc Lab, Beijing 100124, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
C3 Hong Kong Polytechnic University; Beijing University of Technology;
   University of Nottingham
RP Lam, KM (corresponding author), Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
EM enkmlam@polyu.edu.hk
RI Kan, Kin-Man/A-9352-2014
OI Kan, Kin-Man/0000-0002-0422-8454; Qiu, Guoping/0000-0002-5877-5648;
   Wang, Suyu/0000-0001-6004-8661
FU Council of the Hong Kong Special Administrative Region, China [PolyU
   5199/06E]; National Nature Science Foundation of China [60472036,
   60431020, 60402036]; Foundation of Ministry of Education [20040005015]
FX This work was supported by a grant from the Research Grants Council of
   the Hong Kong Special Administrative Region, China (Project No. PolyU
   5199/06E), and by the National Nature Science Foundation of China
   (60472036, 60431020, 60402036), Ph. D. Foundation of Ministry of
   Education (20040005015).
CR Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Baker S, 2000, PROC CVPR IEEE, P372, DOI 10.1109/CVPR.2000.854852
   Chantas GK, 2007, IEEE T IMAGE PROCESS, V16, P1821, DOI 10.1109/TIP.2007.896664
   CHEN M, P 2005 INT S INT SIG, P77
   Ebrahimi M, 2007, LECT NOTES COMPUT SC, V4633, P117
   ELAD M, 2007, COMPUTER J ADV ACCES, V20
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   He H, 2006, IEEE T IMAGE PROCESS, V15, P592, DOI 10.1109/TIP.2005.860599
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Qiu GP, 2000, J VIS COMMUN IMAGE R, V11, P360, DOI [10.1006/jvci.2000.0451, 10.1006/jvci.1999.0451]
   Qiu GP, 1999, IEEE T IMAGE PROCESS, V8, P109, DOI 10.1109/83.736699
   Samaria F. S., 1994, P 2 IEEE WORKSH APPL
   Stephenson TA, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/31062
   Wang Q., 2005, P 10 IEEE INT C COMP
   Zhang XL, 2008, IMAGE VISION COMPUT, V26, P1277, DOI 10.1016/j.imavis.2008.03.003
NR 19
TC 38
Z9 55
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2009
VL 20
IS 5
BP 312
EP 322
DI 10.1016/j.jvcir.2009.03.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 547LX
UT WOS:000273891500002
DA 2024-07-18
ER

PT J
AU Kuschnig, R
   Kofler, I
   Ransburg, M
   Hellwagner, H
AF Kuschnig, Robert
   Kofler, Ingo
   Ransburg, Michael
   Hellwagner, Hermann
TI Design options and comparison of in-network H.264/SVC adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable video coding (H.264/SVC); In-network adaptation; RTP/RTSP MANE;
   MPEG-21 Digital Item Adaptation (DIA); Generic Bitstream Syntax
   Description (gBSD)
ID TRANSPORT; SYSTEM
AB This paper explores design options and evaluates implementations of in-network, RTP/RTSP based adaptation MANEs (Media Aware Network Elements) for H.264/SVC content streaming. The obvious technique to be employed by such an adaptation MANE is to perform SVC specific bitstream, extraction or truncation. Another mechanism that can be used is description (metadata) driven, coding format independent adaptation based on generic Bitstream Syntax Descriptions (gBSD), as specified within MPEG-21 Digital Item Adaptation (DIA). Adaptation MANE architectures for both approaches are developed and presented, implemented in end-to-end streaming/adaptation prototype systems, and experimentally evaluated and compared. For the gBSD based solution, open issues like the granularity of bitstream descriptions and of bitstream adaptation, metadata overhead, metadata packetization and transport options, and error resilience in case of metadata losses, are addressed. The experimental results indicate that a simple SVC specific adaptation MANE does clearly outperform the gBSD based adaptation variants. Yet, the conceptual advantages of the description driven approach, like coding format independence and flexibility, may outweigh the performance drawbacks in specific applications. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Kuschnig, Robert; Kofler, Ingo; Ransburg, Michael; Hellwagner, Hermann] Klagenfurt Univ, Inst Informat Technol, A-9020 Klagenfurt, Austria.
C3 University of Klagenfurt
RP Hellwagner, H (corresponding author), Klagenfurt Univ, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM hermann.hellwagner@uni-klu.ac.at
OI Hellwagner, Hermann/0000-0003-1114-2584
FU Austrian Science Fund (FWF)
FX This work was supported by the Austrian Science Fund (FWF) under project
CR [Anonymous], 2005, 3984 RFC IETF
   *AP SOFTW FDN, XERC C PARS
   *APPL INC, DARW OP SOURC STREAM
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   *COD SYNTH TOOLS, CODSYNTHESIS XSD XML
   De Schrijver D, 2007, J VIS COMMUN IMAGE R, V18, P217, DOI 10.1016/j.jvcir.2007.02.003
   De Schrijver D, 2006, MULTIMEDIA SYST, V11, P403, DOI 10.1007/s00530-006-0021-5
   *GNOME PROJ, XML C PARS TOOLK GNO
   Handley M, 2006, 4566 RFC
   *ISO IEC, 2002, 1593812002 ISOIEC 1
   *JVT, 2007, JVTX202
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   Kofler I., 2008, P ACM INT WORKSHOP N, P63, DOI DOI 10.1145/1496046.1496061
   KOFLER I, 2007, P 14 SPIE ANN EL IM
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Live networks inc, LIVE555 STREAM MED
   MCCANNE TS, 1996, P 1996 ACM C APPL TE, P117
   Pereira F, 2005, IEEE T MULTIMEDIA, V7, P397, DOI 10.1109/TMM.2005.846773
   Ransburg M, 2005, 2005 1ST INTERNATIONAL CONFERENCE ON MULTIMEDIA SERIVCES ACCESS NETWORKS, P25, DOI 10.1109/MSAN.2005.1489936
   RANSBURG M, 2007, P 8 INT WORKSH IM AN, P83
   RANSBURG M, 2007, P 6 WORKSH MULT SEM, P117
   RANSBURG M, 2006, P 1 EUR S MOB MED DE
   SCHIERL T, 2008, SIGNALING MEDIA DECO
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H., 1998, 2326 RFC
   SCHWARZ H, 2006, P 2006 IEEE INT C MU
   Seward J., BZIP2
   Timmerer C, 2005, IEEE INT SYM MULTIM, P534
   TIMMERER C, 2007, 2100072007 ISOIEC 7
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   VETRO A, 2003, IEEE SIGNAL PROCESSI, V20
   Wang YK, 2007, IEEE T CIRC SYST VID, V17, P1149, DOI 10.1109/TCSVT.2007.906827
   WENGER S, 1999, Q15116R1 VID COD EXP
   WENGER S, 2008, RTP PAYLOAD FORMAT S
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
   Wiegand T., 2007, 14496102005AMD3 ISOI
   WIEGAND T, 2007, IEEE T CIRCUITS SYST, V17
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1227, DOI 10.1109/TCSVT.2007.905519
   *XSLT, 1999, 1 0 W3C REC
NR 39
TC 21
Z9 21
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 529
EP 542
DI 10.1016/j.jvcir.2008.07.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300007
DA 2024-07-18
ER

PT J
AU Schierl, T
   Johansen, S
   Perkis, A
   Wiegand, T
AF Schierl, T.
   Johansen, S.
   Perkis, A.
   Wiegand, T.
TI Rateless scalable video coding for overlay multisource streaming in
   MANETs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Channel coding; Scalable video coding; Distributed streaming; Network
   reliability; Rate allocation; Mobile Ad Hoc Networks
ID NETWORKS; CHANNELS
AB Recent advances in forward error correction and scalable video coding enable new approaches for robust, distributed streaming in Mobile Ad Hoc Networks (MANETs). This paper presents an approach for distribution of real time video by uncoordinated peer-to-peer relay or source nodes in an overlay network on top of a MANET. The approach proposed here allows for distributed, rate-distortion optimized transmission-rate allocation for competing scalable video streams at relay nodes in the overlay network. The approach has the desirable feature of path/source diversity that can be used for enhancing reliability in connectivity to serving nodes and/or attaining a higher throughput. The distributed approach reduces signaling overhead as well as avoiding scalability issues that come with centralized processing in MANETs. Results show a significant performance gain over both single-server systems and previously proposed multi-source systems. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Schierl, T.; Wiegand, T.] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, D-10587 Berlin, Germany.
   [Johansen, S.; Perkis, A.] Norwegian Univ Sci & Technol, Ctr Quantifiable Qual Serv Commun Syst, N-7034 Trondheim, Norway.
C3 Fraunhofer Gesellschaft; Norwegian University of Science & Technology
   (NTNU)
RP Schierl, T (corresponding author), Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Berlin, Germany.
EM schierl@hhi.fhg.de; stianjo@q2s.ntnu.no; andrew@q2s.ntnu.no;
   wiegand@hhi.fhg.de
RI Perkis, Andrew/AAI-4792-2020
OI Perkis, Andrew/0000-0003-1414-2870
CR Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   [Anonymous], 2003, PROC IPTPS
   [Anonymous], 80216 IEEE
   [Anonymous], 2007, 26346 3GPP TS
   BAI F, 2003, IMPORTANT FRAMEWORK
   CHOU PA, 2001, MSRTR200135 MICR RES
   IEEE, 2007, P80211 IEEE
   *IETF, IETF MOB ADHOC NETW
   *IETF, 2006, 3626 IETF RFC
   *INF SCI I U SO CA, NETW SIM
   *ISO IEC, 2005, 8802112005 ISOIEC
   *ITU T ISO IEC, 2008, H264 ITU T ISO IEC
   *JOINT VID TEAM, JSVM SOFTW REP CVS
   Jurca D., 2007, IEEE T MULTIMEDIA, V9
   Luby M, 2007, IEEE T BROADCAST, V53, P235, DOI 10.1109/TBC.2007.891703
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   NGUYEN T, 2002, P PACK VID WORKSH AP
   PURI R, 2000, P PACK VID WORKSH 00
   SCHIERL T, 2006, IEEE WIRELESS COMMUN, V13
   SCHIERL T, 2007, P ICIP 07 SAN ANT TX
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Stockhammer T, 2007, WIREL COMMUN MOB COM, V7, P235, DOI 10.1002/wcm.476
   WAGNER JP, 2006, P ICME 06 TOR ON CAN
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
   Zhang M., 2005, P ACM MULTIMEDIA, P287, DOI DOI 10.1145/1101149.1101206
   ZHANG X, 2005, P IEEE INF MIAM US F
   ZHU X, 2007, P INT S MULT OV WIR
NR 28
TC 16
Z9 17
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 500
EP 507
DI 10.1016/j.jvcir.2008.06.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300004
DA 2024-07-18
ER

PT J
AU Pallavi, V
   Mukherjee, J
   Majumdar, AK
   Sural, S
AF Pallavi, V.
   Mukherjee, Jayanta
   Majumdar, Arun K.
   Sural, Shamik
TI Ball detection from broadcast soccer videos using static and dynamic
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shot classification; Soccer analysis; Ball detection; Trajectory;
   Dynamic programming
ID TRACKING
AB In this paper, we propose an approach for detecting ball in broadcast soccer videos. We use hybrid techniques for identifying ball in medium and long shots. Candidate ball positions are first extracted using features based on shape and size. For medium shots, a ball is identified by filtering the candidates with the help of motion information. In long shots, after motion based filtering of the non-ball candidates, a directed weighted graph is constructed for the remaining ball candidates. Each node in the graph represents a candidate and each edge links candidates in a frame with the candidates in next two consecutive frames. Finally, dynamic programming is applied to find the longest path of the graph, which gives the actual ball trajectory. Experiments with several soccer sequences show that the proposed approach is very efficient. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Pallavi, V.; Mukherjee, Jayanta; Majumdar, Arun K.] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Sural, Shamik] Indian Inst Technol, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Pallavi, V (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Near IIT Gate 5, Kharagpur 721302, W Bengal, India.
EM pallavi@cse.iitkgp.ernet.in; jay@cse.iitkgp.ernet.in;
   akmj@cse.iitkgp.ernet.in; shamik@sit.iitkgp.erne-t.in
RI Sural, Shamik/C-1394-2011
OI Sural, Shamik/0000-0002-4315-7329
FU Department of Science and Technology, India [SR/S3/EECE/024/2003]
FX This work has been supported by research grants from Department of
   Science and Technology, India under Grant No: SR/S3/EECE/024/2003. We
   are thankful to Dawei Liang and Yang Liu of School of Computer Science
   and Technology, Harbin Institute of Technology, China for providing
   their video data to us.
CR ALSUWAIYEL MH, 1999, ALGORITHMS DESIGN TE, V7, P205
   D'Orazio T, 2004, PATTERN RECOGN, V37, P393, DOI 10.1016/S0031-3203(03)00228-0
   D'Orazio T, 2002, INT C PATT RECOG, P210, DOI 10.1109/ICPR.2002.1044654
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Kim T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P721, DOI 10.1109/ICCV.1998.710797
   LEO M, 2005, ICGST INT J GRAPHICS, V1, P53
   Liang DW, 2005, LECT NOTES COMPUT SC, V3767, P864
   PALLAVI V, 2006, P REC TRENDS INF SYS, V1, P216
   SEO Y, 1997, P 9 INT C IM AN PROC, V2, P96
   Tong XF, 2004, INT C PATT RECOG, P795, DOI 10.1109/ICPR.2004.1333892
   Yamada A, 2002, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2002.1044697
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
NR 14
TC 32
Z9 38
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2008
VL 19
IS 7
BP 426
EP 436
DI 10.1016/j.jvcir.2008.06.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 363NU
UT WOS:000260274800002
DA 2024-07-18
ER

PT J
AU Chang, JF
   Leou, IJ
AF Chang, Jing-Fu
   Leou, Jin-Jang
TI A quadratic prediction based fractional-pixel motion estimation
   algorithm for H.264
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE quadratic prediction; fractional-pixel motion estimation; center biased
   fractional-pixel search; small diamond search pattern
ID SUCCESSIVE ELIMINATION ALGORITHM; SEARCH ALGORITHM
AB Motion estimation (ME) and compensation is the most important technique in video coding. In H.264, the motion vector (MV) of a variable size block is determined by performing the ME search procedure on integer-pixel positions, followed by fractional-pixel refinement. For fast integer-pixel ME algorithms, on the average, ME can be done by examining less than 5 search positions. Considering the conventional fractional-pixel ME algorithm, 8, 16, and 24 fractional-pixel search positions are required to be examined for the best MV at 1/2-, 1/4-, and 1/8-pixel accuracy, respectively. That is, the computational complexity of fractional-pixel ME becomes comparable to that of fast integer-pixel ME. Therefore, to develop an efficient fractional-pixel ME algorithm is greatly desirable. In this study, a fast fractional-pixel ME algorithm is proposed. In this study, a "degenerate" quadratic function is used to precisely determine the "best" quantized predictive motion vector (PMV) at 1/4-pixel accuracy for a variable size block. Based on the partial probability distributions of the sum of absolute component differences between the best MV at 1/4-pixel accuracy determined by the conventional 2-stage full search ME search algorithm and the "best" quantized PMV determined by the proposed algorithm, the search range of local fraction-pixel ME can be well determined. If the best quantized PMV determined by the proposed algorithm and that determined by the center biased fractional-pixel search algorithm are identically (0, 0), then (0, 0) is directly determined as the MV at 1/4-pixel accuracy for the variable size block, without applying the small diamond search pattern (SDSP). Otherwise, the SDSP at 1/4-pixel accuracy is used to determine the final result and the SDSP will be applied at most three times. Based on the experimental results obtained in this study, the four ME performance measures of the proposed algorithm are better than that of four comparison approaches, with slight degradations in average PSNR and bit rate. (c) 2006 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Leou, IJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM jjleou@cs.ccu.edu.tw
CR [Anonymous], 1981, P NAT TEL C NEW ORL
   Banh XQ, 2004, IEEE T CONSUM ELECTR, V50, P766, DOI 10.1109/TCE.2004.1309460
   Brünig M, 2001, IEEE T CIRC SYST VID, V11, P241, DOI 10.1109/76.905989
   Chalidabhongse J, 1997, IEEE T CIRC SYST VID, V7, P477, DOI 10.1109/76.585927
   CHEN MJ, 1994, IEEE T CIRC SYST VID, V4, P504, DOI 10.1109/76.322998
   Chen YS, 2001, IEEE T IMAGE PROCESS, V10, P1212, DOI 10.1109/83.935037
   CHEN Z, 2002, IEEE INT S CIRC SYST, V3, P26
   CHEN Z, 2002, PREDICTION BASED REF
   CHEN Z, 2002, 6 M AW ISL JAP DEC
   Cheung CK, 2000, IEEE T CIRC SYST VID, V10, P417, DOI 10.1109/76.836286
   Choi WI, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P371
   Du C, 2003, IEEE T CIRC SYST VID, V13, P514, DOI 10.1109/TCSVT.2003.813416
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Kim HS, 2003, INT J MECH SCI, V45, P1999, DOI 10.1016/j.ijmecsci.2004.02.002
   KWON DN, 2003, P IEEE INT C SIGN PR, V1, P73
   Lee KH, 2000, ELECTRON LETT, V36, P625, DOI 10.1049/el:20000529
   Lee YG, 2003, P SOC PHOTO-OPT INS, V5150, P1513, DOI 10.1117/12.502977
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Li XM, 1996, IEEE T CIRC SYST VID, V6, P118, DOI 10.1109/76.486427
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   PO LM, 1995, IEEE INT C IM PROC, V1, P410
   Shi YQ, 1997, IEEE T CIRC SYST VID, V7, P437, DOI 10.1109/76.564124
   SRINIVASAN R, 1985, IEEE T COMMUN, V33, P888, DOI 10.1109/TCOM.1985.1096398
   SUN M, 2001, COMPRESSED VIDEO OVE
   Xu JB, 1999, IEEE T CIRC SYST VID, V9, P1025, DOI 10.1109/76.795056
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   2003, H 264 DRAFT ITU T RE
NR 28
TC 14
Z9 18
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1074
EP 1089
DI 10.1016/j.jvcir.2006.01.001
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700009
DA 2024-07-18
ER

PT J
AU Song, BC
   Ra, JB
AF Song, Byung Cheol
   Ra, Jong Beom
TI Fast exhaustive multi-resolution search algorithm based on clustering
   for efficient image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE exhaustive search; K-means clustering; multi-resolution feature
ID FEATURES
AB To find the best match for a query according to a certain similarity measure, this paper presents a fast exhaustive multi-resolution search algorithm based on image database clustering. Prior to search process, the whole image dataset is partitioned into a pre-defined number of clusters having similar feature contents. For a given query, the proposed algorithm first checks the lower bound of distances in each cluster, eliminating disqualified clusters. Next, it only examines the candidates in the surviving clusters through feature matching. To alleviate unnecessary feature-matching operations in the search procedure, the distance inequality property based on a multi-resolution data structure is employed. Simulation results show that the proposed algorithm guarantees very rapid exhaustive search. (c) 2005 Elsevier Inc. All rights reserved.
C1 Samsung Elect Co Ltd, Digital Media R&D Ctr, Suwon, South Korea.
   Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea.
C3 Samsung; Samsung Electronics; Korea Advanced Institute of Science &
   Technology (KAIST)
RP Song, BC (corresponding author), Samsung Elect Co Ltd, Digital Media R&D Ctr, Suwon, South Korea.
EM bcsong@samsung.com
RI Beom, Jong/C-1958-2011
CR Abdel-Mottaleb M, 2004, IEEE T MULTIMEDIA, V6, P459, DOI 10.1109/TMM.2004.827500
   Berman A, 1997, P SOC PHOTO-OPT INS, V3022, P12, DOI 10.1117/12.263409
   Berman AP, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P55, DOI 10.1109/IVL.1999.781124
   CHEUNG CH, 2003, IEEE INT C AC SPEECH, V3, P601
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   *ISO IEC, 1998, JTC1SC29WG11N2466 IS
   JAIN P, 2003, IEEE TENCON, V2, P581
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   KLEINBERG JM, 1997, P 29 STOC
   Krishnamachari S., 1999, PROC ISTSPIE C STORA, P427
   LEE CH, 1995, IEEE T COMMUN, V43, P1697, DOI 10.1109/26.380218
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   OTTERMAN M, 1992, APPROXIMATE MATCHING
   Pei SC, 1999, IEEE T CIRC SYST VID, V9, P501, DOI 10.1109/76.754779
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
NR 19
TC 1
Z9 1
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 98
EP 106
DI 10.1016/j.jvcir.2005.07.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900006
DA 2024-07-18
ER

PT J
AU Lan, JQ
   Zeng, WJ
   Zhuang, XH
AF Lan, JQ
   Zeng, WJ
   Zhuang, XH
TI Operational distortion-quantization curve-based bit allocation for
   smooth video quality
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE bit allocation; rate control; video coding; video streaming; smooth
   quality; operational distortion-quantization
ID SOURCE MODEL; VBR VIDEO
AB Quality fluctuation has a major negative effect oil subjective video quality. A desirable single-pass frame-level constant-distortion bit allocation scheme is proposed in the paper for smooth video quality throughout the video sequence. The average distortion of all previous coded frames is taken as the target distortion for the current frame. According to the linear rate control algorithm [Z. He, S.K. Mitra, A linear source model and a unified rate control algorithm for DCT video coding, IEEE Trans. Circuits Syst. Video Technol. 12 (2002) 970982; Z. He, S.K. Mitra, Optimum bit allocation and accurate rate control for video coding via p domain source modeling, IEEE Trans. Circuits Syst. Video Technol. 12 (2002) 840849], the distortion and rate are exponential and linear functions of the number of zero coefficients, respectively. Based oil the distribution of the absolute DCT coefficients, an operational distortion-quantization stepsize (D-Q) relationship curve can be established quickly. With the target distortion and operational D-Q curve, we then derive the close-form formulas for estimating the number of zero coefficients and tile slope 0 in the linear rate model, as well as the bit budget for the current frame. Experimental results show that the proposed constant-distortion (but variable rate) bit allocation scheme provides much smoother video quality on all test video sequences than the constant bit allocation scheme that has been used in many standard video coding reference software. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
C3 University of Missouri System; University of Missouri Columbia
RP Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
EM jl629@mizzou.edu; zengw@missouri.edu; zhuangx@missouri.edu
CR Assunçao PAA, 2000, IEEE T CIRC SYST VID, V10, P83, DOI 10.1109/76.825863
   Bai JF, 2002, SIGNAL PROCESS-IMAGE, V17, P187, DOI 10.1016/S0923-5965(01)00015-7
   CHEN T, 2003, INT C MULT EXP BALT
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Côté G, 1998, IEEE T CIRC SYST VID, V8, P849, DOI 10.1109/76.735381
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   FRIMOUT ED, 1993, P SOC PHOTO-OPT INS, V2094, P184, DOI 10.1117/12.157936
   Hang HM, 1997, IEEE T CIRC SYST VID, V7, P287
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P970, DOI 10.1109/TCSVT.2002.805511
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   *ISO IEC, 1998, 144962 ISOIEC
   *ISO IEC, 1997, 14 ISOIEC
   *ITU T, 1997, SG16QUK ITUT VID COD
   Lin LJ, 1998, IEEE T CIRC SYST VID, V8, P446, DOI 10.1109/76.709411
   LIN LJ, 1996, SPIE VISUAL COMMUNIC, P111
   MOHAWNIAN N, 1999, IBM J RES DEV, V43, P489
   ORTEGA A, 1994, IEEE T IMAGE PROCESS, V3, P26, DOI 10.1109/83.265978
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P533, DOI 10.1109/83.334987
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Ronda JI, 1999, IEEE T CIRC SYST VID, V9, P1243, DOI 10.1109/76.809159
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   SMOOT SR, 1996, P SPIE S EL IM SAN J, V2657
   Westerink PH, 1999, IBM J RES DEV, V43, P471, DOI 10.1147/rd.434.0471
   XIE B, 2002, P 2002 INT C IM PROC
   Yang Y, 2001, IEEE T CIRC SYST VID, V11, P1045, DOI 10.1109/76.946521
   1993, ISOIECJTC1SC29WG11N0
NR 27
TC 4
Z9 4
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 527
EP 543
DI 10.1016/j.jvcir.2004.11.013
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600009
DA 2024-07-18
ER

PT J
AU Lee, S
   Bovik, AC
   Kim, YY
AF Lee, S
   Bovik, AC
   Kim, YY
TI High quality, low delay foveated visual communications over mobile
   channels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE foveated visual communications; foveated video; wireless video;
   foveation; video compression; image compression; digital video; rate
   control
ID VIDEO; COMPRESSION
AB Foveated video streams are created by selectively varying the spatio-temporal resolution of video data according to the assumed or measured fixation patterns of the intended viewers. The significant potential of foveated video lies in the considerable entropy reduction relative to the original video data while minimizing the loss of apparent visual information. By exploiting new human-machine interface techniques, such as visual eyetrackers, combined with foveated video compression and communication protocols, more efficient visual multimedia services operating over low bandwidths should become available in the near future. In this paper, we introduce a prototype foveated visual communication system suitable for implementation as a core element of an interactive multimedia wireless communication environment. We demonstrate the benefit of using foveation in noisy wireless low bandwidth applications, using measured fading statistics from the downtown area of Austin, Texas as an example. Based on a maximum source throughput criterion, the source and channel video transmission rates and the target video coding bit rate are adaptively decided according to the channel dynamics. In the simulations, we use the channel throughput, the spatial/temporal resolution, and the transmission delay as criteria to compare the performance of the foveated approach relative to normal (non-foveated) video. The results clearly underline the significant potential of foveated video communication protocols for wireless multimedia applications. (c) 2004 Elsevier Inc. All rights reserved.
C1 Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
   Univ Texas, Austin, TX 78712 USA.
C3 Yonsei University; University of Texas System; University of Texas
   Austin
RP Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
EM slee@yonsei.ac.kr; bovik@ece.utexas.edu
RI Lee, Sanghoon/A-3430-2019; Bovik, Alan/B-6717-2012
OI Lee, Sanghoon/0000-0001-9895-5347; Bovik, Alan/0000-0001-6067-710X
CR [Anonymous], 1996, WIRELESS COMMUNICATI
   Ebrahimi T, 1998, P IEEE, V86, P1109, DOI 10.1109/5.687832
   GEISLER WS, 1998, SPIE P, P3299
   HARTUNG J, 1998, IEEE J SELECTED AREA, V16
   Iun EVH, 1997, ICC'97: 1997 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS - TOWARDS THE KNOWLEDGE MILLENNIUM, CONFERENCE RECORD - VOLS 1-3, P164, DOI 10.1109/ICC.1997.605183
   JAFARKHANI H, 1996, P IEEE VTC 96 APR, P492
   JAKES WC, 1974, MACROWAVE MOBILE COM
   Khan M.A., 1996, Investigation on Biomonitoring and Ecorestoration Measures in selected stretches of the Rivers Ganga and Yamuna, P1
   Kim YY, 2000, WIREL NETW, V6, P481, DOI 10.1023/A:1019126722962
   Kim YY, 1999, IEEE J SEL AREA COMM, V17, P888, DOI 10.1109/49.768203
   KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184
   Lee S, 2003, IEEE T CIRC SYST VID, V13, P149, DOI 10.1109/TCSVT.2002.808441
   Lee S, 2003, J VLSI SIG PROC SYST, V34, P149, DOI 10.1023/A:1022970707332
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Lee S, 2001, IEEE T IMAGE PROCESS, V10, P977, DOI 10.1109/83.931092
   LEE S, 1998, P IEEE INT C IM PROC, V2, P346
   LEE S, 1998, P ICIP, V2, P365
   LEE S, 1999, FOVEATED VIDEO DEMON
   LEE WCY, 1985, IEEE T VEH TECHNOL, V34, P22, DOI 10.1109/T-VT.1985.24030
   LEE WCY, 1986, IEEE T VEH TECHNOL, V35, P48, DOI 10.1109/T-VT.1986.24070
   LING H, 1997, WIRELESS CHANNEL MOD
   Reeves T. H., 1996, Proceedings ACM Multimedia 96, P231, DOI 10.1145/244130.244218
   REXFORD J, 1997, P INT SMOOTH TECN TR
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Silsbee PL, 1993, IEEE T CIRC SYST VID, V3, P291, DOI 10.1109/76.257218
   Sklar B, 1997, IEEE COMMUN MAG, V35, P102, DOI 10.1109/35.601748
   Sklar B, 1997, IEEE COMMUN MAG, V35, P90, DOI 10.1109/35.601747
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   1997, ITUTSG15
NR 30
TC 9
Z9 13
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2005
VL 16
IS 2
BP 180
EP 211
DI 10.1016/j.jvcir.2004.06.001
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 915VY
UT WOS:000228340700004
DA 2024-07-18
ER

PT J
AU Peter, H
AF Peter, H
TI A visualizing application of line integral convolution techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
AB The line integral convolution (LIC) technique, a texture synthesis technique, has served as a useful method for visualizing vector data. However, a number of shortcomings have been identified in the LIC technique, not the least of which are that the technique is computationally expensive and adopts a more or less brute force approach. This paper presents a modification of the original LIC method which addresses these shortcomings. Our method, although used for visualizing atmospheric vortical flows, is also applicable to other atmospheric phenomena. In our method we employ a particular colouring scheme to unambiguously identify the nature of the vortical flows irrespective of the hemisphere in which they occur. (C) 2004 Published by Elsevier Inc.
C1 Lander Univ, Div Math & Comp Sci, Greenwood, SC 29649 USA.
RP Univ W Indies, Dept Comp Sci Math & Phys, Cave Hill, Barbados.
EM hpeter@uwichill.edu.bb
CR Axler SheldonJay., Linear Algebra Done Right
   CABRAL B, ACM SIGGRAPH, P263
   CHARLERY J, 2000, THESIS U W INDIES BA
   Forssell L. K., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P240, DOI 10.1109/VISUAL.1994.346313
   HELMAN J, IEEE COMPUTER GRAPHI, V11, P36
   HIIN AJS, 1993, P VIS 93, P46
   HULTQUIST JPM, 1992, VISUALIZATION 92 : PROCEEDINGS, P171
   Interrante V, 1997, VISUALIZATION '97 - PROCEEDINGS, P421, DOI 10.1109/VISUAL.1997.663912
   Jobard B, 2000, IEEE VISUAL, P155, DOI 10.1109/VISUAL.2000.885689
   Jobard B, 1997, VISUALIZATION '97 - PROCEEDINGS, P323, DOI 10.1109/VISUAL.1997.663899
   Jobard Bruno., VISUALIZATION SCI CO, P43
   MA KL, 1992, VISUALIZATION 92 : PROCEEDINGS, P46
   MAX N, 1993, VISUALIZATION 93, PROCEEDINGS, P19
   OKADA A, 1996, NAS96007
   Shen HW, 1997, VISUALIZATION '97 - PROCEEDINGS, P317, DOI 10.1109/VISUAL.1997.663898
   SHEN HW, VOL VIS S, P63
   STALLING D, ANN C SERIES ACM, P249
   THEISEL H, COMPUTER AIDED GEOME, V14, P719
   Turk G., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P453, DOI 10.1145/237170.237285
   UENG S, IEEE T VIS COMP GRAP, V2, P100
   VANWIJK JJ, 1991, COMP GRAPH, V25, P309, DOI 10.1145/127719.122751
   VANWIJK JJ, 2002, P ACM SIGGRAPH
   VANWIJK JJ, IEEE COMPUTER GRAPHI, V13, P18
   Wegenkittl R, 1997, VISUALIZATION '97 - PROCEEDINGS, P119
   Wegenkittl R, 1997, COMP ANIM CONF PROC, P15, DOI 10.1109/CA.1997.601035
NR 25
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2004
VL 15
IS 4
BP 548
EP 564
DI 10.1016/j.jvcir.2003.08.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 868OZ
UT WOS:000224924200004
DA 2024-07-18
ER

PT J
AU Kuo, CM
   Hung, MS
AF Kuo, CM
   Hung, MS
TI An effective mesh-based motion compensation technique for video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE BMA; regular non-uniform mesh; motion activity; weight interpolation
   block matching
ID ACTIVE MESH; REPRESENTATION; INTERPOLATION; SCHEME; MPEG
AB The block-matching algorithm is the most popular motion compensation technique in video coding. However, it cannot provide acceptable quality at very low bit rate. In this paper, a new mesh-based motion compensation method is proposed to attack the problem. First, a regular non-uniform mesh, which has regular structure with variable patch size, is presented. The patch size is varied according to motion activity of a video sequence. Next, a weighted interpolation block matching is developed to improve the estimate accuracy of displacements of grid points. It utilizes the motion correlation between a grid point and its associated patches. Finally, based on the new mesh and motion estimation scheme, an efficient motion compensation algorithm is developed. When compared to the conventional motion compensation techniques, the proposed method improves performance significantly with lower computational complexity and overhead information bits. (C) 2003 Elsevier Inc. All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
CR Chiariglione L, 1997, IEEE T CIRC SYST VID, V7, P5, DOI 10.1109/76.554414
   Dudon M, 1997, SIGNAL PROCESS-IMAGE, V10, P21, DOI 10.1016/S0923-5965(97)00017-9
   HUANG CL, 1994, IEEE T CIRC SYST VID, V4, P42, DOI 10.1109/76.276171
   Koenen R, 1997, SIGNAL PROCESS-IMAGE, V9, P295, DOI 10.1016/S0923-5965(97)00003-9
   KUO CM, 1999, 1999 INT C IM PROC I, V2, P639
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   LI HB, 1994, IEEE T IMAGE PROCESS, V3, P589, DOI 10.1109/83.334983
   NAKAYA T, 1991, P SPIC VIS COMM IM P, P546
   NAKAYA Y, 1994, IEEE T CIRC SYST VID, V4, P339, DOI 10.1109/76.305878
   NIEWEGLOWSKI J, 1995, SIGNAL PROCESS-IMAGE, V7, P333, DOI 10.1016/0923-5965(95)00007-5
   NIEWEGLOWSKI J, 1993, IEEE T CONSUM ELECTR, V39, P141, DOI 10.1109/30.234575
   SEFERIDIS V, 1993, OPT ENG, V32, P1464, DOI 10.1117/12.138613
   SULLIVAN GJ, 1991, P IEEE C ASSP, P4713
   Tekalp AM, 1998, P IEEE, V86, P1029, DOI 10.1109/5.687828
   Terzopoulos D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P70, DOI 10.1109/CVPR.1991.139663
   Vasilescu M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P829, DOI 10.1109/CVPR.1992.223247
   Wang Y, 1996, IEEE T CIRC SYST VID, V6, P636
   WANG Y, 1994, IEEE T IMAGE PROCESS, V3, P610, DOI 10.1109/83.334982
   Wang Y, 1996, IEEE T CIRC SYST VID, V6, P647
   Wang Y, 1998, IEEE T CIRC SYST VID, V8, P243, DOI 10.1109/76.678617
   Wolberg G., 1990, Digital image warping
   Yan YP, 1998, J VIS COMMUN IMAGE R, V9, P80, DOI 10.1006/jvci.1998.0372
NR 22
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 405
EP 427
DI 10.1016/S1047-3203(03)00035-X
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800003
DA 2024-07-18
ER

PT J
AU Lai, JZC
   Chen, CC
AF Lai, JZC
   Chen, CC
TI Algorithms of halftoning color images with edge enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID ERROR-DIFFUSION
AB Printers usually generate a limited number of colors and lack the ability of producing continuous-tone color images. Traditional error-diffusion algorithms are used to solve this problem. Compared with other approaches, the approaches of using error-diffusion in general can generate halftoned images of better quality. However, smeared edges and textures may occur in these halftoned images. To produce halftoned images of higher quality, these artifacts due to unstable images, dot-overlap, and error-diffusion must be eliminated or reduced. In this paper, we show that unstable images can be eliminated or reduced through using a proper color difference formula to select the reproduction colors even vector error-diffusion is performed in the RGB domain. We also present a method of using different filters to halftone different components of a color. This approach may have clearer and sharper edges for halftoned color images. Unexpected colors may be generated due to dot-overlap in the printing process. We have presented a method to eliminate this color distortion in the process of error-diffusion. Halftorting a color image by our proposed error-diffusion algorithm with edge enhancement has the following characteristics: the unstable images do not exist; the color-error caused by dot-overlap is corrected; and the smeared edges are sharpened. (C) 2003 Elsevier Inc. All rights reserved.
C1 Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
C3 Feng Chia University
RP Lai, JZC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
CR Akarun L, 1997, IEEE T IMAGE PROCESS, V6, P950, DOI 10.1109/83.597270
   CHAO YM, 1982, THESIS
   DAMERA N, IEEE T IP, V10, P1552
   ESCHBACH R, 1991, J OPT SOC AM A, V8, P1844, DOI 10.1364/JOSAA.8.001844
   HAN WY, J ELECT IMAGING, V6, P198
   KIM JH, 1998, 1998 IPPR C COMP VI, V4, P172
   Lai JZC, 1998, IEEE T IMAGE PROCESS, V7, P1753, DOI 10.1109/83.730390
   MILLER R, 1990, P SPSE 43 ANN M ROCH, P149
   Pappas TN, 1997, IEEE T IMAGE PROCESS, V6, P1014, DOI 10.1109/83.597276
   PAPPAS TN, 1995, IEEE T IMAGE PROCESS, V4, P66, DOI 10.1109/83.350813
   PAPPAS TN, 1992, P SOC PHOTO-OPT INS, V1666, P165, DOI 10.1117/12.135965
   PAPPAS TN, 1993, P ICASSP, V5, P333
   Pratt W. K., DIGITAL IMAGE PROCES
   STOFFEL JC, IEEE T COMMUN, V29, P898
   Ulichney R., DIGITAL HALFTONING
   Zaccarin A, 1993, IEEE T IMAGE PROCESS, V2, P442, DOI 10.1109/83.242354
NR 16
TC 8
Z9 9
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 389
EP 404
DI 10.1016/S1047-3203(03)00041-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800002
DA 2024-07-18
ER

PT J
AU Brun, L
   Domenger, JP
   Mokhtari, M
AF Brun, L
   Domenger, JP
   Mokhtari, M
TI Incremental modifications of segmented image defined by discrete maps
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image segmentation; combinatorial maps; discrete geometry
ID PICTURE SEGMENTATION
AB The data structure used to encode an image partition is of critical importance for most of region-based segmentation algorithms. Usual data structures. are often convenient to extract only few parameters from the partition while inducing complex processing to compute others. Moreover, the split and merge operations allowed by such data structure are often restricted. A new model (Braquelaire and Brun, 1998) based on discrete maps allows segmentation algorithms to perform unrestricted split and merge operations and extract a wide range of parameters from a partition. In this paper we describe the two basic primitives used by segmentation algorithms to modify a partition: the segment insertion and segment suppression. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 IUT Reims, Lab Etud & Rech Informat, F-51059 Reims, France.
   Univ Bordeaux 1, Lab Bordelais Rech Informat, F-33405 Talence, France.
C3 Universite de Reims Champagne-Ardenne; Universite de Bordeaux
RP Brun, L (corresponding author), IUT Reims, Lab Etud & Rech Informat, Rue Crayeres, F-51059 Reims, France.
EM brun@leri.univ-reims.fr; domenger@labri.u-bordeaux.fr;
   myriam@leri.univ-reims.fr
RI Domenger, jean-philippe/AAX-5021-2021
OI Brun, Luc/0000-0002-1658-0527; Domenger,
   Jean-philippe/0000-0001-5398-9340
CR AHRONOVITZ E, 1995, 5 DISCR GEOM COMP IM, P107
   AHUJA N, 1984, IEEE PUBL, P251
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], 1986, COMPUTATIONAL APPROA, DOI DOI 10.1109/TPAMI.1986.4767851
   [Anonymous], 1970, Graphes et hypergraphes
   Berti S, 2001, J PSYCHOPHYSIOL, V15, P64
   Bertrand Y, 1999, LECT NOTES COMPUT SC, V1568, P242
   BRAQUELAIRE JP, 1991, COMPUT GRAPH, V15, P41, DOI 10.1016/0097-8493(91)90029-H
   Braquelaire JP, 1998, J VIS COMMUN IMAGE R, V9, P62, DOI 10.1006/jvci.1998.0374
   Braquelaire JP, 1997, COMPUT GRAPH, V21, P587, DOI 10.1016/S0097-8493(97)00037-X
   BRAQUELAIRE JP, 2001, 3 WORKSH GRAPH BAS R, P32
   Bretto A, 2002, PATTERN RECOGN, V35, P651, DOI 10.1016/S0031-3203(01)00067-X
   Bretto A, 1997, GRAPH MODEL IM PROC, V59, P265, DOI 10.1006/gmip.1997.0437
   BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1
   Brun L, 2000, LECT NOTES COMPUT SC, V1876, P256
   BRUN L, 1996, THESIS U BORDEUX 1
   Brun L., 2000, Proceedings of the 1st International Conference on Color in Graphics and Image Processing, P116
   BRUN L, 1997, P 5 INT C CENTR EUR
   BRYANT RP, 1985, Q J MATH, V36, P17, DOI 10.1093/qmath/36.1.17
   CHASTEL S, 2002, LNCS, V2301, P124
   CHEEVASUVIT F, 1986, COMPUT VISION GRAPH, V34, P268, DOI 10.1016/S0734-189X(86)80042-1
   CORI R, 1975, THESIS U PARIS 7
   CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F
   DAMIAND G, 2002, P COMP VIS WINT WORK, P208
   DAMIAND G, 2002, LNCS, V2301, P220
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   DOMENGER JP, 1992, THESIS LABRI U BORDE
   DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838
   EDMONDS J, 1960, NOTICES AM SOC, V7
   Fiorio C., 1995, THESIS U MONTPELLIER
   FLAJOLET P, 1993, ALGORITHMICA, V10, P473, DOI 10.1007/BF01891833
   GUIGUES L, 2001, 3 WORKSH GRAPH BAS R, P22
   HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956
   JONES GA, 1978, P LOND MATH SOC, V37, P273
   Khalimsky E., 1990, J. Appl. Math. Stochastic Anal, V3, P27
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   KROPATSCH WG, 1998, COMPUTER VISION, P75
   KROPATSCH WG, 1997, ADV COMPUT SCI ADV C, P99
   LEE CH, 1997, PAC C COMP GRAPH APP, V5
   LIENHARDT P, 1989, PROCEEDINGS OF THE FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P228, DOI 10.1145/73833.73859
   LIENHARDT P, 1988, LECTURE NOTES COMPUT, V294, P301
   NICOL CJ, 1995, COMPUT VIS IMAGE UND, V61, P17, DOI 10.1006/cviu.1995.1002
   ROLLAND F, 1991, VISUAL FORM, P443
   Ryan J, 1996, SIAM J DISCRETE MATH, V9, P643, DOI 10.1137/S0895480194270469
   SELMAOUI N, 1997, PATTERN RECOGNITION
   Tutte W.T., 1984, Encyclopedia of Mathematics and its Applications, V21
   VIALARD A, 1996, THESIS U BORDEAUX 1
   Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7
NR 48
TC 14
Z9 15
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 251
EP 290
DI 10.1016/S1047-3203(03)00023-3
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200004
DA 2024-07-18
ER

PT J
AU Chung, KL
   Huang, HL
   Chen, IC
AF Chung, KL
   Huang, HL
   Chen, IC
TI New two-phase spatial data structures with applications to binary images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE connected component; geometric operations; image representation; spatial
   data structures
ID COMPRESSION; BINTREE; TREE
AB Considering a binary image, a new two-phase representation is presented in this paper to reduce the memory requirement in the conventional tree-based spatial data structures (SDSs) such as the linear quadtree, DF-expression, S-tree representation, etc. Experimental results show that not only our proposed two-phase representation has a better memory-saving effect. but it also can speed up the coding-time when compared to the existing SDSs. We also show that our proposed two-phase representation has a better computational performance when running geometric operations, such as computing the area and the centroid, on the proposed two-phase representation directly. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM klchung@cs.ntust.edu.tw
RI Chung, Kuo-Liang/H-6207-2011
CR Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Chung KL, 2000, IEEE T COMMUN, V48, P748, DOI 10.1109/26.843184
   Chung KL, 2002, REAL-TIME IMAGING, V8, P137, DOI 10.1006/rtim.2001.0266
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Distasi R, 1997, IEEE T COMMUN, V45, P1095, DOI 10.1109/26.623074
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   JONGE WD, 1994, CVGIP-IMAG UNDERSTAN, V59, P265
   KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967
   OUKSEL MA, 1992, CVGIP-GRAPH MODEL IM, V54, P75, DOI 10.1016/1049-9652(92)90035-V
   Samet H., 1990, The Design and Analysis of Spatial Data Structures
   SAMET H, 1969, APPL SPATIAL DATA ST
   Serra J., 1982, IMAGE ANAL MATH MORP
   SHAFFER CA, 1993, IMAGE VISION COMPUT, V11, P402, DOI 10.1016/0262-8856(93)90044-H
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
NR 15
TC 1
Z9 6
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2003
VL 14
IS 2
BP 97
EP 113
DI 10.1016/S1047-3203(03)00021-X
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 680AJ
UT WOS:000182953900002
DA 2024-07-18
ER

PT J
AU Song, BS
   Lee, KM
   Lee, SU
   Yun, ID
AF Song, BS
   Lee, KM
   Lee, SU
   Yun, ID
TI 3D target recognition based on projective invariant relationships
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE model-based recognition; target recognition; invariant relationships
ID OBJECT RECOGNITION; POINTS; VIEW
AB In this paper, we propose a new 3D target recognition algorithm using a single image. Our approach is based on geometrically invariant relationships. By employing a practical CCD camera model for projective image formation, and analyzing the constraints on the projection parameters, we derive two invariant relationships using six pairs of 3D space features and corresponding image features, such as points and lines. Compared to the conventional approach in which only a single invariant relationship is derived from six point pairs based on the general finite projective camera model, the two relationships obtained from the practical camera model can increase the effectiveness of matching. Based on the derived invariant relationships, a new view-invariant object recognition algorithm using a single image is proposed. The performance of the proposed recognition algorithm is demonstrated by various computer simulations on synthetic and real images of objects. The experimental results show that 3D objects in the image can be robustly recognized, using the linear features, by the proposed algorithm. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Hongik Univ, Dept Elect & Elect Engn, Seoul, South Korea.
   Seoul Natl Univ, Sch Elect Engn, Seoul 151742, South Korea.
   Hankuk Univ Foreign Studies, Dept Control & Instrumentat Engn, Yongin 449791, South Korea.
C3 Hongik University; Seoul National University (SNU); Hankuk University
   Foreign Studies
RP Lee, KM (corresponding author), Hongik Univ, Dept Elect & Elect Engn, Seoul, South Korea.
EM kmlee@wow.hongik.ac.kr
RI Lee, Kyoung Mu/AAC-4063-2020
OI Lee, Kyoung Mu/0000-0001-7210-1036
CR BARRETT EB, 1991, CVGIP-IMAG UNDERSTAN, V53, P46, DOI 10.1016/1049-9660(91)90004-9
   BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774
   Carlsson S, 1996, INT J COMPUT VISION, V17, P193, DOI 10.1007/BF00058751
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233
   HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P191, DOI 10.1016/0146-664X(80)90046-5
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598
   Mundy J., 1992, GEOMETRIC INVARIANCE
   QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34
   ROTHWELL CA, 1993, P IEEE INT C COMPUTE, P573
   WEISS I, 1993, IEEE T PATTERN ANAL, V15, P943, DOI 10.1109/34.232081
   WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536
   WEISS I, 1998, P 5 EUR C COMP VIS F, P716
   Zhu Y, 1996, IMAGE VISION COMPUT, V14, P179, DOI 10.1016/0262-8856(95)01055-6
NR 15
TC 8
Z9 9
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2003
VL 14
IS 1
BP 1
EP 21
DI 10.1016/S1047-3203(02)00013-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 665TZ
UT WOS:000182138500001
DA 2024-07-18
ER

PT J
AU Duan, XT
   Wu, GM
   Li, C
   Li, Z
   Qin, C
AF Duan, Xintao
   Wu, Guoming
   Li, Chun
   Li, Zhuang
   Qin, Chuan
TI DUIANet: A double layer U-Net image hiding method based on improved
   Inception module and attention mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image hiding; Attention mechanism; Improved Inception module;
   Double-layer U-Net
ID STEGANOGRAPHY
AB Image hiding is the process of hiding secret image into cover image, and revealing secret image from steganographic image. However, the quality of generated images and the ability to resist steganalysis detection of steganographic image can be further improved. We propose a novel double-layer U-Net image hiding method based on improved Inception and attention mechanism. The secret image undergoes Haar wavelet transform, hiding network hides the wavelet sub-band of secret image into cover image. We use improved Inception while cascading convolution and attention mechanisms to better extract and fuse information, resulting in high-quality steganographic image. In the revealing stage, Attention mechanism can help networks extract more features about secret image, then we using inverse Haar wavelet transform to revealing high-quality secret image. The experimental results show that the method can obtain high quality images and have good security. When hiding multiple images, the method still has good performance.
C1 [Duan, Xintao; Wu, Guoming; Li, Chun; Li, Zhuang] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.
   [Duan, Xintao] Henan Normal Univ, Key Lab Fdn Artificial Intelligence & Personalized, Xinxiang 453007, Henan, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 Henan Normal University; Henan Normal University; University of Shanghai
   for Science & Technology
RP Duan, XT (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.
EM duanxintao@htu.edu.cn
OI Duan, xintao/0000-0001-8757-2447
FU National Natural Science Foundation of China [U1904123, 62172280,
   U20B2051]; Key Scientific Research Projects of Colleges and Universities
   in Henan Province [23A520006]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. U1904123, No. 62172280, No.
   U20B2051, in part by the Key Scientific Research Projects of Colleges
   and Universities in Henan Province under Grant No. 23A520006.
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Baluja S, 2017, ADV NEUR IN, V30
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Carvalho T, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P866, DOI 10.1109/ICMLA.2017.00-47
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chefranov AG, 2022, J INF SECUR APPL, V70, DOI 10.1016/j.jisa.2022.103314
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P8497, DOI 10.1007/s11042-016-3452-9
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Das A, 2021, Arxiv, DOI arXiv:2101.00350
   Feng BW, 2017, LECT NOTES COMPUT SC, V10431, P275, DOI 10.1007/978-3-319-64185-0_21
   Guan S, 2020, IEEE J BIOMED HEALTH, V24, P568, DOI 10.1109/JBHI.2019.2912935
   Guan ZY, 2023, IEEE T PATTERN ANAL, V45, P372, DOI 10.1109/TPAMI.2022.3141725
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Imaizumi S, 2014, LECT NOTES COMPUT SC, V8333, P99, DOI 10.1007/978-3-642-53842-1_9
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jing JP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4713, DOI 10.1109/ICCV48922.2021.00469
   Johnson N.F., 2001, Information Hiding: Steganography and Watermarking-Attacks and Countermeasures: Steganography and Watermarking: Attacks and Countermeasures, V1
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Katzenbeisser S, 2002, PROC SPIE, V4675, P50, DOI 10.1117/12.465313
   Li FY, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108341
   Li ZZ, 2022, NEUROCOMPUTING, V514, P182, DOI 10.1016/j.neucom.2022.09.146
   Liu LS, 2022, MULTIMED TOOLS APPL, V81, P39803, DOI 10.1007/s11042-022-13206-2
   Liu LS, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107022
   Liu XY, 2022, PROC CVPR IEEE, P2293, DOI 10.1109/CVPR52688.2022.00234
   Lu SP, 2021, PROC CVPR IEEE, P10811, DOI 10.1109/CVPR46437.2021.01067
   Nguyen BC, 2006, LECT NOTES COMPUT SC, V4283, P61
   Pan F, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P282, DOI 10.1109/ICECC.2011.6067590
   Rehman AU, 2019, LECT NOTES COMPUT SC, V11132, P723, DOI 10.1007/978-3-030-11018-5_64
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen XF, 2023, J INF SECUR APPL, V75, DOI 10.1016/j.jisa.2023.103515
   STOLLNITZ EJ, 1995, IEEE COMPUT GRAPH, V15, P76, DOI 10.1109/38.376616
   Su H, 2021, Arxiv, DOI arXiv:2112.14437
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamimi A.A., 2013, Int. J. Adv. Comput. Sci. Appl. (IJACSA), V4
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Wei P, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1621, DOI 10.1145/3503161.3548217
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xu YM, 2022, PROC CVPR IEEE, P7865, DOI 10.1109/CVPR52688.2022.00772
   Zhang C., 2020, Adv. Neural Inf. Process. Syst., V33, P10223
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu XS, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108170
NR 49
TC 1
Z9 1
U1 8
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104035
DI 10.1016/j.jvcir.2023.104035
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FH4I0
UT WOS:001144853800001
DA 2024-07-18
ER

PT J
AU Shao, XY
   Guo, Y
   Wang, YW
   Bao, ZW
   Wang, JY
AF Shao, Xiang-Ying
   Guo, Ying
   Wang, You-Wei
   Bao, Zheng-Wei
   Wang, Ji-Yu
TI A small object detection algorithm based on feature interaction and
   guided learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Small object detection; Aerial image; Faster RCNN; Feature interaction;
   Guided learning
ID FPN
AB At present, for the diverse target sizes, different angles, and complex environment in aerial images, how to detect small objects effectively in aerial images is still a challenge task. In order to further improve the detection ac-curacy and reduce the missing rate, in this paper, we proposes a small target detection algorithm based on feature interaction and guided learning. Firstly, the feature guided alignment module is designed to deal with the problem of information loss and overlap. Secondly, the misallocation of small object samples is optimized by introducing gaussian sample allocation strategy. Then the interactive parallel detection header is designed to solve the detection task conflict problem. Finally, the new regression loss function is designed to enhance the localization ability of the target. The experimental results on the Tinyperson dataset and Visdrone dataset show that this model can improve the detection accuracy and reduce the missing rate of small targets effectively.
C1 [Shao, Xiang-Ying; Guo, Ying; Wang, You-Wei; Bao, Zheng-Wei; Wang, Ji-Yu] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Shao, Xiang-Ying; Guo, Ying; Wang, You-Wei; Bao, Zheng-Wei; Wang, Ji-Yu] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Guo, Y (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.; Guo, Y (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
EM yguo@nuist.edu.cn
FU General Project of the National Natural Science Foundation of China
   [61971229]
FX This work was supported by the General Project of the National Natural
   Science Foundation of China (Grant No. 61971229) .
CR Adepoju O, 2022, SPRING TRACT CIV ENG, P65, DOI 10.1007/978-3-030-85973-2_4
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chen JZ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092276
   Cui LS, 2022, IEEE T CYBERNETICS, V52, P2300, DOI 10.1109/TCYB.2020.3004636
   Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349
   Feng XX, 2021, IEEE T GEOSCI REMOTE, V59, P6946, DOI 10.1109/TGRS.2020.3030990
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Gong YQ, 2021, IEEE WINT CONF APPL, P1159, DOI 10.1109/WACV48630.2021.00120
   Guan LT, 2018, INT J COMPUT INT SYS, V11, P951
   Hsu WY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3142061
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Kisantal M, 2019, Arxiv, DOI arXiv:1902.07296
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li X, 2023, COMPLEX INTELL SYST, V9, P301, DOI 10.1007/s40747-022-00786-7
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li YY, 2021, IEEE J-STARS, V14, P2148, DOI 10.1109/JSTARS.2020.3046482
   Li YC, 2022, APPL INTELL, V52, P15547, DOI 10.1007/s10489-022-03220-0
   Li ZM, 2018, Arxiv, DOI arXiv:1804.06215
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu C, 2022, NEURAL COMPUT APPL, V34, P6149, DOI 10.1007/s00521-021-06802-0
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Ma ZM, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15043034
   Muxian Li, 2022, 2022 IEEE 6th Information Technology and Mechatronics Engineering Conference (ITOEC), P203, DOI 10.1109/ITOEC53115.2022.9734594
   Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982
   Pei Wei, 2019, Journal of Software, V30, P738, DOI 10.13328/j.cnki.jos.005695
   Rahman EU, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9977939
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wang JW, 2022, Arxiv, DOI arXiv:2110.13389
   Weijian Li, 2020, 2020 International Conference on Computer Science and Management Technology (ICCSMT), P149, DOI 10.1109/ICCSMT51754.2020.00036
   Xu C, 2022, LECT NOTES COMPUT SC, V13669, P526, DOI 10.1007/978-3-031-20077-9_31
   Yang CHY, 2022, PROC CVPR IEEE, P13658, DOI 10.1109/CVPR52688.2022.01330
   Yang JM, 2022, APPL INTELL, V52, P1268, DOI 10.1007/s10489-021-02457-5
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Yeom J, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121895
   Yu XH, 2020, IEEE WINT CONF APPL, P1246, DOI 10.1109/WACV45572.2020.9093394
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   [张小孟 Zhang Xiaomeng], 2020, [中国惯性技术学报, Journal of Chinese Inertial Technology], V28, P528
NR 40
TC 0
Z9 0
U1 19
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104011
DI 10.1016/j.jvcir.2023.104011
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DS8M0
UT WOS:001134152200001
DA 2024-07-18
ER

PT J
AU Bi, Q
   Sun, X
   Yu, S
   Ma, K
   Bian, C
   Ning, MN
   He, NJ
   Huang, YW
   Li, YX
   Liu, HR
   Zheng, YF
AF Bi, Qi
   Sun, Xu
   Yu, Shuang
   Ma, Kai
   Bian, Cheng
   Ning, Munan
   He, Nanjun
   Huang, Yawen
   Li, Yuexiang
   Liu, Hanruo
   Zheng, Yefeng
TI MIL-ViT: A multiple instance vision transformer for fundus image
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vision transformer; Multiple instance learning; Fundus image; Attention
   aggregation; Calibrated attention mechanism
ID DIABETIC-RETINOPATHY; ATTENTION; CONVOLUTION; VALIDATION; NETWORK
AB Despite the great success of deep learning approaches, retinal disease classification is still challenging as the early-stage pathological regions of retinal diseases may be extremely tiny and subtle, which are difficult for networks to detect. The feature representations learnt by deep learning models focusing more on the local view may lead to indiscriminative semantic-level representation. On the contrary, if they focus more on the global semantic-level, they may ignore the discerning subtle local pathological regions. To address this issue, in this paper, we propose a hybrid framework, combining the strong global semantic representation learning capability of the vision Transformer (ViT) and the excellent capacity of local representation extraction from the conventional multiple instance learning (MIL). Particularly, a multiple instance vision Transformer (MIL-ViT) is implemented, where the vanilla ViT branch and the MIL branch generate semantic probability distributions separately, and a bag consistency loss is proposed to minimize the difference between them. Moreover, a calibrated attention mechanism is developed to embed the instance representation into the bag representation in our MIL-ViT. To further improve the feature representation capability for fundus images, we pre-train the vanilla ViT on a large-scale fundus image database. The experimental results validate that the generalization capability of the model using our pre-trained weights for fundus disease diagnosis is better than the one using ImageNet pre-trained weights. Extensive experiments on four publicly available benchmarks demonstrate that our proposed MIL-ViT outperforms latest fundus image classification methods, including various deep learning models and deep MIL methods. All our source code and pre-trained models are publicly available at https://github.com/greentreeys/MIL-VT.
C1 [Bi, Qi; Yu, Shuang; Ma, Kai; Bian, Cheng; Ning, Munan; He, Nanjun; Huang, Yawen; Zheng, Yefeng] Jarvis Res Ctr, Tencent YouTu Lab, Shenzhen, Peoples R China.
   [Sun, Xu] Pazhou Lab, Guangzhou, Peoples R China.
   [Li, Yuexiang] Guangxi Med Univ, Life Sci Inst, Nanning, Peoples R China.
   [Liu, Hanruo] Capital Med Univ, Beijing Tongren Hosp, Beijing, Peoples R China.
C3 Tencent; Pazhou Lab; Guangxi Medical University; Capital Medical
   University
RP Sun, X (corresponding author), Pazhou Lab, Guangzhou, Peoples R China.
EM pamixsun@foxmail.com; leeyuexiang@163.com
RI Ma, kai/KSL-8338-2024
OI Ma, kai/0009-0004-3748-2549; Sun, Xu/0000-0001-9155-0427
FU Key-Area Research and Development Program of Guangdong Province, China
   [2018B010111001]; National Key R&D Program of China [2018YFC2000702];
   Scientific and Technical Innovation 2030-"New Generation Artificial
   Intelligence" Project [2020AAA0104100]
FX This work was founded by the Key-Area Research and Development Program
   of Guangdong Province, China (No. 2018B010111001) , National Key R&D
   Program of China (2018YFC2000702) and the Scientific and Technical
   Innovation 2030-"New Generation Artificial Intelligence" Project (No.
   2020AAA0104100) .
CR Adal KM, 2018, IEEE T BIO-MED ENG, V65, P1382, DOI 10.1109/TBME.2017.2752701
   Al Ghamdi M, 2019, INT CONF ACOUST SPEE, P3812, DOI [10.1109/ICASSP.2019.8682915, 10.1109/icassp.2019.8682915]
   [Anonymous], 2022, APTOS 2019 blindness detection
   [Anonymous], 2022, Retinal image analysis for multi -disease detection challenge
   Bi Q, 2021, LECT NOTES COMPUT SC, V12908, P55, DOI 10.1007/978-3-030-87237-3_6
   Bi Q, 2021, NEUROCOMPUTING, V436, P147, DOI 10.1016/j.neucom.2021.01.038
   Bi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1603, DOI 10.1109/LGRS.2019.2949930
   Bi Q, 2020, IEEE T IMAGE PROCESS, V29, P4911, DOI 10.1109/TIP.2020.2975718
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Dai J., 2021, ICLR
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diaz-Pinto A, 2019, IEEE T MED IMAGING, V38, P2211, DOI 10.1109/TMI.2019.2903434
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fang HH, 2022, IEEE T MED IMAGING, V41, P2828, DOI 10.1109/TMI.2022.3172773
   Fang YX, 2021, ADV NEUR IN
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Grassmann F, 2018, OPHTHALMOLOGY, V125, P1410, DOI 10.1016/j.ophtha.2018.02.037
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ilse M, 2018, PR MACH LEARN RES, V80
   Ji W, 2021, PROC CVPR IEEE, P12336, DOI 10.1109/CVPR46437.2021.01216
   Junde Wu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12261), P731, DOI 10.1007/978-3-030-59710-8_71
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Khansari MM, 2020, IEEE T MED IMAGING, V39, P236, DOI 10.1109/TMI.2019.2924452
   Li H, 2021, LECT NOTES COMPUT SC, V12908, P206, DOI 10.1007/978-3-030-87237-3_20
   Li L, 2019, PROC CVPR IEEE, P10563, DOI 10.1109/CVPR.2019.01082
   Li SH, 2019, LECT NOTES COMPUT SC, V11767, P531, DOI 10.1007/978-3-030-32251-9_58
   Li T, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101971
   Li XM, 2021, IEEE T MED IMAGING, V40, P2284, DOI 10.1109/TMI.2021.3075244
   Li XM, 2020, IEEE T MED IMAGING, V39, P4023, DOI 10.1109/TMI.2020.3008871
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Lijun Gong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12262), P591, DOI 10.1007/978-3-030-59713-9_57
   Liu HR, 2019, JAMA OPHTHALMOL, V137, P1353, DOI 10.1001/jamaophthalmol.2019.3501
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Matsoukas C., 2021, Is it time to replace cnns with transformers for medical images?
   Mok TCW, 2022, PROC CVPR IEEE, P20803, DOI 10.1109/CVPR52688.2022.02017
   Pan JW, 2022, AAAI CONF ARTIF INTE, P2026
   Peng YF, 2019, OPHTHALMOLOGY, V126, P565, DOI 10.1016/j.ophtha.2018.11.015
   Playout C, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102608
   Rakhlin A., 2018, bioRxiv
   Rodriguez M., 2022, IEEE J Biomed Health Informatics
   Shao ZC, 2021, ADV NEUR IN
   Shaoteng Liu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P585, DOI 10.1007/978-3-030-59722-1_56
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Sun R, 2021, PROC CVPR IEEE, P10933, DOI 10.1109/CVPR46437.2021.01079
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Ting DSW, 2019, PROG RETIN EYE RES, V72, DOI 10.1016/j.preteyeres.2019.04.003
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Valanarasu JMJ, 2021, LECT NOTES COMPUT SC, V12901, P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XF, 2021, AAAI CONF ARTIF INTE, V35, P2826
   Wang XG, 2018, PATTERN RECOGN, V74, P15, DOI 10.1016/j.patcog.2017.08.026
   Wang ZW, 2020, IEEE T MED IMAGING, V39, P2904, DOI 10.1109/TMI.2020.2980117
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie YT, 2021, LECT NOTES COMPUT SC, V12903, P171, DOI 10.1007/978-3-030-87199-4_16
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yang Y., 2021, IEEE Trans Cybern, P1
   Yu S, 2021, LECT NOTES COMPUT SC, V12908, P45, DOI 10.1007/978-3-030-87237-3_5
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhao YT, 2020, IEEE T MED IMAGING, V39, P341, DOI 10.1109/TMI.2019.2926492
   Zhou BC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4595, DOI 10.1109/ICASSP39728.2021.9414323
   Zhou SK, 2021, P IEEE, V109, P820, DOI 10.1109/JPROC.2021.3054390
NR 67
TC 3
Z9 3
U1 4
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103956
DI 10.1016/j.jvcir.2023.103956
EA OCT 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y3HW7
UT WOS:001104223400001
DA 2024-07-18
ER

PT J
AU Li, Y
   Zhang, K
   Chen, Z
   Ouyang, WP
   Cui, MP
   Jiang, CX
   Yang, DQ
   Chen, ZZ
AF Li, Yang
   Zhang, Kao
   Chen, Zhao
   Ouyang, Wanping
   Cui, Mingpeng
   Jiang, Chenxi
   Yang, Daiqin
   Chen, Zhenzhong
TI Towards object tracking for quadruped robots
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Siamese network; Quadruped robot
AB With the development of quadruped robot technology, object tracking for quadruped robots has become an important research topic where violent camera shaking caused by the robot's movement makes this task very challenging. In this letter, a quadruped robot object tracking dataset (QROD-111), including 111 video sequences, is first established, which was collected through our quadruped robot platform. A tracking algorithm based on Siamese network is then proposed where an alignment module is introduced to alleviate tracking difficulties caused by the quadruped robot movement. Moreover, a scale adaptation subnetwork is designed to alleviate the impact of the object scale variation during the whole tracking process. Experimental results demonstrate that our algorithm can achieve advanced performance for quadruped robot object tracking.
C1 [Li, Yang; Zhang, Kao; Chen, Zhao; Ouyang, Wanping; Cui, Mingpeng; Jiang, Chenxi; Yang, Daiqin; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Zhang, Kao] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Sch Future Technol, Nanjing 210044, Peoples R China.
C3 Wuhan University; Nanjing University of Information Science & Technology
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM zzchen@ieee.org
FU National Natural Science Foundation of China [62036005, 62201404]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62036005 and Grant 62201404.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bledt G., 2020, Ph.D. thesis
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Darkpgmr DarkLabel, 2021, Video/image labeling and annotation tool
   Di Carlo J, 2018, IEEE INT C INT ROBOT, P7440, DOI 10.1109/IROS.2018.8594448
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Guo YJ, 2019, IEEE J-STARS, V12, P3538, DOI 10.1109/JSTARS.2019.2933488
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kim D., 2018, IEEE INT C INTELLIGE, P1
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li WS, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103687
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Ruan L, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3158652
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   STVIR Pysot, 2021, SenseTime research platform for single object tracking
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu YQ, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2022.103742
   Yan Song, 2021, P IEEE CVF INT C COM, P10725
NR 30
TC 0
Z9 0
U1 17
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103958
DI 10.1016/j.jvcir.2023.103958
EA OCT 2023
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y2WS5
UT WOS:001103927400001
DA 2024-07-18
ER

PT J
AU Raj, MSS
   George, SN
AF Raj, M. S. Subodh
   George, Sudhish N.
TI An approximate tensor singular value decomposition approach for the fast
   grouping of whole-body human poses
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Approximate tensor-SVD; Human pose depth map; Human pose grouping;
   Tensor-QR decomposition
ID ACTION RECOGNITION; REPRESENTATION
AB We propose a fast method to group similar human poses from single-view depth maps using an approximate singular value decomposition approach in the tensor domain. To this end, the input tensor is decomposed, and a representation tensor is learned using the tensor-QR decomposition and ������2 ,1 norm minimization. The spatial structure and, thereby, the spatial information in each depth map, vital in performing accurate grouping of human poses, is preserved by adopting the 3D tensor approach in treating the data. For the seamless integration of discriminatory information of each pose, a new dissimilarity measure based on sub-tensors is devised and integrated into the optimization problem. Experimental analysis showcases the ability of the proposed method to achieve 10%-15% improvement in the grouping results compared with the state-of-the-art counterparts. The proposed algorithm also converges in less than ten iterations on average, thereby improving CPU time.
C1 [Raj, M. S. Subodh; George, Sudhish N.] Natl Inst Technol Calicut, Dept Elect & Commun Engn, Calicut, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Raj, MSS (corresponding author), Natl Inst Technol Calicut, Dept Elect & Commun Engn, Calicut, India.
EM subodhrajms@gmail.com; sudhish@nitc.ac.in
RI M S, Subodh Raj/K-6771-2018
OI M S, Subodh Raj/0000-0002-1111-9520
CR Aeron S, 2015, ANN ALLERTON CONF, P666, DOI 10.1109/ALLERTON.2015.7447068
   Baburaj M, 2019, MULTIMED TOOLS APPL, V78, P1805, DOI 10.1007/s11042-018-6251-7
   Ball A, 2012, ACMIEEE INT CONF HUM, P225
   Cai B, 2022, INFORM SCIENCES, V609, P46, DOI 10.1016/j.ins.2022.07.049
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Chen YY, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107441
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Ding WW, 2018, IET COMPUT VIS, V12, P110, DOI 10.1049/iet-cvi.2017.0031
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365
   FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117
   Francis J, 2021, J IMAGING, V7, DOI 10.3390/jimaging7120279
   Francis J, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3399806
   Han DR, 2022, J OPER RES SOC CHINA, V10, P1, DOI 10.1007/s40305-021-00368-3
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   Hu WR, 2017, IEEE T NEUR NET LEAR, V28, P2961, DOI 10.1109/TNNLS.2016.2611525
   Jia CC, 2020, IEEE T CIRC SYST VID, V30, P2801, DOI 10.1109/TCSVT.2019.2910208
   Jia CC, 2016, IEEE T IMAGE PROCESS, V25, P4641, DOI 10.1109/TIP.2016.2589320
   Jiang MX, 2019, NEUROCOMPUTING, V358, P332, DOI 10.1016/j.neucom.2019.05.034
   Kernfeld E, 2015, Arxiv, DOI arXiv:1412.7056
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Koniusz P, 2022, IEEE T PATTERN ANAL, V44, P648, DOI 10.1109/TPAMI.2021.3107160
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624
   Liu Q, 2019, IEEE T NEUR NET LEAR, V30, P803, DOI 10.1109/TNNLS.2018.2851957
   Liu YY, 2015, IEEE T CYBERNETICS, V45, P2437, DOI 10.1109/TCYB.2014.2374695
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Nishihara R, 2015, PR MACH LEARN RES, V37, P343
   Piao X., 2016, arXiv
   Qin ZY, 2024, IEEE T NEUR NET LEAR, V35, P4783, DOI 10.1109/TNNLS.2022.3201518
   Romano S, 2016, J MACH LEARN RES, V17
   Schneider P, 2019, LECT NOTES ARTIF INT, V11531, P281, DOI 10.1007/978-3-030-35699-6_22
   Shi QQ, 2022, IEEE T CYBERNETICS, V52, P10667, DOI 10.1109/TCYB.2021.3067676
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Tang KW, 2014, IEEE T NEUR NET LEAR, V25, P2167, DOI 10.1109/TNNLS.2014.2306063
   Tom AJ, 2021, IEEE T CYBERNETICS, V51, P1004, DOI 10.1109/TCYB.2019.2921827
   Wang L, 2023, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR52729.2023.00544
   Wang L, 2023, LECT NOTES COMPUT SC, V13844, P307, DOI 10.1007/978-3-031-26316-3_19
   Wang L, 2022, LECT NOTES COMPUT SC, V13681, P176, DOI 10.1007/978-3-031-19803-8_11
   Wang L, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4324, DOI 10.1145/3474085.3475572
   Wang L, 2019, IEEE I CONF COMP VIS, P8697, DOI 10.1109/ICCV.2019.00879
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wei L, 2022, IEEE T NEUR NET LEAR, V33, P4610, DOI 10.1109/TNNLS.2021.3059511
   Wu FS, 2021, IEEE T COMPUT IMAG, V7, P1267, DOI 10.1109/TCI.2021.3130977
   Wu T, 2018, IEEE SIGNAL PROC LET, V25, P1196, DOI 10.1109/LSP.2018.2849590
   Xu B, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892979
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   You CZ, 2021, J ALGORITHMS COMPUT, V15, DOI 10.1177/1748302620983690
   Zheng YM, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108240
   Zhong G, 2021, NEUROCOMPUTING, V437, P249, DOI 10.1016/j.neucom.2021.01.077
   Zhou P, 2021, IEEE T PATTERN ANAL, V43, P1718, DOI 10.1109/TPAMI.2019.2954874
NR 54
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103960
DI 10.1016/j.jvcir.2023.103960
EA OCT 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y2GM8
UT WOS:001103503500001
DA 2024-07-18
ER

PT J
AU Wang, HJ
   Qi, LH
   Qu, HY
   Ma, WL
   Yuan, W
   Hao, W
AF Wang, Haijun
   Qi, Lihua
   Qu, Haoyu
   Ma, Wenlai
   Yuan, Wei
   Hao, Wei
TI End-to-end wavelet block feature purification network for efficient and
   effective UAV object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Wavelet; Transformer; Unmanned aerial vehicle; Self-attention learning;
   Downsampling-upsampling strategy
ID CORRELATION FILTER
AB Recently, unmanned aerial vehicle (UAV) object tracking tasks have significantly improved with the emergence of deep learning. However, owing to the object feature pollution caused by motion blur, illumination variation, and occlusion, most of the existing trackers often fail to precisely localize the target in the complex real -world circumstances. To overcome this challenge, we present a novel wavelet block feature purification network (WFPN) for efficient and effective UAV tracking. WFPN is mainly composed of downsampling network through wavelet transforms and upsampling network through inverse wavelet transforms. To be specific, the downsampling network performs discrete wavelet transform (DWT) to reduce interference information and preserve original feature details, while the upsampling network applies inverse DWT (IDWT) to reconstruct decontaminated feature information. Additionally, a novel sequential encoder is introduced to achieve a better purification effect. Finally, a pooling distance loss is devised to improve the purification effect of DWT downsampling network. Extensive experiments show that our WFPN achieves promising tracking performance on three well-known UAV benchmarks, especially on sequences with feature pollution. Moreover, our method runs at 33.2 frames per second on the edge platform of Nvidia Jetson AGX Orin, which is suitable for UAVs with limited onboard payload and computing capability.
C1 [Wang, Haijun; Qi, Lihua; Ma, Wenlai; Yuan, Wei; Hao, Wei] Binzhou Univ, Aviat Informat Technol Res & Dev, Binzhou, Peoples R China.
   [Ma, Wenlai] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing, Peoples R China.
C3 Shandong University of Aeronautics; Nanjing University of Aeronautics &
   Astronautics
RP Wang, HJ (corresponding author), Binzhou Univ, Aviat Informat Technol Res & Dev, Binzhou, Peoples R China.
EM whjkyx@163.com
RI Qu, Haoyu/KHW-7039-2024
OI Qu, Haoyu/0009-0005-1213-5732; haijun, wang/0000-0003-2481-9662
FU National Natural Science Foundation of China [62103060]; Shandong
   Provincial Natural Science Foundation, China [ZR2020MF142]; Doctoral
   Foundation of Binzhou University [2021Y04]; Research Fund Project of
   Binzhou University [2019ZD03, BZXYL1803]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant number 62103060, in part by Shandong
   Provincial Natural Science Foundation, China, under Grant ZR2020MF142,
   in part by the Doctoral Foundation of Binzhou University under Grant
   2021Y04, and in part by the Research Fund Project of Binzhou University
   under Grant 2019ZD03 and Grant BZXYL1803.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cao ZA, 2022, PROC CVPR IEEE, P14778, DOI 10.1109/CVPR52688.2022.01438
   Cao ZA, 2021, IEEE INT C INT ROBOT, P3086, DOI 10.1109/IROS51168.2021.9636309
   Cao ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15437, DOI 10.1109/ICCV48922.2021.01517
   Chen X, 2023, IEEE T PATTERN ANAL, V45, P8507, DOI 10.1109/TPAMI.2022.3232535
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cui YT, 2022, PROC CVPR IEEE, P13598, DOI 10.1109/CVPR52688.2022.01324
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu C., 2022, arXiv, DOI DOI 10.1007/S10462-023-10558-5
   Fu CH, 2022, IEEE INT C INT ROBOT, P12122, DOI 10.1109/IROS47612.2022.9981248
   Fu CH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3083880
   Fu CH, 2022, IEEE GEOSC REM SEN M, V10, P125, DOI 10.1109/MGRS.2021.3072992
   Fu Z., 2022, P 31 INT JOINT C ART, P905
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Han G, 2023, IEEE T MULTIMEDIA, V25, P430, DOI 10.1109/TMM.2021.3127357
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang HL, 2023, APPL SOFT COMPUT, V132, DOI 10.1016/j.asoc.2022.109912
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li F, 2017, IEEE INT CONF COMP V, P2001, DOI 10.1109/ICCVW.2017.234
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li YM, 2020, IEEE INT C INT ROBOT, P1559, DOI 10.1109/IROS45743.2020.9341595
   Lin FL, 2020, IEEE INT CONF ROBOT, P2365, DOI [10.1109/ICRA40945.2020.9196530, 10.1109/icra40945.2020.9196530]
   Lin FL, 2022, IEEE T INTELL TRANSP, V23, P10469, DOI 10.1109/TITS.2021.3094654
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S., 2022, Advances in Neural Information Processing Systems, V35, P1100, DOI DOI 10.48550/ARXIV.2210.16774,35
   Liu SH, 2023, PROC CVPR IEEE, P3759, DOI 10.1109/CVPR52729.2023.00366
   Liu Y, 2021, PROC CVPR IEEE, P13360, DOI 10.1109/CVPR46437.2021.01316
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Niu WJ, 2021, IEEE T IMAGE PROCESS, V30, P7101, DOI 10.1109/TIP.2021.3101402
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sosnovik I, 2021, IEEE WINT CONF APPL, P2764, DOI 10.1109/WACV48630.2021.00281
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Xing DT, 2022, IEEE WINT CONF APPL, P1898, DOI 10.1109/WACV51458.2022.00196
   Yang MP, 2022, LECT NOTES COMPUT SC, V13675, P1, DOI 10.1007/978-3-031-19784-0_1
   Yang Xingyi, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P22552, DOI 10.1109/CVPR52729.2023.02160
   Yang X., 2022, Advances in Neural Information Processing Systems, V35, P25739
   Yang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3131264
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yao L., 2023, P IEEE INT C ROB AUT, P1
   Ye JJ, 2022, IEEE T IND ELECTRON, V69, P6004, DOI 10.1109/TIE.2021.3088366
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yu RA, 2023, Arxiv, DOI arXiv:2301.07014
   Yue HJ, 2019, IEEE T IMAGE PROCESS, V28, P4339, DOI 10.1109/TIP.2019.2909805
   Yue HJ, 2017, IEEE IMAGE PROC, P2976, DOI 10.1109/ICIP.2017.8296828
   Zhang H, 2023, INFORM SCIENCES, V634, P122, DOI 10.1016/j.ins.2023.03.083
   Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang TZ, 2019, IEEE T PATTERN ANAL, V41, P365, DOI 10.1109/TPAMI.2018.2797062
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao J, 2019, IEEE INT CON MULTI, P1420, DOI 10.1109/ICME.2019.00246
   Zheng G., 2022, IEEE Trans. Ind. Inform., P1
   Zheng GZ, 2022, IEEE INT C INT ROBOT, P10486, DOI 10.1109/IROS47612.2022.9982189
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
   Zuo HB, 2022, IEEE INT C INT ROBOT, P12130, DOI 10.1109/IROS47612.2022.9981882
   Zuo HB, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3230043
NR 71
TC 0
Z9 0
U1 5
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103950
DI 10.1016/j.jvcir.2023.103950
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X7EQ7
UT WOS:001100043400001
DA 2024-07-18
ER

PT J
AU Wang, YF
   Yu, X
   Guo, XY
   Wang, XL
   Wei, YH
   Zeng, SJ
AF Wang, Yuefei
   Yu, Xi
   Guo, Xiaoyan
   Wang, Xilei
   Wei, Yuanhong
   Zeng, Shijie
TI A Dual-Decoding branch U-shaped semantic segmentation network combining
   Transformer attention with Decoder: DBUNet
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic Segmentation; U -Shaped Network; Transformer ViT; Medical Image
ID NET
AB Semantic Segmentation is an extremely important medical image auxiliary analysis method. However, existing networks have the following problems: 1) The amount of feature information of Encoder and Decoder is not equal under multi-branch architecture; 2) The direct processing of the original image by ViT Encoder is not sufficient; 3) Multi-channel features are too independent and lack of fusion. Combined with the ViT Encoder framework, this study proposes a 'Single Encoder - Double Decoder' structure: DBUNet. Firstly, ViT Encoder is employed as a part of the Decoder branches to enhance the shallow features. Then, a polarization amplification of channel weights is proposed and placed in front of the ViT Encoder module to achieve early image processing. Finally, a Bottleneck for feature fusion is proposed to solve the problem of channel independence. The comprehensive verification of 13 comparative networks in three aspects, combined with ablation experiments, jointly proves the superiority of DBUNet.
C1 [Wang, Yuefei; Guo, Xiaoyan; Wang, Xilei; Wei, Yuanhong; Zeng, Shijie] Chengdu Univ, Coll Comp Sci, 2025 Chengluo Rd, Chengdu 610106, Sichuan, Peoples R China.
   [Yu, Xi] Chengdu Univ, Stirling Coll, 2025 Chengluo Rd, Chengdu 610106, Sichuan, Peoples R China.
C3 Chengdu University; Chengdu University
RP Yu, X (corresponding author), Chengdu Univ, Stirling Coll, 2025 Chengluo Rd, Chengdu 610106, Sichuan, Peoples R China.
EM yuxi@cdu.edu.cn
RI Wang, Yuefei/I-1985-2018
OI Zeng, Shijie/0000-0001-8116-3845; Yuanhong, Wei/0009-0002-0754-293X
CR Anjum MA, 2020, IEEE ACCESS, V8, P129668, DOI 10.1109/ACCESS.2020.3009276
   Arnab A, 2018, IEEE SIGNAL PROC MAG, V35, P37, DOI 10.1109/MSP.2017.2762355
   Taghanaki SA, 2021, ARTIF INTELL REV, V54, P137, DOI 10.1007/s10462-020-09854-1
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cai L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.44
   Cao H., 2021, arXiv
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Du GT, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.2.020508
   Elharrouss O, 2021, Arxiv, DOI [arXiv:2111.10250, DOI 10.48550/ARXIV.2111.10250]
   Fan CM, 2022, Arxiv, DOI arXiv:2202.14009
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   Hasan SMK, 2019, IEEE ENG MED BIO, P7205, DOI [10.1109/EMBC.2019.8856791, 10.1109/embc.2019.8856791]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3144165
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Huang ZH, 2022, NEUROCOMPUTING, V500, P73, DOI 10.1016/j.neucom.2022.05.023
   Iglovikov V, 2018, Arxiv, DOI arXiv:1801.05746
   Jin Y, 2021, PATTERN RECOGN LETT, V148, P29, DOI 10.1016/j.patrec.2021.04.024
   Kiran I, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105267
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Li HY, 2021, J ENG-JOE, V2021, P594, DOI 10.1049/tje2.12067
   Li X, 2020, IEEE T IMAGE PROCESS, V29, P128, DOI 10.1109/TIP.2019.2930874
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo L, 2018, CHIN CONT DECIS CONF, P1892, DOI 10.1109/CCDC.2018.8407435
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mo YJ, 2022, NEUROCOMPUTING, V493, P626, DOI 10.1016/j.neucom.2022.01.005
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Ohta Y., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P752
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Petit O, 2021, LECT NOTES COMPUT SC, V12966, P267, DOI 10.1007/978-3-030-87589-3_28
   Przelaskowski Artur, 2022, Information Technology in Biomedicine: 9th International Conference, ITIB 2022, Proceedings. Advances in Intelligent Systems and Computing (1429), P246, DOI 10.1007/978-3-031-09135-3_21
   Qi KH, 2019, LECT NOTES COMPUT SC, V11766, P247, DOI 10.1007/978-3-030-32248-9_28
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saeedizadeh Narges, 2021, Comput Methods Programs Biomed Update, V1, P100007, DOI 10.1016/j.cmpbup.2021.100007
   Sha Y., 2021, arXiv
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song CF, 2019, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2019.00325
   Song HJ, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104038
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Tran T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION ENGINEERING (ICECE 2018), P13, DOI 10.1109/ICECOME.2018.8644754
   Trebing K, 2021, PATTERN RECOGN LETT, V145, P178, DOI 10.1016/j.patrec.2021.01.036
   van Rijthoven M, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101890
   Vaswani A, 2017, ADV NEUR IN, V30
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang HY, 2022, INT CONF ACOUST SPEE, P2390, DOI 10.1109/ICASSP43922.2022.9746172
   Wang LB, 2022, ISPRS J PHOTOGRAMM, V190, P196, DOI 10.1016/j.isprsjprs.2022.06.008
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Xia XD, 2017, Arxiv, DOI arXiv:1711.08506
   Xie EZ, 2021, ADV NEUR IN, V34
   Yan HT, 2023, Arxiv, DOI arXiv:2201.01615
   Yang RX, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.638182
   Yu Q., 2021, arXiv
   Yuan XH, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114417
   Alom MZ, 2018, Arxiv, DOI arXiv:1802.06955
   Zhang M, 2020, ARTIF INTELL REV, V53, P4259, DOI 10.1007/s10462-019-09792-7
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 76
TC 4
Z9 4
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103856
DI 10.1016/j.jvcir.2023.103856
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7HJ0
UT WOS:001018109900001
DA 2024-07-18
ER

PT J
AU Qian, YX
   Xue, Y
   Wang, T
AF Qian, Yuxiang
   Xue, Yang
   Wang, Tao
TI Deep interactive image segmentation based on region and Boundary-click
   guidance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive segmentation; Deep learning; Interaction strategy;
   Information diffusion
AB In interactive image segmentation, the target object of interest can be extracted based on the guidance of user interactions. One of the main goals in this task is to reduce the user interaction burden and ensure satisfactory segmentation with as few interactions as possible. Thanks to the development of deep learning technology, neural network-based interactive approaches have significantly improved the segmentation performance through powerful feature representation. Only limited point (click) interaction is required for the user to complete the segmentation. This paper mainly follows the deep learning-based interactive segmentation methods and explores more efficient interaction strategies and effective segmentation models. We further simplify user interaction to two clicks, where the first click is utilized to select the target region and the other aims to determine the target boundary. Based on the region and boundary clicks, an interactive two-stream network structure is naturally derived to learn the region and boundary features of interest. Furthermore, we also construct an information diffusion module to better propagate the region and boundary-click labels, which helps to enhance the similarity within the region and the discrimination between boundaries. Vast experiments on the popular GrabCut, Ber-keley, DAVIS, MS COCO and SBD datasets verified the effectiveness of the proposed method.
C1 [Qian, Yuxiang; Wang, Tao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Xue, Yang] 723 Inst CSSC, Yangzhou 225000, Peoples R China.
   [Wang, Tao] Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Sen, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology
RP Wang, T (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.; Wang, T (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Sen, Nanjing 210094, Peoples R China.
EM wangtaoatnjust@163.com
FU National Natural Science Foundation of China [62172221]; Funda- mental
   Research Funds for the Central Universities [JSGP202204]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62172221 and in part by the Funda-
   mental Research Funds for the Central Universities under Grant NO.
   JSGP202204.
CR Bai JJ, 2014, PROC CVPR IEEE, P392, DOI 10.1109/CVPR.2014.57
   Benenson R, 2019, PROC CVPR IEEE, P11692, DOI 10.1109/CVPR.2019.01197
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen X., 2021, P IEEE CVF INT C COM, P7345
   Chen X., 2022, P IEEECVF C COMPUTER, P1300
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dupont C, 2021, IEEE SYS MAN CYBERN, P3373, DOI 10.1109/SMC52423.2021.9658754
   Forte M, 2020, Arxiv, DOI [arXiv:2003.07932, DOI 10.48550/ARXIV.2003.07932]
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   Hao YY, 2021, IEEE INT CONF COMP V, P1551, DOI 10.1109/ICCVW54120.2021.00180
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jang WD, 2019, PROC CVPR IEEE, P5292, DOI 10.1109/CVPR.2019.00544
   Kim TH, 2010, PROC CVPR IEEE, P3201, DOI 10.1109/CVPR.2010.5540078
   Kingma D, 2014, ICLR P, V2014, P1
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Li HC, 2018, Arxiv, DOI [arXiv:1805.10180, DOI 10.48550/ARXIV.1805.10180]
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li ZW, 2018, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2018.00067
   Liew JH, 2017, IEEE I CONF COMP VIS, P2746, DOI 10.1109/ICCV.2017.297
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Majumder S, 2019, PROC CVPR IEEE, P11594, DOI 10.1109/CVPR.2019.01187
   Maninis KK, 2018, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2018.00071
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shiyin Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12231, DOI 10.1109/CVPR42600.2020.01225
   Sofiiuk K., 2020, IEEE CVF C COMP VIS, P8623
   Sofiiuk K, 2022, IEEE IMAGE PROC, P3141, DOI 10.1109/ICIP46576.2022.9897365
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu JJ, 2014, PROC CVPR IEEE, P256, DOI 10.1109/CVPR.2014.40
   Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng Lin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13336, DOI 10.1109/CVPR42600.2020.01335
NR 43
TC 1
Z9 1
U1 3
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103797
DI 10.1016/j.jvcir.2023.103797
EA MAR 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G7QE2
UT WOS:000991051800001
DA 2024-07-18
ER

PT J
AU Pang, YX
   Zhang, HX
   Zhu, L
   Liu, DM
   Liu, L
AF Pang, Yunxiao
   Zhang, Huaxiang
   Zhu, Lei
   Liu, Dongmei
   Liu, Li
TI Feature generation based on relation learning and image partition for
   occluded person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Occluded person re-identification; Graph convolutional network;
   Partition
ID ATTENTION; NETWORK
AB In order to solve the challenging tasks of person re-identification(Re-ID) in occluded scenarios, we propose a novel approach which divides local units by forming high-level semantic information of pedestrians and generates features of occluded parts. The approach uses CNN and pose estimation to extract the feature map and key points, and a graph convolutional network to learn the relation of key points. Specifically, we design a Generating Local Part (GLP) module to divide the feature map into different units. Based on different occluded conditions, the partition mode of GLP has high flexibility and variability. The features of the non-occluded parts are clustered into an intermediate node, and then the spatially correlated features of the occluded parts are generated according to the de-clustering operation. We conduct experiments on both the occluded and the holistic datasets to demonstrate its effectiveness.
C1 [Pang, Yunxiao; Zhang, Huaxiang; Zhu, Lei; Liu, Dongmei; Liu, Li] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Jiaotong University
RP Zhang, HX; Liu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@hotmail.com; liuli_790209@163.com
FU National Natural Science Foundation of China [62176144, U1836216,
   62076153]; major fundamental research project of Shandong, China
   [ZR2019ZD03]; Taishan Scholar Project of Shandong Province, China
   [ts20190924]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 62176144, U1836216, 62076153) , the major
   fundamental research project of Shandong, China (No. ZR2019ZD03) , and
   the Taishan Scholar Project of Shandong Province, China (No.
   ts20190924).
CR Bai S, 2017, PROC CVPR IEEE, P3356, DOI 10.1109/CVPR.2017.358
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen GY, 2020, IEEE T IMAGE PROCESS, V29, P6963, DOI 10.1109/TIP.2020.2995272
   Chen YF, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108567
   Fan X, 2019, LECT NOTES COMPUT SC, V11362, P19, DOI 10.1007/978-3-030-20890-5_2
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He LX, 2018, Arxiv, DOI arXiv:1810.07399
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Jin HY, 2022, IEEE T CIRC SYST VID, V32, P2170, DOI 10.1109/TCSVT.2021.3088446
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2905, DOI 10.1109/TMM.2020.2965491
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Rao YM, 2019, INT J COMPUT VISION, V127, P701, DOI 10.1007/s11263-018-1135-x
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Song GL, 2018, AAAI CONF ARTIF INTE, P7347
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan HC, 2023, IEEE T NEUR NET LEAR, V34, P8210, DOI 10.1109/TNNLS.2022.3144163
   Tan HC, 2022, IEEE T CIRC SYST VID, V32, P160, DOI 10.1109/TCSVT.2021.3061412
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wu GL, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108239
   Wu Y, 2021, IEEE T COGN DEV SYST, V13, P865, DOI 10.1109/TCDS.2020.3003674
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yan C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11855, DOI 10.1109/ICCV48922.2021.01166
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164431
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhai YT, 2021, INT WORKSH QUAL SERV, DOI 10.1109/IWQOS52092.2021.9521344
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao CR, 2021, IEEE T IMAGE PROCESS, V30, P4212, DOI 10.1109/TIP.2021.3070182
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng WZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12045, DOI 10.1109/ICCV48922.2021.01185
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 51
TC 2
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103772
DI 10.1016/j.jvcir.2023.103772
EA JAN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D4RY5
UT WOS:000968632800001
DA 2024-07-18
ER

PT J
AU Jeny, AA
   Islam, MB
AF Jeny, Afsana Ahsan
   Islam, Md Baharul
TI Optimized video compression with residual split attention and swin-block
   artifact contraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video compression; Residual attention; Image reconstruction; Channel
   residual block; Artifact contraction
ID IMAGE
AB Research in video compression has seen significant advancement in the last several years. However, the existing deep learning-based algorithms continue to be plagued by erroneous motion compression and ineffective motion compensation architectures, resulting in compression errors with a lower rate-distortion trade-off. To overcome these challenges, we present an end-to-end purely deep learning-based video compression method through a set of primary operations (e.g., motion estimation, motion compression, motion compensation, residual compression, and artifact contraction) differently. A deep residual attention split (DRAS) block is introduced for motion compression networks to pay more attention to certain image regions to create more effective features for the decoder while boosting the rate-distortion optimization (RDO) efficiency. A channel residual block (CRB) is proposed in motion compensation to yield a more accurate predicted frame, potentially improving the residual frame. To mitigate the compression errors, an artifact contraction module (ACM) by residual swin convolution UNet block is included in this model to improve the reconstruction quality. To improve the final frame, a buffer is added to fine-tune the previous reference frames. These modules combine with a loss function by assessing the trade-off and enhancing the decoded video quality. A comprehensive ablation study demonstrates the effectiveness of the proposed blocks and modules for video compression. Experimental results show the competitive performance of the proposed method on four benchmark datasets.
C1 [Jeny, Afsana Ahsan; Islam, Md Baharul] Bahcesehir Univ, Dept Comp Engn, Istanbul, Turkey.
   [Islam, Md Baharul] Amer Univ Malta, Coll Data Sci & Engn, Bormla, Malta.
   [Islam, Md Baharul] Daffodil Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 Bahcesehir University; Daffodil International University
RP Islam, MB (corresponding author), Amer Univ Malta, Coll Data Sci & Engn, Bormla, Malta.
EM bislam.eng@gmail.com
RI Islam, Md Baharul/R-3751-2019
OI Islam, Md Baharul/0000-0002-9928-5776
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [118C301]
FX This work is supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) under the 2232 Outstanding Researchers
   program, Project No. 118C301.
CR Agustsson E., 2020, P IEEE CVF C COMP VI, P8503
   Andris S, 2021, Arxiv, DOI arXiv:2008.10273
   [Anonymous], 2018, Cisco Visual Networking Index: Forecast and Trends, 2017-2022
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2017, VIDEO COMPRESSION US
   Ball‚ J, 2017, Arxiv, DOI [arXiv:1611.01704, 10.48550/arXiv.1611.01704]
   Ball‚ J, 2018, Arxiv, DOI arXiv:1802.01436
   Bellard F, 2015, BPG IMAGE FORMAT, V1, P2
   Bjontegaard G., 2001, Document VCEG-M33
   Blau Y, 2019, PR MACH LEARN RES, V97
   Bross B, 2019, Document JVET-N1001
   Chen T, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen ZB, 2020, IEEE T CIRC SYST VID, V30, P566, DOI 10.1109/TCSVT.2019.2892608
   Djelouah A, 2019, IEEE I CONF COMP VIS, P6430, DOI 10.1109/ICCV.2019.00652
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Feng RS, 2020, IEEE COMPUT SOC CONF, P529, DOI 10.1109/CVPRW50498.2020.00068
   Guo Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P456, DOI 10.1007/978-3-030-58536-5_27
   Habibian A, 2019, IEEE I CONF COMP VIS, P7032, DOI 10.1109/ICCV.2019.00713
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu ZH, 2021, PROC CVPR IEEE, P1502, DOI 10.1109/CVPR46437.2021.00155
   Hui TW, 2021, IEEE T PATTERN ANAL, V43, P2555, DOI 10.1109/TPAMI.2020.2976928
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jeny A.A., 2021, 2021 36 INT C IMAGE, P1
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Lee JY, 2019, Arxiv, DOI arXiv:1809.10452
   Li J, 2021, Adv. Neural Inf. Process. Syst, V34
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lim H, 2011, IEEE T CIRC SYST VID, V21, P879, DOI 10.1109/TCSVT.2011.2133250
   Lin JP, 2020, PROC CVPR IEEE, P3543, DOI 10.1109/CVPR42600.2020.00360
   Liu BW, 2021, PROC CVPR IEEE, P701, DOI 10.1109/CVPR46437.2021.00076
   Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405
   Liu HJ, 2019, Arxiv, DOI arXiv:1904.09757
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mercat A, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P297, DOI 10.1145/3339825.3394937
   Minnen D., 2018, arXiv
   Ning LY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103115
   Patel Y, 2019, Arxiv, DOI arXiv:1908.04187
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sheng XH, 2021, Arxiv, DOI arXiv:2111.13850
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Theis L, 2017, Arxiv, DOI [arXiv:1703.00395, DOI 10.48550/ARXIV.1703.00395]
   Toderici G, 2016, Arxiv, DOI arXiv:1511.06085
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang HG, 2016, IEEE IMAGE PROC, P1509, DOI 10.1109/ICIP.2016.7532610
   Wang Z., 2003, P 37 AS C SIGN SYST, P1398, DOI [DOI 10.1109/ACSSC.2003.1292216, 10.1109/ACSSC.2003.1292216]
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu CY, 2018, LECT NOTES COMPUT SC, V11212, P425, DOI 10.1007/978-3-030-01237-3_26
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Wu X., 2020, P IEEE CVF C COMP VI, P156
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang R, 2021, IEEE J-STSP, V15, P388, DOI 10.1109/JSTSP.2020.3043590
   Yang R, 2020, PROC CVPR IEEE, P6627, DOI 10.1109/CVPR42600.2020.00666
   Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697
   Yuan SY, 2019, J VIS COMMUN IMAGE R, V59, P33, DOI 10.1016/j.jvcir.2018.12.043
   Zhang H, 2020, Arxiv, DOI arXiv:2004.08955
   Zhihao Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P193, DOI 10.1007/978-3-030-58536-5_12
NR 67
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103737
DI 10.1016/j.jvcir.2022.103737
EA DEC 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8C2LY
UT WOS:000917447600001
DA 2024-07-18
ER

PT J
AU Sun, KC
   Meng, F
   Tian, YB
AF Sun, Kaichuan
   Meng, Fei
   Tian, Yubo
TI Progressive multi-branch embedding fusion network for underwater image
   enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image enhancement; Marine snow removal; Multi-branch
   embedding fusion; Multi-stage framework
AB The underwater image enhancement techniques are essential for ocean research and engineering applications. In this paper, we propose a progressive multi-branch embedding fusion network (PMEFN) to improve image quality. Specifically, a multi-branch embedding fusion module (MEFM) is designed. The distorted images and its sharpened versions are used as the input, which are fused to learn the contextualized features based on a two-branch hybrid encoder-decoder module (HEDM2) combined with the triple attention module to focus on the noise region. Afterwards, we use the multi-stage refining framework to decompose the image enhancement or marine snow removal tasks into multiple stages and progressively learn the nonlinear functions from the distorted inputs. Additionally, the outputs generated at each stage are further refined and enhanced based on a three-branch hybrid encoder-decoder module (HEDM3). We perform experiments using real underwater datasets, including EUVP, UFO-120, UIEB, and synthetic dataset MSRB. The experimental results show that the proposed method has a superior performance as compared to other methods in terms of quantitative performance and visual quality. In addition, the effectiveness of each component is further validated by performing ablation experiments.
C1 [Sun, Kaichuan] Jiangsu Univ Sci & Technol, Sch Ocean, Zhenjiang 212100, Jiangsu, Peoples R China.
   [Sun, Kaichuan] Chuzhou Univ, Sch Comp & Informat Engn, Chuzhou 239000, Peoples R China.
   [Meng, Fei; Tian, Yubo] Guangzhou Maritime Univ, Sch Informat & Commun Engn, Guangzhou 510725, Peoples R China.
C3 Jiangsu University of Science & Technology; Chuzhou University;
   Guangzhou Maritime University
RP Tian, YB (corresponding author), Guangzhou Maritime Univ, Sch Informat & Commun Engn, Guangzhou 510725, Peoples R China.
EM tianyubo@just.edu.cn
RI Tian, Yu-Bo/ACV-2395-2022
OI Sun, Kaichuan/0000-0003-2229-9915
FU Scientific Research Capacity Improvement Project of Key Developing
   Disciplines in Guangdong Province of China [2021ZDJS057]; National
   Natural Science Foundation of China [61771225]; University Natural
   Science Research Project of Anhui Province [KJ2020B07]
FX This work is supported by the Scientific Research Capacity Improvement
   Project of Key Developing Disciplines in Guangdong Province of China
   (No. 2021ZDJS057), the National Natural Science Foundation of China (No.
   61771225) and University Natural Science Research Project of Anhui
   Province (No. KJ2020B07).
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Chen L, 2021, IEEE T CIRC SYST VID, V31, P3078, DOI 10.1109/TCSVT.2020.3035108
   Chen L, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207506
   Chen XL, 2021, Arxiv, DOI arXiv:2101.00991
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Gao FR, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9020225
   Guo QW, 2017, J OCEAN U CHINA, V16, P757, DOI 10.1007/s11802-017-3242-7
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hou MJ, 2018, IEEE IMAGE PROC, P4043, DOI 10.1109/ICIP.2018.8451209
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUNT BR, 1973, IEEE T COMPUT, VC 22, P805, DOI 10.1109/TC.1973.5009169
   Islam MJ, 2020, IEEE INT C INT ROBOT, P1769, DOI 10.1109/IROS45743.2020.9340821
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Islam MJ, 2020, Arxiv, DOI arXiv:2002.01155
   Jiang Q., 2020, IMAGE COMMUN, V87
   Kaneko R, 2024, Arxiv, DOI arXiv:2103.14249
   Koziarski M., 2018, INT C PATTERN RECOGN, P16
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033023
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2021, IET IMAGE PROCESS, V15, P774, DOI 10.1049/ipr2.12061
   Lin YF, 2021, IEEE SIGNAL PROC LET, V28, P199, DOI 10.1109/LSP.2020.3048619
   Liu P, 2019, IEEE ACCESS, V7, P94614, DOI 10.1109/ACCESS.2019.2928976
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Loshchilov I, 2017, P 5 INT C LEARN REPR
   Marques TP, 2020, IEEE COMPUT SOC CONF, P2286, DOI 10.1109/CVPRW50498.2020.00277
   Metwaly K, 2020, IEEE COMPUT SOC CONF, P1842, DOI 10.1109/CVPRW50498.2020.00234
   Mi ZT, 2018, 2018 OCEANS - MTS/IEEE KOBE TECHNO-OCEANS (OTO)
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Naik A, 2021, Arxiv, DOI arXiv:2101.02073
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Riba E, 2020, Arxiv, DOI arXiv:2009.10521
   Sharma P., 2021, PREPRINT
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Sun X, 2019, IET IMAGE PROCESS, V13, P469, DOI 10.1049/iet-ipr.2018.5237
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang XH, 2019, J OCEAN U CHINA, V18, P376, DOI 10.1007/s11802-019-3858-x
   Wang YQ, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106182
   Wang YD, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116250
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yin SB, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107255
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 54
TC 4
Z9 4
U1 4
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103587
DI 10.1016/j.jvcir.2022.103587
EA JUL 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S1ZS
UT WOS:000839401800001
DA 2024-07-18
ER

PT J
AU Tanwar, VK
   Raman, B
   Rajput, AS
   Bhargava, R
AF Tanwar, Vishesh Kumar
   Raman, Balasubramanian
   Rajput, Amitesh Singh
   Bhargava, Rama
TI <i>SecureDL:</i> A privacy preserving deep learning model for image
   recognition over cloud
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cloud computing; Image classification; Permutation ordered binary number
   system; Encrypted domain
ID ENCRYPTION ALGORITHM; CHAOTIC SYSTEM; SCHEME
AB The key benefits of cloud services such as low cost, access flexibility, and mobility have attracted worldwide users to utilize deep learning algorithms for computer vision. These cloud servers are maintained by third parties, where users are always concerned about sharing their confidential data with them. In this paper, we addressed these concerns for by developing SecureDL, a privacy-preserving image recognition model for encrypted data over cloud. The proposed block-based image encryption scheme is well designed to protect image's visual information. The scheme constitutes an order-preserving permutation ordered binary number system and pseudo-random matrices. The proposed method is proved to be secure in a probabilistic viewpoint, and using various cryptographic attacks. Experiments are conducted over several image recognition datasets, and the trade-off analytics between the achieved recognition accuracy and data encryption is well described. SecureDL overcomes the storage and computational overheads that occur with fully-homomorphic and multi-party computation based secure recognition schemes.
C1 [Tanwar, Vishesh Kumar] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL USA.
   [Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, India.
   [Bhargava, Rama] Indian Inst Technol Roorkee, Dept Math, Roorkee, India.
   [Rajput, Amitesh Singh] Birla Inst Technol & Sci, Pilani, India.
C3 State University System of Florida; University of Central Florida;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee; Birla Institute
   of Technology & Science Pilani (BITS Pilani)
RP Tanwar, VK (corresponding author), Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL USA.
EM visheshkumar.tanwar@ucf.edu
RI Tanwar, Dr. Vishesh Kumar/AFJ-6309-2022
OI Tanwar, Dr. Vishesh Kumar/0000-0002-4802-7582
FU University Grants Commission (UGC) , INDIA [21/12/2014 (ii) EU-V,
   2121440593]
FX Acknowledgment This research was supported by University Grants
   Commission (UGC) , INDIA reference grant number: 21/12/2014 (ii) EU-V,
   2121440593.
CR [Anonymous], 2004, ABSTRACT ALGEBRA
   Bost R, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23241
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fau S, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P284, DOI 10.1109/3PGCIC.2013.48
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hesamifard E., 2017, ARXIV171105189
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jagannathan G., 2005, ACM KDD C, P593, DOI DOI 10.1145/1081870.1081942
   Jha S, 2005, LECT NOTES COMPUT SC, V3679, P397
   Kingma D. P., 2014, arXiv
   Lathey A, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2656205
   Lathey A, 2013, IEEE INT C SEMANT CO, P310, DOI 10.1109/ICSC.2013.60
   Ma X, 2018, INFORM SCIENCES, V459, P103, DOI 10.1016/j.ins.2018.05.005
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Orlandi C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/37343
   Pedrouzo-Ulloa A, 2016, IEEE INT WORKS INFOR
   Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rajput AS, 2018, MULTIMED TOOLS APPL, V77, P24223, DOI 10.1007/s11042-018-5729-7
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Rivest Ronald L., 1978, Found. Secure Comput., V4, P169
   SaghaianNejadEsfahani SM, 2012, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2012.6466843
   Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010036
   Sreekumar A., 2009, Hack, V2009, P33
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tanwar VK, 2018, IEEE SYS MAN CYBERN, P2073, DOI 10.1109/SMC.2018.00357
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Upmanyu M, 2010, LECT NOTES COMPUT SC, V6122, P154, DOI 10.1007/978-3-642-13601-6_17
   Vaidya J., 2002, P 8 ACM SIGKDD INT C, P639, DOI DOI 10.1145/775047.775142
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Xie P., 2014, ABS14126181 CORR
   Xing K, 2017, IEEE T IND INFORM, V13, P2066, DOI 10.1109/TII.2017.2695487
   Yan WQ, 2016, LECT NOTES COMPUT SC, V9431, P775, DOI 10.1007/978-3-319-29451-3_61
   Yonetani R, 2017, IEEE I CONF COMP VIS, P2059, DOI 10.1109/ICCV.2017.225
   Zhang Q., 2017, IEEE Transactions on Big Data
   Zoph B., 2017, ICLR, P1, DOI DOI 10.1109/ICAIIC48513.2020.9065031
NR 46
TC 11
Z9 11
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103503
DI 10.1016/j.jvcir.2022.103503
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1M6GZ
UT WOS:000800067400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pradhan, J
   Pal, AK
   Banka, H
AF Pradhan, Jitesh
   Pal, Arup Kumar
   Banka, Haider
TI A CBIR system based on saliency driven local image features and multi
   orientation texture features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based Image Retrieval (CBIR); Gabor filter; Object detection;
   Saliency map; Singular value decomposition (SVD)
ID FEATURE-EXTRACTION; RETRIEVAL; COLOR; HALLUCINATION; TRANSFORM;
   HISTOGRAMS; GRADIENTS; FRAMEWORK
AB In Content-based Image Retrieval (CBIR), the user provides the query image in which only a selective portion of the image carries the foremost vital information known as the object region of the image. However, the human visual system also focuses on a particular salient region of an image to instinctively understand its semantic meaning. Therefore, the human visual attention technique can be well imposed in the CBIR scheme. Inspired by these facts, we initially utilized the signature saliency map-based approach to decompose the image into its respective main object region (ObR) and non-object region (NObR). ObR possesses most of the vital image information, so block-level normalized singular value decomposition (SVD) has been used to extract salient features of the ObR. In most natural images, NObR plays a significant role in understanding the actual semantic meaning of the image. Accordingly, multi-directional texture features have been extracted from NObR using Gabor filter on different wavelengths. Since the importance of ObR and NObR features are not equal, a new homogeneity-based similarity matching approach has been devised to enhance retrieval accuracy. Finally, we have demonstrated retrieval performances using both the combined and distinct ObR and NObR features on seven standard coral, texture, object, and heterogeneous datasets. The experimental outcomes show that the proposed CBIR system has a promising retrieval efficiency and outperforms various existing systems substantially.
C1 [Pradhan, Jitesh; Pal, Arup Kumar; Banka, Haider] Indian Inst Technol ISM, Dept Comp Sci Engn, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Pradhan, J (corresponding author), Indian Inst Technol ISM, Dept Comp Sci Engn, Dhanbad 826004, Bihar, India.
EM jitpradhan02@gmail.com; arupkrpal@gmail.com; haider.banka@gmail.com
OI Pradhan, Jitesh/0000-0002-6264-4093
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 1997, INTRO WAVELETS WAVEL
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das Gupta R, 2013, PATTERN RECOGN, V46, P3256, DOI 10.1016/j.patcog.2013.05.026
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Galshetwar GM, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102615
   GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Hongpeng Z., 2019, J VIS COMMUN IMAGE R
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Jian MW, 2019, INFORM SCIENCES, V488, P181, DOI 10.1016/j.ins.2019.03.026
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Karaoglu S, 2017, IEEE T MULTIMEDIA, V19, P1063, DOI 10.1109/TMM.2016.2638622
   Khokher A, 2017, MULTIMED TOOLS APPL, V76, P21787, DOI 10.1007/s11042-016-4096-5
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li JX, 2019, INFORM FUSION, V45, P215, DOI 10.1016/j.inffus.2018.02.005
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Meng FJ, 2018, J VIS COMMUN IMAGE R, V55, P572, DOI 10.1016/j.jvcir.2018.07.003
   Min R, 2009, PATTERN RECOGN, V42, P147, DOI 10.1016/j.patcog.2008.07.001
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Peng XS, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2019.102705
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Pradhan J., 2019, IET IMAGE PROCESS
   Pradhan J, 2018, DIGIT SIGNAL PROCESS, V82, P258, DOI 10.1016/j.dsp.2018.07.016
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Ren HY, 2014, IEEE IMAGE PROC, P4057, DOI 10.1109/ICIP.2014.7025824
   Rocha A, 2010, COMPUT ELECTRON AGR, V70, P96, DOI 10.1016/j.compag.2009.09.002
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Teichmann M, 2019, PROC CVPR IEEE, P5104, DOI 10.1109/CVPR.2019.00525
   Varish N, 2017, FUND INFORM, V156, P209, DOI 10.3233/FI-2017-1605
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P15885, DOI 10.1007/s11042-016-3882-4
   Wei SK, 2019, IEEE T IMAGE PROCESS, V28, P4580, DOI 10.1109/TIP.2019.2913513
   Xiang Sean Zhou, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P570, DOI 10.1109/ICIP.1999.822959
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang J, 2017, INFORM SCIENCES, V399, P154, DOI 10.1016/j.ins.2017.03.005
   Zhang J, 2015, J VIS COMMUN IMAGE R, V26, P37, DOI 10.1016/j.jvcir.2014.10.007
NR 56
TC 8
Z9 8
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103396
DI 10.1016/j.jvcir.2021.103396
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200004
DA 2024-07-18
ER

PT J
AU Nguyen, TT
   Nguyen, TP
   Bouchara, F
AF Thanh Tuan Nguyen
   Thanh Phuong Nguyen
   Bouchara, Frederic
TI Dynamic texture representation based on oriented magnitudes of Gaussian
   gradients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic textures; Gaussian-filtered derivatives; Oriented magnitudes;
   LBP; CLBP; Video representation
ID LOCAL BINARY PATTERN; RECOGNITION; SCALE; CLASSIFICATION; DESCRIPTORS;
   SELECTION; FEATURES; PEOPLE; SPACE; COUNT
AB Efficiently capturing shape and turbulent motions of dynamic textures (DTs) for video description is a challenge in real applications due to the negative influences of the well-known problems: environmental elements, illumination, scale, and noise. In this paper, we propose an efficient and simple framework for DT representation based on the oriented features of high-order Gaussian gradients. Firstly, 2D/3D Gaussian-based filtering kernels in high-order partial derivatives are taken into account the video analysis as a preprocessing step to obtain corresponding gradient-filtered images/volumes. After that, the oriented features, which are robust against the above issues, are extracted by decomposing the Gaussian derivative magnitudes into oriented components. Finally, a shallow local encoding is utilized for structuring spatio-temporal features from these oriented magnitudes. This allows constructing discriminative descriptors with promising performances compared to those based on the non-oriented ones. Experimental results for DT classification task on benchmark datasets have verified the interest of our proposal.
C1 [Thanh Tuan Nguyen; Thanh Phuong Nguyen; Bouchara, Frederic] Aix Marseille Univ, Univ Toulon, LIS, CNRS, Marseille, France.
   [Thanh Tuan Nguyen] HCMC Univ Technol & Educ, Fac IT, Ho Chi Minh City, Vietnam.
C3 Centre National de la Recherche Scientifique (CNRS); Aix-Marseille
   Universite; HCMC University of Technology & Education (HCMUTE)
RP Nguyen, TP (corresponding author), Aix Marseille Univ, Univ Toulon, LIS, CNRS, Marseille, France.
EM tuannt@hcmute.edu.vn; tpnguyen@univ-tln.fr; bouchara@univ-tln.fr
OI Nguyen, Thanh Phuong/0000-0002-5646-8505; NGUYEN, Thanh
   Tuan/0000-0002-5210-6152
CR Al-Zaydi ZQH, 2016, J VIS COMMUN IMAGE R, V39, P218, DOI 10.1016/j.jvcir.2016.05.018
   Andrearczyk V, 2018, PATTERN RECOGN, V76, P36, DOI 10.1016/j.patcog.2017.10.030
   [Anonymous], 2017, INT CONF IMAG PROC
   [Anonymous], 1967, AFIPS, DOI 10.1145/1465482.1465560
   Arashloo SR, 2017, J VIS COMMUN IMAGE R, V43, P89, DOI 10.1016/j.jvcir.2016.12.015
   Arashloo SR, 2014, IEEE T MULTIMEDIA, V16, P2099, DOI 10.1109/TMM.2014.2362855
   Baktashmotlagh M, 2014, IEEE T PATTERN ANAL, V36, P2353, DOI 10.1109/TPAMI.2014.2339851
   Chan AB, 2007, PROC CVPR IEEE, P208
   Chen J, 2012, INT C PATT RECOG, P3622
   Chen J, 2013, IEEE T IMAGE PROCESS, V22, P326, DOI 10.1109/TIP.2012.2210234
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dehghan A, 2018, IEEE T PATTERN ANAL, V40, P568, DOI 10.1109/TPAMI.2017.2687462
   Dimitropoulos K, 2015, IEEE T CIRC SYST VID, V25, P339, DOI 10.1109/TCSVT.2014.2339592
   Dubois S, 2015, SIGNAL IMAGE VIDEO P, V9, P819, DOI 10.1007/s11760-013-0532-4
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Ghanem B., 2010, LECT NOTES COMPUT SC, P223
   Ghodsi S, 2018, J VIS COMMUN IMAGE R, V55, P729, DOI 10.1016/j.jvcir.2018.08.001
   Gonçalves WN, 2013, COMPUT VIS IMAGE UND, V117, P1163, DOI 10.1016/j.cviu.2013.04.006
   Goncalves WN, 2013, EXPERT SYST APPL, V40, P4283, DOI 10.1016/j.eswa.2012.12.092
   Gunther N.J, 2007, GUERRILLA CAPACITY P, P41
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hong S, 2018, NEUROCOMPUTING, V273, P611, DOI 10.1016/j.neucom.2017.08.046
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jeyabharathi D, 2018, J VIS COMMUN IMAGE R, V55, P434, DOI 10.1016/j.jvcir.2018.06.024
   Ji H, 2013, IEEE T IMAGE PROCESS, V22, P286, DOI 10.1109/TIP.2012.2214040
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai YX, 2013, INFORM SCIENCES, V230, P39, DOI 10.1016/j.ins.2012.10.002
   Langoni VD, 2020, PATTERN ANAL APPL, V23, P771, DOI 10.1007/s10044-019-00836-w
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Z., 2005, P WORKSHOP MOTION, P241
   Mumtaz A, 2015, IEEE T PATTERN ANAL, V37, P697, DOI 10.1109/TPAMI.2014.2359432
   Mumtaz A, 2013, IEEE T PATTERN ANAL, V35, P1606, DOI 10.1109/TPAMI.2012.236
   Nguyen T.T., 2018, DIRECTIONAL BEAMS DE, P74
   Nguyen TT, 2020, IET COMPUT VIS, V14, P162, DOI 10.1049/iet-cvi.2019.0455
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peh CH, 2002, IEEE T IMAGE PROCESS, V11, P1179, DOI 10.1109/TIP.2002.804265
   Péteri R, 2005, LECT NOTES COMPUT SC, V3523, P223
   Péteri R, 2006, COMPUT IMAGING VIS, V32, P33, DOI 10.1007/1-4020-4179-9_6
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Qi XB, 2016, NEUROCOMPUTING, V171, P1230, DOI 10.1016/j.neucom.2015.07.071
   Quan YH, 2017, COMPUT VIS IMAGE UND, V165, P85, DOI 10.1016/j.cviu.2017.10.008
   Quan YH, 2016, PROC CVPR IEEE, P308, DOI 10.1109/CVPR.2016.40
   Quan YH, 2015, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2015.17
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847
   Ren JF, 2014, IEEE SIGNAL PROC LET, V21, P1346, DOI 10.1109/LSP.2014.2336252
   Ren JF, 2013, INT CONF ACOUST SPEE, P2400, DOI 10.1109/ICASSP.2013.6638085
   Saisan P, 2001, PROC CVPR IEEE, P58
   Shao R, 2019, IEEE T INF FOREN SEC, V14, P923, DOI 10.1109/TIFS.2018.2868230
   Song TC, 2019, IEEE IMAGE PROC, P4405, DOI [10.1109/ICIP.2019.8803518, 10.1109/icip.2019.8803518]
   Srivastava G, 2019, J VIS COMMUN IMAGE R, V62, P330, DOI 10.1016/j.jvcir.2019.06.005
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Nguyen TP, 2016, PATTERN RECOGN LETT, V80, P91, DOI 10.1016/j.patrec.2016.06.003
   Nguyen TP, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600118
   Nguyen TT, 2020, PATTERN RECOGN LETT, V135, P180, DOI 10.1016/j.patrec.2020.04.007
   Nguyen TT, 2019, LECT NOTES COMPUT SC, V11678, P155, DOI 10.1007/978-3-030-29888-3_13
   Nguyen TT, 2020, COMPUT VIS IMAGE UND, V194, DOI 10.1016/j.cviu.2019.102882
   Thanh Tuan Nguyen, 2020, Advanced Concepts for Intelligent Vision Systems. 20th International Conference, ACIVS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12002), P277, DOI 10.1007/978-3-030-40605-9_24
   Nguyen TT, 2019, IEEE IMAGE PROC, P4400, DOI [10.1109/icip.2019.8803449, 10.1109/ICIP.2019.8803449]
   Nguyen TT, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053044
   Tian S, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102576
   Tiwari D, 2017, MULTIMED TOOLS APPL, V76, P6623, DOI 10.1007/s11042-016-3362-x
   Tiwari D, 2017, COMPUT ELECTR ENG, V62, P485, DOI 10.1016/j.compeleceng.2016.11.008
   Tiwari D, 2016, COMPUT VIS IMAGE UND, V150, P58, DOI 10.1016/j.cviu.2016.04.010
   Tiwari D, 2016, MULTIDIM SYST SIGN P, V27, P563, DOI 10.1007/s11045-015-0319-6
   Wang Y, 2016, SOFT COMPUT, V20, P1977, DOI 10.1007/s00500-015-1618-4
   Xu Y, 2015, PATTERN RECOGN, V48, P3239, DOI 10.1016/j.patcog.2015.04.015
   Xu Y, 2012, COMPUT VIS IMAGE UND, V116, P999, DOI 10.1016/j.cviu.2012.05.003
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Nguyen XS, 2018, MULTIMED TOOLS APPL, V77, P8531, DOI 10.1007/s11042-017-4749-z
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhao XC, 2019, IEEE T MULTIMEDIA, V21, P1694, DOI 10.1109/TMM.2018.2890362
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 81
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103330
DI 10.1016/j.jvcir.2021.103330
EA NOV 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700007
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Zhang, LQ
   Wang, D
   Shi, YJ
   Lin, JJ
AF Zhang, Qing
   Zhang, Liqian
   Wang, Dong
   Shi, Yanjiao
   Lin, Jiajun
TI Global and local information aggregation network for edge-aware salient
   object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Saliency; Multi-level feature aggregation;
   Attention; Salient edge
ID MODEL
AB Aggregation of local and global contextual information by exploiting multi-level features in a fully convolutional network is a challenge for the pixel-wise salient object detection task. Most existing methods still suffer from inaccurate salient regions and blurry boundaries. In this paper, we propose a novel edge-aware global and local information aggregation network (GLNet) to fully exploit the integration of side-output local features and global contextual information and utilization of contour information of salient objects. The global guidance module (GGM) is proposed to learn discriminative multi-level information with the direct guidance of global semantic knowledge for more accurate saliency prediction. Specifically, the GGM consists of two key components, where the global feature discrimination module exploits the inter-channel relationship of global semantic features to boost representation power, and the local feature discrimination module enables different side-output local features to selectively learn informative locations by fusing with global attentive features. Besides, we propose an edge-aware aggregation module (EAM) to employ the correlation between salient edge information and salient object information for generating estimated saliency maps with explicit boundaries. We evaluate our proposed GLNet on six widely-used saliency detection benchmark datasets by comparing with 17 state-of-the-art methods. Experimental results show the effectiveness and superiority of our proposed method on all the six benchmark datasets.
C1 [Zhang, Qing; Zhang, Liqian; Wang, Dong; Shi, Yanjiao] Shanghai Inst Technol, Dept Comp Sci & Informat Engn, Shanghai, Peoples R China.
   [Lin, Jiajun] East China Univ Sci & Technol, Dept Informat Sci & Engn, Shanghai, Peoples R China.
C3 Shanghai Institute of Technology; East China University of Science &
   Technology
RP Zhang, Q (corresponding author), Shanghai Inst Technol, Dept Comp Sci & Informat Engn, Shanghai, Peoples R China.
EM zhangqing0329@gmail.com
RI Zhang, Lanyue/JNS-8209-2023; yi, li/KFR-6141-2024; Li, Ly/JCD-4746-2023
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Cai Q, 2019, PATTERN RECOGN, V93, P147, DOI 10.1016/j.patcog.2019.04.019
   Chen L.-C., 2017, IEEE C COMP VIS PATT
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen SH, 2020, IEEE T CYBERNETICS, V50, P2050, DOI 10.1109/TCYB.2018.2879859
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li JY, 2021, IEEE T CYBERNETICS, V51, P3925, DOI 10.1109/TCYB.2020.3008280
   Li JX, 2021, IEEE T MULTIMEDIA, V23, P1397, DOI 10.1109/TMM.2020.2997192
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu Y, 2020, IEEE T IMAGE PROCESS, V29, P360, DOI 10.1109/TIP.2019.2930906
   Liu Y, 2022, IEEE T CYBERNETICS, V52, P6131, DOI 10.1109/TCYB.2021.3051350
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Wang HY, 2017, PATTERN RECOGN, V67, P340, DOI 10.1016/j.patcog.2017.01.033
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang LH, 2020, IEEE T IMAGE PROCESS, V29, P3534, DOI 10.1109/TIP.2019.2962688
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang QJ, 2021, IEEE T IMAGE PROCESS, V30, P1305, DOI 10.1109/TIP.2020.3042084
   Zhang Q, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P582, DOI 10.1145/3240508.3240595
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhu L, 2020, IEEE T CIRC SYST VID, V30, P3358, DOI 10.1109/TCSVT.2019.2941017
NR 69
TC 4
Z9 5
U1 5
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103350
DI 10.1016/j.jvcir.2021.103350
EA OCT 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WP1JM
UT WOS:000712896500005
DA 2024-07-18
ER

PT J
AU Yu, YX
   Zheng, N
   Qiao, T
   Xu, M
   Wu, JS
AF Yu, Yangxin
   Zheng, Ning
   Qiao, Tong
   Xu, Ming
   Wu, Jiasheng
TI Distinguishing between natural and recolored images via lateral
   chromatic aberration*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Recolored images detection; Lateral chromatic
   aberration
AB With the development of image colorization technique, the recolored images (RIs) become more and more authentic, making it very difficult to visually distinguish from natural images (NIs). Recently, researchers have proposed the detection methods towards recolored images. However, the current detection still has limitations such as poor generalization, large-scale training samples, high-dimensional features for training, and high computation cost. To address those issues, this paper proposes a novel method based on the lateral chromatic aberration (LCA) inconsistency and its statistical differences. Generally, RIs have fewer numbers of LCA characteristics than that of NIs, that inspire us to design the classifier for distinguishing two types of images. In particular, we propose to adopt very low 5-dimensional features to feed a classical SVM mechanism. The baseline ImageNet and Oxford datasets are used to verify the effectiveness of the proposed method, in which the performance of our proposed method rivals the prior arts.
C1 [Yu, Yangxin; Zheng, Ning; Qiao, Tong; Xu, Ming; Wu, Jiasheng] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
   [Qiao, Tong] Zhengzhou Sci & Technol Inst, State Key Lab Math Engn & Adv Comp, Zhengzhou, Peoples R China.
C3 Hangzhou Dianzi University; PLA Information Engineering University
RP Qiao, T (corresponding author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
EM tong.qiao@hdu.edu.cn
FU Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK219909299001007]; Natural Science Foundation of China [61803135]
FX This work was funded by the Fundamental Research Funds for the
   Provincial Universities of Zhejiang under grant No. GK219909299001007,
   and the Natural Science Foundation of China under No. 61803135.
CR Agarwal S, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P507, DOI [10.1109/Confluence47617.2020.9057922, 10.1109/confluence47617.2020.9057922]
   Chen XB, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185525
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Cho J, 2017, IEEE COMPUT SOC CONF, P1058, DOI 10.1109/CVPRW.2017.143
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gloe T, 2010, PROC SPIE, V7541, DOI 10.1117/12.839034
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lei CY, 2019, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2019.00387
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Mallon J, 2007, PATTERN RECOGN LETT, V28, P125, DOI 10.1016/j.patrec.2006.06.013
   Mayer O., 2018, IEEE T INFORM FORENS, V13
   Ng T-T., 2005, ADVENT Technical Report, P205
   Pang JH, 2013, INT CONF ACOUST SPEE, P1578, DOI 10.1109/ICASSP.2013.6637917
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Quan W., ARXIV PREPRINT ARXIV
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
   Yan YY, 2019, IEEE T INF FOREN SEC, V14, P5, DOI 10.1109/TIFS.2018.2834155
   Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738
   Zeng JS, 2019, IEEE T INF FOREN SEC, V14, P2735, DOI 10.1109/TIFS.2019.2904413
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhuo L, 2018, ASIAPAC SIGN INFO PR, P733, DOI 10.23919/APSIPA.2018.8659761
NR 30
TC 6
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103295
DI 10.1016/j.jvcir.2021.103295
EA SEP 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA3DL
UT WOS:000702769700003
DA 2024-07-18
ER

PT J
AU Ji, PL
   Li, J
   Li, HC
   Liu, XG
AF Ji, Penglei
   Li, Jie
   Li, Hanchao
   Liu, Xinguo
TI Superpixel alpha-expansion and normal adjustment for stereo matching*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Superpixel; Alpha-expansion; Graph cuts; Normal
   adjustment
ID BELIEF PROPAGATION
AB This paper presents a continuous stereo disparity estimation method based on superpixel segmentation and graph-cuts. We re-parameterize the disparity with a 3D tangent plane, and propose two algorithms to optimize the Markov Random Field (MRF) energy. The first algorithm, called superpixel alpha-expansion, is built on superpixel segmentation to localize the label proposal and the expansion scope. Three levels of superpixels with increasing granularity are generated for acceleration. The second algorithm, called normal adjustment, optimizes the 3D planes for the regions with low texture and/or illumination changes. The normal adjustment is performed along a depth-first similarity path of superpixels. We evaluate our method on the Middlebury 3.0 evaluation benchmark and the Eth3d benchmark. Experimental results show that our method achieves high accuracy on both evaluation benchmarks. (Middlebury 3.0 evaluation benchmark: http://vision.middlebury.edu/stereo/eval3/. Eth3d benchmark: https://www.eth3d.net/low_res_two_view.)
C1 [Ji, Penglei; Li, Jie; Li, Hanchao; Liu, Xinguo] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Liu, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
EM xgliu@cad.zju.edu.cn
RI sun, yuan/KBD-3926-2024; Li, Jie/AAE-6389-2019; zhao,
   wenqing/KEZ-9488-2024; Wang, Jin/GYA-2019-2022
FU National Natural Science Foundation of China [61872317]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and helpful suggestions. This work was supported by
   the National Natural Science Foundation of China under Grant Nos.
   61872317.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2016, J MACH LEARN RES
   BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   Güney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044
   Hadfield S, 2015, IEEE I CONF COMP VIS, P783, DOI 10.1109/ICCV.2015.96
   Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li L., 2016, IEEE T CIRCUITS SYST
   Li LC, 2017, APPL OPTICS, V56, P3411, DOI 10.1364/AO.56.003411
   Olsson C, 2013, PROC CVPR IEEE, P1730, DOI 10.1109/CVPR.2013.226
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Taniai T, 2014, PROC CVPR IEEE, P1613, DOI 10.1109/CVPR.2014.209
   Taniai Tatsunori., 2017, IEEE Trans. on Pattern Analysis and Machine Intelligence
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yamaguchi K, 2012, LECT NOTES COMPUT SC, V7576, P45, DOI 10.1007/978-3-642-33715-4_4
   Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
NR 26
TC 6
Z9 6
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103238
DI 10.1016/j.jvcir.2021.103238
EA JUL 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800003
DA 2024-07-18
ER

PT J
AU Debnath, R
   Bhowmik, MK
AF Debnath, Rajib
   Bhowmik, Mrinal Kanti
TI A comprehensive survey on computer vision based concepts, methodologies,
   analysis and applications for automatic gun/knife detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weapon detection; Survey; Security and surveillance; Multiple object
   detection; Visual and concealed
ID CONCEALED WEAPON DETECTION; IMAGE FUSION; HANDGUN DETECTION;
   RECOGNITION; OBJECT; FEATURES; VIDEOS
AB The ability to detect gun and gun held in hand or other body parts is a typical human skill. The same problem presents an imperative task for computer vision system. Automatic observer independent detection of hand held gun or gun held in the other body part, whether it is visible or concealed, provides enhance security in vulnerable places and initiates appropriate action there. Compare to the automatic object detection systems, automatic detection of gun has very few successful attempts. In the present scope of this paper, we present an extensive survey on automatic detection of gun and define a taxonomy for this particular detection system. We also describe the inherent difficulties related with this problem. In this survey of published papers, we examine different approaches used in state-of-the-art attempts and compare performances of these approaches. Finally, this paper concludes pointing to the possible research gaps in related fields.
C1 [Debnath, Rajib; Bhowmik, Mrinal Kanti] Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 7990022, Tripura, India.
C3 Tripura University
RP Bhowmik, MK (corresponding author), Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 7990022, Tripura, India.
EM rajibdebnath.cse@gmail.com; mrinalkantibhowmik@tripurauniv.ac.in
RI Bhowmik, Mrinal Kanti/AAY-8356-2020; Debnath, Dr. Rajib/GPX-6438-2022
OI Bhowmik, Mrinal Kanti/0000-0003-3451-191X; Debnath, Dr.
   Rajib/0000-0003-4981-6046
CR Adhi BP, 2018, 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL CONFERENCE (INAPR), P67, DOI 10.1109/INAPR.2018.8627033
   Ainsworth T., 2002, Security Oz, V19, P18
   Akcay S., 2018, IEEE T INF FOREN SEC, V13, P2203, DOI DOI 10.1109/TIFS.2018.2812196
   [Anonymous], 2009, ACM INT C PROCEEDING, DOI DOI 10.1145/1558607.1558630
   Aragon-Camarasa G, 2010, PATTERN RECOGN LETT, V31, P1274, DOI 10.1016/j.patrec.2010.03.003
   Ardizzone E, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P25
   Bandyopadhyay S., 2012, ARXIV PREPRINT ARXIV
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cardoso G.V.S., 2019, ANAIS 15 WORKSHOP VI, P109, DOI DOI 10.5753/WVC.2019.7637
   Castillo A, 2019, NEUROCOMPUTING, V330, P151, DOI 10.1016/j.neucom.2018.10.076
   Cho SY, 2010, TENCON IEEE REGION, P228, DOI 10.1109/TENCON.2010.5685995
   Choi K.N., 2014, J SENSORS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Darker I.T., 2009, VISUAL INFORM PROCES, V7341, P73410
   Deepthi T.H., 2019, 2018 1 INT C SEC CYB
   Dubey S., 2019, PROGRAM CHAIR P, P16546
   el den Mohamed Mai Kamal, 2020, International Journal of Sociotechnology and Knowledge Development, V12, P49, DOI 10.4018/IJSKD.2020010103
   Elmir Y., 2019, JERI
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gelana Fraol, 2019, Smart Innovations in Communication and Computational Sciences. Proceedings of ICSICCS-2018. Advances in Intelligent Systems and Computing (AISC 851), P25, DOI 10.1007/978-981-13-2414-7_3
   Glowacz A, 2015, MULTIMED TOOLS APPL, V74, P4253, DOI 10.1007/s11042-013-1537-2
   Goyal Ayush, 2020, Emerging Trends in Electrical, Communications, and Information Technologies. Proceedings of ICECIT-2018. Lecture Notes in Electrical Engineering (LNEE 569), P751, DOI 10.1007/978-981-13-8942-9_64
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   Grega M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010047
   Haladová Z, 2014, LECT NOTES COMPUT SC, V8671, P246, DOI 10.1007/978-3-319-11331-9_30
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hussein N.J, 2016, 2016 INT C INN MAT S
   Hussein NJ, 2017, PATTERN RECOGN LETT, V94, P219, DOI 10.1016/j.patrec.2016.12.011
   imfdb, The Internet Movie Firearms Database
   Iqbal J, 2019, ARXIV PREPRINT ARXIV
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Kaur A., 2016, 2016 International Conference on Control, Computing, Communication and Materials (ICCCCM), P1
   Khajone B., 2012, INT J SCI ENG, V3, P1
   Khotanzad A., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P326, DOI 10.1109/ICPR.1988.28233
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Kowalski M., 2015, SAF SECUR ENG 6, V151, P215
   Lai J., 2017, Course: CS231n
   Lillholm M, 2009, IMAGE VISION COMPUT, V27, P771, DOI 10.1016/j.imavis.2008.08.003
   Lingg A.J., 2009, TERAHERTZ PHYS DEVIC, V7311
   Liu Z, 2006, PATTERN ANAL APPL, V8, P375, DOI 10.1007/s10044-005-0020-8
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahajan R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P375, DOI 10.1109/ICSCCC.2018.8703346
   Malik J., 2011, International Journal of Computer Applications (0975 - 8887), V22, P28, DOI 10.5120/2546-3489
   Matiolanski A, 2016, MULTIMED TOOLS APPL, V75, P10513, DOI 10.1007/s11042-015-2697-z
   Megherbi N, 2010, IEEE IMAGE PROC, P1833, DOI 10.1109/ICIP.2010.5653676
   Mery D, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0315-7
   Fernandez-Carrobles MM, 2019, LECT NOTES COMPUT SC, V11868, P441, DOI 10.1007/978-3-030-31321-0_38
   Nandhini N., 2017, INT J ENG DEV RES, V5, P436
   Oh K, 2016, IMAGE VISION COMPUT, V54, P31, DOI 10.1016/j.imavis.2016.07.007
   Olmos R, 2019, INFORM FUSION, V49, P271, DOI 10.1016/j.inffus.2018.11.015
   Olmos R, 2018, NEUROCOMPUTING, V275, P66, DOI 10.1016/j.neucom.2017.05.012
   Olsson J., 2019, CLIENT SERVER SOLUTI
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Ramac LC, 1998, P SOC PHOTO-OPT INS, V3376, P110, DOI 10.1117/12.303671
   Romero D., 2019, INT C ADV EM TRENDS, P348
   Romero D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9152965
   Shen XL, 2008, IEEE T IMAGE PROCESS, V17, P2465, DOI 10.1109/TIP.2008.2006662
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Slamani MA, 2002, P SOC PHOTO-OPT INS, V4719, P296, DOI 10.1117/12.477470
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tiwari RK, 2015, PROCEDIA COMPUT SCI, V54, P703, DOI 10.1016/j.procs.2015.06.083
   Toet A, 2003, PROC SPIE, V5071, P372, DOI 10.1117/12.484845
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Uner MK, 1997, P SOC PHOTO-OPT INS, V2942, P123, DOI 10.1117/12.267176
   United nations office on drugs and crime (UNODC), 2013, GLOB STUD HOM 2013 D
   Upadhyay E.M., 2013, INT J LATEST TECHNOL, V1, P20
   Vajhala R., 2016, DISSERTATION
   Velastin SA, 2006, TRANSPORT RES C-EMER, V14, P96, DOI 10.1016/j.trc.2006.05.006
   Verma GK, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P84, DOI 10.1145/3154979.3154988
   Vijayalakshmi P., 2013, IOSR J COMPUT ENG, V13, P25
   Villamizar M, 2016, COMPUT VIS IMAGE UND, V149, P51, DOI 10.1016/j.cviu.2016.03.010
   Vo BN, 2010, IEEE T SIGNAL PROCES, V58, P5129, DOI 10.1109/TSP.2010.2050482
   WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Xu T., 2015, 6 INT C IM CRIM PREV, P1
   Xue Z, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL II, P1198, DOI 10.1109/ICIF.2002.1020949
   Xue ZY, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P622
   Zhang Z., 1997, C INFORM SCI SYSTEMS, P168
   최규남, 2014, [The Journal of The Korea Institute of Electronic Communication Sciences, 한국전자통신학회 논문지], V9, P161
NR 85
TC 4
Z9 4
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103165
DI 10.1016/j.jvcir.2021.103165
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1MD
UT WOS:000674618200005
DA 2024-07-18
ER

PT J
AU Zhao, SY
   Chen, ZB
AF Zhao, Shengyang
   Chen, Zhibo
TI Various density light field image coding based on distortion
   minimization interpolation *
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light field image; View partition; Camera array; Image compression; View
   synthesis; Linear approximation
ID COMPRESSION; PREDICTION
AB In recent years, the light field (LF) as a new imaging modality has attracted wide interest. The large data volume of LF images poses great challenge to LF image coding, and the LF images captured by different devices show significant differences in angular domain. In this paper we propose a view prediction framework to handle LF image coding with various sampling density. All LF images are represented as view arrays. We first partition the views into reference view (RV) set and intermediate view (IV) set. The RVs are rearranged into a pseudo sequence and directly compressed by a video encoder. Other views are then predicted by the RVs. To exploit the four dimensional signal structure, we propose the linear approximation prior (LAP) to reveal the correlation among LF views and efficiently remove the LF data redundancy. Based on the LAP, a distortion minimization interpolation (DMI) method is used to predict IVs. To robustly handle the LF images with different sampling density, we propose an Iteratively Updating depth image based rendering (IU-DIBR) method to extend our DMI. Some auxiliary views are generated to cover the target region and then the DMI calculates reconstruction coefficients for the IVs. Different view partition patterns are also explored. Extensive experiments on different types LF images also valid the efficiency of the proposed method.
C1 [Zhao, Shengyang; Chen, Zhibo] Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Chen, ZB (corresponding author), Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.
EM chenzhibo@ustc.edu.cn
RI YANG, DAN/KCL-5217-2024; qin, cheng/KHC-3344-2024; CAO,
   ying/KFA-2972-2024
CR Aggoun A, 2006, INT CONF ACOUST SPEE, P1765
   Aggoun A, 2011, J DISP TECHNOL, V7, P586, DOI 10.1109/JDT.2011.2159359
   Ahmad W, 2017, IEEE IMAGE PROC, P4557, DOI 10.1109/ICIP.2017.8297145
   Amirpour H, 2018, IEEE DATA COMPR CONF, P397, DOI 10.1109/DCC.2018.00050
   [Anonymous], 2015, NOVEL 3D MEDIA TECHN
   [Anonymous], 2017, 76 M
   [Anonymous], 2017, 74 M GEN JAN 2017
   [Anonymous], 2019, 84 M BRUSS JUL
   [Anonymous], 2020, 86 M
   Astola P, 2019, IEEE ACCESS, V7, P176820, DOI 10.1109/ACCESS.2019.2957934
   Astola P, 2018, EUR W VIS INF PROCES
   Bakir N, 2019, IEEE DATA COMPR CONF, P554, DOI 10.1109/DCC.2019.00066
   Cao X, 2014, OPT EXPRESS, V22, P24081, DOI 10.1364/OE.22.024081
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen J, 2017, IEEE T CIRC SYST VID, V27, P855, DOI 10.1109/TCSVT.2015.2513485
   Conti C, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574667
   Conti C, 2016, SIGNAL PROCESS-IMAGE, V42, P59, DOI 10.1016/j.image.2016.01.008
   Conti C, 2012, IEEE IMAGE PROC, P1325, DOI 10.1109/ICIP.2012.6467112
   Dai F, 2015, IEEE IMAGE PROC, P4733, DOI 10.1109/ICIP.2015.7351705
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   Dick J., 2011, 2011 IEEE EUROCON IN, P1
   Girod B, 2000, PROGRESSIVE COMPRESS
   Graziosi DB, 2015, PROC SPIE, V9391, DOI 10.1117/12.2083439
   Heber S, 2014, LECT NOTES COMPUT SC, V8694, P751
   Hou JH, 2019, IEEE T CIRC SYST VID, V29, P517, DOI 10.1109/TCSVT.2018.2802943
   Huang HY, 2016, PROC IEEE MICR ELECT, P2, DOI 10.1109/MEMSYS.2016.7421542
   Jia CM, 2019, IEEE J EM SEL TOP C, V9, P177, DOI 10.1109/JETCAS.2018.2886642
   Jin X, 2018, IEEE T IMAGE PROCESS, V27, P3954, DOI 10.1109/TIP.2018.2832449
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Lin ZC, 2004, INT J COMPUT VISION, V58, P121, DOI 10.1023/B:VISI.0000015916.91741.27
   Lippmann G, 1908, CR HEBD ACAD SCI, V146, P446
   Liu D, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574674
   Magnor MarcusA., 2015, DIGITAL REPRESENTATI
   Monteiro R, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574670
   Olsson R, 2007, PROC SPIE, V6508, DOI 10.1117/12.704330
   Olsson R, 2006, IEEE IMAGE PROC, P513, DOI 10.1109/ICIP.2006.312389
   Perra C, 2016, IEEE INT CONF MULTI
   Rerabek M., 2016, Call for Proposals and Evaluation Procedure
   Schiopu I, 2018, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2018.8451731
   Sepas-Moghaddam A, 2017, IEEE IMAGE PROC, P3815, DOI 10.1109/ICIP.2017.8296996
   Sgouros N, 2008, APPL OPTICS, V47, pD28, DOI 10.1364/AO.47.000D28
   Shi S, 2011, IEEE IMAGE PROC, P137, DOI 10.1109/ICIP.2011.6115695
   Tabus I, 2017, IEEE IMAGE PROC, P4567, DOI 10.1109/ICIP.2017.8297147
   Vieira A, 2015, INT CONF IMAG PROC, P494, DOI 10.1109/IPTA.2015.7367195
   Viola I, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322827
   Wang Q., 2017, IEEE CVPR
   Xu D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1071, DOI 10.1109/ICME.2004.1394394
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Yun Li, 2016, 2016 IEEE International Conference on Multimedia & Expo: Workshops (ICMEW), DOI 10.1109/ICMEW.2016.7574673
   Zhao SY, 2017, IEEE IMAGE PROC, P4562, DOI 10.1109/ICIP.2017.8297146
   Zhong R, 2016, PICT COD SYMP
   Zhong R, 2019, IEEE T CIRC SYST VID, V29, P1116, DOI 10.1109/TCSVT.2018.2826052
NR 55
TC 0
Z9 0
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103036
DI 10.1016/j.jvcir.2021.103036
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600001
DA 2024-07-18
ER

PT J
AU Ren, DK
   Wen, XM
   Jia, T
   Chen, JZ
   Li, ZY
AF Ren, Dakai
   Wen, Xiangming
   Jia, Tao
   Chen, Jiazhong
   Li, Zongyi
TI Saliency detection via cross-scale deep inference*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-scale deep inference; Multi-layer attention; Image saliency; Deep
   learning
ID VISUAL-ATTENTION; NETWORK; MODEL
AB The small, moderate, and large scale saliency patterns in images are valuable to be extracted in saliency detection. By the observation that the probability of small and large saliency patterns appearing in datasets is lower than that of moderate scale saliency patterns. As results, a deep saliency model trained on such datasets would converge to moderate scale saliency patterns, and it is hard to well infer the small and large scale saliency patterns because they are not encoded efficiently in the model for their low probability. Thus a novel but simple saliency detection method using cross-scale deep inference is presented in this paper. Moreover, a new network architecture, in which the attention mechanism is exploited by multiple layers, is proposed to improve the receptive fields of various scale saliency patterns in different scale images. The presented cross-scale deep inference could improve the representation power of small and large scale saliency patterns encoded in multiple scale images efficiently. The quantitative and qualitative evaluation demonstrates our deep model achieves a promising results across a wide of metrics.
C1 [Ren, Dakai; Wen, Xiangming] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Jia, Tao; Chen, Jiazhong; Li, Zongyi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Huazhong University of
   Science & Technology
RP Chen, JZ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM jzchen@hust.edu.cn
RI Li, Zongyi/AAY-3602-2020
OI Li, Zongyi/0000-0002-5989-9132
FU Beijing Nova Program [Z201100006820123]; Beijing Municipal Science and
   Technology Commission, China; Natural Science Foundation of China
   [U1536203, 61972169]; National key research and development program of
   China [2016QY01W0200]; Major Scientific and Technological Project of
   Hubei Province, China [2018AAA068, 2019AAA051]
FX This work was supported in part by the Beijing Nova Program
   (Z201100006820123) from Beijing Municipal Science and Technology
   Commission, China, in part by the Natural Science Foundation of China
   under Grant U1536203 and 61972169, in part by the National key research
   and development program of China (2016QY01W0200) , in part by the Major
   Scientific and Technological Project of Hubei Province, China
   (2018AAA068 and 2019AAA051) .
CR [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], 2012, NIPS DEEP LEARN UNS
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce NDB, 2016, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2016.62
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2016, IEEE T CYBERNETICS, V46, P487, DOI 10.1109/TCYB.2015.2404432
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L., ARXIV150503581
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T., 2012, A benchmark of computational models of saliency to predict human fixations
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kingma D. P., 2014, arXiv
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Kümmerer M, 2018, LECT NOTES COMPUT SC, V11220, P798, DOI 10.1007/978-3-030-01270-0_47
   Kummerer M., 2015, INT C LEARN REPR ICL
   Leborán V, 2017, IEEE T PATTERN ANAL, V39, P893, DOI 10.1109/TPAMI.2016.2567391
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu S, 2018, IEEE T IMAGE PROCESS, V27, P5032, DOI 10.1109/TIP.2018.2836313
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tavakoli HR, 2017, NEUROCOMPUTING, V244, P10, DOI 10.1016/j.neucom.2017.03.018
   UNSER M, 1992, IEEE T INFORM THEORY, V38, P864, DOI 10.1109/18.119742
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wei Z, 2017, PROC CVPR IEEE, P3947, DOI 10.1109/CVPR.2017.420
   Xia C, 2016, IEEE T NEUR NET LEAR, V27, P1227, DOI 10.1109/TNNLS.2015.2512898
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou Z., ARXIV PREPRINT ARXIV
NR 58
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103031
DI 10.1016/j.jvcir.2021.103031
EA JAN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT8KH
UT WOS:000626836800002
DA 2024-07-18
ER

PT J
AU Lin, J
   Horng, JH
   Liu, YJ
   Chang, CC
AF Lin, Juan
   Horng, Ji-Hwei
   Liu, Yanjun
   Chang, Chin-Chen
TI An anisotropic reference matrix for image steganography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anisotropic reference matrix; Data hiding; Steganography; Visual
   quality; Embedding capacity
ID DIGITAL IMAGES
AB A lot of image steganographic techniques (also called data hiding) conceal secret data by utilizing a reference matrix (RM), and some new types of RMs, such as the turtle shell, an octagon-shaped shell, the Sudoku table, and so on, have been proposed in recent years. In this article, we present a novel type of RM called anisotropic RM. By employing a full search strategy, we have found the optimal parameters for constructing the anisotropic RM. To judge the performance of a parameter set quickly, a theoretical peak signal-to-noise ratio (PSNR) evaluation method is proposed. In addition, we extend the RM to three-dimensional (3D) space. Experimental results show that our data hiding scheme, based on the anisotropic RM, has a better quality stego image than previous methods. Moreover, the 3D RM works better than the traditional 2D RM using the same embedding capacity.
C1 [Lin, Juan] Fujian Prov Univ, Fuqing Branch, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou 350300, Peoples R China.
   [Horng, Ji-Hwei] Natl Quemoy Univ, Dept Elect Engn, Kinmen 89250, Taiwan.
   [Liu, Yanjun; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Fuzhou University; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI liu, yan/HGV-1365-2022; Chang, Ching-Chun/JAN-6210-2023; 刘,
   严君/GZL-5764-2022; liu, yan/HCI-5542-2022; Horng, Jihwei/GPX-5709-2022
OI Horng, Ji-Hwei/0000-0002-2134-5257
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Fan Li, 2016, International Journal of Network Security, V18, P410
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   He MZ, 2019, IEEE ACCESS, V7, P141414, DOI 10.1109/ACCESS.2019.2943616
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Horng JH, 2020, CMES-COMP MODEL ENG, V125, P879, DOI 10.32604/cmes.2020.09355
   Horng JH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092739
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kurup S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1982, DOI 10.1109/ICACCI.2015.7275908
   Leng HS, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060760
   Liao X., MULTIMED TOOLS APPL, DOI [10.1007/s11042-017- 4946-9., DOI 10.1007/S11042-017-4946-9.]
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Nguyen TS, 2015, DISPLAYS, V39, P109, DOI 10.1016/j.displa.2015.10.003
   Qiang Jin, 2017, International Journal of Network Security, V19, P154, DOI 10.6633/IJNS.201701.19(1).16
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Xia B-B, 2016, J INF HIDING MULTIME, V7, P836
   Xie XZ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020047
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 26
TC 3
Z9 3
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102969
DI 10.1016/j.jvcir.2020.102969
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OM
UT WOS:000613151000001
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Jin, T
   Zhou, WJ
   Lei, JS
AF Zhang, Xinyue
   Jin, Ting
   Zhou, Wujie
   Lei, Jingsheng
TI Attention-based contextual interaction asymmetric network for RGB-D
   saliency prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D image; Saliency prediction; Attention mechanism; Contextual
   interaction
ID COMPUTATIONAL MODEL
AB Saliency prediction on RGB-D images is an underexplored and challenging task in computer vision. We propose a channel-wise attention and contextual interaction asymmetric network for RGB-D saliency prediction. In the proposed network, a common feature extractor provides cross-modal complementarity between the RGB image and corresponding depth map. In addition, we introduce a four-stream feature-interaction module that fully leverages multiscale and cross-modal features for extracting contextual information. Moreover, we propose a channel-wise attention module to highlight the feature representation of salient regions. Finally, we refine coarse maps through a corresponding refinement block. Experimental results show that the proposed network achieves a performance comparable with state-of-the-art saliency prediction methods on two representative datasets.
C1 [Zhang, Xinyue; Jin, Ting] Hainan Univ, Sch Comp Sci & Cyberspace Secur, Haikou 570228, Hainan, Peoples R China.
   [Zhou, Wujie; Lei, Jingsheng] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Peoples R China.
   [Zhou, Wujie] Zhejiang Univ, Coll Informat & Elect Engn, Hangzhou 310027, Peoples R China.
C3 Hainan University; Zhejiang University of Science & Technology; Zhejiang
   University
RP Jin, T (corresponding author), Hainan Univ, Sch Comp Sci & Cyberspace Secur, Haikou 570228, Hainan, Peoples R China.
EM tingj@fudan.edu.cn
OI zhou, wujie/0000-0002-3055-2493; Zhang, Xinyue/0000-0003-4601-2595
FU National Natural Science Foundation of China [61502429, 61862021,
   61972357, 61971247]; Zhejiang Provincial Natural Science Foundation of
   China [LY18F020012]; Hainan Provincial Natural Science Foundation of
   China [618QN217]
FX This work was supported by the National Natural Science Foundation of
   China (61502429, 61862021, 61972357, 61971247); the Zhejiang Provincial
   Natural Science Foundation of China (LY18F020012); and the Hainan
   Provincial Natural Science Foundation of China (618QN217).
CR Aksu Aksu E. E., P UEVIP 18 NOV 26 28, P1
   Nguyen AD, 2019, IEEE T IMAGE PROCESS, V28, P1939, DOI 10.1109/TIP.2018.2879408
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Banitalebi-Dehkordi A, 2017, MULTIMED TOOLS APPL, V76, P23859, DOI 10.1007/s11042-016-4155-y
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cheng H, 2019, IEEE T MULTIMEDIA, V21, P678, DOI 10.1109/TMM.2018.2864613
   Cheng H, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0210-5
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fang YM, 2017, NEUROCOMPUTING, V266, P284, DOI 10.1016/j.neucom.2017.05.050
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang QP, 2015, SIGNAL PROCESS-IMAGE, V38, P57, DOI 10.1016/j.image.2015.04.007
   Krizhevsky Krizhevsky A. A., P NIPS, P345
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lee H, 2018, IEEE WINT CONF APPL, P1170, DOI 10.1109/WACV.2018.00133
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Liu D, 2018, J VIS COMMUN IMAGE R, V57, P218, DOI 10.1016/j.jvcir.2018.10.002
   Liu WQ, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P495, DOI [10.1109/ITNEC.2019.8729365, 10.1109/itnec.2019.8729365]
   Lv Y., OPT EXPRESS, V27, P34056
   Ma CY, 2015, J VISION, V15, DOI 10.1167/15.6.19
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Qi F, 2017, MULTIMED TOOLS APPL, V76, P3087, DOI 10.1007/s11042-015-3229-6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tavakoli HR, 2017, NEUROCOMPUTING, V244, P10, DOI 10.1016/j.neucom.2017.03.018
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wu JW, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107766
   Xia C, 2018, NEUROCOMPUTING, V321, P126, DOI 10.1016/j.neucom.2018.09.009
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan B, 2017, IEEE IMAGE PROC, P2339, DOI 10.1109/ICIP.2017.8296700
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Zhang M, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2231-4
   Zhang ZJ, 2013, THERANOSTICS, V3, P223, DOI 10.7150/thno.5409
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou D., 2020, ARXIV200309669
   Zhou WJ, 2021, IEEE T MULTIMEDIA, V23, P3388, DOI 10.1109/TMM.2020.3025166
   Zhou WJ, 2021, IEEE INTELL SYST, V36, P73, DOI 10.1109/MIS.2020.2999462
   Zhou WJ, 2020, IEEE T COMPUT IMAG, V6, P883, DOI 10.1109/TCI.2020.2993640
   Zhou WJ, 2021, IEEE T SYST MAN CY-S, V51, P3641, DOI 10.1109/TSMC.2019.2957386
   Zhou XF, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103888
   Zhu DD, 2017, IEEE IMAGE PROC, P2711, DOI 10.1109/ICIP.2017.8296775
   Zou BJ, 2015, J VIS COMMUN IMAGE R, V33, P378, DOI 10.1016/j.jvcir.2015.09.017
NR 48
TC 1
Z9 1
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102997
DI 10.1016/j.jvcir.2020.102997
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900007
DA 2024-07-18
ER

PT J
AU Zhao, HT
   Wu, D
   Su, H
   Zheng, SB
   Chen, J
AF Zhao, Hongtian
   Wu, Di
   Su, Hang
   Zheng, Shibao
   Chen, Jie
TI Gradient-based conditional generative adversarial network for
   non-uniform blind deblurring via DenseResNet
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deblurring; Conditional GAN; DenseResNet; L-1-based gradient loss
AB Blind image deblurring aims to recover the sharp image from a blurry image. The problem is seriously ill-conditioned and many existing algorithms based on kernel estimation require heuristic parameter adjustments and high computational cost, and cannot perform well on non-uniform motion blurs. To address this issue, image deblurring is viewed as an image translation problem in this paper. The authors solve it based on a conditional generative adversarial network (GAN), where the sharp image is restored by an end-to-end trainable neural network. Different from the generative network in basic conditional GAN, the proposed generator is based on dense blocks and residual network (DenseResNet), aiming to mitigate the problems of overfitting and vanishing gradient, and strengthen the blur feature propagation. To generate clear structure, the basic conditional GAN formulation is further revised by introducing joint VGG features and L-1-based gradient loss. Extensive experimental results demonstrate the superior performance of the proposed method.
C1 [Zhao, Hongtian; Wu, Di; Zheng, Shibao] Shanghai Jiao Tong Univ, Dept Elect Engn SEIEE, Shanghai 200240, Peoples R China.
   [Zhao, Hongtian; Wu, Di; Zheng, Shibao] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
   [Su, Hang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100000, Peoples R China.
   [Chen, Jie] Ping Int Smart City Technol Inc, Shenzhen 518000, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Tsinghua
   University
RP Zheng, SB (corresponding author), SEIEE Bldg,800 Dong Chuan Rd, Shanghai 200240, Peoples R China.
EM zhaohongtian@sjtu.edu.cn; sbzh@sjtu.edu.cn
FU NSFC [61671289, 61771303, 61521062]; STCSM, China [18DZ2270700];
   foundation of Key Laboratory of Artificial Intelligence, Ministry of
   Education, P.R. China
FX The authors would like to thank the editor and reviewers for the time
   and effort spent handling this paper. This work has been supported
   partially by the NSFC: 61671289, 61771303, 61521062, and the STCSM,
   China: 18DZ2270700. The work is also supported by the foundation of Key
   Laboratory of Artificial Intelligence, Ministry of Education, P.R.
   China. Hongtian Zhao would like to thank Dr. Orest Kupyn at Lviv,
   Ukraine for providing his PyTorch program.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   August D, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2013)001
   Chen ZM, 2019, INT CONF ACOUST SPEE, P1463, DOI [10.1109/icassp.2019.8683728, 10.1109/ICASSP.2019.8683728]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li LRH, 2019, INT J COMPUT VISION, V127, P1025, DOI 10.1007/s11263-018-01146-0
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu AA, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P821
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan JS, 2019, IEEE T PATTERN ANAL, V41, P1412, DOI 10.1109/TPAMI.2018.2832125
   Pan JS, 2013, SIGNAL PROCESS-IMAGE, V28, P1156, DOI 10.1016/j.image.2013.05.001
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Ulyanov D., 2017, Instance Normalization: The Missing Ingredient for Fast Stylization
   [吴迪 Wu Di], 2020, [中国图象图形学报, Journal of Image and Graphics], V25, P890
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Xu Xiangyu, 2017, IEEE Transactions on Image Processing, V27, P194
   Yan Y, 2017, PROCEEDINGS OF THE 9TH (2017) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, P34
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zheng S, 2019, IEEE SIGNAL PROC LET, V26, P1546, DOI 10.1109/LSP.2019.2939752
   Zuo WM, 2016, IEEE T IMAGE PROCESS, V25, P1751, DOI 10.1109/TIP.2016.2531905
NR 34
TC 11
Z9 11
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102921
DI 10.1016/j.jvcir.2020.102921
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I2ON
UT WOS:000779264200001
DA 2024-07-18
ER

PT J
AU Liu, L
   Sun, M
   Ren, X
   Li, XX
   Zhang, QR
   Ma, L
   Li, YN
   Song, M
AF Liu, Lei
   Sun, Min
   Ren, Xiang
   Li, Xiuxian
   Zhang, Qiaoru
   Ma, Li
   Li, Yongning
   Song, Mo
TI Hyperspectral image quality based on convolutional network of
   multi-scale depth
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral image; Multi-scale deep convolutional network; Quality
   research; Super-resolution processing
AB Hyperspectral imagery has been widely used in military and civilian research fields such as crop yield estimation, mineral exploration, and military target detection. However, for the limited imaging equipment and the complex imaging environment of hyperspectral images, the spatial resolution of hyperspectral images is still relatively low, which limits the application of hyperspectral images. So, studying the data characteristics of hyperspectral images deeply and improving the spatial resolution of hyperspectral images is an important prerequisite for accurate interpretation and wide application of hyperspectral images. The purpose of this paper is to deal with super-resolution of the hyperspectral image quickly and accurately, and maintain the spectral characteristics of the hyperspectral image, makes the spectral separability of the substrate in the original image remains unchanged after super-resolution processing. This paper first learns the mapping relationship between the spectral difference of low-resolution hyper spectral image and the spectral difference of the corresponding high-resolution hyperspectral image based on multiple scale convolutional neural network, Thus, apply this mapping relationship to the input low-resolution hyperspectral image generally, getting the corresponding high resolution spectral difference. Constrained space by using the image of reconstructed spectral difference, this requires the low resolution hyperspectral image generated by the reconstructed image is to be close to the input low resolution hyperspectral image in space, so that the whole process becomes a closed circulation system where the low-resolution hyperspectral image generation of high-resolution hyperspectral images, then back to low-resolution hyperspectral images. This innovative design further enhances the super resolution performance of the algorithm. The experimental results show that the hyperspectral image super-resolution method based on convolutional neural network improves the input image spatial information, and the super-resolution performance of the model is above 90%, which can maintain the spectral information well. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Lei] Space Engn Univ, Sch Space Informat, Beijing 101416, Peoples R China.
   [Sun, Min; Ren, Xiang; Li, Xiuxian] Peking Univ, Inst Remote Sensing & GIS, Beijing 100871, Peoples R China.
   [Zhang, Qiaoru; Ma, Li; Li, Yongning; Song, Mo] 61206 Troop, Beijing 100042, Peoples R China.
C3 Aerospace Engineering University; Peking University
RP Sun, M (corresponding author), Peking Univ, Inst Remote Sensing & GIS, Beijing 100871, Peoples R China.
EM liudaypku@outlook.com
CR Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Cao BA, 2015, OPTIK, V126, P4723, DOI 10.1016/j.ijleo.2015.08.079
   Chakravortty S, 2014, INT ARCH PHOTOGRAMM, V40-8, P1099, DOI 10.5194/isprsarchives-XL-8-1099-2014
   Chen C, 2014, REMOTE SENS-BASEL, V6, P5795, DOI 10.3390/rs6065795
   Dong W., 2016, IEEE T IMAGE PROCESS, V25, P1
   Gao L., 2016, OPT PHOTONICS NEWS, V21, P50
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Liu L.X., 2019, INVEST CLIN, V60, P775
   Moustafa M, 2016, INT J REMOTE SENS, V37, P4201, DOI 10.1080/01431161.2016.1209314
   Shao L., 2019, ACTA MICROSC, V28, P938
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
NR 15
TC 2
Z9 2
U1 16
U2 101
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102721
DI 10.1016/j.jvcir.2019.102721
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900015
DA 2024-07-18
ER

PT J
AU Wang, K
   Zhang, TT
   Xue, TQ
   Lu, Y
   Na, SG
AF Wang, Kai
   Zhang, Tiantian
   Xue, Tianqiao
   Lu, Yu
   Na, Sang-Gyun
TI E-commerce personalized recommendation analysis by deeply-learned
   clustering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Clustering algorithm; Deep learning; Recommendation system
ID SYSTEMS
AB With the development of Internet, personalized recommendation has played an important role in human modern lives. Since the number of users' data is always large-scale, traditional algorithms cannot effectively cope with e-commerce personalized recommendation tasks. This paper proposes an e-commerce product personalized recommendation system based on learning clustering representation. Traditional kNN method has limitation in selecting adjacent object set. Thus, we introduce neighbor factor and time function and leverage dynamic selection model to select the adjacent object set. We combine RNN as well as attention mechanism to design the e-commerce product recommendation system. Comprehensive experimental results have shown the effectiveness of our proposed method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Wang, Kai; Zhang, Tiantian; Xue, Tianqiao; Lu, Yu; Na, Sang-Gyun] Wonkwang Univ, Dept Businesss Adm, 460 Iksandae Ro, Iksan, Jeonbuk, South Korea.
   [Xue, Tianqiao] Pingdingshan Univ, Coll Foreign Languages, Southern Sect Weilai RD Xincheng Dist, Pingdingshan, Henan, Peoples R China.
C3 Wonkwang University; Pingdingshan University
RP Na, SG (corresponding author), Wonkwang Univ, Dept Businesss Adm, 460 Iksandae Ro, Iksan, Jeonbuk, South Korea.
EM nsghy@wku.ac.kr
RI zhang, tiantian/AIE-2834-2022
FU Wonkwang University
FX This paper performance was supported by Wonkwang University in 2019.
CR [Anonymous], P 23 ANN INT ACM SIG
   [Anonymous], P 23 ANN INT ACM SIG
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R, 2000, ENCY LIB INFORM SYST, V69, P175
   Chen HX, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420580124
   Chen T, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2112
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Fränti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227
   Guralnik V, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/ICDM.2001.989516
   He XF, 2011, IEEE T KNOWL DATA EN, V23, P1406, DOI 10.1109/TKDE.2010.259
   He XF, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1065
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Jin X., 2005, KDD 05, P612
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Li CC, 2022, IEEE T AFFECT COMPUT, V13, P729, DOI 10.1109/TAFFC.2019.2954394
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Majid A, 2013, INT J GEOGR INF SCI, V27, P662, DOI 10.1080/13658816.2012.696649
   Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17
   McDonald D. W., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P231, DOI 10.1145/358916.358994
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P46, DOI 10.1145/290941.290956
   Zhang XW, 2017, I C COMM SOFTW NET, P1426, DOI 10.1109/ICCSN.2017.8230344
NR 29
TC 29
Z9 29
U1 14
U2 68
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102735
DI 10.1016/j.jvcir.2019.102735
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900021
DA 2024-07-18
ER

PT J
AU Fu, GP
   Hong, SH
   Li, FL
   Wang, L
AF Fu, Guan-Peng
   Hong, Shao-Hua
   Li, Fu-Lin
   Wang, Lin
TI A novel multi-focus image fusion method based on distributed compressed
   sensing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed compressed sensing; Decision map; Multi-focus image fusion;
   Joint-sparsity-model-1
ID ALGORITHM
AB Multi-focus image fusion aims to produce an all-in-focus image by merging multiple partially focused images of the same scene. The main work is identifying the focused region and then composing all the focused regions. In this paper, a novel efficient multi-focus image fusion method based on distributed compressed sensing (DCS) is proposed. Firstly, the low-frequency and high-frequency images are obtained by comparing the variance of the source images, which are further utilized to get the low-frequency and high-frequency dictionaries. Secondly, DCS using joint sparsity model-1 (JSM-1 ) is applied to reconstruct the precise high-frequency images. Thirdly, the decision map is obtained based on all the high-frequency images and then improved by the morphological processing. Finally, the focused pixels are chosen from the source images through the decision map. Experimental results indicate that the proposed DCS-based method can be competitive with or even outperform some state-of-the-art methods in terms of both visual and quantitative metric evaluations. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Fu, Guan-Peng; Hong, Shao-Hua; Li, Fu-Lin; Wang, Lin] Xiamen Univ, Dept Informat & Commun Engn, Xiamen 361005, Fujian, Peoples R China.
   [Hong, Shao-Hua] Xiamen Univ, Shenzhen Res Inst, Shenzhen 518057, Guangdong, Peoples R China.
C3 Xiamen University; Xiamen University
RP Hong, SH (corresponding author), Xiamen Univ, Dept Informat & Commun Engn, Xiamen 361005, Fujian, Peoples R China.
EM hongsh@xmu.edu.cn
RI LIN, WANG/JWA-3182-2024; wang, lili/HZJ-5080-2023; wang,
   lin/HZK-4145-2023; wang, lili/HDL-7210-2022; wang, lin/GSE-3040-2022
FU National Natural Science Foundation of China [61671395]; Guangdong
   Natural Science Foundation [2018A030313710]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61671395 and by Guangdong Natural Science
   Foundation (No. 2018A030313710).
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Anish A., 2012, International Journal of Advanced Research in Computer Engineering Technology (IJARCET), V1, P319
   [Anonymous], [No title captured]
   Aslantas V, 2017, COMPUT ELECTR ENG, V62, P302, DOI 10.1016/j.compeleceng.2017.02.003
   Baron D., 2006, Technical Report ECE-0612
   Candes E, 2005, ANN IEEE SYMP FOUND, P295
   Cheng F, 2014, COMM COM INF SC, V484, P107
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Devi M. Gayathri, 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P295, DOI 10.1109/I-SMAC.2018.8653701
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Hua KL, 2014, J VIS COMMUN IMAGE R, V25, P951, DOI 10.1016/j.jvcir.2014.02.009
   Kaur G, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1420, DOI 10.1109/ICEEOT.2016.7754918
   Kazemi V, 2014, IRAN CONF ELECTR ENG, P1668, DOI 10.1109/IranianCEE.2014.6999806
   Li FL, 2019, IEEE SIGNAL PROC LET, V26, P515, DOI 10.1109/LSP.2019.2897458
   Li FL, 2018, IEEE IMAGE PROC, P1882, DOI 10.1109/ICIP.2018.8451648
   Li H, 2015, OPT COMMUN, V342, P1, DOI 10.1016/j.optcom.2014.12.048
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo XQ, 2017, J VIS COMMUN IMAGE R, V45, P46, DOI 10.1016/j.jvcir.2017.02.006
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   Ma JL, 2017, CHIN CONTR CONF, P5464, DOI 10.23919/ChiCC.2017.8028223
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang WQ, 2015, NEUROCOMPUTING, V155, P320, DOI 10.1016/j.neucom.2014.11.054
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Zhan K., 2015, J INF HIDING MULTIME, V6, P600
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 38
TC 9
Z9 9
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102760
DI 10.1016/j.jvcir.2020.102760
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800004
DA 2024-07-18
ER

PT J
AU Hu, ZP
   Zhang, L
   Li, SF
   Sun, DG
AF Hu, Zheng-ping
   Zhang, Le
   Li, Shu-fang
   Sun, De-gang
TI Parallel spatial-temporal convolutional neural networks for anomaly
   detection and location in crowded scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Abnormal detection; Video surveillance; Parallel 3D convolution neural
   networks; Spatial-temporal interest cuboids
ID LOCALIZATION
AB Anomaly detection and location in crowded scenes have attracted a lot of attention in computer vision research community recently due to the increased applications of intelligent surveillance improve security in public. We propose a novel parallel spatial-temporal convolution neural networks model to detect and localize the abnormal behavior in video surveillance. Our approach contains two main steps. Firstly, considering the typical position of camera and the large number of background information, we introduce a novel spatial-temporal cuboid of interest detection method with varied-size cell structure and optical flow algorithm. Then, we use the parallel 3D convolution neural networks to describe the same behavior in different temporal-lengths. That step ensures that the most of behavior information in cuboids could be captured, also insures the reduction of information unrelated to the major behavior. The evaluation results on benchmark datasets show the superiority of our method compared to the state-of-the-art methods. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Hu, Zheng-ping; Zhang, Le; Li, Shu-fang] Sch Informat & Engn, Qinhuangdao, Hebei, Peoples R China.
   [Hu, Zheng-ping; Zhang, Le; Li, Shu-fang] Yanshan Univ, Qinhuangdao, Hebei, Peoples R China.
   [Hu, Zheng-ping; Zhang, Le; Li, Shu-fang] Hebei Key Lab Informat Transmiss & Signal Proc, Qinhuangdao 066004, Hebei, Peoples R China.
   [Sun, De-gang] Sch Elect Informat & Engn, Dezhou 253000, Peoples R China.
   [Sun, De-gang] Shandong Huayu Univ Technol, Dezhou 253000, Peoples R China.
C3 Yanshan University; Shandong Huayu University of Technology
RP Zhang, L (corresponding author), Sch Informat & Engn, Qinhuangdao, Hebei, Peoples R China.; Zhang, L (corresponding author), Yanshan Univ, Qinhuangdao, Hebei, Peoples R China.
EM zhangle_25@163.com
FU National Natural Science Foundation of China [61071199]; Natural Science
   Foundation of Hebei Province of China [F2016203422]; Hebei key
   laboratory of information transmission and signal processing
FX This work is supported by National Natural Science Foundation of China
   under Grant (No. 61071199), Natural Science Foundation of Hebei Province
   of China under Grant (No. F2016203422) and Hebei key laboratory of
   information transmission and signal processing. The authors declare that
   there is no conflict of interests regarding the publication of this
   paper.
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Biswas S, 2017, NEUROCOMPUTING, V242, P63, DOI 10.1016/j.neucom.2017.02.058
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Lan ZZ, 2017, IEEE COMPUT SOC CONF, P1219, DOI 10.1109/CVPRW.2017.161
   Leyva R, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P621, DOI 10.1109/TSP.2017.8076061
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li C, 2013, NEUROCOMPUTING, V119, P94, DOI 10.1016/j.neucom.2012.03.040
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu P, 2017, NEUROCOMPUTING, V269, P3, DOI 10.1016/j.neucom.2016.09.138
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mousavi H, 2015, LECT NOTES COMPUT SC, V9280, P722, DOI 10.1007/978-3-319-23234-8_66
   Nallaivarothayan H, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P343, DOI 10.1109/AVSS.2014.6918692
   Rao A, 2014, PROC ASEE ANN C EXPO, P1
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Simonyan K, 2014, ADV NEUR IN, V27
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu L, 2014, INT CONF ACOUST SPEE
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 28
TC 8
Z9 8
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102765
DI 10.1016/j.jvcir.2020.102765
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800001
DA 2024-07-18
ER

PT J
AU Rasoulidanesh, MS
   Payandeh, S
AF Rasoulidanesh, Maryam S.
   Payandeh, Shahram
TI A novel change-detection scheduler for a network of depth sensors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Change detection; Depth sensor; Network sensor; Sensor network
   scheduler; Background subtraction; RGBD tracking
ID KINECT
AB In many monitoring applications such as smart home and surveillance, deployment of multiple depth sensors increases monitoring area and offers better occlusion handling which is not sensitive to illumination condition in comparison with RGB sensors. However, multiple sensors also increase the volume of data associated with signal processing alongside the associated computational complexity and power consumption. In order to address these drawbacks, this paper proposes a novel change detection algorithm that can be used as a part of a sensor scheduler in a centralized (e.g. star) network configuration. Initially, each sensor in the network performs a unique single scan of the common environment in order to detect any incremental changes in the sensed depth signal. This initial change detection is then used as a basis for several follow-up tasks such as foreground segmentation, background detection, target detection, and tracking for monitoring tasks. Here, instead of processing a complete depth frame, we proposed to utilize a collection of 1D scans of the depth frames. A confidence function is defined that can be used to estimate the reliability of the detected changes in each sensor and to reduce any false positive events which can be triggered by the noise and outliers. Analysis of the proposed confidence function is carried out through performance analysis in the presence of sensor noise and other parameters which can affect the reliability of the sensed data of each sensor. Finally, a score function is defined based on the confidence of the detected parameters and sensor resolution in order to rank and match sensors with the associated objects to be tracked. It results in tracking target(s) by a sensor (or sensors) that offer a high tracking score. This approach offers many advantages such as decreasing the overall system power consumption by placing the sensors with a low confidence value on standby mode and reducing the overall computational overheads. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Rasoulidanesh, Maryam S.; Payandeh, Shahram] Simon Fraser Univ, Networked Robot & Sensing Lab, Burnaby, BC, Canada.
C3 Simon Fraser University
RP Rasoulidanesh, MS (corresponding author), Simon Fraser Univ, Networked Robot & Sensing Lab, Burnaby, BC, Canada.
EM rasoulid@sfu.ca; payandeh@sfu.ca
RI Payandeh, Shahram/IZQ-1865-2023
OI Payandeh, Shahram/0000-0001-6846-7289
CR Amon C., 2014, P 6 C ALPS ADRIA ACO, P16
   [Anonymous], 2016, ARXIV
   Bodor R, 2007, J INTELL ROBOT SYST, V50, P257, DOI 10.1007/s10846-007-9164-7
   Fu PC, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717698968
   Fu PC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030639
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hu T, 2018, FUTURE GENER COMP SY, V88, P540, DOI 10.1016/j.future.2018.05.083
   Javaheri Alireza, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P1, DOI 10.1109/ICMEW.2017.8026263
   Lachat E, 2015, INT ARCH PHOTOGRAMM, V40-5, P93, DOI 10.5194/isprsarchives-XL-5-W4-93-2015
   Maddalena L, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050071
   Moyà-Alcover G, 2017, PATTERN RECOGN LETT, V96, P76, DOI 10.1016/j.patrec.2016.09.004
   Palmero C, 2016, INT J COMPUT VISION, V118, P217, DOI 10.1007/s11263-016-0901-x
   Quan W, 2017, PROC SPIE, V10609, DOI 10.1117/12.2283112
   Rasouli MS, 2017, IEEE SYS MAN CYBERN, P1710, DOI 10.1109/SMC.2017.8122862
   Schuon S., 2008, P 2008 IEEE COMP SOC
   Sobral A, 2013, 9 WORKSH VIS COMP WV, V2, P7, DOI DOI 10.13140/2.1.1740.7044
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Sun SW, 2016, J VIS COMMUN IMAGE R, V35, P36, DOI 10.1016/j.jvcir.2015.11.012
   Taherzadeh M, 2014, POW ELECTR DRIV SYST, P1, DOI 10.1109/PEDSTC.2014.6799334
   Cao VT, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P43
   Wasenmüller O, 2017, LECT NOTES COMPUT SC, V10117, P34, DOI 10.1007/978-3-319-54427-4_3
   Xiong N., 2002, Information Fusion, V3, P163, DOI 10.1016/S1566-2535(02)00055-6
   Yang L, 2015, IEEE SENS J, V15, P4275, DOI 10.1109/JSEN.2015.2416651
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zennaro S, 2015, IEEE INT CON MULTI
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 41
TC 2
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102733
DI 10.1016/j.jvcir.2019.102733
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200012
DA 2024-07-18
ER

PT J
AU Wang, XS
   Chen, X
   Cao, CJ
AF Wang, Xusheng
   Chen, Xing
   Cao, Congjun
TI Hierarchically engineering quality-related perceptual features for
   understanding breast cancer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Breast cancer; Deep learning; Quality-related; Weakly-supervised;
   Ranking algorithm
ID SCENE
AB Breast cancer is generally acknowledged as the second leading cause of cancer death among women. Therefore, accurately understanding breast cancer from X-ray images is an indispensable technique in medical sciences and image analysis. In the work, we propose a novel perceptual deep architecture that hierarchically learns deep features from large-scale X-ray images, wherein human visual perception is naturally encoded. More specifically, given a rich number of breast cancer images, we first employ the well-known BING objectness measure to identify all possible visually/semantically salient patches. Due to the relatively huge number of BING object patches, a weakly-supervised ranking algorithm is designed to select high quality object patches according to human visual perception. Subsequently, an aggregation scheme is utilized to derive the deep features of high quality object patches within each brain cancer image. Based on the aggregated deep feature, a multi-class SVM is trained to classify each breast cancer into multiple levels. Extensive comparative studies and visualization results have demonstrated the effectiveness and efficiency of our proposed deep architecture. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Xusheng; Chen, Xing; Cao, Congjun] Xian Univ Technol, Xian, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Wang, XS (corresponding author), Xian Univ Technol, Xian, Shaanxi, Peoples R China.
EM xusheng.w@outlook.com
RI Wang, Xusheng/AAD-2424-2019
CR [Anonymous], 2006, IEEE COMP SOC C COMP
   [Anonymous], 2014, P IEEE C COMPUTER VI
   [Anonymous], 2010, P NIPS
   [Anonymous], 2010, P CVPR
   [Anonymous], 2009, P CVPR
   [Anonymous], 2009, P CVPR
   [Anonymous], 2015, P ICCV
   Arbelaez P., 2014, P CVPR
   Caglayan Ali, 2018, ECCV WORKSH
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cong Y, 2013, IEEE T IMAGE PROCESS, V22, P3179, DOI 10.1109/TIP.2013.2260168
   Krizhevsky A., 2012, Advances in Neural Information Processing Systems, V25, P1106
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Liu S, 2012, IEEE T MULTIMEDIA, V14, P361, DOI 10.1109/TMM.2011.2174780
   Mesnil Gregoire, 2015, P PRAM
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Sameen MI, 2018, J SENSORS, V2018, DOI 10.1155/2018/7195432
   Schulman J, 2017, ARXIV PREPRINT ARXIV
   Tran SN, 2018, IEEE T NEUR NET LEAR, V29, P246, DOI 10.1109/TNNLS.2016.2603784
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang Chang, 2011, P IJCAI
   Wang C, 2019, IEEE GEOSCI REMOTE S, V16, P310, DOI 10.1109/LGRS.2018.2872355
   Wang Y., 2018, P CVPR
   Xiao Y, 2014, IEEE T IMAGE PROCESS, V23, P823, DOI 10.1109/TIP.2013.2295756
   Yang Qiang, 2009, P ACL IJCNLP
   Yao Hu, 2013, P IJCAI
   Zhang Luming, 2014, IEEE T IP, V5071-5084, P3
NR 27
TC 0
Z9 0
U1 2
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102644
DI 10.1016/j.jvcir.2019.102644
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600027
DA 2024-07-18
ER

PT J
AU Wang, XF
   Lee, F
   Chen, Q
AF Wang, Xiaofei
   Lee, Feifei
   Chen, Qiu
TI Similarity-preserving hashing based on deep neural networks for
   large-scale image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Large-scale image retrieval; Similarity comparison; Deep learning;
   Multi-label learning; Quantization error
ID QUANTIZATION; SHAPE
AB Similarity-preserving hashing has become the mainstream of approximate nearest neighbor (ANN) search for large-scale image retrieval. Recent research shows that deep neural networks can produce efficient feature representation. Most existing deep hashing schemes simply utilize the middle-layer features of the deep neural networks to measure the similarity between query images and database images. However, these visual features are suboptimal for discriminating the semantic information of images, especially for complex images that contain multiple objects. In this paper, a deep framework is employed to learn multi-level non-linear transformations to obtain advanced image features, and then we combine these intermediate features and top layer visual information to implement image retrieval. Three criterions are enforced on these compact codes: (1) minimal quantization loss; (2) evenly distributed binary; (3) independent bits. The experimental results on five public large-scale datasets demonstrate the superiority of our method compared with several other state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Xiaofei; Lee, Feifei; Chen, Qiu] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
   [Chen, Qiu] Kogakuin Univ, Grad Sch Engn, Elect Engn & Elect, Tokyo, Japan.
C3 University of Shanghai for Science & Technology; Kogakuin University
RP Lee, F; Chen, Q (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.; Chen, Q (corresponding author), Kogakuin Univ, Grad Sch Engn, Elect Engn & Elect, Tokyo, Japan.
EM feifeilee@ieee.org; q.chen@ieee.org
RI CHEN, QIU/G-7959-2012
FU Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning
FX This work is partially supported by The Program for Professor of Special
   Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning.
CR [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], PROC CVPR IEEE
   [Anonymous], MIR 08
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, IJCAI
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   [Anonymous], 2009, NIPS
   [Anonymous], SIGNAL PROCESS
   [Anonymous], 2009, NEURIPS
   Cao WM, 2018, IEEE ACCESS, V6, P8990, DOI 10.1109/ACCESS.2018.2795798
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Deng C, 2015, NEUROCOMPUTING, V151, P319, DOI 10.1016/j.neucom.2014.09.033
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li WJ, 2016, IJCAI, P1711
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2017, IEEE T IMAGE PROCESS, V26, P5324, DOI 10.1109/TIP.2017.2729896
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P4514, DOI 10.1109/TIP.2016.2593344
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma YK, 2017, IEEE ACCESS, V5, P16532, DOI 10.1109/ACCESS.2017.2737544
   Masoumi M, 2017, J VIS COMMUN IMAGE R, V43, P198, DOI 10.1016/j.jvcir.2017.01.001
   Norouzi M., 2012, ADV NEURAL INFORM PR
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Simonyan K, 2015, IEEE INT C ICLR
   Song DJ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2229, DOI 10.1145/3219819.3220108
   Song DJ, 2015, IEEE I CONF COMP VIS, P1922, DOI 10.1109/ICCV.2015.223
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Weiss Y., 2008, PROC ADV NEURAL INFO, V21, P1753
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   YANG E, 2017, 31 AAAI C ART INT
   Yang E, 2018, IEEE T NEUR NET LEAR, V29, P5292, DOI 10.1109/TNNLS.2018.2793863
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhu DD, 2018, J VIS COMMUN IMAGE R, V54, P1, DOI 10.1016/j.jvcir.2018.03.017
NR 60
TC 19
Z9 19
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 260
EP 271
DI 10.1016/j.jvcir.2019.03.024
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100027
DA 2024-07-18
ER

PT J
AU Fang, JH
   Qian, WJ
   Zhao, ZJ
   Yao, YY
   Wen, Z
AF Fang, Jinghui
   Qian, Weijie
   Zhao, Zhijun
   Yao, Yiyang
   Wen, Zhen
TI Adaptively feature learning for effective power defense
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intelligent video surveillance; Active defense technology; Key frames
ID SYSTEM
AB Active defense technology is very important in intelligent systems and video surveillance. In some important fields, active defense system can effectively find intruders. Many intelligent video surveillance systems were proposed in recent years. They achieved good performance to some extent. Since power station is an important field, it is important to develop an intelligent video surveillance. Considering that detecting the whole surveillance video is time consumption and computation. So in this paper, we propose an active defense system to find intruders automatically. First, a key frame selection algorithm based on adaptive features is presented to select key frames. These key frames can cover the main content of videos and detecting these key frames can also reduce time consumption and computation. Then, a probabilistic model is proposed to learn the training data distribution. Finally, our system can achieve active defense based on probabilistic model. Experimental results show that our active defense system can achieve finding intruders effectively. (C) 2019 Published by Elsevier Inc.
C1 [Fang, Jinghui; Qian, Weijie; Zhao, Zhijun; Yao, Yiyang; Wen, Zhen] State Grid Zhejiang Jiaxing Elect Power Supply Co, Jiaxing, Peoples R China.
RP Fang, JH (corresponding author), State Grid Zhejiang Jiaxing Elect Power Supply Co, Jiaxing, Peoples R China.
EM Jinghuifang66@163.com
RI Zhao, Zhi-jun/AAE-9577-2020
CR [Anonymous], 2016, ARXIV161001708
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Duque D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P362, DOI 10.1109/CIDM.2007.368897
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P40, DOI 10.1109/TMM.2014.2370257
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
NR 22
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 33
EP 37
DI 10.1016/j.jvcir.2019.01.003
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000004
DA 2024-07-18
ER

PT J
AU Xiao, ZL
   Zhang, M
   Chen, LS
   Jin, HY
AF Xiao, Zhaolin
   Zhang, Meng
   Chen, Lisheng
   Jin, Haiyan
TI Detection and segmentation of underwater CW-like signals in spectrum
   image under strong noise background
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CW-like signal; Signal spectrum analysis; Gaussian mixture model;
   Clustering analysis; Signal detection
AB Aiming at the detection and segmentation of underwater Continuous wave-like (CW-like) signals of under strong noise sea background, this paper introduces a Gaussian mixture model clustering method by analyzing the signal spectrum features. First, the time domain original signal is converted to its frequency domain correspondence by Windowed Fast Fourier Transform. Second, by studying on the feature of target signal, we introduce a spectrum filtering to alleviate the background noise of ocean environment, which is analyzed and calculated with both time and frequency information. Then, the target echo location signals is constructed using a Gaussian mixture mode based binary clustering algorithm. Finally, we use the EM algorithm and adaptive binarization for solving and optimizing the clustering results. Experimental results have shown the accuracy and efficiency of our detection, which can be also simply modified and applied for detecting similar and specific signal from complex background noise. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xiao, Zhaolin; Zhang, Meng; Jin, Haiyan] Xian Univ Technol, Sch Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
   [Chen, Lisheng] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW, Australia.
C3 Xi'an University of Technology; University of Technology Sydney
RP Jin, HY (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
EM jinhaiyan@xaut.edu.cn
OI Jin, HaiYai/0000-0003-3742-4029
FU NSFC funds [61871319, 61501370]
FX This work was partially supported by NSFC funds (No.61871319,
   No.61501370)
CR Ali ST, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P153, DOI 10.1109/RISE.2017.8378144
   [Anonymous], UNDERWATER OBJECT TR
   [Anonymous], 2016 IEEE OES CHINA
   [Anonymous], INT COMP C WAV ACT M
   [Anonymous], ACM MM
   [Anonymous], 2016, MACH LEARN
   [Anonymous], SCI TECHNOL ENG
   [Anonymous], MACHINE LEARNING ACT
   [Anonymous], ACTA ACUSTICA
   [Anonymous], INT C COMP SCI APPL
   [Anonymous], 2015, 2015 3 INT C CONTR E
   [Anonymous], J NANJING U NAT SCI
   [Anonymous], J DETECTION CONTROL
   BOASHASH B, 1990, IEEE T ACOUST SPEECH, V38, P1829, DOI 10.1109/29.103085
   Diamant R, 2018, IEEE ACCESS, V6, P4405, DOI 10.1109/ACCESS.2017.2787684
   Erdinç A, 2015, INT GEOSCI REMOTE SE, P5035, DOI 10.1109/IGARSS.2015.7326964
   Guo QL, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P355, DOI 10.1109/ICSPCC.2014.6986214
   Guojun Li, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1929, DOI 10.1109/FSKD.2012.6233844
   Li Guo-jun, 2010, Journal of University of Electronic Science and Technology of China, V39, P227, DOI 10.3969/j.issn.1001-0548.2010.02.016
   Li YA, 2017, INT BHURBAN C APPL S, P656, DOI 10.1109/IBCAST.2017.7868120
   Liu J., 2009, INT C IMAGE SIGNAL P, P1
   Wang Q., 2016, Oxid Med Cell Longev, V2016, P1, DOI 10.1155/2016/8956981
   Xiang Qiang, 2011, Acta Electronica Sinica, V39, P1508
   Zhou Xiao-Na, 2010, Proceedings of the 2010 2nd International Conference on Future Computer and Communication (ICFCC 2010), P335, DOI 10.1109/ICFCC.2010.5497606
NR 24
TC 3
Z9 3
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 287
EP 294
DI 10.1016/j.jvcir.2019.02.036
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000031
DA 2024-07-18
ER

PT J
AU Fang, LY
   Jin, YX
   Huang, LF
   Guo, SY
   Zhao, GZ
   Chen, XD
AF Fang, Leyuan
   Jin, Yuxuan
   Huang, Laifeng
   Guo, Siyu
   Zhao, Guangzhe
   Chen, Xiangdong
TI Iterative fusion convolutional neural networks for classification of
   optical coherence tomography images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Classification; Convolutional neural network (CNN); Deep learning;
   Optical coherence tomography (OCT); Retinal
ID MACULAR DEGENERATION; RETINAL LAYER; OCT IMAGES; SEGMENTATION; DISEASES;
   EDEMA; SHAPE; AMD
AB Optical coherence tomography (OCT) can achieve the high-resolution 3D tomography imaging of the retina, which is crucial for the diagnosis of retinal diseases. Currently, the classification of retinal OCT images is mainly conducted by ophthalmologists, which is time consuming and subjective. In this paper, we propose an iterative fusion convolutional neural network (IFCNN) method for the automatic classification of retinal OCT image. In the convolutional neural network (CNN), different convolutional layers contain feature information from different scales. Therefore, the proposed network adopts an iterative fusion strategy, which iteratively combines features in current convolutional layer with those of all previous layers in the CNN network, and thus can jointly utilize the features of different convolutional layers to achieve accurate classification of OCT images. Experimental results on a real retinal OCT dataset and a musculoskeletal radiographs dataset demonstrate the superiority of the proposed method over the traditional CNN and several well-known OCT classification methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Fang, Leyuan; Jin, Yuxuan; Huang, Laifeng; Guo, Siyu] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
   [Zhao, Guangzhe] Beijing Univ Civil Engn & Architecture, Coll Elect & Informat Engn, Beijing, Peoples R China.
   [Chen, Xiangdong] Hunan Univ Chinese Med, Dept Ophthalmol, Hosp 1, Changsha, Hunan, Peoples R China.
C3 Hunan University; Beijing University of Civil Engineering &
   Architecture; Hunan University of Chinese Medicine
RP Zhao, GZ (corresponding author), Beijing Univ Civil Engn & Architecture, Coll Elect & Informat Engn, Beijing, Peoples R China.; Chen, XD (corresponding author), Hunan Univ Chinese Med, Dept Ophthalmol, Hosp 1, Changsha, Hunan, Peoples R China.
EM zhaoguangzhe@bucea.edu.cn
RI Chen, Xiangdong/KCX-7707-2024; Fang, Leyuan/G-1468-2011
OI zhao, guangzhe/0000-0002-6850-9335; Fang, Leyuan/0000-0003-2351-4461
FU National Natural Science Foundation [61771192, 61471167, 61462089];
   National Natural Science Foundation for Young Scientist of China
   [61501180]; China Postdoctoral Science Foundation [2017T100597];
   National Natural Science Foundation of Hunan Province [2018JJ3077]
FX This work was supported in part by the National Natural Science
   Foundation under Grant No. 61771192, 61471167, and 61462089, the
   National Natural Science Foundation for Young Scientist of China under
   Grant No. 61501180, China Postdoctoral Science Foundation funded Project
   No. 2017T100597, and National Natural Science Foundation of Hunan
   Province Grant No. 2018JJ3077.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Albarrak A., 2013, PROC INT C MED IMAGE, P59
   [Anonymous], PPAR RES
   [Anonymous], 2017, MURA LARGE DATASET A
   [Anonymous], P SPIE MED IMAG
   [Anonymous], OPHTHALMOLOGY
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T PATTERN ANAL
   Drexler W, 2008, PROG RETIN EYE RES, V27, P45, DOI 10.1016/j.preteyeres.2007.07.005
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P1803, DOI 10.1109/TGRS.2017.2768479
   Fang LY, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.11.116011
   Fang LY, 2017, BIOMED OPT EXPRESS, V8, P2732, DOI 10.1364/BOE.8.002732
   Fang LY, 2017, IEEE T MED IMAGING, V36, P407, DOI 10.1109/TMI.2016.2611503
   Fang LY, 2012, BIOMED OPT EXPRESS, V3, P927, DOI 10.1364/BOE.3.000927
   Farsiu S, 2014, OPHTHALMOLOGY, V121, P162, DOI 10.1016/j.ophtha.2013.07.013
   FREUND KB, 1993, AM J OPHTHALMOL, V115, P786, DOI 10.1016/S0002-9394(14)73649-9
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hirai FE, 2008, AM J OPHTHALMOL, V145, P700, DOI 10.1016/j.ajo.2007.11.019
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Jia S, 2018, INT GEOSCI REMOTE SE, P1, DOI 10.1109/IGARSS.2018.8518351
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   King DB, 2015, ACS SYM SER, V1214, P1
   Kuo AN, 2013, AM J OPHTHALMOL, V156, P304, DOI 10.1016/j.ajo.2013.03.012
   Lee CS, 2017, OPHTHALMOL RETINA, V1, P322, DOI 10.1016/j.oret.2016.12.009
   Lemaître G, 2016, J OPHTHALMOL, V2016, DOI 10.1155/2016/3298606
   Liu YY, 2011, MED IMAGE ANAL, V15, P748, DOI 10.1016/j.media.2011.06.005
   PULIAFITO CA, 1995, OPHTHALMOLOGY, V102, P217
   Rasti R, 2018, IEEE T MED IMAGING, V37, P1024, DOI 10.1109/TMI.2017.2780115
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2017, BIOMED OPT EXPRESS, V8, P3627, DOI 10.1364/BOE.8.003627
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Srinivasan PP, 2014, BIOMED OPT EXPRESS, V5, P3568, DOI 10.1364/BOE.5.003568
   Sun YK, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.1.016012
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thomas M, 2013, CLIN OPHTHALMOL, V7, P495, DOI 10.2147/OPTH.S29974
   Tomlins PH, 2005, J PHYS D APPL PHYS, V38, P2519, DOI 10.1088/0022-3727/38/15/002
   Wang Y, 2016, BIOMED OPT EXPRESS, V7, P4928, DOI 10.1364/BOE.7.004928
   Xu YP, 2017, BIOMED OPT EXPRESS, V8, P4061, DOI 10.1364/BOE.8.004061
   Yuan A, 2011, SEMIN OPHTHALMOL, V26, P149, DOI 10.3109/08820538.2011.570846
NR 42
TC 60
Z9 62
U1 4
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 327
EP 333
DI 10.1016/j.jvcir.2019.01.022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600034
DA 2024-07-18
ER

PT J
AU Yous, H
   Serir, A
   Yous, S
AF Yous, Hamza
   Serir, Amina
   Yous, Sofiane
TI CNN-based method for blotches and scratches detection in archived videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital archived video restoration; Defects detection; Convolutional
   neural network; Deep learning
AB In this work, we present a fully connected convolutional encoder-decoder for defects detection in archived video. The proposed method handles the detection of two of the most common archived video-related defects, namely blotches and scratches. It consists of two stages: (1) pixel-level classification and description of each video frame into defects pixels or not, by means of a novel CNN-based encoder-decoder architecture, and (2) spatio-temporal analysis to group and fine-tune the detections. For blotch detection, the learned features, extracted from an intermediate stage of the network, are used to evaluate the dissimilarity between the pre-selected regions in consecutive frames. For scratches detection, the morphology of scratches is used to eliminate false alarms. The experiments are performed on various video sequences suffering synthetic and real scratches and blotches. The results demonstrate the effectiveness of our approach and significant improvement against the most recent detectors. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yous, Hamza; Serir, Amina] USTHB, Elect & Comp Sci Fac, BP 32 El Alia Bab Ezzouar, Algiers 16111, Algeria.
   [Yous, Sofiane] Intel Ireland, New Technol Grp, Collinstown Ind Pk, Leixlip W23 CX38, Kildare, Ireland.
C3 University Science & Technology Houari Boumediene; Intel Corporation
RP Yous, H (corresponding author), USTHB, Elect & Comp Sci Fac, BP 32 El Alia Bab Ezzouar, Algiers 16111, Algeria.
EM hyous@usthb.dz
RI SERIR, Amina/AIE-7078-2022; Yous, Hamza/R-2014-2019
OI SERIR, Amina/0000-0001-7716-1273; 
CR Ammar-Badri H, 2009, 2009 3RD INTERNATIONAL CONFERENCE ON SIGNALS, CIRCUITS AND SYSTEMS (SCS 2009), P401
   Ammar-Badri H., 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P708, DOI 10.1109/ISSPA.2010.5605574
   [Anonymous], THESIS
   [Anonymous], CoRR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], CORR
   [Anonymous], 2017, COMPUTER VISION PATT
   [Anonymous], CORR
   [Anonymous], THESIS
   [Anonymous], CoRR
   [Anonymous], 2007 IEEE INT C IM P
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], FUSION
   [Anonymous], 2011, J COMPUTATIONAL INFO
   [Anonymous], SIGNAL PROCESS
   [Anonymous], 3 INT C SIGN IM VIS
   [Anonymous], P 5 INT WORKSH TIM V
   [Anonymous], 2012, P 9 EUR C VIS MED PR
   [Anonymous], 2007, DRAFTDANIEL6LOWPANHI
   [Anonymous], 2015, PROC IEEE C COMPUT V
   Badrinarayanan Vijay, CORR
   Bruni V, 2003, ISPA 2003: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, PTS 1 AND 2, P5
   Joyeux L, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P8, DOI 10.1109/WACV.2000.895396
   Joyeux L., 1999, Proceedings of the 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V1, P1548
   Kemal Gullu M., 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C), DOI 10.1109/ISCAS.2006.1693652
   Kokaram AC, 2004, IEEE T IMAGE PROCESS, V13, P395, DOI 10.1109/TIP.2004.823815
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1496, DOI 10.1109/83.469931
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kyung-tai Kim, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P468, DOI 10.1109/ICPR.2010.122
   Li HQ, 2013, IEEE T CIRC SYST VID, V23, P1887, DOI 10.1109/TCSVT.2013.2269016
   Müller S, 2009, IEEE IMAGE PROC, P89, DOI 10.1109/ICIP.2009.5414090
   Newson A, 2014, IEEE T IMAGE PROCESS, V23, P1240, DOI 10.1109/TIP.2014.2300824
   Wang XS, 2012, IEEE T IMAGE PROCESS, V21, P3757, DOI 10.1109/TIP.2012.2194505
   Xu ZY, 2015, J SIGNAL PROCESS SYS, V81, P213, DOI 10.1007/s11265-014-0942-8
   Yous H, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), P379, DOI 10.1109/ISIVC.2016.7894019
   Yous H, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023019
NR 36
TC 9
Z9 10
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 486
EP 500
DI 10.1016/j.jvcir.2019.02.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600052
DA 2024-07-18
ER

PT J
AU Guan, J
   Li, YF
   Sun, JG
   Wang, X
   Zhao, HN
   Zhang, JJ
   Liu, ZC
   Qi, SH
AF Guan, Jian
   Li, Yifan
   Sun, Jianguo
   Wang, Xuan
   Zhao, Hainan
   Zhang, Jiajia
   Liu, Zechao
   Qi, Shuhan
TI Graph-based supervised discrete image hashing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discrete optimization; Graph regularization; Image retrieval; Supervised
   discrete hashing
ID CLASSIFICATION; ALGORITHMS
AB Learning based hashing have been widely adopted to the approximate nearest neighbour search in large-scale image retrieval. However, how to preserve the semantic information in hashing embedding is still a challenge problem. Moreover, most of the existing methods employ the relaxation strategy to solve discrete constraint problem, which may accumulate binary quantization error as the coding length increases. In this paper, we propose a graph-based supervised hashing framework to address these problems, where the semantic information is preserved from two aspects. On one hand, we employ a supervised learning model to keep the semantic consistency. On the other hand, the intrinsic manifold structure is captured by a graph-based model. In addition, to reduce the quantization error, we adopt a discrete optimization strategy to replace the relaxation one. Experiments conducted on three benchmark datasets to demonstrate the effectiveness of the proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Guan, Jian; Sun, Jianguo] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Li, Yifan; Wang, Xuan; Liu, Zechao; Qi, Shuhan] Harbin Inst Technol Shenzhen, Comp Applicat Res Ctr, Shenzhen 518055, Peoples R China.
   [Zhao, Hainan] Shenzhen Jingchi Technol Co Ltd, Shenzhen 518055, Peoples R China.
   [Zhang, Jiajia] Shenzhen Cyberspace Lab, Shenzhen 518055, Peoples R China.
C3 Harbin Engineering University; Harbin Institute of Technology
RP Qi, SH (corresponding author), Harbin Inst Technol Shenzhen, Comp Applicat Res Ctr, Shenzhen 518055, Peoples R China.
EM j.guan@hrbeu.edu.cn; liyifan@cs.hitsz.edu.cn; sunjianguo@hrbeu.edu.cn;
   xuanwang@cs.hitsz.edu.cn; zhangjj@pcl.ac.cn; liuzechao@cs.hitsz.edu.cn;
   shuhanqi@cs.hitsz.edu.cn
RI Li, Yifan/AAO-3483-2020
OI Li, Yifan/0000-0003-2804-4243; shuhan, qi/0000-0002-6903-145X
FU National Key Research and Development Program of China [2017YFB0803002];
   Science and Technology Planning Project of Guangdong Province
   [2016A040403046]; National Natural Science Foundation of China
   [61772237]; Fundamental Research Funds by the Central Universities
   [HEUCFG201827, HEUCFP201839]
FX This work is supported by the National Key Research and Development
   Program of China (No. 2017YFB0803002), by Science and Technology
   Planning Project of Guangdong Province (2016A040403046), by the National
   Natural Science Foundation of China (No. 61772237), by the Fundamental
   Research Funds by the Central Universities (HEUCFG201827, HEUCFP201839).
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], ARXIV180500313
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2009, NEURIPS
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], 2016, P AAAI C ART INT
   [Anonymous], ARXIV170200758
   [Anonymous], 2009, NIPS
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], P IEEE C INT C PATT
   [Anonymous], 2009, NEURIPS
   [Anonymous], ARXIV150605163
   [Anonymous], Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:160902907
   [Anonymous], ARXIV160308861
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166
   Defferrard M., 2016, P 30 INT C NEURAL IN, V29, P3844
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Feng YF, 2015, NEUROCOMPUTING, V169, P68, DOI 10.1016/j.neucom.2014.11.091
   Foster DP, 2008, TR20084 TTI
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gordo A, 2014, IEEE T PATTERN ANAL, V36, P33, DOI 10.1109/TPAMI.2013.101
   He JF, 2011, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.2011.5995518
   Hu WM, 2017, IEEE T PATTERN ANAL, V39, P172, DOI 10.1109/TPAMI.2016.2539944
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jin TS, 2015, PATTERN RECOGN, V48, P1011, DOI 10.1016/j.patcog.2014.09.002
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Ju W, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2488902
   Karri SPK, 2017, BIOMED OPT EXPRESS, V8, P579, DOI 10.1364/BOE.8.000579
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lu GF, 2016, IEEE T IMAGE PROCESS, V25, P2196, DOI 10.1109/TIP.2016.2542919
   Lu YJ, 2010, IEEE T MULTIMEDIA, V12, P288, DOI 10.1109/TMM.2010.2046292
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Norouzi M.E., 2011, ICML
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Qi SH, 2018, NEUROCOMPUTING, V274, P29, DOI 10.1016/j.neucom.2016.06.097
   Salakhutdinov Ruslan., 2007, RBM, V500, P500
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Sun FM, 2016, NEUROCOMPUTING, V173, P233, DOI 10.1016/j.neucom.2015.01.103
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang JY, 2012, INT C PATT RECOG, P963
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Yang H.-T., 2017, 2017 14 ANN IEEE INT, P1
   Zhang JP, 2019, IEEE ACM T COMPUT BI, V16, P396, DOI 10.1109/TCBB.2017.2701379
   Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600
NR 57
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 675
EP 687
DI 10.1016/j.jvcir.2018.12.025
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100064
DA 2024-07-18
ER

PT J
AU Prates, R
   Schwartz, WR
AF Prates, Raphael
   Schwartz, William Robson
TI Kernel cross-view collaborative representation based classification for
   person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Kernel collaborative representation based
   classification
ID SPARSE REPRESENTATION
AB Person re-identification aims at the maintenance of a global identity as a person moves among non-overlapping surveillance cameras. It is a hard task due to different illumination conditions, viewpoints and the small number of annotated individuals from each pair of cameras (small-sample-size problem). Common subspace learning methods have been proposed to handle the camera transition problems. However, after learning the low-dimensional representation, these methods usually compute distances using a simple cosine or Mahalanobis distance. Therefore, an still open question is how to better match probe and gallery images in the learned common subspace considering reduced number of training samples and the nonlinear behavior of the data. Collaborative Representation based Classification (CRC) has been employed successfully to address the small-sample-size problem in computer vision. However, the original CRC formulation is not well-suited for person re-identification since it does not consider that probe and gallery samples are from different cameras. Furthermore, it is a linear model, while appearance changes caused by different camera conditions indicate a strong nonlinear transition between cameras. To overcome such limitations, we propose the Kernel Cross-View Collaborative Representation based Classification (Kernel X-CRC), method that represents probe and gallery images by balancing representativeness and similarity nonlinearly. According to experimental results, we achieve state-of-the-art for rank-I matching rates in three person re-identification datasets (CUHK03, PRID450S and GRID) and the second best results on VIPeR and CUHK01 datasets. Furthermore, we present outperforming results on Market-1501 dataset demonstrating that the Kernel X-CRC is suitable to a large-scale and multiple cameras scenario. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Prates, Raphael; Schwartz, William Robson] Univ Fed Minas Gerais, Smart Sense Lab, Comp Sci Dept, Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais
RP Prates, R (corresponding author), Univ Fed Minas Gerais, Smart Sense Lab, Comp Sci Dept, Belo Horizonte, MG, Brazil.
EM prates@dcc.ufmg.br; william@dcc.ufmg.br
RI Schwartz, William Robson/E-6612-2011; Prates, Raphael/T-2999-2019
OI Schwartz, William/0000-0003-1449-8834
FU National Council for Scientific and Technological Development - CNPq
   [3110531 2016-5]; Minas Gerais Research Foundation - FAPEMIG
   [APQ-00567-14, PPM-00540-17]; Coordination for the Improvement of Higher
   Education Personnel - CAPES (DeepEyes Project); Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES) [001]
FX The authors would like to thank the National Council for Scientific and
   Technological Development - CNPq (Grant similar to 3110531 2016-5), the
   Minas Gerais Research Foundation - FAPEMIG (Grants similar to
   APQ-00567-14 and similar to PPM-00540-17) and the Coordination for the
   Improvement of Higher Education Personnel - CAPES (DeepEyes Project).
   This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647
   [Anonymous], P 11 INT C DISTR SMA
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P INT C DISTR SMART
   [Anonymous], ARXIV12042358
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Cai Y, 2011, LECT NOTES COMPUT SC, V6468, P205
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Cheng DC, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-26
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Prates RFD, 2015, INT CONF BIOMETR, P65, DOI 10.1109/ICB.2015.7139077
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang S., ARXIV151105169
   Ibn Khedher M, 2015, LECT NOTES COMPUT SC, V9491, P241, DOI 10.1007/978-3-319-26555-1_28
   Ibn Khedher M, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P159, DOI 10.1109/AVSS.2013.6636633
   Jose C., ARXIV160300370
   Karanam Srikrishna, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P33, DOI 10.1109/CVPRW.2015.7301392
   Khan F. M., ARXIV160705975
   Kodirov E, 2015, BRIT MACH VIS C, V44, P1
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li JY, 2014, IEEE T GEOSCI REMOTE, V52, P3707, DOI 10.1109/TGRS.2013.2274875
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu CX, 2014, PATTERN RECOGN, V47, P1602, DOI 10.1016/j.patcog.2013.11.001
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Martinel N, 2016, INT C PATT RECOG, P1225, DOI 10.1109/ICPR.2016.7899804
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Prates R, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P249, DOI 10.1109/AVSS.2016.7738030
   Prates RF, 2016, INT C PATT RECOG, P2091, DOI 10.1109/ICPR.2016.7899944
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Shi H., ARXIV151107545
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Tian C, 2015, IEEE SIGNAL PROC LET, V22, P1595, DOI 10.1109/LSP.2014.2372338
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu S, 2016, The Metallogenic Mechanism of Distal Contact Pb-Zn-ag Vines in Shizhuyuan Ore District, Hunan Province, China, V2016, P1
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zeng MY, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301296
   Zhang HC, 2012, PATTERN RECOGN, V45, P1290, DOI 10.1016/j.patcog.2011.09.009
   Zhang L., ARXIV160302139
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L., ARXIV161002984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
NR 70
TC 12
Z9 13
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 304
EP 315
DI 10.1016/j.jvcir.2018.12.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, QL
   Chen, BL
   Lu, X
   Xia, QQ
AF Zhang, Qinglin
   Chen, Bingling
   Lu, Xuan
   Xia, Qiaoqiao
TI Super-resolution of single multi-color image with guided filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Multi-color image; Guided filter; Chromatic channel
ID REGULARIZATION; RESOLUTION
AB Super resolution reconstruction is a method that can transcend the limitations of optical imaging systems through the use of image processing algorithms. Recent techniques of super-resolution for single monochrome images develop rapidly, but for single multi-color images, to efficiently apply the monochrome super-resolution algorithms to all channels is still under exploration. In most of the recent research, the chromatic channels are simply upscaled by interpolation, which leads to the quality of the chromatic channels downgraded. This application may not be noticed by the visual systems of humans, but can affect other algorithms when super-resolution plays roles at image pre-processing. In this paper, we present a novel approach for multi-color super-resolution reconstruction. Using the super-resolution reconstructed luminance channel as the guide image, we adopt guided filters to manage the interpolated chromatic channels. Guided filters retain the sharp edges and fine details from the guided image and carry them to the output images. Meanwhile the whole process is quite computationally economic. Extensive experiments on natural images show that our method achieves better results than the method that is used in most of the algorithm in the literature in both statistic and visual aspects. (C) 2018 Published by Elsevier Inc.
C1 [Zhang, Qinglin; Chen, Bingling; Xia, Qiaoqiao] Cent China Normal Univ, Coll Phys Sci & Technol, Wuhan 430079, Hubei, Peoples R China.
   [Lu, Xuan] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei, Peoples R China.
C3 Central China Normal University; Wuhan University
RP Xia, QQ (corresponding author), Cent China Normal Univ, Coll Phys Sci & Technol, Wuhan 430079, Hubei, Peoples R China.
EM qiaoqiaoxia123@126.com
RI xia, Qiaoqiao/AAZ-7348-2020; Zhang, Qinglin/AAA-2842-2020
OI qiaoqiao, xia/0000-0001-7517-8856; Zhang, Qinglin/0000-0001-6023-6734
CR [Anonymous], 2010, EUR C COMP VIS
   [Anonymous], J ELECT IMAGING
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Glasner D., 2009, P 12 INT C COMP VIS
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li JM, 2015, INFORM SCIENCES, V298, P257, DOI 10.1016/j.ins.2014.11.032
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tom BC, 2001, IEEE T IMAGE PROCESS, V10, P278, DOI 10.1109/83.902292
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 17
TC 3
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 277
EP 284
DI 10.1016/j.jvcir.2018.11.040
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100028
DA 2024-07-18
ER

PT J
AU Liu, L
   Yan, ZJ
   Liu, Q
AF Liu, Long
   Yan, Zijing
   Liu, Qing
TI Panoramic visual tracking based on adaptive mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Panoramic vision; Target tracking; Particle filtering; Feature fusion;
   Adaption
AB Panoramic visual tracking has high application value in many situations, but its visual distortion is likely to cause low tracking robustness or loss of target. This paper presents a panoramic visual tracking method based on adaptive feature fusion method, the size of the trapezoidal frame is calibrated with target moving in the method, and the linear model of trapezoidal frame parameters is fitted, then according to the model trapezoidal area of target extracted, and are modified to target trapezoidal region through the affine transformation; Based on filter tracking framework, the fusion of color and shape information is as the main characteristics of the target tracking, and Bayesian fusion recursive formula is used for calculating the particle weights. The experimental results show that the proposed algorithm is better than the existing methods in tracking precision and anti occlusion, and effectively improves the robustness of panoramic visual tracking. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Long; Yan, Zijing; Liu, Qing] Xian Univ Technol, Automat & Informat Sch, Xian, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Liu, L (corresponding author), Xian Univ Technol, Automat & Informat Sch, Xian, Shaanxi, Peoples R China.
EM liulong.edu@gmail.com
FU National Natural Science Foundation of China [61673318, 61702410,
   61502385]
FX Thanks to the funding of the National Natural Science Foundation of
   China (61673318, 61702410, 61502385).
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BAZIN J C, 2009, BMVC, P1, DOI [10.5244/C.23.37, DOI 10.5244/C.23.37]
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P1298, DOI 10.1109/TIP.2011.2169970
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Rameau F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P328, DOI 10.1109/ICCVW.2011.6130260
   Rameau F, 2011, ELECTRON LETT, V47, P1183, DOI 10.1049/el.2011.2838
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
NR 12
TC 4
Z9 4
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 99
EP 106
DI 10.1016/j.jvcir.2018.10.020
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400013
DA 2024-07-18
ER

PT J
AU Wang, X
   Zhang, PP
   Zhang, Y
   Ma, L
   Kwong, S
   Jiang, JM
AF Wang, Xu
   Zhang, Pingping
   Zhang, Yun
   Ma, Lin
   Kwong, Sam
   Jiang, Jianmin
TI Deep intensity guidance based compression artifacts reduction for depth
   map
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; Compression artifacts reduction; JPEG
   compression; Depth map
ID BLOCKING ARTIFACTS; DEBLOCKING; DCT
AB In this paper, we propose an deep intensity guidance based compression artifacts reduction model (denoted as DIG-Net) for depth map. The proposed DIG-Net model can learn an end-to-end mapping from the color image and distorted depth map to the uncompressed depth map. To eliminate undesired artifacts such as discontinuities around object boundary, the proposed model is with three branches, which extracts the high frequency information from color image and depth maps as priors. Based on the modified edge preserving loss function, the deep multi-scale guidance information are learned and fused in the model to make the edge of depth map sharper. Experimental results show the effectiveness and superiority of our proposed model compared with the state-of-the-art methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Xu; Zhang, Pingping; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Wang, Xu; Zhang, Pingping; Jiang, Jianmin] Shenzhen Univ, Natl Engn Lab Big Data Syst Comp Technol, Shenzhen 518060, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Ma, Lin] Tencent AI Lab, Shenzhen, Peoples R China.
C3 Shenzhen University; Shenzhen University; City University of Hong Kong;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Tencent
RP Wang, X (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.; Wang, X (corresponding author), Shenzhen Univ, Natl Engn Lab Big Data Syst Comp Technol, Shenzhen 518060, Peoples R China.
EM wangxu@szu.edu.cn; yun.zhang@siat.ac.cn; cssamk@szu.edu.cn;
   jianmin.jiang@szu.edu.cn
RI Kwong, Sam/C-9319-2012; Zhang, Yun/V-7261-2019
OI Kwong, Sam/0000-0001-7484-7261; Zhang, Yun/0000-0001-9457-7801; Zhang,
   Pingping/0000-0003-4188-1572
FU National Natural Science Foundation of China [31670553, 61871270,
   61501299, 61672443, 61620106008]; Guangdong Nature Science Foundation
   [2016A030310058]; Shenzhen Emerging Industries of the Strategic Basic
   Research Project [JCYJ20160226191842793]; Natural Science Foundation of
   SZU [827000144]; Tencent "Rhinoceros Birds"-Scientific Research
   Foundation for Young Teachers of Shenzhen University
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 31670553, 61871270, 61501299, 61672443
   and 61620106008, in part by the Guangdong Nature Science Foundation
   under Grant 2016A030310058, in part by the Shenzhen Emerging Industries
   of the Strategic Basic Research Project under Grants
   JCYJ20160226191842793, in part by the Natural Science Foundation of SZU
   (Grant No. 827000144), and in part by the Tencent "Rhinoceros
   Birds"-Scientific Research Foundation for Young Teachers of Shenzhen
   University.
CR [Anonymous], 2017, P C COMP VIS PATT RE
   [Anonymous], 2003, 2003 IEEE COMP SOC C
   [Anonymous], OPT ENG
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2016, Journal of WSCG
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P509, DOI 10.1109/TIP.2016.2627807
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Mao X., 2016, CoRR
   Meilland M, 2015, J FIELD ROBOT, V32, P474, DOI 10.1002/rob.21531
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Ren W., 2018, IEEE C COMPUTER VISI
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shen XY, 2015, IEEE I CONF COMP VIS, P3406, DOI 10.1109/ICCV.2015.389
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Singh S, 2007, DIGIT SIGNAL PROCESS, V17, P225, DOI 10.1016/j.dsp.2005.08.003
   Thatte J, 2016, IEEE IMAGE PROC, P1569, DOI 10.1109/ICIP.2016.7532622
   Wang C, 2013, SIGNAL PROCESS-IMAGE, V28, P522, DOI 10.1016/j.image.2013.01.006
   Yaman M, 2015, J VIS COMMUN IMAGE R, V26, P115, DOI 10.1016/j.jvcir.2014.11.010
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Yang Y, 2019, IEEE T IMAGE PROCESS, V28, P302, DOI 10.1109/TIP.2018.2867740
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zhang PP, 2018, LECT NOTES COMPUT SC, V10735, P863, DOI 10.1007/978-3-319-77380-3_83
   Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134
NR 35
TC 9
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 234
EP 242
DI 10.1016/j.jvcir.2018.11.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400028
DA 2024-07-18
ER

PT J
AU Shijila, B
   Tom, AJ
   George, SN
AF Shijila, B.
   Tom, Anju Jose
   George, Sudhish N.
TI Moving object detection by low rank approximation and
   <i>l</i><sub>1</sub>-<i>TV</i> regularization on RPCA framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving object detection; Low rank recovery; Background subtraction;
   Robust principle component analysis
ID VARIABLE SELECTION; ALGORITHM; NORM; DECOMPOSITION; GRADIENT
AB The detection of moving objects and the subtraction of the scene background are significant tasks for intelligent video surveillance systems as it is one among the fundamental steps. Inspired by the challenging cases yet to be resolved in Moving Object Detection (MOD), a new formulation is done to detect moving objects from video sequences based on Robust Principal Component Analysis (RPCA) principle by adopting the regularization of Total Variation (TV) norm using a convergent convex optimization algorithm. While the nuclear norm exploits the low-rank property of background, the sparsity is enhanced by the l(1)-norm and the foreground spatial smoothness is explored by TV regularization. The goodness of this method lies in the reduced computational complexity, quickness and on the superiority acquired in quantitative evaluation based on F-measure, Recall and Precision with respect to the state of the art methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Shijila, B.; Tom, Anju Jose; George, Sudhish N.] Natl Inst Technol Calicut, Dept Elect & Commun Engn, Calicut 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Shijila, B (corresponding author), Natl Inst Technol Calicut, Dept Elect & Commun Engn, Calicut 673601, Kerala, India.
EM shijilanitc@gmail.com
RI George, Sudhish/U-3625-2019; Tom, Anju Jose/AAE-2677-2019; JOSE TOM,
   ANJU/HGD-1885-2022
OI Tom, Anju Jose/0000-0002-8057-6223; JOSE TOM, ANJU/0000-0002-8057-6223
CR Batmanghelich N., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P146
   Bergqvist G, 2010, IEEE SIGNAL PROC MAG, V27, P151, DOI 10.1109/MSP.2010.936030
   Boas T., SHRINKAGE FUNCTION I
   Bouwmans T, 2016, HANDBOOK OF ROBUST LOW-RANK AND SPARSE MATRIX DECOMPOSITION: APPLICATIONS IN IMAGE AND VIDEO PROCESSING, P1, DOI 10.1201/b20190
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Braman K, 2010, LINEAR ALGEBRA APPL, V433, P1241, DOI 10.1016/j.laa.2010.05.025
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chen C, 2015, NUMER LINEAR ALGEBR, V22, P999, DOI 10.1002/nla.1993
   Chen RA, 2016, PROCEEDINGS OF 2016 THE 2ND INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS, P312, DOI 10.1109/ICCAR.2016.7486747
   Chen YY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020161
   Deledalle C.A., 2015, SIGNAL PROCESSING AD
   Ebadi S. E., IEEE T PATTERN ANAL
   Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   He W, 2016, IEEE T GEOSCI REMOTE, V54, P176, DOI 10.1109/TGRS.2015.2452812
   Henkelman R. M., ITERATIVE BLOCK TENS
   Hu WR, 2017, IEEE T IMAGE PROCESS, V26, P724, DOI 10.1109/TIP.2016.2627803
   Javed S., 2015, 6 INT C IM CRIM PREV, P5
   Jayswal A, 2014, AIN SHAMS ENG J, V5, P1371, DOI 10.1016/j.asej.2014.07.008
   Jiang C, 2016, CAN J REMOTE SENS, V42, P53, DOI 10.1080/07038992.2016.1158094
   Komodakis N, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2014.2377273
   LEBLANC LJ, 1985, TRANSPORT SCI, V19, P445, DOI 10.1287/trsc.19.4.445
   Lee H, 2016, IEEE T MULTIMEDIA, V18, P2093, DOI 10.1109/TMM.2016.2595262
   Lei J, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/353970
   Li RY, 2015, LECT NOTES COMPUT SC, V9350, P700, DOI 10.1007/978-3-319-24571-3_84
   Li S, 2016, IEEE T NEUR NET LEAR, V27, P2160, DOI 10.1109/TNNLS.2015.2464090
   Li XX, 2015, NUMER LINEAR ALGEBR, V22, P845, DOI 10.1002/nla.1981
   Lin M. C. Z., 2011, THE AUGMENTED LAGRAN
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Madathil B, 2018, INFORM SCIENCES, V423, P376, DOI 10.1016/j.ins.2017.09.058
   Rodriguez P, 2016, J MATH IMAGING VIS, V55, P1, DOI 10.1007/s10851-015-0610-z
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sagheer SVM, 2017, BIOMED SIGNAL PROCES, V38, P236, DOI 10.1016/j.bspc.2017.06.011
   Shao WZ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/656074
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun YP, 2015, IEEE T IMAGE PROCESS, V24, P2515, DOI 10.1109/TIP.2015.2419075
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55
   Xie Y, 2016, IEEE T GEOSCI REMOTE, V54, P4642, DOI 10.1109/TGRS.2016.2547879
   Xu Z, 2017, AAAI CONF ARTIF INTE, P2803
   Yao JW, 2018, MED IMAGE ANAL, V44, P14, DOI 10.1016/j.media.2017.11.003
   Zhai H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040335
   Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhang ZD, 2011, IEEE I CONF COMP VIS, P1347, DOI 10.1109/ICCV.2011.6126388
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhu L, 2018, IEEE SIGNAL PROC LET, V25, P15, DOI 10.1109/LSP.2017.2768582
NR 54
TC 18
Z9 18
U1 4
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 188
EP 200
DI 10.1016/j.jvcir.2018.09.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500019
DA 2024-07-18
ER

PT J
AU Gan, WH
   Lee, MS
   Wu, CH
   Kuo, CC
AF Gan, Weihao
   Lee, Ming-Sui
   Wu, Chi-hao
   Kuo, C. -C. (Jay)
TI Online object tracking via motion-guided convolutional neural network
   (MGNet)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Online tracking; Convolutional neural network; Optical
   flow; Multi-domain learning
ID ROBUST VISUAL TRACKING
AB Tracking-by-detection (TBD) is widely used in visual object tracking. However, many TBD-based methods ignore the strong motion correlation between current and previous frames. In this work, a motion-guided convolutional neural network (MGNet) solution to online object tracking is proposed. The MGNet tracker is built upon the multi-domain convolutional neural network with two innovations: (1) a motion-guided candidate selection (MCS) scheme based on a dynamic prediction model is proposed to accurately and efficiently generate the candidate regions and (2) the spatial RGB and temporal optical flow are combined as inputs and processed in an unified end-to-end trained network, rather than a two-branch processing network. We compare the performance of the MGNet, the MDNet and several state-of-the-art online object trackers on the OTB and the VOT benchmark datasets, and demonstrate that the temporal correlation between any two consecutive frames in videos can be more effectively captured by the MGNet via extensive performance evaluation.
C1 [Gan, Weihao; Wu, Chi-hao; Kuo, C. -C. (Jay)] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Lee, Ming-Sui] Natl Taiwan Univ, Taipei, Taiwan.
C3 University of Southern California; National Taiwan University
RP Gan, WH (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM weihaoga@usc.edu
RI Wu, chihao/G-3512-2011; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Akin O, 2016, J VIS COMMUN IMAGE R, V38, P763, DOI 10.1016/j.jvcir.2016.04.018
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, CVPR
   [Anonymous], ARXIV150104587
   [Anonymous], 2017, ARXIV170406036
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2
   Danelljan M., 2016, ARXIV161109224
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Doucet A, 2001, STAT ENG IN, P3
   Fan Heng, 2016, ARXIV161106878
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gan WH, 2016, SIGNAL PROCESS-IMAGE, V47, P303, DOI 10.1016/j.image.2016.07.005
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hong ZB, 2014, LECT NOTES COMPUT SC, V8694, P155, DOI 10.1007/978-3-319-10599-4_11
   Ji ZJ, 2015, J VIS COMMUN IMAGE R, V28, P44, DOI 10.1016/j.jvcir.2015.01.008
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kuo C.-C.J., 2017, IEEE SIG PROCESS MAG
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Kwon J, 2014, LECT NOTES COMPUT SC, V8689, P377, DOI 10.1007/978-3-319-10590-1_25
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lebeda K, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P153, DOI 10.1109/ICCVW.2013.26
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li ZY, 2017, J VIS COMMUN IMAGE R, V44, P1, DOI [10.1016/j.jvcir.2017.01.012, 10.16339/j.cnki.hdxbzkb.2017.11.001]
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Matthias M., 2017, P IEEE C COMP VIS PA
   Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250
   Ruan Y, 2016, J VIS COMMUN IMAGE R, V35, P146, DOI 10.1016/j.jvcir.2015.12.009
   Saffari A, 2010, LECT NOTES COMPUT SC, V6313, P776
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie CJ, 2014, J VIS COMMUN IMAGE R, V25, P423, DOI 10.1016/j.jvcir.2013.12.012
   Yao R, 2017, IEEE T MULTIMEDIA, V19, P772, DOI 10.1109/TMM.2016.2631727
   Yuan Y, 2015, IEEE T MULTIMEDIA, V17, P1125, DOI 10.1109/TMM.2015.2440996
   Zeisl B, 2010, PROC CVPR IEEE, P1879, DOI 10.1109/CVPR.2010.5539860
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 59
TC 11
Z9 11
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 180
EP 191
DI 10.1016/j.jvcir.2018.03.016
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800017
DA 2024-07-18
ER

PT J
AU Ma, QT
   Kong, DX
AF Ma, Qianting
   Kong, Dexing
TI A new variational model for joint restoration and segmentation based on
   the Mumford-Shah model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Image restoration; Mumford-Shah model
ID IMAGE SEGMENTATION; ACTIVE CONTOURS
AB Due to the typical challenges including image noise or blurriness, intensity inhomogeneity or various image modalities, image segmentation is still an open problem. In this paper, a new variational model is proposed for multiphase segmentation of gray and color images corrupted by noise or blur. Based on the aspects of image restoration, the coupled fidelity terms are utilized in order to effectively and robustly tackle images with a high level of noise or blurriness. For intensity inhomogeneous images, we use the bias-corrected fuzzy c-means method to eliminate the effect of bias field before our implementation. A partial result for the energy minimization problem is established. For solving the new variational model, the alternating minimization algorithm is studied. Experiments demonstrate that our method gives excellent results in terms of segmentation quality in comparison with other state-of-the-art segmentation methods.
C1 [Ma, Qianting; Kong, Dexing] Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Kong, DX (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Zhejiang, Peoples R China.
EM 11435025@zju.edu.cn; dkong@zju.edu.cn
RI Ma, Qianting/HKF-6159-2023
OI Ma, Qianting/0000-0001-5370-0252
FU National Natural Science Foundation of China [91630311]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 91630311).
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   An J, 2007, LECT NOTES COMPUT SC, V4792, P495
   [Anonymous], MRI TISSUE CLASSIFIC
   [Anonymous], 2006, Mathematical problems in image processing: Partial differential equations and the calculus of variations
   [Anonymous], 1960, Arch. Math. (Basel)
   [Anonymous], 1999, CLASSICS APPL MATH
   Bar L, 2004, LECT NOTES COMPUT SC, V3022, P166
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P203
   Cai XH, 2015, PATTERN RECOGN, V48, P2029, DOI 10.1016/j.patcog.2015.01.008
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YM, 2000, COMPUT MATH APPL, V39, P131, DOI 10.1016/S0898-1221(00)00050-X
   Duan YP, 2014, IEEE IMAGE PROC, P6, DOI 10.1109/ICIP.2014.7025000
   Duan YP, 2015, IEEE T IMAGE PROCESS, V24, P3927, DOI 10.1109/TIP.2015.2451957
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Han X, 2007, IEEE T MED IMAGING, V26, P479, DOI 10.1109/TMI.2007.893282
   He Y., 2012, PATTERN RECOGN, V45, P3436, DOI DOI 10.1016/J.PATC0G.2012.03.009
   Ivanovska T, 2016, COMPUT MED IMAG GRAP, V48, P9, DOI 10.1016/j.compmedimag.2015.11.005
   Lankton S., 2007, SPIE MED IM S
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li C, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P1, DOI 10.1145/1329125.1329187
   Li F, 2010, SIAM J IMAGING SCI, V3, P277, DOI 10.1137/080736752
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Mory B, 2007, LECT NOTES COMPUT SC, V4485, P214
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Paul G, 2013, INT J COMPUT VISION, V104, P69, DOI 10.1007/s11263-013-0615-2
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   RUDIN LI, 1994, IEEE IMAGE PROC, P31
   Setzer S., 2008, VARIATIONAL METHODS, P360
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Xue JR, 2011, IEEE T IMAGE PROCESS, V20, P1177, DOI 10.1109/TIP.2010.2077643
   Yang Y., 2010, J NANOMATER, V2010, P1, DOI DOI 10.1371/J0URNAL.P0NE.0013427
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Yuan J, 2010, LECT NOTES COMPUT SC, V6316, P379, DOI 10.1007/978-3-642-15567-3_28
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 43
TC 6
Z9 6
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 224
EP 234
DI 10.1016/j.jvcir.2018.03.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800021
DA 2024-07-18
ER

PT J
AU Jacinto, H
   Valette, S
   Prost, R
AF Jacinto, Hector
   Valette, Sebastien
   Prost, Remy
TI Multi-atlas automatic positioning of anatomical landmarks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Orthopaedics; Knee; Landmarks; Atlas; Registration; Positioning
ID NONRIGID REGISTRATION; IMAGE REGISTRATION; KNEE ALIGNMENT; CT-SCAN;
   SHAPE; PARAMETERIZATION; ACCURACY
AB We propose a method for the automatic positioning of pre-defined landmarks on 3-D models of anatomical structures. We exploit a group of atlases consisting of multiple triangular meshes for which the defined landmarks have been placed by experts. We compute an initial coarse global registration of the patient mesh with an expert mesh by using a curvature-enhanced Iterative Closest Point (ICP) algorithm. Adaptive local rigid registrations refine the fit for the projection of reference landmarks onto the surface of the patient structure. An automatic selection based on a fit criterion computes a final position for each landmark. Our positioning method improves the efficiency of the positioning task, being completely unsupervised and yielding results competitive with those of the manual positioning. We provide comparisons with previous works of the literature. The automatic positioning for each target structure is completely reproducible as opposed to manual positioning, affected by infra-operator variability.
C1 [Jacinto, Hector] OneFit Med SAS, Besancon, France.
   [Jacinto, Hector; Valette, Sebastien; Prost, Remy] Univ Lyon, INSERM, CNRS, CREATIS,UMR5220,U630,INSA Lyon, Villeurbanne, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Centre
   National de la Recherche Scientifique (CNRS); CNRS - Institute for
   Engineering & Systems Sciences (INSIS); Institut National de la Sante et
   de la Recherche Medicale (Inserm)
RP Valette, S (corresponding author), Univ Lyon, INSERM, CNRS, CREATIS,UMR5220,U630,INSA Lyon, Villeurbanne, France.
EM sebastien.valette@creatis.insa-lyon.fr
RI Valette, Sebastien/H-4195-2014; Prost, Rémy/I-2675-2014
OI Valette, Sebastien/0000-0001-7549-4808; 
FU Association Nationale de la Recherche et de la Technologie (ANRT; Paris,
   France) [CIFRE:2011/1426]
FX We thank OneFit Medical, SAS (Besancon, France) and the Association
   Nationale de la Recherche et de la Technologie (ANRT; Paris, France) for
   founding this work (CIFRE:2011/1426).
CR Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   Andresen PR, 2001, MED IMAGE ANAL, V5, P81, DOI 10.1016/S1361-8415(00)00036-0
   [Anonymous], EUR WORKSH 3D OBJ RE
   AU O. K.-C., 2010, COMPUTER GRAPHICS FO, V29, P3
   Baek SY, 2013, COMPUT AIDED DESIGN, V45, P505, DOI 10.1016/j.cad.2012.10.033
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Cazals F., 2003, Symposium on Geometry Processing, P177
   Chen QF, 2015, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2015.236
   Della Croce U, 2005, GAIT POSTURE, V21, P226, DOI 10.1016/j.gaitpost.2004.05.003
   Deng BL, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12021
   Derek T, 2007, J RHEUMATOL, V34, P1796
   Do Carmo M.P., 1976, DIFFERENTIAL GEOMETR, V2
   Du SY, 2010, J VIS COMMUN IMAGE R, V21, P442, DOI 10.1016/j.jvcir.2010.02.005
   Ehrhardt J, 2004, METHOD INFORM MED, V43, P391
   Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998
   Gelfand N., 2005, P EUR S GEOM PROC, V2, P5
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jacinto H, 2014, IEEE IMAGE PROC, P3572, DOI 10.1109/ICIP.2014.7025725
   Jacinto H, 2012, WEB3D 2012, P51
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Kéchichian R, 2013, IEEE T IMAGE PROCESS, V22, P4224, DOI 10.1109/TIP.2013.2271192
   Koch PP, 2013, KNEE SURG SPORT TR A, V21, P2200, DOI 10.1007/s00167-013-2625-6
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Kraus VB, 2005, ARTHRITIS RHEUM, V52, P1730, DOI 10.1002/art.21100
   Li H., COMPUTER GRAPHICS FO, V27
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Nagamine R, 2000, J Orthop Sci, V5, P232, DOI 10.1007/s007760050157
   Nieuwenhuis C, 2013, INT J COMPUT VISION, V104, P223, DOI 10.1007/s11263-013-0619-y
   Phan CB, 2015, INT J COMPUT ASS RAD, V10, P1711, DOI 10.1007/s11548-015-1155-8
   Pokrass J., ABS12096560 CORR
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Subburaj K, 2009, COMPUT MED IMAG GRAP, V33, P359, DOI 10.1016/j.compmedimag.2009.03.001
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Valette S, 2004, COMPUT GRAPH FORUM, V23, P381, DOI 10.1111/j.1467-8659.2004.00769.x
   Valette S, 2008, IEEE T VIS COMPUT GR, V14, P369, DOI 10.1109/TVCG.2007.70430
   Van Haver A, 2014, KNEE, V21, P518, DOI 10.1016/j.knee.2013.11.016
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x
   Vanwanseele B, 2009, CLIN ORTHOP RELAT R, V467, P504, DOI 10.1007/s11999-008-0545-4
   Victor J, 2009, KNEE, V16, P358, DOI 10.1016/j.knee.2009.01.001
   Yau WP, 2008, KNEE SURG SPORT TR A, V16, P670, DOI 10.1007/s00167-008-0550-x
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   Zheng Y., 2015, 3D DEEP LEARNING EFF
NR 52
TC 9
Z9 10
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 167
EP 177
DI 10.1016/j.jvcir.2017.11.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700017
DA 2024-07-18
ER

PT J
AU Aslan, S
   Akgül, CB
   Sankur, B
   Tunali, ET
AF Aslan, Sinem
   Akgul, Ceyhun Burak
   Sankur, Bulent
   Tunali, E. Turhan
TI Exploring visual dictionaries: A model driven perspective
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Model-driven; Visual dictionary; Bag of Visual Words; Shape models;
   Primitive image structures; Image understanding; Object recognition;
   Scene classification
ID BASIC IMAGE FEATURES; MUTUAL INFORMATION; CLASSIFICATION; RECOGNITION;
   ILLUMINATION; SPACE; SIFT
AB Good representative dictionaries is the most critical part of the BoVW: Bag of Visual Words scheme, used for such tasks as category identification. The paradigm of learning dictionaries from datasets is by far the most widely used approach and there exists a plethora of methods to this effect. Dictionary learning methods demand abundant data, and when the amount of training data is limited, the quality of dictionaries and consequently the performance of BoVW methods suffer. A much less explored path for creating visual dictionaries starts from the knowledge of primitives in appearance models and creates families of parametric shape models. In this work, we develop shape models starting from a small number of primitives and develop a visual dictionary using various nonlinear operations and nonlinear combinations. Compared with the existing model-driven schemes, our method is able to represent and characterize images in various image understanding applications with competitive, and often better performance.
C1 [Aslan, Sinem] Ege Univ, Int Comp Inst, Izmir, Turkey.
   [Akgul, Ceyhun Burak; Sankur, Bulent] Bogazici Univ, Elect & Elect Engn Dept, Istanbul, Turkey.
   [Tunali, E. Turhan] Izmir Univ Econ, Dept Comp Engn, Izmir, Turkey.
C3 Ege University; Bogazici University; Izmir Ekonomi Universitesi
RP Aslan, S (corresponding author), Ege Univ, Int Comp Inst, Izmir, Turkey.
EM sinem.aslan@ege.edu.tr; cb.akgul@gmail.com; bulent.sankur@boun.edu.tr;
   turhan.tunali@ieu.edu.tr
RI Tekalp, Murat/AAW-1060-2020; Aslan, Sinem/C-3381-2008
OI Aslan, Sinem/0000-0003-0068-6551
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], P 10 EUR C COMP
   [Anonymous], 2009, FINDING GROUPS DATA
   [Anonymous], MAXIMUM RESPONSE MR
   [Anonymous], ARXIV14113230
   [Anonymous], 2013, ICML
   [Anonymous], THESIS
   [Anonymous], CONT BAS IM RETR
   [Anonymous], TECH REP
   [Anonymous], MIUA
   [Anonymous], THESIS
   [Anonymous], ARXIVMATH9602214
   [Anonymous], IEEE WORKSH STAT COM
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], TECH REP
   [Anonymous], P INT C PATT REC ICP
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], COMPUT METHODS BIOME
   [Anonymous], LEARNING RECOGNIZE 3
   [Anonymous], ELECT IMAGING 2007
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], BASIC IMAGE FEATURES
   [Anonymous], IEEE WORKSH STAT COM
   [Anonymous], 2013, ICML
   [Anonymous], 2006, GESTS International Transactions on Computer Science and Engineering
   BARLOW HB, 1953, J PHYSIOL-LONDON, V119, P69, DOI 10.1113/jphysiol.1953.sp004829
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Berger AlanL., 2001, Introduction to Second Generation Voices: Reflections by Children of Holocaust Survivors and Perpetrators, P1
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cen F, 2004, LECT NOTES COMPUT SC, V3117, P304
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Cusano C, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061410
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danaci EG, 2016, PATTERN RECOGN LETT, V84, P185, DOI 10.1016/j.patrec.2016.09.015
   Dantone M, 2014, IEEE T PATTERN ANAL, V36, P2131, DOI 10.1109/TPAMI.2014.2318702
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Deselaers T, 2004, INT C PATT RECOG, P505, DOI 10.1109/ICPR.2004.1334280
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dollar P., PIOTRS COMPUTER VISI
   Donoho DL, 1999, PROC SPIE, V3813, P468, DOI 10.1117/12.366804
   Doquire G, 2013, NEUROCOMPUTING, V122, P148, DOI 10.1016/j.neucom.2013.06.035
   Dou JF, 2014, OPTIK, V125, P435, DOI 10.1016/j.ijleo.2013.06.079
   Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P194
   Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Griffin LD, 2007, IEEE T PATTERN ANAL, V29, P1355, DOI 10.1109/TPAMI.2007.1066
   Griffin LD, 2009, LECT NOTES COMPUT SC, V5567, P343, DOI 10.1007/978-3-642-02256-2_29
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004
   Hamsici OC, 2009, IEEE T PATTERN ANAL, V31, P1985, DOI 10.1109/TPAMI.2008.234
   Hanbury A, 2004, INT C PATT RECOG, P672, DOI 10.1109/ICPR.2004.1334259
   Hartline HK, 1938, AM J PHYSIOL, V121, P400, DOI 10.1152/ajplegacy.1938.121.2.400
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heiler M, 2005, INT J COMPUT VISION, V63, P5, DOI 10.1007/s11263-005-4944-7
   HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932
   HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855
   Horaud R., 1990, P EUROPEAN C COMPUTE, P374
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jayasumana S, 2013, IEEE I CONF COMP VIS, P1249, DOI 10.1109/ICCV.2013.158
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   KERBER R, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P123
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Law MT, 2014, ADV COMPUT VIS PATT, P29, DOI 10.1007/978-3-319-05696-8_2
   Lawson S, 2002, ELECTRON COMMUN ENG, V14, P112, DOI 10.1049/ecej:20020303
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li FX, 2010, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2010.5539839
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090
   Marr D., 1982, Visual perception
   MarSSe R., 2004, P 6 ASIAN C COMPUTER, V2, P860
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Morgan MJ, 2011, VISION RES, V51, P738, DOI 10.1016/j.visres.2010.08.002
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317
   Naik SK, 2007, IEEE T PATTERN ANAL, V29, P1291, DOI 10.1109/TPAMI.2007.1029
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Newell A. J., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P191, DOI 10.1109/DICTA.2011.39
   Newell AJ, 2014, PATTERN RECOGN, V47, P2255, DOI 10.1016/j.patcog.2013.11.029
   Newell AJ, 2012, J FORENSIC SCI, V57, P1285, DOI 10.1111/j.1556-4029.2012.02126.x
   Nowak E., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P277
   Obdrzálek S, 2003, LECT NOTES COMPUT SC, V2781, P490
   Obdrzalek S., 2002, Proceedings of the British Machine Vision Conference, V1, P3
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Perronnin F., 2007, P IEEE C COMPUTER VI, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pham D. S., 2008, P IEEE C COMPUTER VI, P1
   Pu YC, 2016, JMLR WORKSH CONF PRO, V51, P741
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   SAUND E, 1990, IEEE T PATTERN ANAL, V12, P817, DOI 10.1109/34.57672
   Shao H, 2003, LECT NOTES COMPUT SC, V2728, P71
   Shao H., 2003, ZUBUD ZURICH BUILD I, P6
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Ventura RMFI, 2006, IEEE T IMAGE PROCESS, V15, P726, DOI 10.1109/TIP.2005.860596
   VILNROTTER FM, 1986, IEEE T PATTERN ANAL, V8, P76, DOI 10.1109/TPAMI.1986.4767754
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Witkin A.P., 1983, Human and Machine Vision
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang LF, 2015, IEEE IMAGE PROC, P4873, DOI 10.1109/ICIP.2015.7351733
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhu F, 2014, PROC CVPR IEEE, P2457, DOI 10.1109/CVPR.2014.315
NR 130
TC 4
Z9 5
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 315
EP 331
DI 10.1016/j.jvcir.2017.09.009
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800026
DA 2024-07-18
ER

PT J
AU Furnari, A
   Battiato, S
   Grauman, K
   Farinella, GM
AF Furnari, Antonino
   Battiato, Sebastiano
   Grauman, Kristen
   Farinella, Giovanni Maria
TI Next-active-object prediction from egocentric videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Egocentric vision; Forecasting; Object interaction; Next-active-object
AB Although First Person Vision systems can sense the environment from the user's perspective, they are generally unable to predict his intentions and goals. Since human activities can be decomposed in terms of atomic actions and interactions with objects, intelligent wearable systems would benefit from the ability to anticipate user-object interactions. Even if this task is not trivial, the First Person Vision paradigm can provide important cues to address this challenge. We propose to exploit the dynamics of the scene to recognize next-active-objects before an object interaction begins. We train a classifier to discriminate trajectories leading to an object activation from all others and forecast next-active-objects by analyzing fixed-length trajectory segments within a temporal sliding window. The proposed method compares favorably with respect to several baselines on the Activity of Daily Living (ADL) egocentric dataset comprising 10 h of videos acquired by 20 subjects while performing unconstrained interactions with several objects.
C1 [Furnari, Antonino; Battiato, Sebastiano; Farinella, Giovanni Maria] Univ Catania, Dept Math & Comp Sci, Catania, Italy.
   [Grauman, Kristen] Univ Texas Austin, Comp Sci Dept, Austin, TX 78712 USA.
C3 University of Catania; University of Texas System; University of Texas
   Austin
RP Furnari, A (corresponding author), Univ Catania, Dept Math & Comp Sci, Catania, Italy.
EM furnari@dmi.unict.it; battiato@dmi.unict.it; grauman@cs.utexas.edu;
   gfarinella@dmi.unict.it
RI Battiato, Sebastiano/O-7799-2019; Battiato, Sebastiano/ABI-1584-2020;
   Furnari, Antonino/J-2358-2019; FARINELLA, Giovanni Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; Furnari,
   Antonino/0000-0001-6911-0302; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432
FU NVIDIA Corporation; ONR PECASE [N00014-15-1-2291]
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan X Pascal GPU used for this research. This research
   is supported in part by ONR PECASE N00014-15-1-2291 (KG).
CR [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.214
   [Anonymous], 2016 IEEE Winter Conf. Appl. Comput. Vision, DOI [DOI 10.1109/WACV.2016.7477708, 10.1109/WACV.2016.7477708]
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Bertasius G., 1 PERSON ACTION OBJE
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   CIPOLLA R, 1992, LECT NOTES COMPUT SC, V588, P187
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   Furnari A, 2015, LECT NOTES COMPUT SC, V8927, P806, DOI 10.1007/978-3-319-16199-0_56
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Huang D, 2014, LECT NOTES COMPUT SC, V8691, P410, DOI 10.1007/978-3-319-10578-9_27
   Kitani K. M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3241, DOI 10.1109/CVPR.2011.5995406
   Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Land MF, 2006, PROG RETIN EYE RES, V25, P296, DOI 10.1016/j.preteyeres.2006.01.002
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625
   Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399
   Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209
   McCandless T., 2013, BRIT MACH VIS C, P301
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Nebehay G, 2015, PROC CVPR IEEE, P2784, DOI 10.1109/CVPR.2015.7298895
   Park HS, 2016, PROC CVPR IEEE, P4697, DOI 10.1109/CVPR.2016.508
   Peleg S., 2014, CVPR, P2537, DOI DOI 10.1109/CVPR.2014.325
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryoo MS, 2015, ACMIEEE INT CONF HUM, P295, DOI 10.1145/2696454.2696462
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh KrishnaKumar., 2016, IEEE Winter Conference on Applications of Computer Vision, P1
   Soran B, 2015, IEEE I CONF COMP VIS, P4669, DOI 10.1109/ICCV.2015.530
   Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354
   Su YC, 2016, LECT NOTES COMPUT SC, V9909, P454, DOI 10.1007/978-3-319-46454-1_28
   Su YC, 2016, LECT NOTES COMPUT SC, V9911, P783, DOI 10.1007/978-3-319-46478-7_48
   Tetnpleman R, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23014
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhou Y, 2016, PROC CVPR IEEE, P1904, DOI 10.1109/CVPR.2016.210
   Zhou YP, 2015, IEEE I CONF COMP VIS, P4498, DOI 10.1109/ICCV.2015.511
NR 49
TC 39
Z9 43
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 401
EP 411
DI 10.1016/j.jvcir.2017.10.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800034
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, WC
   Yin, ZZ
AF Jiang, Wenchao
   Yin, Zhaozheng
TI Combining passive visual cameras and active IMU sensors for persistent
   pedestrian tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Persistent pedestrian tracking; Visual object tracking; IMU tracking;
   Dead reckoning
ID PERSON TRACKING; OCCLUSION; MULTIPLE
AB Vision based pedestrian tracking becomes a hard problem when long-term/heavy occlusion happens or pedestrian temporarily moves out of the visual field. In this paper, a novel persistent pedestrian tracking system is presented which combines visual signal from surveillance cameras and sensor signals from Inertial Measurement Unit (IMU) carried by pedestrians themselves. IMU tracking performs Dead Reckoning (DR) approach utilizing accelerometer, gyroscope and magnetometer. IMU tracking has nothing to do with visual occlusion, so it keeps working even when pedestrians are visually occluded. Meanwhile, visual tracking assists in calibrating IMU to avoid the bias drift during DR. The experimental results show that the IMU and visual tracking are complementary to each other and their combination performs robust pedestrian tracking in many challenging scenarios. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Jiang, Wenchao; Yin, Zhaozheng] Missouri Univ Sci & Technol, Rolla, MO 65409 USA.
C3 University of Missouri System; Missouri University of Science &
   Technology
RP Yin, ZZ (corresponding author), Missouri Univ Sci & Technol, Rolla, MO 65409 USA.
EM yinz@mst.edu
RI jiang, wen/GYI-9662-2022
FU Intelligent Systems Center (ISC) at Missouri University of Science and
   Technology; National Science Foundation (NSF) [CMMI-1646162]; Office Of
   The Director; Office of Integrative Activities [1355406] Funding Source:
   National Science Foundation
FX This work was supported by Intelligent Systems Center (ISC) at Missouri
   University of Science and Technology, and the National Science
   Foundation (NSF) grant CMMI-1646162.
CR Alonso R.F., 2009, Journal of Physical Agents, V3, P35, DOI DOI 10.14198/JOPHA.2009.3.1.05
   Andriluka M., 2008, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)
   [Anonymous], 2016, COMPUTER VISION PATT
   [Anonymous], 2016, P INT C IND POS IND
   [Anonymous], WORLD ACAD SCI ENG T
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], COMPUTER VISION PATT
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Falcone P, 2012, IEEE RAD CONF
   Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140
   Gao K, 2012, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2012.6248059
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Hache G., 2010, IEEE International Workshop on Medical Measurements and Applications, P43
   Hardegger M, 2015, PERS UBIQUIT COMPUT, V19, P123, DOI 10.1007/s00779-014-0815-y
   Hung TN, 2013, SENSORS-BASEL, V13, P5614, DOI 10.3390/s130505614
   Jiang WC, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1338
   Jin YY, 2011, INT CONF PERVAS COMP, P222, DOI 10.1109/PERCOM.2011.5767590
   Kourogi M, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P103, DOI 10.1109/ISMAR.2003.1240693
   Leykin A., 2006, Computer Vision and Pattern Recognition Workshop, P136, DOI DOI 10.1109/CVPRW.2006.175
   Li Z, 2008, ELECTRON LETT, V44, P622, DOI 10.1049/el:20080064
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Madgwick Sebastian O H, 2011, IEEE Int Conf Rehabil Robot, V2011, P5975346, DOI 10.1109/ICORR.2011.5975346
   Mao YX, 2015, IEEE WINT CONF APPL, P170, DOI 10.1109/WACV.2015.30
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2014, NEUROCOMPUTING, V139, P220, DOI 10.1016/j.neucom.2014.02.040
   Reddy S, 2010, ACM T SENSOR NETWORK, V6, DOI 10.1145/1689239.1689243
   Roy A, 2015, IET COMPUT VIS, V9, P821, DOI 10.1049/iet-cvi.2014.0170
   Sherrah J., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P314, DOI 10.1109/DICTA.2010.61
   Steinhoff Ulrich, 2010, 2010 IEEE International Conference on Pervasive Computing and Communications (PerCom 2010), P162, DOI 10.1109/PERCOM.2010.5466978
   Wang H, 2007, WORKS POSIT NAVIGAT, P1
   Woo S, 2011, AUTOMAT CONSTR, V20, P3, DOI 10.1016/j.autcon.2010.07.009
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Yang J, 2010, ADV PATTERN RECOGNIT, P185, DOI 10.1007/978-1-84996-507-1_8
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhou BD, 2015, IEEE T HUM-MACH SYST, V45, P562, DOI 10.1109/THMS.2014.2368092
NR 40
TC 17
Z9 19
U1 5
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 419
EP 431
DI 10.1016/j.jvcir.2017.03.015
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700036
OA Bronze
DA 2024-07-18
ER

PT J
AU Huang, RB
   Liu, C
   Zhou, JL
AF Huang, Rongbing
   Liu, Chang
   Zhou, Jiliu
TI Discriminant analysis via jointly <i>L</i><sub>2,1</sub>-norm sparse
   tensor preserving embedding for image classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Tensor; Discriminant analysis; Local preserving
   embedding
ID FACE-RECOGNITION; DIMENSIONALITY; REPRESENTATION; FRAMEWORK
AB There exits an increasing interest on sparse subspace learning (SSL) for dimensionality reduction and pattern recognition. In this paper, we propose a novel sparse subspace learning method named discriminant sparse tensor neighborhood preserving embedding (DSTNPE) which incorporates discriminant information into tensor sparse neighborhood preserving embedding to perform robust image classification. DSTNPE introduces the L-2,L-1-norm to sparse neighborhoods and criterion, in which the within neighborhood tensor scatter and between-neighborhood tensor scatter are defined for sparse regression. One virtue of DSTNPE is that it can avoid selecting the scale of local neighborhood of the manifold learning algorithms. Additionally, DSTNPE can iteratively obtain the transformation matrices by the sparse tensor neighborhoods preservation. Furthermore, by means of virtue of maximum margin criterion (MMC), the discriminant performance of DSTNPE is further enhanced. To evaluate the proposed method, extensive experiments conducted on five public databases demonstrate that our proposed algorithm outperforms many state-of-the-art algorithms. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Huang, Rongbing; Liu, Chang] Chengdu Univ, Inst Higher Educ Sichuan Prov, Key Lab Pattern Recognit & Intelligent Informat P, Chengdu 610104, Peoples R China.
   [Huang, Rongbing] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Zhou, Jiliu] Sichuan Univ, Sch Comp & Software, Chengdu 610065, Peoples R China.
C3 Chengdu University; Sichuan University; Sichuan University
RP Huang, RB (corresponding author), Chengdu Univ, Coll Informat Sci & Engn, Chengdu 610106, Peoples R China.
EM huangrb2006@126.com
RI zhang, weijie/JQX-1450-2023; huang, rongbing/ABF-4341-2021; WANG,
   JIAXUAN/JMP-8599-2023
OI Huang, Rongbing/0000-0002-3962-2881
FU National Natural Science Foundation of China [61502059]; Natural Science
   Foundation from Sichuan Provincial Department of Education [17ZB0106]
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant No. 61502059), Natural Science Foundation
   from Sichuan Provincial Department of Education (Grant No. 17ZB0106).
CR [Anonymous], 2012, POLYU PALMPR DAT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Benavente R, 1998, 24 COMP VIS CTR
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Comon P, 2014, IEEE SIGNAL PROC MAG, V31, P44, DOI 10.1109/MSP.2014.2298533
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   Gao QX, 2015, IEEE T IMAGE PROCESS, V24, P5684, DOI 10.1109/TIP.2015.2479559
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   He X., 2005, Advances in neural information processing systems, P499
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Hu Z., 2016, J VIS COMMUN IMAGE R, P735
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kong H, 2016, NEUROCOMPUTING, V177, P198, DOI 10.1016/j.neucom.2015.11.033
   Kotsia I., 2012, HIGHER RANK SUPPORT
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li Q, 2014, IEEE T PATTERN ANAL, V36, P2524, DOI 10.1109/TPAMI.2014.2342214
   Lu GF, 2012, KNOWL-BASED SYST, V31, P119, DOI 10.1016/j.knosys.2012.02.014
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P993
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tareq MO, 2009, OPT ENG, V48, DOI 10.1117/1.3158945
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Vasilescu MAO, 2003, PROC CVPR IEEE, P93
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wong WK, 2015, IEEE T CYBERNETICS, V45, P2425, DOI 10.1109/TCYB.2014.2374452
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang SM, 2009, IEEE T KNOWL DATA EN, V21, P1285, DOI 10.1109/TKDE.2008.204
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2005, PATTERN RECOGN, V38, P1125, DOI 10.1016/j.patcog.2004.11.019
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Zang F, 2011, NEUROCOMPUTING, V74, P2176, DOI 10.1016/j.neucom.2011.02.012
   Zhang HJ, 2012, PATTERN RECOGN, V45, P1866, DOI 10.1016/j.patcog.2011.11.002
   Zhang JG, 2016, J VIS COMMUN IMAGE R, V41, P260, DOI 10.1016/j.jvcir.2016.10.006
   Zhao HT, 2014, NEUROCOMPUTING, V133, P427, DOI 10.1016/j.neucom.2013.12.019
NR 51
TC 5
Z9 6
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2017
VL 47
BP 10
EP 22
DI 10.1016/j.jvcir.2017.05.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX8TD
UT WOS:000403522200002
DA 2024-07-18
ER

PT J
AU Asghar, MN
   Kousar, R
   Majid, H
   Fleury, M
AF Asghar, Mamoona N.
   Kousar, Rukhsana
   Majid, Hooriya
   Fleury, Martin
TI Transparent encryption with scalable video communication: Lower-latency,
   CABAC-based schemes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE B-frames; Scalable video streaming; Reduced encryption; Selective
   encryption; Transparent encryption
ID FORMAT-COMPLIANT ENCRYPTION; SELECTIVE ENCRYPTION; CODING EXTENSION;
   H.264/AVC; IMAGE
AB Selective encryption masks all of the content without completely hiding it, as full encryption would do at a cost in encryption delay and increased bandwidth. Many commercial applications of video encryption do not even require selective encryption, because greater utility can be gained from transparent encryption, i.e. allowing prospective viewers to glimpse a reduced quality version of the content as a taster. Our lightweight selective encryption scheme when applied to scalable video coding is well suited to transparent encryption. The paper illustrates the gains in reducing delay and increased distortion arising from a transparent encryption that leaves reduced quality base layer in the clear. Reduced encryption of B frames is a further step beyond transparent encryption in which the computational overhead reduction is traded against content security and limited distortion. This spectrum of video encryption possibilities is analyzed in this paper, though all of the schemes maintain decoder compatibility and add no bitrate overhead as a result of jointly encoding and encrypting the input video by virtue of carefully selecting the entropy coding parameters that are encrypted. The schemes are suitable both for H.264 and HEVC codecs, though demonstrated in the paper for H.264. Selected Content Adaptive Binary Arithmetic Coding (CABAC) parameters are encrypted by a lightweight Exclusive OR technique, which is chosen for practicality. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Asghar, Mamoona N.; Kousar, Rukhsana; Majid, Hooriya] Islamia Univ Bahawalpur, Dept Comp Sci & Informat Technol, Bahawalpur, Pakistan.
   [Fleury, Martin] Univ Essex, Colchester, Essex, England.
C3 Islamia University of Bahawalpur; University of Essex
RP Fleury, M (corresponding author), Univ Essex, Colchester, Essex, England.
EM fleum@essex.ac.uk
OI Asghar, Mamoona/0000-0001-7460-266X
CR Abombara M., 2010, INT J COMPUT THEORY, V2, P282
   Algin GB, 2011, J VIS COMMUN IMAGE R, V22, P353, DOI 10.1016/j.jvcir.2011.02.005
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   Arachchi HK, 2009, SIGNAL PROCESS-IMAGE, V24, P468, DOI 10.1016/j.image.2009.02.004
   Asghar M., 2011, 2011 8th International ISC Conference on Information Security and Cryptology, P83, DOI 10.1109/ISCISC.2011.6062331
   Asghar M. N., 2012, 2012 4th Computer Science and Electronic Engineering Conference (CEEC 2012). Proceedings, P139, DOI 10.1109/CEEC.2012.6375393
   Asghar M. N., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P443, DOI 10.1109/TrustCom.2012.268
   Asghar M.N., 2012, RECENT PAT TELECOMMU, V1, P41
   Asghar M, 2012, IEEE IMAGE PROC, P2645, DOI 10.1109/ICIP.2012.6467442
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   Asghar MN, 2013, IEEE T CIRC SYST VID, V23, P425, DOI 10.1109/TCSVT.2012.2204941
   Chen TC, 2006, IEEE T CIRCUITS-II, V53, P832, DOI 10.1109/TCSII.2006.880014
   Civanlar R., 2009, U.S. Patent, Patent No. [7 593 032, 7593032]
   Deng RH, 2014, MULTIMEDIA SYST, V20, P165, DOI 10.1007/s00530-013-0326-0
   Furht B, 2005, INTERNET COMMUN SER, P95
   Helle P, 2013, IEEE DATA COMPR CONF, P201, DOI 10.1109/DCC.2013.28
   Hellwagner H, 2009, SIGNAL PROCESS-IMAGE, V24, P740, DOI 10.1016/j.image.2009.07.002
   Hofbauer H, 2014, INT CONF ACOUST SPEE
   Hong D, 2012, IEEE INT SYMP CIRC S, P890, DOI 10.1109/ISCAS.2012.6272185
   Kelsey John., 1999, 6 ANN WORKSHOP SELEC, P13, DOI [10.1007/3-540-46513-82, DOI 10.1007/3-540-46513-82]
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Li S., 2007, IEEE T CIRCUITS SYST, V17, P1
   Lopez F., 2006, 4 INT WORKSH AD MULT, P149
   Lotspiech J, 2005, INTERNET COMMUN SER, P691
   Magli E, 2011, SIGNAL PROCESS, V91, P1103, DOI 10.1016/j.sigpro.2010.10.012
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Naor D., 2001, Advances in Cryptology - CRTPTO 2001. 21st Annual International Cryptology Conference, Proceedings (Lecture Notes in Computer Science Vol.2139), P41
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Park SW, 2009, IEICE T INF SYST, VE92D, P851, DOI 10.1587/transinf.E92.D.851
   Podesser M., 2002, 6 NORD SIGN PROC S
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Shahid Z, 2009, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2009.5413605
   Stütz T, 2008, IEEE INT SYM MULTIM, P446, DOI 10.1109/ISM.2008.52
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2004, P SOC PHOTO-OPT INS, V5558, P454, DOI 10.1117/12.564457
   Tew Y, 2015, ASIAPAC SIGN INFO PR, P963, DOI 10.1109/APSIPA.2015.7415415
   Thomas N, 2009, POLIT ASIA, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Z, 2012, SIGNAL PROCESS-IMAGE, V27, P1011, DOI 10.1016/j.image.2012.06.005
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 46
TC 17
Z9 18
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 122
EP 136
DI 10.1016/j.jvcir.2017.02.017
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhuang, PX
   Fu, XY
   Huang, Y
   Ding, XH
AF Zhuang, Peixian
   Fu, Xueyang
   Huang, Yue
   Ding, Xinghao
TI Image enhancement using divide-and-conquer strategy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image enhancement; Subspace decomposition; Gradient distribution
   specification; Weighted fusion
ID HISTOGRAM EQUALIZATION; LANDSCAPE PHOTOGRAPHS; PARALLEL FRAMEWORK;
   RETINEX; ILLUMINATION
AB Existing enhancement methods tend to overlook the difference between image components of low frequency and high-frequency. However, image low-frequency portions contain smooth areas occupied the majority of the image, while high-frequency components are sparser in the image. Meanwhile, the different importance of image low-frequency and high-frequency components cannot be precisely and effectively for image enhancement. Therefore, it is reasonable to deal with these components separately when designing enhancement algorithms with image subspaces. In this paper, we propose a novel divide and-conquer strategy to decompose the observed image into four subspaces and enhance the images corresponding to each subspace individually. We employ the existing technique of gradient distribution specification for these enhancements, which has displayed promising results for image naturalization. We then reconstruct the full image using the weighted fusion of these four subspace images. Experimental results demonstrate the effectiveness of the proposed strategy in both image naturalization and details promotion. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Zhuang, Peixian; Fu, Xueyang; Huang, Yue; Ding, Xinghao] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Peoples R China.
C3 Xiamen University
RP Ding, XH (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Peoples R China.
EM dxh@xmu.edu.cn
RI Fu, Xueyang/AAA-4940-2021; Huang, Yue/ABD-7847-2021
OI Fu, Xueyang/0000-0001-8036-4071; 
FU National Natural Science Foundation of China [61571382, 61571005,
   81301278, 61172179, 61103121]; Guangdong Natural Science Foundation
   [2015A030313007]; Fundamental Research Funds for the Central
   Universities [20720160075, 20720150169, 20720150093]; Research Fund for
   the Doctoral Program of Higher Education [20120121120043]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61571382, 61571005, 81301278, 61172179,
   and 61103121, in part by the Guangdong Natural Science Foundation under
   Grant 2015A030313007, in part by the Fundamental Research Funds for the
   Central Universities under Grant 20720160075, 20720150169 and
   20720150093, and in part by the Research Fund for the Doctoral Program
   of Higher Education under Grant 20120121120043.
CR Bertalmío M, 2009, INT J COMPUT VISION, V83, P101, DOI 10.1007/s11263-009-0221-5
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gong YH, 2016, IEEE J-STSP, V10, P99, DOI 10.1109/JSTSP.2015.2506122
   Gong YH, 2015, LECT NOTES COMPUT SC, V9009, P47, DOI 10.1007/978-3-319-16631-5_4
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jia Z, 2011, IEEE INT CONF ROBOT
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Joshi SH, 2009, I S BIOMED IMAGING, P161, DOI 10.1109/ISBI.2009.5193008
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Micheloni C, 2004, INT C PATT RECOG, P326, DOI 10.1109/ICPR.2004.1334533
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Sen D, 2011, IEEE T IMAGE PROCESS, V20, P1211, DOI 10.1109/TIP.2010.2083676
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Wang LQ, 2014, IEEE T IMAGE PROCESS, V23, P3381, DOI 10.1109/TIP.2014.2324813
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang XY, 2014, IEEE T MULTIMEDIA, V16, P653, DOI 10.1109/TMM.2014.2299511
   Zhang XY, 2011, IEEE IMAGE PROC, P1113, DOI 10.1109/ICIP.2011.6115622
   Zosso D, 2015, SIAM J IMAGING SCI, V8, P787, DOI 10.1137/140972664
NR 32
TC 7
Z9 8
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 137
EP 146
DI 10.1016/j.jvcir.2017.02.018
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100012
DA 2024-07-18
ER

PT J
AU Li, ZY
   Gao, S
   Nai, K
AF Li, Zhiyong
   Gao, Song
   Nai, Ke
TI Robust object tracking based on adaptive templates matching via the
   fusion of multiple features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Feature fusion; Double templates matching; Timed motion
   history image
ID VISUAL TRACKING; PARALLEL FRAMEWORK; ONLINE SELECTION; MOTION;
   RECOGNITION
AB Moving object tracking under complex scenes remains to be a challenging problem because the appearance of a target object can be drastically changed due to several factors, such as occlusions, illumination, pose, scale change and deformation. This study proposes an adaptive multi-feature fusion strategy, in which the target appearance is modeled based on timed motion history image with HSV color histogram features and edge orientation histogram features. The variances based on the similarities between the candidate patches and the target templates are used for adaptively adjusting the weight of each feature. Double templates matching, including online and offline template matching, is adopted to locate the target object in the next frame. Experimental evaluations on challenging sequences demonstrate the accuracy and robustness of the proposed algorithm in comparison with several state-of-the-art algorithms. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Li, Zhiyong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   Key Lab Embedded & Network Comp Hunan Prov, Changsha, Peoples R China.
C3 Hunan University
RP Li, ZY (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
EM zhiyong.li@hnu.edu.cn
RI li, zy/HZM-1892-2023
FU National Natural Science Foundation of China [61672215, 91320103];
   Special Project on the Integration of Industry, Education and Research
   of Guangdong Province, China [2012A090300003]; Science and Technology
   Planning Project of Guangdong Province, China [2013B090700003]
FX This work was partially supported by the National Natural Science
   Foundation of China (Nos. 61672215, 91320103), the Special Project on
   the Integration of Industry, Education and Research of Guangdong
   Province, China (No. 2012A090300003) and the Science and Technology
   Planning Project of Guangdong Province, China (No. 2013B090700003).
CR Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Cai Z., 2014, MULTIMED TOOLS APPL, P1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Davis J.W., 2007, P 7 IEEE WORKSH APPL, P34
   Dawei Liang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P369
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan H., 2015, MULTIMED TOOLS APPL, P1
   Fen Xu, 2012, 2012 10th World Congress on Intelligent Control and Automation (WCICA 2012), P4612, DOI 10.1109/WCICA.2012.6359353
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang Guan-Long, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166882
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li GR, 2012, J VIS COMMUN IMAGE R, V23, P254, DOI 10.1016/j.jvcir.2011.11.001
   Lin YP, 2011, MACH VISION APPL, V22, P505, DOI 10.1007/s00138-010-0264-1
   Mazzeo P. L., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P498, DOI 10.1109/AVSS.2011.6027383
   Nguyen THD, 2005, IEEE T VIS COMPUT GR, V11, P706, DOI 10.1109/TVCG.2005.105
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Scholkopft B., 1999, Neural networks for signal processing IX, V1, P1
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Wang J, 2006, ICAT 2006: 16TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE - WORSHOPS, PROCEEDINGS, P137
   Xiaofeng Lu, 2012, 2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012). Proceedings, P237, DOI 10.1109/ICIEA.2012.6360729
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang M, 2005, PROC CVPR IEEE, P1059
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin Z., 2006, P C COMP VIS PATT RE, P133, DOI DOI 10.1109/CVPRW.2006.131
   Zha Y, 2015, MULTIMED TOOLS APPL, P1
   Zhang KH, 2013, IEEE T CIRC SYST VID, V23, P1957, DOI 10.1109/TCSVT.2013.2269772
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zoidi O, 2013, IEEE T CIRC SYST VID, V23, P870, DOI 10.1109/TCSVT.2012.2226527
NR 46
TC 28
Z9 32
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 1
EP 20
DI 10.1016/j.jvcir.2017.01.012
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600001
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Watson, J
   Allen, A
AF Liu, Zonghua
   Watson, John
   Allen, Alastair
TI A polygonal approximation of shape boundaries of marine plankton
   based-on genetic algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Polygonal approximation; Genetic algorithm; Marine
   plankton
ID DOMINANT POINTS
AB Polygonal approximation of a shape boundary can provide a minimalistic representation of the shape. It can also accelerate the processing speed of feature extraction. Our interest is in applying such a method to approximate the boundaries of plankton shapes. A polygonal approximation method based on genetic algorithms has been designed to compactly describe the plankton shapes by polygons. Firstly, two artificial digital curves are used to test the performance of our algorithm. Results are compared with other existing algorithms which show that our algorithm has efficient performance for solving the problem of the polygonal approximation. Secondly, the proposed method is applied to a selection of platrikton images under three different approximation levels to a polygonal fit and then five evaluation criteria are applied to determine which approximation level of a particular image is most suitable for describing the shape. The stability and robustness of three approximation levels are also tested. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Zonghua; Watson, John; Allen, Alastair] Univ Aberdeen, Sch Engn, Aberdeen AB24 3UE, Scotland.
C3 University of Aberdeen
RP Liu, ZH (corresponding author), Univ Aberdeen, Sch Engn, Aberdeen AB24 3UE, Scotland.
EM r01zl14@abdn.ac.uk; j.watson@abdn.ac.uk; a.allen@abdn.ac.uk
RI Allen, Alastair R/B-3605-2012; Wang, Guanhua/JXM-6373-2024
CR [Anonymous], 2002, The Design of Innovation: Lessons from and for Competent Genetic Algorithms
   Back T., 1997, Handbook of evolutionary computation, V1st
   Baker J.E., P INT C GEN ALG THEI, P101
   BEZDEK JC, 1985, IEEE T SYST MAN CYB, V15, P637, DOI 10.1109/TSMC.1985.6313440
   Burns NM, 2011, IMAGING SCI J, V59, P90, DOI 10.1179/174313111X12966579709313
   Burns NM, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.11.112212
   Chatterjee S, 1996, EUR J OPER RES, V93, P490, DOI 10.1016/0377-2217(95)00077-1
   Chen XD, 2010, COMPUT AIDED DESIGN, V42, P523, DOI 10.1016/j.cad.2010.01.008
   CHUNG PC, 1994, PATTERN RECOGN, V27, P1505, DOI 10.1016/0031-3203(94)90128-7
   Gen M., 1997, Genetic Algorithms and Engineering Design
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   GREFENSTETTE JJ, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P20
   Gribov A, 2004, LECT NOTES COMPUT SC, V3138, P504
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   LEU JG, 1988, PATTERN RECOGN LETT, V7, P231, DOI 10.1016/0167-8655(88)90107-9
   LONCARIC S, 1995, PATTERN RECOGN, V28, P571, DOI 10.1016/0031-3203(94)00121-2
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   Masood A, 2007, J VIS COMMUN IMAGE R, V18, P264, DOI 10.1016/j.jvcir.2006.12.002
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   Pal NR, 1998, INT J SYST SCI, V29, P207, DOI 10.1080/00207729808929513
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PHILLIPS TY, 1988, PATTERN RECOGN LETT, V7, P291, DOI 10.1016/0167-8655(88)90069-4
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D
   RAY BK, 1995, PATTERN RECOGN LETT, V16, P161, DOI 10.1016/0167-8655(94)00081-D
   RAY BK, 1993, PATTERN RECOGN, V26, P505, DOI 10.1016/0031-3203(93)90106-7
   ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   Sastry K., 2005, Genet. Algorithms, P97
   Shi YH, 1999, IEEE T FUZZY SYST, V7, P109, DOI 10.1109/91.755393
   Sun H, 2008, PHILOS T R SOC A, V366, P1789, DOI 10.1098/rsta.2007.2187
   Sun HY, 2007, IEEE J OCEANIC ENG, V32, P373, DOI 10.1109/JOE.2007.891891
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   Yang HP, 2004, COMPUT AIDED DESIGN, V36, P639, DOI 10.1016/S0010-4485(03)00140-4
   Yin PY, 1998, PATTERN RECOGN LETT, V19, P1017, DOI 10.1016/S0167-8655(98)00082-8
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 38
TC 5
Z9 5
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 305
EP 313
DI 10.1016/j.jvcir.2016.10.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000027
DA 2024-07-18
ER

PT J
AU Wang, Y
   Zheng, J
   Xu, QZ
   Li, B
   Hu, HM
AF Wang, Yue
   Zheng, Jin
   Xu, Qi-Zhi
   Li, Bo
   Hu, Hai-Miao
TI An improved RANSAC based on the scale variation homogeneity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scale variation homogeneity; Scale ratio; RANSAC; SIFT matches
ID IMAGE PAIRS; REGISTRATION; CONSENSUS
AB For random sample consensus (RANSAC) method, high levels of contamination may slow down its convergence and impede the acquisition of the optimal model. In this paper, an improved RANSAC algorithm based on SIFT matches is proposed, which could provide robust performance in high levels of contamination and with low computational complexity. The improved RANSAC algorithm is particularly tailored to planar homography, by appropriately exploring feature scales. Firstly, a new feature scale constraint, i.e., the scale variation homogeneity (SVH), is proposed by exploiting the fact that the feature scale ratio of a correct match is approximate to the actual scale variation of two matched images. As a result, the potential correct and false matches can be effectively determined by SVH. Secondly, each model is scored by the number of partial identified false matches instead of all correct matches, which will speed up the evaluation process. Finally, fast converge can be obtained by adaptive selection of the test set for determining termination criterion according to the levels of contamination. Experimental results have demonstrated that the proposed SVH-RANSAC algorithm can perform very well even in the scenario of 90% contamination level. The number of iterations could be decreased by at least 35% and computational complexity for the evaluation procedure could be decreased by at least 2.5% compared with the LOPRANSAC. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Yue; Zheng, Jin; Xu, Qi-Zhi; Li, Bo; Hu, Hai-Miao] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Wang, Yue] Shenyang Aerosp Univ, Sch Comp, Shenyang 110136, Liaoning, Peoples R China.
   [Zheng, Jin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Shenyang Aerospace University; Beihang University
RP Zheng, J (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM JinZheng@buaa.edu.cn
RI Li, bo/IWL-9318-2023; Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888
FU National 863 Program [2014AA015104]; National Science Foundation of
   China [61370124]; National Science Fund for Distinguished Young Scholars
   [61125206]
FX The authors appreciate Mr. K. Lebeda for providing the code of the
   LO<SUP>+</SUP>-RANSAC. This work was partially supported by the National
   863 Program (Project No. 2014AA015104), the National Science Foundation
   of China (No. 61370124) and the National Science Fund for Distinguished
   Young Scholars (No. 61125206).
CR [Anonymous], 2011, P 2 ANN ACM C MULTIM
   Bastanlar Y, 2010, ELECTRON LETT, V46, P346, DOI 10.1049/el.2010.2548
   Botterill T., 2009, P BRIT MACH VIS C
   Capel D., 2005, Proc. BMVC, P629
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   HESS R., 2010, P INT C MULTIMEDIA, P1493, DOI DOI 10.1145/1873951.1874256
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Lebeda K., 2012, CTUCMP201217
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Li QL, 2009, IEEE GEOSCI REMOTE S, V6, P287, DOI 10.1109/LGRS.2008.2011751
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Litman R, 2015, PROC CVPR IEEE, P5243, DOI 10.1109/CVPR.2015.7299161
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Magri L, 2014, PROC CVPR IEEE, P3954, DOI 10.1109/CVPR.2014.505
   Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009
   Meier A., 2010, P BRIT MACH VIS C
   Ni K, 2009, IEEE I CONF COMP VIS, P2193, DOI 10.1109/ICCV.2009.5459241
   Vural MF, 2009, INT GEOSCI REMOTE SE, P1545, DOI 10.1109/IGARSS.2009.5417801
   Wang HZ, 2013, IEEE IMAGE PROC, P305, DOI 10.1109/ICIP.2013.6738063
   Xu QZ, 2014, REMOTE SENS LETT, V5, P451, DOI 10.1080/2150704X.2014.917774
   Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]
   Yi Z, 2008, ELECTRON LETT, V44, P107, DOI 10.1049/el:20082477
NR 26
TC 14
Z9 15
U1 3
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 751
EP 764
DI 10.1016/j.jvcir.2016.08.019
PN B
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600029
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Han, Y
   Hao, DS
   Lv, ZH
AF Zhang, Xiaolei
   Han, Yong
   Hao, DongSheng
   Lv, Zhihan
TI ARGIS-based outdoor underground pipeline information system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Augmented reality; Pipeline; ARGIS; Computer vision; Sensor
ID AUGMENTED REALITY; TRACKING
AB Outdoor augmented reality geographic information system (ARGIS) is a hot topic of augmented reality application over recent years. This paper tackles the key issues of ARGIS, designs the mobile augmented reality based underground pipeline information system, and respectively realizes the computer vision based version (CV-version) and the sensor based version (Sensor-version). The CV-version system employs the neural network based 3D features matching method. After comparison and evaluation of the two versions as well as interviewing the domain exports' opinions on the proposed system and the traditional PC-version virtual reality pipeline information system, it indicates that the CV-version is better in virtual-reality fusion and interactive experience and that Sensor-version is better in environmental robustness; PC-version virtual reality pipeline information system is more macroscopic in demonstration communication and this system is more assistant in the site survey of urban underground pipelines. To sum up, taking the underground pipeline information system as an example, this paper studies the characteristics of two different techniques of computer vision and sensor fusion in ARGIS, and makes a detailed comparison of these two techniques from two aspects of performance parameters and user experience. Some guiding conclusions are drawn, which provides a new way for the research of the application system in the field of outdoor geographic information system. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Xiaolei; Han, Yong; Hao, DongSheng] Ocean Univ China, Coll Informat Sci & Engn, Engn Res Ctr Marine Informat Technol, Qingdao, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Shenzhen, Peoples R China.
C3 Ocean University of China; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS
RP Han, Y (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Engn Res Ctr Marine Informat Technol, Qingdao, Peoples R China.
EM 181949337@qq.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022; zhang,
   xiaolei/P-1428-2018
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074; 
FU Innovation Fund for Technology Based Firms, China [14c26211100180];
   Qingdao Science and Technology project of China [14-9-2-12-pt]
FX This research is supported by Innovation Fund for Technology Based
   Firms, China (No: 14c26211100180) and Qingdao Science and Technology
   project of China (No: 14-9-2-12-pt).
CR Anke P., 1999, BUILDING HYBRID TRAC
   [Anonymous], 2015, COMPLEX EVENT DETECT
   [Anonymous], 2007, 6 IEEE ACM INT S MIX
   [Anonymous], P IEEE INT C COMP VI
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BEHZADAN AH, 2009, P 2009 CONSTR RES C
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Caggianese G, 2014, LECT NOTES COMPUT SC, V8853, P267, DOI 10.1007/978-3-319-13969-2_20
   Castle R. O., 2008, 12 IEEE INT S WEAR C
   Caudell T. P., 1992, HAW INT C SYST SCI
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang Xiaojun, 2016, DYNAMIC CONCEPT COMP
   Chekhlov D., 2007, IEEE CONFERENCE ON C
   CHEN LN, 1995, NEURAL NETWORKS, V8, P915, DOI 10.1016/0893-6080(95)00033-V
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Eishita F.Z., 2010, P INT AC C FUT GAM D
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Fernandes B.C.A., 2010, DIGIT ED REV, P66
   Fortin P.-A., 2006, 3 CAN C COMP ROB VIS
   GENC Y, 2002, P INT S MIX AUGM REA
   Gethin W.R., 2002, USE AUGMENTED REALIT
   Guo Y., 2008, ISPRS C
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Heidemann G., 2004, P 6 INT C MULT INT
   Hong R., 2010, ACM INT C IM VID RET
   HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141
   Irschara A., 2009, IEEE C COMP VIS PATT
   Ismail AW, 2015, ADV INTELL SYST, V331, P245, DOI 10.1007/978-3-319-13153-5_24
   King G. R., 2005, P IEEE ACM INT S MIX
   Klein G., 2009, 8 IEEE INT S MIX AUG
   Langlotz T, 2013, COMMUN ACM, V56, P34, DOI 10.1145/2527190
   Langlotz T, 2011, COMPUT GRAPH-UK, V35, P831, DOI 10.1016/j.cag.2011.04.004
   Li X., 2010, 2010 2 IEEE INT C IN
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu Z, 2013, IEEE IJCNN
   Lv Z., 2013, WEBVRGIS P2P NETWORK, P503
   Lv Z., 2015, BIG CITY 3D VISUAL A
   Lv Z., 2014, SIGGRAPH ASIA 2014 M
   Lv Z., 2015, 2015 IEEE VIRTUAL RE
   Macisaac D., 2015, The Physics Teacher, V53, P125
   Mavor A.S., 1994, VIRTUAL REALITY SCI
   Milette G., 2012, Professional Android Sensop Programming, V1st
   Nie L., 2011, P INT ACM SIGIR C RE
   Nie L., 2012, P 20 ACM INT C MULT
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Pupilli M., 2005, BMVC
   Ruiz-Ruiz A. J., 2012, INT C  INDOOR POSIT
   Schall G., 2010, 2010 9 IEEE INT S MI
   Schall G, 2013, PERS UBIQUIT COMPUT, V17, P1533, DOI 10.1007/s00779-012-0599-x
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Sun M., 2007, WORKSH FRONT COMP SC
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   WAGNER D, 2009, IEEE INT S MIX AUGM
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Yan Y, 2015, MULTITASK LEARNING F
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   You SY, 1999, IEEE COMPUT GRAPH, V19, P36, DOI 10.1109/38.799738
   Yousefi S., 2011, COMPUTER ANAL IMAGES
   Zlatanova S., 2010, AUGMENTED REALITY TE
NR 62
TC 29
Z9 33
U1 3
U2 48
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 779
EP 790
DI 10.1016/j.jvcir.2016.07.011
PN B
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600032
DA 2024-07-18
ER

PT J
AU Han, NN
   Song, ZJ
   Li, Y
AF Han, Ningning
   Song, Zhanjie
   Li, Ying
TI Cluster-based image super-resolution via jointly low-rank and sparse
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image super-resolution; Low-rank representation; Sparse representation;
   Subspace; Cluster
ID RESOLUTION
AB In this paper, we propose a novel algorithm for single image super-resolution by developing a concept of cluster rather than using patch as the basic unit. For the proposed algorithm, all patches are splitted into numerous subspaces, and the optimal representation problem is solved with jointly low-rank and sparse regularization for each subspace. By enforcing global consistency constraint of each subspace with nuclear norm regularization and capturing local linear structure of each patch with l(1)-norm regularization, effective matching functions for test and exemplar patches can be created. Accordingly, the desirable results with low computational complexity are obtained. Experimental results show that the proposed algorithm generates high-quality images in comparison with other state-of-the-art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Han, Ningning; Song, Zhanjie] Tianjin Univ, Sch Sci, Tianjin 300072, Peoples R China.
   [Li, Ying] Tianjin Univ, State Key Lab Hydraul Engn Simulat & Safety, Tianjin 300072, Peoples R China.
C3 Tianjin University; Tianjin University
RP Li, Y (corresponding author), Tianjin Univ, State Key Lab Hydraul Engn Simulat & Safety, Tianjin 300072, Peoples R China.
EM ning_ninghan@tju.edu.cn; zhanjiesong@tju.edu.cn; yingli2011@tju.edu.cn
FU National Natural Science Foundation of China [61379014]; Tianjin
   Research Program of Application Foundation and Advanced Technology
   [15JCYBJC21700]; National Basic Key Research Program of China (973
   Program) [2014CB046804]
FX The work was partially supported by the National Natural Science
   Foundation of China (No. 61379014), the Tianjin Research Program of
   Application Foundation and Advanced Technology (15JCYBJC21700) and the
   National Basic Key Research Program of China (973 Program, No.
   2014CB046804).
CR [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], ARXIV10095055
   [Anonymous], COMPUTER VISION ACCV
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen XX, 2014, IEEE SIGNAL PROC LET, V21, P79, DOI 10.1109/LSP.2013.2286417
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Fernandez-Granda C, 2013, IEEE I CONF COMP VIS, P3336, DOI 10.1109/ICCV.2013.414
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   He H, 2011, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2011.5995713
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jiji CV, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/73767
   Jiji C, 2006, LECT NOTES COMPUT SC, V3954, P255
   Jiji CV, 2004, INT J IMAG SYST TECH, V14, P105, DOI 10.1002/ima.20013
   Kim KI, 2008, LECT NOTES COMPUT SC, V5096, P456
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Su K, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1123
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2012, IEEE T IMAGE PROCESS, V21, P4054, DOI 10.1109/TIP.2012.2199330
   Zhang HC, 2010, LECT NOTES COMPUT SC, V6313, P566
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 42
TC 8
Z9 9
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 175
EP 185
DI 10.1016/j.jvcir.2016.02.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100015
DA 2024-07-18
ER

PT J
AU Srividhya, S
   Sathishkumar, R
   Sudha, GF
AF Srividhya, S.
   Sathishkumar, R.
   Sudha, Gnanou Florence
TI Implementation of TiOISSS with meaningful shadows and with an additional
   authentication image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Extended visual cryptography; Halftoning;
   Polynomial image secret sharing
ID SECRET SHARING SCHEME; VISUAL CRYPTOGRAPHY
AB Visual Cryptography Scheme (VCS) is a cryptographic technique for protecting secret images. The advantage of using VCS is that decoding can be done without use of any computations. Nevertheless, the reconstructed image has poor visual quality. Therefore, Two in One Image Secret Sharing Scheme (TiOISSS) was proposed which takes the advantage of VCS and provides good quality decoded images. However, the existing TiOISSS has security limitations as it is implemented only for noisy shadows. Hence, in this paper, modified TiOISSS is proposed and implemented for meaningful shadows. To enhance the security of the shares and prevent fake shares that may be introduced by hackers, an authentication image is shared along with the secret image. The quality of the reconstructed image is improved by using adaptive halftoning technique. Experimental results demonstrate the improved security and quality by the proposed scheme. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Srividhya, S.; Sudha, Gnanou Florence] Pondicherry Engn Coll, Dept Elect & Commun, Pondicherry, India.
   [Sathishkumar, R.] Perunthalaivar Kamarajar Inst Engn & Tech, Dept Elect & Commun, Pondicherry, India.
C3 Pondicherry Engineering College
RP Sathishkumar, R (corresponding author), Perunthalaivar Kamarajar Inst Engn & Tech, Dept Elect & Commun, Pondicherry, India.
EM srividhya2207@gmail.com; sathish.pkiet@gmail.com; gfsudha@pec.edu
RI SRIDHAR, SRIVIDHYA/AAH-6420-2020; Sudha, Gnanou Florence/GLU-3814-2022
OI Sudha, Gnanou Florence/0000-0002-5471-3255
CR Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Askari N., 2013, IEEE CAN C EL COMP E, P1
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Lee CC, 2014, J VISUAL LANG COMPUT, V25, P243, DOI 10.1016/j.jvlc.2013.11.001
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Liu Feng, 2014, T DATA HIDING MULTIM, V9, P1, DOI DOI 10.1371/J0URNAL.P0NE.0110272
   Lou DC, 2011, DISPLAYS, V32, P118, DOI 10.1016/j.displa.2011.02.001
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Sridhar Srividhya, 2015, J MULTIMED TOOLS APP, P1
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 18
TC 11
Z9 11
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 284
EP 296
DI 10.1016/j.jvcir.2016.03.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100024
DA 2024-07-18
ER

PT J
AU Cai, YZ
   Li, SZ
   Cheng, Y
   Ji, RR
AF Cai, Yuanzheng
   Li, Shaozi
   Cheng, Yun
   Ji, Rongrong
TI Local consistent hierarchical Hough Match for image re-ranking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Bag-of-words; Geometry rerank; Hierarchical; Hough
   Space; Large scale retrieval; Local consistence; Inverted index
ID PRODUCT QUANTIZATION
AB Geometric image re-ranking is a widely adopted phrase to refine the large-scale image retrieval systems built based upon popular paradigms such as Bag-of-Words (BoW) model. Its main idea can be treated as a sort of geometric verification targeting at reordering the initial returning list by previous similarity ranking metrics, e.g. Cosine distance over the BoW vectors between query image and reference ones. In the literature, to guarantee the re-ranking accuracy, most existing schemes requires the initial retrieval to be conducted by using a large vocabulary (codebook), corresponding to a high-dimensional BoW vector. However, in many emerging applications such as mobile visual search and massive-scale retrieval, the retrieval has to be conducted by using a compact BoW vector to accomplish the memory or time requirement. In these scenarios, the traditional re-ranking paradigms are questionable and new algorithms are urgently demanded. In this paper, we propose an accurate yet efficient image re-ranking algorithm specific for small vocabulary in aforementioned scenarios. Our idea is inspired by Hough Voting in the transformation space, where votes come from local feature matches. Most notably, this geometry re-ranking can easily been aggregated to the cutting-edge image based retrieval systems yielding superior performance with a small vocabulary and being able to store in mobile end facilitating mobile visual search systems. We further prove that its time complexity is linear in terms of the re-ranking instance, which is a significant advantage over the existing scheme. In terms of mean Average Precision, we show that its performance is comparable or in some cases better than the state-of-the-art re-ranking schemes. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Cai, Yuanzheng; Li, Shaozi; Ji, Rongrong] Xiamen Univ, Dept Cognit Sci, Xiamen, Peoples R China.
   [Cai, Yuanzheng; Li, Shaozi; Ji, Rongrong] Xiamen Univ, Brain Like Intelligent Syst, Xiamen, Peoples R China.
   [Cheng, Yun] Hunan Univ Humanities Sci & Technol, Loudi, Hunan, Peoples R China.
C3 Xiamen University; Xiamen University; Hunan University Of Humanities,
   Science & Technology
RP Li, SZ (corresponding author), Xiamen Univ, Dept Cognit Sci, Xiamen, Peoples R China.
EM szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU Nature Science Foundation of China [61202143, 61373076]; Collaborative
   Innovation Special Foundation of Xuchang University [XCUXT2014-08]
FX This work is supported by the Nature Science Foundation of China (No.
   61202143, No. 61373076), the Collaborative Innovation Special Foundation
   of Xuchang University (No. XCUXT2014-08).
CR [Anonymous], WEAKLY SUPERVISED MU
   [Anonymous], IJCAI P INT JOINT C
   [Anonymous], MINING COMPACT BAG O
   [Anonymous], 2008, P IEEE C COMP VIS PA
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Ji R., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P573
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950
   Ji RR, 2011, INT CONF ACOUST SPEE, P2316
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister David, 2006, CVPR
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Philbin J., 2008, CVPR 2008 IEEE C COM, P1
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tolias G, 2011, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2011.6126427
   Zhang LM, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P237, DOI 10.1145/2647868.2654903
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 32
TC 3
Z9 4
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 32
EP 39
DI 10.1016/j.jvcir.2015.06.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700005
DA 2024-07-18
ER

PT J
AU Okade, M
   Biswas, PK
AF Okade, Manish
   Biswas, Prabir Kumar
TI A novel moving object segmentation framework utilizing camera motion
   recognition for H.264 compressed videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Block motion vectors; Camera motion; Moving object segmentation; Wavelet
   subbands; Neural network classifier; Graph cut; Compressed domain;
   Back-propagation training
ID SPATIOTEMPORAL SEGMENTATION; ENERGY MINIMIZATION; IMAGE SEGMENTATION;
   TRACKING; SEQUENCES; FIELD
AB This paper presents a novel coarse to fine moving object segmentation framework for H.264/AVC compressed videos. The proposed framework integrates the global motion estimation and global motion compensation steps in the segmentation pipeline unlike previous techniques which did not consider such an integration. The integration is based on testing for presence of global motion by classifying the interframe motion vectors into moving camera class and still camera class. The decision boundary separating these two classes is learnt from the training video data. The integration automates the moving object segmentation to be applicable for static, moving and combination of static/moving camera cases which to the best of our knowledge has not been carried out earlier. Further, a novel coarse segmentation technique is proposed by decomposing the inter-frame motion vectors into wavelet sub-bands and utilizing logical operations on LH, HL and HH sub-band wavelet coefficients. The premise is based on the fact that since the LH, HL and HH sub-bands contain the detail information pertaining to horizontal, vertical and diagonal moving blocks respectively, they can be exploited to identify the coarse moving boundaries. The coarse segmentation is fast in comparison to state-of-the-art coarse segmentation methods as demonstrated by our experiments. Finally, these coarse boundaries are modeled in an energy minimization framework and shown that by minimizing the energy using graph cut optimization the segmentation is refined to obtain the fine segmentation. The proposed framework is tested on a number of standard video sequences encoded with H.264/AVC JM encoder and comparison is carried out with state-of-the-art compressed domain moving object segmentation methods as well as with an existing state-of-the-art pixel domain method to establish and validate the proposed moving object segmentation framework. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Okade, Manish] Natl Inst Technol, Dept Elect & Commun Engn, Rourkela 769008, India.
   [Biswas, Prabir Kumar] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Kharagpur
RP Okade, M (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Rourkela 769008, India.
EM okadem@nitrkl.ac.in; pkb@ece.iitkgp.ernet.in
RI Biswas, Prabir Kumar/AAY-5904-2021; Okade, Manish/AAT-1658-2020; Biswas,
   Prabir Kumar/AAV-4935-2021
CR [Anonymous], 2013, ICCV
   Arvanitidou MG, 2013, SIGNAL PROCESS-IMAGE, V28, P1420, DOI 10.1016/j.image.2013.09.008
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bagon S., 2006, MATLAB WRAPPER GRAPH
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Brouard O, 2008, IEEE IMAGE PROC, P1552, DOI 10.1109/ICIP.2008.4712064
   Chang MM, 1997, IEEE T IMAGE PROCESS, V6, P1326, DOI 10.1109/83.623196
   Chen YM, 2011, IEEE T CIRC SYST VID, V21, P1316, DOI 10.1109/TCSVT.2011.2148490
   Chen YM, 2011, IEEE T MULTIMEDIA, V13, P421, DOI 10.1109/TMM.2011.2127464
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   CLOUTIER L, 1994, IEEE IMAGE PROC, P805, DOI 10.1109/ICIP.1994.413682
   Dey B, 2013, IEEE T CIRC SYST VID, V23, P1695, DOI 10.1109/TCSVT.2013.2255416
   Fei W, 2010, IET IMAGE PROCESS, V4, P11, DOI 10.1049/iet-ipr.2009.0038
   Khatoonabadi SH, 2013, IEEE T IMAGE PROCESS, V22, P300, DOI 10.1109/TIP.2012.2214049
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kowdle A, 2012, LECT NOTES COMPUT SC, V7574, P272, DOI 10.1007/978-3-642-33712-3_20
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Liu Z, 2007, J VIS COMMUN IMAGE R, V18, P275, DOI 10.1016/j.jvcir.2007.02.002
   Okade M., 2015, IEEE T CIRC SYST VID
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Porikli F, 2004, P SOC PHOTO-OPT INS, V5297, P195, DOI 10.1117/12.527188
   Qi B, 2008, IEEE T IMAGE PROCESS, V17, P958, DOI 10.1109/TIP.2008.921985
   Qu W, 2007, IEEE T IMAGE PROCESS, V16, P2129, DOI 10.1109/TIP.2007.899619
   Ritch M., 2007, IEEE ICIP, V6
   Sabirin H, 2012, IEEE T MULTIMEDIA, V14, P657, DOI 10.1109/TMM.2012.2187777
   Shi XL, 2007, OPT ENG, V46, DOI 10.1117/1.2784773
   Su YB, 2005, IEEE T CIRC SYST VID, V15, P232, DOI 10.1109/TCSVT.2004.841656
   Yu Lu, 2008, 2008 11th IEEE International Conference on Communication Technology (ICCT 2008), P645, DOI 10.1109/ICCT.2008.4716180
   Yu XD, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P933
   Zhang KH, 2015, IEEE T CYBERNETICS, V45, P1426, DOI 10.1109/TCYB.2014.2352343
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
NR 32
TC 4
Z9 5
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 199
EP 212
DI 10.1016/j.jvcir.2016.01.016
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200017
DA 2024-07-18
ER

PT J
AU Lin, TL
   Yang, NC
   Syu, RH
   Liao, CC
   Tsai, WL
   Chou, CC
   Chen, SL
AF Lin, Ting-Lan
   Yang, Neng-Chieh
   Syu, Ray-Hong
   Liao, Chin-Chie
   Tsai, Wei-Lin
   Chou, Chi-Chan
   Chen, Shih-Lun
TI NR-Bitstream video quality metrics for SSIM using encoding decisions in
   AVC and HEVC coded videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SSIM (Structural SIMilarity index); HEVC (High efficiency video coding);
   AVC (Advanced video coding); H.264; No-reference video quality
   monitoring; Support vector regression (SVR) model; Video coding
   partition information; Video coding motion vector information
AB We propose a no-reference compressed video quality model to predict the full-reference SSIM metrics for AVC (Advanced Video Coding, H.264) and HEVC (High Efficiency Video Coding) videos. The model we use is support vector regression (SVR) model. We use only encoding decisions made during motion estimation to perform the prediction, and do not need the information from pixel domain. We show that the Block-Partition-related features have great importance in SSIM prediction, especially for HEVC videos, due to its partition decisions being more complex than those of AVC. The proposed SVR model trained by data of two different encoding configurations can predict SSIM well for AVC videos (0.78 correlation) and for HEVC videos (0.88 correlation). The proposed models are also compared with a state-of-the-art no-reference-bitstream-pixel SSIM prediction model. We show that the proposed methods provide higher prediction correlation (as high as 13.13% improvement in correlation) with much lower complexity. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lin, Ting-Lan; Yang, Neng-Chieh; Syu, Ray-Hong; Liao, Chin-Chie; Tsai, Wei-Lin; Chou, Chi-Chan; Chen, Shih-Lun] Chung Yuan Christian Univ, Dept Elect Engn, Zhongli City 320, Taoyuan County, Taiwan.
C3 Chung Yuan Christian University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
EM tinglan@cycu.edu.tw; g10079014@cycu.edu.tw; g10076022@cycu.edu.tw;
   g10279024@cycu.edu.tw; g10276038@cycu.edu.tw; g10276011@cycu.edu.tw;
   chrischen@cycu.edu.tw
RI Chen, Shih-Lun/AFF-8659-2022
FU National Science Council Taiwan [NSC 100-2218-E-033-004, NSC
   101-2221-E-033-036, NSC 102-2221-E-033-018]; Ministry of Science and
   Technology, Taiwan [MOST 103-2221-E-033-020, MOST 103-2221-E-033-070]
FX This research is supported by the National Science Council Taiwan under
   Grant NSC 100-2218-E-033-004, NSC 101-2221-E-033-036, NSC
   102-2221-E-033-018, and by the Ministry of Science and Technology,
   Taiwan under Grant MOST 103-2221-E-033-020 and MOST 103-2221-E-033-070.
CR [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 1 INT WORKSH VID PRO
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Corinna C., 1995, MACH LEARN, V20, P273, DOI [DOI 10.1007/BF00994018, 10.1007/BF00994018. S2CID 206787478]
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Girod Bernd, 1993, P207
   Lee B, 2013, IEEE T BROADCAST, V59, P20, DOI 10.1109/TBC.2012.2226533
   Li B., 2012, COMP COMPRESSION PER
   Lin TL, 2010, IEEE T IMAGE PROCESS, V19, P722, DOI 10.1109/TIP.2009.2038834
   Loke MH, 2006, IEEE IMAGE PROC, P457, DOI 10.1109/ICIP.2006.312492
   McCann K., 2012, HIGH EFFICIENCY VIDE
   Ohm J.-R., 2012, IEEE T CIRCUITS SYST, V99
   Richardson I. E. G., H 264 MPEG 4 10
   Shanableh T, 2011, IEEE SIGNAL PROC LET, V18, P335, DOI 10.1109/LSP.2011.2130524
   Staelens N, 2012, IEEE T BROADCAST, V58, P187, DOI 10.1109/TBC.2012.2189334
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
NR 22
TC 4
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 257
EP 271
DI 10.1016/j.jvcir.2015.03.008
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300022
DA 2024-07-18
ER

PT J
AU Liu, YW
   Liu, JX
   Song, JP
   Argyriou, A
AF Liu, Yanwei
   Liu, Jinxia
   Song, Junping
   Argyriou, Antonios
TI Scalable 3D video streaming over P2P networks with playback length
   changeable chunk segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable 3D video; P2P; 3D video chunk segmentation; 3D video streaming;
   Chunk scheduling; Playback length; Mobile networks; Error resilience
ID MULTIVIEW VIDEO; EFFICIENCY
AB 3D video distribution over P2P networks has been thought as a promising way for 3D video entering home. The convergence of scalable 3D video coding and P2P streaming can provide diverse 3D experiences for heterogeneous clients with high distribution efficiencies. However, the conventional chunk segmentation and scheduling algorithms originally aiming at the non-scalable 2D video streaming are not very efficient for scalable 3D video streaming over P2P networks due to the particular data characteristics of scalable 3D video. Based on this motivation, this paper first presents a playback length changeable 3D video chunk segmentation (PLC3DCS) algorithm to provide different error resilience strengths to video and depth as well as layers with different importance levels in the 3D video transmission. Then, a hybrid-priority based chunk scheduling (HPS) algorithm is proposed to be tied in with the proposed chunk segmentation algorithm to further promote the overall 3D video P2P streaming performance. The simulation results show that the proposed PLC3DCS algorithm with the corresponding HPS can increase the success delivery rates of chunks with more important levels, and further improve the user's quality of 3D experience. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liu, Yanwei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Zhejiang, Peoples R China.
   [Song, Junping] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Argyriou, Antonios] Univ Thessaly, Volos, Greece.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Zhejiang Wanli University; Chinese Academy of Sciences; Institute of
   Software, CAS; University of Thessaly
RP Liu, JX (corresponding author), Zhejiang Wanli Univ, Ningbo, Zhejiang, Peoples R China.
EM liuyanwei@iie.ac.cn; liujinxia1969@126.com
RI Liu, Jinxia/H-1794-2011; Argyriou, Antonios/AAF-9586-2021; liu,
   yanwei/L-2453-2019
OI Argyriou, Antonios/0000-0002-2510-3124; 
FU National Natural Science Foundation of China [61102077, 61472388];
   Zhejiang Provincial Natural Science Foundation of China [LY13F010012];
   Public welfare project of Zhejiang Province [201401072]; Strategic Pilot
   Project of Chinese Academy of Sciences [XDA06010306]
FX This work was supported in part by National Natural Science Foundation
   of China under Grants 61102077 and 61472388, Zhejiang Provincial Natural
   Science Foundation of China under Grant LY13F010012, Public welfare
   project of Zhejiang Province under Grant 201401072, and the Strategic
   Pilot Project of Chinese Academy of Sciences under Grant XDA06010306.
CR [Anonymous], P IEEE INT WORKSH MU
   [Anonymous], 2013, Petroleum and Chemical Industry Technical Conference (PCIC), 2013 Record of Conference Papers Industry Applications Society 60th Annual IEEE
   [Anonymous], 2011, P 3DTV C TRUE VIS CA
   [Anonymous], BT50010 ITUT
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], UCMEDIA
   [Anonymous], P INT WORKSH PEER TO
   [Anonymous], P SPIE STER DISPL AP
   [Anonymous], P ACM MULT SYST C
   Bari F, 2007, IEEE NETWORK, V21, P34, DOI 10.1109/MNET.2007.314536
   Ding Y, 2012, SIGNAL PROCESS-IMAGE, V27, P470, DOI 10.1016/j.image.2012.02.009
   Ding Y, 2010, COMPUT COMMUN, V33, P1589, DOI 10.1016/j.comcom.2010.04.025
   Furini M, 2007, IEEE ICC, P1679, DOI 10.1109/ICC.2007.281
   Gürler CG, 2013, IEEE COMMUN MAG, V51, P108, DOI 10.1109/MCOM.2013.6515054
   Gurler CG, 2012, IEEE IMAGE PROC, P2253, DOI 10.1109/ICIP.2012.6467344
   Hu H, 2011, IEEE T CIRC SYST VID, V21, P1013, DOI 10.1109/TCSVT.2011.2129290
   Lee TC, 2008, LECT NOTES COMPUT SC, V5274, P104, DOI 10.1007/978-3-540-87359-4_10
   Li Z, 2008, INT C WAVEL ANAL PAT, P1, DOI 10.1109/ICWAPR.2008.4635740
   Liu Y., 2013, PROC VISUAL COMMUNIC, P1
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Liu ZY, 2009, IEEE T MULTIMEDIA, V11, P1340, DOI 10.1109/TMM.2009.2030656
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Ozbek N, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P213, DOI 10.1109/ICME.2006.262420
   Savas SS, 2012, SIGNAL PROCESS-IMAGE, V27, P522, DOI 10.1016/j.image.2012.02.013
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shirmohammadi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348820
   Song JP, 2012, IEEE ICC, P2032, DOI 10.1109/ICC.2012.6364579
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Yang Z., 2006, P 2006 INT WORKSHOP, p14:1
NR 30
TC 5
Z9 5
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 41
EP 53
DI 10.1016/j.jvcir.2015.05.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600004
DA 2024-07-18
ER

PT J
AU Pandey, S
   Khanna, P
   Yokota, H
AF Pandey, Shreelekha
   Khanna, Pritee
   Yokota, Haruo
TI An effective use of adaptive combination of visual features to retrieve
   image semantics from a hierarchical image database
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image semantics; Semantic similarity; Visual similarity; Hierarchical
   image database; Semantic based categorization; Visual features; Visual
   search space; Search space pruning
ID ANNOTATION
AB Correlating semantic and visual similarity of an image is a challenging task. Unlimited possibilities of objects classification in real world are challenges for learning based techniques. Semantics based categorization of images gives a semantically categorized hierarchical image database. This work utilizes the strength of such database and proposes a system for automatic semantics assignment to images using an adaptive combination of multiple visual features. 'Branch Selection Algorithm' selects only a few subtrees to search from this image database. Pruning Algorithms further reduce this search space. Correlation of semantic and visual similarities is also explored to understand overlapping of semantics in visual space. The efficacy of the proposed algorithms analyzed on hierarchical and non-hierarchical databases shows that the system is capable of assigning accurate general and specific semantics to images automatically. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Pandey, Shreelekha; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg Ja, Jabalpur 482005, MP, India.
   [Yokota, Haruo] Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Meguro Ku, Tokyo 1528552, Japan.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Tokyo Institute of Technology
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg Ja, Dumna Aizport Rd, Jabalpur 482005, MP, India.
EM shreelekha@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in; yokota@cs.titech.ac.jp
RI Khanna, Pritee/V-5418-2019; Yokota, Haruo/N-6975-2014
OI Khanna, Pritee/0000-0003-0518-2133; Yokota, Haruo/0000-0001-9788-0443
FU JSPS
FX This work is done during the JSPS Invitation Fellowship for Research in
   Japan (Long-Term) from May 2011 to January 2012. The authors acknowledge
   the support provided by JSPS Fellowship.
CR [Anonymous], 2014, GOOGLE IMAGE SEARCH
   [Anonymous], NIST SEMATECH E HDB
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Gali R., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P243, DOI 10.1109/CICSyN.2012.52
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Hui H.W., 2010, INT J IMAGE PROCESS, V4, P192
   Khanna Pritee, 2013, Database and Expert Systems Applications. 24th International Conference, DEXA 2013. Proceedings: LNCS 8055, P103, DOI 10.1007/978-3-642-40285-2_11
   Kim JR, 2007, IEEE T CIRC SYST VID, V17, P635, DOI 10.1109/TCSVT.2007.894040
   Kinnaree P, 2011, PROCEDIA ENGINEER, V8, P36, DOI 10.1016/j.proeng.2011.03.007
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malik F., 2012, 2012 International Conference on Innovation Management and Technology Research, P624, DOI 10.1109/ICIMTR.2012.6236471
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Marszalek Marcin, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Qi GJ, 2009, IEEE T PATTERN ANAL, V31, P1880, DOI 10.1109/TPAMI.2008.218
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sternberg R.J., 2008, COGNITIVE PSYCHOL, V5th
   Sural S, 2002, PROCEEDINGS OF THE 6TH JOINT CONFERENCE ON INFORMATION SCIENCES, P664
   Vassilieva NS, 2009, PROGRAM COMPUT SOFT+, V35, P158, DOI 10.1134/S0361768809030049
   Wang L, 2014, IEEE T PATTERN ANAL, V36, P417, DOI 10.1109/TPAMI.2013.160
   Wang M, 2014, INFORM SCIENCES, V262, P159, DOI 10.1016/j.ins.2013.11.005
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wong RCF, 2008, IEEE T PATTERN ANAL, V30, P1933, DOI 10.1109/TPAMI.2008.125
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
NR 46
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 136
EP 152
DI 10.1016/j.jvcir.2015.03.010
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Geng, YB
   Hu, HM
   Zeng, GD
   Zheng, J
AF Geng, Yanbing
   Hu, Hai-Miao
   Zeng, Guodong
   Zheng, Jin
TI A person re-identification algorithm by exploiting region-based feature
   salience
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Region-based feature saliance; Salient color
   descriptor; Feature extraction; Feature fusion; Metric distance
   calculation; Illumination variation; Video surveillance
ID DISTANCE
AB Due to the changes of the pose and illumination, the appearances of the person captured in surveillance may have obvious variation. Different parts of persons will possess different characteristics. Applying the same feature extraction and description to all parts without differentiating their characteristics will result in poor re-identification performances. Therefore, a person re-identification algorithm is proposed to fully exploit region-based feature salience. Firstly, each person is divided into the upper part and the lower part. Correspondingly, a part-based feature extraction algorithm is proposed to adopt different features for different parts. Moreover, the features of every part are separately represented to retain their salience. Secondly, in order to accurately represent the color feature, the salient color descriptor is proposed by considering the color diversity between current region and its surrounding regions. The experimental results demonstrate that the proposed algorithm can improve the accuracy of person re-identification compared with the state-of-the-art algorithms. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Geng, Yanbing; Hu, Hai-Miao; Zeng, Guodong; Zheng, Jin] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Hu, Hai-Miao; Zheng, Jin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Geng, Yanbing] North Univ China, Coll Elect & Comp Sci & Technol, Taiyuan 030051, Shanxi, Peoples R China.
C3 Beihang University; Beihang University; North University of China
RP Hu, HM (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM frank0139@163.com
RI Zeng, Guodong/U-1292-2019
FU National Science Fund for Distinguished Young Scholars [61125206];
   National Natural Science Foundation of China [61370121]; National
   Hi-Tech Research and Development Program (863 Program) of China
   [2014AA015102]; Outstanding Tutors for doctoral dissertations of S&T
   project in Beijing [20131000602]
FX This work was partially supported by the National Science Fund for
   Distinguished Young Scholars (No. 61125206), the National Natural
   Science Foundation of China (No. 61370121), the National Hi-Tech
   Research and Development Program (863 Program) of China (No.
   2014AA015102), and Outstanding Tutors for doctoral dissertations of S&T
   project in Beijing (No. 20131000602).
CR [Anonymous], P NIPS
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], P BMVC
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2012, ECCV LECT NOTES COMP
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P WORKSH MULT MULT S
   Bazzani L, 2014, ADV COMPUT VIS PATT, P43, DOI 10.1007/978-1-4471-6296-4_3
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bedagkar-Gala A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1721, DOI 10.1109/ICCVW.2011.6130457
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis J. V., 2007, ICML, P209
   Ess A., 2007, IEEE INT C COMPUTER, P1
   Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI [10.1109/CVPR.2008.4587581, DOI 10.1109/CVPR.2008.4587581]
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Geng YB, 2013, IEEE IMAGE PROC, P3363, DOI 10.1109/ICIP.2013.6738693
   Globerson A., 2005, ADV NEURAL INFORM PR
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hu M, 2004, INT C PATT RECOG, P724, DOI 10.1109/ICPR.2004.1334361
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   Lee J., 2008, IEEE C COMPUTER VISI, P1
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Ma LY, 2011, IEEE IMAGE PROC, P1441, DOI 10.1109/ICIP.2011.6115774
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Weinberger K.Q., 2006, Advances in neural information processing systems, P1473
   Wu ZZ, 2014, P IEEE INT FREQ CONT, P136, DOI 10.1007/s10766-014-0304-y
   Xing E.P., Advances in neural information processing systems, 2003, P521
   Yang L., 2006, P AAAI
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yinghao Cai, 2010, Computer Vision. International Workshops (ACCV 2010). Revised Selected Papers, P205, DOI 10.1007/978-3-642-22822-3_21
   Zeng GD, 2014, IEEE IMAGE PROC, P2447, DOI 10.1109/ICIP.2014.7025495
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 40
TC 19
Z9 20
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 89
EP 102
DI 10.1016/j.jvcir.2015.02.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100009
DA 2024-07-18
ER

PT J
AU Zhang, J
   Li, D
   Zhao, YX
   Chen, ZH
   Yuan, YB
AF Zhang, Jing
   Li, Da
   Zhao, Yaxin
   Chen, Zhihua
   Yuan, Yubo
TI Representation of image content based on Rol-BoW
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rol-BoW; Representation of image content; Different size segmentation;
   Image retrieval; Bag of words; Region of Interest; Feature extraction;
   Gabor filtering
ID BAG-OF-WORDS; GRANGER CAUSALITY; SEGMENTATION; RETRIEVAL; ALGORITHM;
   REGIONS; MODELS
AB Representation of image content is an important part of image annotation and retrieval, and it has become a hot issue in computer vision. As an efficient and accurate image content representation model, bag-of-words (BOW) has attracted more attention in recent years. After segmentation, BoW treats all of the image regions equally. In fact, some regions of image are more important than others in image retrieval, such as salient object or region of interest. In this paper, a novel region of interest based bag-of-words model (Rol-BoW) for image representation is proposed. At first, the difference of Gaussian (DOG) is adopted to find key points in an image and generates different size grid as Rol to construct visual words by the BoW model. Furthermore, we analyze the influence of different size segmentation on image content representation by content based image retrieval. Experiments on Corel 5K verify the effectiveness of Rol-BoW on image content representation, and prove that Rol-BoW outperforms the BoW model significantly. Moreover, amounts of experiments illustrate the influence of different size segmentation on image representation based on the Bow model and Rol-BoW model respectively. This work is helpful to choose appropriate grid size in different situations when representing image content, and meaningful to image classification and retrieval. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Jing; Li, Da; Zhao, Yaxin; Chen, Zhihua; Yuan, Yubo] E China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.
   [Zhang, Jing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 East China University of Science & Technology; Nanjing University
RP Chen, ZH (corresponding author), E China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.
EM czh@ecust.edu.cn; ybyuan@ecust.edu.cn
RI yuan, yubo/HSG-3147-2023; Yuan, Yubo/O-7235-2016; Li,
   Zilong/JEZ-8642-2023
FU National Nature Science Foundation of China [61402174, 61370174]; Nature
   Science Foundation of Shanghai Province of China [11ZR1409600]
FX This research has been supported by the National Nature Science
   Foundation of China (Grant 61402174 and 61370174), and Nature Science
   Foundation of Shanghai Province of China (11ZR1409600).
CR Achanta R., 2009, P SPING C COMP VIS, P66
   Albatal R, 2010, 2010 INT WORKSH CONT, P1
   Albatal R, 2011, 2011 IEEE INT C MULT, P1
   Alvarez S, 2012, PATTERN RECOGN, V45, P4312, DOI 10.1016/j.patcog.2012.04.032
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], 2007, CIVR '07
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   Ashrafulla S, 2013, NEUROIMAGE, V83, P189, DOI 10.1016/j.neuroimage.2013.06.056
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   BOVIK AC, 1992, IEEE T INFORM THEORY, V38, P691, DOI 10.1109/18.119731
   Burghouts GJ, 2013, PATTERN RECOGN LETT, V34, P1861, DOI 10.1016/j.patrec.2013.01.024
   Chen KT, 2010, J VIS COMMUN IMAGE R, V21, P815, DOI 10.1016/j.jvcir.2010.06.003
   Chen T, 2011, IEEE IMAGE PROC, P825, DOI 10.1109/ICIP.2011.6116684
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   Cour T, 2005, PROC CVPR IEEE, P1124
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Garcia-Alvarez JC, 2013, J VIS COMMUN IMAGE R, V24, P1316, DOI 10.1016/j.jvcir.2013.09.003
   He XM, 2004, PROC CVPR IEEE, P695
   Hu HM, 2011, J VIS COMMUN IMAGE R, V22, P615, DOI 10.1016/j.jvcir.2011.07.002
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Inoue N, 2013, J VIS COMMUN IMAGE R, V24, P1450, DOI 10.1016/j.jvcir.2013.10.005
   Kuanar SK, 2013, J VIS COMMUN IMAGE R, V24, P1212, DOI 10.1016/j.jvcir.2013.08.003
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li T, 2008, INT CONF ACOUST SPEE, P1333
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Li ZX, 2010, J VIS COMMUN IMAGE R, V21, P798, DOI 10.1016/j.jvcir.2010.06.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Nguyen DA, 2010, LECT NOTES ARTIF INT, V5990, P294
   Qixing Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1953, DOI 10.1109/CVPR.2011.5995571
   Raveaux R, 2013, J VIS COMMUN IMAGE R, V24, P1252, DOI 10.1016/j.jvcir.2013.08.010
   Sato JR, 2010, NEUROIMAGE, V52, P1444, DOI 10.1016/j.neuroimage.2010.05.022
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song TC, 2013, PATTERN RECOGN LETT, V34, P1323, DOI 10.1016/j.patrec.2013.04.020
   TAN TN, 1995, PATTERN RECOGN, V28, P1283, DOI 10.1016/0031-3203(94)00017-G
   TURNER MR, 1986, BIOL CYBERN, V55, P71
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Wang B, 2009, J VIS COMMUN IMAGE R, V20, P45, DOI 10.1016/j.jvcir.2008.10.001
   Wang FR, 2012, INT CONF WIRE COMMUN, DOI 10.1109/WCSP.2012.6543016
   Wu L, 2011, IEEE MULTIMEDIA, V18, P24, DOI 10.1109/MMUL.2011.7
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Wu XB, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON AGRICULTURE ENGINEERING, P162
   Xishun Wang, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1984, DOI 10.1109/CISP.2010.5648193
   Zhang CJ, 2013, J VIS COMMUN IMAGE R, V24, P786, DOI 10.1016/j.jvcir.2013.05.004
   Zhang J, 2013, ACM INTERNATIONAL CO, P17
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
NR 52
TC 10
Z9 12
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 37
EP 49
DI 10.1016/j.jvcir.2014.10.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000005
DA 2024-07-18
ER

PT J
AU Liu, J
   Tai, XC
   Leung, SY
   Huang, HY
AF Liu, Jun
   Tai, Xue-cheng
   Leung, Shingyu
   Huang, Haiyang
TI A new continuous max-flow algorithm for multiphase image segmentation
   using super-level set functions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Global minimization; Graph cut; Continuous max-flow;
   Super-level set functions; Convex relaxation; Augmented Lagrangian
   method; Potts model
ID AUGMENTED LAGRANGIAN METHOD; SPLIT BREGMAN ITERATION; GLOBAL
   MINIMIZATION; DUAL METHODS; MUMFORD; MODEL; OPTIMIZATION; VARIANT; ROF
AB We propose a graph cut based global minimization method for image segmentation by representing the segmentation label function with a series of nested binary super-level set functions. This representation enables us to use K - 1 binary functions to partition any images into K phases. Both continuous and discretized formulations will be treated. For the discrete model, we propose a new graph cut algorithm which is faster than the existing graph cut methods to obtain the exact global solution. In the continuous case, we further improve the segmentation accuracy using a number of techniques that are unique to the continuous segmentation models. With the convex relaxation and the dual method, the related continuous dual model is convex and we can mathematically show that the global minimization can be achieved. The corresponding continuous max-flow algorithms are easy and stable. Experimental results show that our model is very competitive to some existing methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Liu, Jun; Huang, Haiyang] Beijing Normal Univ, Minist Educ, Lab Math & Complex Syst, Sch Math Sci, Beijing 100875, Peoples R China.
   [Tai, Xue-cheng] Univ Bergen, Dept Math, N-5007 Bergen, Norway.
   [Leung, Shingyu] Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Hong Kong, Peoples R China.
C3 Beijing Normal University; University of Bergen; Hong Kong University of
   Science & Technology
RP Liu, J (corresponding author), Beijing Normal Univ, Minist Educ, Lab Math & Complex Syst, Sch Math Sci, Beijing 100875, Peoples R China.
EM jliu@bnu.edu.cn
RI Leung, Shingyu/E-3100-2013; tai, xuecheng/L-9821-2013; Chan,
   Tony/IQW-1869-2023; Tai, Xue-Cheng/JDV-5122-2023
OI Leung, Shingyu/0000-0002-4549-2761; tai, xuecheng/0000-0003-3359-9104;
   Tai, Xue-Cheng/0000-0003-3359-9104
FU National Natural Science Foundation of China [11201032, 11071023];
   Fundamental Research Funds for the Central Universities; HKUST
   [RPC11SC06]
FX Liu is partially supported by National Natural Science Foundation of
   China (No. 11201032) and the Fundamental Research Funds for the Central
   Universities, Huang is partially supported by National Natural Science
   Foundation of China (No. 11071023), Leung is partially supported by the
   HKUST Grant RPC11SC06.
CR [Anonymous], 1960, Arch. Math. (Basel)
   Bae E., 2010, UCLA CAM Report 10-62
   Bae E., 2011, 1182 UCLA CAM, P11
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Bae E, 2009, LECT NOTES COMPUT SC, V5681, P28, DOI 10.1007/978-3-642-03641-5_3
   Bae E, 2009, LECT NOTES COMPUT SC, V5567, P1, DOI 10.1007/978-3-642-02256-2_1
   Bertelli L, INT J COMPUT VISION, V90
   Boykov Y, 2001, LECT NOTES COMPUT SC, V2134, P359
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A., 2011, CONVEX APPROACH MINI
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Darbon J, 2006, J MATH IMAGING VIS, V26, P277, DOI 10.1007/s10851-006-0644-3
   Ekeland I., 1999, SIAM CLASSICS APPL M
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908
   Jung YM, 2007, SIAM J APPL MATH, V67, P1213, DOI 10.1137/060662708
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lellmann J, 2009, LECT NOTES COMPUT SC, V5567, P150, DOI 10.1007/978-3-642-02256-2_13
   Li Y, 2011, COMPUT MATH APPL, V62, P737, DOI 10.1016/j.camwa.2011.05.054
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Lie J, 2006, MATH COMPUT, V75, P1155, DOI 10.1090/S0025-5718-06-01835-7
   Liu J, 2013, J MATH IMAGING VIS, V46, P161, DOI 10.1007/s10851-012-0376-5
   Liu J, 2012, J VIS COMMUN IMAGE R, V23, P1234, DOI 10.1016/j.jvcir.2012.09.002
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Pock T., 2009, IEEE CVPR2009
   Pock T, 2008, LECT NOTES COMPUT SC, V5304, P792, DOI 10.1007/978-3-540-88690-7_59
   POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Yuan J., 2011, 1185 UCLA CAM
   Yuan J, 2010, LECT NOTES COMPUT SC, V6316, P379, DOI 10.1007/978-3-642-15567-3_28
   Yuan J, 2010, PROC CVPR IEEE, P2217, DOI 10.1109/CVPR.2010.5539903
   Zach C., 2008, VIS MOD VIS WORKSH V
NR 41
TC 11
Z9 11
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1472
EP 1488
DI 10.1016/j.jvcir.2014.04.011
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100016
DA 2024-07-18
ER

PT J
AU Xu, YY
   Xiong, LZ
   Xu, ZQ
   Pan, SM
AF Xu, Yanyan
   Xiong, Lizhi
   Xu, Zhengquan
   Pan, Shaoming
TI A content security protection scheme in JPEG compressed domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content security; Compressed domain; Encryption; Fingerprint; Format
   compliance; Variable length coding; Space mapping; Compressed data
   stream
ID MULTIMEDIA DISTRIBUTION; WATERMARKING; VIDEO; ENCRYPTION; MULTICAST
AB The access and distribution convenience of public networks opens a considerable content security threat when sending, receiving, and using multimedia information. In this paper, a content security protection scheme that integrates encryption and digital fingerprinting is proposed to provide comprehensive security protection for multimedia information during its transmission and usage. In contrast to other schemes, this method is implemented in the JPEG compressed domain with no transcoding or decompression, therefore, this scheme is highly efficient and suitable for multimedia information, which is seldom available in an uncompressed form. In addition, a variable modular encryption method is proposed to solve the invalid variable length coding (VLC) problem when a compressed data stream is encrypted directly. Experimental results demonstrate improved security and the efficiency provided by the proposed scheme. The experiments also demonstrate imperceptibility and collusion resistance of fingerprints. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Xu, Yanyan; Xiong, Lizhi; Xu, Zhengquan; Pan, Shaoming] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University
RP Xu, YY (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM xuyy@whu.edu.cn
RI Xiong, Lizhi/KCK-1464-2024
FU National Natural Science Foundation of China [41101416]; National Basic
   Research Program of China [2011CB302204]; Open Research Fund of The
   Academy of Satellite Application [20121689]
FX This work is supported by the National Natural Science Foundation of
   China (No. 41101416), the National Basic Research Program of China (No.
   2011CB302204), and the Open Research Fund of The Academy of Satellite
   Application (No. 20121689).
CR Adelsbach A, 2006, LECT NOTES COMPUT SC, V4058, P136
   Anderson R, 1997, LECT NOTES COMPUT SC, V1267, P107
   Bloom JA, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P621
   Boho A, 2013, IEEE SIGNAL PROC MAG, V30, P97, DOI 10.1109/MSP.2012.2230220
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Brown I, 1999, LECT NOTES COMPUT SC, V1736, P286
   Celik MU, 2008, IEEE T INF FOREN SEC, V3, P475, DOI 10.1109/TIFS.2008.926988
   Hartung F, 1997, INT CONF ACOUST SPEE, P2621, DOI 10.1109/ICASSP.1997.595326
   He S, 2006, IEEE T INF FOREN SEC, V1, P231, DOI 10.1109/TIFS.2006.873597
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Lemma A, 2006, LECT NOTES COMPUT SC, V4283, P433
   LIAN SG, 2009, MULTIMEDIA CONTENT E
   Lian SG, 2008, IEEE T CIRC SYST VID, V18, P1462, DOI 10.1109/TCSVT.2008.2002829
   Lian SG, 2006, IEEE IMAGE PROC, P1953, DOI 10.1109/ICIP.2006.312797
   Lian SG, 2010, COMPUT COMMUN, V33, P1664, DOI 10.1016/j.comcom.2010.03.015
   Lin CY, 2012, SIGNAL PROCESS, V92, P2159, DOI 10.1016/j.sigpro.2012.02.002
   Mobasseri B., P SPIE, V5681
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Pegueroles J, 2006, LECT NOTES COMPUT SC, V3982, P527, DOI 10.1007/11751595_56
   Sadeghi AR, 2008, LECT NOTES COMPUT SC, V5041, P2
   Serra-Ruiz J, 2011, INT J REMOTE SENS, V32, P5583, DOI 10.1080/01431161.2010.507256
   Serra-Sagristà J, 2008, STUD COMPUT INTELL, V133, P27
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Tosun A. S., 2001, P ACM INT MULT C EXH, P302
   Wen JT, 2002, IEEE T CIRC SYST VID, V12, P545, DOI 10.1109/TCSVT.2002.800321
   Wu C.P., 2000, SPIE INT S INFORM TE, V4209, P284
   Wu CP, 2001, PROC SPIE, V4314, P128, DOI 10.1117/12.435392
   Zhao HV, 2006, IEEE T IMAGE PROCESS, V15, P12, DOI 10.1109/TIP.2005.860356
NR 28
TC 14
Z9 15
U1 2
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 805
EP 813
DI 10.1016/j.jvcir.2014.01.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200009
DA 2024-07-18
ER

PT J
AU Aflaki, P
   Hannuksela, MM
   Sarbolandi, H
   Gabbouj, M
AF Aflaki, Payman
   Hannuksela, Miska M.
   Sarbolandi, Hamed
   Gabbouj, Moncef
TI Simultaneous 2D and 3D perception for stereoscopic displays based on
   polarized or active shutter glasses
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic; Depth perception; Subjective quality assessment; 3DV; 2DV;
   Low pass filtering; Contrast adjustment; Disparity adjustment
ID COMPRESSION
AB Viewing stereoscopic 3D content is typically enabled either by using polarizing or active shutter glasses. In certain cases, some viewers may not wear viewing glasses and hence, it would be desirable to tune the stereoscopic 3D content so that it could be simultaneously watched with and without viewing glasses. In this paper we propose a video post-processing technique which enables good quality 3D and 2D perception of the same content. This is done through manipulation of one view by making it more similar to the other view to reduce the ghosting artifact perceived without viewing glasses while 3D perception is maintained. The proposed technique includes three steps: disparity selection, contrast adjustment, and low-pass filtering. The proposed approach was evaluated through an extensive series of subjective tests, which also revealed good adjustment parameters to suit viewing with and without viewing glasses with an acceptable 3D and 2D quality, respectively. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Aflaki, Payman; Sarbolandi, Hamed; Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
   [Hannuksela, Miska M.] Nokia Res Ctr, Tampere, Finland.
C3 Tampere University; Nokia Corporation; Siemens AG; Nokia Siemens
   Networks; Nokia Finland
RP Aflaki, P (corresponding author), Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
EM ext-payman.aflaki-beni@nokia.com
RI Gabbouj, Moncef/G-4293-2014
OI Gabbouj, Moncef/0000-0002-9788-2323
CR Aflaki P., 2011, P INT S IM SIGN PROC
   Aflaki P., 2010, P IEEE INT C IM PROC
   Aflaki P., 2010, P 3DTV C IEEE JUN
   Aksay A., 2005, EUR SIGN PROC C EUSI
   [Anonymous], 2011, JTC1SC29WG11 ISOIEC
   [Anonymous], 2012, ADV VID COD GEN AUD
   [Anonymous], THESIS
   [Anonymous], 2020, INT TELECOMMUNICATIO
   ASHER H, 1953, BRIT J OPHTHALMOL, V37, P37, DOI 10.1136/bjo.37.1.37
   BLAKE R, 1977, J EXP PSYCHOL HUMAN, V3, P251, DOI 10.1037/0096-1523.3.2.251
   Coltekin A., 2006, THESIS HELSINKI U TE
   Cooligan H., 2004, RES METHODS STAT PSY, V4th
   Domanski M., 2009, 2009M17050 MPEG
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Howarth P.A., 1996, P HOS BUNK FDN S HUM
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   IJsselsteijn WA, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P219
   Julesz B., 1971, Foundation of Cyclopean Perception
   Konrad J, 2007, IEEE SIGNAL PROC MAG, V24, P97, DOI 10.1109/MSP.2007.905706
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Merkle P, 2007, IEEE IMAGE PROC, P201
   MPEG, 2009, JTC1SC29WG11 MPEG IS
   Papelba G., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5123, P323, DOI 10.1117/12.517039
   Pastoor S., 1995, P INT DISPL WORKSH A
   PERKINS MG, 1992, IEEE T COMMUN, V40, P684, DOI 10.1109/26.141424
   Qin D., 2004, J LIGHT VIS ENVIRON, V28, P126, DOI DOI 10.2150/JLVE.28.126
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Shao F, 2010, IEEE T CONSUM ELECTR, V56, P2460, DOI 10.1109/TCE.2010.5681128
   Speranza F., 2006, P STEREOSCOPIC DISPL, V6055
   Stelmach L, 2000, IEEE T CIRC SYST VID, V10, P188, DOI 10.1109/76.825717
   Stelmach L.B., 2000, P IEEE INT C IM PROC
   Strohmeier Dominik, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P70, DOI 10.1109/QOMEX.2010.5518028
   Surydkumar R., 2005, STUDY DYNAMIC INTERA
   Wang X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P467, DOI 10.1109/CISP.2008.371
   Wheatstone C., 1838, PHILOS T ROYAL SOC
   Wilcox LM, 2000, VISION RES, V40, P3575, DOI 10.1016/S0042-6989(00)00216-9
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wopking M., 1995, Journal of the Society for Information Display, V3, P101
   ZIVKOVIC Z, 2012, INT C CONS EL ICCE I, P682
NR 40
TC 5
Z9 6
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 622
EP 631
DI 10.1016/j.jvcir.2013.03.014
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500003
DA 2024-07-18
ER

PT J
AU Yang, WJ
   Chung, KL
   Huang, YH
   Lin, LC
AF Yang, Wei-Jen
   Chung, Kuo-Liang
   Huang, Yong-Huai
   Lin, Le-Chung
TI Quality-efficient syntax element-based de-interlacing method for
   H.264-coded video sequences with various resolutions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE De-interlacing; Field image; H.264/AVC; Inter mode; Motion vector;
   Quality; Syntax elements; Various resolutions
ID MOTION ESTIMATION; INTERPOLATION; COMPENSATION
AB In this paper, we propose a novel quality-efficient de-interlacing method for H.264-coded video sequences with various resolutions. In the proposed method, using the syntax elements provided in H.264 bitstreams, four new and efficient strategies are delivered for inter-coded macroblocks to improve the quality of de-interlaced video sequences as well as alleviate the error propagation side effect. Based on the real and generated interlaced video sequences with various common resolutions, experimental results demonstrate the proposed de-interlacing method achieves better quality in terms of both objective and subjective measures when compared with the recently published method by Dong and Ngan. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yang, Wei-Jen; Chung, Kuo-Liang; Lin, Le-Chung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Huang, Yong-Huai] Jinwen Univ Sci & Technol, Inst Comp & Commun Engn, Dept Elect Engn, New Taipei City 23154, Taiwan.
C3 National Taiwan University of Science & Technology
RP Huang, YH (corresponding author), Jinwen Univ Sci & Technol, Inst Comp & Commun Engn, Dept Elect Engn, 99 An Chung Rd, New Taipei City 23154, Taiwan.
EM klchung01@gmail.com; yonghuai@ms28.hinet.net
FU National Council of Science of R.O.C. [NSC 99-2221-E-011-078-MY3, NSC
   101-2221-E-011-139-MY3]; National Science Council of R.O.C.
   [NSC100-2221-E-228-007, NSC101-2221-E-228-010]
FX Supported by National Council of Science of R.O.C. under contracts NSC
   99-2221-E-011-078-MY3 and NSC 101-2221-E-011-139-MY3.; Supported by the
   National Science Council of R.O.C. under the contracts
   NSC100-2221-E-228-007 and NSC101-2221-E-228-010.
CR Chang J, 2009, IEEE T CIRC SYST VID, V19, P1214, DOI 10.1109/TCSVT.2009.2020341
   Chang YL, 2005, IEEE T CIRC SYST VID, V15, P1569, DOI 10.1109/TCSVT.2005.858746
   Chen YR, 2009, IEEE T CIRC SYST VID, V19, P1489, DOI 10.1109/TCSVT.2009.2022782
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   De Haan G, 1998, P IEEE, V86, P1839, DOI 10.1109/5.705528
   DELOGNE P, 1994, IEEE T IMAGE PROCESS, V3, P482, DOI 10.1109/83.334992
   Dong J, 2010, IEEE T CIRC SYST VID, V20, P1144, DOI 10.1109/TCSVT.2010.2056952
   Doyle T., 1990, Signal Processing of HDTV, II. Proceedings of the Third International Workshop on HDTV, P711
   Draft ITU-T Recommendation and Final Draft International Standard of Joint Video Specification, 2003, ITU T REC F IN PRESS
   Fan YC, 2009, IEEE T CIRC SYST VID, V19, P932, DOI 10.1109/TCSVT.2009.2020327
   Li RX, 2000, IEEE T CIRC SYST VID, V10, P23, DOI 10.1109/76.825854
   Park M., 2003, IEEE T CONSUM ELECT, V49
   Renfors M., 1990, Signal Processing of HDTV, II. Proceedings of the Third International Workshop on HDTV, P685
   Schutten RJ, 1998, IEEE T CONSUM ELECTR, V44, P930, DOI 10.1109/30.713216
   Tai SC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P659, DOI 10.1109/ICME.2004.1394278
   Wu C.H., 2008, DEINTERLACING ALGORI
   Yoo H, 2002, IEEE T CONSUM ELECTR, V48, P954, DOI 10.1109/TCE.2003.1196426
NR 17
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 466
EP 477
DI 10.1016/j.jvcir.2013.12.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300022
DA 2024-07-18
ER

PT J
AU Chen, JW
   Villasenor, J
   He, Y
   Luo, G
AF Chen, Jianwen
   Villasenor, John
   He, Yun
   Luo, Gang
TI Parallel fast inter mode decision for H.264/AVC encoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fast mode decision; H.264/AVC; Video codec design; Parallel encoding
ID DISTORTION ESTIMATION; VIDEO
AB For H.264/AVC encoding, the mode selection process consumes a large proportion of the overall computation. To reduce this burden, various fast mode decision algorithms have been proposed. The current fast mode decision algorithms usually exploit the relationship among the coding modes and use the context-based approach to reduce the number of modes to be checked for both intra coding and inter coding. The parallel capacity of hardware architectures are also taken into consideration. However, almost all the parallel fast mode decision designs are focusing on intra coding. In this paper, a hardware friendly parallel fast inter mode decision method is proposed. With the proposed method, the inter mode decision can be conducted efficiently in one pass and significant encoding speedup can be achieved with negligible coding efficiency loss. Moreover, the proposed method can be easily mapped to hardware architecture which can be used for the real-time video encoding. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Jianwen; Villasenor, John] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90024 USA.
   [He, Yun] Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing, Peoples R China.
   [Luo, Gang] Harvard Univ, Sch Med, Schepens Eye Res Inst, Boston, MA USA.
C3 University of California System; University of California Los Angeles;
   Tsinghua University; Harvard University; Harvard Medical School;
   Schepens Eye Research Institute
RP Chen, JW (corresponding author), Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90024 USA.
EM jianwen.chen@ieee.org; villa@ee.ucla.edu; hey@tsinghua.edu.cn;
   gang.luo@schepens.harvard.edu
RI he, yun/JMB-6362-2023; luo, gang/C-6016-2009; chen, jw/IQW-1558-2023
OI Luo, Gang/0000-0003-0623-6236
CR [Anonymous], 1994, GEN COD MOV PICT A 2
   [Anonymous], 144962 ISOIEC
   Ates HF, 2008, INT CONF ACOUST SPEE, P1045, DOI 10.1109/ICASSP.2008.4517792
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Chen PH, 2010, C IND ELECT APPL, P253
   Chen Q., 2004, P PICT COD S PCS2004
   Cheney J.T., 2004, Geological Society of America Special Paper, V377, P151, DOI [DOI 10.1130/0-8137-2377-9.151, 10.1130/0-8137-2377 -9.151]
   Hyun JH, 2010, IEEE INT CON MULTI, P655, DOI 10.1109/ICME.2010.5582556
   International Telecommunication Union Telecommunication Standardization Sector (ITU-T), 2000, VID COD LOW BIT RAT, V263
   Jamil-Ur-Rehman, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5094
   Joch A., 2002, P INT C IM PROC, V2
   KIM BG, 2007, INT C EL MAT PACK WA, P1
   Lee J, 2010, IEEE T CONSUM ELECTR, V56, P1942, DOI 10.1109/TCE.2010.5606350
   LIM KP, 2003, FAST INTER MODE SELE
   Moon JM, 2010, IEEE T CIRC SYST VID, V20, P207, DOI 10.1109/TCSVT.2009.2031389
   Pan F., 2003, RAHARDJA FAST MODE D
   Po LM, 2007, IEEE T CIRC SYST VID, V17, P765, DOI 10.1109/TCSVT.2007.896663
   Porto Roger, 2010, Proceedings of the VI Southern Programmable Logic Conference (SPL), P183, DOI 10.1109/SPL.2010.5483015
   Sarwer MG, 2007, IEEE T CIRC SYST VID, V17, P1402, DOI 10.1109/TCSVT.2007.903787
   Shafique M, 2009, DES AUT TEST EUROPE, P1434
   Tsai TH, 2008, IEEE INT SYM MULTIM, P124, DOI 10.1109/ISM.2008.98
   Tu YK, 2006, IEEE T CIRC SYST VID, V16, P600, DOI 10.1109/TCSVT.2006.873160
   Turaga DS, 2001, IEEE T MULTIMEDIA, V3, P41, DOI 10.1109/6046.909593
   Turaga DS, 2001, IEEE T CIRC SYST VID, V11, P1098, DOI 10.1109/76.954496
   Wang JX, 2010, J INF SCI ENG, V26, P409
   Wei Z., 2007, P 32 INT C AC SPEECH
   Yang J, 2009, 2009 WASE INTERNATIONAL CONFERENCE ON INFORMATION ENGINEERING, ICIE 2009, VOL I, P153, DOI 10.1109/ICIE.2009.11
   Yin Peng, 2003, IM PROC 2003 ICIP 20, V3, pIII
   Zeng HQ, 2009, IEEE T CIRC SYST VID, V19, P491, DOI 10.1109/TCSVT.2009.2014014
   Zhou D., 2010, 2 INT C FUT COMP COM, V3
   Zhu W, 2010, IEEE T CONSUM ELECTR, V56, P1696, DOI 10.1109/TCE.2010.5606315
NR 31
TC 1
Z9 1
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1443
EP 1449
DI 10.1016/j.jvcir.2013.10.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700018
DA 2024-07-18
ER

PT J
AU Chen, YB
   Cai, CH
   Ma, KK
   Wang, XL
AF Chen, Yibin
   Cai, Canhui
   Ma, Kai-Kuang
   Wang, Xiaolan
TI Layered moving-object segmentation for stereoscopic video using motion
   and depth information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video segmentation; Stereoscopic video; Layered segmentation;
   Depth-layer mask; Disparity estimation; Motion mask; Moving objects;
   Higher order statistics; Change detection
ID AUTOMATIC SEGMENTATION; BILAYER SEGMENTATION
AB A novel layered stereoscopic moving-object segmentation method is proposed in this paper by exploiting both motion information and depth information to extract moving objects for each depth layer with high accuracy on their shape boundary. By taking a higher-order statistics on two frame-difference fields across three adjacent frames, the computed motion information are used to conduct change detection and generate one motion mask that consists of all the moving objects from all the depth layers involved at each view. It would be highly desirable, and challenging, to further differentiate them according to their residing depth layer to achieve layered segmentation. For that, multiple depth-layer masks are generated using our proposed disparity estimation method, one for each depth layer. By intersecting the motion mask and one depth-layer mask at any given layer-of-interest, the moving objects associated with the corresponding layer are then extracted. All the above-mentioned processes are repeatedly performed along the video sequence with a sliding window of three frames at a time. For demonstration, only the foreground and the background layers are considered in this paper, while the proposed method is generic and can be straightforwardly extended to more layers, once the corresponding depth-layer masks are made available. Experimental results have shown that the proposed layered moving-object segmentation method is able to segment the foreground and background moving objects separately, with high accuracy on their shape boundary. In addition, the required computational load is considered fairly inexpensive, since our design methodology is to generate masks and perform intersections for extracting the moving objects for each depth layer. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Yibin; Cai, Canhui; Wang, Xiaolan] Huaqiao Univ, Sch Informat Sci & Technol, Fujian, Peoples R China.
   [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Huaqiao University; Nanyang Technological University
RP Cai, CH (corresponding author), Huaqiao Univ, Sch Informat Sci & Technol, Fujian, Peoples R China.
EM chenyibin@sptdi.com; chcai@hqu.edu.cn; ekkma@ntu.edu.sg;
   413260175@qq.com
RI Chen, Yibin/A-3019-2015; Ma, Kai-Kuang/KBA-9411-2024; 王,
   小兰/HOC-9816-2023
FU National Natural Science Foundation of China [61250009]; Fujian Province
   Natural Science Foundation [2011J01354]
FX This paper is partially supported by the National Natural Science
   Foundation of China under Grant 61250009 and the Fujian Province Natural
   Science Foundation under Grant 2011J01354.
CR [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   Camplani M, 2014, J VIS COMMUN IMAGE R, V25, P122, DOI 10.1016/j.jvcir.2013.03.009
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   GONZALEZ C, 2007, DIGITAL IMAGE PROCES, P741
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kolmogorov V, 2005, PROC CVPR IEEE, P407
   Liu HW, 2014, J VIS COMMUN IMAGE R, V25, P709, DOI 10.1016/j.jvcir.2013.03.012
   Meier T, 1998, IEEE T CIRC SYST VID, V8, P525, DOI 10.1109/76.718500
   Neri A, 1997, P SOC PHOTO-OPT INS, V3024, P246, DOI 10.1117/12.263236
   Patras I, 2001, IEEE T PATTERN ANAL, V23, P326, DOI 10.1109/34.910886
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Silva LS, 2010, IEEE T IMAGE PROCESS, V19, P1036, DOI 10.1109/TIP.2009.2038778
   Tsaig Y, 2002, IEEE T CIRC SYST VID, V12, P597, DOI 10.1109/TCSVT.2002.800513
   Wu Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1353, DOI 10.1109/ICME.2008.4607694
   Xu F, 2011, IEEE T IMAGE PROCESS, V20, P2615, DOI 10.1109/TIP.2011.2121081
   Yin P, 2011, IEEE T PATTERN ANAL, V33, P30, DOI 10.1109/TPAMI.2010.65
   Zhang GF, 2011, IEEE T PATTERN ANAL, V33, P603, DOI 10.1109/TPAMI.2010.115
   Zhang Q, 2011, IEEE T IMAGE PROCESS, V20, P3308, DOI 10.1109/TIP.2011.2159228
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 19
TC 4
Z9 4
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 829
EP 837
DI 10.1016/j.jvcir.2013.05.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700009
DA 2024-07-18
ER

PT J
AU Ma, LY
   Yang, XK
   Xu, Y
   Zhu, J
AF Ma, Lianyang
   Yang, Xiaokang
   Xu, Yi
   Zhu, Jun
TI A generalized EMD with body prior for pedestrian identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE EMD; Generalized EMD; Pedestrian identification; Body prior;
   Probabilistic map; Matching metric; KL divergence; Learning weight
AB In this paper, we present a generalized Earth Mover's Distance (EMD) for pedestrian identification with body prior. (i) The general configuration of body is a valuable cue for human identification. A model of body prior about the general configuration is pursued to describe body prior for every pedestrian. In addition, the spatial incompatibility is computed by Kullback-Leibler divergence according to the pursued model and embedded into the ground distance of EMD. (ii) Furthermore, we generalize EMD by assigning different weights to regions of body, which are learned based on maximum margin criterion to boost discriminative power for pedestrian identification. The experimental results show that the generalized EMD and body prior substantially improve performance on pedestrian identification and the proposed approach is comparable to the state-of-the-art performance. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Ma, Lianyang; Yang, Xiaokang; Xu, Yi; Zhu, Jun] Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, XK (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
EM xkyang@sjtu.edu.cn
RI Yang, Xiaokang/C-6137-2009; Zhu, Jun/Q-3667-2016
OI Yang, Xiaokang/0000-0003-4029-3322; 
FU NSFC [61025005, 60932006, 60902073, 61001146]; 973 Program
   [2010CB731401, 2010CB731406]; STCSM [10511500802]; 111 Project [B07022]
FX This work was partially supported by NSFC (61025005, 60932006, 60902073,
   61001146), 973 Program (2010CB731401, 2010CB731406), STCSM (10511500802)
   and the 111 Project (B07022).
CR Andrew Rosenberg J.H., 2007, 2007 JOINT C EMP MET
   [Anonymous], 2009, P 22 BRAZ S COMP GRA
   [Anonymous], 2008, ECCV
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Ess A., 2007, ICCV 07
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farenzena A.P.V.M., 2010, CVPR
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gilbert B.R., 2006, EUR C COMP VIS
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Hitchcock F. L., 1941, J MATH PHYS, V20, P224, DOI DOI 10.1002/SAPM1941201224
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Loy T.X.C.C., 2009, IEEE C COMP VIS PATT
   Madden C, 2007, MACH VISION APPL, V18, P233, DOI 10.1007/s00138-007-0070-6
   Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013
   Omar Javed K.S., 2003, 9 IEEE INT C COMP VI
   Omar Javed K.S., 2005, IEEE INT C COMP VIS
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Prosser B. J., 2008, P BMVC, VVol. 8
   RUBIN DB, 1983, ENCY STAT SCI, V4
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
NR 23
TC 3
Z9 3
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 708
EP 716
DI 10.1016/j.jvcir.2012.04.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900008
DA 2024-07-18
ER

PT J
AU Chakareski, J
AF Chakareski, Jacob
TI Multi-path content delivery: Efficiency analysis and optimization
   algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video streaming; Multi-path delivery; Rate-distortion optimization;
   Packet scheduling; Rate allocation; Server diversity; Joint
   source-channel coding; Markov decision processes
ID VIDEO COMMUNICATION; DIVERSITY
AB The paper studies the benefits of multi-path content delivery from a rate-distortion efficiency perspective. We develop an optimization framework for computing transmission schedules for streaming media packets over multiple network paths that maximize the end-to-end video quality, for the given bandwidth resources. We comprehensively address the two prospective scenarios of content delivery with packet path diversity. In the context of sender-driven systems, our framework enables the sender to compute at every transmission instance the mapping of packets to network paths that meets a rate constraint while minimizing the end-to-end distortion. In receiver-driven multi-path streaming, our framework enables the client to dynamically decide which packets, if any, to request for transmission and from which media servers, such that the end-to-end distortion is minimized for a given transmission rate constraint. Via simulation experiments, we carefully examine the performance of the scheduling framework in both multi-path delivery scenarios. We demonstrate that the optimization framework closely approaches the performance of an ideal streaming system working at channel capacity with an infinite play-out delay. We also show that the optimization leads to substantial gains in rate-distortion performance over a conventional content-agnostic scheduler. Through the concept of error-cost performance for streaming a single packet, we provide another useful insight into the operation of the optimization framework and the conventional scheduling system. (c) 2012 Elsevier Inc. All rights reserved.
C1 Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Chakareski, J (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
EM jakov.cakareski@epfl.ch
FU Swiss National Science Foundation under Ambizione [PZOOP2-126416]
FX This work was supported by the Swiss National Science Foundation under
   Ambizione Grant PZOOP2-126416.
CR [Anonymous], 2001, P 9 ACM INT C MULTIM, DOI DOI 10.1145/500141.500205
   [Anonymous], 2001, Probability, Random Variables and Stochastic Processes
   Apostolopoulos J, 2002, IEEE INFOCOM SER, P1736, DOI 10.1109/INFCOM.2002.1019427
   Apostolopoulos JG, 2001, IEEE IMAGE PROC, P966, DOI 10.1109/ICIP.2001.959208
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Bolot J.-C., 1993, Computer Communication Review, V23, P289, DOI 10.1145/167954.166265
   Chakareski J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P645
   Chakareski J, 2003, IEEE DATA COMPR CONF, P203
   Chakareski J., 2005, IEEE INT C IM PROC 2, V2, P161
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Gogate N, 2002, IEEE T CIRC SYST VID, V12, P777, DOI 10.1109/TCSVT.2002.803229
   ITU-T and ISO/IEC JTC 1, 2005, 1 ITUT ISOIEC JTC
   Jurca D, 2008, SIGNAL PROCESS-IMAGE, V23, P754, DOI 10.1016/j.image.2008.09.002
   Liang YJ, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P420
   Liang YJ, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P555, DOI 10.1109/MMSP.2001.962791
   Loguinov D, 2002, IEEE INFOCOM SER, P723, DOI 10.1109/INFCOM.2002.1019318
   Majumdar A, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P177, DOI 10.1109/ICIP.2002.1038934
   Nguyen T., 2002, P INT PACK VID WORKS
   Nguyen TP, 2002, PROC SPIE, V4673, P186
   Poor H., 1998, WIRELESS COMMUNICATI
   Rejaie R, 1999, IEEE INFOCOM SER, P1337, DOI 10.1109/INFCOM.1999.752152
   Savage S, 1999, COMP COMM R, V29, P289, DOI 10.1145/316194.316233
   Sehgal A, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P857, DOI 10.1109/ICME.2002.1035917
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Stevens W, 1994, TCP/ IP Illustrated, V1
   Wang Y, 2002, IEEE IMAGE PROC, P21
   Yajnik M, 1999, IEEE INFOCOM SER, P345, DOI 10.1109/INFCOM.1999.749301
NR 29
TC 1
Z9 2
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1189
EP 1198
DI 10.1016/j.jvcir.2012.07.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300003
DA 2024-07-18
ER

PT J
AU Li, F
   Zeng, TY
   Zhang, GX
AF Li, Fang
   Zeng, Tieyong
   Zhang, Guixu
TI Lagrangian multipliers and split Bregman methods for minimization
   problems constrained on S<SUP>n-1</SUP>
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lagrangian method; Split Bregman method; Total variation
ID IMAGE-RESTORATION; ALGORITHMS; ENHANCEMENT
AB The numerical methods of total variation (TV) model for image denoising, especially Rudin-Osher-Fatemi (ROF) model, is widely studied in the literature. However, the Sn-1 constrained counterpart is less addressed. The classical gradient descent method for the constrained problem is limited in two aspects: one is the small time step size to ensure stability; the other is that the data must be projected onto Sn-1 during evolution since the unit norm constraint is poorly satisfied. In order to avoid these drawbacks, in this paper, we propose two alternative numerical methods based on the Lagrangian multipliers and split Bregman methods. Both algorithms are efficient and easy to implement. A number of experiments demonstrate that the proposed algorithms are quite effective in denoising of data constrained on S-1 or S-2, including general direction data diffusion and chromaticity denoising. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zhang, Guixu] E China Normal Univ, Dept Comp Sci, Shanghai 200062, Peoples R China.
   [Li, Fang] E China Normal Univ, Dept Math, Shanghai 200062, Peoples R China.
   [Zeng, Tieyong] Hong Kong Baptist Univ, Ctr Math Imaging & Vis, Kowloon Tong, Hong Kong, Peoples R China.
   [Zeng, Tieyong] Hong Kong Baptist Univ, Dept Math, Kowloon Tong, Hong Kong, Peoples R China.
C3 East China Normal University; East China Normal University; Hong Kong
   Baptist University; Hong Kong Baptist University
RP Zhang, GX (corresponding author), E China Normal Univ, Dept Comp Sci, Shanghai 200062, Peoples R China.
EM gxzhang@cs.ecnu.edu.cn
RI Zeng, Tieyong/B-7147-2009
OI ZENG, Tieyong/0000-0002-0688-202X
FU 973 Program [2011CB707104]; National Science Foundation of China
   [11001082]; RGC [203109, 211710, 211911]; RFGs of HKBU
FX This work is supported by the 973 Program (2011CB707104), the National
   Science Foundation of China (11001082), and RGC 203109, 211710, 211911
   and RFGs of HKBU.
CR Aubert G., 2006, APPL MATH SCI
   Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Bresson X, 2008, INVERSE PROBL IMAG, V2, P455, DOI 10.3934/ipi.2008.2.455
   Cecil T, 2004, J COMPUT PHYS, V198, P567, DOI 10.1016/j.jcp.2004.01.020
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Chen Y, 2002, J MATH ANAL APPL, V272, P117, DOI 10.1016/S0022-247X(02)00141-5
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Estellers V., UCLA CAM REPORTS, P11
   Gabay D., 1983, AUGMENTED LAGRANGIAN, V15, P299, DOI DOI 10.1016/S0168-2024(08)70034-1
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2281, DOI 10.1109/TIP.2006.875247
   Goldfarb D, 2009, SIAM J IMAGING SCI, V2, P84, DOI 10.1137/080726926
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Haehnle J, 2011, SIAM J IMAGING SCI, V4, P1200, DOI 10.1137/100795620
   Jia RQ, 2010, ADV COMPUT MATH, V33, P231, DOI 10.1007/s10444-009-9128-5
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Li F, 2011, J VIS COMMUN IMAGE R, V22, P529, DOI 10.1016/j.jvcir.2011.06.006
   Li F, 2010, J MATH IMAGING VIS, V37, P98, DOI 10.1007/s10851-010-0195-5
   LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071
   Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5
   Ng MK, 2011, SIAM J SCI COMPUT, V33, P1643, DOI 10.1137/100807697
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Tai XC, 2011, SIAM J IMAGING SCI, V4, P313, DOI 10.1137/100803730
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986
   Tschumperlé D, 2002, INT J COMPUT VISION, V50, P237, DOI 10.1023/A:1020870207168
   Vese LA, 2003, SIAM J NUMER ANAL, V40, P2085
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   WEN ZX, PREPRINT
NR 35
TC 4
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1041
EP 1050
DI 10.1016/j.jvcir.2012.07.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900008
DA 2024-07-18
ER

PT J
AU Li, P
   Ma, PJ
   Su, XH
   Yang, CN
AF Li, Peng
   Ma, Pei-Jun
   Su, Xiao-Hong
   Yang, Ching-Nung
TI Improvements of a two-in-one image secret sharing scheme based on gray
   mixing model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image secret sharing; Visual cryptography; Polynomial-based secret
   sharing; Gray mixing model; Information hiding; Lagrange interpolation;
   (k,n)-threshold scheme; Image processing
ID VISUAL CRYPTOGRAPHY SCHEMES; CONTRAST; STEGANOGRAPHY
AB Yang and Ciou recently proposed a two-in-one image secret sharing scheme (TiOISSS), which can easily preview a vague image by human eyes, but also provide a perfect reconstruction of the original image by computation. However, their scheme cannot recover the lossless image by computation as they claimed. In this paper, we resolve the problem of lossless reconstruction. In addition, we improve the visual quality of the previewed image. Also, we introduce a new definition of contrast to evaluate the visual quality of the previewed image. Compared with Yang and Ciou's TiOISSS, our scheme can gain the lossless secret image and meantime enhance the contrast of previewed image. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Li, Peng] Harbin Inst Technol, Sch Comp Sci & Technol, Dept Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 Harbin Institute of Technology; National Dong Hwa University
RP Li, P (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Dept Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM lphit@163.com
RI Li, Peng/D-7073-2012; Yang, Ching-Nung/HKV-1639-2023
OI Yang, Ching-Nung/0000-0002-3881-7329
FU Testbed@TWISC, National Science Council [NSC 100-2219-E-006-001]
FX This work was supported in part by the Testbed@TWISC, National Science
   Council under the Grant NSC 100-2219-E-006-001.
CR Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2006, THEOR COMPUT SCI, V369, P169, DOI 10.1016/j.tcs.2006.08.008
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Cimato S, 2007, THEOR COMPUT SCI, V374, P261, DOI 10.1016/j.tcs.2007.01.006
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Grinstead C., 1998, Introduction to Probability
   Horng G., 2008, DESIGN CODE CRYPTOGR, V2, P151
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Krause M, 2003, COMB PROBAB COMPUT, V12, P285, DOI 10.1017/S096354830200559X
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Peng Li, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P367, DOI 10.1109/PCSPA.2010.95
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Yang CN, 2008, COMPUT J, V51, P710, DOI 10.1093/comjnl/bxm118
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Yang CN, 2008, PATTERN RECOGN, V41, P3114, DOI 10.1016/j.patcog.2008.03.031
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2011, VISUAL CRYPTOGRAPHY
NR 36
TC 72
Z9 72
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 441
EP 453
DI 10.1016/j.jvcir.2012.01.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800004
DA 2024-07-18
ER

PT J
AU Chen, HY
   Leou, JJ
AF Chen, Hsuan-Ying
   Leou, Jin-Jang
TI Saliency-directed color image interpolation using artificial neural
   network and particle swarm optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention model; Color image interpolation; Artificial neural
   network (ANN); Particle swarm optimization (PSO); Interpolation
   filtering mask; Bilinear interpolation; Magnification factor; Image
   super-resolution
ID VISUAL-ATTENTION; MODEL
AB In this study, a saliency-directed color image interpolation approach using artificial neural network (ANN) and particle swarm optimization (PSO) is proposed. First, a high-quality saliency map of a color image to be interpolated is generated by a modified block-based visual attention model in an effective manner. Then, based on the saliency map, bilinear interpolation and ANN-PSO interpolation are employed for non-saliency (non-ROI) and saliency (ROI) blocks, respectively, to obtain the final color interpolation results. In the proposed ANN-PSO interpolation scheme, ANN is used to determine the orientation of each 5 x 5 image pattern (block), whereas PSO is employed to determine the weights in 5 x 5 interpolation filtering masks. The proposed approach is applicable to image interpolation with arbitrary magnification factors (MFs). Based on the experimental results obtained in this study, the color interpolation results by the proposed approach are better than those by five comparison approaches. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chen, Hsuan-Ying; Leou, Jin-Jang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM chenhy@cs.ccu.edu.tw; jjleou@cs.ccu.edu.tw
FU National Science Council, Taiwan, Republic of China [NSC
   98-2221-E-194-034-MY3, NSC 99-2221-E-194-032-MY3]
FX This work was supported in part by National Science Council, Taiwan,
   Republic of China under Grants NSC 98-2221-E-194-034-MY3 and NSC
   99-2221-E-194-032-MY3.
CR [Anonymous], P IEEE INT C CONS EL
   [Anonymous], 2002, COMPUTATIONAL INTELL
   Atkins C.B., 1998, THESIS PURDUE U W LA
   Auwatanamongkol S, 2007, PATTERN RECOGN LETT, V28, P1428, DOI 10.1016/j.patrec.2007.02.013
   Broadbent DE, 2013, PERCEPTION COMMUNICA
   Carrato S, 2000, IEEE SIGNAL PROC LET, V7, P132, DOI 10.1109/97.844630
   Cha Y, 2007, IEEE T IMAGE PROCESS, V16, P1496, DOI 10.1109/TIP.2007.896645
   Cha YJ, 2006, IEEE T IMAGE PROCESS, V15, P2315, DOI 10.1109/TIP.2006.875182
   Chen HY, 2010, J INF SCI ENG, V26, P1657
   Chen HY, 2010, SIGNAL PROCESS, V90, P1676, DOI 10.1016/j.sigpro.2009.11.019
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Davis L., 1991, Handbook of Genetic Algorithms
   DEUTSCH JA, 1963, PSYCHOL REV, V70, P80, DOI 10.1037/h0039515
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Hu Y., 2005, P 33TH ANN C CANADIA, P1
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   James W., 1890, The Principles of Psychology, V1
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Kanemura A, 2010, IEEE T IMAGE PROCESS, V19, P1480, DOI 10.1109/TIP.2010.2043010
   Kang LW, 2006, J VIS COMMUN IMAGE R, V17, P1127, DOI 10.1016/j.jvcir.2006.08.003
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Le Meur O, 2004, PROC SPIE, V5292, P284, DOI 10.1117/12.527440
   Lee K, 2005, IEEE T NEURAL NETWOR, V16, P910, DOI 10.1109/TNN.2005.851787
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Looney CarlGrant., 1997, Pattern recognition using neural networks: theory and algorithms for engineers and scientists
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Nagaty KA, 2001, NEURAL NETWORKS, V14, P1293, DOI 10.1016/S0893-6080(01)00086-7
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Shih FY, 2005, J VIS COMMUN IMAGE R, V16, P115, DOI 10.1016/j.jvcir.2004.05.002
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Stentiford F., 2001, PICTURE CODING S, P24
   Su H, 2008, IEEE IMAGE PROC, P1236, DOI 10.1109/ICIP.2008.4711985
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P247, DOI 10.1109/83.366474
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yin PY, 2006, J VIS COMMUN IMAGE R, V17, P143, DOI 10.1016/j.jvcir.2005.02.002
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 44
TC 13
Z9 14
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 343
EP 358
DI 10.1016/j.jvcir.2011.11.006
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900012
DA 2024-07-18
ER

PT J
AU Liu, F
   Guo, T
   Wu, CK
   Qian, L
AF Liu, Feng
   Guo, Teng
   Wu, ChuanKun
   Qian, Lina
TI Improving the visual quality of size invariant visual cryptography
   scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Visual quality; Size invariant; Secret sharing;
   Thin line problem; Variance; Multi-pixel encryption; Probabilistic
   visual cryptography scheme
ID SECRET-SHARING SCHEME; CONTRAST; IMAGES
AB In order to reduce the pixel expansion of visual cryptography scheme (VCS), many size invariant visual cryptography schemes (SIVCS's) were proposed. However, most of the known SIVCS's have bad visual quality and thin line problems, hence the known SIVCS's are only suitable to encrypt coarse secret images. In this paper, we notice that the variance of the darkness levels of the pixels also reflects the visual quality of the recovered secret image, as well as the average contrast. We verify, analytically and experimentally, the effectiveness of the variance to be a criterion for evaluating the visual quality of the recovered secret image. Furthermore, we propose two multi-pixel encryption size invariant visual cryptography schemes (ME-SIVCS's) which improve the visual quality of the recovered secret image by reducing the variance of the darkness levels. In addition, the proposed ME-SIVCS's can be used to encrypt fine secret images since they avoid some known thin line problems. Experimental results and comparisons are also given to show the effectiveness of the proposed ME-SIVCS's. Finally, we give suggestions on obtaining good visual quality for the recovered secret image. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Liu, Feng; Guo, Teng; Wu, ChuanKun; Qian, Lina] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100864, Peoples R China.
   [Guo, Teng] Chinese Acad Sci, Grad Sch, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Liu, F (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100864, Peoples R China.
EM liufeng@is.iscas.ac.cn; guoteng@is.iscas.ac.cn; ckwu@is.iscas.ac.cn
RI liu, feng/B-3050-2019
FU NSFC [60903210, 61173134]
FX Many thanks to the anonymous reviewers for their valuable comments. This
   work was supported by NSFC Nos. 60903210 and 61173134.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chang C.Y., 2000, THESIS NATL CENTRAL
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   FLOYD RW, 1976, P SID, V17, P75
   Hou Y.C., 2003, J INF TECHNOL, V2, P19
   Hou Y.C., 2004, J INFORM TECHNOLOGY, V4, P95
   Hou YC, 2005, J RES PRACT INF TECH, V37, P179
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Koga H, 2002, LECT NOTES COMPUT SC, V2501, P328
   Krause M, 2003, COMB PROBAB COMPUT, V12, P285, DOI 10.1017/S096354830200559X
   Kuwakado H, 2004, IEICE T FUND ELECTR, VE87A, P1193
   Lin C.H., 2002, THESIS NATL CENTRAL
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu F, 2010, INFORM PROCESS LETT, V110, P241, DOI 10.1016/j.ipl.2010.01.003
   NAOR, 1995, LECT NOTES COMPUT SC, V950, P1
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Wu XY, 2009, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY (ISCSCT 2009), P310
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2011, VISUAL CRYPTOGRAPHY
NR 27
TC 42
Z9 43
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 331
EP 342
DI 10.1016/j.jvcir.2011.11.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900011
DA 2024-07-18
ER

PT J
AU Shaaban, KM
   Omar, NM
AF Shaaban, Khaled M.
   Omar, Nagwa M.
TI 3D information extraction using Region-based Deformable Net for
   monocular robot navigation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robot navigation; Monocular vision; Stereo vision; Correspondence
   problem; Video segmentation; Deformable contours; 3D information
   extraction; Depth information extraction
ID VIDEO SEGMENTATION; OBJECT TRACKING; MOTION; SHAPE
AB This paper extends the Region-based Deformable Net (RbDN) technique described in [1] to extract the 3D information of all the objects in the scene from a single moving camera. The technique is used for segmenting real-time video sequences captured from a single moving camera. The deformation process tracks the changes in the location and the shape of the segments across the frames. These changes along with the camera displacement are used to estimate the 3D information. The algorithm is completely autonomous and does not require pre-knowledge, training, or assumption about the contents of the sequence. It can handle the difficult case where the motion of the camera is parallel to its optical axis. It can also estimate the distances to objects that are more than 100 m away as long as the camera displacement is over 10% of the expected distance to the objects. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Shaaban, Khaled M.] Assiut Univ, Fac Engn, Dept Elect Engn, Assiut, Egypt.
   [Omar, Nagwa M.] Assiut Univ, Fac Comp & Informat, Dept Informat Technol, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Assiut University; Egyptian Knowledge
   Bank (EKB); Assiut University
RP Shaaban, KM (corresponding author), Assiut Univ, Fac Engn, Dept Elect Engn, Assiut, Egypt.
EM kshaaban@hotmail.com; nagwa_omar@hotmail.com
OI Omar, Nagwa/0000-0002-7089-2740
CR Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P575, DOI 10.1109/TCSVT.2005.844447
   Chang CC, 2006, IEEE T IMAGE PROCESS, V15, P2743, DOI 10.1109/TIP.2006.877344
   Chang CK, 2010, IEEE INT C INT ROBOT, P4147, DOI 10.1109/IROS.2010.5649136
   Chen Z., 2006, P IEEE INT C ROB AUT
   Chen ZC, 2009, IEEE T ROBOT, V25, P749, DOI 10.1109/TRO.2009.2017140
   Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Foresti GL, 2004, IEEE T SYST MAN CY C, V34, P325, DOI 10.1109/TSMCC.2003.819701
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Han X, 2003, IEEE T PATTERN ANAL, V25, P755, DOI 10.1109/TPAMI.2003.1201824
   Ho PK, 2000, IEEE T PATTERN ANAL, V22, P215, DOI 10.1109/34.825760
   Jain R., 1995, MACHINE VISION
   Kim SY, 2008, IEEE T BROADCAST, V54, P732, DOI 10.1109/TBC.2008.2002338
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Molloy D., 2000, THESIS DUBLIN CITY U
   Murphey YL, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P122, DOI 10.1109/IVS.2000.898329
   Niethammer M, 2006, IEEE T AUTOMAT CONTR, V51, P562, DOI 10.1109/TAC.2006.872837
   Papandreou G, 2007, IEEE T IMAGE PROCESS, V16, P229, DOI 10.1109/TIP.2006.884952
   Repo T., 2002, MODELING STRUCTURED
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y
   Sakalli M, 2006, IEEE T IMAGE PROCESS, V15, P1182, DOI 10.1109/TIP.2006.871401
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Segvic S, 2009, COMPUT VIS IMAGE UND, V113, P172, DOI 10.1016/j.cviu.2008.08.005
   SHAABAN K, 2004, J ENG SCI, V32, P471
   Shaaban KM, 2009, IMAGE VISION COMPUT, V27, P1504, DOI 10.1016/j.imavis.2009.02.003
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   Stoykova E, 2007, IEEE T CIRC SYST VID, V17, P1568, DOI 10.1109/TCSVT.2007.909975
   Sun SJ, 2003, IEEE T CIRC SYST VID, V13, P75, DOI 10.1109/TCSVT.2002.808089
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Valencia G, 2004, PATTERN RECOGN, V37, P377, DOI 10.1016/S0031-3203(03)00233-4
   Wedel A, 2007, LECT NOTES COMPUT SC, V4713, P264
   Yamaguti N, 1997, SICE '97 - PROCEEDINGS OF THE 36TH SICE ANNUAL CONFERENCE, INTERNATIONAL SESSION PAPERS, P1255, DOI 10.1109/SICE.1997.624999
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang Y.J., 2006, Advances in image and video segmentation
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008
NR 37
TC 4
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 397
EP 408
DI 10.1016/j.jvcir.2011.12.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900016
DA 2024-07-18
ER

PT J
AU Xiao, B
   Ma, JF
   Cui, JT
AF Xiao, Bin
   Ma, Jian-Feng
   Cui, Jiang-Tao
TI Radial Tchebichef moment invariants for image recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Radial Tchebichef moments; Images reconstruction; Image recognition;
   Invariant moments; Orthogonal moments; Polar coordinate; Complex
   moments; Orthogonal Fourier-Mellin moments
ID SCALE INVARIANTS
AB Radial Tchebichef moments as discrete orthogonal moments in the polar coordinate have been successfully used in the field of image recognition. However, the scale invariant property of these moments has not been studied due to its complexity of the problem. In this paper, we present a method to construct a set of scale and rotation invariants extracted from radial Tchebichef moments, named radial Tchebichef moment invariants (RTMI). Experimental results show the efficiency and the robustness to noise of the proposed method for recognition tasks. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Xiao, Bin; Ma, Jian-Feng; Cui, Jiang-Tao] Xidian Univ, Minist Educ, Key Lab Comp Networks & Informat Secur, Xian 710071, Peoples R China.
   [Xiao, Bin] Ningxia Univ, Sch Phys & Elect Informat Engn, Yinchuan 750021, Peoples R China.
C3 Xidian University; Ningxia University
RP Xiao, B (corresponding author), Xidian Univ, Minist Educ, Key Lab Comp Networks & Informat Secur, Xian 710071, Peoples R China.
EM xiaobinic@gmail.com
RI Xiao, Bin/E-2722-2012; Ma, Jianfeng/GZB-0110-2022
FU National Natural Science Foundation of China [61072066, 61173089]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61072066 and 61173089. The authors would like to
   thank the anonymous referees for their valuable comments and
   suggestions.
CR [Anonymous], BUTTERFLY DATABASE
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   Flusser J, 2002, PATTERN RECOGN, V35, P3015, DOI 10.1016/S0031-3203(02)00093-6
   Ghorbel F, 2006, PATTERN RECOGN LETT, V27, P1361, DOI 10.1016/j.patrec.2006.01.001
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Mukundan R, 2004, Proceedings of the Sixth IASTED International Conference on Signal and Image Processing, P80
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 2009, P BRIT MACH VIS C BM
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
   Zhang L, 2007, OPT EXPRESS, V15, P2251, DOI 10.1364/OE.15.002251
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
   Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9
NR 19
TC 27
Z9 29
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 381
EP 386
DI 10.1016/j.jvcir.2011.11.008
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900014
DA 2024-07-18
ER

PT J
AU Zhou, Q
   Wong, KW
   Liao, XF
   Hu, Y
AF Zhou, Qing
   Wong, Kwok-wo
   Liao, Xiaofeng
   Hu, Yue
TI On the security of multiple Huffman table based encryption
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia encryption; Huffman encoding; Cryptographic analysis;
   Pruning; Known-plaintext attack; Ciphertext-only attack; Multiple
   Huffman table; Long-term key; Per-message key
ID COMPRESSION; VIDEO
AB Recently, an encryption algorithm using multiple Huffman tables was proposed to protect multimedia content. Since the encryption operation can be efficiently implemented, its speed is several times faster than AES (Advanced Encryption Standard) or any known stream ciphers. In this paper, the security of this algorithm will be analyzed in detail. It is shown that the key is recovered with one ciphertext and the corresponding plaintext consisting of about 10 blocks of symbols by known-plaintext attack or with thousands of ciphertexts by ciphertext-only attack. Crown Copyright (C) 2010 Published by Elsevier Inc. All rights reserved.
C1 [Zhou, Qing; Liao, Xiaofeng; Hu, Yue] Chongqing Univ, Dept Comp Sci & Engn, Chongqing 400044, Peoples R China.
   [Wong, Kwok-wo] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chongqing University; City University of Hong Kong
RP Zhou, Q (corresponding author), Chongqing Univ, Dept Comp Sci & Engn, Chongqing 400044, Peoples R China.
EM tzhou@cqu.edu.cn; itkwwong@cityu.edu.hk; xfliao@cqu.edu.cn;
   huyue@cqu.edu.cn
RI zhou, qing/D-3005-2013; Liao, Xiaofeng/HPD-6655-2023; Wong,
   Kwok-Wo/K-9442-2015
FU Fundamental Research Funds for the Central Universities [CDJZR10 18 00
   26]
FX The work is supported by the Fundamental Research Funds for the Central
   Universities (Project No. CDJZR10 18 00 26).
CR Agi I., 1996, Proceedings of the Symposium on Network and Distributed System Security, P137, DOI 10.1109/NDSS.1996.492420
   Bose R, 2006, IEEE T CIRCUITS-I, V53, P848, DOI 10.1109/TCSI.2005.859617
   Bourbakis N, 2003, IEEE MULTIMEDIA, V10, P79, DOI 10.1109/MMUL.2003.1218259
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Eskicioglu AM, 2003, COMPUTER, V36, P39, DOI 10.1109/MC.2003.1212689
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Furht B., 2004, MULTIMEDIA SECURITY
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Meyer J., 1995, SECURITY MECH MULTIM
   Podesser M., 2002, 5 NORDIC SIGNAL PROC, P1037
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   SPANOS GA, 1995, 4 INT C COMP COMM NE, P2
   *USC SIPI, 2007, USC SIPI IM DAT
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Yang M, 2004, IEEE POTENTIALS, V23, P28
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
NR 22
TC 4
Z9 4
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 85
EP 92
DI 10.1016/j.jvcir.2010.10.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300008
DA 2024-07-18
ER

PT J
AU García, JA
   Rodriguez-Sánchez, R
   Fdez-Valdivia, J
AF Garcia, J. A.
   Rodriguez-Sanchez, Rosa
   Fdez-Valdivia, J.
TI Relevance of knowledge from bit-saving in progressive transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Prioritization; Progressive transmission; Low-cost bit-reserves;
   Bit-allocation; Sustained improvement; Transmission technology;
   Knowledge from bit-saving; SAVING coder
ID COMPRESSION
AB For progressive transmission, the limited bit-reserves of low transmission cost seem to provide a limit to the growing low-cost bit-allocation and to the sustainable amount of significant coefficients for which we allocate our exhaustible low-cost bit-reserves. Following a bit-saving path in the progressive image transmission, bit streams are prioritized in response to the use of a prioritization protocol, but only a part of the prioritized low-cost bit streams is to be transmitted to the decoder at this time. The level of transmission technology may also be augmented by investing part of the gross income in transmission improvement. The rest of prioritized bit streams, which were not sent to the decoder at their prioritization time, is to be added to a knowledge base from bit-saving.
   It is a bit-saving just reducing the amount of transmitted bits at the present time, but additions to the knowledge base may be transmitted later following an improved transmission technology at higher bit rates. Our aim is to find the paths of transmission, bit-reserves use, and sustained improvement in transmission technology which maximizes utility of future transmission. It uncovers the exact role and relevance of knowledge from bit-saving in the optimal transmission path. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Fdez-Valdivia, J.] CITIC UGR, ETS Ingn Informat, Dept Ciencias Computac & IA, Granada 18071, Spain.
C3 University of Sevilla
RP Fdez-Valdivia, J (corresponding author), CITIC UGR, ETS Ingn Informat, Dept Ciencias Computac & IA, C Periodista Daniel Saucedo Aranda S-N, Granada 18071, Spain.
EM jags@decsai.ugr.es; J.Fedz-Valdivia@decsai.ugr.es
RI Rodriguez Sanchez, Rosa Maria/B-1847-2012; Fdez-Valdivia, J/B-1844-2012;
   Garcia, Jose A./C-1703-2010
OI Rodriguez Sanchez, Rosa Maria/0000-0001-7886-9329; Fdez-Valdivia,
   J/0000-0001-7181-1554; Garcia, Jose A./0000-0001-7742-7270
FU Spanish Board for Science and Technology (CICYT) [TEC2007-60450]
FX This research was sponsored by the Spanish Board for Science and
   Technology (CICYT) under Grant TEC2007-60450.
CR Garcia JA, 2007, OPT ENG, V46, DOI 10.1117/1.2717132
   García JA, 2002, OPT ENG, V41, P2216, DOI 10.1117/1.1496789
   GARCIA JA, 2001, COMPUTATIONAL MODELS, P202
   Garcia JA, 2008, OPT ENG, V47, DOI 10.1117/1.2904824
   Garcia JA, 2007, OPT ENG, V46, DOI 10.1117/1.2802151
   Garcia JA, 2007, OPT ENG, V46, DOI 10.1117/1.2727247
   KEMP MC, 1980, EXHAUSTIBLE RESOURCE, P247
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   Pontryagin L., 1962, MATH THEORY OPTIMAL
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
NR 10
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 741
EP 750
DI 10.1016/j.jvcir.2010.05.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400013
DA 2024-07-18
ER

PT J
AU Setzer, S
   Steidl, G
   Teuber, T
AF Setzer, S.
   Steidl, G.
   Teuber, T.
TI Deblurring Poissonian images by split Bregman techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deblurring; Poisson noise; I-divergence; Kullback-Leibler divergence;
   TV; Alternating split Bregman algorithm; Douglas-Rachford splitting
ID TOTAL VARIATION MINIMIZATION; ALGORITHMS; SCHEMES
AB The restoration of blurred images corrupted by Poisson noise is an important task in various applications such as astronomical imaging, electronic microscopy, single particle emission computed tomography (SPECT) and positron emission tomography (PET). In this paper, we focus on solving this task by minimizing an energy functional consisting of the I-divergence as similarity term and the TV regularization term. Our minimizing algorithm uses alternating split Bregman techniques (alternating direction method of multipliers) which can be reinterpreted as Douglas-Rachford splitting applied to the dual problem. In contrast to recently developed iterative algorithms, our algorithm contains no inner iterations and produces nonnegative images. The high efficiency of our algorithm in comparison to other recently developed algorithms to minimize the same functional is demonstrated by artificial and real-world numerical examples. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Setzer, S.; Steidl, G.; Teuber, T.] Univ Mannheim, Dept Math & Comp Sci, D-68131 Mannheim, Germany.
C3 University of Mannheim
RP Teuber, T (corresponding author), Univ Mannheim, Dept Math & Comp Sci, A5, D-68131 Mannheim, Germany.
EM ssetzer@kiwi.math.uni-mannheim.de; steidl@math.uni-mannheim.de;
   tteuber@kiwi.math.uni-mannheim.de
FU DFG [Ste 571/9-1]
FX T.T. gratefully acknowledges partial support by DFG Grant Ste 571/9-1.
CR Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bratsolis E, 2001, ASTRON ASTROPHYS, V375, P1120, DOI 10.1051/0004-6361:20010709
   Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI [10.1016/0041-5553(67)90040-7, DOI 10.1016/0041-5553(67)90040-7]
   Brune C., COMMUNICATION
   Brune C, 2009, LECT NOTES COMPUT SC, V5567, P235, DOI 10.1007/978-3-642-02256-2_20
   Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chaux C, 2009, SIAM J IMAGING SCI, V2, P730, DOI 10.1137/080727749
   Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264
   Combettes PL, 2004, OPTIMIZATION, V53, P475, DOI 10.1080/02331930412331327157
   CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Esser E, 2009, 0931 CAM UCLA
   FESSLER JA, 1995, IEEE T IMAGE PROCESS, V4, P1417, DOI 10.1109/83.465106
   FIGUEIREDO MAT, 2009, IEEE WORKSH STAT SIG
   Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   Gabay D., 1983, AUGMENTED LAGRANGIAN, V15, P299, DOI DOI 10.1016/S0168-2024(08)70034-1
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Kryvanos A, 2005, P SOC PHOTO-OPT INS, V5674, P432, DOI 10.1117/12.586909
   LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071
   Loris I, 2009, APPL COMPUT HARMON A, V27, P247, DOI 10.1016/j.acha.2009.02.003
   Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5
   Panin VY, 1999, IEEE T NUCL SCI, V46, P2202, DOI 10.1109/23.819305
   REMMELE S, 2008, P WORKSH BILDV MED 2, P72
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sawatzky A., 2008, Nuclear Science Symposium Conference Record, P5133, DOI DOI 10.1109/NSSMIC.2008.4774392
   Setzer S, 2009, LECT NOTES COMPUT SC, V5567, P464, DOI 10.1007/978-3-642-02256-2_39
   Shepp L A, 1982, IEEE Trans Med Imaging, V1, P113, DOI 10.1109/TMI.1982.4307558
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Weiss P, 2009, SIAM J SCI COMPUT, V31, P2047, DOI 10.1137/070696143
   Welk M, 2008, APPL COMPUT HARMON A, V24, P195, DOI 10.1016/j.acha.2007.05.004
   WETS R. J. B., 2004, VARIATIONAL ANAL
NR 35
TC 263
Z9 287
U1 1
U2 44
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 193
EP 199
DI 10.1016/j.jvcir.2009.10.006
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400001
DA 2024-07-18
ER

PT J
AU Koumaras, H
   Lin, CH
   Shieh, CK
   Kourtis, A
AF Koumaras, Harilaos
   Lin, C. -H.
   Shieh, C-K.
   Kourtis, Anastasios
TI A framework for end-to-end video quality prediction of MPEG video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video quality; MPEG; PQoS; Quality of Experience (QoE); Packet loss;
   Frame loss; Prediction; SSIM
ID TRANSMISSION; VISIBILITY
AB This paper proposes, describes and evaluates a novel framework for video quality prediction of MPEG-based video services, considering the perceptual degradation that is introduced by the encoding process and the provision of the encoded signal over an error-prone wireless or wire-line network. The concept of video quality prediction is considered in this work, according to which the encoding parameters of the video service and the network QoS conditions are used for performing an estimation/prediction of the video quality level at the user side, without further processing of the actual encoded and transmitted video content. The proposed prediction framework consists of two discrete models: (i) a model for predicting the video quality of an encoded signal at a pre-encoding stage by correlating the spatiotemporal content dynamics to the bit rate that satisfies a specific level of user satisfaction; and (ii) a model that predicts primarily the undecodable frames (and subsequently the perceived quality degradation caused by them) based on the monitored averaged packet loss ratio of the network. The proposed framework is experimentally tested and validated with video signals encoded according to MPEG-4 standard. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Koumaras, Harilaos; Kourtis, Anastasios] NCSR Demokritos, Inst Informat & Telecommun, Athens, Greece.
   [Lin, C. -H.; Shieh, C-K.] Natl Cheng Kung Univ, Tainan 70101, Taiwan.
   [Koumaras, Harilaos] BCA, Dept Comp Sci, Athens, Greece.
C3 National Centre of Scientific Research "Demokritos"; National Cheng Kung
   University
RP Koumaras, H (corresponding author), NCSR Demokritos, Inst Informat & Telecommun, Athens, Greece.
EM koumaras@iit.demokritos.gr
OI Kourtis, Anastasios/0000-0003-3047-4568
FU ADAMANTIUM Project [FP7 ICT-214751]
FX Part of the work in this paper has been performed within the research
   framework of FP7 ICT-214751 ADAMANTIUM Project (www.ict-adamantium.eu).
   The authors also thank the anonymous reviewers for their constructive
   comments, which help a lot for improving the quality of the paper.
CR [Anonymous], YUV VIDEO SEQUENCES
   [Anonymous], P SPIE
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], NS 2 SIMULATOR
   Cavallaro A, 2004, IEEE IMAGE PROC, P3543
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   EBERT J, 1999, TKN99002 TU BERL
   Engelke U, 2007, 2007 NEXT GENERATION INTERNET NETWORKS, P190, DOI 10.1109/NGI.2007.371215
   FARIAS MCQ, 2002, P IEEE INT C IM PROC, P141
   Ferzli Rony, 2005, P 1 INT WORKSH VID P
   GUNAWAN IP, 2003, LOND COMM S
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P1051, DOI 10.1109/TCSVT.2006.881198
   HEMAMI SS, 2005, P 1 INT WORKSH VID P
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Koumaras H, 2007, MULTIMED TOOLS APPL, V34, P355, DOI 10.1007/s11042-007-0111-1
   Koumaras H, 2005, J COMMUN NETW-S KOR, V7, P235, DOI 10.1109/JCN.2005.6389807
   KOUMARAS H, 2004, P 2 INT C PERF MOD E
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   LIN CH, 2006, P IEEE 20 INT C ADV
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   Liu-ming L., 2007, P 2 WORKSH DIG MED I, P365
   Lotfallah OA, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/42083
   LU L, 2002, P IEEE INT C MULT
   MARICHAL X, 2002, P IEEE INT C IM PROC, P386
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mitchell J.L., 1996, MPEG VIDEO COMPRESSI
   MONTENOVO M, 2006, P 2 INT WORKSH VID P
   Ong E, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P189
   Ou y f, 2009, NOVEL QUALITY METRIC
   Pastrana-Vidal RR, 2004, P SOC PHOTO-OPT INS, V5292, P182, DOI 10.1117/12.525746
   PASTRANAVIDAL RR, 2006, P 2 INT WORKSH VID P
   RIES M, 2007, P IEEE WIR COMM NETW
   RIES M, 2005, P DSPCS 05 WITSP 05, P98
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 41
TC 15
Z9 15
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 139
EP 154
DI 10.1016/j.jvcir.2009.07.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Parameswaran, V
   Kannur, A
   Li, BX
AF Parameswaran, Viswesh
   Kannur, Avin
   Li, Baoxin
TI Adapting quantization offset in multiple description coding for error
   resilient video transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple description coding (MDC); Video streaming; H.264/AVC encoder;
   Error resilient video transmission; Wireless ad hoc networks; Video
   quality; Video over wireless; Quantization offset
ID DESIGN
AB Multiple description coding (MDC) provides an excellent error resilient approach for transmitting video over wireless ad hoc networks. In this paper, we propose an improvement to this scheme by jointly selecting the quantization offsets in different paths to achieve the best overall video quality at the decoder. The statistical distribution of the transform coefficients in the encoded video sequence is parameterized using a Laplacian model. The optimal offset values are computed by solving a multi-level optimization problem based on the statistics of the transform coefficients and the individual path failure probabilities. In order to reduce the computational complexity, the encoding modes for the motion vectors and transform coefficients are collected in the first step. In the second step, the model parameter is calculated from the transform coefficients and the offset search is performed when the model parameter between frames deviates beyond the pre-set threshold. In the final step, the stored modes and the respective offset values are directly used for encoding the two bit streams. The simulation results using H.264/AVC system confirm the advantages of the proposed approach under different packet loss conditions. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Parameswaran, Viswesh; Kannur, Avin; Li, Baoxin] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85281 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Li, BX (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85281 USA.
EM vparames@asu.edu; akannur@asu.edu; baoxin.li@asu.edu
FU ARO [W911NF-06-1-0354]
FX This research was supported in part by ARO Grant W911NF-06-1-0354. The
   information reported here does not reflect the position or the policy of
   the federal government.
CR Altunbasak Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P177
   [Anonymous], P MIL COMM C
   Ayanoglu E, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P833, DOI [10.1007/BF01193259, 10.1109/ICIP.1996.561034]
   Bernardini R., 2005, Proceedings. DCC 2006. Data Compression Conference
   ELLIOTT EO, 1965, P BSTJ JAN, P44
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Ha VHS, 2005, IEEE ICCE, P255, DOI 10.1109/ICCE.2005.1429814
   HENG B, 2006, EURASIP J APPL SIG P, V5, P12
   *ITU T, 2003, H264 ITUT
   Jafarkhani H, 1999, IEEE T COMMUN, V47, P799, DOI 10.1109/26.771331
   KONDI L, 2000, P SPIE C VIS COMM IM, P108
   Lakhani G, 2000, IEEE T CIRC SYST VID, V10, P819, DOI 10.1109/76.856460
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee YC, 2005, IEEE T CIRC SYST VID, V15, P457, DOI 10.1109/TCSVT.2005.844446
   MA S, 2005, IEEE T CIRCUITS SYST, V15, P533
   OGUZ NC, 1995, IEEE INFOCOM SER, P728
   PARAMESWARAN V, 2007, P IEEE MIL COMM C OC, P1
   REIBMAN AR, 2002, P 12 INT PACK VID WO
   RICHARDSON I, 2003, VOCDEX H 264 TUTORIA
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   VAISHAMPAYAN VA, 1994, IEEE T INFORM THEORY, V40, P245, DOI 10.1109/18.272491
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Vaishampayan VA, 2001, IEEE T INFORM THEORY, V47, P1718, DOI 10.1109/18.930913
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   WANG Y, 2002, BOOK VIDEO PROCESSIN
   WEDI T, 2005, P IEEE INT S CIRC SY
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yap CW, 1999, SIGNAL PROCESS-IMAGE, V14, P559, DOI 10.1016/S0923-5965(98)00058-7
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 30
TC 4
Z9 6
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2009
VL 20
IS 7
BP 491
EP 503
DI 10.1016/j.jvcir.2009.07.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 559DJ
UT WOS:000274800800005
DA 2024-07-18
ER

PT J
AU Bryt, O
   Elad, M
AF Bryt, Ori
   Elad, Michael
TI Compression of facial images using the K-SVD algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image compression; sparse representations; redundancy; K-SVD; OMP;
   facial images; PCA; JPEG; JPEG2000; VQ
ID OVERCOMPLETE DICTIONARIES; VECTOR QUANTIZATION; SPARSE
AB The use of sparse representations in signal and image processing is gradually increasing in the past several years. Obtaining an overcomplete dictionary from a set of signals allows us to represent them as a sparse linear combination of dictionary atoms. Pursuit algorithms are then used for signal decomposition. A recent work introduced the K-SVD algorithm, which is a novel method for training overcomplete dictionaries that lead to sparse signal representation. In this work we propose a new method for compressing facial images, based on the K-SVD algorithm. We train K-SVD dictionaries for predefined image patches, and compress each new image according to these dictionaries. The encoding is based on sparse coding of each image patch using the relevant trained dictionary, and the decoding is a simple reconstruction of the patches by linear combination of atoms. An essential pre-process stage for this method is an image alignment procedure, where several facial features are detected and geometrically warped into a canonical spatial location. We present this new method, analyze its results and compare it to several competing compression techniques. (c) 2008 Published by Elsevier Inc.
C1 [Elad, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Technion, Haifa, Israel.
   [Bryt, Ori] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
C3 Technion Israel Institute of Technology; Technion Israel Institute of
   Technology
RP Elad, M (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, Taub Bldg,Off 516, IL-32000 Technion, Haifa, Israel.
EM stinger@cs.technion.ac.il; elad@cs.technion.ac.il
RI , Miki/AAH-4640-2019
CR Aharon M, 2006, LINEAR ALGEBRA APPL, V416, P48, DOI 10.1016/j.laa.2005.06.035
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Cosman PC, 1996, IEEE T IMAGE PROCESS, V5, P202, DOI 10.1109/83.480760
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   DONOHO DL, 2007, IEEE T INFORM THEORY, V147, P185
   Elad M, 2007, IEEE T IMAGE PROCESS, V16, P2379, DOI 10.1109/TIP.2007.903259
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   FERREIRA AJ, 2003, P IEEE 13 WORKSH NEU, P17
   FERREIRA AJ, 2003, P INT C IM PROC ICIP, P14
   Ferreira AJ, 2006, SIGNAL PROCESS-IMAGE, V21, P378, DOI 10.1016/j.image.2006.01.002
   Gerek ON, 2004, SIGNAL PROCESS, V84, P1041, DOI 10.1016/j.sigpro.2004.03.007
   Gersho A., 2003, Vector Quantization and Signal Compression
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Hazan T, 2005, IEEE I CONF COMP VIS, P50
   Hu JH, 1996, OPT ENG, V35, P198, DOI 10.1117/1.600878
   Huang JC, 1999, IEEE T IMAGE PROCESS, V8, P102, DOI 10.1109/83.736696
   Inoue K., 2005, P IEEE INT S CIRC SY, P23
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MOGHADDAM B, 1995, P DCC 95 DAT COMPR C, P28
   PATI YC, 1993, C REC 27 AS C SIGN S
   Peotta L, 2006, SIGNAL PROCESS, V86, P444, DOI 10.1016/j.sigpro.2005.05.023
   QIUYU Z, 2005, P PAC RIM C COMM COM, P24
   Sakalli M, 1999, COMPUT VIS IMAGE UND, V75, P269, DOI 10.1006/cviu.1999.0776
   Sakalli M, 1998, OPT ENG, V37, P1520, DOI 10.1117/1.601667
   SAKALLI M, 1998, P 14 INT C PATT REC, P16
   Shashkov A.T., 2001, Eurasian Borderland, P8
   Taubman D., 2012, JPEG2000: image compression fundamentals, standards and practice, V642
   Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
NR 34
TC 214
Z9 256
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2008
VL 19
IS 4
BP 270
EP 282
DI 10.1016/j.jvcir.2008.03.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 311MK
UT WOS:000256604100005
DA 2024-07-18
ER

PT J
AU Chung, KL
   Liao, PH
   Chang, JM
AF Chung, Kuo-Liang
   Liao, Po-Hsuan
   Chang, Jia-Ming
TI Novel efficient two-pass algorithm for closed polygonal approximation
   based on LISE and curvature constraint criteria
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE algorithm; closed curve; closed polygonal approximation algorithm;
   curvature; local integral square error; shortest path algorithm
ID PIECEWISE LINEAR-APPROXIMATION; DIGITAL CURVES; DOMINANT POINTS;
   DIGITIZED-CURVES
AB Given a closed curve with n points, based on the local integral square error and the curvature constraint criteria, this paper presents a novel two-pass O(Fn + mn(2))-time algorithm for solving the closed polygonal approximation problem where m(<< n) denotes the minimal number of covering feasible segments for one point and empirically the value of m is rather small, and F (<< n(2)) denotes the number of feasible approximate segments. Based on some real closed curves, experimental results demonstrate that under the same number of segments used, our proposed two-pass algorithm has better quality and execution-time performance when compared to the previous algorithm by Chung et al. Experimental results also demonstrate that under the same number of segments used, our proposed two-pass algorithm has better quality, but has some execution-time degradation when compared to the currently published algorithms by Wu and Sarfraz et al. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Chung, Kuo-Liang; Liao, Po-Hsuan; Chang, Jia-Ming] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM k.l.chung@mail.ntust.edu.tw
RI Chang, Jia-Ming/A-5642-2008; Chung, Kuo-Liang/H-6207-2011
OI Chang, Jia-Ming/0000-0002-6711-1739; 
CR Chung KL, 2002, PATTERN RECOGN, V35, P2539, DOI 10.1016/S0031-3203(01)00226-6
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Horng JH, 2002, PATTERN RECOGN LETT, V23, P171, DOI 10.1016/S0167-8655(01)00098-8
   Hu JM, 1997, PATTERN RECOGN, V30, P701, DOI 10.1016/S0031-3203(96)00105-7
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   Jordan CL, 1998, COMPUT VIS IMAGE UND, V71, P198, DOI 10.1006/cviu.1998.0707
   Mayster Y, 2006, J VIS COMMUN IMAGE R, V17, P1178, DOI 10.1016/j.jvcir.2006.04.002
   MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PIKAZ A, 1995, PATTERN RECOGN, V28, P373, DOI 10.1016/0031-3203(94)00108-X
   RAY BK, 1994, PATTERN RECOGN LETT, V15, P161, DOI 10.1016/0167-8655(94)90045-0
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SATO Y, 1992, PATTERN RECOGN, V25, P1535, DOI 10.1016/0031-3203(92)90126-4
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   WU WY, 1993, CVGIP-GRAPH MODEL IM, V55, P79, DOI 10.1006/cgip.1993.1006
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Zhu Y, 1997, IEE P-VIS IMAGE SIGN, V144, P8, DOI 10.1049/ip-vis:19970985
NR 18
TC 5
Z9 6
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2008
VL 19
IS 4
BP 219
EP 230
DI 10.1016/j.jvcir.2008.01.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 311MK
UT WOS:000256604100001
DA 2024-07-18
ER

PT J
AU Aujol, JF
   Chan, TF
AF Aujol, Jean-Francois
   Chan, Tony F.
TI Combining geometrical and textured information to perform image
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE classification; texture; geometrical image; decomposition; logic model;
   level-set; active contour; PDE; wavelets
ID TOTAL VARIATION MINIMIZATION; LEVEL SET APPROACH; ACTIVE CONTOURS; NOISE
   REMOVAL; SEGMENTATION; DECOMPOSITION; MODEL; REPRESENTATION; FRAMEWORK;
   MUMFORD
AB In this paper, we propose a framework to carry out supervised classification of images containing both textured and non textured areas. Our approach is based on active contours. Using a decomposition algorithm inspired by the recent work of Y. Meyer, we can get two channels from the original image to classify: one containing the geometrical information, and the other the texture. Using the logic framework by Chan and Sandberg, we can then combine the information from both channels in a user definable way. Thus, we design a classification algorithm in which the different classes are characterized both from geometrical and textured features. Since natural images are combinations of both textured and non textured patterns, this integrative approach enlarges the scope of possible applications for active contours-based classification algorithms. (c) 2006 Elsevier Inc. All rights reserved.
C1 ENS, CMLA, CNRS, UMR 8536, F-94235 Cachan, France.
   Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - National
   Institute for Mathematical Sciences (INSMI); Universite Paris Saclay;
   University of California System; University of California Los Angeles
RP Aujol, JF (corresponding author), ENS, CMLA, CNRS, UMR 8536, Ave President Wilson, F-94235 Cachan, France.
EM aujol@cmla.ens-cachan.fr; chan@math.ucla.edu
RI Aujol, Jean-Francois/AHC-7262-2022; cai, bo/G-1491-2010; Chan,
   Tony/IQW-1869-2023; Chan, Tony F/A-4166-2013
OI Aujol, Jean-Francois/0000-0001-6716-0509; Chan, Tony
   F/0000-0001-6196-2068
CR Ambrosio L., 2000, OX MATH M, pxviii, DOI 10.1017/S0024609301309281
   [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   [Anonymous], 2002, MATH PROBLEMS IMAGE
   Aubert G, 2005, APPL MATH OPT, V51, P163, DOI 10.1007/s00245-004-0812-z
   AUBERT G, 4507 INRIA
   AUJOL J.-F., 2005, APPL ANAL, V84, P15
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Aujol JF, 2003, IEEE T IMAGE PROCESS, V12, P1634, DOI 10.1109/TIP.2003.819309
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   AUJOL JF, 2004, ACIVS
   AUJOL JF, 2006, J VIS COMMUN IMAGE R
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6
   BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898
   Brox T, 2004, LECT NOTES COMPUT SC, V3022, P578
   BROX T, 2004, LECT NOTES COMPUTER, V3175
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   CHAN T, 2005, 0518 CAM
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108
   Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855
   Cremers D, 2003, IMAGE VISION COMPUT, V21, P77, DOI 10.1016/S0262-8856(02)00128-2
   Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915
   Daubechies I, 2005, APPL COMPUT HARMON A, V19, P1, DOI 10.1016/j.acha.2004.12.004
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249
   Fjortoft R, 1998, IEEE T GEOSCI REMOTE, V36, P793, DOI 10.1109/36.673672
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   GALUN M, 2003, ICCV 03
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   JEHANBESSON S, EURASIP J APPL SIGNA
   KATO Z, 1994, THESIS U NICE SOPHIA
   LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443
   Le TM, 2005, MULTISCALE MODEL SIM, V4, P390, DOI 10.1137/040610052
   LEMARECHAL C, 1998, P SAR IMAG AN MOD TE
   MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046
   Meyer Y., 2001, 15 DEAN JACQ B LEW M
   MOELICH M, 2003, 0306 CAM
   Osher S, 2001, J COMPUT PHYS, V169, P463, DOI 10.1006/jcph.2000.6636
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   PARAGIOS N, INT J COMPUT VISION, V46
   Patwardhan KA, 2004, IEEE IMAGE PROC, P645
   PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Rousson M, 2003, PROC CVPR IEEE, P699
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003
   Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594
   Sandberg B, 2005, J VIS COMMUN IMAGE R, V16, P333, DOI 10.1016/j.jvcir.2004.08.005
   SANDBERG BY, 2002, 0239 CAM
   Shen JH, 2005, APPL MATH RES EXPRES, P143, DOI 10.1155/AMRX.2005.143
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   STRONG D, 2006, IN PRESS SIAM J
   Sumengen B, 2006, IEEE T PATTERN ANAL, V28, P509, DOI 10.1109/TPAMI.2006.76
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   Unal G, 2005, INT J COMPUT VISION, V62, P199, DOI 10.1007/s11263-005-4880-6
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234
   YIN W, 2005, LECT NOTES COMPUTER, V3752, P61
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   ZHU SC, IEEE T PATTERN ANAL, V18
   Zibulski M, 1997, APPL COMPUT HARMON A, V4, P188, DOI 10.1006/acha.1997.0209
NR 70
TC 33
Z9 38
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1004
EP 1023
DI 10.1016/j.jvcir.2006.02.001
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700005
DA 2024-07-18
ER

PT J
AU Kung, WY
   Kim, CS
   Kuo, CCJ
AF Kung, WY
   Kim, CS
   Kuo, CCJ
TI Packet video transmission over wireless channels with adaptive channel
   rate allocation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE packet video; wireless video; robust video transmission; joint
   source-channel coding; unequal error protection
ID ROBUST IMAGE
AB A robust video communication system based on layered coding and unequal error protection is developed in this work. We consider two video communication scenarios. First, for pre-compressed video bitstreams, a channel code rate allocation scheme is proposed to minimize the expected mean square error subject to a constraint on the overall bit budget. Second, for real-time video transmission, we jointly optimize the quantization parameters and the channel coding rates according to channel conditions. To this end, we develop a simple rate-distortion model for general video coders using DCT and motion compensation, so that the rate and the distortion can be estimated without an expensive encoding procedure. Simulation results Show that the proposed algorithms provide acceptable image quality even in high bit error rate environments. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ So Calif, Dept Elect Engn, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.
C3 University of Southern California; Chinese University of Hong Kong
RP Univ So Calif, Dept Elect Engn, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
EM weiyingk@ieee.org; cskim@ieee.org; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Bystrom M, 2000, IEEE IMAGE PROC, P359, DOI 10.1109/ICIP.2000.900969
   Cheung G, 2000, IEEE T IMAGE PROCESS, V9, P340, DOI 10.1109/83.826773
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Gallant M, 2001, IEEE T CIRC SYST VID, V11, P357, DOI 10.1109/76.911161
   Gharavi H, 1999, P IEEE, V87, P1751, DOI 10.1109/5.790635
   Gharavi H, 2002, IEEE T CIRC SYST VID, V12, P77, DOI 10.1109/76.988655
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   Hang HM, 1997, IEEE T CIRC SYST VID, V7, P287
   He Z, 2001, IEE P-VIS IMAGE SIGN, V148, P398, DOI 10.1049/ip-vis:20010320
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   Heinzelman W. R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P530, DOI 10.1109/ICIP.1999.822952
   Hochwald B, 1997, IEEE T INFORM THEORY, V43, P1412, DOI 10.1109/18.623141
   HSU CY, 1999, IEEE J SEL AREA COMM, V17, P1
   *ISO IEC, 1998, 144962 ISO IEC
   Ji Z, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P447, DOI 10.1109/MMSP.2001.962774
   Kondi LP, 2001, IEEE IMAGE PROC, P994, DOI 10.1109/ICIP.2001.959215
   KONDI LP, 2001, P IEEE INT C AC SPEE, V3, P1377
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Li HZ, 2001, IEEE T CIRC SYST VID, V11, P1183, DOI 10.1109/76.964785
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   WEI LF, 1993, IEEE T COMMUN, V41, P1439, DOI 10.1109/26.237878
   YANG KH, 2001, P ICIP, P534
   YANG KH, 1997, P INT C IM PROC SANT, V2, P41
   ZHANG Q, 2001, P IEEE INT S CIRC SY, V5, P137
   Zheng HT, 1999, IEEE T MULTIMEDIA, V1, P88, DOI 10.1109/6046.748174
NR 28
TC 3
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 475
EP 498
DI 10.1016/j.jvcir.2005.03.005
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600006
DA 2024-07-18
ER

PT J
AU Hsia, SC
AF Hsia, SC
TI A fast efficient restoration algorithm for high-noise image filtering
   with adaptive approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE median filter; adaptive algorithm; impulse noise; signal processing
ID IMPULSE NOISE; REMOVAL
AB The video signal is easily interfered by noise over the wireless system. The well-known "median filter" and its modified methods could completely remove the impulse noise when the ratio of noise/image is low. However, if the noise ratio becomes high, the filtering performance degrades seriously. In this study, an adaptive algorithm is proposed to reduce the impulse noise for high noise images. To avoid filtering image edges, the noise reduction ability is adaptive according to the image content. The main techniques include the adaptive noise detection and the non-linear low-pass filter. Experimental results show that the proposed method is capable to provide a better picture quality than the median filters and which is faster than alternatives. (C) 2004 Elsevier Inc. All rights reserved.
C1 Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung, Taiwan.
C3 National Kaohsiung University of Science & Technology
RP Hsia, SC (corresponding author), Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung, Taiwan.
EM hsia@ccms.nkfust.edu.tw
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   [Anonymous], 1992, R. woods digital image processing
   BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247
   Hsia SC, 2000, INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P265, DOI 10.1109/MMSE.2000.897221
   Huang SJ, 1997, IEEE SYS MAN CYBERN, P3142, DOI 10.1109/ICSMC.1997.633077
   JUAN CJ, 1995, IEEE T CONSUM ELECTR, V41, P73, DOI 10.1109/30.370312
   Kong H, 1998, IEEE T CIRCUITS-II, V45, P422, DOI 10.1109/82.664255
   LIN HM, 1988, IEEE T CIRCUITS SYST, V35, P675, DOI 10.1109/31.1805
   NODES TA, 1982, IEEE T ACOUST SPEECH, V30
   QIAN C, 1996, P ICSP 96, P606
   QIN G, 1996, IEEE T IMAGE PROCESS, V5, P646
   WANG T, 1994, ACOUSTIC SPEECH SIGN, P425
   WANG Z, 1998, IEEE SIGNAL PROCESS, V5
   Windyga PS, 2001, IEEE T IMAGE PROCESS, V10, P173, DOI 10.1109/83.892455
   ZHANG Q, 1995, IEEE T CONSUM ELECTR, V41, P731, DOI 10.1109/30.468016
NR 15
TC 13
Z9 18
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 379
EP 392
DI 10.1016/j.jvcir.2004.09.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500008
DA 2024-07-18
ER

PT J
AU Bradley, AP
   Stentiford, FWM
AF Bradley, AP
   Stentiford, FWM
TI Visual attention for region of interest coding in JPEG 2000
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image compression; JPEG 2000; region of interest; visual attention; two
   alternative forced choice visual trial
AB This paper details work undertaken on the application of an algorithm for visual attention (VA) to region of interest (ROI) coding in JPEG 2000 (JP2K). In this way, an "interest ordered" progressive bit-stream is produced where the regions highlighted by the VA algorithm are presented first in bit-stream. The paper briefly outlines the terminology used in JP2K, the packet structure of the bit-stream, and the methods available to achieve ROI coding in JP2K (tiling, coefficient scaling, and code-block selection). The paper then describes how the output of the VA algorithm is post-processed so that an ROI is produced that can be efficiently coded using coefficient scaling in JP2K. Finally, a two alternative forced choice (2AFC) visual trial is undertaken to compare the visual quality of images encoded using the proposed VA ROI algorithm and conventional JP2K. The experimental results show that, while there is no overall preference for the VA ROI encoded images; there is an improvement in perceived image quality at low bit rates (below 0.25 bits per pixel). It is concluded that an overall increase in image quality only occurs when the increase in quality of the ROI more than compensates for the decrease in quality of the image background (i.e., non-ROI). (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Univ Queensland, Cooperat Res Ctr Sensor Signal & Informat Proc, CSSIP, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia.
   UCL, Ipswich, Suffolk, England.
C3 University of Queensland; University of London; University College
   London
RP Univ Queensland, Cooperat Res Ctr Sensor Signal & Informat Proc, CSSIP, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia.
EM A.Bradley@cssip.uq.edu.au
RI Bradley, Andrew P./C-5685-2009; Bradley, Andrew P./O-8516-2019
OI Bradley, Andrew P./0000-0003-0109-6844; Bradley, Andrew
   P./0000-0003-0109-6844
CR Bradley A.P., 2002, JPEG 2000 REGION INT, P303
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cruz D. S., 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P389, DOI 10.1109/MMSP.1999.793870
   Daly S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P443, DOI 10.1109/ICIP.1998.727233
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   *MATHW INC, 1999, MATL US GUID STAT TO
   Pennebaker W.B., 1993, JPEG: Still Image Compression Standard
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   STENTIFORD FWM, 2001, ESTIMATOR VISUAL ATT, P101
   STENTIFORD FWM, 2001, EVOLUTIONAR PROGRAMM
   Taubman D.S., 2001, JPEG 2000: Image Compression Fundamentals, Standards and Practice
NR 12
TC 41
Z9 48
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 232
EP 250
DI 10.1016/S1047-3203(03)00037-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, ZN
   Liu, T
   Yan, B
   Pan, JS
   Yang, HM
AF Liu, Zi-Nan
   Liu, Tao
   Yan, Bin
   Pan, Jeng-Shyang
   Yang, Hong-Mei
TI Multitone reconstruction visual cryptography based on phase periodicity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Grayscale image; Visual cryptography; Phase periodicity; Light
   polarization
ID QUALITY
AB The current no-computation grayscale image visual cryptography (VC) can only achieve halftone reconstruction but cannot truly achieve multitone. To solve this problem, we propose the concept of phase periodicity of the 2/2 retarder film and calculate the optical axis angle set with phase periodicity. According to the phase periodicity, we propose a 2/2 retarder film phase periodicity visual cryptography (RPP-VC). In RPP-VC, the secret pixels are encoded as the optical axis angles of n 2/2 retarder films and distributed to n shares. The decoding process does not require computation. The reconstructed image has no pixel expansion and can reach up to 23 tones. The quality of the reconstructed images has been greatly improved and the evaluation indicators of perceived quality are nearly doubled compared with other grayscale image VC schemes. The experimental results verify the feasibility of RPP-VC.
C1 [Liu, Zi-Nan; Yan, Bin] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
   [Liu, Tao; Pan, Jeng-Shyang; Yang, Hong-Mei] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
EM zinanliu1024@163.com; taoliu0201@163.com; yanbinhit@sdust.edu.cn;
   jengshyangpan@gmail.com; yhm1998@163.com
RI Liu, Tao/AAB-4111-2019; Pan, Jeng-Shyang/AEO-3450-2022
OI Liu, Tao/0000-0001-5917-8303; Pan, Jeng-Shyang/0000-0002-3128-9025
FU Shandong Provincial Natural Science Foundation, China [ZR2021MF050]; MOE
   (Ministry of Educa-tion in China) Project of Humanities and Social
   Sciences [18YJAZH110]; National Statistics Science Project [2021LY082]
FX Acknowledgments This work was funded by the Shandong Provincial Natural
   Science Foundation, China (No. ZR2021MF050) , the MOE (Ministry of
   Educa-tion in China) Project of Humanities and Social Sciences (Project
   No. 18YJAZH110) , and the National Statistics Science Project
   (2021LY082) .
CR [Anonymous], 2014, J INF HIDING MULTIME
   Biham E., 1998, P WEIZM WORKSH CRYPT, P1
   Blesswin AJ, 2022, WIRELESS PERS COMMUN, V122, P3085, DOI 10.1007/s11277-021-09041-7
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Ding Haiyang, 2018, [The Journal of China Universities of Posts and Telecommunications, 中国邮电高校学报], V25, P60
   FLOYD RW, 1976, P SID, V17, P75
   Gerrard A., 1994, Introduction to matrix methods in optics
   Hecht E., 1987, Optics, V2nd
   Imagawa T, 2009, JPN J APPL PHYS, V48, DOI 10.1143/JJAP.48.09LC02
   Joy Jo-Yi Chang, 2010, 2010 10th International Symposium on Communications and Information Technologies (ISCIT 2010), P458, DOI 10.1109/ISCIT.2010.5664885
   Lee CC, 2014, J VISUAL LANG COMPUT, V25, P243, DOI 10.1016/j.jvlc.2013.11.001
   Li P, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103513
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Liu SM, 2022, MULTIMED TOOLS APPL, V81, P43125, DOI 10.1007/s11042-022-13187-2
   Liu T, 2022, MACROMOL RAPID COMM, V43, DOI 10.1002/marc.202200538
   Liu YL, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/4617885
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Pan JS, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103405
   Pedrotti F. L., 2017, Introduction to optics
   Saleh B. E. A., 2019, FUNDAMENTALS PHOTONI
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2013, IEEE T CIRC SYST VID, V23, P414, DOI 10.1109/TCSVT.2012.2204940
   Sun R., 2020, IEEE ACCESS, V8
   Tuyls P., 2002, IACR EPRINT ARCH
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yamamoto H, 2010, PROC SPIE, V7542, DOI 10.1117/12.839399
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 30
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103827
DI 10.1016/j.jvcir.2023.103827
EA APR 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G5VI8
UT WOS:000989828000001
DA 2024-07-18
ER

PT J
AU Barajas-Solano, C
   Ramirez, JM
   Torre, JIM
   Arguello, H
AF Barajas-Solano, Crisostomo
   Ramirez, Juan-Marcos
   Torre, Jose Ignacio Martinez
   Arguello, Henry
TI Compressive Spectral Video Sensing using the Convolutional Sparse Coding
   framework CSC4D
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive spectral video sensing; Convolutional sparse coding; Sparse
   representation; Spectral videos
ID APERTURE DESIGN
AB Spectral Videos (SV) contain a scene's spatial-spectral-time information. Just as with Spectral Images (SI), SVs require expensive sensing hardware, storage plus high frame ratios. Although Super Resolution techniques improve the quality of low-resolution SVs, Compressive Spectral Video Sensing (CSVS) senses high-quality SVs by extending the Compressive Sensing Image (CSI) techniques. CSI uses the universal Sparse Signal Representation (SSR) model for SVs and SIs despite the limited quality of the recovered signals. On the other hand, dictionaries synthesis models are used successfully for representing SIs, SVs, and in CSI. This work proposes the 4D convolutional sparse representation (CSC4D) for recovering full-resolution SV from CSVS measurements. It is based on a multidimensional formulation of the CSC model, profiting from its robustness without additional optical flow information. Extensive numerical simulations (two CSI architectures and noise models) show that the proposed CSC4D+CSVS improves the state-of-the-art in both quality and border sharpness by up to 1.5 dB.
C1 [Barajas-Solano, Crisostomo; Arguello, Henry] Univ Ind Santander, Santander, Colombia.
   [Ramirez, Juan-Marcos] Inst IMDEA Networks, Madrid, Spain.
   [Torre, Jose Ignacio Martinez] Univ Rey Juan Carlos, Madrid, Spain.
C3 Universidad Industrial de Santander; Universidad Rey Juan Carlos
RP Arguello, H (corresponding author), Univ Ind Santander, Santander, Colombia.
EM henarfu@uis.edu.co
RI Ramirez, Juan/ABH-7334-2020; MT, JI/KVC-1396-2024
OI Ramirez, Juan/0000-0003-0000-1073; MT, JI/0000-0002-5261-5352
FU  [785]
FX Acknowledgment Ph.D. (c) Crisostomo Barajas-Solano is supported by the
   Minciencias scholarship #785.
CR Arce GR, 2014, IEEE SIGNAL PROC MAG, V31, P105, DOI 10.1109/MSP.2013.2278763
   Arguello H, 2013, IEEE T IMAGE PROCESS, V22, P941, DOI 10.1109/TIP.2012.2222899
   Banerjee A., 2009, 1 WORKSHOP HYPERSPEC
   Barajas-Solano C., 2019, OPTICAL SENSORS SENS, V2019, DOI [10.1364/hise.2019.htu3b.5, DOI 10.1364/HISE.2019.HTU3B.5]
   Barajas-Solano C., 2020, DATA COMPRESSION C
   Barajas-Solano C, 2019, SYMP IMAG SIG PROC A, DOI 10.1109/stsiva.2019.8730285
   Barajas-Solano C, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102690
   Barducci A., 2012, INT C SPACE OPTICS I
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Buttingsrud B, 2006, CHEMOMETR INTELL LAB, V84, P62, DOI 10.1016/j.chemolab.2006.04.014
   Cao X, 2016, IEEE SIGNAL PROC MAG, V33, P95, DOI 10.1109/MSP.2016.2582378
   Cheng SY, 2007, COMPUT VIS IMAGE UND, V106, P245, DOI 10.1016/j.cviu.2006.08.010
   Correa Claudia V., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7789, DOI 10.1109/ICASSP.2014.6855116
   Correa CV, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.4.041309
   Correa CV, 2015, J OPT SOC AM A, V32, P1754, DOI 10.1364/JOSAA.32.001754
   Galvis L, 2017, APPL OPTICS, V56, P6332, DOI 10.1364/AO.56.006332
   Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686
   HENDERSON HV, 1981, SIAM REV, V23, P53, DOI 10.1137/1023004
   Hinojosa C, 2018, IEEE J-STSP, V12, P1589, DOI 10.1109/JSTSP.2018.2878293
   Kwan C, 2017, INT CONF ACOUST SPEE, P6180, DOI 10.1109/ICASSP.2017.7953344
   Leitner R, 2013, PATTERN RECOGN LETT, V34, P85, DOI 10.1016/j.patrec.2012.07.020
   León-López KM, 2019, IEEE T IMAGE PROCESS, V28, P253, DOI 10.1109/TIP.2018.2867171
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Manolakis D., 2003, Lincoln Laboratory Journal, V14, P79
   Papyan V, 2018, IEEE SIGNAL PROC MAG, V35, P72, DOI 10.1109/MSP.2018.2820224
   Papyan V, 2017, IEEE T SIGNAL PROCES, V65, P5687, DOI 10.1109/TSP.2017.2733447
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   Sellar RG, 2005, OPT ENG, V44, DOI 10.1117/1.1813441
   Shaw G. A., 2003, Lincoln Laboratory Journal, V14, P3
   Van Nguyen H., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, P44
   Wang YQ, 2018, IEEE T IMAGE PROCESS, V27, P4850, DOI 10.1109/TIP.2018.2842152
   Wohlberg B, 2016, IEEE IMAGE PROC, P1833, DOI 10.1109/ICIP.2016.7532675
   Wohlberg B, 2016, IEEE SW SYMP IMAG, P57, DOI 10.1109/SSIAI.2016.7459174
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Yi DR, 2011, IEEE PHOTONIC TECH L, V23, P606, DOI 10.1109/LPT.2011.2116153
   Yuan X, 2015, IEEE J-STSP, V9, P964, DOI 10.1109/JSTSP.2015.2411575
   Zuzak K.J., 2013, P INT C SENSING TECH, P145
NR 38
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103782
DI 10.1016/j.jvcir.2023.103782
EA FEB 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9V4IC
UT WOS:000948357200001
DA 2024-07-18
ER

PT J
AU Li, PC
   Gai, S
AF Li, Pengcheng
   Gai, Shan
TI Single image deraining using multi-scales context information and
   attention network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deraining; Convolutional neural network; Attention mechanism;
   Depthwise separable convolution; Feature fusion
ID RAIN STREAKS; REMOVAL
AB The existing deraining methods based on convolutional neural networks (CNNs) have made great success, but some remaining rain streaks can degrade images drastically. In this work, we proposed an end-to-end multi-scale context information and attention network, called MSCIANet. The proposed network consists of multi-scale feature extraction (MSFE) and multi-receptive fields feature extraction (MRFFE). Firstly, the MSFE can pick up features of rain streaks in different scales and propagate deep features of the two layers across stages by skip connections. Secondly, the MRFFE can refine details of the background by attention mechanism and the depthwise separable convolution of different receptive fields with different scales. Finally, the fusion of these outputs of two subnetworks can reconstruct the clean background image. Extensive experimental results have shown that the proposed network achieves a good effect on the deraining task on synthetic and real-world datasets. The demo can be available at https://github.com/CoderLi365/MSCIANet.
C1 [Li, Pengcheng; Gai, Shan] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Jiangxi, Peoples R China.
C3 Nanchang Hangkong University
RP Gai, S (corresponding author), Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Jiangxi, Peoples R China.
EM gaishan@nchu.edu.cn
RI Li, Pengcheng/HJG-7296-2022
OI Li, Pengcheng/0000-0002-1685-3804
FU National Natural Science Foundation of China [62061032]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62061032.
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Chang Y, 2017, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2017.191
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Du YJ, 2020, IEEE T IMAGE PROCESS, V29, P6288, DOI 10.1109/TIP.2020.2990606
   Feng TT, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMMUNICATION, IMAGE AND SIGNAL PROCESSING (CCISP 2020), P145, DOI [10.1109/ccisp51026.2020.9273507, 10.1109/CCISP51026.2020.9273507]
   Fu X., 2021, 35 AAAI C ART INT AA
   Fu XY, 2021, INT J COMPUT VISION, V129, P1691, DOI 10.1007/s11263-020-01428-6
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Garg K., 2004, P 2004 IEEE COMP SOC
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XW, 2019, PROC CVPR IEEE, P8014, DOI 10.1109/CVPR.2019.00821
   Huang HB, 2021, INT J COMPUT VISION, V129, P1282, DOI 10.1007/s11263-020-01421-z
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Islam MR, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P425, DOI 10.1109/dicta47822.2019.8946080
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kingma Diederik P., 2015, arXiv
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2017, IEEE T IMAGE PROCESS, V26, P3874, DOI 10.1109/TIP.2017.2708841
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Wang YL, 2017, IEEE T IMAGE PROCESS, V26, P3936, DOI 10.1109/TIP.2017.2708502
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZQ, 2019, IEEE I CONF COMP VIS, P3977, DOI 10.1109/ICCV.2019.00408
   Wu HP, 2021, IEEE T CIRC SYST VID, V31, P512, DOI 10.1109/TCSVT.2020.2988895
   Xiao JS, 2018, PATTERN RECOGN LETT, V116, P212, DOI 10.1016/j.patrec.2018.10.006
   Yang WH, 2020, IEEE T IMAGE PROCESS, V29, P6759, DOI 10.1109/TIP.2020.2993406
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yang Y., 2020, ICME, P1
   Yang YZ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1814, DOI 10.1145/3343031.3351149
   Yasarla R, 2020, PROC CVPR IEEE, P2723, DOI 10.1109/CVPR42600.2020.00280
   Yasarla R, 2019, PROC CVPR IEEE, P8397, DOI 10.1109/CVPR.2019.00860
   Zhang H, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103106
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang KH, 2018, PATTERN RECOGN, V81, P147, DOI 10.1016/j.patcog.2018.03.029
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao B, 2023, IEEE T NEUR NET LEAR, V34, P5181, DOI 10.1109/TNNLS.2021.3119969
   Zhao B, 2022, IEEE T PATTERN ANAL, V44, P2793, DOI 10.1109/TPAMI.2021.3072117
   Zhao B, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2916757
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 52
TC 3
Z9 3
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103695
DI 10.1016/j.jvcir.2022.103695
EA NOV 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E3JI4
UT WOS:000974535500001
DA 2024-07-18
ER

PT J
AU Shang, XW
   Li, GP
   Zhao, XL
   Zuo, YF
AF Shang, Xiwu
   Li, Guoping
   Zhao, Xiaoli
   Zuo, Yifan
TI Low complexity inter coding scheme for Versatile Video Coding (VVC)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile Video Coding (VVC); Low complexity; Inter coding; CU size
   decision; Mode decision
AB The latest coding standard Versatile Video Coding (VVC) developed by the Joint Video Experts Team (JVET) and Video Coding Experts Group (VCEG) was finalized in 2020. By introducing several new coding techniques, VVC improves the compression efficiency by 50% compared with H.265/HEVC. However, the coding complexity increases dramatically, which obstructs it from real-time application. To tackle this issue, a fast inter coding algorithm utilizing coding information is proposed to speed up the coding process. First, by analyzing the coding areas of the neighboring CUs, we predict the coding area of the current CU to terminate unnecessary splitting modes. Then, the temporally optimal coding mode generated during the prediction process is further utilized to shrink the candidate modes to speed up the coding process. Finally, the distribution of neighboring prediction modes are exploited to measure the motion complexity of the current CU, based on which the unnecessary prediction modes can be skipped earlier. Experimental results demonstrate that the proposed method can reduce the coding complexity by 40.08% on average with 0.07 dB BDPSNR decrease and 1.56% BDBR increase, which outperforms the state-of-the-art approach.
C1 [Shang, Xiwu; Li, Guoping; Zhao, Xiaoli] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
   [Zuo, Yifan] Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang, Peoples R China.
C3 Shanghai University of Engineering Science; Jiangxi University of
   Finance & Economics
RP Zhao, XL (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
EM zhaoxiaoli@sues.edu.cn
RI Zuo, Yifan/JVZ-3041-2024
OI Zuo, Yifan/0000-0003-4980-7211
FU National Natural Science Foundation of China [62001283, 61901197];
   National Key R&D Project of China [2019YFB1802702]
FX This work was financially supported by the National Natural Science
   Foundation of China under 62001283, National Key R&D Project of China
   under 2019YFB1802702, National Natural Science Foundation of China under
   61901197.
CR Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Cao J, 2020, LECT NOTES COMPUT SC, V11961, P739, DOI 10.1007/978-3-030-37731-1_60
   Chen F, 2020, MULTIMED TOOLS APPL, V79, P27923, DOI 10.1007/s11042-020-09401-8
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Huang YW, 2021, IEEE T CIRC SYST VID, V31, P3818, DOI 10.1109/TCSVT.2021.3088134
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P345, DOI 10.1109/TCSVT.2021.3057518
   Pan ZQ, 2021, IEEE SIGNAL PROC LET, V28, P1260, DOI 10.1109/LSP.2021.3086692
   Pan ZS, 2023, IEEE ACM T COMPUT BI, V20, P1180, DOI 10.1109/TCBB.2022.3170367
   Suehring K, 2019, JVETM1010
   Yang SH, 2021, ELECTRON LETT, V57, P11, DOI 10.1049/ell2.12011
   Yeo W.H., 2021, KOREA MULTIMEDIA SOC
NR 12
TC 8
Z9 8
U1 4
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103683
DI 10.1016/j.jvcir.2022.103683
EA NOV 2022
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200001
DA 2024-07-18
ER

PT J
AU Chen, YD
   Yan, H
   Yang, ZX
   Wu, EH
AF Chen, Yadang
   Yan, Hui
   Yang, Zhi-Xin
   Wu, Enhua
TI Meta-transfer-adjustment learning for few-shot learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Few-shot learning; Deep neural networks; Feature adjustment; Task
   adjustment
ID NETWORKS
AB Deep neural network models with strong feature extraction capacity are prone to overfitting and fail to adapt quickly to new tasks with few samples. Gradient-based meta-learning approaches can minimize overfitting and adapt to new tasks fast, but they frequently use shallow neural networks with limited feature extraction capacity. We present a simple and effective approach called Meta-Transfer-Adjustment learning (MTA) in this paper, which enables deep neural networks with powerful feature extraction capabilities to be applied to few -shot scenarios while avoiding overfitting and gaining the capacity for quickly adapting to new tasks via training on numerous tasks. Our presented approach is classified into two major parts, the Feature Adjustment (FA) module, and the Task Adjustment (TA) module. The feature adjustment module (FA) helps the model to make better use of the deep network to improve feature extraction, while the task adjustment module (TA) is utilized for further improve the model's fast response and generalization capabilities. The proposed model delivers good classification results on the benchmark small sample datasets MiniImageNet and Fewshot-CIFAR100, as proved experimentally.
C1 [Chen, Yadang; Yan, Hui] Nanjing Univ Informat Sci & Technol, Minist Educ, Engn Res Ctr Digital Forens, Nanjing 210044, Peoples R China.
   [Chen, Yadang; Yan, Hui] Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.
   [Yang, Zhi-Xin] Univ Macau, Dept Electromech Engn, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China.
   [Wu, Enhua] Univ Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; University of Macau;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Yang, ZX (corresponding author), Univ Macau, Dept Electromech Engn, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China.
EM zxyang@um.edu.mo
RI Liu, xuefeng/IUP-1483-2023
FU National Natural Science Foundation of China [62072449, 61802197];
   Science and Technology Development Fund, Macau SAR [0018/2019/AKP,
   SKL-IOTSC(UM)-2021-2023]; Guangdong Science and Technology Department
   [2018B030324002]; Zhuhai Science and Technology Innovation Bureau
   Zhuhai-Hong Kong-Macau Special Cooperation Project [ZH22017002200001PWC]
FX This work was partially supported by the National Natural Science
   Foundation of China (Grant Nos. 62072449, 61802197) and is also funded
   in part by the Science and Technology Development Fund, Macau SAR (Grant
   no. 0018/2019/AKP and SKL-IOTSC(UM)-2021-2023), in part by the Guangdong
   Science and Technology Depart-ment (Grant no. 2018B030324002), in part
   by the Zhuhai Science and Technology Innovation Bureau Zhuhai-Hong
   Kong-Macau Special Cooperation Project (Grant no. ZH22017002200001PWC).
CR Rusu AA, 2019, Arxiv, DOI arXiv:1807.05960
   Antoniou A, 2019, Arxiv, DOI arXiv:1810.09502
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Finn C, 2017, PR MACH LEARN RES, V70
   Gidaris S, 2019, IEEE I CONF COMP VIS, P8058, DOI 10.1109/ICCV.2019.00815
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou RB, 2019, ADV NEUR IN, V32
   Hu YQ, 2021, LECT NOTES COMPUT SC, V12892, P487, DOI 10.1007/978-3-030-86340-1_39
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Kingma D. P., 2014, arXiv
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li HY, 2019, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2019.00009
   Lian D., 2019, INT C LEARNING REPRE
   Lu Lin, 2022, EXPERT SYST APPL
   Manandhar D, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102871
   Mishra N, 2018, Arxiv, DOI arXiv:1707.03141
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Patacchiola M., 2020, Advances in Neural Information Processing Systems, V33, P16108, DOI DOI 10.48550/ARXIV.1910.05199
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shao S, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4193, DOI 10.1145/3474085.3475553
   Shi ZF, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103312
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang NY, 2022, ICT EXPRESS, V8, P322, DOI 10.1016/j.icte.2022.03.014
   Wu HS, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103265
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xue WQ, 2020, AAAI CONF ARTIF INTE, V34, P6558
   Ye Han-Jia, 2022, IEEE Trans Pattern Anal Mach Intell
   Ye WJ, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103378
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Zhang BQ, 2022, AAAI CONF ARTIF INTE, P9014
   Zhang Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3143, DOI 10.1145/3474085.3475459
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V59, P563, DOI 10.1016/j.jvcir.2019.02.006
   Zintgraf L, 2019, PR MACH LEARN RES, V97
NR 39
TC 1
Z9 1
U1 4
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103678
DI 10.1016/j.jvcir.2022.103678
EA NOV 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600004
DA 2024-07-18
ER

PT J
AU Liu, J
   Tan, JQ
   Ge, XY
   Hu, DD
   He, L
AF Liu, Jing
   Tan, Jieqing
   Ge, Xianyu
   Hu, Dandan
   He, Lei
TI Blind deblurring with fractional-order calculus and local minimal pixel
   prior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion deblurring; Deconvolution; Kernel estimation; Fractional-Order
   calculus Theory; Local Minimal Pixel Prior
ID DECONVOLUTION; IMAGES
AB Fractional-order calculus is an extension of integer order calculus. In signal processing, fractional-order calculus can non-linearly enhance the low-frequency signal and suppress the high-frequency signal. In this paper, a new fractional-order local minimum pixel prior (FOLMP) is proposed by combining fractional-order calculus with the local minimum pixel prior. The FOLMP of the sharp images includes fewer non-zero pixels than the blur images. A new blur kernel estimation algorithm is proposed by combining L0 regularized FOLMP with the maximum posterior probability. Furthermore, the kernel similarity is employed to adjust the iteration times to accelerate the computational efficiency. Comparative experiments show that the proposed algorithm can perform better on different types of datasets than the most advanced algorithms. In addition, non-overlapping image patches are adopted to compute the FOLMP, and the kernel similarity is used to suppress excessive iterations. Therefore, the proposed algorithm is several times or even tens of times more efficient than the classical prior-based methods.
C1 [Liu, Jing; Ge, Xianyu] Anhui Jianzhu Univ, Sch Elect & Informat Engn, Hefei 230601, Peoples R China.
   [Tan, Jieqing; Hu, Dandan; He, Lei] Hefei Univ Technol, Sch Math, Hefei 230009, Peoples R China.
C3 Anhui Jianzhu University; Hefei University of Technology
RP Ge, XY (corresponding author), Anhui Jianzhu Univ, Sch Elect & Informat Engn, Hefei 230601, Peoples R China.
EM shuxuegxy@126.com
RI Tan, Jie/IVV-5250-2023
FU National Natural Science Foundation of China;  [62172135]
FX Acknowledgments This work is supported by the National Natural Science
   Foundation of China (No.62172135) .
CR Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Cai JR, 2020, IEEE T IMAGE PROCESS, V29, P6885, DOI 10.1109/TIP.2020.2995048
   Campisi P., 2007, Blindimagedeconvolution:theoryandapplications
   CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770
   Cao X., 2015, IEEE T IMAGE PROCESS, P3426
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Chen L, 2019, PROC CVPR IEEE, P1742, DOI 10.1109/CVPR.2019.00184
   Chen MY, 2019, OPT LASER ENG, V122, P170, DOI 10.1016/j.optlaseng.2019.06.011
   Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38
   Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432
   Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5
   Joshi N, 2008, PROC CVPR IEEE, P3823
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601
   Lee H, 2020, IEEE T IMAGE PROCESS, V29, P710, DOI 10.1109/TIP.2019.2933739
   Lei T., 2016, ASIAN C COMPUTER VIS, P576
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Li TH, 2002, IEEE T IMAGE PROCESS, V11, P847, DOI 10.1109/TIP.2002.801127
   LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605
   Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shao WZ, 2020, NEUROCOMPUTING, V413, P305, DOI 10.1016/j.neucom.2020.06.093
   STOCKHAM TG, 1975, P IEEE, V63, P678, DOI 10.1109/PROC.1975.9800
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Sun LB, 2013, IEEE INT CONF COMPUT
   Tang YC, 2022, STRUCTURES, V37, P426, DOI 10.1016/j.istruc.2021.12.055
   Tang YC, 2019, ROBOT CIM-INT MANUF, V59, P36, DOI 10.1016/j.rcim.2019.03.001
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen F, 2021, IEEE T CIRC SYST VID, V31, P2923, DOI 10.1109/TCSVT.2020.3034137
   Whyte Oliver, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P745
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Wiener N., 1949, Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications, DOI 10.7551/mitpress/2946.001.0001
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan RM, 2016, IEEE T IMAGE PROCESS, V25, P1910, DOI 10.1109/TIP.2016.2535273
   Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738
   Yasarla R, 2020, IEEE T IMAGE PROCESS, V29, P6251, DOI 10.1109/TIP.2020.2990354
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
NR 58
TC 6
Z9 6
U1 3
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103645
DI 10.1016/j.jvcir.2022.103645
EA OCT 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300006
DA 2024-07-18
ER

PT J
AU Li, HY
   Lei, Q
   Zhang, HB
   Du, JX
   Gao, SC
AF Li, Huiying
   Lei, Qing
   Zhang, Hongbo
   Du, Jixiang
   Gao, Shangce
TI Skeleton-based deep pose feature learning for action quality assessment
   on figure skating videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action quality assessment; Figure skating sport videos; Spatial-temporal
   pose feature extraction; Action relation learning
AB Most of the existing Action Quality Assessment (AQA) methods for scoring sports videos have deeply researched how to evaluate the single action or several sequential-defined actions that performed in short-term sport videos, such as diving, vault, etc. They attempted to extract features directly from RGB videos through 3D ConvNets, which makes the features mixed with ambiguous scene information. To investigate the effectiveness of deep pose feature learning on automatically evaluating the complicated activities in long-duration sports videos, such as figure skating and artistic gymnastic, we propose a skeleton-based deep pose feature learning method to address this problem. For pose feature extraction, a spatial-temporal pose extraction module (STPE) is built to capture the subtle changes of human body movements and obtain the detail representations for skeletal data in space and time dimensions. For temporal information representation, an inter-action temporal relation extraction module (ATRE) is implemented by recurrent neural network to model the dynamic temporal structure of skeletal subsequences. We evaluate the proposed method on figure skating activity of MIT-skate and FIS-V datasets. The experimental results show that the proposed method is more effective than RGB video-based deep feature learning methods, including SENet and C3D. Significant performance progress has been achieved for the Spearman Rank Correlation (SRC) on MIT-Skate dataset. On FIS-V dataset, for the Total Element Score (TES) and the Program Component Score (PCS), better SRC and MSE have been achieved between the predicted scores against the judge's ones when compared with SENet and C3D feature methods.
C1 [Li, Huiying; Lei, Qing; Zhang, Hongbo; Du, Jixiang] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361000, Peoples R China.
   [Gao, Shangce] Univ Toyama, Fac Engn, Toyama 9308555, Japan.
C3 Huaqiao University; University of Toyama
RP Lei, Q (corresponding author), Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361000, Peoples R China.
EM leiqing@hqu.edu.cn
RI Zhang, Hong-Bo/GWC-9306-2022; GAO, Shangce/I-3422-2012
OI GAO, Shangce/0000-0001-5042-3261; LEI, QING/0000-0003-3573-4226
FU Natural Science Foundation of China [62001176, 61871196]; Natural
   Science Foundation of Fujian Province, China [2020J01085, 2019J01082];
   National Key Research and Development Program of China [2019YFC1604700];
   Promotion Program for Young and Middleaged Teacher in Science and
   Technology Research of Huaqiao University,China [ZQN-YX601]; Japan
   Society for the Promotion of Science (JSPS) KAKENHI [JP22H03643]
FX This work was supported by the Natural Science Foundation of China No.
   62001176, No. 61871196; the Natural Science Foundation of Fujian
   Province, China No. 2020J01085, No. 2019J01082; the National Key
   Research and Development Program of China No. 2019YFC1604700; the
   Promotion Program for Young and Middleaged Teacher in Science and
   Technology Research of Huaqiao University,China No. ZQN-YX601; and the
   Japan Society for the Promotion of Science (JSPS) KAKENHI No.
   JP22H03643.
CR Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Debnath B, 2022, MULTIMEDIA SYST, V28, P209, DOI 10.1007/s00530-021-00815-4
   Dong LJ, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107388
   Doughty H, 2019, PROC CVPR IEEE, P7854, DOI 10.1109/CVPR.2019.00805
   Doughty H, 2018, PROC CVPR IEEE, P6057, DOI 10.1109/CVPR.2018.00634
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elkholy AM, 2020, IEEE J BIOMED HEALTH, V24, P280, DOI 10.1109/JBHI.2019.2904321
   Fard MJ, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1850
   Fawaz HI, 2018, LECT NOTES COMPUT SC, V11073, P214, DOI 10.1007/978-3-030-00937-3_25
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   International Skating Union, 2021, NETWORK DATA
   Jain H, 2021, IEEE T CIRC SYST VID, V31, P2260, DOI 10.1109/TCSVT.2020.3017727
   Jiahao Wang, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12306), P3, DOI 10.1007/978-3-030-60639-8_1
   Jibin Gao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P222, DOI 10.1007/978-3-030-58577-8_14
   Kingma D. P., 2014, arXiv
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lei Q, 2021, SIGNAL IMAGE VIDEO P, V15, P1575, DOI 10.1007/s11760-021-01890-w
   Lei Q, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194129
   Li YJ, 2018, LECT NOTES COMPUT SC, V11165, P125, DOI 10.1007/978-3-030-00767-6_12
   Li Yongjun, 2018, PROC ASIAN C COMPUT
   Liao YL, 2020, IEEE T NEUR SYS REH, V28, P468, DOI 10.1109/TNSRE.2020.2966249
   Nair V., 2020, J IEEE I C DEVELOP L, P1
   Nekoui M, 2020, IEEE COMPUT SOC CONF, P3941, DOI 10.1109/CVPRW50498.2020.00458
   Nekoui M, 2021, IEEE WINT CONF APPL, P394, DOI 10.1109/WACV48630.2021.00044
   Pan JH, 2019, IEEE I CONF COMP VIS, P6340, DOI 10.1109/ICCV.2019.00643
   Parmar P, 2019, PROC CVPR IEEE, P304, DOI 10.1109/CVPR.2019.00039
   Parmar P, 2019, IEEE WINT CONF APPL, P1468, DOI 10.1109/WACV.2019.00161
   Parmar P, 2017, IEEE COMPUT SOC CONF, P76, DOI 10.1109/CVPRW.2017.16
   Pirsiavash H, 2014, LECT NOTES COMPUT SC, V8694, P556, DOI 10.1007/978-3-319-10599-4_36
   Sardari F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185258
   Venkataraman V., 2015, BMVC
   Wang ZH, 2018, INT J COMPUT ASS RAD, V13, P1959, DOI 10.1007/s11548-018-1860-1
   Xiang X, 2018, IEEE IMAGE PROC, P928, DOI 10.1109/ICIP.2018.8451364
   Xu CM, 2020, IEEE T CIRC SYST VID, V30, P4578, DOI 10.1109/TCSVT.2019.2927118
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yansong Tang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9836, DOI 10.1109/CVPR42600.2020.00986
   Yu BXB, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108095
NR 39
TC 1
Z9 1
U1 12
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103625
DI 10.1016/j.jvcir.2022.103625
EA SEP 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5K3LX
UT WOS:000869631900002
DA 2024-07-18
ER

PT J
AU Si, YZ
   Yang, F
   Guo, Y
   Zhang, W
   Yang, YP
AF Si, Yazhong
   Yang, Fan
   Guo, Ya
   Zhang, Wei
   Yang, Yipu
TI A comprehensive benchmark analysis for sand dust image reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sand dust image; Benchmark dataset; Image reconstruction; Comprehensive
   evaluation; Convolutional neural networks
ID QUALITY ASSESSMENT; ENHANCEMENT
AB Recently, numerous sand dust removal algorithms have been proposed. To our best knowledge, however, most methods evaluated their performance in a no-reference way using few selected real-world images from the internet. It is unclear how to quantitatively analyze the performance of the algorithms in a supervised way. Moreover, due to the absence of large-scale datasets, there are no well-known sand dust reconstruction report algorithms up till now. To bridge the gaps, we presented a comprehensive perceptual study and analysis of real-world sandstorm images, then constructed a Sand-dust Image Reconstruction Benchmark(SIRB) for training Convolutional Neural Networks(CNNs) and evaluating the algorithm's performance. We adopted the existing image transformation neural network trained on SIRB as the baseline to illustrate the generalization of SIRB for training CNNs. Finally, we conducted a comprehensive evaluation to demonstrate the performance and limitations of the sandstorm enhancement algorithms, which shed light on future research in sandstorm image reconstruction.
C1 [Si, Yazhong; Yang, Fan; Guo, Ya; Zhang, Wei; Yang, Yipu] Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology
RP Yang, F (corresponding author), Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.
EM yangfan@hebut.edu.cn
RI Yang, Fan/GRJ-6470-2022; si, yazhong/JDW-4576-2023
FU National Key Research and Devel-opment Program of China; Natural Science
   Foundation of Hebei Province, China;  [2019YFB1312102];  [F2019202364]
FX Acknowledgments This work is supported by the National Key Research and
   Devel-opment Program of China (2019YFB1312102) and the Natural Science
   Foundation of Hebei Province, China (F2019202364) .
CR Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Anvari Z, 2020, Arxiv, DOI arXiv:2008.06632
   Anwar S, 2018, Arxiv, DOI arXiv:1807.03528
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Chen CH, 2021, PROC CVPR IEEE, P7738, DOI 10.1109/CVPR46437.2021.00765
   Cheng YQ, 2020, IEEE ACCESS, V8, P196690, DOI 10.1109/ACCESS.2020.3034151
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Fu XY, 2020, SIGNAL PROCESS-IMAGE, V86, DOI 10.1016/j.image.2020.115892
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2014, IEEE INT WORKSH MULT
   Gao GX, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165659
   Gao GX, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2975833
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jian Wang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P842, DOI 10.1007/978-3-319-27671-7_70
   Dhara SK, 2021, IEEE T CIRC SYST VID, V31, P2076, DOI 10.1109/TCSVT.2020.3007850
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li RT, 2019, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2019.00173
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   McDonald R, 1995, J SOC DYERS COLOUR, V111, P376
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moorthy A. K., 2009, IEEE Signal Process. Lett, V17, P7
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Park TH, 2021, IEEE ACCESS, V9, P19749, DOI 10.1109/ACCESS.2021.3054899
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ryde J., 1941, Report no. 7831, P22
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shi ZH, 2020, IET IMAGE PROCESS, V14, P747, DOI 10.1049/iet-ipr.2019.0992
   Shi ZH, 2019, IEEE ACCESS, V7, P116722, DOI 10.1109/ACCESS.2019.2936444
   Si Y., 2022, MULTIMEDIA TOOLS APP, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Uplavikar P. M., 2019, P IEEE C COMP VIS PA, P1
   Wang B, 2021, SIGNAL IMAGE VIDEO P, V15, P637, DOI 10.1007/s11760-020-01786-1
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1643, DOI 10.1145/3394171.3413820
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2517, DOI 10.1145/3394171.3413559
   Wang N, 2021, Arxiv, DOI arXiv:1912.10269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu GL, 2020, IEEE-CAA J AUTOMATIC, V7, P1649, DOI 10.1109/JAS.2020.1003423
   Yasarla R, 2020, PROC CVPR IEEE, P2723, DOI 10.1109/CVPR42600.2020.00280
   Yu SY, 2016, J MOD OPTIC, V63, P2121, DOI 10.1080/09500340.2016.1184340
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2355, DOI 10.1145/3394171.3413763
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   [智宁 Zhi Ning], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1585
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 58
TC 9
Z9 10
U1 4
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103638
DI 10.1016/j.jvcir.2022.103638
EA SEP 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5K3LX
UT WOS:000869631900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Denipitiyage, D
   Jayasundara, V
   Rodrigo, R
   Edussooriya, CUS
AF Denipitiyage, Dishanika
   Jayasundara, Vinoj
   Rodrigo, Ranga
   Edussooriya, Chamira U. S.
TI PointCaps: Raw point cloud processing using capsule networks with
   Euclidean distance routing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Point cloud reconstruction; Classification; Capsule networks; Error
   routing
AB Raw point cloud processing using capsule networks is widely adopted in classification, reconstruction, and segmentation due to its ability to preserve spatial agreement of the input data. However, most of the existing capsule based network approaches are computationally heavy and fail at representing the entire point cloud as a single capsule. We address these limitations in existing capsule network based approaches by proposing PointCaps, a novel convolutional capsule architecture with parameter sharing. Along with PointCaps, we propose a novel Euclidean distance routing algorithm and a class-independent latent representation. The latent representation captures physically interpretable geometric parameters of the point cloud, with dynamic Euclidean routing, PointCaps well-represents the spatial (point-to-part) relationships of points. PointCaps has a significantly lower number of parameters and requires a significantly lower number of FLOPs while achieving better reconstruction with comparable classification and segmentation accuracy for raw point clouds compared to state-of-the-art capsule networks.
C1 [Denipitiyage, Dishanika; Rodrigo, Ranga; Edussooriya, Chamira U. S.] Univ Moratuwa, Dept Elect & Telecommun Engn, Moratuwa, Sri Lanka.
   [Edussooriya, Chamira U. S.] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL USA.
   [Jayasundara, Vinoj] Univ Maryland, Dept Comp Sci, College Pk, MD USA.
C3 University Moratuwa; State University System of Florida; Florida
   International University; University System of Maryland; University of
   Maryland College Park
RP Edussooriya, CUS (corresponding author), Univ Moratuwa, Dept Elect & Telecommun Engn, Moratuwa, Sri Lanka.
EM chamira@uom.lk
OI Rodrigo, Ranga/0000-0002-1034-7513; Edussooriya,
   Chamira/0000-0001-6715-6198
CR Chen XZ, 2015, ADV NEUR IN, V28
   Chen ZQ, 2020, PROC CVPR IEEE, P42, DOI 10.1109/CVPR42600.2020.00012
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Cheraghian A, 2019, IEEE WINT CONF APPL, P1194, DOI 10.1109/WACV.2019.00132
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Deprelle T., 2019, ADV NEURAL INFORM PR, P7433
   Geiger A, 2015, LECT NOTES COMPUT SC, V9358, P183, DOI 10.1007/978-3-319-24947-6_15
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298
   Lee SH, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103246
   Lei H, 2018, Arxiv, DOI arXiv:1805.07872
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li YZ, 2018, ADV NEUR IN, V31
   Liu LY, 2021, Arxiv, DOI arXiv:1908.03265
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Maiseli B, 2017, J VIS COMMUN IMAGE R, V46, P95, DOI 10.1016/j.jvcir.2017.03.012
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qin NN, 2018, ISPRS J PHOTOGRAMM, V143, P205, DOI 10.1016/j.isprsjprs.2018.03.011
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Ramachandran P, 2017, Arxiv, DOI arXiv:1710.05941
   Sabour S, 2017, ADV NEUR IN, V30
   Sun WW, 2021, Arxiv, DOI arXiv:2012.04718
   Wang WM, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104092
   Wang Y, 2019, Arxiv, DOI arXiv:1910.12240
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wen X, 2020, IEEE T IMAGE PROCESS, V29, P8855, DOI 10.1109/TIP.2020.3019925
   Wu H, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104193
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xiang T., 2021, ARXIV
   Xu QG, 2020, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR42600.2020.00570
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang S, 2019, J VIS COMMUN IMAGE R, V61, P170, DOI 10.1016/j.jvcir.2019.03.005
   Zhao YH, 2020, Arxiv, DOI arXiv:1912.12098
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
NR 47
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103612
DI 10.1016/j.jvcir.2022.103612
EA SEP 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU He, W
   Li, WJ
   Zhang, GY
   Tu, B
   Kim, YK
   Wu, JH
   Qi, Q
AF He, Wei
   Li, Wujing
   Zhang, Guoyun
   Tu, Bing
   Kim, Yong Kwan
   Wu, Jianhui
   Qi, Qi
TI Detection of moving objects using adaptive multi-feature histograms*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving object detection; Background subtraction; Local compact binary
   descriptor; Multi-feature histogram
ID BACKGROUND SUBTRACTION; MODEL; SEGMENTATION
AB This paper presents a moving object detection scheme that incorporates three innovations. First, considering the inter-frame consistency of pixels, we extend the compact binary face descriptor (CBFD) to the temporal domain and propose a novel local binary descriptor named temporally-consistent local compact binary descriptor (TCLCBD), which exploits the useful correlation of the intensities of inter-frame pixels to guarantee good performance in complex scenes. We do this mainly because the background scene between frames has a significant coherence. Second, both color and TC-LCBD features are modeled as a group of adaptive histograms for characterizing each pixel, which can enhance the robustness to dynamic backgrounds and illumination changes. Third, by comparing changes in histogram proximity between two adjacent frames, we can dynamically adjust the model sensitivity and adaptation rate without user intervention. Experimental results on well-known, challenging data sets demonstrate that the proposed method significantly outperforms many state-of-the-art methods.
C1 [He, Wei; Li, Wujing; Zhang, Guoyun; Tu, Bing; Wu, Jianhui; Qi, Qi] Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang, Hunan, Peoples R China.
   [He, Wei; Kim, Yong Kwan; Wu, Jianhui] Hoseo Univ, Dept Informat & Commun Engn, Asan, Chungcheongnam, South Korea.
C3 Hunan Institute of Science & Technology; Hoseo University
RP Zhang, GY; Qi, Q (corresponding author), Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang, Hunan, Peoples R China.
EM gyzhang@hnist.edu.cn; qqi8315@hotmail.com
RI Kim, Yong Kwan/GQZ-6055-2022; Li, Wujing/GZL-9066-2022
FU Hunan Provincial Natural Science Foundation of China [2019JJ40104,
   2019JJ50211]; Open Fund of Education Department of Hunan Province [20
   K062]; Ministry of Oceans and Fisheries, Korea
FX The authors would like to acknowledge that this work was supported by
   the Hunan Provincial Natural Science Foundation of China (2019JJ40104,
   2019JJ50211); the Open Fund of Education Department of Hunan Province
   (20 K062); and the Ministry of Oceans and Fisheries, Korea.
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Caseiro R, 2012, PATTERN RECOGN, V45, P3997, DOI 10.1016/j.patcog.2012.04.011
   Chen ML, 2018, IEEE T PATTERN ANAL, V40, P1518, DOI 10.1109/TPAMI.2017.2717828
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Guo JM, 2011, IEEE T CIRC SYST VID, V21, P804, DOI 10.1109/TCSVT.2011.2133270
   Guo LL, 2016, IEEE COMPUT SOC CONF, P1159, DOI 10.1109/CVPRW.2016.148
   He W, 2019, MULTIMED TOOLS APPL, V78, P31415, DOI 10.1007/s11042-019-7688-z
   He W, 2019, IEEE ACCESS, V7, P92329, DOI 10.1109/ACCESS.2019.2927745
   He W, 2018, INT C PATT RECOG, P1518, DOI 10.1109/ICPR.2018.8545062
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   HEIKKILA M., 2004, British Machine Vision Conference, P187, DOI DOI 10.5244/C.18.21
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Javed S, 2019, IEEE T IMAGE PROCESS, V28, P1007, DOI 10.1109/TIP.2018.2874289
   Jeyabharathi D, 2018, J VIS COMMUN IMAGE R, V55, P434, DOI 10.1016/j.jvcir.2018.06.024
   Jiang SQ, 2018, IEEE T CIRC SYST VID, V28, P2105, DOI 10.1109/TCSVT.2017.2711659
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   López-Rubio E, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065717500563
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu XQ, 2014, IEEE IMAGE PROC, P3268, DOI 10.1109/ICIP.2014.7025661
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Narayana M, 2012, PROC CVPR IEEE, P2104, DOI 10.1109/CVPR.2012.6247916
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Roy SM, 2018, IEEE T CIRC SYST VID, V28, P1513, DOI 10.1109/TCSVT.2017.2669362
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sobral A., 2013, 9 WORKSH VID COMP WV
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P5085, DOI 10.1109/TGRS.2019.2896471
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P1573, DOI 10.1109/TGRS.2018.2867444
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Wang J, 2014, PR MACH LEARN RES, V32, P235
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004
   Xue GJ, 2010, IEEE INT CON MULTI, P1050, DOI 10.1109/ICME.2010.5582601
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang D, 2018, IEEE T IMAGE PROCESS, V27, P1112, DOI 10.1109/TIP.2017.2768828
   Yang S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P641
   Yong HW, 2018, IEEE T PATTERN ANAL, V40, P1726, DOI 10.1109/TPAMI.2017.2732350
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 58
TC 3
Z9 3
U1 3
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103278
DI 10.1016/j.jvcir.2021.103278
EA AUG 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600008
DA 2024-07-18
ER

PT J
AU Guruprasad, S
   Bharathi, SH
   Delvi, DAR
AF Guruprasad, Shrividya
   Bharathi, S. H.
   Delvi, D. Anto Ramesh
TI Effective compressed sensing MRI reconstruction via hybrid GSGWO
   algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed sensing; Cross guided bilateral filter; Quasi random
   sampling; Hybridized Galactic Swarm Optimization and; Grey Wolf
   Optimization; Hybridized Walsh Hadamard Transform and; Discrete Wavelet
   Transform
ID LOW-RANK; PROJECTION; NETWORKS; SAR
AB In a bio-imaging context, the main issues which obstruct the CS (Compressed sensing) application are image reconstruction time and computational cost. This paper presents an effective compressed sensing-based MRI reconstruction through a hybrid optimization algorithm. Initially, the preprocessing stage is performed using Cross guided bilateral filter. Then the K-space is generated by the Fourier transform. The hybrid Walsh Hadamard Transform and Discrete Wavelet Transform (HWHDWT) is utilized for the compressive sensing of the images. Finally, the Hybrid Galactic Swarm Optimization and Grey Wolf Optimization (HGSGWO) algorithm are developed for MRI reconstruction. The dataset collected from a hospital which contains MRI images both in JPEG and DICOM format. The performance of SSIM (Structural Similarity Index), PSNR (Peak Signal to Noise Ratio), MSE (mean square error) and reconstruction time are evaluated for images and it is compared with the existing methods.
C1 [Guruprasad, Shrividya; Bharathi, S. H.] REVA Univ, Sch E&C Engn, Bengaluru 560064, India.
   [Delvi, D. Anto Ramesh] Columbia Asia Hosp, Dept Radiol, Petaling Jaya, Malaysia.
C3 REVA University
RP Guruprasad, S (corresponding author), REVA Univ, Sch E&C Engn, Bengaluru 560064, India.
CR Babacan SD, 2010, IEEE T IMAGE PROCESS, V19, P53, DOI 10.1109/TIP.2009.2032894
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Baron D, 2010, IEEE T SIGNAL PROCES, V58, P269, DOI 10.1109/TSP.2009.2027773
   Bazerque JA, 2010, IEEE T SIGNAL PROCES, V58, P1847, DOI 10.1109/TSP.2009.2038417
   Berger CR, 2010, IEEE COMMUN MAG, V48, P164, DOI 10.1109/MCOM.2010.5621984
   Bianchi T, 2016, IEEE T INF FOREN SEC, V11, P313, DOI 10.1109/TIFS.2015.2493982
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Ch MMI, 2019, MULTIDIM SYST SIGN P, V30, P2199, DOI 10.1007/s11045-019-00646-7
   Chen C., 2012, P INT C ADV NEUR INF, V25, P1115
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Deng J., 2015, J VISUAL COMMUN IMAG, V31, P112
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Duarte MF, 2013, APPL COMPUT HARMON A, V35, P111, DOI 10.1016/j.acha.2012.08.003
   Eldar Y. C., 2012, COMPRESSED SENSING T
   Ender JHG, 2010, SIGNAL PROCESS, V90, P1402, DOI 10.1016/j.sigpro.2009.11.009
   Farias AR, 2018, MAGN RESON IMAGING, V50, P45, DOI 10.1016/j.mri.2018.03.005
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gan SW, 2016, J APPL GEOPHYS, V130, P194, DOI 10.1016/j.jappgeo.2016.03.033
   Huang JZ, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P968, DOI 10.1109/ISBI.2012.6235718
   Huang JZ, 2011, MED IMAGE ANAL, V15, P670, DOI 10.1016/j.media.2011.06.001
   Jhamb Tanuj Kumar, 2015, International Journal of Image, Graphics and Signal Processing, V7, P42, DOI 10.5815/ijigsp.2015.07.06
   Li SC, 2013, IEEE T IND INFORM, V9, P2177, DOI 10.1109/TII.2012.2189222
   Li WM, 2016, J INDIAN SOC REMOTE, V44, P41, DOI 10.1007/s12524-015-0468-y
   Liu SJ, 2017, J VIS COMMUN IMAGE R, V46, P150, DOI 10.1016/j.jvcir.2017.03.017
   Majumdar A, 2017, MAGN RESON IMAGING, V39, P64, DOI 10.1016/j.mri.2017.02.001
   Majumdar A, 2015, MAGN RESON IMAGING, V33, P174, DOI 10.1016/j.mri.2014.08.031
   Manisha,, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P205, DOI 10.1109/RTEICT.2017.8256586
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Muthiah-Nakarajan V, 2016, APPL SOFT COMPUT, V38, P771, DOI 10.1016/j.asoc.2015.10.034
   Quan T.M., 2008, IEEE T MED IMAGING
   Ramgopal A., 2014, THESIS U N CAROLINA
   Roohi SF, 2017, PATTERN RECOGN, V63, P667, DOI 10.1016/j.patcog.2016.09.040
   Schlemper J, 2017, LECT NOTES COMPUT SC, V10265, P647, DOI 10.1007/978-3-319-59050-9_51
   Tillmann Andreas M., 2014, IEEE Transactions on Information Theory, V60, P1248, DOI 10.1109/TIT.2013.2290112
   Xi Y, 2016, IEEE T BIO-MED ENG, V63, P1301, DOI 10.1109/TBME.2015.2487779
   Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
   Yao JW, 2018, MED IMAGE ANAL, V44, P14, DOI 10.1016/j.media.2017.11.003
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
   Zhu XX, 2010, IEEE T GEOSCI REMOTE, V48, P3839, DOI 10.1109/TGRS.2010.2048117
   Zhu ZG, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/907501
   Zong FR, 2016, MAGN RESON IMAGING, V34, P227, DOI 10.1016/j.mri.2015.10.009
NR 43
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103274
DI 10.1016/j.jvcir.2021.103274
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600001
DA 2024-07-18
ER

PT J
AU Nien, YC
   Tang, CW
AF Nien, Yu-Chieh
   Tang, Chih-Wei
TI Region-level bit allocation for rate control of 360-degree videos using
   cubemap projection☆
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 360-degree video coding; Cubemap projection (CMP); Rate control; Bit
   allocation; Machine learning; Detection of high HEVC coding cost regions
AB Featuring with more uniform sampling density in the sphere domain and less non-uniform geometric deformations in the planar domain, variants of cubemap projection (CMP) format enable the higher compression ratio in on-going 360-degree video coding standardization. Different from single-view videos, 360-degree CMP videos feature with content discontinuity combined with the abrupt change of motion vectors between some adjacent faces. However, there is few bit allocation scheme designed for rate control of video coding of CMP format. Thus, this paper proposes a region-level bit allocation scheme for rate control of interframe coding of CMP format. The proposed scheme consists of two parts. The first part is machine learning based high HEVC coding cost region detection for individual faces, where the feature descriptor of a CTU consists of the face based texture complexity, motion magnitude, motion density, and temporal coherence of motion vector. The second part is fitting function based region-level bit allocation. Different from previous work, bits are assigned to the high coding cost region and non-high coding cost region in individual faces of CMP format. Experimental results indicate that the proposed scheme achieves higher bitrate accuracy and larger BD-WS-PSNR compared with the original rate control scheme of the reference software of HEVC, HM16.16 with the 360Lib.
C1 [Nien, Yu-Chieh] Hon Hai Technol Grp, 5 Xinan Rd, Hsinchu 300, Taiwan.
   [Tang, Chih-Wei] Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
C3 Hon Hai Precision Industry; National Central University
RP Tang, CW (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
EM cwtang@ce.ncu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST 107-2221-E-008-058,
   MOST-108-2221-E-008-024, MOST-109-2221-E-008-050]
FX This work is supported by the Ministry of Science and Technology of
   Taiwan under the Grants MOST 107-2221-E-008-058,
   MOST-108-2221-E-008-024, and MOST-109-2221-E-008-050.
CR [Anonymous], 2016, 1SC29WG11 ISO IEC JT
   [Anonymous], 2017, JVETF0025
   [Anonymous], 2017, JVETG1003
   [Anonymous], 1SC29WG11 ISO IEC JT
   Azevedo R.G.d.A., 2001, IEEE T CIRC SYST VID
   Azevedo RGD, 2021, IEEE OPEN J CIRCUITS, V2, P338, DOI 10.1109/OJCAS.2021.3073891
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Boyce J., 2016, Document JVET-D1030
   Dai M, 2004, IEEE IMAGE PROC, P1093
   Gao PC, 2021, IEEE T MULTIMEDIA, V23, P926, DOI 10.1109/TMM.2020.2991507
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   Guanghui Ren, 2010, Information Technology Journal, V9, P1390, DOI 10.3923/itj.2010.1390.1396
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He Y., 2017, JVETG0006
   He Y., 2017, JVETF0042
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li BY, 2017, INT CONF ADV ROBOT, P1
   Li L, 2020, IEEE J-STSP, V14, P130, DOI 10.1109/JSTSP.2019.2963154
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Lin JL, 2019, IEEE J EM SEL TOP C, V9, P84, DOI 10.1109/JETCAS.2019.2899660
   Liu YF, 2018, J VIS COMMUN IMAGE R, V53, P76, DOI 10.1016/j.jvcir.2018.03.001
   Liu YF, 2017, IEEE INT CON MULTI, P691, DOI 10.1109/ICME.2017.8019379
   Ma YF, 2002, IEEE IMAGE PROC, P129
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   Meddeb M, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.15
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun Y., 2016, JVETD0040
   Tang MH, 2017, IEEE INT CON MULTI, P799, DOI 10.1109/ICME.2017.8019460
   Wang CC, 2018, J VIS COMMUN IMAGE R, V54, P108, DOI 10.1016/j.jvcir.2018.05.001
   Wien M., 2019, IEEE J EMERGING SEL, V9
   Wu YY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165698
   Xu Q., 2017, JVETF0065
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zhou M, 2017, JVETG0056
NR 37
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103242
DI 10.1016/j.jvcir.2021.103242
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800007
DA 2024-07-18
ER

PT J
AU Sanyal, S
AF Sanyal, Samriddha
TI Who will receive the ball? Predicting pass recipient in soccer videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pass prediction; Dependent models; Soccer dataset
ID NETWORK ANALYSIS; TEAM
AB The game of soccer involves an act of one team trying to score a goal against the other. During the game, defending players constantly try to predict the pass of the attacking player to prevent a goal. So, pass prediction is an important facet to anticipate the game strategy of participating teams. Here we present a probabilistic framework for pass prediction. Aberrating the state-of-the-art notion of mutually independent decision models, the proposed framework predicts pass recipients by integrating two dependent models, designed from the coordinates of the players in abstract top-view visualization. To evaluate the real time efficacy of the proposed pass prediction framework, a soccer data set has been introduced. The proposed pass prediction algorithm is compared against recent methods and the ground truth available in the soccer data set. The proposed method outperforms the existing approaches by a noticeable margin.
C1 [Sanyal, Samriddha] Indian Stat Inst, 203 BT Rd, Kolkata 700108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Sanyal, S (corresponding author), Indian Stat Inst, 203 BT Rd, Kolkata 700108, India.
EM samriddha.s@gmail.com
OI Sanyal, Samriddha/0000-0002-8929-4038
FU Indian Statistical Institute
FX The primary funder is Indian Statistical Institute.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bialkowski A, 2016, IEEE T KNOWL DATA EN, V28, P2596, DOI 10.1109/TKDE.2016.2581158
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chawla S, 2017, ACM TRANS SPAT ALGOR, V3, DOI 10.1145/3105576
   Cintia P, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (IEEE DSAA 2015), P392
   Clemente Filipe Manuel, 2014, Motriz: rev. educ. fis., V20, P262
   Duch J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010937
   Felsen P, 2017, IEEE I CONF COMP VIS, P3362, DOI 10.1109/ICCV.2017.362
   Fewell JH, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047445
   Gama J, 2014, INT J PERF ANAL SPOR, V14, P692, DOI 10.1080/24748668.2014.11868752
   Giancola S, 2018, IEEE COMPUT SOC CONF, P1792, DOI 10.1109/CVPRW.2018.00223
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goes FR, 2019, BIG DATA-US, V7, P57, DOI 10.1089/big.2018.0067
   Gonçalves B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171156
   Grund TU, 2012, SOC NETWORKS, V34, P682, DOI 10.1016/j.socnet.2012.08.004
   Gudmundsson J, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054132
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Homayounfar N, 2017, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR.2017.427
   Link D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179953
   Lusher D, 2010, MEAS PHYS EDUC EXERC, V14, P211, DOI 10.1080/1091367X.2010.495559
   Maksai A, 2016, PROC CVPR IEEE, P972, DOI 10.1109/CVPR.2016.111
   Pappalardo L, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0247-7
   Pena J. Lopez, 2012, ARXIV1206
   Pettersen S. A., 2014, P ACM MULT SYST C MI, P18, DOI [10.1145/2557642.2563677, DOI 10.1145/2557642.2563677]
   Power P, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1605, DOI 10.1145/3097983.3098051
   Ramanathan V, 2016, PROC CVPR IEEE, P3043, DOI 10.1109/CVPR.2016.332
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rein R, 2017, HUM MOVEMENT SCI, V55, P172, DOI 10.1016/j.humov.2017.07.010
   Rein R, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3108-2
   Sanyal S., 2016, P 10 IND C COMP VIS, P1
   Sarkar S., 2019, P IEEE C COMP VIS PA
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spearman W., 2018, P 11 MIT SLOAN SPORT
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Taki T, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P815, DOI 10.1109/ICIP.1996.560865
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
NR 38
TC 4
Z9 4
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103190
DI 10.1016/j.jvcir.2021.103190
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500007
DA 2024-07-18
ER

PT J
AU Kumar, A
   Jha, RK
   Nishchal, NK
AF Kumar, Avishek
   Jha, Rajib Kumar
   Nishchal, Naveen K.
TI An improved Gamma correction model for image dehazing in a
   multi-exposure fusion framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Gamma correction model; Multi-exposure fusion
ID ENHANCEMENT
AB A usual problem encountered during bad weather conditions is the degraded image quality due to haze/fog. In basic Gamma correction method there is always an uncertainty regarding the choice of a particular exponential factor, which improves the quality of the input image because of the nonlinearity involved in the process. This issue has been solved in this study by proposing a modified Gamma correction method, in which the exponential correction factor is varied incrementally to generate images. We also propose the implementation of an automatic image selection criterion for fusion which helps chose images with varied and distinct features. The implementation of the multi-exposure fusion framework is done in the hue-saturation-value color space which has close resemblance with the human vision. The intensity channel of the selected images is fused in the gradient domain which captures minute details and takes an edge as compared to other conventional fusion based methods. The fused saturation channel is obtained by averaging fusion followed by enhancement using a non-linear sigmoid function. The hue channel of the input hazy image is left unprocessed to avoid color distortion. The experimental analysis demonstrates that the proposed method outperforms most of the single image dehazing methods.
C1 [Kumar, Avishek; Jha, Rajib Kumar] Indian Inst Technol Patna, Dept Elect Engn, Bihta 801106, Bihar, India.
   [Nishchal, Naveen K.] Indian Inst Technol Patna, Dept Phys, Bihta 801106, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology (IIT) - Patna
RP Nishchal, NK (corresponding author), Indian Inst Technol Patna, Dept Phys, Bihta 801106, Bihar, India.
EM nkn@iitp.ac.in
RI kumar, avishek/AAS-6112-2021
OI kumar, avishek/0000-0003-0927-3956; Nishchal, Naveen/0000-0001-7032-3946
FU CSIR [09/1023 (0021) /2018EMRI]
FX This work was supported by funding from CSIR, Govt. of India, under
   Grant Nos. 09/1023 (0021) /2018EMRI.
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Arriaga-Garcia EF, 2014, INT CONF ELECTR COMM, P28, DOI 10.1109/CONIELECOMP.2014.6808563
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Feng C, 2013, IEEE IMAGE PROC, P2363, DOI 10.1109/ICIP.2013.6738487
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gao Y, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103868
   Gao Y, 2019, IFAC PAPERSONLINE, V52, P225, DOI 10.1016/j.ifacol.2019.12.412
   Gao Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107284
   Gao YY, 2019, IEEE T MULTIMEDIA, V21, P351, DOI 10.1109/TMM.2018.2856095
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Hayat N, 2019, IET IMAGE PROCESS, V13, P2554, DOI 10.1049/iet-ipr.2019.0438
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hong S, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107798
   Hulburt EO, 1941, J OPT SOC AM, V31, P467, DOI 10.1364/JOSA.31.000467
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   Mehra I, 2014, OPT EXPRESS, V22, P5474, DOI 10.1364/OE.22.005474
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Naik SK, 2003, IEEE T IMAGE PROCESS, V12, P1591, DOI 10.1109/TIP.2003.819231
   Nishchal NK, 2020, IOP SER ADV OPT PHOT, P1, DOI 10.1088/978-0-7503-2220-1
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Sevcenco IS, 2015, MULTIDIM SYST SIGN P, V26, P717, DOI 10.1007/s11045-013-0262-3
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shin J, 2020, IEEE T MULTIMEDIA, V22, P30, DOI 10.1109/TMM.2019.2922127
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu G, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, PROCEEDINGS, P60, DOI 10.1109/ISCID.2009.22
   Yi Wan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457892
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zheng MY, 2020, IEEE SENS J, V20, P8062, DOI 10.1109/JSEN.2020.2981719
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 45
TC 19
Z9 19
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103122
DI 10.1016/j.jvcir.2021.103122
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LJ
UT WOS:000674616200002
DA 2024-07-18
ER

PT J
AU Gong, YX
   Wang, RG
   Yang, J
   Xue, LX
   Hu, M
AF Gong, Yuxiu
   Wang, Ronggui
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Person Re-identification with Global-Local Background_bias Net
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person Re-identification; Body misalignment; Foreground features;
   Background information
AB Person Re-identification (Re-ID) is an important technique in intelligent video surveillance. Because of the variations on camera viewpoints and body poses, there are some problems such as body misalignment, the diverse background clutters and partial bodies occlusion, etc. To address these problems, we propose the Global-Local Background_bias Net (GLBN), a novel network architecture that consists of Foreground Partial Segmentation Net (FPSN), Global Aligned Supervision Net (GASN) and Background_bias Constraint Net (BCN) modules. Firstly, to enhance the adaptability of foreground features and reduce the interference of the background, FPSN is applied to perform local segmentation on the foreground image. Secondly, global features generated by GASN are purposed to supervise the learning of local features. Finally, BCN constrains the background information to reduce the impact of background information again. Extensive experiments implemented on the mainstream evaluation datasets including Market1501, DukeMTMC-reID and CLIFIK03 indicate that our method is efficient and robust.
C1 [Gong, Yuxiu; Wang, Ronggui; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei 230601, Peoples R China.
C3 Hefei University of Technology
RP Gong, YX (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230601, Peoples R China.
EM yuxiugong888@gmail.com; yangjuan@hfut.edu.cn; jsjxhumin@hfut.edu.cn
RI Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]; State Key
   Program of NSFC-Shenzhen Joint Foundation [U1613217]
FX This study was funded by the National Natural Science Foundation of
   China (grant number 61672202) and State Key Program of NSFC-Shenzhen
   Joint Foundation (grant number U1613217).
CR [Anonymous], 2017, ARXIV
   [Anonymous], 2017, ARXIV170307220
   Bai S., 2016, IEEE T IMAGE PROCESS, V2, P4
   Borenstein E., 2004, P IEEE WORKSH PERC O
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Y., 2016, ICCV W CROSS DOMAIN, V6, P16
   Chung D., 2017, P IEEE C COMP VIS PA
   Dai Tang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P765, DOI 10.1109/ICME.2012.184
   Fan Liangzhong, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P1315
   Fu HZ, 2014, IEEE T CYBERNETICS, V44, P644, DOI 10.1109/TCYB.2013.2264051
   He K., 2018, IEEE T PATTERN ANAL, V42, P386, DOI DOI 10.1109/TPAMI.2018.2844175
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang H., 2018, P IEEE C COMP VIS PA, P2
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Lankton S, 2007, PROC SPIE, V6510, DOI 10.1117/12.709700
   Le C., 2017, INT C CONS EL AS ICC, P2
   Leibe B., 2017, ARXIV170307737CS
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W., 2014, COMPUTER VISION PATT, V1, P6
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin W., 2019, IEEE T CYBERNETICS
   Lin WY, 2017, IEEE T IMAGE PROCESS, V26, P2438, DOI 10.1109/TIP.2017.2683063
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu T., 2007, P IEEE C COMPUTER VI
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Rosenfeld A, 2011, IEEE I CONF COMP VIS, P1371, DOI 10.1109/ICCV.2011.6126391
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen C, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1942, DOI 10.1145/3123266.3123452
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Nguyen TB, 2016, INT CONF KNOWL SYS, P339, DOI 10.1109/KSE.2016.7758077
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang H., 2010, IEEE INT C AC SPEECH
   Wei L., 2017, ACM MM, V1, P6
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yi D., 2014, P INT C PATT REC ICP, V2, P8
   Yu-Chen Chang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P1, DOI 10.1109/ISPACS.2012.6473442
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L., 2017, IEEE T IMAGE PROCESS
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
NR 52
TC 0
Z9 1
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102961
DI 10.1016/j.jvcir.2020.102961
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OJ
UT WOS:000613150700003
DA 2024-07-18
ER

PT J
AU Wu, YC
   Wang, YM
   Liang, J
   Bajic, IV
   Wang, AH
AF Wu, Yingchun
   Wang, Yumei
   Liang, Jie
   Bajic, Ivan, V
   Wang, Anhong
TI Light field all-in-focus image fusion based on spatially-guided angular
   information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light field camera; Micro-lens array; All-in-focus image fusion; Spatial
   information; Angular information; Guided filtering
AB Compared to traditional 2D images, light field images record both spatial and angular information of the scene, which can provide more data for image fusion. In this paper, a light field all-in-focus image fusion algorithm based on spatially-guided angular information is proposed. In the proposed method, the initial weight maps carrying the angular information are calculated by comparing the block variance of the 4D light field data. The initial weight maps are then guided by digital refocused images carrying the spatial information to obtain the refined weight maps. In the refocused image multi-scale decomposition, the micro-lens calibration error is considered and the additional edge layers are extracted to suppress the edge artifacts. Experiments demonstrate the effectiveness of the proposed algorithm. Quantitative evaluation results show that the proposed algorithm performs the best in the feature-based index and structural similarity-based index without sacrificing the information and perceptual sharpness of the fused image.
C1 [Wu, Yingchun; Wang, Yumei; Wang, Anhong] Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
   [Liang, Jie; Bajic, Ivan, V] Simon Fraser Univ, Sch Engn Sci, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
C3 Taiyuan University of Science & Technology; Simon Fraser University
RP Wang, YM (corresponding author), Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
EM yingchunwu3030@foxmail.com; 1954569241@qq.com; jiel@sfu.ca
OI Liang, Jie/0000-0003-3003-4343
FU National Natural Science Foundation of China [61601318]; Shanxi
   Scholarship Council of China; Shanxi Science Foundation of Applied
   Foundational Research [201601D021078]; Fund of Shanxi Key Subjects
   Construction; Collaborative Innovation Center of Internet+3D Printing in
   Shanxi Province; Key Innovation Team of Shanxi 1331 Project; Scientific
   and Technological Innovation Team of Shanxi Province [201705D131025];
   Youth Foundation of Taiyuan University of Science and Technology
   [20132023]; Foundation of China Scholarship Council
FX This work was supported by the National Natural Science Foundation of
   China (61601318), Research Project Supported by Shanxi Scholarship
   Council of China, Shanxi Science Foundation of Applied Foundational
   Research (201601D021078), the Fund of Shanxi Key Subjects Construction,
   the Collaborative Innovation Center of Internet+3D Printing in Shanxi
   Province, Key Innovation Team of Shanxi 1331 Project, Scientific and
   Technological Innovation Team of Shanxi Province (201705D131025), Youth
   Foundation of Taiyuan University of Science and Technology (20132023)
   and Foundation of China Scholarship Council.
CR [Anonymous], 2005, Comput. Sci. Tech. Rep.
   Bok Y, 2017, IEEE T PATTERN ANAL, V39, P287, DOI 10.1109/TPAMI.2016.2541145
   Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Feichtenhofer C, 2013, IEEE SIGNAL PROC LET, V20, P379, DOI 10.1109/LSP.2013.2248711
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Haghighat M, 2014, I C APPL INF COMM TE, P424
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Juneja M., 2009, Int J Comput Theory Eng, V1, P614, DOI DOI 10.7763/IJCTE.2009.V1.100
   Lee M, 2016, IEEE T IMAGE PROCESS, V25, P1887, DOI 10.1109/TIP.2016.2523419
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li J, 2018, INFRARED PHYS TECHN, V89, P129, DOI 10.1016/j.infrared.2018.01.003
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu X., 2018, 3D IMAGE ACQUISITION
   Löytynoja M, 2008, I C DIGIT ECOSYST TE, P25
   Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256
   SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2
   Sun JG, 2018, J OPT SOC AM A, V35, P480, DOI 10.1364/JOSAA.35.000480
   Takahashi N.T., 2003, 13 INT C ART REAL TE, P3
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang SZ, 2018, PROC CVPR IEEE, P2031, DOI 10.1109/CVPR.2018.00217
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Xiong ZW, 2017, IEEE IMAGE PROC, P1612, DOI 10.1109/ICIP.2017.8296554
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang H, 2006, 2006 3RD INTERNATIONAL IEEE CONFERENCE INTELLIGENT SYSTEMS, VOLS 1 AND 2, P300
   Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333
   Zhang YX, 2019, SIGNAL IMAGE VIDEO P, V13, P727, DOI 10.1007/s11760-018-1402-x
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zou Jiabin, 2018, Journal of Computer Applications, V38, P859, DOI 10.11772/j.issn.1001-9081.2017081970
NR 33
TC 5
Z9 6
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102878
DI 10.1016/j.jvcir.2020.102878
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400007
DA 2024-07-18
ER

PT J
AU Joshi, G
   Singh, S
   Vig, R
AF Joshi, Garima
   Singh, Sukhwinder
   Vig, Renu
TI Taguchi-TOPSIS based HOG parameter selection for complex background sign
   language recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Histogram of Oriented Gradients (HOG); Taguchi; TOPSIS; Sign Language
   Recognition System (SLRS); Complex background; Indian Sign Language
   (ISL)
ID OPTIMIZATION; TRANSFORM; SYSTEM
AB This paper presents an approach to design Indian Sign Language (ISL) recognition system for complex background. In many applications, Histogram of Oriented Gradients (HOG) have been proved to be effective. However, it is observed that the choice of HOG parameters affects the feature vector size and its classification capability. The objective is to select the parameter values in order to have maximal accuracy at a minimal computational time and reduced feature vector size. A combined Taguchi and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) based decision-making technique is applied to determine the values of these parameters. Results show that the combined TOPSIS-Taguchi based technique is effective in selecting the parameter combination to get high overall performance. For the acquired ISL complex background dataset, the selected values of parameters are further used to obtain multi-level HOG resulting in the overall accuracy of 92% for 280 features. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Joshi, Garima; Vig, Renu] Panjab Univ, Elect & Commun Engn Dept, UIET, Sect 25, Chandigarh, India.
   [Singh, Sukhwinder] Panjab Univ, Comp Sci & Engn Dept, UIET, Sect 25, Chandigarh, India.
C3 Panjab University; Panjab University
RP Singh, S (corresponding author), Panjab Univ, Comp Sci & Engn Dept, UIET, Sect 25, Chandigarh, India.
EM sukhdalip@pu.ac.in
RI Singh, Sukhwinder/JGL-7957-2023; vig, renu/HJJ-0935-2023
CR Alirezaei M, 2019, EXPERT SYST APPL, V127, P47, DOI 10.1016/j.eswa.2019.02.037
   Balasubramaniyan S, 2017, J CHIN INST ENG, V40, P267, DOI 10.1080/02533839.2017.1308233
   Collumeau JF, 2011, INT SYMP IMAGE SIG, P247
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Feng KP, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P936, DOI 10.1109/IMSNA.2013.6743432
   Gupta P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P19, DOI 10.1109/ICCSP.2016.7754217
   Joshi G., 2018, ADV COMPUT DATA SCI, V905, P65
   Joshi G, 2018, IET COMPUT VIS, V12, P570, DOI 10.1049/iet-cvi.2017.0394
   Joshi G, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P541, DOI 10.5220/0006200905410548
   Kakade S., 2014, ADV COMPUT SCI INF T, V1, P27
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Kaur B, 2017, IMAGING SCI J, V65, P171, DOI 10.1080/13682199.2017.1311524
   Kaur B, 2016, ADV HUM-COMPUT INTER, V2016, DOI 10.1155/2016/6727806
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Munib Q, 2007, EXPERT SYST APPL, V32, P24, DOI 10.1016/j.eswa.2005.11.018
   Ong SCW, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P559, DOI 10.1109/AFGR.2004.1301592
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Qu J., 2012, 8 C NAT COMP, P1
   Saghapour E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184203
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shunmugesh K, 2017, ARCH METALL MATER, V62, P1803, DOI 10.1515/amm-2017-0273
   Simsek B, 2013, CHEMOMETR INTELL LAB, V125, P18, DOI 10.1016/j.chemolab.2013.03.012
   Stergiopoulou E, 2014, ENG APPL ARTIF INTEL, V35, P54, DOI 10.1016/j.engappai.2014.06.006
   Tavari N. V., 2014, International Journal of Computer Science and Information Technologies, V5, P3657
   Tian-Syung Lan, 2009, Information Technology Journal, V8, P917, DOI 10.3923/itj.2009.917.922
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Viswanathan D.M., 2014, INT C DAT SCI ENG, P221
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zyoud SH, 2017, EXPERT SYST APPL, V78, P158, DOI 10.1016/j.eswa.2017.02.016
NR 31
TC 14
Z9 14
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102834
DI 10.1016/j.jvcir.2020.102834
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400014
DA 2024-07-18
ER

PT J
AU Moreira, TP
   Menotti, D
   Pedrini, H
AF Moreira, Thierry Pinheiro
   Menotti, David
   Pedrini, Helio
TI Video action recognition based on visual rhythm representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Visual rhythm; Video sequences; Computer vision
ID DESCRIPTORS
AB Advances in video acquisition and storage technologies have promoted a great demand for automatic recognition of actions. The use of cameras for security and surveillance purposes has applications in several scenarios, such as airports, parks, banks, stations, roads, hospitals, supermarkets, industries, stadiums, schools. An inherent difficulty of the problem is the complexity of the scene under usual recording conditions, which may contain complex background and motion, multiple people on the scene, interactions with other actors or objects, and camera motion. Most recent databases are built primarily with shared recordings on YouTube and with snippets of movies, situations where these obstacles are not restricted. Another difficulty is the impact of the temporal dimension since it expands the size of the data, increasing computational cost and storage space. In this work, we present a methodology of volume description using the Visual Rhythm (VR) representation. This technique reshapes the original volume of the video into an image, where two-dimensional descriptors are computed. We investigated different strategies for constructing the representation by combining configurations in several image domains and traversing directions of the video frames. From this, we propose two feature extraction methods, Naive Visual Rhythm (Naive VR) and Visual Rhythm Trajectory Descriptor (VRTD). The first approach is the straightforward application of the technique in the original video volume, forming a holistic descriptor that considers action events as patterns and formats in the visual rhythm image. The second variation focuses on the analysis of small neighborhoods obtained from the process of dense trajectories, which allows the algorithm to capture details unnoticed by the global description. We tested our methods in eight public databases, one of hand gestures (SKIG), two in first person (DogCentric and JPL), and five in third person (Weizmann, KTH, MuHAVi, UCF11 and HMDB51). The results show that the developed techniques are able to extract motion elements along with format and appearance information, achieving competitive accuracy rates compared to state-of-the-art action recognition approaches. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Moreira, Thierry Pinheiro; Pedrini, Helio] Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
   [Menotti, David] Univ Fed Parana, Dept Informat, BR-81531980 Curitiba, Parana, Brazil.
C3 Universidade Estadual de Campinas; Universidade Federal do Parana
RP Pedrini, H (corresponding author), Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
EM helio@ic.unicamp.br
RI Menotti, David/M-6205-2014
OI Menotti, David/0000-0003-2430-2030
FU Sao Paulo Research Foundation (FAPESP) [2017/12646-3, 2015/03156-7,
   2014/12236-1]; National Council for Scientific and Technological
   Development (CNPq) [305169/2015-7]
FX Funding was provided by Sao Paulo Research Foundation (FAPESP Grants
   2017/12646-3, 2015/03156-7 and 2014/12236-1) and National Council for
   Scientific and Technological Development (CNPq Grant 305169/2015-7).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alcantara Marlon F., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2917, DOI 10.1109/ICASSP.2014.6854134
   Alcantara M.F., J ELECT IMAG, V25
   Alcantara M. F., 2013, 18 IB C PATT REC HAV, V8259, P471
   Almeida J, 2013, IEEE IMAGE PROC, P4412, DOI 10.1109/ICIP.2013.6738909
   Almeida R, 2017, LECT NOTES COMPUT SC, V10484, P185, DOI 10.1007/978-3-319-68560-1_17
   Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   [Anonymous], 2014, P 2 INT C HUM AG INT
   [Anonymous], 2013, Iberoamerican Congress on Pattern Recognition
   [Anonymous], COMP VIS PATT REC 19
   Antonucci A, 2015, INT J APPROX REASON, V56, P249, DOI 10.1016/j.ijar.2014.07.005
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Barkan O., 2013, COMP VIS INT C COMP
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bradski G.Dr., Dobb's Journal of Software Tools
   Choi J, 2008, ROUTL PHILOS COMPAN, P291
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Csurka G, 2011, COMM COM INF SC, V229, P28
   da Silva Pinto A., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P221, DOI 10.1109/SIBGRAPI.2012.38
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   de Alcantara MF, 2017, SIGNAL IMAGE VIDEO P, V11, P325, DOI 10.1007/s11760-016-0940-3
   Doumanoglou A., IET C P, V10
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Iwashita Y, 2014, INT C PATT RECOG, P4310, DOI 10.1109/ICPR.2014.739
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Javidani A., ARXIV180100192
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jhuang H., 2013, HMDB LARGE HUMAN MOT
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jones E., 2001, SciPy: Open source scientific tools for Python
   Kahani R., ABS171105523 CORR
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kihl O, 2016, MACH VISION APPL, V27, P351, DOI 10.1007/s00138-014-0652-z
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu L., 2013, 23 INT JOINT C ART I
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Tran LT, 2014, PALG STUD GLOB HIGHE, P3
   Moghaddam Z, 2014, IEEE T AUTOM SCI ENG, V11, P394, DOI 10.1109/TASE.2013.2262940
   Mohanaiah P., 2013, INT J SCI RES PUB, V3, P1, DOI 10.5772/58692
   Nazir S., COMPUT ELECT ENG
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peng X., ABS14054506
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Purwanto D, 2017, IEEE INT CON MULTI, P895, DOI 10.1109/ICME.2017.8019520
   Ravanbakhsh M., ABS151203980 CORR
   Rosa R.D., 2014, BRIT MACH VIS C
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Ryoo M.S., 2013, COMPUTER VISION PATT
   Schling B., 2011, The Boost C++ Libraries
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scikit-Image, 2018, SCIK IM HIST OR GRAD
   Shi F, 2015, IEEE WINT CONF APPL, P1107, DOI 10.1109/WACV.2015.152
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Takamine A, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P619, DOI 10.1109/SII.2015.7405050
   Valio FB, 2011, LECT NOTES COMPUT SC, V7042, P157, DOI 10.1007/978-3-642-25085-9_18
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Wang H., 2013, IMPROVED DENSE TRAJE
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   WANG L, 1990, PATTERN RECOGN, V23, P905, DOI 10.1016/0031-3203(90)90135-8
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Zaki HFM, 2017, PROC CVPR IEEE, P1619, DOI 10.1109/CVPR.2017.176
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 79
TC 7
Z9 7
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102771
DI 10.1016/j.jvcir.2020.102771
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900024
DA 2024-07-18
ER

PT J
AU Wang, D
   Hu, GQ
   Lyu, CZ
AF Wang, Dan
   Hu, Guoqing
   Lyu, Chengzhi
TI Multi-path connected network for medical image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Medical image segmentation; Multi-path connections; Convolutional neural
   networks; Encoder-decoder structure
ID NET
AB In recent years, deep learning has been successfully applied to medical image segmentation. However, as the network extends deeper, the consecutive downsampling operations will lead to more loss of spatial information. In addition, the limited data and diverse targets increase the difficulty for medical image segmentation. To address these issues, we propose a multi-path connected network (MCNet) for medical segmentation problems. It integrates multiple paths generated by pyramid pooling into the encoding phase to preserve semantic information and spatial details. We utilize multi-scale feature extractor block (MFE block) in the encoder to obtain large and multi-scale receptive fields. We evaluated MCNet on three medical datasets with different image modalities. The experimental results show that our method achieves better performance than the state-of-the-art approaches. Our model has strong feature learning ability and is robust to capture different scale targets. It can achieve satisfactory results while using only 0.98 million (M) parameters. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Wang, Dan; Hu, Guoqing; Lyu, Chengzhi] South China Univ Technol, Sch Mech & Automot Engn, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Wang, D (corresponding author), South China Univ Technol, Sch Mech & Automot Engn, Guangzhou, Peoples R China.
FU Nature Science Foundation of Guangdong province [2016A030313520]
FX This work is supported by the Nature Science Foundation of Guangdong
   province, No. 2016A030313520.
CR Adal KM, 2018, IEEE T BIO-MED ENG, V65, P1382, DOI 10.1109/TBME.2017.2752701
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   [Anonymous], 2017, ARXIV170408545
   [Anonymous], 2016, INT C LEARNING REPRE
   Chang J, 2019, J VIS COMMUN IMAGE R, V58, P316, DOI 10.1016/j.jvcir.2018.11.047
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia HZ, 2020, IEEE T MED IMAGING, V39, P447, DOI 10.1109/TMI.2019.2928056
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   KIM B, 2019, ARXIV190402872
   Li H, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102611
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li Y., 2017, ARXIV170300577
   Lian S, 2018, J VIS COMMUN IMAGE R, V56, P296, DOI 10.1016/j.jvcir.2018.10.001
   Lin D., 2018, EUR C COMP VIS ECCV
   Liu J, 2018, IEEE T BIO-MED ENG, V65, P1943, DOI 10.1109/TBME.2018.2845706
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Novikov AA, 2018, IEEE T MED IMAGING, V37, P1865, DOI 10.1109/TMI.2018.2806086
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roychowdhury S., 2017, IEEE J BIOMED HLTH I, V19, P1118
   Simonyan K., 2014, CORR
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wu YC, 2019, LECT NOTES COMPUT SC, V11764, P264, DOI 10.1007/978-3-030-32239-7_30
   Xie Y., 2019, ARXIV190303313
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 38
TC 9
Z9 10
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102852
DI 10.1016/j.jvcir.2020.102852
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400009
DA 2024-07-18
ER

PT J
AU Dai, KH
   Wang, YH
AF Dai, Kaiheng
   Wang, Yuehuan
TI End-to-end DeepNCC framework for robust visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; End-to-end framework; NCC; Template matching
ID NORMALIZED CROSS-CORRELATION; OBJECT TRACKING; SCALE
AB In this paper, we propose an NCC-based object tracking deep framework, which can be well initialized with the limited target samples in the first frame. The proposed framework contains a pretrained model, online feature fine-tuning layers and tracking processes. The pretrained model provides rich feature representations while online feature fine-tuning layers select discriminative and generic features for the tracked object. We choose normalized cross-correlation as a template tracking layer to perform the tracking process. To enable the learned features representation closely coordinated to the tracked target, we jointly train the feature representation network and tracking processes. In online tracking, an adaptive template and a fixed template are fused to find the optimal tracking results. Scale estimation and a high-confidence model update scheme are perfectly integrated into the framework to adapt to the target appearance changes. The extensive experiments demonstrate that the proposed tracker achieves superior performance compared with other state-of-the-art trackers. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Dai, Kaiheng; Wang, Yuehuan] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
   [Wang, Yuehuan] Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, YH (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
EM daikaiheng@hust.edu.cn; yuehwang@hust.edu.cn
OI Wang, Yuehuan/0000-0001-7046-7587
FU Chinese advanced research project [41415020402]; Fundamental Research
   Funds for the Central Universities [2017KFYXJJ179]; Aerospace Institute
   I University Joint Innovation Fund Project [CALT201810]
FX This work was supported by Chinese advanced research project (No.
   41415020402), the Fundamental Research Funds for the Central
   Universities (No. 2017KFYXJJ179), Aerospace Institute I University Joint
   Innovation Fund Project (No. CALT201810).
CR Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Buniatyan D., CORR
   Chen S, 2014, J VIS COMMUN IMAGE R, V25, P793, DOI 10.1016/j.jvcir.2014.01.010
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Di Caterina G, 2012, ELECTRON LETT, V48, P261, DOI 10.1049/el.2011.3888
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Donoser M., 2006, COMPUTER VISION PATT, V1, P553, DOI DOI 10.1109/CVPR.2006.107
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Grabner H., 2006, BMVC, P47
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jiang N, 2011, PROC CVPR IEEE, P1161, DOI 10.1109/CVPR.2011.5995716
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Lewis JP, 1994, PROC CANAD IMAG PROC, P120
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li ZY, 2017, J VIS COMMUN IMAGE R, V44, P1, DOI [10.1016/j.jvcir.2017.01.012, 10.16339/j.cnki.hdxbzkb.2017.11.001]
   Luo JW, 2010, IEEE T ULTRASON FERR, V57, P1347, DOI 10.1109/TUFFC.2010.1554
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mei X, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1818
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ruan Y, 2016, J VIS COMMUN IMAGE R, V35, P146, DOI 10.1016/j.jvcir.2015.12.009
   Subramaniam A, 2016, ADV NEUR IN, V29
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2625, DOI 10.1016/S0167-8655(03)00106-5
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang J, 2016, NEUROCOMPUTING, V200, P55, DOI 10.1016/j.neucom.2016.03.016
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang N., CORR
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang Q., CoRR
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhou T, 2017, IEEE T CIRC SYST VID, V27, P2153, DOI 10.1109/TCSVT.2016.2576941
   Zhou T, 2015, PATTERN RECOGN, V48, P2459, DOI 10.1016/j.patcog.2015.03.008
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 60
TC 2
Z9 2
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102800
DI 10.1016/j.jvcir.2020.102800
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900015
DA 2024-07-18
ER

PT J
AU Li, X
   Tang, HZ
   Zhang, DB
   Liu, T
   Mao, LZ
   Chen, TY
AF Li, Xiao.
   Tang, Hongzhong
   Zhang, Dongbo.
   Liu, Ting.
   Mao, Lizhen.
   Chen, Tianyu.
TI Histopathological image classification through discriminative feature
   learning and mutual information-based multi-channel joint sparse
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discriminative feature learning; Stack-based discriminative prediction
   sparse decomposition (SDPSD); Mutual information-based Multi-channel
   joint sparse model (MIMJSM); Histopathological image classification
ID FEATURE-EXTRACTION; FACE RECOGNITION; DICTIONARY; FRAMEWORK; PATHOLOGY;
   MODEL
AB Histopathological image classification is a very challenging task because of the biological heterogeneities and rich geometrical structures. In this paper, we propose a novel histopathological image classification framework, which includes the discriminative feature learning and the mutual information-based multi-channel joint sparse representation. We first propose a stack-based discriminative prediction sparse decomposition (SDPSD) model by incorporating the class labels information to predict deep discriminant features automatically. Subsequently, a mutual information-based multi-channel joint sparse model (MIMCJSM) is presented to jointly encode the common component and particular components of the discriminative features. Especially, the main advantage of the MIMCJSM is the construction of a joint dictionary using a mutual information criterion, which contains a common sub-dictionary and three particular sub-dictionaries. Based on the joint dictionary, the MIMCJSM captures the relationship of multi-channel features, which can improve discriminative ability of joint sparse representation coefficients. Finally, the joint sparse representation coefficients of different levels can be aggregated using the spatial pyramid matching (SPM) model, and the linear support vector machine (SVM) is used as the classifier. Experimental results on ADL and BreaKHis datasets demonstrate that our proposed framework consistently performs better than popular existing classification frameworks. Additionally, it can show promising strong-robustness performance for histopathological image classification. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Xiao.; Tang, Hongzhong; Zhang, Dongbo.; Liu, Ting.; Mao, Lizhen.; Chen, Tianyu.] Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
   [Li, Xiao.] Natl Univ Def Technol, Changsha 410022, Peoples R China.
   [Tang, Hongzhong; Zhang, Dongbo.; Liu, Ting.; Mao, Lizhen.; Chen, Tianyu.] Xiangtan Univ, Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan 411105, Peoples R China.
C3 Xiangtan University; National University of Defense Technology - China;
   Xiangtan University
RP Tang, HZ (corresponding author), Xiangtan Univ, Coll Automat & Elect Informat, Xiangtan 411105, Peoples R China.
EM diandiant@126.com
FU National Natural Science Foundation in china [61573299, 61602397];
   Natural Science Foundation of Hunan Province in China [2017JJ3315,
   2017JJ2251, 2016JJ3125]
FX This article is supported by National Natural Science Foundation in
   china (61573299, 61602397), Natural Science Foundation of Hunan Province
   in China (2017JJ3315, 2017JJ2251, 2016JJ3125).
CR Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Boureau Y.-l., 2008, ADV NEURAL INFORM PR, P1185
   Brachtel E, 2012, J BIOPHOTONICS, V5, P327, DOI 10.1002/jbio.201100103
   Chang H, 2015, INT J COMPUT VISION, V113, P3, DOI 10.1007/s11263-014-0790-9
   Chang H, 2013, LECT NOTES COMPUT SC, V8150, P91, DOI 10.1007/978-3-642-40763-5_12
   Diamant I, 2017, IEEE T BIO-MED ENG, V64, P1380, DOI 10.1109/TBME.2016.2605627
   Duarte MF, 2006, IPSN 2006: THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P177
   Ergin S, 2014, COMPUT BIOL MED, V51, P171, DOI 10.1016/j.compbiomed.2014.05.008
   Fu W, 2018, IEEE T GEOSCI REMOTE, V56, P1336, DOI 10.1109/TGRS.2017.2761893
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   He B, 2014, COGN COMPUT, V6, P264, DOI 10.1007/s12559-013-9224-1
   Irshad Humayun, 2013, J Pathol Inform, V4, pS12, DOI 10.4103/2153-3539.109870
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Kavukcuoglu K., 2008, CBLLTR20081201
   Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605, DOI 10.1109/CVPRW.2009.5206545
   Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861
   Li F, 2017, PATTERN RECOGN, V67, P410, DOI 10.1016/j.patcog.2017.02.025
   Luo J, 2012, COMM COM INF SC, V321, P497
   Lv L, 2017, COGN COMPUT, V9, P115, DOI 10.1007/s12559-016-9438-0
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J., 2008, NIPS, V21, P1033
   McCann MT, 2015, IEEE SIGNAL PROC MAG, V32, P78, DOI 10.1109/MSP.2014.2346443
   Monga V, 2013, ANIMAL DIAGNOSTICS L
   MOON YI, 1995, PHYS REV E, V52, P2318, DOI 10.1103/PhysRevE.52.2318
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Sarkar R, 2018, IEEE T IMAGE PROCESS, V27, P749, DOI 10.1109/TIP.2017.2763829
   Shi J, 2015, COMPUT MED IMAG GRAP, V41, P61, DOI 10.1016/j.compmedimag.2014.06.002
   Siddiqi MH, 2016, MULTIMED TOOLS APPL, V75, P935, DOI 10.1007/s11042-014-2333-3
   Song Y, 2015, IEEE T MED IMAGING, V34, P1362, DOI 10.1109/TMI.2015.2393954
   Song Y, 2015, MED IMAGE ANAL, V22, P102, DOI 10.1016/j.media.2015.03.003
   Song Y, 2018, NEUROCOMPUTING, V310, P277, DOI 10.1016/j.neucom.2018.05.036
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Srinivas U, 2014, IEEE T MED IMAGING, V33, P1163, DOI 10.1109/TMI.2014.2306173
   Srinivas U, 2013, I S BIOMED IMAGING, P1118
   SUROWIEC AJ, 1988, IEEE T BIO-MED ENG, V35, P257, DOI 10.1109/10.1374
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   Vu TH, 2015, I S BIOMED IMAGING, P990, DOI 10.1109/ISBI.2015.7164037
   Vu TH, 2016, IEEE T MED IMAGING, V35, P738, DOI 10.1109/TMI.2015.2493530
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yan K, 2017, ARTIF INTELL MED, V79, P1, DOI 10.1016/j.artmed.2017.03.006
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yu NN, 2013, J MATH IMAGING VIS, V45, P46, DOI 10.1007/s10851-012-0343-1
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967
   Zhang H, 2017, IEEE T PATTERN ANAL, V39, P1690, DOI 10.1109/TPAMI.2016.2613924
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang XF, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2461671
   Zheng P, 2017, PATTERN RECOGN, V63, P206, DOI 10.1016/j.patcog.2016.09.043
   Zhou Y, 2014, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2014.394
   Zhu SJ, 2018, J VIS COMMUN IMAGE R, V55, P243, DOI 10.1016/j.jvcir.2018.06.001
NR 58
TC 8
Z9 8
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102799
DI 10.1016/j.jvcir.2020.102799
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900014
DA 2024-07-18
ER

PT J
AU Sasithradevi, A
   Roomi, SMM
AF Sasithradevi, A.
   Roomi, Mohamed Mansoor S.
TI A new pyramidal opponent color-shape model based video shot boundary
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shot boundary detection; Abrupt transition; Gradual transition; Opponent
   color space; Ensemble algorithm
ID CUT DETECTION; EXTRACTION; HISTOGRAM; ALGORITHM
AB Video shot boundary detection (VSBD) is one of the most essential criteria for many intelligent video analysis-related applications, such as video retrieval, indexing, browsing, categorization and summarization. VSBD aims to segment big video data into meaningful fragments known as shots. This paper put forwards a new pyramidal opponent colour-shape (POCS) model which can detect abrupt transition (AT) and gradual transition (GT) simultaneously, even in the presence of illumination changes, huge object movement between frames, and fast camera motion. First, the content of frames in the video subjected to VSBD is represented by the proposed POCS model. Consequently, the temporal nature of the POCS model is subjected to a suitable segment (SS) selection procedure in order to minimize the complexity of VSBD method. The SS from the video frames is examined for transitions within it using a bagged-trees classifier (BTC) learned on a balanced training set via parallel processing. To prove the superiority of the proposed VSBD algorithm, it is evaluated on the TRECVID 2001, TRECVID2007 and VIDEOSEG2004 data sets for classifying the basic units of video according to no transition (NT), AT and GT. The experimental evaluation results in an F-l -score of 95.13%, 98.13% and 97.11% on the TRECVID 2001, TRECVID2007 and VIDEOSEG2004 data sets, respectively. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Sasithradevi, A.] VV Coll Engn, Dept Elect & Commun Engn, Tirunelveli, India.
   [Roomi, Mohamed Mansoor S.] Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Sasithradevi, A (corresponding author), VV Coll Engn, Dept Elect & Commun Engn, Tirunelveli, India.
EM sasithradevi@vvcoe.org; smmroomi@tce.edu
RI A, Sasithradevi/ABI-7042-2020; Sindha, Mohamed Mansoor
   Roomi/AAP-6496-2020
OI Anbalagan, Sasithradevi/0000-0001-5198-6648
CR Abdulhussain SH, 2019, MULTIMED TOOLS APPL, V78, P20361, DOI 10.1007/s11042-019-7364-3
   Almeida J, 2011, LECT NOTES COMPUT SC, V7042, P71, DOI 10.1007/978-3-642-25085-9_8
   Angadi SA., 2012, Comput Sci Inform Technol, V2, P57, DOI [10.5121/csit.2012.2307, DOI 10.5121/CSIT.2012.2307]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Bai Y, 2009, IEEE IMAGE PROC, P3305, DOI 10.1109/ICIP.2009.5413938
   Cirne M. V. M., 2017, MULTIMED TOOLS APPL, P1
   Dutta D, 2016, MULTIMED TOOLS APPL, V75, P93, DOI 10.1007/s11042-014-2273-y
   Fan JY, 2017, MULTIMED TOOLS APPL, V76, P10169, DOI 10.1007/s11042-016-3604-y
   Guimaraes SJF, 2009, INT J SEMANT COMPUT, V3, P155, DOI 10.1142/S1793351X09000707
   Fu QF, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P219, DOI 10.1109/CIS.2013.53
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Guder M, 2013, IEEE INT SYM MULTIM, P227, DOI 10.1109/ISM.2013.43
   Hanjalic A., 2004, CONTENT BASED ANAL D
   Janwe NJ, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P476, DOI 10.1109/ICIIP.2013.6707637
   Kar T, 2018, IET IMAGE PROCESS, V12, P1903, DOI 10.1049/iet-ipr.2017.1237
   Kikukawa T., 1992, Transactions of the Institute of Electronics, Information and Communication Engineers A, VJ75-A, P204
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Lienhart R, 1998, PROC SPIE, V3656, P290, DOI 10.1117/12.333848
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Liu F, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P351, DOI 10.1109/ICACI.2015.7184728
   Liu TR, 2014, INT CONF DIGIT SIG, P541, DOI 10.1109/ICDSP.2014.6900724
   Mondal J, 2018, MULTIMED TOOLS APPL, V77, P8139, DOI 10.1007/s11042-017-4707-9
   OTSUJI K, 1991, P SOC PHOTO-OPT INS, V1606, P980, DOI 10.1117/12.50328
   Pal G., 2015, INT J IMAGE MINING, V1, P87, DOI DOI 10.1504/IJIM.2015.070027
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Priya GGL, 2012, PROC TECH, V1, P247, DOI 10.1016/j.protcy.2012.10.030
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Santos ACSE, 2017, IEEE SYS MAN CYBERN, P1310, DOI 10.1109/SMC.2017.8122794
   SRRR AS., 2016, IJCTA, V9, P3231
   Whitehead A, 2004, LECT NOTES COMPUT SC, V3115, P410
   Youssef B, 2017, COMPUT VIS IMAGE UND, V161, P20, DOI 10.1016/j.cviu.2017.06.003
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
NR 39
TC 25
Z9 25
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102754
DI 10.1016/j.jvcir.2020.102754
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800006
DA 2024-07-18
ER

PT J
AU Li, CK
   Hou, YH
   Li, WQ
   Wang, PC
AF Li, Chuankun
   Hou, Yonghong
   Li, Wanqing
   Wang, Pichao
TI Learning attentive dynamic maps (ADMs) for Understanding Human Actions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human-robot/machine interaction; Deep learning; Human action recognition
ID ACTION RECOGNITION
AB This paper presents a novel end-to-end trainable deep architecture to learn an attentive dynamic map (ADM) for understanding human motion from skeleton data. An ADM intends not only to capture the dynamic information over the period of human motion, referred to as an action, as the conventional dynamic image/map does, but also to embed in it the spatio-temporal attention for the classification of the action. Specifically, skeleton sequences are encoded into sequences of Skeleton Joint Maps (STMs), each STM encodes both joint location (i.e. spatial) and relative temporal order (i.e. temporal) of the skeleton in the sequence. The STM sequences are fed into a customized 3DConvLSTM to explore the local and global spatio-temporal information from which a dynamic map is learned. This dynamic map is subsequently used to learn the spatio-temporal attention at each time-stamp. ADMs are then generated from the learned attention weights and all hidden states of the 3DConvLSTM and used for action classification. The proposed method achieved competitive performance compared with the state-of-the-art results on the Large Scale Combined dataset. MSRC-12 dataset and NTU RGB+D dataset. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Chuankun; Hou, Yonghong] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Li, Wanqing] Univ Wollongong, Adv Multimedia Res Lab, Wollongong, NSW, Australia.
   [Wang, Pichao] Alibaba Grp, San Mateo, CA USA.
C3 Tianjin University; University of Wollongong; Alibaba Group
RP Li, WQ (corresponding author), Univ Wollongong, Adv Multimedia Res Lab, Wollongong, NSW, Australia.
EM wanqing@uow.edu.au
RI Li, Wanqing/ABG-2620-2020
OI Wang, Pichao/0000-0002-1430-0237; Li, Wanqing/0000-0002-4427-2687
FU National Natural Science Foundation of China [61571325]; Key Projects in
   the Tianjin Science & Technology Pillar Program [16ZXHLGX001900]
FX This work was partly supported by the National Natural Science
   Foundation of China (grant 61571325) and Key Projects in the Tianjin
   Science & Technology Pillar Program (16ZXHLGX001900)
CR [Anonymous], PATTERN RECOGN
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], ARXIV170807590
   [Anonymous], 2015, NIPS 15 P 28 INT C N
   [Anonymous], ARXIV180304831
   [Anonymous], 32 AAAI C ART INT
   [Anonymous], ARXIV171106427
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], ARXIV170703141
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], ICLR
   [Anonymous], IEEE ACCESS
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   [Anonymous], 2017, IEEE CVPR
   [Anonymous], P EUROPEAN C COMPUTE
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.55
   Baradel F, 2017, IEEE INT CONF COMP V, P604, DOI 10.1109/ICCVW.2017.77
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Cao Z., 2017, P IEEE C COMP VIS PA, P7291
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen X, 2015, NEUROCOMPUTING, V149, P387, DOI 10.1016/j.neucom.2013.10.046
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2016, J CHEM RES, P579, DOI 10.3184/174751916X14733526548948
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feichtenhofer Christoph, 2017, P IEEE C COMP VIS PA, P4768
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hussein M.E., 2013, P 23 INT JOINT C ART
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Knez M, 2017, ADV KARST SCI, P3, DOI 10.1007/978-3-319-45465-8_1
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Li CL, 2017, INT CONF MACH LEARN, P1, DOI 10.1109/TPAMI.2017.2766142
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu JJ, 2017, CHIN CONTR CONF, P2432, DOI 10.23919/ChiCC.2017.8027723
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Simonyan K., 2013, Advances in Neural Information Processing Systems
   Song Jie, 2017, P IEEE C COMPUTER VI, P4220
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tang C., 2016, INT WORKSHOP UNDERST, P101
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xin M, 2016, IEEE IJCNN, P456, DOI 10.1109/IJCNN.2016.7727234
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang S, 2014, INT C PATT RECOG, P2613, DOI 10.1109/ICPR.2014.451
   Zhang HL, 2017, NEUROCOMPUTING, V230, P417, DOI 10.1016/j.neucom.2016.12.041
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
NR 68
TC 2
Z9 2
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102640
DI 10.1016/j.jvcir.2019.102640
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700015
DA 2024-07-18
ER

PT J
AU Mahdi, A
   Qin, J
AF Mahdi, Ali
   Qin, Jun
TI An extensive evaluation of deep featuresof convolutional neural networks
   for saliency prediction of human visual attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural networks; Feature maps; Human fixation prediction;
   Saliency map; Transfer learning
ID SCENE; SEARCH; SCALE; MODEL
AB Based on transfer learning, feature maps of deep convolutional neural networks (DCNNs) have been used to predict human visual attention. In this paper, we conduct extensive comparisons to investigate effects of feature maps on the predictions of the human visual attention using a deep features based saliency model framework. The feature maps of seven pretrained DCNNs are investigated using classical and class activation maps approaches. The performances of various saliency implementations are evaluated over four datasets using three metrics. The results demonstrate that deep feature maps of the pretrained DCNNs can be used to create saliency maps for the prediction of human visual attention. The incorporation of multiple levels of blurred and multi-scale feature maps improves the extraction of salient regions. Moreover, DCNNs pretrained using the Places dataset provide more localized objects that can be beneficial to the top-down saliency maps. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Mahdi, Ali; Qin, Jun] Southern Illinois Univ, Dept Elect & Comp Engn, Carbondale, IL 62901 USA.
C3 Southern Illinois University System; Southern Illinois University
RP Qin, J (corresponding author), Southern Illinois Univ, Dept Elect & Comp Engn, Carbondale, IL 62901 USA.
EM jqin@siu.edu
OI Qin, Jun/0000-0002-8186-5705
CR [Anonymous], 2008, BRIT MACHINE VISION
   [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], ARXIV170101081
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce N., 2010, Journal of Vision, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cornelis M., 2018, The Impact Human Health and Coffee on of Caffeine, P1
   Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720
   Gao K, 2008, 7TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE IN CONJUNCTION WITH 2ND IEEE/ACIS INTERNATIONAL WORKSHOP ON E-ACTIVITY, PROCEEDINGS, P191, DOI 10.1109/ICIS.2008.24
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Henderson JM, 1999, ANNU REV PSYCHOL, V50, P243, DOI 10.1146/annurev.psych.50.1.243
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Itti L., 2003, Realistic avatar eye and head animation using a neurobiological model of visual attention
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Judd T., 2012, A benchmark of computational models of saliency to predict human fixations
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kammerer M., 2015, INT C LEARN REPR ICL
   Kootstra G, 2011, COGN COMPUT, V3, P223, DOI 10.1007/s12559-010-9089-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lee K.W., 2003, INT WORKSHOP ATTENTI, P55
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2013, OPT LETT, V38, P700, DOI 10.1364/OL.38.000700
   Mahdi Ali, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P247, DOI 10.1109/BHI.2018.8333415
   Mahdi A, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P106, DOI 10.1109/DEVLRN.2015.7346124
   Mandi A., 2015, IEEE T COGNITIVE DEV, V10
   Mandi A., 2019, IEEE T COGNIT DEV SY
   Nothdurft Hans-Christoph, 2005, P233, DOI 10.1016/B978-012375731-9/50042-2
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pan J., ARXIV150701422
   Parkhurst DJ, 2003, SPATIAL VISION, V16, P125, DOI 10.1163/15685680360511645
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Tavakoli HR, 2017, NEUROCOMPUTING, V244, P10, DOI 10.1016/j.neucom.2017.03.018
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 62
TC 3
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102662
DI 10.1016/j.jvcir.2019.102662
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA JU0WA
UT WOS:000501398700020
DA 2024-07-18
ER

PT J
AU Xu, HY
   Xin, R
   Zhao, YF
   Jin, XM
AF Xu, Huiying
   Xin, Rui
   Zhao, Yufei
   Jin, Xianmei
TI Image quality study of CT imaging examination in children with childhood
   tumors under ultrasound-guided puncture
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Ultrasound; Puncture; Childhood tumor; CT imaging; Image quality
AB According to data released by the World Health Organization, malignant tumors have become the second leading cause of death among Chinese children. For malignant tumors, effective diagnostic information directly determines the subsequent treatment outcome. Because of the small age of children with childhood tumors and the specificity of their constitution, many diagnostic methods are not very effective in the diagnosis of children's tumors. Ultrasound-guided puncture is a widely used method. However, puncture and biopsy may lead to a series of serious complications such as bleeding, infection, organ damage and even tumor rupture. Regarding the complications caused by puncture and biopsy, most of the current studies use B-ultrasound imaging or even clinical observation to observe. Ultrasound is not applicable to bones and organs with more gas (such as intestinal tract). In response to these problems, this paper selects hospitalized children with solid tumors in the hospital oncology department, performs CT imaging examination on children who have undergone ultrasound-guided puncture, and conducts quality studies on CT imaging images to observe under ultrasound guidance. The complications after puncture were evaluated, and the feasibility of puncture biopsy in the diagnosis of childhood tumors was evaluated. The results show that the CT image after image quality control can meet the requirements of analyzing the condition and can effectively observe the complications after puncture. The results show that ultrasound-guided puncture can be used for the diagnosis of childhood tumors. (C) 2019 Published by Elsevier Inc.
C1 [Xu, Huiying] First Hosp Jilin Univ, Dept Ultrasound, Changchun 130021, Jilin, Peoples R China.
   [Xin, Rui] Jilin Univ, Dept Radiol, Hosp 2, Changchun 130021, Jilin, Peoples R China.
   [Zhao, Yufei; Jin, Xianmei] First Hosp Jilin Univ, Dept Pediat Oncol, Changchun 130021, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Jin, XM (corresponding author), First Hosp Jilin Univ, Dept Pediat Oncol, Changchun 130021, Jilin, Peoples R China.
EM gawayiyi@jlu.edu.cn; xinr@jlu.edu.cn; yfzhao15@mails.jlu.edu.cn;
   jxmei715@jlu.edu.cn
CR [Anonymous], 2018, ULTR FREQ CHAR IM AL
   [Anonymous], 2018, J CHENGDU U TECHNOL, V21, P6
   [Anonymous], 2018, ULTR GUID NONN PRESS
   Boustany NN, 1999, LAB INVEST, V79, P1201
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Li Lian, 2019, HLTH VISION, V8, P37
   Liu Zhi, 2018, IMAGING RES MED APPL, V17, P178
   Nair D., 2017, J VIS COMMUN IMAGE R
   Qi Qi, 2017, MED EQUIP, V38, P16
   Shan XJ, 2017, ACTA OCEANOL SIN, V36, P39, DOI 10.1007/s13131-017-1091-2
   Shen Keshu, 2019, CHINESE HLTH NUTR, V29, P76
   Sherbini A. M., 2015, Int. J. Sci. Res, V4, P1153, DOI DOI 10.7717/PEERJ-CS.270/FIG-1
   Tang Jingyan, 2017, CHINESE J PEDIAT, V55, P721
   Wang Jian, 2018, IMAGING RES MED APPL, V2
   Wei Zhang, 2018, CHINESE J PEDIAT, V20
   Xie Junhua, 2017, INT J LAB MED, V38, P1123
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Xu Xin, 2018, TELEVISION TECHNOL, V42, P41
   Yang HF, 2015, EXPERT SYST APPL, V42, P6168, DOI 10.1016/j.eswa.2015.03.019
   Yildiray Anagiin, 2019, J VIS COMMUN IMAGE R, V61, P178
   Yücebas SC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091404
   Zhang Caijie, 2017, MODERN HLTH, V12, P131
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang TT, 2017, SPECTROSC SPECT ANAL, V37, P594, DOI 10.3964/j.issn.1000-0593(2017)02-0594-05
   Zhang Xiaoli, 2018, MAGN RESON IMAGING, V9
   Zhen Zijun, 2015, FAM MED, V6, P6
   2018, WORLDS LATEST MED IN, V18, P39
NR 33
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102630
DI 10.1016/j.jvcir.2019.102630
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700011
DA 2024-07-18
ER

PT J
AU Zhou, LF
   Li, WS
   Du, YW
   Lei, BJ
   Liang, S
AF Zhou, Lifang
   Li, Weisheng
   Du, Yuewei
   Lei, Bangjun
   Liang, Shan
TI Adaptive illumination-invariant face recognition via local nonlinear
   multi-layer contrast feature
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Illumination invariant face recognition; Local binary patterns; Local
   nonlinear multi-layer contrast patterns; Fuzzy fusion framework
ID VARYING ILLUMINATION; PATTERNS
AB Traditional face recognition method usually faces the challenge of varying lighting condition. In this paper, we propose an illumination-invariant local binary descriptor learning method for face recognition. Unlike local binary descriptor (LBP) and its variants, which usually utilize the rigid sign function for binarization despite of data distributions. We first determine a dynamic thresholds strategy including the information of illumination variation to extract nonlinear multi-layer contrast features. Specially, Exponential Discriminant Analysis (EDA) is designed to act as preprocessing which can contribute to improve the discriminative ability of the face image by enlarging the margin between different classes relative to the same class. To further improve the recognition performance, we combined our preliminary work, the adaptive fuzzy fusion framework, to integrate the recognition results for multi-scale features spaces. Extensive experiments conducted on four face databases validate the effectiveness of the proposed method for illumination face recognition. (C) 2019 Published by Elsevier Inc.
C1 [Zhou, Lifang; Li, Weisheng; Du, Yuewei] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
   [Lei, Bangjun] China Three Gorges Univ, Hubei Key Lab Intelligent Vis Based Monitoring Hy, Yichang 443002, Peoples R China.
   [Zhou, Lifang] Chongqing Univ Posts & Telecommun, Coll Software, Chongqing 400000, Peoples R China.
   [Zhou, Lifang; Liang, Shan] Chongqing Univ, Coll Automat, Chongqing 400044, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; China Three Gorges
   University; Chongqing University of Posts & Telecommunications;
   Chongqing University
RP Zhou, LF (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
EM zhoulf@cqupt.edu.cn
FU Natural Science Foundation of China [61100114, U1401252]; Chongqing
   Overseas Scholars Innovation Program [cx2018124]; Hubei Key Laboratory
   of Intelligent Vision Based Monitoring for Hydroelectric Engineering
   [2017SDSJ02]; Natural science foundation of Chongqing
   [cstc2019jcyj-msxmx0461]
FX This work was supported in part by Natural Science Foundation of China
   (No. 61100114, U1401252), Chongqing Overseas Scholars Innovation Program
   (cx2018124), Hubei Key Laboratory of Intelligent Vision Based Monitoring
   for Hydroelectric Engineering (2017SDSJ02). Natural science foundation
   of Chongqing (cstc2019jcyj-msxmx0461)
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Akhloufi MA, 2010, IEEE SYS MAN CYBERN, P3308, DOI 10.1109/ICSMC.2010.5642391
   [Anonymous], PATTERN RECOGN
   [Anonymous], CALTECH FRONTAL FACE
   [Anonymous], IEEE T PATTERN ANAL
   Chen HX, 2011, INT J PATTERN RECOGN, V25, P147, DOI 10.1142/S0218001411008518
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Duan YQ, 2018, PROC CVPR IEEE, P8270, DOI 10.1109/CVPR.2018.00863
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Faraji MR, 2014, IEEE SIGNAL PROC LET, V21, P1457, DOI 10.1109/LSP.2014.2343213
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   Huang D, 2007, LECT NOTES COMPUT SC, V4842, P437
   Huang WL, 2017, PATTERN RECOGN, V68, P126, DOI 10.1016/j.patcog.2017.03.010
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kang CC, 2014, NEUROCOMPUTING, V133, P141, DOI 10.1016/j.neucom.2013.11.022
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang HT, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P819
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Yu YF, 2017, PATTERN RECOGN, V67, P201, DOI 10.1016/j.patcog.2017.02.004
   Zhang TP, 2010, IEEE T SYST MAN CY B, V40, P186, DOI 10.1109/TSMCB.2009.2024759
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
   Zhou LF, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413560028
   Zhu CR, 2012, INFORM SCIENCES, V187, P93, DOI 10.1016/j.ins.2011.10.014
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 44
TC 8
Z9 9
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102641
DI 10.1016/j.jvcir.2019.102641
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600025
DA 2024-07-18
ER

PT J
AU Fong, CM
   Wang, HW
   Kuo, CH
   Hsieh, PC
AF Fong, Cher-Min
   Wang, Hui-Wen
   Kuo, Chien-Hung
   Hsieh, Pei-Chun
TI Image quality assessment for advertising applications based on neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Image quality assessment; Image classification
ID STREAMS
AB Image quality assessment (IQA) is a key technique in computer vision, which is widely applied in image classification, image aesthetic prediction. IQA plays an important role in advertising assessment system, which can recommend higher quality advertising for users. However, traditional algorithms cannot effectively predict advertising quality. In this paper, we propose an advertising assessment system using IQA algorithm based on neural networks. Specifically, we first incorporate both low-level features and high-level sematic features for image representation, where manifold learning algorithm is leveraged for high-level feature learning. Then, we leverage CNN based method for deep representation learning, which will be concatenated into deep feature vector. Finally, we leverage HMM model for learning image quality of advertising based on learned feature vector. Comprehensive experiments show the effectiveness of our proposed method. (C) 2019 Published by Elsevier Inc.
C1 [Fong, Cher-Min; Wang, Hui-Wen; Hsieh, Pei-Chun] Natl Sun Yat Sen Univ, Dept Business Management, 70 Lien Hai Rd, Kaohsiung 804, Taiwan.
   [Kuo, Chien-Hung] Natl Sun Yat Sen Univ, Inst Human Resource Management, 70 Lien Hai Rd, Kaohsiung 804, Taiwan.
C3 National Sun Yat Sen University; National Sun Yat Sen University
RP Fong, CM (corresponding author), Natl Sun Yat Sen Univ, Dept Business Management, 70 Lien Hai Rd, Kaohsiung 804, Taiwan.
EM cmfong@bm.nsysu.eud.tw
RI Wang, Huiwen/JED-3206-2023
CR Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   [Anonymous], P SPIE INT SOC OPT E
   [Anonymous], J SHANDONG U
   [Anonymous], 2017, IPSJ T COMPUT VIS AP, DOI DOI 10.1186/s41074-017-0020-9
   [Anonymous], SCI CHINA INFORM SCI
   Ansari R, 2007, PROC SPIE, V6566, DOI 10.1117/12.720984
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen CF, 2015, NEUROCOMPUTING, V168, P941, DOI 10.1016/j.neucom.2015.05.031
   Chen CF, 2012, COMPUT GEOSCI-UK, V48, P9, DOI 10.1016/j.cageo.2012.05.018
   Chen JZ, 2015, PATTERN ANAL APPL, V18, P441, DOI 10.1007/s10044-014-0427-1
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Chi Y, 2006, KNOWL INF SYST, V10, P265, DOI 10.1007/s10115-006-0003-0
   Claussen JC, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005361
   Datar M, 2002, SIAM J COMPUT, V31, P1794, DOI 10.1137/S0097539701398363
   Gibbons PB, 2004, THEOR COMPUT SYST, V37, P457, DOI 10.1007/s00224-004-1156-4
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   ISHIKAWA A, 1990, J ELECTRON MICROSC, V39, P73
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Lin XM, 2005, PROC INT CONF DATA, P502
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Pang ZH, 2016, IEEE T CYBERNETICS, V46, P1400, DOI 10.1109/TCYB.2015.2448031
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Sultana NN, 2018, IET COMPUT VIS, V12, P1096, DOI 10.1049/iet-cvi.2018.5238
   Tao YF, 2006, IEEE T KNOWL DATA EN, V18, P377, DOI 10.1109/TKDE.2006.48
   Tian G, 2017, INFORM SYST FRONT, V19, P75, DOI 10.1007/s10796-015-9590-1
   Wang F, 2016, INFORM SCIENCES, V370, P385, DOI 10.1016/j.ins.2016.07.070
   Wang ZG, 2015, NEUROCOMPUTING, V149, P100, DOI 10.1016/j.neucom.2014.03.072
   Wen HG, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22160-9
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhang XM, 2017, NEUROCOMPUTING, V235, P182, DOI 10.1016/j.neucom.2017.01.011
   Zhong Z., 2017, IEEE T GEOSCI ELECT, VPP, P1
   Zhou AY, 2008, KNOWL INF SYST, V15, P181, DOI 10.1007/s10115-007-0070-x
   Zhu DD, 2018, J VIS COMMUN IMAGE R, V54, P1, DOI 10.1016/j.jvcir.2018.03.017
   Zou L, 2017, IEEE T CYBERNETICS, V47, P1830, DOI 10.1109/TCYB.2017.2685425
   Zou SM, 2005, J ADVERTISING, V34, P99, DOI 10.1080/00913367.2005.10639185
NR 36
TC 3
Z9 4
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102593
DI 10.1016/j.jvcir.2019.102593
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200027
DA 2024-07-18
ER

PT J
AU Stosic, D
   Stosic, D
   Ludermir, TB
   Ren, TI
AF Stosic, Dusan
   Stosic, Darko
   Ludermir, Teresa Bernarda
   Ren, Tsang Ing
TI Natural image segmentation with non-extensive mixture models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-extensive statistics; Image segmentation; q-Gaussians; Finite
   mixture models
ID NEURAL-NETWORKS; DISTRIBUTIONS; CONSTRAINTS; ALGEBRA; SYSTEMS; SHAPE;
   CUTS
AB Finite mixture models have been widely used for image segmentation in many computer vision and pattern recognition problems. While images of natural scenes are difficult to model, we can employ emerging concepts from statistical physics to achieve better representations. This paper introduces a new class of finite mixture models for solving such problems. The proposed non-extensive mixture models have real-valued power-law exponents that characterize the degree of correlations. The exponents are used to capture rare or frequent occurring patterns in the image. They can describe complex features found with a hierarchy of sizes in natural images: from small objects with a few dozen pixels to large ones that occupy the entire image. We also present a method to determine the parameters based on maximum likelihood estimation. Our numerical experiments indicate more robust and accurate capabilities of non-extensive mixture models for natural image segmentation than conventional mixture models. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Stosic, Dusan; Stosic, Darko; Ludermir, Teresa Bernarda; Ren, Tsang Ing] Univ Fed Pernambuco, Ctr Informat, BR-50670901 Recife, PE, Brazil.
C3 Universidade Federal de Pernambuco
RP Stosic, D (corresponding author), Univ Fed Pernambuco, Ctr Informat, BR-50670901 Recife, PE, Brazil.
EM dbstosic@bu.edu; ddstosic@bu.edu; tbl@cin.ufpe.br; tir@cin.ufpe.br
RI Ren, Tsang Ing/AAD-3221-2022; Ludermir, Teresa B/F-6766-2012
OI Ludermir, Teresa B/0000-0002-8980-6742; Ing Ren,
   Tsang/0000-0002-3677-0264
FU Brazilian agency CAPES; Brazilian agency CNPq [442668/2014-7,
   140840/2016-8]
FX This work is supported by Brazilian agencies CAPES and CNPq (grants No.
   442668/2014-7 and No. 140840/2016-8).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bach SH, 2017, PR MACH LEARN RES, V70
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Borges EP, 2004, PHYSICA A, V340, P95, DOI 10.1016/j.physa.2004.03.082
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Di Zio M, 2007, COMPUT STAT DATA AN, V51, P2573, DOI 10.1016/j.csda.2006.01.001
   Erdil E, 2017, IEEE T IMAGE PROCESS, V26, P5312, DOI 10.1109/TIP.2017.2728185
   Franco M, 2009, STAT PROBABIL LETT, V79, P1724, DOI 10.1016/j.spl.2009.05.005
   Han LX, 2006, OPTIM METHOD SOFTW, V21, P1, DOI 10.1080/10556780512331318290
   Han V.-H., 2012, UBIQUITOUS INFORM TE
   Harsha SS, 2016, INT J ADV COMPUT SC, V7, P17
   Hazan A, 2003, COMPUT STAT DATA AN, V42, P111, DOI 10.1016/S0167-9473(02)00153-6
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Inoue N, 2013, J VIS COMMUN IMAGE R, V24, P1450, DOI 10.1016/j.jvcir.2013.10.005
   Ji Y, 2005, BIOINFORMATICS, V21, P2118, DOI 10.1093/bioinformatics/bti318
   Kasun LLC, 2016, IEEE T IMAGE PROCESS, V25, P3906, DOI 10.1109/TIP.2016.2570569
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Koopman BO, 1936, T AM MATH SOC, V39, P399, DOI 10.2307/1989758
   Lee SX, 2013, ADV DATA ANAL CLASSI, V7, P241, DOI 10.1007/s11634-013-0132-8
   Lenzi EK, 1999, J PHYS A-MATH GEN, V32, P8551, DOI 10.1088/0305-4470/32/48/314
   Lina Y.-C., 2017, INT J ENG SCI INNOV, V6
   Maji P, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040305
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mayrose I, 2005, BIOINFORMATICS, V21, P151, DOI 10.1093/bioinformatics/bti1125
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   Nadarajah S, 2007, PHYSICA A, V377, P465, DOI 10.1016/j.physa.2006.11.054
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Nguyen DMH, 2017, IEEE WINT CONF APPL, P815, DOI 10.1109/WACV.2017.96
   Nie D, 2019, IEEE T CYBERNETICS, V49, P1123, DOI 10.1109/TCYB.2018.2797905
   Nivanen L, 2003, REP MATH PHYS, V52, P437, DOI 10.1016/S0034-4877(03)80040-X
   Pearson K., 1894, Philosophical Transactions, V185a, P71, DOI 10.1098/rsta.1894.0003
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Picoli S, 2009, BRAZ J PHYS, V39, P468, DOI 10.1590/S0103-97332009000400023
   Richardson J. M., 1969, Journal of Statistical Physics, V1, P71, DOI 10.1007/BF01007242
   Roh Y., ARXIV181103402CSLG
   Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4
   Saremi S, 2016, IEEE T PATTERN ANAL, V38, P1016, DOI 10.1109/TPAMI.2015.2481402
   Saremi S, 2013, P NATL ACAD SCI USA, V110, P3071, DOI 10.1073/pnas.1222618110
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sima HF, 2018, IEEE T SYST MAN CY-S, V48, P354, DOI 10.1109/TSMC.2016.2608831
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Nguyen TM, 2014, PATTERN RECOGN, V47, P3132, DOI 10.1016/j.patcog.2014.03.030
   Nguyen TM, 2013, IEEE T CYBERNETICS, V43, P751, DOI 10.1109/TSMCB.2012.2215849
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Tsallis C., 1994, Quim. Nova, V17, P468
   Tsallis C., NONEXTENSIVE STAT ME
   Umarov S, 2008, PHYS LETT A, V372, P4874, DOI 10.1016/j.physleta.2008.04.071
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang J, 2018, IEEE T IMAGE PROCESS, V27, P2420, DOI 10.1109/TIP.2018.2804218
   Zheng Q, 2018, J VIS COMMUN IMAGE R, V55, P157, DOI 10.1016/j.jvcir.2018.06.005
   Zong B., 2018, P 6 INT C LEARN REPR
NR 62
TC 5
Z9 5
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102598
DI 10.1016/j.jvcir.2019.102598
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200024
DA 2024-07-18
ER

PT J
AU Sun, YQ
   Li, L
   Zheng, L
   Hu, J
   Li, WC
   Jiang, YT
   Yan, CG
AF Sun, Yaoqi
   Li, Liang
   Zheng, Liang
   Hu, Ji
   Li, Wenchao
   Jiang, Yatong
   Yan, Chenggang
TI Image classification base on PCA of multi-view deep representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; Principal component analysis; Multi-view depth
   characters
AB In the age of information explosion, image classification is the key technology of dealing with and organizing a large number of image data. Currently, the classical image classification algorithms are mostly based on RGB images or grayscale images, and fail to make good use of the depth information about objects or scenes. The depth information in the images has a strong complementary effect, which can enhance the classification accuracy significantly. In this paper, we propose an image classification technology using principal component analysis based on multi-view depth characters. In detail, firstly, the depth image of the original image is estimated; secondly, depth characters are extracted from the RGB views and the depth view separately, and then the reducing dimension operation through the PCA is implemented. Eventually, the SVM is applied to image classification. The experimental results show that the method has good performance. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Sun, Yaoqi; Zheng, Liang; Hu, Ji; Li, Wenchao; Jiang, Yatong; Yan, Chenggang] Hangzhou Dianzi Univ, Hangzhou, Peoples R China.
   [Li, Liang] Chinese Acad Sci, Inst Comp Technol, Kexueyuan South Rd 6, Beijing, Peoples R China.
C3 Hangzhou Dianzi University; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS
RP Zheng, L (corresponding author), Hangzhou Dianzi Univ, Hangzhou, Peoples R China.; Li, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Kexueyuan South Rd 6, Beijing, Peoples R China.
EM liang.li@ict.ac.cn; zhengliang@hdu.edu.cn
RI Zheng, Liang/AAU-4903-2021; sun, jiamin/JPY-2155-2023; Li,
   Wenchao/S-5567-2016; liu, peiyao/KFT-1810-2024
OI Zheng, Liang/0000-0002-3459-1844; Li, Wenchao/0000-0003-4756-6397; Li,
   Liang/0000-0002-1943-8219
CR [Anonymous], ACM INT C MULT
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], INT C ART INT
   [Anonymous], 2016, IEEE INT C 3D VIS 3D
   [Anonymous], IEEE CVPR2017
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2016 ACM
   [Anonymous], 2016, Learning From Multiple Social Networks
   [Anonymous], OBJECT OPTIM
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Goodkind JR, 2014, PSYCHOL SERV, V11, P333, DOI 10.1037/a0035081
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HOPFIELD JJ, 1988, IEEE CIRCUIT DEVIC, V4, P3, DOI 10.1109/101.8118
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jones N, 2014, NATURE, V505, P146, DOI 10.1038/505146a
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Li L, 2010, AAAI CONF ARTIF INTE, P1377
   Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063
   Nikhil R., 2008, 2008 IEEE C COMP VIS, P1
   Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   [余凯 Yu Kai], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P1799
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
NR 33
TC 22
Z9 23
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 253
EP 258
DI 10.1016/j.jvcir.2019.05.016
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600024
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shastri, S
   Thanikaiselvan, V
AF Shastri, Shounak
   Thanikaiselvan, V.
TI Dual image reversible data hiding using trinary assignment and centre
   folding strategy with low distortion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Dual images; Centre folding strategy; Trinary
   assignment; High PSNR; High security
AB Dual image Reversible Data Hiding (RDH) algorithms generate two stego images instead of one. These algorithms are considered more secure because the secret data can be recovered only if both stego images are available. This paper proposes a dual image RDH algorithm based on the Centre Folding Strategy (CFS) and the Shiftable Pixel Coordinate Selection Strategy. The proposed algorithm improves the visual quality of the two stego images while maintaining a high embedding rate. It uses a look-up table containing the shifts that the cover pixel will undergo after the data has been embedded. Some overhead information is required for accurate extraction of the hidden data and it is delivered to the users as a password after embedding. The results show that the proposed algorithm outperforms other methods in terms of visual quality with an average Peak-Signal-to-Noise-Ratio (PSNR) of 50.66 dB with an embedding rate of 1.56 bits per pixel. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Shastri, Shounak; Thanikaiselvan, V.] VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Thanikaiselvan, V (corresponding author), VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM thanikaiselvan@vit.ac.in
OI Shastri, Shounak/0000-0002-2247-9046; Thanikaiselvan,
   V/0000-0003-2418-5217
CR Alattar AM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Franzen Rich, 1999, KODAK LOSSLESS TRUE, V4
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P6225, DOI 10.1007/s11042-017-4533-0
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lu TC, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9100223
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yao H, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0281-y
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   2013, SIGNAL PROCESS, V93, P154, DOI DOI 10.1016/J.SIGPRO.2012.07.012
   2015, SIGNAL PROCESS, V108, P77, DOI DOI 10.1016/J.SIGPRO.2014.08.022
   2013, DIGIT SIGNAL PROCESS, V23, P919, DOI DOI 10.1016/J.DSP.2012.12.014
NR 34
TC 10
Z9 10
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 130
EP 140
DI 10.1016/j.jvcir.2019.03.022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100014
DA 2024-07-18
ER

PT J
AU Huang, HH
   Xu, Y
   Hua, X
   Yan, WX
   Huang, YJ
AF Huang, Honghe
   Xu, Yi
   Hua, Xiao
   Yan, Weixiong
   Huang, Yanjie
TI A crowdsourced system for robust eye tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eye tracking; Gaze shifting path; Large-scale dataset; CNN
AB Eye tracking is widely used in modern intelligent applications, such as HCI, somatosensory game and fatigue driving. Traditional eye tracking system based on Haar-like features or external hardware, which is loss of accuracy and complicated. It is obviously that human gaze point is related to head pose. However, the label of head pose in most dataset is ambiguous. So in this paper, we propose a crowdsourced system which can collect large-scale dataset for eye tracking. For better performance, we leverage head guidance point and random dot instead of fixed dot as the concern when capture frames from camera. And different illumination, poses and persons also considered for robust performance. And we propose a two-phase CNN training strategy for combining head pose and eye angles. The proposed CNN architecture can reduce the overfitting when we train eye tracking models with head pose directly. The experimental results show that our proposed method can perform well in eye tracking. (C) 2019 Published by Elsevier Inc.
C1 [Huang, Honghe; Xu, Yi; Hua, Xiao; Yan, Weixiong; Huang, Yanjie] State Grid Zhejiang Quzhou Power Supply Co, Hangzhou, Zhejiang, Peoples R China.
RP Huang, HH (corresponding author), State Grid Zhejiang Quzhou Power Supply Co, Hangzhou, Zhejiang, Peoples R China.
EM honghe_huang@126.com
RI huang, yan/GWM-4747-2022; Huang, YQ/JOK-7580-2023
CR Baltrusaitis Tadas, 2016 IEEE WINT C WAC
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Deng H, 2017, IEEE I CONF COMP VIS, P3162, DOI 10.1109/ICCV.2017.341
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Sun L, 2014, IEEE INT CON MULTI
   Wood E., 2015, ICCV
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2018, IEEE T MULTIMEDIA, V20, P1462, DOI 10.1109/TMM.2017.2769799
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang LM, 2016, IEEE T AUTOM SCI ENG, V13, P894, DOI 10.1109/TASE.2015.2418223
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2015, IEEE T NEUR NET LEAR, V26, P1622, DOI 10.1109/TNNLS.2014.2347398
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 34
TC 4
Z9 4
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 28
EP 32
DI 10.1016/j.jvcir.2019.01.007
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000003
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Shen, ZQ
AF Zhang, Xialin
   Shen, Zaiquan
TI Copyright protection method for 3D model of geological body based on
   digital watermarking technology
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital watermarking; Geological body; Point cloud model; Copyright
   protection
ID TRANSFORMATION
AB In the continuous development of Internet technology and geological information technology, problems such as illegal possession, copying, modification and dissemination of unauthorized digital products have occurred in the field of geological information technology. In the field of geological information technology, not only traditional digital products such as text, image, audio and video are produced, but also 3D model digital products unique to geological information technology, which are geological bodies, geological phenomena, geological structures, geological processes and geology. Regular 3D visualization analysis and the foundation and platform for comprehensive decision making of 3D visualization, the 3D model of geological body plays an increasingly important role in the field of geological information technology. Of course, it also faces the problems faced by traditional digital products and copyright protection. In this paper, the advantages and disadvantages of digital watermarking technology in copyright protection and the characteristics of geological body 3D model itself, and the current mature 3D model digital watermarking algorithm are introduced. The research idea of 3D geological body digital watermarking algorithm based on point cloud model is proposed. According to the spatial characteristics of the point cloud model of geological body, the spatial characteristic variables of the point cloud model are obtained by using the spatial characteristic analysis algorithm. The spatial domain information represented by the spatial characteristic variables is transformed into the frequency domain information, and then the frequency domain information is analyzed by means of mathematical statistics to extract the digital watermarking information of the whole geological body point cloud model. The feasibility of the algorithm is analyzed and verified by the experimental analysis. The digital watermark information before and after the attack is extracted by geometric attacks such as affine transformation and shearing. The extracted digital watermark information is correlated with the coefficient analysis and the robustness of the algorithm is obtained. A better robustness effect can effectively protect the copyright of the owner of the 3D model of the geological body. (C) 2018 Published by Elsevier Inc.
C1 [Zhang, Xialin] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
   [Zhang, Xialin; Shen, Zaiquan] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences; China University of Geosciences
RP Zhang, XL (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.; Zhang, XL (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Hubei, Peoples R China.
EM zhangxialin@cug.edu.cn
FU National Natural Science Foundation of China [U1711267]; Guizhou science
   and technology project "Development and application of big data
   management and intelligent processing system for manganese exploration
   and development" [[2017]2951]; China national uranium Co. Ltd project
   "Digital uranium exploration system"; Geological research project of
   Guizhou Bureau of Geology and mineral resources exploration and
   development"
FX This work was supported by the National Natural Science Foundation of
   China (No. U1711267). Guizhou science and technology project
   "Development and application of big data management and intelligent
   processing system for manganese exploration and development (No.
   [2017]2951)". China national uranium Co. Ltd project "Digital uranium
   exploration system". Geological research project of Guizhou Bureau of
   Geology and mineral resources exploration and development"
CR Aggoun A, 2011, J DISP TECHNOL, V7, P586, DOI 10.1109/JDT.2011.2159359
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Ding S, 2004, COMPUT AIDED DESIGN, V36, P1281, DOI 10.1016/S0010-4485(03)00109-X
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   Dong P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P489, DOI 10.1109/ICIP.2002.1039014
   Durupt A, 2008, VIRTUAL PHYS PROTOTY, V3, P51, DOI 10.1080/17452750802047917
   Edward J., 2001, SIGNAL PROCESS MAG, V14, P33
   Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85
   Jassim T., 2013, NEW ROBUST FRAGILE W, P465
   Kandhway K, 2008, TENCON IEEE REGION, P18
   Kohei M., 2003, ISM S STAT COMB GEOM
   Liang C, 2008, GEOMETRIC MODELING AND ALGEBRAIC GEOMETRY, P199, DOI 10.1007/978-3-540-72185-7_11
   Díaz-Toca GM, 2014, APPL MATH COMPUT, V228, P349, DOI 10.1016/j.amc.2013.11.099
   Megalingam RK, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P349, DOI 10.1109/ICSAP.2010.79
   Motwani R, 2010, SECOND INTERNATIONAL CONFERENCE ON FUTURE NETWORKS: ICFN 2010, P447, DOI 10.1109/ICFN.2010.104
   Nakazawa S., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P110, DOI 10.1109/IIHMSP.2010.35
   Sakurai Y., 2010, SYST COMPUT JPN, V36, P88
   Santhi V, 2013, J INF SECUR APPL, V18, P167, DOI 10.1016/j.istr.2013.01.001
   Spielman DA, 2010, PROCEEDINGS OF THE INTERNATIONAL CONGRESS OF MATHEMATICIANS, VOL IV: INVITED LECTURES, P2698
   Tarmissi K, 2009, EXPERT SYST APPL, V36, P9409, DOI 10.1016/j.eswa.2008.12.062
   Uccheddu F., 2004, PROC ACM MULTIMEDIA, P143
   Yambor Wendy S., 2000, EMPIRICAL EVAL TECH, P39
   Yucesoy CA, 2002, J BIOMECH, V35, P1253, DOI 10.1016/S0021-9290(02)00069-6
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
NR 25
TC 5
Z9 6
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 334
EP 346
DI 10.1016/j.jvcir.2018.12.013
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600035
DA 2024-07-18
ER

PT J
AU Zhou, SR
   Ke, ML
   Luo, P
AF Zhou, Shuren
   Ke, Maolin
   Luo, Peng
TI Multi-camera transfer GAN for person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Generative adversarial networks; Deep learning; Computer vision; Person
   re-identification
ID ADAPTATION
AB Person re-identification is a cross-camera retrieval task. Person re-identification performance in a single dataset has been significantly improved, but person re-identification model trained in one dataset usually can't work well in another dataset. To solve this problem, this paper proposes a method of image-to image translation, CTGAN (Multi-Camera Transfer GAN), which can be performed on multiple camera domains of pedestrian dataset by using one single model. The marked training images are transferred to each camera of the target dataset. At the same time, for the feature learning model, this paper adopts the MSCDA (Mixed Selective Convolution Descriptor Aggregation) method, which can locate the main pedestrian objects in the image, filter out the background noise, and keep the useful depth descriptor. In the paper, experiments show that the method is effective. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhou, Shuren; Ke, Maolin; Luo, Peng] Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
   [Zhou, Shuren; Ke, Maolin; Luo, Peng] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology
RP Zhou, SR (corresponding author), Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
EM zsr@csust.edu.cn
RI zhou, shuren/JNS-2873-2023; Zhou, Shu-Ren/AAI-9134-2020
OI zhou, shuren/0000-0002-0465-3258; 
FU Scientific Research Fund of Hunan Provincial Education Department of
   China [17A007]; Teaching Reform and Research Project of Hunan Province
   of China
FX This work was supported by the Scientific Research Fund of Hunan
   Provincial Education Department of China (Project No. 17A007); and the
   Teaching Reform and Research Project of Hunan Province of China (Project
   No. JG1615).
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu Ming Yu, 2016, ADV NEURAL INF PROCE, P469
   Odena Augustus., 2016, Semi-supervised learning with generative adversarial networks
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Radford A., 2015, ARXIV
   Reed S, 2016, PR MACH LEARN RES, V48
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Wu L., 2016, ARXIV160107255
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 37
TC 100
Z9 102
U1 3
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 393
EP 400
DI 10.1016/j.jvcir.2019.01.029
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600041
DA 2024-07-18
ER

PT J
AU Shan, PF
   Lai, XP
AF Shan Pengfei
   Lai Xingping
TI Influence of CT scanning parameters on rock and soil images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image processing; Relative standard deviation; Parameters;
   Geotechnical CT image
ID DAMAGE
AB Geotechnical mechanical testing machine is an important means to study the characteristics of rock and soil rupture, which is of great significance in shale gas exploitation, nuclear waste disposal and earthquake prediction. For the convenience of research, the complex structure of rock and soil is often neglected, and the geotechnical material is regarded as a macro continuum. On this basis, a new method is used, X-ray CT scale cracks, crack size is larger than the micro-scale cracks, the number of cracks is less, but geotechnical CT images can still show the crack initiation location, propagation path, through the process, cracks and the relationship between aggregate mortar. When CT-scale microcracks can be found, the length of microcracks is equal to the magnitude of aggregate-scale, and can be compared with numerical simulation results. In this paper, four different kinds of soil samples are selected to design relevant tests. The specific effects of CT scanning parameters on CT images of rock and soil samples are studied by direct and indirect methods combined with CT number curves under different scanning conditions. The results show that the scanning voltage and filtering function have great influence on CT images and CT numbers of rock and soil samples. The enhancement or inhibition of the filtering function to the geotechnical CT image depends on the property of the selected filtering function, but has nothing to do with the soil quality of the sample. Finally, the selection principle of the CT scanning parameters is given. With the help of reasonable CT scanning parameters, the quality of the geotechnical CT image can be improved and the relatively accurate geotechnical CT value can be obtained. (C) 2018 Published by Elsevier Inc.
C1 [Shan Pengfei; Lai Xingping] Xian Univ Sci & Technol, Sch Energy Engn, Xian 710054, Shaanxi, Peoples R China.
C3 Xi'an University of Science & Technology
RP Shan, PF (corresponding author), Xian Univ Sci & Technol, Sch Energy Engn, Xian 710054, Shaanxi, Peoples R China.
EM shanpengfei@xust.edu.cn; laixp@xust.edu.cn
FU 973 Key National Basic Research Program of China [2015CB251602]; China
   Postdoctoral Science Foundation [2017M623328XB]; Science and Technology
   Innovation Team Project of Shaanxi Province [2018TD-038]; Natural
   Science Foundation of Shaanxi Province [2018JQ5194]; Hunan Province
   Engineering Research Center of Radioactive Control Technology in Uranium
   Mining and Metallurgy & Hunan Province Engineering Technology Research
   Center of Uranium Tailings Treatment Technology [2018YKZX2001]
FX Financial support for this work was provided by the 973 Key National
   Basic Research Program of China (no. 2015CB251602), the China
   Postdoctoral Science Foundation (no. 2017M623328XB), the Science and
   Technology Innovation Team Project of Shaanxi Province (no. 2018TD-038),
   the Natural Science Foundation of Shaanxi Province (no. 2018JQ5194), the
   Hunan Province Engineering Research Center of Radioactive Control
   Technology in Uranium Mining and Metallurgy & Hunan Province Engineering
   Technology Research Center of Uranium Tailings Treatment Technology (no.
   2018YKZX2001). Support from these agencies is gratefully acknowledged.
CR Calderwood LB, 2015, J INTEGR PEST MANAG, V6, DOI 10.1093/jipm/pmv017
   Cheng M. S., 2016, CHINESE J GEOTECH EN
   Dai B., 2018, KSCE J CIV ENG, V3, P1
   Forghani A, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, 2015, VOL 3
   Hong M. H., 2016, CHINA RURAL WATER HY
   Jian-Ping L. I., 2015, J SICHUAN ORDNANCE
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Li XW, 2014, ROCK SOIL MECH, V35, P141
   Liu H., 2016, CHIN J UNDERGR SPACE
   Ma TS, 2014, PETROL EXPLOR DEV+, V41, P249, DOI 10.1016/S1876-3804(14)60029-X
   Manahiloh KN, 2018, J NONDESTRUCT EVAL, V37, DOI 10.1007/s10921-018-0508-y
   Murphey MD, 2014, RADIOGRAPHICS, V34, P1003, DOI 10.1148/rg.344140019
   Owlia M, 2014, AM J MED, V127, P406, DOI 10.1016/j.amjmed.2014.01.023
   Park K., 2015, Appl. Mech. Rev., V64, P1002
   Simonyan A, 2018, ECOTOX ENVIRON SAFE, V154, P13, DOI 10.1016/j.ecoenv.2018.02.025
   [孙华飞 Sun Huafei], 2014, [煤炭学报, Journal of China Coal Society], V39, P452
   Tian W., 2016, ENG J WUHAN U
   Tian W. L., 2016, ROCK SOIL MECH
   Wang Y, 2015, ENVIRON EARTH SCI, V73, P5545, DOI 10.1007/s12665-014-3808-2
   Wang Y, 2015, BIOMED PHARMACOTHER, V74, P1, DOI 10.1016/j.biopha.2015.05.007
   Weida NJ., 2017, YANGTZE RIVER
   Xie J., 2015, J CHANGSHA U SCI TEC
   Yashuai L. I., 2018, J HEBEI U ENG
   Zhang N. L., 2017, J EXP MECH
   Zhang WP, 2017, SAUDI J BIOL SCI, V24, P563, DOI 10.1016/j.sjbs.2017.01.027
   Zheng Y., 2018, LASER TECHNOL
NR 26
TC 37
Z9 40
U1 9
U2 65
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 642
EP 650
DI 10.1016/j.jvcir.2018.12.014
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100061
DA 2024-07-18
ER

PT J
AU Zhang, XX
   Zhu, ZF
   Zhao, Y
AF Zhang, Xingxing
   Zhu, Zhenfeng
   Zhao, Yao
TI Sparsity induced prototype learning via <i>l</i><sub>p,1</sub>-norm
   grouping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Prototype; Subset selection; l(p,1)-norm; Sparse learning; Video
   summarization
ID ALGORITHM; SELECTION
AB Prototype learning aims to eliminate redundancy of large-scale data by selecting an informative subset. It is at the center of visual data analysis and processing. However, due to intrinsic structures among sample groups, the learnt prototypes are generally less representative and diversified. To alleviate this issue, we develop in this paper a structurally regularized model via l(p,1)-norm grouping, in which both the intra-group and inter-group structures of source data in object-space are rationally exploited. Thus, while the learnt representative prototypes are prone to distribute in different groups at the inter-group level, the grouping constraint via l(p,1)-norm will enforce the greatest diversity for intra-group prototypes. Considering the convexity in the formulated model, an alternative re-weighting solver is presented to efficiently solve the proposed optimization problem. Experimental results on video summarization, scene categorization and handwriting recognition demonstrate that the proposed method is considerably superior to the state-of-the-art methods in prototype learning. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhu, Zhenfeng] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Zhu, ZF (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM zhangxing@bjtu.edu.cn; zhfzhu@bjtu.edu.cn; yzhao@bjtu.edu.cn
RI Zhang, Xingxing/HGE-4445-2022
OI Zhang, Xingxing/0000-0002-9838-6962
FU National Key Research and Development of China [2016YFB0800404];
   National Natural Science Foundation of China [61532005, 61332012,
   61572068]; Fundamental Research Funds for the Central Universities
   [2018JBZ001]
FX This work was supported in part by the National Key Research and
   Development of China under Grant 2016YFB0800404, in part by the National
   Natural Science Foundation of China under Grants 61532005, 61332012, and
   61572068 and in part by the Fundamental Research Funds for the Central
   Universities under Grant 2018JBZ001.
CR Bahrampour S, 2016, IEEE T IMAGE PROCESS, V25, P24, DOI 10.1109/TIP.2015.2496275
   Bao CL, 2013, IEEE I CONF COMP VIS, P3384, DOI 10.1109/ICCV.2013.420
   Bien Jacob., 2010, Advances in Neural Information Processing Systems, P217
   Borzeshi EZ, 2013, PATTERN RECOGN, V46, P1648, DOI 10.1016/j.patcog.2012.11.020
   Boyd S., 2004, CONVEX OPTIMIZATION
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   CHAN TF, 1987, LINEAR ALGEBRA APPL, V88-9, P67, DOI 10.1016/0024-3795(87)90103-0
   Chang F, 2006, J MACH LEARN RES, V7, P2125
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dornaika F, 2015, PATTERN RECOGN, V48, P3714, DOI 10.1016/j.patcog.2015.05.018
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Elhamifar E., 2012, P INT C NEUR INF PRO, P19
   Elhamifar E, 2016, IEEE T PATTERN ANAL, V38, P2182, DOI 10.1109/TPAMI.2015.2511748
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Franc V, 2003, LECT NOTES COMPUT SC, V2756, P426
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   García S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006
   García S, 2012, IEEE T PATTERN ANAL, V34, P417, DOI 10.1109/TPAMI.2011.142
   Har-Peled S., 2003, ADV NEURAL INFORM PR, P809
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jin XB, 2010, PATTERN RECOGN, V43, P2428, DOI 10.1016/j.patcog.2010.01.013
   Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
   Kong DG, 2016, AAAI CONF ARTIF INTE, P1765
   Kulesza A., 2011, P 28 INT C MACH LEAR, P1193
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Motai Y, 2013, IEEE T KNOWL DATA EN, V25, P1863, DOI 10.1109/TKDE.2012.110
   Motwani Rajeev, 1995, RANDOMIZED ALGORITHM
   Nandan M, 2014, J MACH LEARN RES, V15, P59
   Simonyan K., 2014, 14091556 ARXIV
   Subedi S, 2016, IEEE T SIGNAL PROCES, V64, P3619, DOI 10.1109/TSP.2016.2552498
   Vidal R, 2008, AUTOMATICA, V44, P2274, DOI 10.1016/j.automatica.2008.01.025
   Wang HX, 2017, PATTERN RECOGN, V63, P268, DOI 10.1016/j.patcog.2016.10.014
   Wang SS, 2013, J MACH LEARN RES, V14, P2729
   Xiao B, 2010, NEUROCOMPUTING, V73, P840, DOI 10.1016/j.neucom.2009.10.014
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Zhang XX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3141
   Zhang XX, 2018, IEEE T CIRC SYST VID, V28, P3066, DOI 10.1109/TCSVT.2017.2713480
   Zheng S, 2011, LECT NOTES COMPUT SC, V7064, P629, DOI 10.1007/978-3-642-24965-5_71
NR 46
TC 1
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 192
EP 201
DI 10.1016/j.jvcir.2018.10.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400023
DA 2024-07-18
ER

PT J
AU Dehnavi, M
   Eshghi, M
AF Dehnavi, M.
   Eshghi, M.
TI Cost and power efficient FPGA based stereo vision system using
   directional graph transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FPGA; Stereo vision; Hardware architecture; Disparity map
ID MANY-CORE PROCESSORS; DISPARITY ESTIMATION; PARALLEL FRAMEWORK;
   AGGREGATION; CENSUS
AB 3D information of an environment using stereo cameras is important information for navigation of intelligent systems. The cost, power, accuracy, and speed are four important parameters in these systems. In this article, an accurate, real-time, low-power and low-cost system is provided to extract disparity maps in a stereo vision, using FPGA hardware platform. First, a new transform based on directional graphs is proposed. Then, benefiting from this graph transform and cross-based matching method, disparity map is computed. By using optimized hardware for the proposed transform and algorithm, we have obtained an accurate, low-cost, low-power and fast stereo vision system. The proposed system is fully implemented on relatively low cost FPGA platform, XC7K160t, in order to operate as a Standalone system. This system uses 40 K registers, 31 K LUTs, 215 memory blocks, and 258 DSP blocks of this FPGA. The proposed system is tested and evaluated in Middlebury dataset. The results show that the proposed stereo system can process a HD quality video at 60 frames per second for 64 disparity levels with only 7.1% error in the final disparity map. The total power consumption of the proposed stereo vision core is about 1 W. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Dehnavi, M.; Eshghi, M.] Shahid Beheshti Univ, EC Dept, Tehran, Iran.
C3 Shahid Beheshti University
RP Dehnavi, M (corresponding author), Shahid Beheshti Univ, EC Dept, Tehran, Iran.
EM M.Dehnavi@sbu.ac.ir
OI Dehnavi, Mohammad/0000-0003-0896-6734
CR [Anonymous], P AS C COMP VIS, DOI DOI 10.1007/978-3-642-19315-6_3
   Pham CC, 2013, IEEE T CIRC SYST VID, V23, P1119, DOI 10.1109/TCSVT.2012.2223794
   Dehnavi M, 2017, J SYST ARCHITECT, V81, P32, DOI 10.1016/j.sysarc.2017.10.002
   Einecke N., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P227, DOI 10.1109/DICTA.2010.49
   Galar M, 2011, IEEE T IMAGE PROCESS, V20, P1949, DOI 10.1109/TIP.2011.2107525
   Greisen P, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-18
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hu G, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P177
   Huq S, 2013, COMPUT VIS IMAGE UND, V117, P688, DOI 10.1016/j.cviu.2013.01.008
   Jiao JB, 2014, IEEE MULTIMEDIA, V21, P16, DOI 10.1109/MMUL.2014.51
   Jin MX, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2567659
   Jin S, 2010, IEEE T CIRC SYST VID, V20, P15, DOI 10.1109/TCSVT.2009.2026831
   Kim S, 2016, DIGIT SIGNAL PROCESS, V53, P51, DOI 10.1016/j.dsp.2015.12.019
   Kim S, 2014, IEEE T CIRC SYST VID, V24, P1844, DOI 10.1109/TCSVT.2014.2329377
   LEE SH, 2011, IEEE T CONSUMER ELEC, V57
   Lee Z, 2013, IEEE T MULTIMEDIA, V15, P1855, DOI 10.1109/TMM.2013.2270456
   Livatino S, 2015, IEEE T IND ELECTRON, V62, P525, DOI 10.1109/TIE.2014.2334675
   Michailidis GT, 2014, IEEE T CIRC SYST VID, V24, P929, DOI 10.1109/TCSVT.2013.2290575
   Min DB, 2013, IEEE T PATTERN ANAL, V35, P2539, DOI 10.1109/TPAMI.2013.15
   Mozerov MG, 2015, IEEE T IMAGE PROCESS, V24, P1153, DOI 10.1109/TIP.2015.2395820
   Pei SC, 2013, I SYMP CONSUM ELECTR, P209
   Huynh P, 2016, C IND ELECT APPL, P988, DOI 10.1109/ICIEA.2016.7603726
   Schumacher F, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P3064, DOI 10.1109/ITSC.2014.6958182
   Shan Y, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584659
   Tian J. J., 2016, 2016 P 10 EUR C ANT, DOI DOI 10.1109/SSCI.2016.7850209
   Ttofis C, 2016, IEEE T COMPUT, V65, P2678, DOI 10.1109/TC.2015.2506567
   Vala CK, 2018, IEEE T CIRCUITS-I, V65, P606, DOI 10.1109/TCSI.2017.2729084
   Wang WQ, 2015, IEEE T CIRC SYST VID, V25, P1696, DOI 10.1109/TCSVT.2015.2397196
   Xu Y, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/594782
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Zhan YL, 2016, IEEE T CIRC SYST VID, V26, P1632, DOI 10.1109/TCSVT.2015.2473375
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhang L, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P55
   Zicari P, 2013, MICROPROCESS MICROSY, V37, P1144, DOI 10.1016/j.micpro.2013.09.007
   Zicari P, 2012, MICROPROCESS MICROSY, V36, P281, DOI 10.1016/j.micpro.2012.02.014
NR 38
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 106
EP 115
DI 10.1016/j.jvcir.2018.09.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500009
DA 2024-07-18
ER

PT J
AU Han, DX
   Chen, H
   Tu, CH
   Xu, YY
AF Han, Dongxue
   Chen, Hui
   Tu, Changhe
   Xu, Yanyan
TI View synthesis using foreground object extraction for disparity control
   and image inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Virtual view synthesis; DIBR; Disparity control; Exemplar-based
   inpainting; Foreground object extraction
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; VISUAL COMFORT; GENERATION;
   DISPLAY; SYSTEM; VIDEO
AB Among the rapidly growing three-dimensional technologies, multiview displays have drawn great research interests in three-dimensional television due to their adaption to the motion parallax and wider viewing angles. However, multiview displays still suffer from dazzling discomfort on the border of viewing zones. Leveraging on the separability of scene via foreground segmentation, we propose a novel virtual view synthesis method for depth-image-based rendering to alleviate the discomfort. Foreground objects of interest are extracted to segment the whole image into multiple layers, which are further warped to the virtual viewpoint in order. To alleviate the visual discomfort, global disparity adjustments and local depth control are performed for specific objects in each layer. For the post-processing, we improve an exemplar-based inpainting algorithm to tackle the disoccluded areas. Experimental results demonstrate that our method achieves effective disparity control and generates high-quality virtual view images. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Han, Dongxue; Chen, Hui] Shandong Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Tu, Changhe] Shandong Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Xu, Yanyan] MIT, Dept Civil & Environm Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 Shandong University; Shandong University; Massachusetts Institute of
   Technology (MIT)
RP Chen, H (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.; Xu, YY (corresponding author), MIT, Dept Civil & Environm Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM huichen@sdu.edu.cn; yanyanxu@mit.edu
RI Tu, Changhe/H-5162-2013
FU Key Project of National Natural Science Foundation of China [61332015];
   Natural Science Foundation of Shandong Province of China [ZR2013FM302,
   ZR2017MF057]
FX This work is supported by the Key Project of National Natural Science
   Foundation of China under Grant No. 61332015, and the Natural Science
   Foundation of Shandong Province of China under Grant Nos. ZR2013FM302
   and ZR2017MF057. Thanks also goes to Dr. Weiping Huang and the
   Foundation of Hisense.
CR Ahn I, 2013, IEEE T BROADCAST, V59, P614, DOI 10.1109/TBC.2013.2281658
   [Anonymous], SIGN INF PROC ASS AN
   [Anonymous], ELECT IMAGING
   [Anonymous], 2011, P 2011 3DTV C TRUE V, DOI DOI 10.1109/3DTV.2011.5877181
   [Anonymous], 2007, PROC IEEE C COMPUT V
   Arai J, 2017, P IEEE, V105, P837, DOI 10.1109/JPROC.2017.2652541
   Celikcan U, 2013, VISUAL COMPUT, V29, P685, DOI 10.1007/s00371-013-0804-6
   Chang YJ, 2016, J VIS COMMUN IMAGE R, V40, P118, DOI 10.1016/j.jvcir.2016.06.017
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo Ismael, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P167, DOI 10.1109/MMSP.2010.5662013
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Gotfryd M., ISOIECJTC1SC29WG11MP
   Kiechle M, 2013, IEEE I CONF COMP VIS, P1545, DOI 10.1109/ICCV.2013.195
   Lei JJ, 2014, J DISP TECHNOL, V10, P373, DOI 10.1109/JDT.2014.2312648
   Mangiat S., 2012, 2012 IEEE International Conference on Emerging Signal Processing Applications, P147, DOI 10.1109/ESPA.2012.6152467
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Muddala SM, 2016, J VIS COMMUN IMAGE R, V38, P351, DOI 10.1016/j.jvcir.2016.02.017
   Shen J, 2013, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2013.157
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Sohn H, 2014, IEEE T CIRC SYST VID, V24, P745, DOI 10.1109/TCSVT.2013.2291281
   Tam WJ, 2011, IEEE T BROADCAST, V57, P335, DOI 10.1109/TBC.2011.2125070
   Tehrani MP, 2017, APSIPA TRANS SIGNAL, V6, DOI 10.1017/ATSIP.2017.5
   Tian Y., 2016, APPL COMP VIS WACV 2, P1
   Um G., JTC1SC29WG11 ISOIEC
   Wang LH, 2015, MULTIMED TOOLS APPL, V74, P9529, DOI 10.1007/s11042-014-2133-9
   [王颖 Wang Ying], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P452
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao C. H., 2017, COMPUT VISUAL MEDIA, V3, P387
   Yamanoue H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1701, DOI 10.1109/ICME.2006.262877
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 35
TC 9
Z9 9
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 287
EP 295
DI 10.1016/j.jvcir.2018.10.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500028
DA 2024-07-18
ER

PT J
AU Fakhar, B
   Kanan, HR
   Behrad, A
AF Fakhar, Babak
   Kanan, Hamidreza Rashidy
   Behrad, Alireza
TI Learning an event-oriented and discriminative dictionary based on an
   adaptive label-consistent K-SVD method for event detection in soccer
   videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Soccer videos; Event detection; Sparse coding; Supervised dictionary
   learning; Adaptive discriminative dictionary learning
ID SPARSE REPRESENTATION; BAYESIAN NETWORK; ANNOTATION; FRAMEWORK;
   TRACKING; FEATURES; SYSTEM; MODEL
AB In this paper, we formulate the soccer video event detection task as a sparse representation problem by learning a supervised, discriminative and event-oriented dictionary based on learned weighted local features. To this end, we present a novel framework based on two ideas: First, we propose an approach for computing the representativeness of each video frame for each soccer event. Second, we propose an Adaptive Label-Consistent K-SVD (ALC-KSVD) algorithm to learn an event-oriented and discriminative dictionary based on the computed representativeness of frames to transfer video frames to a sparse space. To improve discrimination among frames of different events, we proposed a weighting method to identify local features that are more representative in each event category. Next, the representativeness score of each frame is calculated by aggregating the weighted local features within each frame. The calculated representativeness score of each frame indicates its belonging degree to each event. The representativeness score matrix, being a discriminative term, is combined with the reconstruction error to form an objective function to improve the discrimination ability in the sparse representation during the dictionary learning process. The obtained objective function is efficiently and optimally solved by the K-SVD algorithm. The representativeness score matrix, which is automatically calculated based on the training samples, defines an adaptive correspondence between the dictionary atoms and the labels of the frames. We demonstrate the effectiveness of the proposed framework on the detection and classification of several soccer events based on an extensive experimental investigation that was conducted using a large collection of video data. The experimental results indicate that our approach maintains good classification performance and outperforms the state-of-the-art methods.
C1 [Fakhar, Babak] Islamic Azad Univ, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
   [Kanan, Hamidreza Rashidy] Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
   [Behrad, Alireza] Shahed Univ, Dept Elect Engn, Tehran, Iran.
C3 Islamic Azad University; Shahid Rajaee Teacher Training University
   (SRTTU); Shahed University
RP Kanan, HR (corresponding author), Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
EM h.rashidykanan@sru.ac.ir
RI Rashidy Kanan, Hamidreza/AAI-7928-2020; Behrad, Alireza/F-8795-2018
OI Rashidy Kanan, Hamidreza/0000-0001-8789-8658; Behrad,
   Alireza/0000-0002-1990-6668; Fakhar, Babak/0000-0002-4999-1058
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Bialkowski A, 2016, IEEE T KNOWL DATA EN, V28, P2596, DOI 10.1109/TKDE.2016.2581158
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   D'Orazio T, 2009, COMPUT VIS IMAGE UND, V113, P622, DOI 10.1016/j.cviu.2008.01.010
   D'Orazio T, 2009, IEEE T CIRC SYST VID, V19, P1804, DOI 10.1109/TCSVT.2009.2026817
   Dai WR, 2016, IEEE T IMAGE PROCESS, V25, P4580, DOI 10.1109/TIP.2016.2594490
   Dong J, 2015, NEUROCOMPUTING, V158, P246, DOI 10.1016/j.neucom.2015.01.024
   Eldib MY, 2009, IEEE IMAGE PROC, P4345, DOI 10.1109/ICIP.2009.5413649
   Gangeh MJ, 2013, IEEE T SIGNAL PROCES, V61, P4753, DOI 10.1109/TSP.2013.2274276
   Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432
   Gregor K, 2010, P 27 INT C INT C MAC, P399
   Guo Z, 2016, NEUROCOMPUTING, V208, P299, DOI 10.1016/j.neucom.2016.03.083
   Hosseini MS, 2013, APPL SOFT COMPUT, V13, P846, DOI 10.1016/j.asoc.2012.10.007
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Huang K., 2007, P 19 INT C NEUR INF, P609, DOI DOI 10.7551/MITPRESS/7503.003.0081
   Jai-Andaloussi S, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P398, DOI 10.1109/CSCI.2015.59
   Jiang HH, 2016, PROC INT C TOOLS ART, P490, DOI [10.1109/ICTAI.2016.0081, 10.1109/ICTAI.2016.78]
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jiang ZL, 2012, PROC CVPR IEEE, P3418, DOI 10.1109/CVPR.2012.6248082
   Kolekar MH, 2015, IEEE T BROADCAST, V61, P195, DOI 10.1109/TBC.2015.2424011
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee H., 2007, ADV NEURAL INFORM PR, P801, DOI DOI 10.7551/MITPRESS/7503.003.0105
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Liu Jingen., 2008, Computer Vision and Pattern Recognition, P1
   Liu TX, 2017, LECT NOTES COMPUT SC, V10635, P440, DOI 10.1007/978-3-319-70096-0_46
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Ng A., 2013, Softmax Regression
   Niu ZX, 2012, PATTERN RECOGN, V45, P1937, DOI 10.1016/j.patcog.2011.10.023
   Phaisangittisagul E, 2017, EXPERT SYST APPL, V69, P101, DOI 10.1016/j.eswa.2016.10.019
   Qian XM, 2012, MULTIMED TOOLS APPL, V60, P233, DOI 10.1007/s11042-011-0817-y
   Raventós A, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1065-9
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sigari MH, 2016, IMAGE VISION COMPUT, V53, P20, DOI 10.1016/j.imavis.2015.07.004
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu C, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P805, DOI 10.1109/ICME.2002.1035904
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Yajima C., 2002, Visual and Multimedia Information Management. IFIP TC2/WG2.6. Sixth Working Conference on Visual Database Systems, P357
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhan YZ, 2016, J VIS COMMUN IMAGE R, V41, P65, DOI 10.1016/j.jvcir.2016.09.006
   Zhang CJ, 2014, COMPUT VIS IMAGE UND, V123, P14, DOI 10.1016/j.cviu.2014.02.013
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhao W, 2015, Proceedings 3rd IAPR Asian Conference on Pattern Recognition ACPR 2015, P341, DOI 10.1109/ACPR.2015.7486522
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 53
TC 4
Z9 5
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 489
EP 503
DI 10.1016/j.jvcir.2018.06.014
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100043
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Zhou, M
   Yang, HZ
   Shen, XJ
   Wang, YB
AF Zhang, Caiyou
   Zhou, Man
   Yang, Hongzhen
   Shen, Xiaojun
   Wang, Yanbo
TI RETRACTED: A method of multi-criteria set recognition based on deep
   feature representation (Retracted article. See vol. 67, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Person re-identification; Convolutional neural network; Multiple metric
   ensembles
AB The large variations in the angle of different camera views and illumination can change the appearance of a lot of people, which makes human re identification is still a challenging problem. Therefore, the development of robust feature descriptors and the design of discriminative distance metrics to measure similarity between pedestrian images are two key aspects of human re identification. In this paper, we propose a method to improve the performance of the re identification using depth learning and multiple metric ensembles. First, we use a variety of data sets to train the general convolutional neural network (CNN), which is used to extract the features of the training and test set after deep level. Deep architecture makes it possible for people to learn more abstract and internal features that are robust to changes in viewpoint and illumination. Then, we utilize the deep features of the training set to learn a specific distance metric and combine it with the cosine distance metric. Multi metric sets can be used to measure the similarity between different images. Finally, a large number of experiments show that our method can effectively improve the recognition performance compared to the state-of-the-art methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Caiyou; Zhou, Man; Yang, Hongzhen; Shen, Xiaojun; Wang, Yanbo] State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Zhang, CY (corresponding author), State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
EM 634423778@qq.com
RI wang, yan/JBJ-7462-2023; Xiaojun, Shen/B-9435-2018; Wang,
   Yin/HCI-9352-2022; Wang, Yanbo/HFZ-8018-2022; wang, yan/GSE-6489-2022;
   wang, yiran/IAP-0414-2023; wangwangwang, yuanyaunyuan/HHN-6432-2022;
   Wang, Yuan/HHC-1520-2022
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2016, ARXIV161001708
   [Anonymous], FCV
   [Anonymous], ARXIV160407528
   [Anonymous], 2009, BMVC
   [Anonymous], ARXIV15120056
   Bohné J, 2014, LECT NOTES COMPUT SC, V8690, P679, DOI 10.1007/978-3-319-10605-2_44
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Davis J. V., 2007, ICML, P209
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Loffe S., 2015, P 32 INT C MACH LEAR, P448
   Long Y., 2017, INFORM SCI
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
NR 38
TC 1
Z9 1
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 756
EP 760
DI 10.1016/j.jvcir.2018.08.011
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100065
DA 2024-07-18
ER

PT J
AU Tang, HS
   Ni, RR
   Zhao, Y
   Li, XL
AF Tang, Hongshen
   Ni, Rongrong
   Zhao, Yao
   Li, Xiaolong
TI Median filtering detection of small-size image based on CNN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Median filtering forensics; CNN; Nearest neighbor interpolation
AB Existing median filtering detection methods are no longer effective for small size or highly compressed images. To deal with this problem, a new median filtering detection method based on CNN is proposed in this paper. Specifically, a new network structure called MFNet is constructed. First, for preprocessing, the nearest neighbor interpolation method is utilized to up-sample the small-size images. The property of median filtering can be well preserved by the up-sampling operation and enlarged difference between the original image and its median filtered version can be obtained. Then, the well-known mlpconv structure is employed in the first and second layers of MFNet. With mlpconv layers, the nonlinear classification ability of the proposed method can be enhanced. After that, three conventional convolutional layers are utilized to finally derive the feature maps. The experimental results show that the proposed method achieves significant improved detection performance. Moreover, the proposed method performs well for highly compressed image of size as small as 16 x 16.
C1 Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
   Beijing Key Lab Adv Informat Sci & Network Techno, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Ni, RR (corresponding author), Beijing Jiaotong Univ, Beijing 100044, Peoples R China.
EM rrni@bjtu.edu.cn
RI li, xiao/GSN-6181-2022; Li, xiaolong/GRS-9148-2022
FU National Key Research and Development of China [2016YFB0800404];
   National NSF of China [61332012, 61672090]; Fundamental Research Funds
   for the Central Universities [2015JBZ002]
FX This work was supported in part by the National Key Research and
   Development of China (2016YFB0800404), National NSF of China (61332012,
   61672090), Fundamental Research Funds for the Central Universities
   (2015JBZ002).
CR [Anonymous], 2014, PROC INT C LEARN REP
   [Anonymous], 2011, P 13 INF HID C PRAG
   Bayar B., 2016, ACM WORKSH INF HID M
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Kakar P, 2010, IEEE INT CON MULTI, P486, DOI 10.1109/ICME.2010.5582562
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kao YT, 2012, IEEE T IMAGE PROCESS, V21, P3443, DOI 10.1109/TIP.2012.2191562
   Kirchberg M., 2010, System Sciences (HICSS), 2010 43rd Hawaii International Conference on, P1
   Kirchner M., 2008, P SPIE SECURITY FORE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Neelamani R, 2006, IEEE T IMAGE PROCESS, V15, P1365, DOI 10.1109/TIP.2005.864171
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Tuama A, 2016, IEEE INT WORKS INFOR
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 24
TC 48
Z9 51
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 162
EP 168
DI 10.1016/j.jvcir.2018.01.011
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500016
DA 2024-07-18
ER

PT J
AU Barni, M
   Bondi, L
   Bonettini, N
   Bestagini, P
   Costanzo, A
   Maggini, M
   Tondi, B
   Tubaro, S
AF Barni, M.
   Bondi, L.
   Bonettini, N.
   Bestagini, P.
   Costanzo, A.
   Maggini, M.
   Tondi, B.
   Tubaro, S.
TI Aligned and non-aligned double JPEG detection using convolutional neural
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Double JPEG detection; Double JPEG localization;
   Convolutional neural networks
ID COMPRESSION; IMAGES
AB Due to the wide diffusion of JPEG coding standard, the image forensic community has devoted significant attention to the development of double JPEG (DJPEG) compression detectors through the years. The ability of detecting whether an image has been compressed twice provides paramount information toward image authenticity assessment. Given the trend recently gained by convolutional neural networks (CNN) in many computer vision tasks, in this paper we propose to use CNNs for aligned and non-aligned double JPEG compression detection. In particular, we explore the capability of CNNs to capture DJPEG artifacts directly from images. Results show that the proposed CNN-based detectors achieve good performance even with small size images (i.e., 64 x 64), outperforming state-of-the-art solutions, especially in the non-aligned case. Besides, good results are also achieved in the commonly-recognized challenging case in which the first quality factor is larger than the second one. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Barni, M.; Costanzo, A.; Maggini, M.; Tondi, B.] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Bondi, L.; Bonettini, N.; Bestagini, P.; Tubaro, S.] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Milan, Italy.
C3 University of Siena; Polytechnic University of Milan
RP Bestagini, P (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Milan, Italy.
EM paolo.bestagini@polimi.it
RI Bondi, Luca/L-4871-2015; Costanzo, Andrea/HJY-6070-2023; BONETTINI,
   NICOLÒ/AAH-2159-2019; Bestagini, Paolo/KHC-7516-2024
OI Bondi, Luca/0000-0003-3974-7542; BONETTINI, NICOLÒ/0000-0002-7500-8512;
   Bestagini, Paolo/0000-0003-0406-0222
FU DARPA; Air Force Research Laboratory (AFRL) [FA8750-16-2-0173]
FX This material is based on research sponsored by DARPA and Air Force
   Research Laboratory (AFRL) under agreement number FA8750-16-2-0173. The
   U.S. Government is authorized to reproduce and distribute reprints for
   Governmental purposes notwithstanding any copyright notation thereon.
   The views and conclusions contained herein are those of the authors and
   should not be interpreted as necessarily representing the official
   policies or endorsements, either expressed or implied, of DARPA and Air
   Force Research Laboratory (AFRL) or the U.S. Government.
CR Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2008, IEEE WORKSH MULT SIG
   [Anonymous], 2015, SPIE IS T ELECT IMAG
   [Anonymous], HDB BRAIN THEORY NEU
   [Anonymous], 2010, INT C MACH LEARN ICM
   Barni M., 2017, EUR SIGN PROC C EUSI, P113
   Bayar B., 2016, ACM WORKSH INF HID M
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bianchi T, 2011, IEEE INT C AC SPEECH
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bohme R., 2016, P 4 ACM WORKSH INF H, P11
   Bondi L., 2017, IS T INT S EL IM MED
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Chen C., 2008, IEEE INT C PATT REC
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Luo W, 2007, IEEE INT C AC SPEECH
   Mihcak M.K., 1999, IEEE INT C AC SPEECH
   Pasquini C, 2014, IEEE INT WORKS INFOR, P113, DOI 10.1109/WIFS.2014.7084313
   Pasquini Cecilia, 2015, ACM MULT SYST C, P7
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Pibre L., 2016, 15 T INT S EL IM MED
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Popescu A., 2004, INT C INF HID
   Qu Z., 2008, IEEE INT C AC SPEECH
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Sedighi V., 2017, IS T INT S EL IM MED
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   Tuama A, 2016, IEEE INT WORKS INFOR
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
NR 37
TC 118
Z9 134
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 153
EP 163
DI 10.1016/j.jvcir.2017.09.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800013
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Zalik, B
   Mongus, D
   Zalik, KR
   Lukac, N
AF Zalik, Borut
   Mongus, Domen
   Zalik, Krista Rizman
   Lukac, Niko
TI Boolean operations on rasterized shapes represented by chain codes using
   space filling curves
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Chain codes; Space filling curves; Hilbert curve; Boolean operations
ID LOSSLESS COMPRESSION; ALGORITHM; QUADTREE
AB This paper introduces a new algorithm for Boolean operations on rasterized geometric shapes that are represented with chain codes. The algorithm works in three steps. Firstly, the chain code symbols are transformed in the Hilbert space, where the overlaid chain code symbols are recognised. After that, a suitable starting cell is determined. Finally, the walk-about through the sequence of the initial chain code symbols is performed to obtain the sequence of chain code symbols representing the shape of the required Boolean operation. The algorithm is demonstrated on Freeman chain code in four directions. The time and space complexity of the proposed algorithm is linear, which was proven theoretically and confirmed by experiments.
C1 [Zalik, Borut; Mongus, Domen; Zalik, Krista Rizman; Lukac, Niko] Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SI-2000 Maribor, Slovenia.
C3 University of Maribor
RP Zalik, B (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SI-2000 Maribor, Slovenia.
EM borut.zalik@um.si
RI Žalik, Borut/X-1320-2019; Lukač, Niko/IVV-5895-2023; Lukač,
   Niko/B-7524-2014
OI Lukač, Niko/0000-0002-9517-1157
FU Slovenian Research Agency [P2-0041];  [J2-8176]
FX This work was supported by the Slovenian Research Agency under research
   core funding No. P2-0041, as well as research project No. J2-8176.
CR [Anonymous], 2013, Texts in Computational Science and Engineering
   Asano T, 1997, THEOR COMPUT SCI, V181, P3, DOI 10.1016/S0304-3975(96)00259-9
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   BUTZ AR, 1971, IEEE T COMPUT, VC 20, P424, DOI 10.1109/T-C.1971.223258
   CHAZELLE B, 1992, J ACM, V39, P1, DOI 10.1145/147508.147511
   Chen Z, 2001, IMAGE VISION COMPUT, V19, P413, DOI 10.1016/S0262-8856(00)00080-9
   Chung KL, 2007, INFORM SCIENCES, V177, P2130, DOI 10.1016/j.ins.2006.12.003
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Dai XL, 1999, IEEE T GEOSCI REMOTE, V37, P2351, DOI 10.1109/36.789634
   DAVIS IJ, 1992, COMPUT J, V35, P636, DOI 10.1093/comjnl/35.6.636
   Filho M, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0354-8
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Ganster H., 1995, Theory and Applications of Image Analysis II. Selected Paper from the 9th Scandinavian Conference on Image Analysis, P343
   Ge N, 2011, IEEE T PLASMA SCI, V39, P2884, DOI 10.1109/TPS.2011.2159132
   Globacnik T, 2010, PATTERN RECOGN, V43, P4137, DOI 10.1016/j.patcog.2010.07.018
   Greiner G, 1998, ACM T GRAPHIC, V17, P71, DOI 10.1145/274363.274364
   Gupta RK, 2012, COMPUT AIDED DESIGN, V44, P99, DOI 10.1016/j.cad.2011.09.012
   Hoffmann C., 1989, Geometric and Solid Modeling: An Introduction
   Jain J., 2012, ADV COMPUTER SCI INF, P611
   Lawder J., 2000, THESIS
   Lawder JK, 2001, INT J COMPUT MATH, V78, P327, DOI 10.1080/00207160108805115
   Lawder JK, 2000, LECT NOTES COMPUT SC, V1832, P20
   Li K, 2013, PETROL SCI, V10, P347, DOI 10.1007/s12182-013-0283-4
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Liu YK, 2007, COMPUT GEOSCI-UK, V33, P589, DOI 10.1016/j.cageo.2006.08.008
   Liu YK, 2012, SIGNAL PROCESS-IMAGE, V27, P973, DOI 10.1016/j.image.2012.07.008
   MAIRSON H, 1988, NATO ASI SERIES F, V40, P307
   Mortenson ME., 1997, Geometric modeling, V2nd
   PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029
   Peng Y, 2005, COMPUT GRAPH-UK, V29, P57, DOI 10.1016/j.cag.2004.11.001
   Ren M, 2009, T GIS, V13, P197, DOI 10.1111/j.1467-9671.2009.01147.x
   Rivero M, 2000, COMPUT GRAPH-UK, V24, P881, DOI 10.1016/S0097-8493(00)00090-X
   Sagan H., 1994, SPACE FILLING CURVES
   Salomon D., 2010, Handbook of Data Compression, V5th
   SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836
   Samet H., 1990, The Design and Analysis of Spatial Data Structures
   Samet H., 1988, NATO ASI SERIES F, VF40
   Sánchez-Cruz H, 2005, OPT ENG, V44, DOI 10.1117/1.2052793
   Sánchez-Cruz H, 2007, PATTERN RECOGN, V40, P1660, DOI 10.1016/j.patcog.2006.10.013
   Sánchez-Cruz H, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013031
   Shih FY, 2001, PATTERN RECOGN, V34, P631, DOI 10.1016/S0031-3203(00)00008-X
   Sun H, 2005, PATTERN RECOGN LETT, V26, P1266, DOI 10.1016/j.patrec.2004.11.007
   VATTI BR, 1992, COMMUN ACM, V35, P56, DOI 10.1145/129902.129906
   Wang CQ, 2012, APPL SOFT COMPUT, V12, P423, DOI 10.1016/j.asoc.2011.08.028
   Young I.T., 2016, FUNDAMENTALS IMAGE P
   Zalik B, 2000, COMPUT GEOSCI, V26, P137, DOI 10.1016/S0098-3004(99)00071-0
   Zalik B, 2016, J VIS COMMUN IMAGE R, V38, P186, DOI 10.1016/j.jvcir.2016.03.001
   Zalik B, 2016, DIGIT SIGNAL PROCESS, V53, P1, DOI 10.1016/j.dsp.2016.03.002
   Zalik B, 2015, J VIS COMMUN IMAGE R, V29, P8, DOI 10.1016/j.jvcir.2015.01.013
   Zalik B, 2014, SIGNAL PROCESS-IMAGE, V29, P96, DOI 10.1016/j.image.2013.09.002
NR 51
TC 4
Z9 4
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 420
EP 432
DI 10.1016/j.jvcir.2017.10.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800036
DA 2024-07-18
ER

PT J
AU Liu, SL
   Rahman, MA
   Lin, CF
   Wong, CY
   Jiang, GN
   Liu, SC
   Kwok, N
   Shi, HY
AF Liu, Shilong
   Rahman, Md Arifur
   Lin, Ching-Feng
   Wong, Chin Yeow
   Jiang, Guannan
   Liu, San Chi
   Kwok, Ngaiming
   Shi, Haiyan
TI Image contrast enhancement based on intensity expansion-compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; Information content; Expansion-compression
ID HISTOGRAM EQUALIZATION
AB In most image based applications, input images of high information content are required to ensure that satisfactory performances can be obtained from subsequent processes. Manipulating the intensity distribution is one of the popular methods that have been widely employed. However, this conventional procedure often generates undesirable artifacts and causes reductions in the information content. An approach based on expanding and compressing the intensity dynamic range is here proposed. By expanding the intensity according to the polarity of local edges, an intermediate image of continuous intensity spectrum is obtained. Then, by compressing this image to the allowed intensity dynamic range, an increase in information content is ensured. The combination of edge guided expansion with compression also enables the preservation of fine details contained in the input image. Experimental results show that the proposed method outperforms other approaches, which are based on histogram divisions and clippings, in terms of image contrast enhancement. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Shilong; Rahman, Md Arifur; Lin, Ching-Feng; Wong, Chin Yeow; Jiang, Guannan; Liu, San Chi; Kwok, Ngaiming] Univ New South Wales, Sch Mech & Mfg Engn, Sydney, NSW 2052, Australia.
   [Shi, Haiyan] Shaoxing Univ, Sch Comp Sci & Technol, Shaoxing 312000, Zhejiang, Peoples R China.
C3 University of New South Wales Sydney; Shaoxing University
RP Kwok, N (corresponding author), Univ New South Wales, Sch Mech & Mfg Engn, Sydney, NSW 2052, Australia.
EM nmkwok@unsw.edu.au
RI liu, shilong/JZD-8395-2024; Kwok, Ngai Ming/F-1608-2011
OI Rahman, Md Arifur/0000-0001-8941-3685
CR [Anonymous], IEEE T CONSUM ELECT
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Çelebi AT, 2015, IEEE T CONSUM ELECTR, V61, P119, DOI 10.1109/TCE.2015.7064119
   Celik T, 2016, IEEE T IMAGE PROCESS, V25, P4719, DOI 10.1109/TIP.2016.2599103
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Huang LD, 2015, J VIS COMMUN IMAGE R, V31, P86, DOI 10.1016/j.jvcir.2015.06.007
   Jiang G, 2015, J MOD OPTIC, V62, P536, DOI 10.1080/09500340.2014.991358
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lai Y. -R., 2015, MULTIMEDIA TOOLS APP, P1
   Lin SCF, 2016, OPTIK, V127, P407, DOI 10.1016/j.ijleo.2015.08.046
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Liu SL, 2015, INT CONF INFO SCI, P345, DOI 10.1109/ICIST.2015.7288994
   Ma HJ, 2013, INT GEOSCI REMOTE SE, P3718, DOI 10.1109/IGARSS.2013.6723638
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Rahman M. A., 2015, International Journal of Image Processing (IJIP), V9, P241
   Shin J, 2015, IEEE SIGNAL PROC LET, V22, P1293, DOI 10.1109/LSP.2015.2399612
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Xu YL, 2015, ROBOT CIM-INT MANUF, V32, P25, DOI 10.1016/j.rcim.2014.09.002
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
   Zhang GY, 2015, IEEE T GEOSCI REMOTE, V53, P5861, DOI 10.1109/TGRS.2015.2423688
   Zhao XM, 2015, DIGIT SIGNAL PROCESS, V43, P8, DOI 10.1016/j.dsp.2015.04.009
NR 26
TC 17
Z9 17
U1 1
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 169
EP 181
DI 10.1016/j.jvcir.2017.05.011
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700014
DA 2024-07-18
ER

PT J
AU Chen, X
   Chen, ZZ
AF Chen, Xiu
   Chen, Zhenzhong
TI Exploring visual attention using random walks based eye tracking
   protocols
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eye tracking; Visual attention; Fixation; Area of interest; Random walks
ID SALIENCY DETECTION MODEL; BIT ALLOCATION; VIDEO; SENSITIVITY; IMAGE;
   ALGORITHMS
AB Identifying visual attention plays an important role in understanding human behavior and optimizing relevant multimedia applications. In this paper, we propose a visual attention identification method based on random walks. In the proposed method, fixations recorded by the eye tracker are partitioned into clusters where each cluster presents a particular area of interest (AoI). In each cluster, we estimate the transition probabilities of the fixations based on their point-to-point adjacency in their spatial positions. We obtain the initial coefficients for the fixations according to their density. We utilizing random walks to iteratively update the coefficients until their convergency. Finally, the center of the AOI is calculated according to the convergent coefficients of the fixations. Experimental results demonstrate that our proposed method which combines the fixations' spatial and temporal relations, highlights the fixations of higher densities and eliminates the errors inside the cluster. It is more robust and accurate than traditional methods.(C) 2017 Published by Elsevier Inc.
C1 [Chen, Xiu; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Luoyu Rd 129, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Luoyu Rd 129, Wuhan 430079, Peoples R China.
EM zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015
FU National Natural Science Foundation of China [61471273, 91438203];
   National Hightech R&D Program of China (863 Program) [2015AA015903];
   Natural Science Foundation of Hubei Province of China [2015CFA053]
FX This work was supported in part by National Natural Science Foundation
   of China (Nos. 61471273, 91438203), National Hightech R&D Program of
   China (863 Program, 2015AA015903), and Natural Science Foundation of
   Hubei Province of China (No. 2015CFA053).
CR Buscher G, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P21
   Chen X, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P6, DOI 10.1109/GlobalSIP.2015.7416925
   Chen ZZ, 2006, IEEE T MULTIMEDIA, V8, P1117, DOI 10.1109/TMM.2006.884633
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   GOLDBERG JH, 1995, STUD VIS INFORM PROC, V6, P491
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadizadeh H, 2013, IEEE T MULTIMEDIA, V15, P2099, DOI 10.1109/TMM.2013.2281024
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Just M.A., 1984, NEW METHODS READING, P151
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Leigh RJ., 2015, NEUROLOGY EYE MOVEME, P836
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Matsuda Noriyuki, 2012, International Journal of Computer Information Systems and Industrial Management Applications, V4, P109
   Nielsen J., 2010, Eyetracking Web Usability
   Nyström M, 2010, BEHAV RES METHODS, V42, P188, DOI 10.3758/BRM.42.1.188
   Privitera Claudio M., 2005, P296, DOI 10.1016/B978-012375731-9/50052-5
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Salvucci DD, 2000, 2000 S EYE TRACKING, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Santella A., 2004, P S EYE TRACKING RES, P27, DOI DOI 10.1145/968363.968368
   Shen CY, 2015, IEEE T MULTIMEDIA, V17, P2084, DOI 10.1109/TMM.2015.2483370
   Shic F, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P111, DOI 10.1145/1344471.1344500
   Spakov O, 2007, INF TECHNOL CONTROL, V36, P213
   Tafaj E., 2012, P S EYE TRACK RES AP, P285, DOI DOI 10.1145/2168556.2168617
   Tafaj E, 2013, LECT NOTES COMPUT SC, V8131, P442, DOI 10.1007/978-3-642-40728-4_56
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Wang Y., 2016, ELECT IMAG, V2016, P1, DOI DOI 10.1007/S00294-016-0593-3
   Zamir AR, 2014, PROC CVPR IEEE, P4280, DOI 10.1109/CVPR.2014.545
   Zhao Y, 2011, IEEE T CIRC SYST VID, V21, P1890, DOI 10.1109/TCSVT.2011.2157189
NR 37
TC 8
Z9 9
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 147
EP 155
DI 10.1016/j.jvcir.2017.02.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100013
DA 2024-07-18
ER

PT J
AU Chen, F
   Jiao, RZ
   Peng, ZJ
   Jiang, GY
   Yu, M
AF Chen, Fen
   Jiao, Renzhi
   Peng, Zongju
   Jiang, Gangyi
   Yu, Mei
TI Virtual view quality assessment based on shift compensation and visual
   masking effect
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth image based rendering; Multiview video plus depth; Visual masking
   effect; Virtual viewpoint quality assessment
AB Depth image based rendering technology is essential for free viewpoint video systems. Because of the compression of depth images and limitations of rendering algorithms, various types of distortion might occur in the virtual viewpoints and cannot effectively be evaluated by traditional two-dimensional assessment methods. Hence, this paper proposes a method for virtual viewpoint quality assessment using the visual masking effect. First, shift is compensated for the distorted virtual viewpoint and then the compensated virtual viewpoint is objectively assessed. Next, according to human visual characteristics such as texture, magnitude, and distribution masking, the corresponding visual sensitivity map and visual masks are extracted. Finally, the visual masking and all factors are pooled to create the final quality score. As verified by the experimental results, the method proposed in this paper corresponds with the characteristics of human vision and can serve as a more effective method for assessing the quality of virtual viewpoints. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Fen; Jiao, Renzhi; Peng, Zongju; Jiang, Gangyi; Yu, Mei] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Chen, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM chenfen@nbu.edu.cn
RI jiang, gang/KII-8233-2024; Peng, Zongju/AAA-2914-2020; Chen,
   Fen/ABG-7013-2021
OI Peng, Zongju/0000-0001-8286-538X; 
FU National Natural Science Foundation of China [61620106012, 61271270,
   U1301257]; Natural Science Foundation of Zhejiang Province [LY16F010002,
   LY15F010005, LY17F010005]; Natural Science Foundation of Ningbo
   [2015A610127, 2015A610124]; Ningbo University Research Foundation
   (Science)/Discipline Project [xkxl1502]; K.C. Wong Magna Fund in Ningbo
   University
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61620106012, Grant 61271270, and Grant U1301257, the
   Natural Science Foundation of Zhejiang Province under Grant LY16F010002,
   Grant LY15F010005, and Grant LY17F010005, the Natural Science Foundation
   of Ningbo under Grant 2015A610127 and Grant 2015A610124, and Ningbo
   University Research Foundation (Science)/Discipline Project under Grant
   xkxl1502. It is also sponsored by K.C. Wong Magna Fund in Ningbo
   University.
CR [Anonymous], INT WORKSH QUAL MULT
   [Anonymous], P SPIE INT SOC OPT E
   [Anonymous], 2013, 2013 VISUAL COMMUNIC
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2013, 3D TV SYSTEM DEPTH I, DOI DOI 10.1007/978-1-4419-9964-1_15
   [Anonymous], IEEE T CIRCUITS SYST
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Chen YY, 2011, OPT ENG, V50, DOI 10.1117/1.3646404
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Joveluro P, 2010, 3DTV CONF
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2010, IEEE INT CON MULTI, P424, DOI 10.1109/ICME.2010.5583559
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Solh M., 2011, Multimedia and Expo (ICME), 2011 IEEE International Conference on, P1
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wu JJ, 2013, IEEE INT SYMP CIRC S, P933, DOI 10.1109/ISCAS.2013.6572001
NR 20
TC 3
Z9 4
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 41
EP 49
DI 10.1016/j.jvcir.2016.12.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400005
DA 2024-07-18
ER

PT J
AU Guo, JF
   Hu, G
   Xu, WJ
   Huang, LF
AF Guo, Jiefeng
   Hu, Gong
   Xu, Weijian
   Huang, Lianfen
TI Hierarchical content importance-based video quality assessment for HEVC
   encoded videos transmitted over LTE networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content type; High efficiency video coding (HEVC); Long term evolution
   (LTE) network; Mean opinion score (MOS); Neural network; Quality of
   experience (QoE); Video quality assessment (VQA)
ID MODEL
AB To improve the accuracy of assessment, many previous works take into account the video content. However, these previous works just only consider the video content, but do not consider the location and importance of the degraded content. Thus, this paper takes into account not only the video content, but also the location and importance of the degraded content, and proposes a hierarchical content importance-based video quality assessment. Firstly, we propose to use the hierarchical content importance-based frame degradation rate (HFDR) metric to quantify the importance of degraded content hierarchically. Secondly, we propose to use the intra random access point (IRAP) loss rate (ILR) metric to quantify the impact of IRAP. Finally, the proposed HFDR metric and ILR metric are subsequently used to develop an objective video quality assessment model. The experimental results show that the predicted mean opinion score (MOS) of the proposed method highly correlates with the actual MOS. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Guo, Jiefeng; Hu, Gong; Xu, Weijian; Huang, Lianfen] Xiamen Univ, Sch Informat Sci & Engn, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Huang, LF (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Xiamen 361005, Peoples R China.
EM jfguo@xmu.edu.cn; gdemonhunter@foxmail.com; xwjxwj@jmu.edu.cn;
   lfhuang@xmu.edu.cn
RI Xu, Wei-Jian/ABA-4972-2021
OI Xu, Wei-Jian/0000-0003-1818-0284
FU National High Technology Research and Development Program
   [2015AA01A707]; National Natural Science Foundation of China [61371081];
   National Natural Young Science Foundation of China [61401381]
FX The work presented in this paper was partially supported by National
   High Technology Research and Development Program (Grant number
   2015AA01A707), 2014 National Natural Science Foundation of China (Grant
   number 61371081), 2015 National Natural Young Science Foundation of
   China (Grant number 61401381).
CR [Anonymous], VAL RED REF NO REF O
   [Anonymous], 2007, BT1788 ITUR
   Archana P, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P348, DOI 10.1109/ICSIP.2014.61
   Bossen F., 2014, JCTVC SOFTWARE MANUA
   Bross B., 2013, JOINT COLL TEAM VID, P14
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Greengrass J, 2009, IEEE INTERNET COMPUT, V13, P74, DOI 10.1109/MIC.2009.40
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Huang X., 2015, 2015 IEEE INT C VIS
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Nasralla MM, 2014, INT CONF TELECOMM, P254, DOI 10.1109/TEMU.2014.6917770
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Part-Enander E., 1996, THE MATLAB HDB
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.7551/MITPRESS/5236.001.0001
   Schierl T., 2016, 7798 IETF RFC
   Schulzrinne H., 2003, 3550 IETF RFC
   Su H, 2012, INT J COMPUT COMMUN, V7, P565
   Su HL, 2014, J VIS COMMUN IMAGE R, V25, P1199, DOI 10.1016/j.jvcir.2014.04.004
   VQEG, 2010, VAL VID QUAL MOD HIG
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wenger S, 2011, 6190 IETF RFC
NR 24
TC 3
Z9 3
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 50
EP 60
DI 10.1016/j.jvcir.2016.12.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400006
DA 2024-07-18
ER

PT J
AU Hati, A
   Chaudhuri, S
   Velmurugan, R
AF Hati, Avik
   Chaudhuri, Subhasis
   Velmurugan, Rajbabu
TI An image texture insensitive method for saliency detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency; Texture suppression; Total variation; Sparse segmentation;
   Relevance feedback; Image matting
ID OBJECT DETECTION; REGION DETECTION; BOTTOM-UP; MODEL; RECONSTRUCTION
AB We propose a texture insensitive, region based image saliency detection algorithm, having excellent detection and localization properties, to obtain salient objects. We use a total variation based regularizer to suppress textures from the image and to make the method invariant to textural variations in the scene. This leads to an image that contains piecewise constant gray valued regions. This texture-free image is sparsely segmented into a small number of regions using the expectation maximization algorithm assuming a Gaussian mixture model. We compute three different saliency measures for every region using its intensity and spatial features. We adopt a relevance feedback mechanism to obtain weights for combining the three saliency measures and obtain the final saliency map. Next we input the thres-holded saliency map to an image matting technique and extract the salient objects from the image with exact boundaries. Experimental comparisons with existing saliency detection algorithms demonstrate the superiority of the proposed technique. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Hati, Avik; Chaudhuri, Subhasis; Velmurugan, Rajbabu] Indian Inst Technol, Dept Elect Engn, Mumbai 400076, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay
RP Hati, A (corresponding author), Indian Inst Technol, Dept Elect Engn, Mumbai 400076, Maharashtra, India.
EM avik@ee.iitb.ac.in; sc@ee.iitb.ac.in; rajbabu@ee.iitb.ac.in
RI Hati, Avik/AAZ-3940-2021
OI Hati, Avik/0000-0003-2276-3618
CR Achanta R., 2008, P ICCVS
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], 2016, P CVPR
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   Gao D., 2005, P ADV NEUR INF PROC, P481
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hati A., 2014, P IND C COMP VIS GRA
   Hati A, 2015, IEEE IMAGE PROC, P1767, DOI 10.1109/ICIP.2015.7351104
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li J, 2015, IEEE T PATTERN ANAL, V37, P2428, DOI 10.1109/TPAMI.2015.2424870
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li YB, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION IN COMMUNICATION, P246, DOI 10.1109/ICASID.2009.5276913
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Ma XL, 2015, J VIS COMMUN IMAGE R, V32, P95, DOI 10.1016/j.jvcir.2015.08.003
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Naqvi SS, 2016, PATTERN RECOGN, V51, P209, DOI 10.1016/j.patcog.2015.09.026
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rigas I, 2015, COMPUT VIS IMAGE UND, V134, P33, DOI 10.1016/j.cviu.2015.01.007
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Shuai JM, 2013, IEEE IMAGE PROC, P2470, DOI 10.1109/ICIP.2013.6738509
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Tian YH, 2015, INT J COMPUT VISION, V111, P153, DOI 10.1007/s11263-014-0737-1
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Valenti R, 2009, IEEE IMAGE PROC, P993, DOI 10.1109/ICIP.2009.5413810
   Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004
   Wang M, 2011, PROC CVPR IEEE, P417, DOI 10.1109/CVPR.2011.5995743
   Wang Q, 2013, COMPUT VIS IMAGE UND, V117, P1748, DOI 10.1016/j.cviu.2013.07.002
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xia C, 2015, PATTERN RECOGN, V48, P1337, DOI 10.1016/j.patcog.2014.10.007
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yeh HH, 2014, PATTERN RECOGN, V47, P1740, DOI 10.1016/j.patcog.2013.11.015
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang XJ, 2015, PATTERN RECOGN, V48, P1315, DOI 10.1016/j.patcog.2014.10.016
   Zhu GK, 2014, COMPUT VIS IMAGE UND, V118, P40, DOI 10.1016/j.cviu.2013.07.011
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou BJ, 2015, J VIS COMMUN IMAGE R, V33, P378, DOI 10.1016/j.jvcir.2015.09.017
NR 73
TC 9
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 212
EP 226
DI 10.1016/j.jvcir.2017.01.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400020
DA 2024-07-18
ER

PT J
AU Ren, YZ
   Chen, C
   Li, SW
   Kuo, CCJ
AF Ren, Yuzhuo
   Chen, Chen
   Li, Shangwen
   Kuo, C. -C. Jay
TI GAL: A global-attributes assisted labeling system for outdoor scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Outdoor layout estimation; Semantic labeling; Global attribute vector;
   Convolutional neural network; 3D reconstruction
ID IMAGE; FEATURES
AB An approach that extracts global attributes from outdoor images to facilitate geometric layout labeling is investigated in this work. The proposed Global-attributes Assisted Labeling (GAL) system exploits both local features and global attributes. First, by following a classical method, we use local features to provide initial labels for all super-pixels. Then, we develop a set of techniques to extract global attributes from 2D outdoor images. They include sky lines, ground lines, vanishing lines, etc. Finally, we propose the GAL system that integrates global attributes in the conditional random field (CRF) framework to improve initial labels so as to offer a more robust labeling result. The performance of the proposed GAL system is demonstrated and benchmarked with several state-of-the-art algorithms against a popular outdoor scene layout dataset. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ren, Yuzhuo; Chen, Chen; Li, Shangwen; Kuo, C. -C. Jay] Univ Southern Calif, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Ren, YZ (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.
EM yuzhuore@usc.edu; chen80@usc.edu; shangwel@usc.edu; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU University of Southern Californias Center for High-Performance Computing
FX Computation for the work described in this paper was supported by the
   University of Southern Californias Center for High-Performance Computing
   (hpcc.usc.edu).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], ARXIV13062795
   [Anonymous], 2009, IEEE I CONF COMP VIS, DOI 10.1109/ICCV.2009.5459175
   [Anonymous], ARXIV151100561
   [Anonymous], 2010, NIPS
   [Anonymous], ARXIV151204412
   [Anonymous], ARXIV160205110
   Barinova O, 2010, LECT NOTES COMPUT SC, V6312, P57, DOI 10.1007/978-3-642-15552-9_5
   Bishop C. M., MACHINE LEARNING, P128
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen C, 2015, LECT NOTES COMPUT SC, V9008, P426, DOI 10.1007/978-3-319-16628-5_31
   Chen Chen., 2016, Big Visual Data Analysis, P65
   Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., FAST EDGE DETECTION
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Eigen D., 2014, NIPS, DOI DOI 10.5555/2969033.2969091
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fu X, 2015, IEEE I CONF COMP VIS, P1618, DOI 10.1109/ICCV.2015.189
   Girshick R. B., Discriminatively Trained Deformable Part Models, Release 5
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Gupta A, 2010, LECT NOTES COMPUT SC, V6314, P482, DOI 10.1007/978-3-642-15561-1_35
   Gururaj C., 2016, Emerging Research in Computing, Information, Communication and Applications, P279
   Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI [10.1109/TPAMI.2008.65, 10.1109/TPAMI.2008.55]
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hoiem D., 2008, Proceedings of CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587587
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Koutsourakis P, 2009, IEEE I CONF COMP VIS, P1795, DOI 10.1109/ICCV.2009.5459400
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Lazebnik S, 2009, PROC CVPR IEEE, P2372
   Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872
   Li S., ARXIV160208680
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu XB, 2014, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.2014.93
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mobahi Hossein, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P593, DOI 10.1109/ICCVW.2011.6130297
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pan JY, 2015, PROC CVPR IEEE, P2918, DOI 10.1109/CVPR.2015.7298910
   Park S, 2015, 14TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, VRCAI 2015, P89, DOI 10.1145/2817675.2817689
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Ramanathan S., 2008, PHOTOVOLTAIC SPECIAL, P1, DOI DOI 10.1201/9781420068764
   Ren Y., ARXIV160700598
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Song DJ, 2015, IEEE T IMAGE PROCESS, V24, P3124, DOI 10.1109/TIP.2015.2438553
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Zang MJ, 2015, NEUROCOMPUTING, V148, P467, DOI 10.1016/j.neucom.2014.07.018
   Zheng S., 2008, P IEEE INT C COMP VI, P1529
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 55
TC 9
Z9 9
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 192
EP 206
DI 10.1016/j.jvcir.2016.11.004
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Haque, S
   Rahman, SMM
   Hatzinakos, D
AF Haque, Samiul
   Rahman, S. M. Mahbubur
   Hatzinakos, Dimitrios
TI Gaussian-Hermite moment-based depth estimation from single still image
   for stereo vision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anaglyph image; Depth estimation; Focus cue; Gaussian-Hermite moments;
   Laplacian matting
ID 2D-TO-3D CONVERSION; PARALLEL FRAMEWORK; VIDEO; 3D; 2D; MOTION; HEVC;
   EXTRACTION; RECONSTRUCTION; GENERATION
AB Depth information of objects plays a significant role in image-based rendering. Traditional depth estimation techniques use different visual cues including the disparity, motion, geometry, and defocus of objects. This paper presents a novel approach of focus cue-based depth estimation for still images using the Gaussian-Hermite moments (GHMs) of local neighboring pixels. The GHMs are chosen due to their superior reconstruction ability and invariance properties to intensity and geometric distortions of objects as compared to other moments. Since depths of local neighboring pixels are significantly correlated, the Laplacian matting is employed to obtain final depth map from the moment-based focus map. Experiments are conducted on images of indoor and outdoor scenes having objects with varying natures of resolution, edge, occlusion, and blur contents. Experimental results reveal that the depth estimated from GHMs can provide anaglyph images with stereo quality better than that provided by existing methods using traditional visual cues. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Haque, Samiul; Rahman, S. M. Mahbubur] Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka 1205, Bangladesh.
   [Haque, Samiul] North Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27606 USA.
   [Hatzinakos, Dimitrios] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada.
   [Haque, Samiul] Bangladesh Univ Engn & Technol, Dhaka, Bangladesh.
C3 Bangladesh University of Engineering & Technology (BUET); North Carolina
   State University; University of Toronto; Bangladesh University of
   Engineering & Technology (BUET)
RP Rahman, SMM (corresponding author), Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka 1205, Bangladesh.
EM shaque2@ncsu.edu; mahbubur@eee.buet.ac.bd; dimitris@comm.utoronto.ca
RI Haque, Samiul/J-2569-2019
FU Natural Sciences and Engineering Research Council (NSERC) of Canada
FX The initial part of this work was supported by the Natural Sciences and
   Engineering Research Council (NSERC) of Canada. The authors would like
   to give thanks to the anonymous reviewers for their valuable comments
   that were useful to improve the quality of the paper.
CR Alatan AA, 1998, IEEE T IMAGE PROCESS, V7, P904, DOI 10.1109/83.679440
   [Anonymous], 2012, 2012 IEEE COMP SOC C
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Campo FB, 2012, IEEE J-STSP, V6, P437, DOI 10.1109/JSTSP.2012.2204036
   Battiato S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P124
   Battiato S, 2004, PROC SPIE, V5302, P95, DOI 10.1117/12.526634
   Cao X, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.65
   Cao X, 2011, IEEE T BROADCAST, V57, P491, DOI 10.1109/TBC.2011.2127650
   Chao-Chung Cheng, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P377, DOI 10.1109/ICCE.2010.5418746
   Chen WY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1315
   Chen Y, 2011, PROC SPIE, V7863, DOI 10.1117/12.872159
   Choi CH, 2004, IEEE T CONSUM ELECTR, V50, P903, DOI 10.1109/TCE.2004.1341698
   Choi J, 2010, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2010.5653389
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Curti S, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P550, DOI 10.1109/TDPVT.2002.1024116
   Fawaz M, 2012, INT CONF ACOUST SPEE, P1441, DOI 10.1109/ICASSP.2012.6288162
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Harman P, 2002, PROC SPIE, V4660, P78, DOI 10.1117/12.468020
   Herrera JL, 2015, IEEE IMAGE PROC, P4753, DOI 10.1109/ICIP.2015.7351709
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   Hong L, 2004, PROC CVPR IEEE, P74
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Hung YS, 1999, IEEE T PATTERN ANAL, V21, P570, DOI 10.1109/34.771330
   Ideses I, 2007, J REAL-TIME IMAGE PR, V2, P3, DOI 10.1007/s11554-007-0038-9
   Imran SM, 2016, PATTERN RECOGN, V56, P100, DOI 10.1016/j.patcog.2016.03.006
   Ishibashi Takashi, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P22, DOI 10.1109/PCS.2010.5702472
   Jung JinWoo., 2010, Communications Workshops (ICC), 2010 IEEE International Conference on, P1
   Jung SW, 2012, IEEE T IMAGE PROCESS, V21, P3624, DOI 10.1109/TIP.2012.2191569
   Jung Y. J., 2009, P SPIE
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Kim J, 2010, PROC SPIE, V7524, DOI 10.1117/12.839925
   Kim TW, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.3.033108
   Klaus A, 2006, INT C PATT RECOG, P15
   Kuo TY, 2012, INT CONF ACOUST SPEE, P1433, DOI 10.1109/ICASSP.2012.6288160
   Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298
   Lebreton P, 2012, IEEE J-STSP, V6, P710, DOI 10.1109/JSTSP.2012.2213236
   Lee G. G., 2010, CHINESE J IMAGING RE, V16, P116
   Lee GG, 2015, J SIGNAL PROCESS SYS, V81, P345, DOI 10.1007/s11265-014-0955-3
   Lee S, 2012, INT CONF ACOUST SPEE, P801, DOI 10.1109/ICASSP.2012.6288005
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Lin GS, 2010, IEEE INT CON MULTI, P1141, DOI 10.1109/ICME.2010.5583347
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu JH, 2015, FRONT PLANT SCI, V6, DOI 10.3389/fpls.2015.00827
   Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97
   Lu Wang, 2011, 2011 IEEE 13th International Conference on Communication Technology (ICCT), P389, DOI 10.1109/ICCT.2011.6157903
   Matsui S, 2014, IMAGE VISION COMPUT, V32, P954, DOI 10.1016/j.imavis.2014.09.001
   McNerney PJ, 2007, IEEE T CIRC SYST VID, V17, P785, DOI 10.1109/TCSVT.2007.894045
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller T, 2011, PROC CVPR IEEE, P1193, DOI 10.1109/CVPR.2011.5995633
   Paramanand C, 2012, IEEE T IMAGE PROCESS, V21, P2798, DOI 10.1109/TIP.2011.2179664
   Ponomaryov V., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P407, DOI 10.1109/ISSPA.2012.6310584
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Rahman SMM, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0090-5
   Ren YN, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON UBI-MEDIA COMPUTING AND WORKSHOPS (UMEDIA), P91, DOI 10.1109/U-MEDIA.2014.55
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Shantaram V., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P201, DOI 10.1109/ITCC.2000.844211
   Shen J, 2000, INT J PATTERN RECOGN, V14, P875, DOI 10.1142/S0218001400000581
   Shen W., 2009, P INT SPIE C PATTERN, V7496, P1
   Su H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601159
   SWAIN C, 1995, INT CONF ACOUST SPEE, P2403, DOI 10.1109/ICASSP.1995.479977
   Taketomi Y, 2013, I S INTELL SIG PROC, P403, DOI 10.1109/ISPACS.2013.6704583
   Tian H, 2014, IEEE IMAGE PROC, P2017, DOI 10.1109/ICIP.2014.7025404
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Valencia SA, 2003, P SOC PHOTO-OPT INS, V5006, P377, DOI 10.1117/12.474113
   Wang HQ, 2014, I C CONT AUTOMAT ROB, P1524, DOI 10.1109/ICARCV.2014.7064542
   WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074
   Wu YF, 2005, EURASIP J APPL SIG P, V2005, P588, DOI 10.1155/ASP.2005.588
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Yang B, 2011, PATTERN RECOGN LETT, V32, P1283, DOI 10.1016/j.patrec.2011.03.012
   Yap PT, 2004, IEE P-VIS IMAGE SIGN, V151, P128, DOI 10.1049/ip-vis:20040395
   Yea-Shuan Huang, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.205
   Zhu ZY, 2012, IEEE T CIRC SYST VID, V22, P1405, DOI 10.1109/TCSVT.2012.2198133
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
   Zisserman A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P51, DOI 10.1109/MMCS.1999.779119
NR 82
TC 3
Z9 3
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 281
EP 295
DI 10.1016/j.jvcir.2016.10.008
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000025
DA 2024-07-18
ER

PT J
AU Hettiarachchi, R
   Peters, JF
AF Hettiarachchi, R.
   Peters, J. F.
TI Multi-manifold-based skin classifier on feature space Voronoi regions
   for skin segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skin segmentation; Multi-manifold learning; Feature space Voronoi
   segmentation
AB Skin segmentation is a crucial and a challenging step in many face and gesture recognition techniques and it has various applications in human computer interaction, objectionable content filtering, image retrieval and many more. In this article, we propose a novel skin segmentation method, which uses multi-manifold-based skin classification of feature space skin candidate Voronoi regions to achieve accurate skin segmentation. The state-of-the-art skin segmentation techniques reported in this article focus on discrimination between textural feature vectors belonging to skin and non-skin classes. In contrast, the proposed method focuses on discrimination between textural feature vectors belonging to skin and skin-like (non-skin) classes, which lead to higher skin classification accuracy. Furthermore, we introduce a novel image segmentation technique based on spatial and feature space Dirichlet tessellation (also called a Voronoi diagram) to achieve feature space segmentation of skin candidate regions of an image. These feature space segments will then be classified using a multi-manifold-based skin classifier. The proposed skin segmentation method was evaluated on two benchmark skin segmentation data sets and its results were compared with four other state-of-the-art methods proposed for skin segmentation. The experimental results reported in this article confirm that the proposed method outperforms the existing skin segmentation approaches in terms of false alarm rates in the skin segmentation process. Also, the proposed method results in the lowest minimal detection error compared to the existing methods reported in this article. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hettiarachchi, R.; Peters, J. F.] Univ Manitoba, Dept Elect & Comp Engn, Computat Intelligence Lab, Winnipeg, MB R3T 5V6, Canada.
   [Peters, J. F.] Adiyaman Univ, Dept Math, TR-02040 Adiyaman, Turkey.
C3 University of Manitoba; Adiyaman University
RP Peters, JF (corresponding author), Univ Manitoba, Dept Elect & Comp Engn, Computat Intelligence Lab, Winnipeg, MB R3T 5V6, Canada.
EM james.peters3@umanitoba.ca
RI Peters, James/AAE-1310-2020
CR [Anonymous], 2004, THESIS
   [Anonymous], 1850, Crelles Journal, DOI 10.1515/crll.1850.40.209
   Baldi A., 2014, SKIN CANC, P523
   Ballerini L., 2013, Color medical image analysis, P63
   Ballerini L, 2010, LECT NOTES COMPUT SC, V5853, P31, DOI 10.1007/978-3-642-11769-5_3
   Bhoyar K. K., 2010, Journal of Computer Sciences, V6, P963, DOI 10.3844/jcssp.2010.963.968
   Bilal S, 2015, J REAL-TIME IMAGE PR, V10, P371, DOI 10.1007/s11554-012-0305-2
   Cech E., 1966, Topological Spaces
   Chen MJ, 2003, IEEE T CONSUM ELECTR, V49, P724, DOI 10.1109/TCE.2003.1233810
   Daxiang L., 2013, INT J COMPUT SCI, V10
   Di Concilio A, 2009, CONTEMP MATH, V486, P89
   Du Q, 2006, J MATH IMAGING VIS, V24, P177, DOI 10.1007/s10851-005-3620-4
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Fan MY, 2012, IEEE DATA MINING, P241, DOI 10.1109/ICDM.2012.98
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Hettiarachchi R, 2015, PATTERN RECOGN, V48, P2947, DOI 10.1016/j.patcog.2015.04.003
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang SS, 2011, EVID-BASED COMPL ALT, V2011, P1, DOI 10.1155/2011/895857
   Jolliffe I.T., 1986, Springer Series in Statistics, V1
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kawulok M., 2014, Advances in Low-Level Color Image Processing. Lecture Notes in Computational Vision and Biomechanics, V11, P329
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kevitt P.M, 2008, 8 INT C INFORM TECHN, P54
   Kovac J., 2003, HUMAN SKIN COLOR CLU, V2
   Lee JS, 2007, PATTERN RECOGN, V40, P2261, DOI 10.1016/j.patcog.2006.11.016
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Mollineda R., 2007, II Congreso Espanol de Informatica CEDI 2007, P978
   Norusis M.J., 2012, IBM SPSS Statistics 19 Statistical Procedures Companion
   Ostrovsky R, 2006, ANN IEEE SYMP FOUND, P165
   Pan Ng, 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P213, DOI 10.1109/CICSyN.2011.54
   Peters J. F., 2016, INTELLIGENT SYSTEMS, V102
   Peters JF, 2014, INTEL SYST REF LIBR, V63, P1, DOI 10.1007/978-3-642-53845-2_1
   Petersen J., 2015, ACS Appl. Mater. Interfaces, V4, P1
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Radlak K, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P145, DOI 10.1109/ICTEA.2012.6462854
   Radtke Paulo, 2013, Multiple Classifier Systems. 11th International Workshop, MCS 2013. Proceedings, P95, DOI 10.1007/978-3-642-38067-9_9
   Romesburg C., 2004, CLUSTER ANAL RES
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saxen F, 2014, IEEE IMAGE PROC, P4467, DOI 10.1109/ICIP.2014.7025906
   SEBER G. A., 2009, Multivariate observations, V252
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119
   Sobottka K, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P483, DOI 10.1109/ICIP.1996.560536
   Stöttinger J, 2009, LECT NOTES COMPUT SC, V5876, P303, DOI 10.1007/978-3-642-10520-3_28
   Suhail M. A., 2002, 2002 IEEE International Conference on Systems, Man and Cybernetics. Conference Proceedings (Cat. No.02CH37349), DOI 10.1109/ICSMC.2002.1176427
   Taqa AY, 2010, SCI RES ESSAYS, V5, P2480
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Voronoi G., 1907, Journal fr die Reine und Angewandte Mathematik, V133, P97, DOI DOI 10.1515/CRLL.1908.133.97
   Weiss GM, 2003, J ARTIF INTELL RES, V19, P315, DOI 10.1613/jair.1199
   Xiaohua Wang, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P1985
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Yogarajah P, 2012, INT J BIOMETRICS, V4, P38, DOI 10.1504/IJBM.2012.044291
NR 55
TC 11
Z9 11
U1 4
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 123
EP 139
DI 10.1016/j.jvcir.2016.09.011
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000012
DA 2024-07-18
ER

PT J
AU Mbarki, Z
   Seddik, H
   Ben Braiek, E
AF Mbarki, Zouhair
   Seddik, Hassene
   Ben Braiek, Ezzedine
TI A rapid hybrid algorithm for image restoration combining parametric
   Wiener filtering and wave atom transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Parametric Wiener filtering; Wave atom transform
ID PARALLEL FRAMEWORK; DECONVOLUTION
AB Image restoration refers to removal or minimization of known degradations in an image. This includes de-blurring images degraded by the limitations of sensors or source of captures in addition to noise filtering and correction of geometric distortion due to sensors. There are several classical image restoration methods such as Wiener filtering. To find an estimate of the original image, Wiener filter requires the prior knowledge of the degradation phenomenon, the blurred image and the statistical properties of the noise process. In this work, we propose a new rapid and blind algorithm for image restoration that does not require a priori knowledge of the noise distribution. The degraded image is first de convoluted in Fourier space by parametric Wiener filtering, and then, it is smoothed by the wave atom transform after setting the threshold to its coefficients. Experiment results are significant and show the efficiency of our algorithm compared with other techniques in use. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Mbarki, Zouhair; Seddik, Hassene; Ben Braiek, Ezzedine] Univ Tunis, Dept Elect Engn, CEREP, ENSIT, 5 Ave Taha Hussein, Tunis 1008, Tunisia.
C3 Universite de Tunis
RP Mbarki, Z (corresponding author), Univ Tunis, Dept Elect Engn, CEREP, ENSIT, 5 Ave Taha Hussein, Tunis 1008, Tunisia.
EM mbarki.zouhair84@gmail.com; seddikhassne@gmail.com;
   Ezzedine.benbraiek@esstt.rnu.tn
RI mbarki, zouhair/AAD-1232-2020; mbarki, zouhair/HQY-5968-2023
OI hassene, seddik/0000-0003-0848-8285
CR Afonso M.V., IEEE T IMAGE PROCESS, V19
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chaudhry A, 2013, APPL SOFT COMPUT, V13, P817, DOI 10.1016/j.asoc.2012.10.017
   Dai Wenzhan, 2007, P 2007 IEEE INT C IN
   Demanet L, 2007, APPL COMPUT HARMON A, V23, P368, DOI 10.1016/j.acha.2007.03.003
   Dobes M, 2010, DIGIT SIGNAL PROCESS, V20, P1677, DOI 10.1016/j.dsp.2010.03.012
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Kaur L., 2002, P 3 IND C COMP VIS G
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Li Xiang, 2010, P 2010 IEEE INT C ME
   Lihong Yang, 2011, Proceedings 2011 IEEE 2nd International Conference on Software Engineering and Service Science (ICSESS 2011), P890, DOI 10.1109/ICSESS.2011.5982483
   Liu F, 2012, OPT COMMUN, V285, P5008, DOI 10.1016/j.optcom.2012.08.007
   Liu J, 2015, INFORM SCIENCES, V295, P232, DOI 10.1016/j.ins.2014.10.041
   Naimi H, 2015, J KING SAUD UNIV-COM, V27, P40, DOI 10.1016/j.jksuci.2014.03.015
   Palakkal S, 2012, SIGNAL PROCESS, V92, P2002, DOI 10.1016/j.sigpro.2012.01.008
   Qin FQ, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P360, DOI 10.1109/CISP.2012.6470002
   Tang S, 2014, SIGNAL PROCESS, V94, P339, DOI 10.1016/j.sigpro.2013.07.005
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang GC, 2015, DIGIT SIGNAL PROCESS, V47, P157, DOI 10.1016/j.dsp.2015.04.011
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 24
TC 8
Z9 8
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 694
EP 707
DI 10.1016/j.jvcir.2016.08.009
PN B
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600024
DA 2024-07-18
ER

PT J
AU Wang, RG
   Ding, K
   Yang, J
   Xue, LX
AF Wang, Ronggui
   Ding, Kai
   Yang, Juan
   Xue, Lixia
TI A novel method for image classification based on bag of visual words
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE BOW; Saliency; Topological structure; Delaunay triangulation; Image
   classification
ID ASSIGNMENT
AB Bag of words (BOW) model is widely applied in image classification. The traditional BOW neglects the spatial information and object shape information, which fails to distinguish between image features absolutely. In this paper, we combine the salient region with visual words topological structure. It not only can produce more representative visual words, but also can avoid the disturbance of complex background efficiently. Firstly, the salient regions are extracted and the BOW model is built on salient regions. Secondly, in order to describe the characteristics of the image more accurately and to resist the influence of background information, the visual words topological structure and Delaunay triangulation method are employed, which is able to integrate into the global and local information. The performance of the proposed algorithm is tested on several datasets, and compared with other models. The experiment results seem to demonstrate that the proposed method provide a higher classification accuracy. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Ronggui; Ding, Kai; Yang, Juan; Xue, Lixia] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM yangjuan6985@163.com
RI Lin, Kuan-Yu/JXM-6653-2024
CR Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng Y, 2014, IEEE T CYBERNETICS, V44, P1924, DOI 10.1109/TCYB.2014.2300192
   Deng Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063385
   Donahue J., 131015312013 ARXIV
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Guo XJ, 2012, PATTERN RECOGN LETT, V33, P872, DOI 10.1016/j.patrec.2011.08.021
   Holub A., 2007, 7694 CALTECH
   Huang Jing, 1997, P IEEE COMP SOC C CO
   Jiang Yue, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1366, DOI 10.3724/SP.J.1089.2010.10919
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Li Y, 2005, PROC CVPR IEEE, P711
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu Shuo-yan, 2010, Acta Electronica Sinica, V38, P1156
   Ma JB, 2000, PROC CVPR IEEE, P637, DOI 10.1109/CVPR.2000.854932
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tang G., 2008, STUDY IMPROVED FINGE
   van Gemert JC, 2008, LECT NOTES COMPUT SC, V5304, P696
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng Dan, 2011, Journal of Computer Aided Design & Computer Graphics, V23, P1725
   Zhang S, 2009, P 17 ACM INT C MULT
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   Zhang YM, 2009, PROC CVPR IEEE, P1762, DOI 10.1109/CVPRW.2009.5206791
   Zhou DX, 2004, IEEE INT CONF ROBOT, P2730
NR 30
TC 18
Z9 19
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 24
EP 33
DI 10.1016/j.jvcir.2016.05.022
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500003
DA 2024-07-18
ER

PT J
AU Zhang, HZ
   Li, F
   Deng, H
   Li, ZM
   Yan, K
   Xie, C
   Wang, KQ
AF Zhang, Hongzhi
   Li, Feng
   Deng, Hong
   Li, Zhengming
   Yan, Ke
   Xie, Charlene
   Wang, Kuanquan
TI Adjusting samples for obtaining better <i>l</i><sub>2</sub>-norm
   minimization based sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE l(2)-norm; Sparse representation; Face recognition; Sample adjusting
ID FACE RECOGNITION; SUPERRESOLUTION; IDEA
AB l(2)-norm sparse representation (l(2)-SR) based face recognition method has attracted increasing attention due to its excellent performance, simple algorithm and high computational efficiency. However, one of the drawbacks of l(2)-SR is that the test sample may be conspicuous difference from the training samples even from the same class and thus the method shows poor robustness. Another drawback is that l(2)-SR does not perform well in identifying the training samples that are trivial in correctly classifying the test sample. In this paper, to avoid the above imperfection, we proposed a novel l(2)-SR. We first identifies the training samples that are important in correctly classifying the test sample and then neglects components that cannot be represented by the training samples. The proposed method also involve in-depth analysis of l(2)-SR and provide novel ideas to improve previous methods. Experimental results on face datasets show that the proposed method can greatly improve l(2)-SR. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Hongzhi; Li, Feng; Deng, Hong; Wang, Kuanquan] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Li, Zhengming] Guangdong Polytech Normal Univ, Ind Training Ctr, Guangzhou, Guangdong, Peoples R China.
   [Yan, Ke; Xie, Charlene] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Guangdong Polytechnic Normal University;
   Harbin Institute of Technology
RP Zhang, HZ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM zhanghz@hit.edu.cn
RI Wang, Kuanquan/JCE-9520-2023; Yan, Kefen/GZK-4905-2022; wu,
   sen/HKE-6181-2023; Zhang, Hongzhi/HHS-0345-2022
FU National Natural Science Foundation of China [61471146, 61401125,
   51308096]
FX This study was partially supported by National Natural Science
   Foundation of China under grants no. 61471146, 61401125, 51308096.
   Thanks to Dr. Edward C. Mignot, Shandong University, for linguistic
   advice.
CR Anitori L, 2013, IEEE T SIGNAL PROCES, V61, P813, DOI 10.1109/TSP.2012.2225057
   [Anonymous], 2007, IEEE T PATTERN ANAL
   [Anonymous], COMMUN ACM
   Cheng H, 2013, SIGNAL PROCESS, V93, P1408, DOI 10.1016/j.sigpro.2012.09.011
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Fan ZZ, 2015, J VIS COMMUN IMAGE R, V28, P15, DOI 10.1016/j.jvcir.2015.01.001
   Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004
   Gao S., 2010, KERNEL SPARSE REPRES, P1
   Han PY, 2011, J VIS COMMUN IMAGE R, V22, P634, DOI 10.1016/j.jvcir.2011.07.009
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Huang JZ, 2009, IEEE I CONF COMP VIS, P64, DOI 10.1109/ICCV.2009.5459202
   Huang LK, 2014, J VIS COMMUN IMAGE R, V25, P1774, DOI 10.1016/j.jvcir.2014.08.006
   Liu ZH, 2013, APPL INTELL, V39, P307, DOI 10.1007/s10489-012-0414-4
   Naseem I, 2012, PATTERN RECOGN, V45, P104, DOI 10.1016/j.patcog.2011.07.003
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Ren CX, 2012, PATTERN RECOGN, V45, P2708, DOI 10.1016/j.patcog.2012.01.003
   Shenghua Gao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2809, DOI 10.1109/CVPR.2011.5995454
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Sivalingam R., 2010, TENSOR SPARSE CODING, P722
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2013, NEUROCOMPUTING, V113, P168, DOI 10.1016/j.neucom.2013.01.036
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu Yong., 2012, Int J Innov Comput Inf Control, V8, P1349
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M., TECHNICAL REPORT
   Yang M, 2013, IEEE T NEUR NET LEAR, V24, P900, DOI 10.1109/TNNLS.2013.2245340
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yang S., 2012, Int. J. Electrochem, V2012, P1, DOI DOI 10.1109/SCET2012.6342146
   Yang Y, 2011, PROC CVPR IEEE, P881, DOI 10.1109/CVPR.2011.5995499
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhu P., 2012, MULTISCALE PATCH BAS, P822
   Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909
NR 42
TC 3
Z9 3
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 93
EP 99
DI 10.1016/j.jvcir.2016.05.013
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900009
DA 2024-07-18
ER

PT J
AU Lo, CW
   Zhou, C
   Lin, CW
   Chen, YC
AF Lo, Chi-Wen
   Zhou, Chao
   Lin, Chia-Wen
   Chen, Yung-Chang
TI An unequal error protection scheme for reliable peer-to-peer scalable
   video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video streaming; Peer-to-peer streaming; Scalable video coding; Joint
   source-channel coding; Unequal error protection
ID THROUGHPUT; EXTENSION; MULTICAST; CONSENSUS; SELECTION
AB This paper proposes an unequal error protection (UEP) scheme for transporting scalable video packets over packet-lossy peer-to-peer networks. In our scheme, given an estimated system uplink capacity, a receiver-driven joint source-channel coding (JSCC) mechanism is proposed by which each child-peer minimizes the received visual distortion by subscribing to appropriate numbers of source and channel coding packets. Because the bandwidth for inter-peer transmissions may fluctuate largely due to peer dynamics, in our method, a peer estimates the available system uplink capacity based on consensus propagation to avoid the fluctuating allocations of JSCC. To efficiently utilize the uplink bandwidth of peers, parent-peers utilize sender-driven contribution-guided peer selection to reject the low-contribution subscriptions requested from candidate child-peers. Simulation results demonstrate that our method significantly improves the visual quality, compared to other state-of-the-art schemes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lo, Chi-Wen] Ind Technol Res Inst, Informat & Commun Res Labs, Hsinchu, Taiwan.
   [Zhou, Chao] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Lin, Chia-Wen; Chen, Yung-Chang] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan.
C3 Industrial Technology Research Institute - Taiwan; Peking University;
   National Tsing Hua University
RP Lin, CW (corresponding author), Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan.
EM kenlo0425@gmail.com; zhouchaoyf@gmail.com; cwlin@ee.nthu.edu.tw;
   ycchen@ee.nthu.edu.tw
RI Lin, Chia-Wen/ABH-6075-2020; Zhou, Chao/A-9803-2012; Lin,
   Chia-Wen/M-4571-2013
OI Lin, Chia-Wen/0000-0002-9097-2318
CR Akbari B, 2008, MULTIMEDIA SYST, V13, P345, DOI 10.1007/s00530-007-0097-6
   Bickson D., 2008, PEER TO PEER NETW AP
   Chang CL, 2014, IEEE SYST J, V8, P304, DOI 10.1109/JSYST.2013.2258199
   Chen CM, 2007, SIGNAL PROCESS-IMAGE, V22, P277, DOI 10.1016/j.image.2006.12.010
   Chen CM, 2010, IEEE T CIRC SYST VID, V20, P1448, DOI 10.1109/TCSVT.2010.2077475
   Chi H.-Y., 2008, P IEEE INT S CIRC SY
   Corman T. H, 2009, Introduction to Algorithms, V3rd
   Ghaeini HR, 2014, LECT NOTES COMPUT SC, V8458, P109, DOI 10.1007/978-3-319-13174-0_9
   Habib A, 2006, IEEE T MULTIMEDIA, V8, P610, DOI 10.1109/TMM.2006.870724
   He YF, 2009, IEEE T MULTIMEDIA, V11, P509, DOI 10.1109/TMM.2009.2012921
   Hellge C, 2011, IEEE T MULTIMEDIA, V13, P551, DOI 10.1109/TMM.2011.2129499
   Hu H, 2011, IEEE T CIRC SYST VID, V21, P1013, DOI 10.1109/TCSVT.2011.2129290
   Ji W, 2012, IEEE T MULTIMEDIA, V14, P443, DOI 10.1109/TMM.2011.2177645
   Li ZC, 2009, IEEE T CIRC SYST VID, V19, P917, DOI 10.1109/TCSVT.2009.2022806
   Liu LX, 2011, IEEE T CIRC SYST VID, V21, P39, DOI 10.1109/TCSVT.2011.2105570
   Liu ZY, 2009, IEEE T MULTIMEDIA, V11, P1340, DOI 10.1109/TMM.2009.2030656
   Lo CW, 2012, IEEE T CIRC SYST VID, V22, P1388, DOI 10.1109/TCSVT.2012.2202072
   Maani E, 2010, IEEE T CIRC SYST VID, V20, P407, DOI 10.1109/TCSVT.2009.2035846
   Moallemi CC, 2006, IEEE T INFORM THEORY, V52, P4753, DOI 10.1109/TIT.2006.883539
   Olfati-Saber R, 2007, P IEEE, V95, P215, DOI 10.1109/JPROC.2006.887293
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Paschalidis IC, 2011, IEEE T AUTOMAT CONTR, V56, P2290, DOI 10.1109/TAC.2011.2163875
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Setton E, 2008, P IEEE, V96, P25, DOI 10.1109/JPROC.2007.909925
   Stoufs M, 2008, IEEE T CIRC SYST VID, V18, P1657, DOI 10.1109/TCSVT.2008.2004922
   Tong S., 2013, P POWERTECH, P1
   Wu PJ, 2009, IEEE T CIRC SYST VID, V19, P1766, DOI 10.1109/TCSVT.2009.2026956
   Xiao X, 2010, IEEE T PARALL DISTR, V21, P685, DOI 10.1109/TPDS.2009.93
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
   Xu YS, 2002, IEEE T BROADCAST, V48, P237, DOI 10.1109/TBC.2002.803706
   Zegura EW, 1996, IEEE INFOCOM SER, P594, DOI 10.1109/INFCOM.1996.493353
   Zhang M, 2009, IEEE T PARALL DISTR, V20, P97, DOI 10.1109/TPDS.2008.69
   Zorzi M, 1998, IEEE VTC P, P1390, DOI 10.1109/VETEC.1998.686502
NR 33
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 790
EP 801
DI 10.1016/j.jvcir.2016.04.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100066
DA 2024-07-18
ER

PT J
AU Lu, GF
   Tang, GY
   Zou, J
AF Lu, Gui-Fu
   Tang, Ganyi
   Zou, Jian
TI Spare L1-norm-based maximum margin criterion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature extraction; Linear discriminant analysis; L1-norm; L2-norm;
   Maximum margin criterion; Elastic net; Sparse subspace; Face recognition
ID DISCRIMINANT-ANALYSIS; ROBUST; RECOGNITION; REGRESSION
AB Maximum margin criterion (MMC) is a popular method for dimensionality reduction or feature extraction. MMC can alleviate the small size sample (SSS) problem encountered by linear discriminant analysis (LDA) and extract more discriminant vectors than LDA. However, the objective function of MMC is derived from L2-norm, which makes MMC be sensitive to noise and outliers. Besides, the basis vectors of MMC are dense, which makes it hard to explain the obtained features. To address the drawbacks of MMC, in this paper, we propose a novel sparse L1-norm-based maximum margin criterion (SMMC-L1). L1-norm rather than L2-norm is used in the objective function of SMMC-L1. Besides, L1-norm is also used as a lasso penalty to regularize the basis vectors. An iterative algorithm for solving SMMC-L1 is proposed. Experiment results on some databases show the effectiveness of the proposed SMMC-L1. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lu, Gui-Fu; Tang, Ganyi; Zou, Jian] AnHui Polytech Univ, Sch Comp & Informat, Wuhu 241000, AnHui, Peoples R China.
   [Lu, Gui-Fu] Nanjing Univ Sci & Technol, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Jiangsu, Peoples R China.
C3 Anhui Polytechnic University; Nanjing University of Science & Technology
RP Lu, GF (corresponding author), AnHui Polytech Univ, Sch Comp & Informat, Wuhu 241000, AnHui, Peoples R China.
EM luguifu_tougao@163.com
FU NSFC [61572033, 71371012]; Natural Science Foundation of Education
   Department of Anhui Province of China [KJ2015ZD08]; Social Science and
   Humanity Foundation of the Ministry of Education of China [13YJA630098];
   Anhui Provincial Natural Science Foundation China [1308085MF95]
FX This research is supported by NSFC (Nos. 61572033, 71371012), the
   Natural Science Foundation of Education Department of Anhui Province of
   China (No. KJ2015ZD08), the Social Science and Humanity Foundation of
   the Ministry of Education of China (No. 13YJA630098), Anhui Provincial
   Natural Science Foundation China (No. 1308085MF95). The authors would
   like to thank the anonymous reviews and the editor for their helpful
   comments and suggestions to improve the quality of this paper.
CR [Anonymous], P 21 AAAI C ART INT
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2003, ADV NEURAL INFORM PR
   [Anonymous], P IEEE C COMP VIS PA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jenatton R., 2010, JMLR WORKSH C P 2010, P366
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li X, 2010, NEUROCOMPUTING, V73, P2571, DOI 10.1016/j.neucom.2010.05.016
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu J, 2007, IEEE T NEURAL NETWOR, V18, P1862, DOI 10.1109/TNN.2007.900813
   Liu TL, 2016, IEEE T NEUR NET LEAR, V27, P1851, DOI 10.1109/TNNLS.2015.2458986
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu TL, 2014, INT CONF INFO SCI, P100, DOI 10.1109/ICIST.2014.6920341
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Meng DY, 2012, PATTERN RECOGN, V45, P487, DOI 10.1016/j.patcog.2011.07.009
   Nie F., 2011, P 22 INT JOINT C ART, P1
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Song FX, 2007, IEEE T SYST MAN CY B, V37, P1599, DOI 10.1109/TSMCB.2007.906579
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Wang HX, 2013, NEURAL NETWORKS, V46, P190, DOI 10.1016/j.neunet.2013.06.002
   Wang HX, 2012, IEEE T BIO-MED ENG, V59, P653, DOI 10.1109/TBME.2011.2177523
   Wang HX, 2012, NEURAL NETWORKS, V27, P38, DOI 10.1016/j.neunet.2011.11.003
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xu C., 2014, P INT C MACH LEARN, p865~873
   Xu C, 2015, AAAI CONF ARTIF INTE, P1924
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zheng WM, 2014, IEEE T NEUR NET LEAR, V25, P793, DOI 10.1109/TNNLS.2013.2281428
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 46
TC 7
Z9 7
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 11
EP 17
DI 10.1016/j.jvcir.2016.02.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100002
DA 2024-07-18
ER

PT J
AU Rasti, P
   Samiei, S
   Agoyi, M
   Escalera, S
   Anbarjafari, G
AF Rasti, Pejman
   Samiei, Salma
   Agoyi, Mary
   Escalera, Sergio
   Anbarjafari, Gholamreza
TI Robust non-blind color video watermarking using QR decomposition and
   entropy analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video watermarking; QR decomposition; Discrete Wavelet Transformation;
   Chirp Z-transform; Singular value decomposition; Orthogonal-triangular
   decomposition
ID CHIRP-Z-TRANSFORM; CORRELATION-COEFFICIENT; IMAGE WATERMARKING;
   ALGORITHM; DCT
AB Issues such as content identification, document and image security, audience measurement, ownership and copyright among others can be settled by the use of digital watermarking. Many recent video watermarking methods show drops in visual quality of the sequences. The present work addresses the aforementioned issue by introducing a robust and imperceptible non-blind color video frame watermarking algorithm. The method divides frames into moving and non-moving parts. The non-moving part of each color channel is processed separately using a block-based watermarking scheme. Blocks with an entropy lower than the average entropy of all blocks are subject to a further process for embedding the watermark image. Finally a watermarked frame is generated by adding moving parts to it. Several signal processing attacks are applied to each watermarked frame in order to perform experiments and are compared with some recent algorithms. Experimental results show that the proposed scheme is imperceptible and robust against common signal processing attacks. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Rasti, Pejman; Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
   [Samiei, Salma] Axinom OU, EE-51013 Tartu, Estonia.
   [Agoyi, Mary] Cyprus Int Univ, Fac Engn, KICTC, Via Mersin 10, Lefkosa, Turkey.
   [Escalera, Sergio] Comp Vis Ctr, Barcelona, Spain.
   [Escalera, Sergio] Univ Barcelona, Barcelona, Spain.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Fac Engn, Dept Elect & Elect Engn, Gaziantep, Turkey.
C3 University of Tartu; Cyprus International University; Centre de Visio
   per Computador (CVC); University of Barcelona; Hasan Kalyoncu University
RP Anbarjafari, G (corresponding author), Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
RI Agoyi, Mary/JZE-3274-2024; Anbarjafari, Gholamreza/A-3845-2010;
   Escalera, Sergio/L-2998-2015; Rasti, Pejman/E-8523-2016
OI Anbarjafari, Gholamreza/0000-0001-8460-5717; Escalera,
   Sergio/0000-0003-0617-8873; Rasti, Pejman/0000-0002-7924-0001; Samiei,
   Salma/0000-0002-6333-4417
FU Estonian Research Council Grant PUT [PUT638]; Spanish project
   [TIN2013-43478-P]
FX This research is supported by the Estonian Research Council Grant PUT
   (PUT638), and the Spanish project TIN2013-43478-P.
CR Adeli H., 2010, ADV COMPUTER SCI INF
   Agoyi M., 2012, 6 INT C INF SEC CRYP
   Anjum S.R., 2012, INT J ADV COMPUT RES, V2
   [Anonymous], SIGNAL IMAGE VIDEO P
   [Anonymous], 2014, IND C INDICON 2014 A
   [Anonymous], 1990, Compact numerical methods for computers: linear algebra and function minimization
   Arizona State University, 2015, KYUV VID SEQ
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Campisi P, 2005, LECT NOTES COMPUT SC, V3710, P432
   Deguillaume F, 1999, PROC SPIE, V3657, P113, DOI 10.1117/12.344662
   Dejey D, 2011, IET IMAGE PROCESS, V5, P315, DOI 10.1049/iet-ipr.2009.0239
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   Farfoura ME, 2013, J CHIN INST ENG, V36, P87, DOI 10.1080/02533839.2012.726041
   Ghazy Rania A., 2007, 24th Radio National Science Conference (NRSC 2007), P1, DOI 10.1109/NRSC.2007.371376
   Han SC, 2012, INT CONF SIGN PROCES, P1592, DOI 10.1109/ICoSP.2012.6491884
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Houmansadr A, 2006, SIGMAP 2006: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P252
   Hsu CT, 1998, IEEE T CONSUM ELECTR, V44, P206, DOI 10.1109/30.663749
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Jane O, 2014, TURK J ELECTR ENG CO, V22, P1354, DOI 10.3906/elk-1212-75
   Kapre Bhagyashri S., 2011, 2011 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P295, DOI 10.1109/CSAE.2011.5952684
   Khalifa A., 2015, ADV COMPUT SCI INT J, V4, P97
   Khalilian H, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P1643
   Khalilian H, 2013, IEEE T IMAGE PROCESS, V22, P4825, DOI 10.1109/TIP.2013.2278463
   Khalilian H, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P125, DOI 10.1109/PACRIM.2011.6032879
   Koch J. D., 2011, CAMCORDING FILM PIRA
   Koz A, 2008, IEEE T CIRC SYST VID, V18, P326, DOI 10.1109/TCSVT.2008.918446
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Langelaar G.C., 2000, IEEE SIGNAL PROCESS, V17
   Larijani HH, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P157, DOI 10.1109/ICCCE.2008.4580587
   Laur L, 2015, SIG PROCESS COMMUN, P471, DOI 10.1109/SIU.2015.7129861
   Lee MJ, 2010, IEEE T MULTIMEDIA, V12, P605, DOI 10.1109/TMM.2010.2061221
   Lee YY, 2003, PROCEEDINGS OF THE 46TH IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS & SYSTEMS, VOLS 1-3, P1579
   Mahmood A, 2012, IEEE T IMAGE PROCESS, V21, P2099, DOI 10.1109/TIP.2011.2171696
   Manjunath M, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P193, DOI 10.1109/ICACCCT.2012.6320769
   Megalingam RK, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P349, DOI 10.1109/ICSAP.2010.79
   Mitra P., 2012, Proceedings of the 2012 International Conference on Recent Advances in Computing and Software Systems (RACSS), P135, DOI 10.1109/RACSS.2012.6212712
   Park H, 2006, LECT NOTES COMPUT SC, V4283, P397
   RABINER LR, 1969, BELL SYST TECH J, V48, P1249, DOI 10.1002/j.1538-7305.1969.tb04268.x
   Stillings S., 1972, STUDY CHIRP Z TRANSF
   Stutz T., 2014, IEEE T MULTIMEDIA
   Tabassum T, 2012, INT CONF COMPUT INFO, P101, DOI 10.1109/ICCITechn.2012.6509780
   Takaya K., 1990, MVA, P77
   TAYLOR R, 1990, J DIAGN MED SONOG, V6, P35, DOI 10.1177/875647939000600106
   Tong RQ, 1999, MAGNET RESON MED, V41, P253, DOI 10.1002/(SICI)1522-2594(199902)41:2<253::AID-MRM7>3.0.CO;2-1
   Wang SM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING AND 2008 INTERNATIONAL PACIFIC WORKSHOP ON WEB MINING AND WEB-BASED APPLICATION, P598, DOI 10.1109/ISIP.2008.149
   Xu W, 2007, IEEE T SIGNAL PROCES, V55, P5552, DOI 10.1109/TSP.2007.899374
   Yang Q., 2012, P 2012 S PHOTONICS O, P1, DOI [10.1109/SOPO.2012.6270549, DOI 10.1109/SOPO.2012.6270549]
   Zhu X., 2014, IEEE T MULTIMEDIA
NR 49
TC 39
Z9 43
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 838
EP 847
DI 10.1016/j.jvcir.2016.05.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100070
DA 2024-07-18
ER

PT J
AU Ding, WW
   Liu, K
   Cheng, F
   Zhang, J
AF Ding, Wenwen
   Liu, Kai
   Cheng, Fei
   Zhang, Jin
TI Learning hierarchical spatio-temporal pattern for human activity
   prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skeleton joints; 3D action feature representation; Self-organizing map;
   Hebbian learning; Variable order Markov model; Probabilistic suffix
   tree; RGB-D dataset; 3D trajectory segmentation
ID RECOGNITION; LATENCY
AB Human activity prediction has become increasingly valuable in many applications. This paper, initially from the perspective of cognition science, presents a novel approach to learning a hierarchical spatio-temporal pattern of human activities to predict ongoing activities from videos that contain only the onsets of the activities. Spatio-temporal pattern can be learned by a Hierarchical Self-Organizing Map (HSOM), which consists of two self-organizing maps (i.e., action map and actionlet map) connected via associative links trained by Hebbian learning. Ongoing activities can be predicted by Variable order Markov Model (VMM), which provides the means for capturing both large and small order Markov dependencies based on the training actionlet sequences. Experiments of the proposed method on four challenging 3D action datasets captured by commodity depth cameras show promising results. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ding, Wenwen; Liu, Kai; Cheng, Fei; Zhang, Jin] Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
C3 Xidian University
RP Liu, K (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
EM dww2048@163.com; kailiu@mail.xidian.edu.cn; chengfei8582@163.com;
   jinzhang.cv@gmail.com
RI Zhou, Jing/IVH-8073-2023; Liu, Kai/IST-6808-2023
OI , ding/0000-0001-8582-2078
FU National Natural Science Foundation of China [61571345, 9153801,
   61550110247]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61571345, the National Natural
   Science Foundation of China under Grant No. 9153801, and the National
   Natural Science Foundation of China under Grant No. 61550110247.
CR [Anonymous], 2002, ORG BEHAV NEUROPSYCH
   Begleiter R, 2004, J ARTIF INTELL RES, V22, P385, DOI 10.1613/jair.1491
   Bejerano G, 2001, BIOINFORMATICS, V17, P23, DOI 10.1093/bioinformatics/17.1.23
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Ding WW, 2015, J VIS COMMUN IMAGE R, V26, P329, DOI 10.1016/j.jvcir.2014.10.009
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hu WM, 2004, IEEE T SYST MAN CY B, V34, P1618, DOI 10.1109/TSMCB.2004.826829
   Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Martínez-Contreras F, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P43, DOI 10.1109/AVSS.2009.46
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Soon CS, 2008, NAT NEUROSCI, V11, P543, DOI 10.1038/nn.2112
   Sumpter N, 2000, IMAGE VISION COMPUT, V18, P697, DOI 10.1016/S0262-8856(99)00073-6
   Sun Q., 2013, BRIT MACH VIS C CIT
   Vesanto J., 1999, P MATL DSP C, P16
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang J, 2014, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-04561-0_2
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yu Z. L. Gang, 2014, COMPUTER VISION ACCV, P201
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
NR 36
TC 29
Z9 31
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 103
EP 111
DI 10.1016/j.jvcir.2015.12.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600009
DA 2024-07-18
ER

PT J
AU Lee, SH
   Kang, JW
   Kim, CS
AF Lee, Se-Ho
   Kang, Je-Won
   Kim, Chang-Su
TI Compressed domain video saliency detection using global and local
   spatiotemporal features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video saliency detection; Spatiotemporal feature; Compressed domain;
   Visual attention; Partial decoding; Image understanding; Image analysis;
   Motion analysis
ID VISUAL-ATTENTION; FAST ALGORITHMS; DETECTION MODEL; ADAPTIVE IMAGE;
   RANDOM-WALK; EXTRACTION; OBJECTS
AB A compressed domain video saliency detection algorithm, which employs global and local spatiotemporal (GLST) features, is proposed in this work. We first conduct partial decoding of a compressed video bit-stream to obtain motion vectors and DCT coefficients, from which GLST features are extracted. More specifically, we extract the spatial features of rarity, compactness, and center prior from DC coefficients by investigating the global color distribution in a frame. We also extract the spatial feature of texture contrast from AC coefficients to identify regions, whose local textures are distinct from those of neighboring regions. Moreover, we use the temporal features of motion intensity and motion contrast to detect visually important motions. Then, we generate spatial and temporal saliency maps, respectively, by linearly combining the spatial features and the temporal features. Finally, we fuse the two saliency maps into a spatiotemporal saliency map adaptively by comparing the robustness of the spatial features with that of the temporal features. Experimental results demonstrate that the proposed algorithm provides excellent saliency detection performance, while requiring low complexity and thus performing the detection in real-time. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lee, Se-Ho; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Kang, Je-Won] Ewha Womans Univ, Dept Elect Engn, Seoul 120750, South Korea.
C3 Korea University; Ewha Womans University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM seholee@mcl.korea.ac.kr; jewonk@ewha.ac.kr; changsukim@korea.ac.kr
RI Kang, Jewon/AAU-9722-2020
OI Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF) - Korea Government (MSIP)
   [NRF-2015R1A2A1A10055037]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MSIP) (No.
   NRF-2015R1A2A1A10055037).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Akamine K, 2012, COMPUT J, V55, P3, DOI 10.1093/comjnl/bxq075
   [Anonymous], 2012, ITUTSG16 WP3
   Chen C, 2005, IEEE INT SYMP CIRC S, P1497, DOI 10.1109/ISCAS.2005.1464883
   Chen DY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1085, DOI 10.1109/ICME.2008.4607627
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Khatoonabadi S. H., 2014, P 1 INT WORKSH PERC, P3
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Lee SH, 2014, IEEE IMAGE PROC, P1120, DOI 10.1109/ICIP.2014.7025223
   Li Y, 2009, IEEE IMAGE PROC, P3093, DOI 10.1109/ICIP.2009.5414465
   Lin CW, 2001, IEEE IMAGE PROC, P421, DOI 10.1109/ICIP.2001.959043
   Liu P., 2013, SCI WORLD J
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Merhav N, 1997, IEEE T CIRC SYST VID, V7, P468, DOI 10.1109/76.585926
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Suehring K., H 264 AVC REFERENCE
   Sukmarg O., 2000, 2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119), P364, DOI 10.1109/TENCON.2000.892290
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wolf L, 2007, IEEE I CONF COMP VIS, P1418
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yin Li, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P246
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JY, 2014, IEEE T IMAGE PROCESS, V23, P797, DOI 10.1109/TIP.2013.2294541
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 41
TC 9
Z9 10
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 169
EP 183
DI 10.1016/j.jvcir.2015.12.011
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600015
DA 2024-07-18
ER

PT J
AU Li, X
   Fang, M
   Zhang, JJ
AF Li, Xiao
   Fang, Min
   Zhang, Ju-Jie
TI Projected Transfer Sparse Coding for cross domain image representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; Domain adaptation; Sparse coding; Projection
   matrix; L-2,L-1 norm; Shared dictionary; Maximum Mean Discrepancy; KSVD
ID FACE RECOGNITION; DICTIONARIES
AB Sparse coding has been used for image representation successfully. However, when there is considerable variation between source and target domain, sparse coding cannot achieve satisfactory results. In this paper, we proposed a Projected Transfer Sparse Coding algorithm. In order to reduce their distribution difference, we project source and target data into a shared low dimensional space. Meanwhile, we learn a projection matrix and a shared dictionary and the sparse coding of source and target data in the low dimensional space. Unlike existing methods, the sparse representations are learnt using the projected data which are invariant to the distribution difference and the irrelevant samples. Thus, the sparse representations are robust and can improve the classification performance. We do not need to know any explicit correspondence across domains. We learn the projection matrix, the discriminative sparse representations, and the dictionary in a unified objective function. Our image representation method yields state-of-the-art results. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Li, Xiao; Fang, Min; Zhang, Ju-Jie] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
C3 Xidian University
RP Fang, M (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
EM mfang@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61472305, 61070143,
   61303034]; Science and Technology project of Shaanxi province, China
   [2015GY027]; Fundamental Research Funds for the Central Universities
   [SMC1405]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 61472305, 61070143, 61303034), Science and Technology
   project of Shaanxi province, China (Grant No. 2015GY027), and the
   Fundamental Research Funds for the Central Universities (Grant No.
   SMC1405).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Al-Shedivat M, 2014, AAAI CONF ARTIF INTE, P1665
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fang M, 2015, PATTERN RECOGN LETT, V51, P101, DOI 10.1016/j.patrec.2014.08.011
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Griffin G., 2007, CALTECH 256 OBJECT C
   Nguyen HV, 2013, IEEE T IMAGE PROCESS, V22, P5123, DOI 10.1109/TIP.2013.2282078
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2013.59
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Qiu Q, 2012, LECT NOTES COMPUT SC, V7575, P631, DOI 10.1007/978-3-642-33765-9_45
   Ranjan V., 2014, COMP VIS ACCV 2014 W, P247
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shekhar S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431440
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhang CJ, 2013, J VIS COMMUN IMAGE R, V24, P786, DOI 10.1016/j.jvcir.2013.05.004
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 38
TC 6
Z9 8
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 265
EP 272
DI 10.1016/j.jvcir.2015.09.018
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700024
DA 2024-07-18
ER

PT J
AU Qin, LX
   Sheng, B
   Lin, WY
   Wu, W
   Shen, RM
AF Qin, Lixia
   Sheng, Bin
   Lin, Weiyao
   Wu, Wen
   Shen, Ruimin
TI GPU-Accelerated Video Background Subtraction Using Gabor Detector
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Background subtraction; ViBe; Background model; Gabor filter bank; Ghost
   suppression; GPU parallel optimization; Boundary information; Anti-noise
AB Background subtraction is a technique in which a background model is built and compared with the current frame to distinguish the foreground from the background. The technique is extensively used to facilitate automatic detection, segmentation, and tracking of objects in videos. However, conventional background subtraction methods have disadvantages, such as slow model-updating speeds, the inability to leverage edge information, and negative anti-noise properties in conditions with illumination variations. We therefore propose a ViBe-based method that employs simplified Gabor wavelets to calculate image edge information. The method randomly applies relevant pixels to initialize or update the background model and considers the variation dispersion degree during segmentation. Experimental results indicate that the proposed method performs well in foreground-background segmentation and in color shift situations caused by illumination or aperture adjustments. Moreover, the processing speed of the proposed approach is accelerated by parallel computing capacity of graphics processing units. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Qin, Lixia; Sheng, Bin; Lin, Weiyao; Shen, Ruimin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Sheng, Bin] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Wen] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of
   Software, CAS; University of Macau
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
RI lin, yuxi/HKF-6212-2023
OI Lin, Weiyao/0000-0001-8307-7107
FU National Natural Science Foundation of China [61202154, 61272326,
   61133009, 61471235]; National Basic Research Project of China
   [2011CB302203]; National Key Technology RD Program [2012BAH55F02];
   Shanghai Pujiang Program [13PJ1404500]; University of Macau
   [MYRG2014-00139-FST, MYRG202(Y1-L4)-FST11-WEH]; Science and Technology
   Commission of Shanghai Municipality Program [13511505000];
   Interdisciplinary Program of Shanghai Jiao Tong University [14JCY10];
   State Key Lab of CAD&CG, Zhejiang University [A1401]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments. The work is supported by the
   National Natural Science Foundation of China (Nos. 61202154, 61272326,
   61133009, 61471235), the National Basic Research Project of China (No.
   2011CB302203), National Key Technology R&D Program (No. 2012BAH55F02),
   Shanghai Pujiang Program (No. 13PJ1404500), the Grant of University of
   Macau under Grant No. MYRG2014-00139-FST and MYRG202(Y1-L4)-FST11-WEH,
   the Science and Technology Commission of Shanghai Municipality Program
   (No. 13511505000), the Interdisciplinary Program of Shanghai Jiao Tong
   University (No. 14JCY10), and the Open Project Program of the State Key
   Lab of CAD&CG (No. A1401), Zhejiang University.
CR [Anonymous], 1999, P IEEE C COMPUTER VI
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Chang JY, 2002, IEEE T CONSUM ELECTR, V48, P108, DOI 10.1109/TCE.2002.1010098
   Ding F. Y. L. Z. Y., 2004, J COMPUT AID DES COM, V4, P017
   Godbehere AB, 2012, P AMER CONTR CONF, P4305
   Harville M, 2002, LECT NOTES COMPUT SC, V2352, P543
   JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907
   Javed O, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P22, DOI 10.1109/MOTION.2002.1182209
   Jiang W, 2007, 2008 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND SIGNAL PROCESSING, VOLS 1 AND 2, P586
   Jodoin PM, 2007, IEEE T CIRC SYST VID, V17, P1758, DOI 10.1109/TCSVT.2007.906935
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Li Y.H., 2010, 2010 INT C INF NETW, DOI [10.1109/ICINA.2010.5636758, DOI 10.1109/ICINA.2010.5636758]
   LU H.-Q., 2005, J IMAGE GRAPH, V7, P001
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Portz T, 2012, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2012.6247871
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 20
TC 11
Z9 11
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 1
EP 9
DI 10.1016/j.jvcir.2015.07.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300001
DA 2024-07-18
ER

PT J
AU Chou, HH
   Hsu, LY
   Hu, HT
AF Chou, Hsien-Hsin
   Hsu, Ling-Yuan
   Hu, Hwai-Tsu
TI Multi-level adaptive switching filters for highly corrupted images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive median filter; Noise detection; Impulse noise; Switching
   filter; BDND; Directional correlation; Miss-detection; False alarm
ID DISCRIMINATIVE NOISE DETECTION; MEDIAN FILTER; IMPULSE NOISE; REMOVAL;
   ALGORITHMS; DETECTOR
AB The performance of a switching filter is highly dependent on its detection accuracy. Inspired by adaptive median filter methodology, this paper proposes a multi-level adaptive switching filter (MASF) for the recovery of highly corrupted images. In particular, the adaptive technique is employed in all the detective, edge-preserving and restorative stages in order to improve noise discrimination and suppression simultaneously. Most critical design parameters in the proposed algorithm, e.g., the limit of window-expansion size and the noise range, are self-adaptive so as to retain simple implementation and high computational efficiency. Furthermore, several effective modifications on both stages of the MASF, such as the convergence factor, switching initialization and spatial adaptive weighting, are also introduced in order to provide better and more robust results. Monte-Carlo simulations show that the MASF outperforms many existing state-of-the-art algorithms in terms of both visual and quantitative results. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chou, Hsien-Hsin; Hu, Hwai-Tsu] Natl Ilan Univ, Dept Elect Engn, Yilan 26047, Taiwan.
   [Hsu, Ling-Yuan] St Marys Jr Coll Med Nursing & Management, Dept Informat Management, Yilan 26644, Taiwan.
C3 National Ilan University
RP Hsu, LY (corresponding author), 100,Ln 265,Sec 2,Sanxing Rd, Sanxing Township 266, Yilan County, Taiwan.
EM lyhsu@smc.edu.tw
OI Hsu, Ling-Yuan/0000-0002-9543-6872; Chou, Hsien-Hsin/0000-0001-7169-6752
CR Akkoul S, 2010, IEEE SIGNAL PROC LET, V17, P587, DOI 10.1109/LSP.2010.2048646
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chou HH, 2013, IEEE T CYBERNETICS, V43, P296, DOI 10.1109/TSMCB.2012.2205678
   Duan F, 2010, IEEE SIGNAL PROC LET, V17, P647, DOI 10.1109/LSP.2010.2049515
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Qiu GP, 1996, IEEE T IMAGE PROCESS, V5, P646, DOI 10.1109/83.491340
   Tripathi AK, 2011, IET IMAGE PROCESS, V5, P598, DOI 10.1049/iet-ipr.2010.0252
   Wang GH, 2010, SIGNAL PROCESS, V90, P3213, DOI 10.1016/j.sigpro.2010.05.026
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
NR 16
TC 6
Z9 7
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 363
EP 375
DI 10.1016/j.jvcir.2015.05.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900032
DA 2024-07-18
ER

PT J
AU Zhong, FJ
   Li, DF
   Zhang, JS
AF Zhong, Fujin
   Li, Defang
   Zhang, Jiashu
TI Robust locality preserving projection based on maximum correntropy
   criterion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Locality preserving projections; Outliers; Robustness; Half-quadratic
   optimization; Correntropy; Maximum correntropy criterion; Optimization;
   Dimensionality reduction
ID DIMENSIONALITY REDUCTION; MULTIVIEW; EIGENMAPS
AB Conventional local preserving projection (LPP) is sensitive to outliers because its objective function is based on the L2-norm distance criterion and suffers from the small sample size (SSS) problem. To improve the robustness of LPP against outliers, LPP-L1 uses L1-norm distance metric. However, LPP-L1 does not work ideally when there are larger outliers. We propose a more robust version of LPP, called LPP-MCC, which formulates the objective problem based on maximum correntropy criterion (MCC). The objective problem is efficiently solved via a half-quadratic optimization procedure and the complicated non-linear optimization procedure can thereby be reduced to a simple quadratic optimization at each iteration. Moreover, LPP-MCC avoids the SSS problem because the generalized eigenvalues computation is not involved in the optimization procedure. The experimental results on both synthetic and real-world databases demonstrate that the proposed method can outperform LPP and LPP-L1 when there are large outliers in the training data. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhong, Fujin; Li, Defang; Zhang, Jiashu] Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
   [Zhong, Fujin] Yibin Univ, Sch Comp & Informat Engn, Yibin 644000, Peoples R China.
C3 Southwest Jiaotong University; Yibin University
RP Zhang, JS (corresponding author), Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
EM fujin-zhong@163.com; ldf125@home.swjtu.edu.cn; jszhang@home.swjtu.edu.cn
FU National Science Foundation of P.R. China [61271341, 60971104]; Sichuan
   Basic Science & Technology Foundation [2013JY0036]
FX This work was partially supported by National Science Foundation of P.R.
   China (Grant: 61271341 and Grant 60971104), Sichuan Basic Science &
   Technology Foundation (Grant: 2013JY0036).
CR [Anonymous], 2005, ELEMENTS INFORM THEO, DOI DOI 10.1002/047174882X
   [Anonymous], 2003, P ADV NEUR INF PROC
   [Anonymous], 2002, ADV NEURAL INFORM PR
   [Anonymous], UNSUPERVISED ADAPTIV
   [Anonymous], ARXIV12073438V1STATM
   [Anonymous], 2009, 2009 INT C MANAGEMEN, DOI DOI 10.1109/ICMSS.2009.5304217
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chen X, 2010, INT J PATTERN RECOGN, V24, P1047, DOI 10.1142/S0218001410008299
   Dahyot R, 2000, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2000.855886
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Guan NY, 2011, IEEE T NEURAL NETWOR, V22, P1218, DOI 10.1109/TNN.2011.2157359
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   He R, 2010, AAAI CONF ARTIF INTE, P475
   He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   He R, 2010, NEUROCOMPUTING, V73, P1840, DOI 10.1016/j.neucom.2009.12.032
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huber P., 1981, Robust Statistics
   Jeong KH, 2009, PATTERN RECOGN, V42, P871, DOI 10.1016/j.patcog.2008.09.023
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Nikolova M, 2007, IEEE T IMAGE PROCESS, V16, P1623, DOI 10.1109/TIP.2007.896622
   Pang YW, 2010, NEUROCOMPUTING, V73, P968, DOI 10.1016/j.neucom.2009.08.020
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Pang YW, 2005, LECT NOTES COMPUT SC, V3644, P117
   Pokharel PP, 2009, SIGNAL PROCESS, V89, P1902, DOI 10.1016/j.sigpro.2009.03.027
   Qi YF, 2009, APPL MATH COMPUT, V213, P1, DOI 10.1016/j.amc.2009.03.014
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Santamaría I, 2006, IEEE T SIGNAL PROCES, V54, P2187, DOI 10.1109/TSP.2006.872524
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Yu J, 2012, PATTERN RECOGN LETT, V33, P1196, DOI 10.1016/j.patrec.2012.02.002
   Yu J, 2011, IEEE T IMAGE PROCESS, V20, P3257, DOI 10.1109/TIP.2011.2158225
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 46
TC 12
Z9 14
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1676
EP 1685
DI 10.1016/j.jvcir.2014.08.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100017
DA 2024-07-18
ER

PT J
AU Zhang, F
   Steinbach, E
   Zhang, P
AF Zhang, Fan
   Steinbach, Eckehard
   Zhang, Peng
TI MDVQM: A novel multidimensional no-reference video quality metric for
   video transcoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video quality assessment; Video transcoding; Perceived video quality
   metric; No-reference; Frame dropping; Spatial down-sampling; Quality of
   experience; Subjective video quality
ID QUANTIZATION
AB In this paper, we study the impact of quantization, frame dropping and spatial down-sampling on the perceived quality of compressed video streams. Based on the analysis of quality ratings obtained from extensive subjective tests, we propose a no-reference metric (named MDVQM) for video quality estimation in the presence of both spatial and temporal quality impairments. The proposed metric is based on the per-pixel bitrate of the encoded stream and selected spatial and temporal activity measures extracted from the video content. All the values required to compute the proposed video quality metric can be obtained without using the original reference video which makes the metric for instance useful for making transcoding decisions in a wireless video transmission scenario. Different from comparable metrics in the literature, we have also considered the case when both frame rate and frame size are changed simultaneously. The validation results show that the proposed metric provides more accurate estimation of the video quality than the state of the art metrics. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Fan; Steinbach, Eckehard] Tech Univ Munich, Inst Media Technol, D-80333 Munich, Germany.
   [Zhang, Peng] Huawei Technol Co Ltd, Beijing, Peoples R China.
C3 Technical University of Munich; Huawei Technologies
RP Zhang, F (corresponding author), Tech Univ Munich, Inst Media Technol, Arcisstr 21, D-80333 Munich, Germany.
EM fan.zhang@tum.de
OI Steinbach, Eckehard/0000-0001-8853-2703
CR [Anonymous], 2004, OBJ PERC VID QUAL ME
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 2007, METH SUBJ ASS VID QU
   [Anonymous], VAL RED REF NO REF O
   [Anonymous], 1998, P910 ITUT
   [Anonymous], 1999, METH SUBJ ASS QUAL T
   Blin J., 2006, P 2 INT WORKSH VID P
   Feghali R, 2007, IEEE T BROADCAST, V53, P441, DOI 10.1109/TBC.2007.891700
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kim CS, 2008, IEICE T COMMUN, VE91B, P1269, DOI 10.1093/ietcom/e91-b.5.1269
   Ou Y., 2011, IVMSP WORKSH ITH NY
   OU Y, 2009, P VPQM 09 SCOTTSD US
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Peng Y, 2011, IEEE IMAGE PROC
   Pinson M.H., 2008, TR09457 NITA
   Ries Michal, 2008, Journal of Communications, V3, P41, DOI 10.4304/jcm.3.1.41-50
   Sohn H, 2010, IEEE T BROADCAST, V56, P269, DOI 10.1109/TBC.2010.2050628
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   *VQEG, 2008, FIN REP VQEGS MULT P
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   Xue Y., 2010, PACK VID WORKSH HONG
   Youtube video, PRES OB 2012 AIP POL
   Youtube video, L A LAK HIGHL VS NEW
NR 23
TC 10
Z9 10
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 542
EP 554
DI 10.1016/j.jvcir.2013.11.011
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100004
DA 2024-07-18
ER

PT J
AU Wang, L
   Cheng, H
   Liu, ZC
   Zhu, C
AF Wang, Ling
   Cheng, Hong
   Liu, Zicheng
   Zhu, Ce
TI A robust elastic net approach for feature learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature learning; Principal component analysis; Elastic net; Spars
   representation; Robust statistics; Object recognition; Background
   reconstruction; Maximum likelihood estimation
ID PRINCIPAL COMPONENT ANALYSIS; FACE RECOGNITION; SPARSE PCA
AB Unsupervised feature learning has drawn more and more attention especially in visual representation in past years. Traditional feature learning approaches assume that there are few noises in training data set, and the number of samples is enough compared with the dimensions of samples. Unfortunately, these assumptions are violated in most of visual representation scenarios. In these cases, many feature learning approaches are failed to extract the important features. Toward this end, we propose a Robust Elastic Net (REN) approach to handle these problems. Our contributions are twofold. First of all, a novel feature learning approach is proposed to extract features by weighting elastic net. A distribution induced weight function is used to leverage the importance of different samples thus reducing the effects of outliers. Moreover, the REN feature learning approach can handle High Dimension, Low Sample Size (HDLSS) issues. Second, a REN classifier is proposed for object recognition, and can be used for generic visual representation including that from the REN feature extraction. By doing so, we can reduce the effect of outliers in samples. We validate the proposed REN feature learning and classifier on face recognition and background reconstruction. The experimental results showed the robustness of this proposed approach for both corrupted/occluded samples and HDLSS issues. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Ling; Cheng, Hong; Zhu, Ce] Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
   [Liu, Zicheng] Microsoft Res Redmond, Redmond, WA 98052 USA.
C3 University of Electronic Science & Technology of China; Microsoft
RP Cheng, H (corresponding author), Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu 611731, Peoples R China.
EM eewangling@uestc.edu.cn; hcheng@uestc.edu.cn; zliu@microsoft.com;
   eczhu@uestc.edu.cn
RI Zhu, Ce/AEN-1875-2022; Wang, Ling/JJD-5612-2023
FU Fundamental Research Funds for the Central Universities [ZYGX2010J016];
   National Natural Science Foundation of China (NSFC) [61075045,
   61273256]; Program for New Century Excellent Talents in University
   [NECT-10-0292]
FX This work is supported by the Grant from "the Fundamental Research Funds
   for the Central Universities" (No. ZYGX2010J016), "National Natural
   Science Foundation of China (NSFC)" (Nos. 61075045 and 61273256), "the
   Program for New Century Excellent Talents in University" (NECT-10-0292).
CR [Anonymous], 2006, P 23 INT C MACH LEAR
   [Anonymous], 2012, ECCV
   Baccini A, 1996, ST CLASS DAT ANAL, P359
   Bengio Y., 2012, 12065538 ARXIV
   Candes E., 2009, 09123599 ARXIV
   Cheng H, 2013, SIGNAL PROCESS, V93, P1408, DOI 10.1016/j.sigpro.2012.09.011
   Coates A., 2010, NIPS WORKSH DEEP LEA
   Croux C, 2013, TECHNOMETRICS, V55, P202, DOI 10.1080/00401706.2012.727746
   d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506
   Dalai N., 2005, IEEE CVPR
   De la Torre F., 2001, IEEE ICCV
   Fergus R., IEEE CVPR, V2
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hu DD, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.016101
   Jenatton R., 2010, INT C ART INT STAT A
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Ke Q., 2005, IEEE CVPR
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu C.-Y., J VISUAL COMMUNICATI, V24
   Raina R., ACM ICML
   Ranzato MA, 2007, IEEE CVPR
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Saxe A., 2011, ICML
   Shen D, 2013, J MULTIVARIATE ANAL, V115, P317, DOI 10.1016/j.jmva.2012.10.007
   Shen HP, 2008, J MULTIVARIATE ANAL, V99, P1015, DOI 10.1016/j.jmva.2007.06.007
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Wang JP, 2012, J VIS COMMUN IMAGE R, V23, P53, DOI 10.1016/j.jvcir.2011.08.002
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M., 2011, IEEE CVPR
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
   Zou H., J ROYAL STAT SOC B, V67
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 35
TC 13
Z9 18
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 313
EP 321
DI 10.1016/j.jvcir.2013.11.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300008
DA 2024-07-18
ER

PT J
AU Xie, CJ
   Tan, JQ
   Chen, P
   Zhang, J
   He, L
AF Xie, Chengjun
   Tan, Jieqing
   Chen, Peng
   Zhang, Jie
   He, Lei
TI Collaborative object tracking model with local sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Discriminative model; Generative model; Sparse
   representation; Appearance model; Collaborative model; Sparse coding
   histogram; Similarity measure
ID ROBUST VISUAL TRACKING
AB There existed many visual tracking methods that are based on sparse representation model, most of them were either generative or discriminative, which made object tracking more difficult when objects have undergone large pose change, illumination variation or partial occlusion. To address this issue, in this paper we propose a collaborative object tracking model with local sparse representation. The key idea of our method is to develop a local sparse representation-based discriminative model (SRDM) and a local sparse representation-based generative model (SRGM). In the SRDM module, the appearance of a target is modeled by local sparse codes that can be formed as training data for a linear classifier to discriminate the target from the background. In the SRGM module, the appearance of the target is represented by sparse coding histogram and a sparse coding-based similarity measure is applied to compute the distance between histograms of a target candidate and the target template. Finally, a collaborative similarity measure is proposed for measuring the difference of the two models, and then the corresponding likelihood of the target candidates is input into a particle filter framework to estimate the target state sequentially over time in visual tracking. Experiments on some publicly available benchmarks of video sequences showed that our proposed tracker is robust and effective. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Xie, Chengjun; Tan, Jieqing; He, Lei] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
   [Xie, Chengjun; Zhang, Jie] Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.
   [Chen, Peng] Anhui Univ, Inst Hlth Sci, Hefei 230601, Anhui, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Hefei
   Institutes of Physical Science, CAS; Anhui University
RP Chen, P (corresponding author), Anhui Univ, Inst Hlth Sci, Hefei 230601, Anhui, Peoples R China.
EM cjxie@iim.ac.cn; bigeagle@mail.ustc.edu.cn
RI chen, peng/HMD-1278-2023; Chen, Peng/E-4507-2011; Tan, Jie/IVV-5250-2023
OI Chen, Peng/0000-0002-5810-8159
FU NSFC-Guangdong Joint Foundation Key Project [U1135003]; National Nature
   Science Foundation of China [61070227, 61300058]
FX This work was supported by the NSFC-Guangdong Joint Foundation Key
   Project under Grant (No. U1135003), the National Nature Science
   Foundation of China (Nos. 61070227 and 61300058).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai TX, 2012, PATTERN RECOGN, V45, P2390, DOI 10.1016/j.patcog.2011.12.004
   Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884
   Cabido R., J VISUAL COMMUN IMAG, V23
   Chen F, 2011, IMAGE VISION COMPUT, V29, P787, DOI 10.1016/j.imavis.2011.08.006
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Doucet A, 2001, STAT ENG IN, P3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Han ZJ, 2011, PATTERN RECOGN, V44, P2170, DOI 10.1016/j.patcog.2011.03.002
   He S. F., 2013, COMPUT VISION PATTER
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Li GR, 2012, J VIS COMMUN IMAGE R, V23, P254, DOI 10.1016/j.jvcir.2011.11.001
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nejhum S.M. Shahed., 2008, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, P1
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y., 2013, COMPUT VISION PATTER
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 35
TC 20
Z9 22
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 423
EP 434
DI 10.1016/j.jvcir.2013.12.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300018
DA 2024-07-18
ER

PT J
AU Ho, D
   Park, Y
   Song, H
AF Ho, Donghyeok
   Park, Yongseok
   Song, Hwangjun
TI QoS-supporting video streaming system with minimum data service cost
   over heterogeneous wireless networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Heterogeneous wireless networks; Multipath system; LTE; Video streaming;
   Quality of service; Data service cost; Data transmission charges;
   Fountain code
ID CODES
AB This paper presents a video streaming system that supports quality-of-service by effectively consolidating multiple physical paths in a cost-effective way over heterogeneous wireless networks. In the proposed system, the fountain encoding symbols of compressed video data are transmitted through multiple physical paths concurrently to overcome the limitation of single path transmission and harmonize multiple physical paths with diverse characteristics effectively, and the number of transmitted packets is determined by considering the requested quality-of-service of video streaming and the data service cost. The proposed system is fully implemented in Java and C/C++, and tested over real WLAN and LTE networks. Experimental results are provided to demonstrate the performance improvement of the proposed system. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Ho, Donghyeok; Song, Hwangjun] POSTECH Pohang Univ Sci & Technol, Pohang 790784, South Korea.
   [Park, Yongseok] Samsung Elect, DMC R&D Ctr, Commun Res Team, Hwasung City, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Samsung
RP Song, H (corresponding author), POSTECH Pohang Univ Sci & Technol, Pohang 790784, South Korea.
EM hwangjun@postech.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education [NRF-2013R1A1A2006732]; Samsung
   Electronics
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2013R1A1A2006732) and Samsung Electronics.
CR [Anonymous], 26346 3GPP TS
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], 2012, NOK SIEM NETW WHIT P
   [Anonymous], 2012, Introduction to Cisco IOS NetFlow-A Technical Overview
   [Anonymous], 2012, 36913 3GPP TR
   [Anonymous], 2011, ER ANN REP
   [Anonymous], 80216MTM IEEE
   Apostolopoulos J, 2002, IEEE INFOCOM SER, P1736, DOI 10.1109/INFCOM.2002.1019427
   Astély D, 2009, IEEE COMMUN MAG, V47, P44, DOI 10.1109/MCOM.2009.4907406
   Capgemini, 2011, LTE OPP CHALL TELC
   *ETSI EN, 2004, 302304 ETSI EN
   Han S., 2011, IEEE J SELECTED AREA, V29
   Jurca D., 2006, INT PACK VID WORKSH, V7, P713
   Jurca D, 2007, IEEE T MULTIMEDIA, V9, P1227, DOI 10.1109/TMM.2007.902852
   Lee D, 2011, IEEE T MULTIMEDIA, V13, P788, DOI 10.1109/TMM.2011.2124448
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Luby M., 2007, 5053 RFC
   MacKay DJC, 2005, IEE P-COMMUN, V152, P1062, DOI 10.1049/ip-com:20050237
   Maymounkov P., 2002, TR2002833 NEW YORK U
   Nguyen-Vuong QT, 2008, COMPUT NETW, V52, P3358, DOI 10.1016/j.comnet.2008.09.002
   Ormond O., 2005, IEEE INT S PERS IND
   Ribeiro V., 2003, PASSIVE ACTIVE MEASU
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Zhang WH, 2004, IEEE WCNC, P653, DOI 10.1109/WCNC.2004.1311263
NR 24
TC 6
Z9 6
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1293
EP 1302
DI 10.1016/j.jvcir.2013.08.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700007
DA 2024-07-18
ER

PT J
AU Tang, CW
   Hu, X
   Chen, L
   Zhai, GT
   Yang, XK
AF Tang, Chongwu
   Hu, Xi
   Chen, Li
   Zhai, Guangtao
   Yang, Xiaokang
TI Sample-based image completion using structure synthesis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image completion; Inpainting; Image sample; Template matching;
   Foreground extraction; Boundary band map; Structure synthesis;
   Correlation score
AB Image completion technique is widely used in image processing applications such as textural recovery, object removal, image edit, etc. When filling in the missing areas of an image, it is often a challenge to keep local consistency of image structures while avoiding ambiguity and visual artifacts. To tackle with this problem, we propose a robust sample-based image completion scheme which is a cascade of two major procedures. First, we extract structural information from both source and sample images and then apply boundary band map (BBM) descriptor to perform template matching under contour consistency constraint and reconstruct the damaged structures. Second, a weighted exemplar-based image synthesis algorithm is further devised taking the previous structural information and matching results into account. Extensive experiments and comparative study show the reliability and superiority of our image completion algorithm. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Tang, Chongwu; Hu, Xi; Chen, Li; Zhai, Guangtao; Yang, Xiaokang] Shanghai Jiao Tong Univ, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Tang, CW (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
EM tangcw@sjtu.edu.cn; hed279@sjtu.edu.cn; hilichen@sjtu.edu.cn;
   zhaiguangtao@sjtu.edu.cn; xkyang@sjtu.edu.cn
RI Zhai, Guangtao/X-5949-2019
OI Zhai, Guangtao/0000-0001-8165-9322
FU National Nature Science Foundation of China (NSFC) [61025005, 60932006,
   61001145, 61102098]; Science and Technology Commission of Shanghai
   Municipality (STCSM [12DZ2272600]; 111 Project [B07022]
FX This work was supported by National Nature Science Foundation of China
   (NSFC) (61025005, 60932006, 61001145, 61102098), Science and Technology
   Commission of Shanghai Municipality (STCSM) (12DZ2272600), 111 Project
   (B07022).
CR Amirshahi H, 2008, IEICE T FUND ELECTR, VE91A, P2918, DOI 10.1093/ietfec/e91-a.10.2918
   [Anonymous], 2006, COMPUTER VISION PATT
   [Anonymous], 2007, P IEEE C COMP VIS PA
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Black P.E., Greedy algorithm. Dictionary of Algorithms and Data Structures
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Cheng Ming-rong, 2010, Fudan Xuebao (Yixueban), V37, P29
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Gonzalez R. C., 2008, DIGITAL IMAGE PROCES, P122
   Hays J, 2008, COMMUN ACM, V51, P87, DOI 10.1145/1400181.1400202
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Ting H., 2007, Proceedings of ACM International Conference on Multimedia, P517
   Wang H., DATABASE AS SISTED I
NR 17
TC 8
Z9 10
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1115
EP 1123
DI 10.1016/j.jvcir.2013.07.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700035
DA 2024-07-18
ER

PT J
AU Zhang, CJ
   Wang, SH
   Huang, QM
   Liang, C
   Liu, T
   Tian, Q
AF Zhang, Chunjie
   Wang, Shuhui
   Huang, Qingming
   Liang, Chao
   Liu, Ting
   Tian, Qi
TI Laplacian affine sparse coding with tilt and orientation consistency for
   image classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; Affine transformation; Sparse coding; Laplacian
   matrix; Tilt and orientation; Smooth constraints; Object categorization;
   Bag-of-visual words model
ID OBJECT RECOGNITION; FEATURES; MODEL
AB Recently, sparse coding has become popular for image classification. However, images are often captured under different conditions such as varied poses, scales and different camera parameters. This means local features may not be discriminative enough to cope with these variations. To solve this problem, affine transformation along with sparse coding is proposed. Although proven effective, the affine sparse coding has no constraints on the tilt and orientations as well as the encoding parameter consistency of the transformed local features. To solve these problems, we propose a Laplacian affine sparse coding algorithm which combines the tilt and orientations of affine local features as well as the dependency among local features. We add tilt and orientation smooth constraints into the objective function of sparse coding. Besides, a Laplacian regularization term is also used to characterize the encoding parameter similarity. Experimental results on several public datasets demonstrate the effectiveness of the proposed method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Chunjie; Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China.
   [Wang, Shuhui; Huang, Qingming] Chinese Acad Sci, Key Lab Intell Info Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Liang, Chao] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Liu, Ting] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology,
   CAS; Wuhan University; Chinese Academy of Sciences; Institute of
   Automation, CAS; University of Texas System; University of Texas at San
   Antonio (UTSA)
RP Zhang, CJ (corresponding author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China.
EM cjzhang@jdl.ac.cn; shwang@jdl.ac.cn; qmhuang@jdl.ac.cn;
   liangchao827@gmail.com; jliu@nlpr.ia.ac.cn; qitian@cs.utsa.edu
RI zhang, chunjie/Z-3035-2019; Liang, Chao/A-5929-2009; Huang,
   Qingming/GLR-3473-2022
OI zhang, chunjie/0000-0002-1161-8995; Huang, Qingming/0000-0002-3025-7099
FU National Laboratory of Pattern Recognition (NLPR) [201204268]; China
   Postdoctoral Science Foundation [2012M520434]; National Basic Research
   Program of China (973 Program) [2012CB316400]; National Natural Science
   Foundation of China [61025011, 61272329, 61202325]
FX This work is supported by the Open Project Program of the National
   Laboratory of Pattern Recognition (NLPR): 201204268, China Postdoctoral
   Science Foundation: 2012M520434, National Basic Research Program of
   China (973 Program): 2012CB316400, National Natural Science Foundation
   of China: 61025011, 61272329, 61202325.
CR [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], P COMP VIS PATT REC
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fergus R, 2005, PROC CVPR IEEE, P380
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Kulkarni N, 2011, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2011.5995701
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237
   Li L., 2007, P INT C COMP VIS RIO
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Sande K., IEEE T PATTERN ANAL, V32
   Serre T, 2005, PROC CVPR IEEE, P994
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang XG, 2011, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2011.5995696
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Xie NH, 2010, PROC CVPR IEEE, P2313, DOI 10.1109/CVPR.2010.5539917
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yao B., 2011, P INT C MACH LEARN J
   Yu GS, 2009, INT CONF ACOUST SPEE, P1597, DOI 10.1109/ICASSP.2009.4959904
   Zhang C., 2012, SIGNAL PROCESS, V93, P2111
   Zhang CJ, 2012, IEEE MULTIMEDIA, V19, P58, DOI 10.1109/MMUL.2011.20
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
NR 31
TC 8
Z9 11
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 786
EP 793
DI 10.1016/j.jvcir.2013.05.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700005
DA 2024-07-18
ER

PT J
AU Li, MD
   Chen, ZZ
   Tan, YP
AF Li, Maodong
   Chen, Zhenzhong
   Tan, Yap-Peng
TI On quality of experience of scalable video adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality of experience; QoE database; Rate adaptation; SVC; Scalability
   adaptation track; QoE model; Rate-QoE; Video streaming
ID QOE; EXTENSION
AB In this paper, we study the quality of experience (QoE) issues in scalable video coding (SVC) for its adaptation in video communications. A QoE assessment database is developed according to SVC scalabilities. Based on the subjective evaluation results, we derive the optimal scalability adaptation track for the individual video and further summarize common scalability adaptation tracks for videos according to their spatial information (SI) and temporal information (TI). Based on the summarized adaptation tracks, we conclude some general guidelines for the effective SVC video adaptation. A rate-QoE model for SVC adaptation is derived accordingly. Experimental results show that the proposed QoE-aware scalability adaptation scheme significantly outperforms the conventional adaptation schemes in terms of QoE. Moreover, the proposed QoE model reflects the rate and QoE relationship in SVC adaptation and thus, provides a useful methodology to estimate video QoE which is important for QoE-aware scalable video streaming. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Li, Maodong; Chen, Zhenzhong; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chen, ZZ (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM e080002@e.ntu.edu.sg; zzchen@ieee.org; eyptan@ntu.edu.sg
RI 陈, 震中/C-6857-2014; Chen, Zhenzhong/C-2529-2015; Tan,
   Yap-Peng/A-5158-2011
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   [Anonymous], 1994, E800 ITUR
   [Anonymous], P910 ITUR
   [Anonymous], 2007, P10G100 ITUR
   [Anonymous], 2006, P8001 ITUR
   [Anonymous], 2020, INT TELECOMMUNICATIO
   [Anonymous], 2011, JSVM SOFTW MAN VER J
   BJONTEGAARD G, 2001, VCEG M AUST US APR
   Brandt J, 2010, IEEE 14 INT S CONS E, P1
   Brooks P, 2010, IEEE NETWORK, V24, P8, DOI 10.1109/MNET.2010.5430138
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Lee DB, 2010, J VIS COMMUN IMAGE R, V21, P245, DOI 10.1016/j.jvcir.2010.01.002
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Ma Z., 2011, P IEEE MMSP OCT
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   ParandehGheibi A, 2011, IEEE J SEL AREA COMM, V29, P1064, DOI 10.1109/JSAC.2011.110516
   Peng WH, 2008, J VIS COMMUN IMAGE R, V19, P543, DOI 10.1016/j.jvcir.2008.08.002
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   STAELENS N, 2009, 1 INT WORKSH QUAL MU, P29
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Stankiewicz R, 2011, IEEE COMMUN MAG, V49, P148, DOI 10.1109/MCOM.2011.5741159
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Venkataraman M, 2011, IEEE NETWORK, V25, P4, DOI 10.1109/MNET.2011.5687947
   Volk M, 2010, IEEE COMMUN MAG, V48, P126, DOI 10.1109/MCOM.2010.5534597
   Wang Y, 2005, IEEE T CIRC SYST VID, V15, P1270, DOI 10.1109/TCSVT.2005.854224
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Zinner Thomas, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P29, DOI 10.1109/QOMEX.2010.5518277
NR 30
TC 8
Z9 8
U1 3
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 509
EP 521
DI 10.1016/j.jvcir.2013.03.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900001
DA 2024-07-18
ER

PT J
AU Sun, XS
   Yao, HX
   Ji, RR
AF Sun, Xiaoshuai
   Yao, Hongxun
   Ji, Rongrong
TI Visual attention modeling based on short-term environmental adaption
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention modeling; Saliency detection; Short-term environmental
   adaption; Adaptive sparse representation; Independent component
   analysis; Adaptive saliency measurement; Conditional self information;
   Eye fixation prediction
ID SALIENCY
AB Visual attention modeling is crucial for interpreting the structure and functionality of human vision system. A typical computational model of visual attention includes two basic elements: visual representation and saliency measurement. Most existing models left two phases unmodifiable without explicit adaption to the statistics of their corresponding visual environment. Inspired by neural adaption of biological neural systems, we proposed a novel principle for modeling visual attention mechanism named short-term environmental adaption. Given the statistics of a specified short-term visual environment, the proposed model adaptively extract sparse features and treats saliency as the features' conditional self-information, which is more accurate in saliency measurement and more sparse with respect to visual signal representation.
   We have demonstrated our superior effectiveness and robustness over state-of-the-arts by carrying out dense experiments on human eye fixation benchmarks as well as psychological patterns. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Sun, Xiaoshuai; Yao, Hongxun; Ji, Rongrong] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 W Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
EM xiaoshuaisun@hit.edu.cn; h.yao@hit.edu.cn; rrji@hit.edu.cn
FU National Science Foundation of China [61071180, 61133003]
FX The work was supported in part by the National Science Foundation of
   China No. 61071180, and Key Program Grant of National Science Foundation
   of China No. 61133003.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Hae Jong Seo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204207
   Hou X., 2006, ADV NEURAL INFORM PR, P681
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kwon M., 2009, J VISION, V9, P976
   MCLEOD P, 1984, ATTENTION PERFORM, V10, P55
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 20
TC 6
Z9 6
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 171
EP 180
DI 10.1016/j.jvcir.2012.01.014
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000010
DA 2024-07-18
ER

PT J
AU Wang, XF
   Xue, JR
   Zheng, ZQ
   Liu, ZL
   Li, N
AF Wang, Xiaofeng
   Xue, Jianru
   Zheng, Zhenqiang
   Liu, Zhenli
   Li, Ning
TI Image forensic signature for content authenticity analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Forensic signature; Robust image hash; Content authenticity analysis;
   Geometric transform estimation; Tampering detection; Tampering
   localization; Adaptive Harris corner detection; Fisher criterion
ID ROBUST
AB A novel image forensic approach for content authenticity analysis is proposed. We call it forensic signature. It is a compact and scalable representation generated by proper selecting robust features from the original image. In the proposed method, adaptive Harris corner detection algorithm is used to extract image feature points, then the statistics of feature point neighborhood are used to construct forensic signature. This forensic signature can provide evidence for analyzing the processed history of the received image at a lower computational cost, including geometric transform estimation, tampering detection and tampering localization. The characteristics of the proposed method are: (1) It provides a novel forensics analysis tool for tracing the processed history of the image. (2) It achieves a trade-off between robustness against content-preserving manipulations and sensitivity for the changes caused by malicious attacks. (3) By using Fisher criterion, it provides an adaptive method to generate the signature matching threshold value. (4) It can detect subtle changes in texture and color. Experimental results show that proposed method is robust for content-preserving manipulations such as JPEG compression, adding noise, and filtering, etc., and it is also capable to trace the processed history of the received image. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Wang, Xiaofeng; Zheng, Zhenqiang; Liu, Zhenli; Li, Ning] Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
   [Xue, Jianru] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Xi'an Jiaotong University
RP Xue, JR (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM .xfwang66@sina.com.cn; jrxue@mail.xjtu.edu.cn
RI Xue, Jianru/N-3923-2014; li, ye/GWN-2672-2022; Hu, Shaolin/N-1791-2018
FU National High Technology Development 973 Program of China
   [2012CB316400]; National Natural Science Foundation of China [61075007,
   60875008]; Natural Science Foundation of Shaanxi Province of China
   [2009JM8004-5, 11JK0900]
FX This work was supported by the National High Technology Development 973
   Program of China under Grant No. 2012CB316400; the National Natural
   Science Foundation of China under Grant No. 61075007, No. 60875008; the
   Natural Science Foundation of Shaanxi Province of China under Grant No.
   2009JM8004-5 and No. 11JK0900.
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2006, Multimedia Security Technologies for Digital Rights, chapter Passive-Blind Image Forensics
   [Anonymous], 1977, TECHNIQUES AUTOMATIC
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bhattacharjee S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P435, DOI 10.1109/ICIP.1998.723518
   Bhattacharjee SK, 1999, P SOC PHOTO-OPT INS, V3813, P732, DOI 10.1117/12.366829
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Fared Hany, 2009, IEEE SPECTR MAG, V46, P8
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Guo XC, 2007, LECT NOTES COMPUT SC, V4810, P755
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Harris C., 1988, ALVEY VISION C, P147151
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lefebvre F., 2002, P EUR SIGN PROC C, P299
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   LIN CY, 2000, THESIS COLUMBIA U
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Lou Ou-Jun, 2009, Chinese Journal of Computers, V32, P308, DOI 10.3724/SP.J.1016.2009.00308
   Lu CS, 2005, MULTIMEDIA SYST, V11, P159, DOI 10.1007/s00530-005-0199-y
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lu Wenjun., 2010, Media Forensics and Secutiry, VII, P7541
   Memon N., 2008, PART INDIAN STAT I P
   Mihcak M. K., 2001, ACM WORKSH DIG RIGHT, P13
   Monga V, 2004, IEEE IMAGE PROC, P677
   Monga V, 2006, IEEE T INF FOREN SEC, V1, P68, DOI 10.1109/TIFS.2005.863502
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang S, 2005, LECT NOTES COMPUT SC, V3481, P547
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Ye Weiguo, 2007, Journal of Southeast University (Natural Science Edition), V37, P109
   Zhao Wan-jin, 2008, Computer Engineering, V34, P212
NR 35
TC 30
Z9 37
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 782
EP 797
DI 10.1016/j.jvcir.2012.03.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400009
DA 2024-07-18
ER

PT J
AU Dogra, DP
   Majumdar, AK
   Sural, S
AF Dogra, D. P.
   Majumdar, A. K.
   Sural, S.
TI Evaluation of segmentation techniques using region area and boundary
   matching information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Segmentation evaluation; Region area; Region boundary; Matching index
ID IMAGE; COLOR
AB Evaluation techniques play an important role while picking a suitable segmentation scheme out of a number of alternatives. In this paper, a novel supervised segmentation evaluation scheme is proposed that is designed by combining segment area and boundary information. Using the evaluation metric, a ranking of the popular segmentation algorithms is carried out. A comparative analysis with existing supervised metrics that are commonly used for grading segmentation schemes is performed. Experimental results indicate that the performance of the proposed measure is promising. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Dogra, D. P.; Majumdar, A. K.] Indian Inst Technol, Dept Comp Sc & Engn, Kharagpur 721302, W Bengal, India.
   [Sural, S.] Indian Inst Technol, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Dogra, DP (corresponding author), Indian Inst Technol, Dept Comp Sc & Engn, Kharagpur 721302, W Bengal, India.
EM debiprosadcom@yahoo.com; akmj@cse.iitkgp.er-net.in;
   shamik@sit.iitkgp.ernet.in
RI Sural, Shamik/C-1394-2011; cai, bo/G-1491-2010
OI Sural, Shamik/0000-0002-4315-7329
FU Ministry of Communication and Information Technology, Department of
   Information Technology, Govt. of India [1(4)/2009-ME&TMD (28-08-2009)]
FX The work has been funded by Ministry of Communication and Information
   Technology under Approval No. 1(4)/2009-ME&TMD (28-08-2009), Department
   of Information Technology, Govt. of India.
CR [Anonymous], BERKELEY SEGMENTATIO
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   COMANICIU D, MEAN SHIFT IMAGE SEG
   Dogra DP, 2009, LECT NOTES COMPUT SC, V5909, P285, DOI 10.1007/978-3-642-11164-8_46
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FREIXENET X, 2002, P ECCV, P408
   Huang Q, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC53
   Kendall M., 1990, Correlation methods
   Kuan YH, 2008, IEEE T MULTIMEDIA, V10, P832, DOI 10.1109/TMM.2008.922853
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin D., 2002, Ph.D. Thesis
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
NR 21
TC 16
Z9 16
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 150
EP 160
DI 10.1016/j.jvcir.2011.09.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100015
DA 2024-07-18
ER

PT J
AU Zhang, L
   Zhao, X
   Ma, SW
   Wang, Q
   Gao, W
AF Zhang, Li
   Zhao, Xin
   Ma, Siwei
   Wang, Qiang
   Gao, Wen
TI Novel intra prediction via position-dependent filtering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; Image coding; Intra prediction; Interpolation filtering; Least
   square method; Mode-dependent directional transform (MDDT); KTA;
   Singular value decomposition
AB This paper presents a novel intra prediction algorithm, named position-dependent filtering (PDF), to improve the intra prediction accuracy. Different from the existing schemes where the samples along one prediction direction are predicted with the same set of filtering coefficients, in the proposed PDF, position-dependent filtering coefficients are employed, i.e., different sets of filtering coefficients are pre-defined for samples with different coordinates in one coding block. For each intra prediction mode, the set of linear filtering coefficients for each position within one block is obtained from off-line training using the least square method. Moreover, to further reduce the algorithm complexity, a simplified PDF (sPDF) is proposed. In sPDF, only a subset of reference samples are used for prediction and the others are discarded because of the minor contribution to intra prediction. The proposed algorithm has been implemented in the latest ITU-T VCEG KTA software. Experimental results demonstrate that, compared with the original KTA with new intra coding tool enabled, up to 0.53 dB of average coding gain is achieved by the proposed method, while applicable computational complexity is retained for practical video codecs. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Zhang, Li; Ma, Siwei; Gao, Wen] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
   [Zhao, Xin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Zhao, Xin] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
   [Ma, Siwei] Beijing Univ Aeronaut & Astronaut, State Key Lab Virtual Real Technol & Syst, Beijing 100083, Peoples R China.
   [Wang, Qiang] State Adm Radio Film & Televis, Acad Broadcasting Sci, Beijing, Peoples R China.
C3 Peking University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; Beihang University
RP Zhang, L (corresponding author), Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
EM li.zhang@pku.edu.cn
OI MA, Siwei/0000-0002-2731-5403
FU National Natural Science Foundation of China [60833013, 60803068];
   National Basic Research Program of China (973 Program) [2009CB320903]
FX The work was supported in part by National Natural Science Foundation
   Research Program of China under Grant (Nos. 60833013, 60803068) and
   National Basic Research Program of China (973 Program. 2009CB320903).
   The authors would like to thank Dr. Shawmin Lei for providing some good
   suggestions.
CR [Anonymous], 2009, JM110KTA26
   [Anonymous], JVTC151
   [Anonymous], 2001, ITU T VCEG M AUST TE
   Bjontegaard G., 1997, Q15C23 ITUT
   Conklin G., 2001, VCEGN54 ITUT
   Guo Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1117, DOI 10.1109/ICME.2008.4607635
   ITU-T, 1995, INF TECHN GEN COD MO
   Liu L., 2010, JCTVCA022 ITUT ISOIE
   Liu L., 2007, PCS NOV
   McCann K., 2010, JCTVCA124 ITUT ISOIE
   NETRAVALI AN, 1980, P IEEE, V68, P366, DOI 10.1109/PROC.1980.11647
   ONEAL JB, 1977, IEEE T INFORM THEORY, V23, P697, DOI 10.1109/TIT.1977.1055796
   Taichiro S., 2007, VCEGAG08 ITUT
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Tan TK, 2007, CONSUM COMM NETWORK, P405, DOI 10.1109/CCNC.2007.86
   Ugur K., 2010, JCTVCA119 ITUT ISOIE
   Wang D., 2001, VCEGL09 ITUT
   Wang LP, 2009, IEEE INT CON MULTI, P165, DOI 10.1109/ICME.2009.5202462
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Ye Y, 2008, IEEE IMAGE PROC, P2116, DOI 10.1109/ICIP.2008.4712205
   Yu SS, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1477, DOI 10.1109/ICALIP.2008.4590060
   Zhang YB, 2010, INT CONF ACOUST SPEE, P898, DOI 10.1109/ICASSP.2010.5495264
   Zheng YF, 2008, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2008.4711707
NR 24
TC 11
Z9 14
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 687
EP 696
DI 10.1016/j.jvcir.2010.11.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200001
DA 2024-07-18
ER

PT J
AU Hong, WE
   Chen, TS
AF Hong, Wien
   Chen, Tung-Shou
TI Reversible data embedding for high quality images using interpolation
   and reference pixel distribution mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Histogram-shifting; Image interpolation;
   Reference pixel; Steganography; Interpolation error; Expansion
   embedding; Embedding capacity
ID HISTOGRAM-MODIFICATION; EXPANSION
AB This paper proposes a reversible data hiding method based on image interpolation and the detection of smooth and complex regions in the cover images. A binary image that represents the locations of reference pixels is constructed according the local image activity. In complex regions, more reference pixels are chosen and, thus, fewer pixels are used for embedding, which reduces the image degradation. On the other hand, in smooth regions, less reference pixels are chosen, which increases the embedding capacity without introducing significant distortion. Pixels are interpolated according to the constructed binary image, and the interpolation errors are then used to embed data through histogram shifting. The pixel values in the cover image are modified one grayscale unit at most to ensure that a high quality stego image can be produced. The experimental results show that the proposed method provides better image quality and embedding capacity compared with prior works. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Hong, Wien] Yu Da Univ, Dept Informat Management, Miaoli 361, Taiwan.
   [Chen, Tung-Shou] Natl Taichung Inst Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
RP Hong, WE (corresponding author), Yu Da Univ, Dept Informat Management, Miaoli 361, Taiwan.
EM wienhong@ydu.edu.tw; tschen@ntit.edu.tw
FU National Science Council of the Republic of China
   [NSC99-2622-E-412-006-CC3]
FX This research was supported by the National Science Council of the
   Republic of China under the Grant No. NSC99-2622-E-412-006-CC3.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], IMAGE DATABASE
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Guo JM, 2007, INT J IMAG SYST TECH, V17, P328, DOI 10.1002/ima.20128
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Rossi L, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/382310
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 23
TC 89
Z9 95
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 131
EP 140
DI 10.1016/j.jvcir.2010.11.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600003
DA 2024-07-18
ER

PT J
AU Maitre, M
   Do, MN
AF Maitre, Matthieu
   Do, Minh N.
TI Depth and depth-color coding using shape-adaptive wavelets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-TV; Free-viewpoint video; Depth map; Depth image; Shape-adaptive
   wavelet transform; Lifting; Boundary wavelets; Edge coding;
   Rate-distortion optimization
ID COMPRESSION; ALGORITHMS
AB We present a novel depth and depth-color codec aimed at free-viewpoint 3D-TV. The proposed codec uses a shape-adaptive wavelet transform and an explicit encoding of the locations of major depth edges. Unlike the standard wavelet transform, the shape-adaptive transform generates small wavelet coefficients along depth edges, which greatly reduces the bits required to represent the data. The wavelet transform is implemented by shape-adaptive lifting, which enables fast computations and perfect reconstruction. We derive a simple extension of typical boundary extrapolation methods for lifting schemes to obtain as many vanishing moments near boundaries as away from them. We also develop a novel rate-constrained edge detection algorithm, which integrates the idea of significance bitplanes into the Canny edge detector. Together with a simple chain code, it provides an efficient way to extract and encode edges. Experimental results on synthetic and real data confirm the effectiveness of the proposed codec, with PSNR gains of more than 5 dB for depth images and significantly better visual quality for synthesized novel view images. Published by Elsevier Inc.
C1 [Do, Minh N.] Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, Urbana, IL 61801 USA.
   [Do, Minh N.] Univ Illinois, Beckman Inst, Urbana, IL 61801 USA.
   [Maitre, Matthieu] Microsoft Corp, Windows Experience Grp, Redmond, WA 98052 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   University of Illinois System; University of Illinois Urbana-Champaign;
   Microsoft
RP Do, MN (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, 1406 W Green St, Urbana, IL 61801 USA.
EM mmaitre@microsoft.com; minhdo@uiuc.edu
RI Do, Minh N./AAX-8498-2020
OI Do, Minh N./0000-0001-5132-4986
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   [Anonymous], P SIGGRAPH
   [Anonymous], P EUR STAT OF THE AR
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cohen A, 1994, J APPL COMPUT HARMON, V1, P54, DOI DOI 10.1006/ACHA.1993.1005
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dragotti PL, 2003, IEEE T SIGNAL PROCES, V51, P1306, DOI 10.1109/TSP.2003.810296
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Fowler JE, 2000, P SOC PHOTO-OPT INS, V4115, P294, DOI 10.1117/12.411554
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Li SP, 2000, IEEE T CIRC SYST VID, V10, P725, DOI 10.1109/76.856450
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   MAITRE M, 2008, P ICIP
   MAITRE M, 2009, P PICT COD S
   Maitre M, 2008, IEEE T IMAGE PROCESS, V17, P946, DOI 10.1109/TIP.2008.922425
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MORVAN Y, 2007, P ICIP
   Nguyen HT, 2009, IEEE T IMAGE PROCESS, V18, P703, DOI 10.1109/TIP.2009.2012884
   PEYRE G, 2005, P SIGGRAPH, P601
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shukla R, 2005, IEEE T IMAGE PROCESS, V14, P343, DOI 10.1109/TIP.2004.840710
   Shum H., 2007, IMAGE BASED RENDERIN
   Smolic A, 2005, P IEEE, V93, P98, DOI 10.1109/JPROC.2004.839608
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Taubman D., 2012, JPEG2000: image compression fundamentals, standards and practice, V642
   Vetterli M, 2001, IEEE SIGNAL PROC MAG, V18, P59, DOI 10.1109/79.952805
   Wakin MB, 2006, IEEE T IMAGE PROCESS, V15, P1071, DOI 10.1109/TIP.2005.864175
   Willett RM, 2003, IEEE T MED IMAGING, V22, P332, DOI 10.1109/TMI.2003.809622
NR 29
TC 27
Z9 33
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 513
EP 522
DI 10.1016/j.jvcir.2010.03.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Han, B
   Wu, F
   Wu, DP
AF Han, Bing
   Wu, Feng
   Wu, Dapeng
TI Image representation by compressive sensing for visual sensor networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; Compressive sensing; Random sampling; Projection
   onto convex sets; Convex optimization; Image decomposition;
   Interpolation; Image reconstruction
ID RECONSTRUCTION; NEIGHBORLINESS; PROJECTIONS; POLYTOPES; DIMENSION
AB This paper addresses the image representation problem in visual sensor networks. We propose a new image representation method for visual sensor networks based on compressive sensing (CS). CS is a new sampling method for sparse signals, which is able to compress the input data in the sampling process. Combining both signal sampling and data compression, CS is more capable of image representation for reducing the computation complexity in image/video encoder in visual sensor networks where computation resource is extremely limited. Since CS is more efficient for sparse signals, in our scheme, the input image is firstly decomposed into two components, i.e., dense and sparse components; then the dense component is encoded by the traditional approach OPEC or JPEG 2000) while the sparse component is encoded by a CS technique. In order to improve the rate distortion performance, we leverage the strong correlation between dense and sparse components by using a piecewise autoregressive model to construct a prediction of the sparse component from the corresponding dense component. Given the measurements and the prediction of the sparse component as initial guess, we use projection onto convex set (POCS) to reconstruct the sparse component. Our method considerably reduces the number of random measurements needed for CS reconstruction and the decoding computational complexity, compared to the existing CS methods. In addition, our experimental results show that our method may achieves up to 2 dB gain in PSNR over the existing CS based schemes, for the same number of measurements. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Han, Bing; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
   [Han, Bing; Wu, Feng] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 State University System of Florida; University of Florida; Microsoft;
   Microsoft Research Asia
RP Han, B (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM binghan@ufl.edu; wu@ece.ufl.edu
RI Wu, Feng/KCY-3017-2024
OI Wu, Dapeng/0000-0003-1755-0183
CR [Anonymous], P COMP IM 5 SPIE EL
   [Anonymous], P INT C DIG SIGN PRO
   [Anonymous], INT C INF PROC SENS
   [Anonymous], 200618 STANF U DEP S
   [Anonymous], 2006, P COMP IM 4 SPIE EL
   [Anonymous], P 44 ANN ALL C COMM
   BARANIUK R, 2007, RANDOM PROJECTIONS S
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   BLUMENSATH T, 2007, GRADIENT PURSU UNPUB
   BLUMENSATH T, J FOURIER A IN PRESS
   Bregman L. M., 1965, SOV MATH DOKL, V6, P688
   CANDES E, 2004, WAVELET APPL SIGNAL, V11, P5914
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Cohen A, 2009, J AM MATH SOC, V22, P211
   Donoho DL, 2009, J AM MATH SOC, V22, P1
   Donoho DL, 2006, DISCRETE COMPUT GEOM, V35, P617, DOI 10.1007/s00454-005-1220-0
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9452, DOI 10.1073/pnas.0502258102
   DUARTE M, 2005, P SPARS WORKSH NOV
   Duarte M. F., 2006, P IEEE INT C AC SPEE
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Elad M, 2007, IEEE T SIGNAL PROCES, V55, P5695, DOI 10.1109/TSP.2007.900760
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gilbert AC, 2007, ACM S THEORY COMPUT, P237, DOI 10.1145/1250790.1250824
   JERRI AJ, 1977, P IEEE, V65, P1565, DOI 10.1109/PROC.1977.10771
   Jung H, 2007, PHYS MED BIOL, V52, P3201, DOI 10.1088/0031-9155/52/11/018
   Kim S., 2007, METHOD LARGE S UNPUB
   Kirolos S., 2006, P IEEE DALL CIRC SYS
   LA C, 2005, P SPIE WAVELETS, V11
   Laska J., 2007, P IEEE INT S CIRC SY
   LASKA J, 2006, P IEEE DALL CIRC SYS
   Lustig M., 2006, P 14 ANN M ISMRM SEA
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MUTHUKRISHNAN S, 2006, 44 ANN ALL C SEPT 20
   Peyré G, 2007, LECT NOTES COMPUT SC, V4485, P80
   RABBAT M, 2006, P INT C INF PROC SEN
   RAGHEB T, 2007, 50 IEEE INT MIDW S C
   Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190
   Sarvotham S., 2006, P ALL C COMM CONTR C
   SARVOTHAM S, 2006, P IEEE INT S INF THE
   Sheikh Mona, 2007, 0706 TREE RIC ECE DE
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   TROPP J, 2005, SIGNAL RECOVER UNPUB
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   WAINWRIGHT M, 2007, P IEEE INT S INF THE
   Wakin M., 2006, P INT C IM PROC ATL
   WANG W, 2007, P INT C INF PROC SEN
   Ye JC, 2007, IEEE SIGNAL PROC LET, V14, P750, DOI 10.1109/LSP.2007.898342
   Yeh A., 2006, P AS C SIGN SYST COM
   ZHANG X, 2007, DAT COMPR C, P193
NR 54
TC 33
Z9 41
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 325
EP 333
DI 10.1016/j.jvcir.2010.02.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800005
DA 2024-07-18
ER

PT J
AU Wang, Y
   Chau, LP
   Yap, KH
AF Wang, Yu
   Chau, Lap-Pui
   Yap, Kim-Hui
TI Adaptive resynchronization approach for scalable video over wireless
   channel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; H.264/SVC; Hierarchical B pictures; FGS; Error control;
   Error-resilience; Resynchronization; Hill-climbing method
ID ERROR-PRONE NETWORKS; TRANSMISSION
AB Scalable video coding technique is developed to provide a full scalability including temporal, spatial and quality scalability. The compressed bitstream can be separated into base layer and enhancement layers, where the base layer is usually small and of high importance. Error-free transmission could be realized for the base layer through high-priority protection. Therefore, the overall quality greatly depends on the enhancement layers. In this paper, we propose an adaptive resynchronization method to achieve a robust transmission of the enhancement layer information. The scheme firstly groups the enhancement layer bitstream of a group of pictures (GOPs) into a set of units with different temporal levels and quality levels. We measure the importance of each unit and organize them into hierarchical units from the most important unit to the least important one. The overall distortion is formulated and a local hill-climbing algorithm is designed to optimally insert different amount of resynchronization markers to different unit considering the time-varying channel conditions and the significance of each unit. It is shown from experimental results that the proposed method can perform a graceful degradation under a variety of error conditions and shows advantages over conventional method. The improvement is up to 1 dB. We also conduct the experiments to demonstrate that the resynchronization method can also be employed together with other error resilient methods to further improve the quality of the decoded video. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Wang, Yu; Chau, Lap-Pui; Yap, Kim-Hui] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chau, LP (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Block S2,50 Nanyang Ave, Singapore 639798, Singapore.
EM YWang@pmail.ntu.edu.sg; ELPChau@ntu.edu.sg
RI Chau, Lap-Pui/A-5149-2011; Yap, Kim-Hui/A-5157-2011
OI Chau, Lap-Pui/0000-0003-4932-0593; Yap, Kim-Hui/0000-0003-1933-4986
CR [Anonymous], NETWORK SIMULATOR 2
   [Anonymous], JTC1SC29WG11N2502 IS
   BARBOSA LO, 2000, IEEE T BROADCAST, V46, P134
   Côté G, 2000, IEEE J SEL AREA COMM, V18, P952, DOI 10.1109/49.848249
   Fang T, 2005, IEEE T MULTIMEDIA, V7, P1021, DOI 10.1109/TMM.2005.858378
   Harmanci O, 2007, IEEE T IMAGE PROCESS, V16, P684, DOI 10.1109/TIP.2006.891047
   *ITU T, 1998, H263 ITUT
   Lee SH, 2001, ELECTRON LETT, V37, P348, DOI 10.1049/el:20010255
   Lee TWA, 2002, IEEE T CIRC SYST VID, V12, P1059, DOI 10.1109/TCSVT.2002.806816
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   *MPEG COMM, 2007, JTC1SC29WG11W8752 IS
   REICHEL J, 2007, JTC1SC29WG11N8751 IS
   Sklar B, 1997, IEEE COMMUN MAG, V35, P136, DOI 10.1109/35.620535
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   YAN R, 2000, IEEE PAC RIM C MULT
   Yoo KY, 1998, ELECTRON LETT, V34, P2084, DOI 10.1049/el:19981458
NR 16
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 210
EP 218
DI 10.1016/j.jvcir.2009.12.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400003
DA 2024-07-18
ER

PT J
AU Bao, FX
   Sun, QH
   Duan, Q
AF Bao, Fangxun
   Sun, Qinghua
   Duan, Qi
TI Point control of the interpolating curve with a rational cubic spline
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rational spline; Value control; Convexity control; Error estimate; Cubic
   interpolation; Curve design; Local shape control; Inflection point
   control
ID FUNCTION VALUES
AB A rational cubic spline, a kind of smoothness interpolation with quadratic denominator, is constructed using the values of a function only. In order to meet the needs of practical design, an interpolation technique is employed to control the shape of curves. The method of value control, inflection-point control and convexity control of the interpolation at a point is also developed. The advantage of this new control method is that it can be applied to modify the local shape of an interpolating curve by selecting suitable parameters simply. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Bao, Fangxun; Sun, Qinghua; Duan, Qi] Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
C3 Shandong University
RP Duan, Q (corresponding author), Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
EM duanqi@sdu.edu.cn
FU National Nature Science Foundation of China [10771125]; Nature Science
   Foundation of the Shandong Province of China [Y2007A20]
FX The support of the National Nature Science Foundation of China (No.
   10771125) and the Nature Science Foundation of the Shandong Province of
   China (No. Y2007A20) are gratefully acknowledged.
CR BRODLIE KW, 1991, COMPUT GRAPH, V15, P15, DOI 10.1016/0097-8493(91)90026-E
   Dierckx P., 1989, Computer-Aided Geometric Design, V6, P279, DOI 10.1016/0167-8396(89)90029-0
   Duan Q, 2000, J COMPUT APPL MATH, V117, P121, DOI 10.1016/S0377-0427(99)00336-2
   Duan Q, 1998, COMPUT GRAPH, V22, P479, DOI 10.1016/S0097-8493(98)00046-6
   Duan Q, 2005, APPL MATH COMPUT, V161, P311, DOI 10.1016/j.amc.2003.12.030
   Duan Q, 1999, INT J COMPUT MATH, V72, P155, DOI 10.1080/00207169908804842
   Duan Q, 2003, COMMUN NUMER METH EN, V19, P833, DOI 10.1002/cnm.634
   Duan Q, 2007, J COMPUT APPL MATH, V200, P1, DOI 10.1016/j.cam.2005.12.007
   Foley T. A., 1986, Computer-Aided Geometric Design, V3, P281, DOI 10.1016/0167-8396(86)90004-X
   FRITSCH FN, 1984, SIAM J SCI STAT COMP, V5, P303
   GOODMAN TNT, 1988, SIAM J NUMER ANAL, V25, P1
   GREGORY JA, 1986, COMPUT AIDED DESIGN, V18, P53, DOI 10.1016/S0010-4485(86)80012-4
   GREGORY JA, 1994, COMPUT GRAPH, V18, P153, DOI 10.1016/0097-8493(94)90089-2
   LAHTINEN A, 1992, J COMPUT APPL MATH, V39, P109, DOI 10.1016/0377-0427(92)90227-O
   Sarfraz M, 2006, J COMPUT APPL MATH, V189, P513, DOI 10.1016/j.cam.2005.04.039
   Sarfraz M., 1994, ANN U SCI BUDAP, V37, P53
   Sarfraz M., 1992, B KOREAN MATH SOC, V29, P193
   Schultz M.H., 1973, Spline Analysis
   SCHUMAKER LL, 1983, SIAM J NUMER ANAL, V20, P854, DOI 10.1137/0720057
NR 19
TC 15
Z9 21
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2009
VL 20
IS 4
BP 275
EP 280
DI 10.1016/j.jvcir.2009.03.003
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 447EV
UT WOS:000266175300004
DA 2024-07-18
ER

PT J
AU Chattopadhyay, S
   Bhandarkar, SM
AF Chattopadhyay, Siddhartha
   Bhandarkar, Suchendra M.
TI Hybrid layered video encoding and caching for resource constrained
   environments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Layered video encoding; Layered video caching; Generative video;
   Generative sketch-based video; Layered video; Power adaptive video;
   Content based video encoding
ID SEGMENTATION
AB Video playback on a mobile device is a resource-intensive task. Since the battery life of a mobile device decreases with time, it is desirable to have a video representation which adapts dynamically to the available battery life during the playback process. A novel Hybrid Layered Video (HLV) encoding scheme is proposed, which comprises of content-aware, multi-layer encoding of texture and a generative sketch-based representation of the object outlines. Different combinations of the texture- and sketch-based representations are shown to result in distinct video states, each with a characteristic power consumption profile. Further, a smart content-aware caching scheme is proposed which is suitable for low-latency dissemination of HLV over the Internet. The proposed HLV representation, combined with the proposed caching scheme, is shown to be effective for video playback and dissemination on power-constrained mobile devices. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Chattopadhyay, Siddhartha] Google Inc, Mountain View, CA 94043 USA.
   [Bhandarkar, Suchendra M.] Univ Georgia, Dept Comp Sci, Athens, GA 30602 USA.
C3 Google Incorporated; University System of Georgia; University of Georgia
RP Chattopadhyay, S (corresponding author), Google Inc, Mountain View, CA 94043 USA.
EM siddhartha2k5@gmail.com; suchi@cs.uga.edu
CR [Anonymous], 2007, Computer Architecture: A Quantitative Approach
   ATALLAH MJ, 1983, INFORM PROCESS LETT, V17, P207, DOI 10.1016/0020-0190(83)90042-X
   BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881
   Bouguet J.Y, Pyramidal Implementation of the Lucas Kanade Feature Tracker -Description of the Algorithm
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHATTOPADHYAY S, 2007, P 15 ACM INT C MULT, P24
   CHATTOPADHYAY S, 2007, P ACM MULT COMP NETW
   CHATTOPADHYAY S, 2006, P ACM INT WORKSH NET
   Cherkasova L.., 1998, Improving WWW Proxies Performance With Greedy- Dual-Size-Frequency Caching Policy
   Cheung S.C., 2005, EURASIP J APPL SIG P, V14, P1
   Choi K, 2003, DES AUT CON, P912, DOI 10.1109/DAC.2003.1219150
   Cornea R, 2006, DES AUT TEST EUROPE, P682
   CUCCHIARA R, 2003, P 1 ACM SIGMM INT WO
   DAI M, 2005, P IEEE INFOCOM
   DAVIES E, 1990, MACHINE VISION THEOR, P42
   GEUSEBROEK JM, 2001, IEEE T CIRCUITS SYST, V11
   HAKEEM A, 2005, P 13 ANN ACM INT C M, P608
   *ISO IEC, 2000, 144962FPDAM4 ISOIEC
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   Javed O, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P22, DOI 10.1109/MOTION.2002.1182209
   JIN S, 2000, P 20 INT C DISTR COM, P254
   Khan S, 2001, PROC CVPR IEEE, P746
   KU CW, 1995, P SPIE C VIS COMM IM, V3, P1318
   LI W, 2001, IEEE T CIRCUITS SYST, V11
   LIANG C, 2006, P CONS COMM NETW C C, V3, P833
   LUO X, 2005, P INT C IM AN REC TO, P1226
   LUO X, 2006, P IEEE INT C ADV VID, P13
   Luo XZ, 2007, LECT NOTES COMPUT SC, V4358, P203
   Mohapatra Shivajit., 2003, P 11 ANN ACM INT C M, P582
   NI P, 2006, P 14 ACM INT C MULT
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507
   Salembier P, 1997, IEEE T CIRC SYST VID, V7, P60, DOI 10.1109/76.554418
   Salomon D., 2004, Data Compression: the Complete Reference, V4th ed.
   Sikora T, 2005, P IEEE, V93, P6, DOI 10.1109/JPROC.2004.839601
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
NR 37
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 573
EP 588
DI 10.1016/j.jvcir.2008.09.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300010
DA 2024-07-18
ER

PT J
AU Zribi, M
AF Zribi, Mourad
TI Unsupervised Bayesian image segmentation using orthogonal series
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE unsupervised Bayesian image segmentation; orthogonal series estimator;
   Stochastic and Nonparametric Expectation-Maximization
ID MAXIMUM-LIKELIHOOD; DENSITY; MIXTURE; MODEL
AB This paper deals with the problem of unsupervised image segmentation which consists in first mixture identification phase and second a Bayesian decision phase. During the mixture identification phase, the conditional probability density function (pdf) and the a priori class probabilities must be estimated. The most difficult part is the estimation of the number of pixel classes or in other words the estimation of the number of density mixture components. To resolve this problem, we propose here a Stochastic and Nonparametric Expectation-Maximization (SNEM) algorithm. The algorithm finds the most likely number of classes, their associated model parameters and generates a segmentation of the image by classifying the pixels into these classes. The non-parametric aspect comes from the use of the orthogonal series estimator. Experimental results are promising, we have obtained accurate results on a variety of real images. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Zribi, Mourad] Univ Littoral Cote dOpale, Maison La Rech Blaise Pascal, Lab Anal Syst Littoral, F-62228 Calais, France.
C3 Universite du Littoral-Cote-d'Opale
RP Zribi, M (corresponding author), Univ Littoral Cote dOpale, Maison La Rech Blaise Pascal, Lab Anal Syst Littoral, 50 Rue Ferdinand Buisson,BP 699, F-62228 Calais, France.
EM Mourad.Zribi@lasl.univ-littoral.fr
CR ASSELIN JP, 1978, CRAS A T, V286
   Bergasa LM, 2000, IMAGE VISION COMPUT, V18, P987, DOI 10.1016/S0262-8856(00)00042-1
   BRAATHEN B, 1993, MACHINE GRAPHICS VIS, V2, P39
   Caillol H, 1997, IEEE T IMAGE PROCESS, V6, P425, DOI 10.1109/83.557353
   Celeux G., 1985, Computational Statistics Quarterly, V2, P73
   Cencov N., 1962, Doklady, V3, P1559
   CRAIN BR, 1974, ANN STAT, V2, P454, DOI 10.1214/aos/1176342706
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng HW, 2004, PATTERN RECOGN, V37, P2323, DOI [10.1016/S0031-3203(04)00195-5, 10.1016/j.patcog.2004.04.015]
   DIGGLE PJ, 1986, J AM STAT ASSOC, V81, P230, DOI 10.2307/2287995
   Gehringer K, 1990, THESIS U TULSA
   Guo GD, 2000, PATTERN RECOGN LETT, V21, P107, DOI 10.1016/S0167-8655(99)00137-3
   HALL P, 1987, J MULTIVARIATE ANAL, V21, P189, DOI 10.1016/0047-259X(87)90001-7
   HALL P, 1982, J MULTIVARIATE ANAL, V12, P432, DOI 10.1016/0047-259X(82)90076-8
   HALLUM CR, 1972, 640TR114 HOUST AER S
   HART JD, 1985, J STAT COMPUT SIM, V21, P95, DOI 10.1080/00949658508810808
   Jain A. K., 1996, Advances in Image Understanding: A Festschrift for Azriel Rosenfeld, P65
   KRONMAL R, 1968, J AM STAT ASSOC, V63, P925, DOI 10.2307/2283885
   LOCK MD, 1990, THESIS U CALIFORNIA
   Luenberger D. G., 1997, Optimization by Vector Space Methods
   MASSON P, 1993, IEEE T GEOSCI REMOTE, V31, P618, DOI 10.1109/36.225529
   Peng A, 1995, GRAPH MODEL IM PROC, V57, P389, DOI 10.1006/gmip.1995.1033
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   REDNER RA, 2000, COMMUNICATION
   Scott DW, 2015, WILEY SER PROBAB ST, P1
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   ZHANG J, 1994, IEEE T IMAGE PROCESS, V3, P404, DOI 10.1109/83.298395
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
   Zribi M, 2003, PATTERN RECOGN LETT, V24, P97, DOI 10.1016/S0167-8655(02)00193-9
NR 29
TC 7
Z9 12
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2007
VL 18
IS 6
BP 496
EP 503
DI 10.1016/j.jvcir.2007.05.001
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 243NA
UT WOS:000251803400004
DA 2024-07-18
ER

PT J
AU Li, F
   Shen, CM
   Fan, JS
   Shen, CL
AF Li, Fang
   Shen, Chaomin
   Fan, Jingsong
   Shen, Chunli
TI Image restoration combining a total variational filter and a
   fourth-order filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image restoration; total variation; fourth-order filter; BV space; BV2
   space
ID TOTAL VARIATION MINIMIZATION; NOISE REMOVAL; EQUATIONS; SPACE
AB In this paper, a noise removal algorithm based on variational method and partial differential equations (PDEs) is proposed. It combines a total variational filter (ROF filter) with a fourth-order PDE filter (LLT filter). The combined algorithm takes the advantage of both filters since it is able to preserve edges while avoiding the staircase effect in smooth regions. The existence and uniqueness of a solution to the minimization problem is established. Experimental results illustrate the effectiveness of the model in image restoration. (c) 2007 Elsevier Inc. All rights reserved.
C1 E China Normal Univ, Dept Math, Shanghai 200062, Peoples R China.
   E China Normal Univ, Joint Lab Imaging Sci & Technol, Shanghai 200062, Peoples R China.
   E China Normal Univ, Dept Comp Sci, Shanghai 200062, Peoples R China.
C3 East China Normal University; East China Normal University; East China
   Normal University
RP Li, F (corresponding author), E China Normal Univ, Dept Math, Shanghai 200062, Peoples R China.
EM lifangswnu@126.com
RI Li, Chun/KBC-9591-2024
CR ACAR R, 1994, INVERSE PROBL, V10, P1217, DOI 10.1088/0266-5611/10/6/003
   BLOMGREN P, 1997, P IEEE INT C IM PROC, V3, P384
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chen Y, 2002, J MATH ANAL APPL, V272, P117, DOI 10.1016/S0022-247X(02)00141-5
   Chen YM, 2003, SIAM J MATH ANAL, V34, P1084, DOI 10.1137/S0036141002404577
   Didas S, 2005, LECT NOTES COMPUT SC, V3663, P451
   Didas S., 2005, LECT NOTES COMPUTER, V3459
   Evans L. C., 1992, MEASURE THEORY PROPE
   GIUSTI F, 1984, MINIMAL SURFACES FUN, V80
   Greer JB, 2004, SIAM J MATH ANAL, V36, P38, DOI 10.1137/S0036141003427373
   Greer JB, 2004, DISCRETE CONT DYN-A, V10, P349
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Nikolova M, 2004, J MATH IMAGING VIS, V21, P155, DOI 10.1023/B:JMIV.0000035180.40477.bd
   OBEREDER A, 0435 UCLA
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Osher S., 2004, Comm. Math. Sci, V2, P237
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
NR 21
TC 166
Z9 185
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2007
VL 18
IS 4
BP 322
EP 330
DI 10.1016/j.jvcir.2007.04.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 200NU
UT WOS:000248770900003
DA 2024-07-18
ER

PT J
AU Liu, Z
   Lu, Y
   Zhang, ZY
AF Liu, Zhi
   Lu, Yu
   Zhang, Zhaoyang
TI Real-time spatiotemporal segmentation of video objects in the H.264
   compressed domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE compressed domain segmentation; video object segmentation; H.264;
   real-time segmentation; spatiotemporal segmentation
ID MOVING-OBJECTS; EXTRACTION; RETRIEVAL; SEQUENCES; TRACKING
AB This paper presents a real-time spatiotemporal segmentation approach to extract video objects in the H.264 compressed domain. The only exploited segmentation cue is the motion vector (MV) field extracted from the H.264 compressed video. MV field is first temporally and spatially normalized and then accumulated by an iteratively backward projection scheme to enhance the salient motion. Then global motion compensation is performed on the accumulated MV field, which is also moderately segmented into different motion -homogenous regions by a modified statistical region growing algorithm. The hypothesis testing using the block residuals of global motion compensation is employed for intra-frame classification of segmented regions, and the projection is exploited for inter-frame tracking of previous video objects. Using the above results of intra-frame classification and inter-frame tracking as input, a correspondence matrix based spatiotemporal segmentation approach is proposed to segment video objects under different situations including appearing and disappearing objects, splitting and merging objects, stopping moving objects, multiple object tracking and scene change in a unified and efficient way. Experimental results for several H.264 compressed video sequences demonstrate the real-time performance and good segmentation quality of the proposed approach. (c) 2007 Elsevier Inc. All rights reserved.
C1 Shanghai Univ, Sch Communn & Informat Engn, Shanghai 200072, Peoples R China.
   Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
C3 Shanghai University; Brunel University
RP Liu, Z (corresponding author), Shanghai Univ, Sch Communn & Informat Engn, Shanghai 200072, Peoples R China.
EM liuzhisjtu@163.com
RI LIU, Zhi/D-4518-2012; Zhang, Zhaoyang/AFQ-9161-2022; Lu,
   Kevin/E-7290-2011
OI LIU, Zhi/0000-0002-8428-1131; 
CR Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   CREUSERE CD, 2001, P AS C SIGN SYST COM, V1, P93
   Eng HL, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1531, DOI 10.1109/ICME.2000.871059
   Favalli L, 2000, IEEE T CIRC SYST VID, V10, P427, DOI 10.1109/76.836288
   Jamrozik ML, 2002, IEEE IMAGE PROC, P113
   Kim M, 2001, IMAGE VISION COMPUT, V19, P245, DOI 10.1016/S0262-8856(00)00074-3
   Kuo CM, 2005, J VIS COMMUN IMAGE R, V16, P68, DOI 10.1016/j.jvcir.2004.01.004
   Liu Z, 2005, PATTERN RECOGN LETT, V26, P653, DOI 10.1016/j.patrec.2004.09.017
   LIU Z, 2006, P 7 INT WORKSH IM AN, P333
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P1190, DOI 10.1109/76.809155
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   Nielsen R, 2005, LECT NOTES COMPUT SC, V3766, P131, DOI 10.1007/11573425_13
   Nock R, 2005, PATTERN RECOGN, V38, P835, DOI 10.1016/j.patcog.2004.11.009
   Porikli F, 2004, P SOC PHOTO-OPT INS, V5297, P195, DOI 10.1117/12.527188
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Schonfeld D, 2000, J VIS COMMUN IMAGE R, V11, P154, DOI 10.1006/jvci.1999.0432
   Su YB, 2005, IEEE T CIRC SYST VID, V15, P232, DOI 10.1109/TCSVT.2004.841656
   SUKMARG O, 2000, P IEEE TENCON, V3, P364
   Tsaig Y, 2002, IEEE T CIRC SYST VID, V12, P597, DOI 10.1109/TCSVT.2002.800513
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu HF, 2004, IEEE T CIRC SYST VID, V14, P796, DOI 10.1109/TCSVT.2004.828338
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
NR 22
TC 35
Z9 45
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 275
EP 290
DI 10.1016/j.jvcir.2007.02.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300007
DA 2024-07-18
ER

PT J
AU Shao, L
   Brady, M
AF Shao, Ling
   Brady, Michael
TI Invariant salient regions based image retrieval under viewpoint and
   illumination variations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE salient region detection; content-based image retrieval; moment
   invariants; object category retrieval
ID MOMENT INVARIANTS; RECOGNITION; SCALE
AB In this paper, we present a novel image retrieval technique based on salient regions that are invariant under viewpoint and illumination variations. The salient regions are detected according to local entropy and scale selection. The detected regions have very high repeatability under various viewpoint and illumination changes. We apply the invariant region detector on content-based image retrieval applications. The detected regions are the most informative ones, hence are potentially more effective for image indexing and retrieval. Generalized colour moment invariants are used as the invariant descriptor for characterizing the selected salient regions under geometric and photometric changes. Two datasets are used for experiments: one for evaluating the invariance of the algorithm under geometric and photometric transformations; the other for testing the algorithm on object category retrieval. The experimental results show that our proposed region detector is very efficient and effective on retrieving a variety of cluttered images with partial occlusion. (C) 2006 Elsevier Inc. All rights reserved.
C1 Philips Res Labs, Eindhoven, Netherlands.
   Univ Oxford, Robot Res Grp, Oxford OX1 2JD, England.
C3 Philips; Philips Research; University of Oxford
RP Shao, L (corresponding author), Philips Res Labs, Eindhoven, Netherlands.
EM l.shao@philips.com; jmb@robots.ox.ac.uk
RI cai, bo/G-1491-2010; Shao, Ling/D-3535-2011
OI Shao, Ling/0000-0002-8264-6117
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P 8 EUR C COMP VIS P
   [Anonymous], P IEEE C COMP VIS PA
   Burl M., 1998, P EUR C COMP VIS
   FEIFEI L, 2003, P INT C COMP VIS NIC
   Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Ko B, 2005, IEEE T MULTIMEDIA, V7, P105, DOI 10.1109/TMM.2004.840603
   LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   MIKOLAJCZYK K, 2002, P 7 EUR C COP VIS CO
   MIKOLAJCZYK K, 2003, P IEEE C COMP VIS PA
   MIKOLAJCZYK K, 2006, INT J COMPUTER VISIO
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   MINDRU F, 1998, P INT C ADV PATT REC
   REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087
   SHAO L, IN PRESS INFORMATION
   SIVIC J, 2004, P 12 EUR SIGN PROC C
   VANGOOL L, 1995, IMAGE VISION COMPUT, V13, P259, DOI 10.1016/0262-8856(95)99715-D
   WEBER M, 2000, P IEEE C COMP VIS PA
   ZHANG R, 2004, P IEEE INT C MULT EX
NR 23
TC 12
Z9 15
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1256
EP 1272
DI 10.1016/j.jvcir.2006.08.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200009
DA 2024-07-18
ER

PT J
AU Chiu, CY
   Wu, CC
   Wu, YC
   Wu, MY
   Chao, SP
   Yang, SN
AF Chiu, Chih-Yi
   Wu, Chun-Chih
   Wu, Yao-Cyuan
   Wu, Ming-Yang
   Chao, Shih-Pin
   Yang, Shi-Nine
TI Retrieval and constraint-based human posture reconstruction from a
   single image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE posture retrieval and reconstruction; posture library; physical and
   environmental constraint
ID MOTION
AB In this study, we present a novel model-based approach to reconstruct the 3D human posture from a single image. The approach is guided by a posture library and a set of constraints. Given a 2D human figure, i.e., a set of labeled body segments and estimated root orientation in the image, a 3D pivotal posture whose 2D projection is similar to the human figure is first retrieved from the posture library. To facilitate the retrieval process, a table-lookup technique is proposed to index postures according to their 2D projections with respect to designated view directions. Next physical and environmental constraints, including segment length ratios, joint angle limits, pivotal posture reference, and feet-floor contact, are automatically applied to reconstruct the 3D posture. Experimental results show the effectiveness of the proposed approach. (C) 2005 Elsevier Inc. All rights reserved.
C1 Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 Academia Sinica - Taiwan; National Tsing Hua University
RP Chiu, CY (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
EM cychiu@iis.sinica.edu.tw
RI Chiu, Chih-Yi/AAN-2961-2020
OI Chiu, Chih-Yi/0000-0002-2859-6120
CR AGARWAL A, 2004, IEEE C COMP VIS PATT
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], IEEE C COMP VIS PATT
   Barron C., 2000, IEEE C COMP VIS PATT
   Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   CHEUNG GKM, 2003, IEEE COMPUTER VISION
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   DAVIS J, 2003, ACM SIGGRAPH EUR S C
   DIFRANCO DE, 1999, COMPAQ CAMBRIDGE RES
   ELGAMMAL A, 2004, IEEE C COMP VIS PATT
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   HOWE N, 1999, NEURAL INFORMATION P
   *ISO IEC, 2002, JTC1SC29WG11N4668 IS
   LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   LEE MW, 2004, IEEE C COMP VIS PATT
   Li CS, 1998, PROC SPIE, V3656, P2, DOI 10.1117/12.307561
   LIU X, 1999, ACM INT C MULT ORL F
   Loy G, 2004, LECT NOTES COMPUT SC, V2034, P442
   McFarlane S., 1999, The complete book of t'ai chi
   Mori G., 2004, IEEE C COMP VIS PATT
   MORIMURA K, 2002, INT C WEB DEL MUS DA
   Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622
   Ning HZ, 2004, IMAGE VISION COMPUT, V22, P429, DOI 10.1016/j.imavis.2004.01.001
   Parameswaran V., 2004, IEEE C COMP VIS PATT
   PARK MJ, 2002, ACM SIGGRAPH S COMP
   Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203
   REN L, 2004, ACM SIGGRAPH C SKETC
   ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006
   ROSALES R, 2001, NEURAL INFORMATION P
   SUNDARAM H, 1999, SPIE STORAGE RETRIEV
   Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878
   THEOBALT C, 2002, PAC C COMP GRAPH APP
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
NR 36
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 892
EP 915
DI 10.1016/j.jvcir.2005.01.002
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500013
DA 2024-07-18
ER

PT J
AU Zhou, Z
   Xin, J
   Sun, MT
AF Zhou, Zhi
   Xin, Jun
   Sun, Ming-Ting
TI Fast motion estimation and Inter-mode decision for H.264/MPEG-4 AVC
   encoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE computation reduction; H.264/MPEG4 AVC; mode decision; motion estimation
ID SEARCH
AB In H.264/MPEG-4 AVC encoding, computational complexity is the main concern for implementation and application. Motion estimation (ME) and Inter-mode decision (MD) consume a large portion of encoder computation power. ME is referred to the process to find the motion vector (MV) for a block, and MD is referred to the process to determine the best block-size for Inter-frame prediction. This paper proposes a new concept of introducing diversity into the MV search strategy. Based on the diversity concept, we introduce a new fast ME search strategy: adaptive diversity search strategy (ADSS), by combining the strength of different search strategies. We also investigate three fast ME strategies by MV merging and splitting for variable-size block motion estimation (VSBME), which explores the correlation of MVs of overlapping blocks. In addition, an Inter-mode decision is proposed by fast mode exclusion (FME). The experiment results show that the proposed fast ME can reduce the search points to about 4% of that by full search, and that the proposed FME can reduce the computation further, with negligible degradation in the rate-distortion (R-D) performance. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   Mitsubishi Elect Res Labs, Cambridge, MA USA.
C3 University of Washington; University of Washington Seattle
RP Zhou, Z (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
EM zhouzhi@ee.washington.edu
CR ALKANHAL M, 1999, PICT COD S PORTL OR
   Bierling M., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V1001, P942, DOI 10.1117/12.969046
   CHEN Z, 2002, JVT F017 AW JAP DEC
   CHOI WI, 2003, P IEEE INT C IM PROC
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Koga B.T., 1981, P NAT TEL C
   KUCUKGOZ M, 2004, SPIE P VIS COMM IM P
   LI X, 2002, JVT F011 AW JAP DEC
   LIM KP, 2003, JVT I020 SAN DIEG US
   Liu B, 1993, IEEE T CIRC SYST VID, V3, P148, DOI 10.1109/76.212720
   MA KK, 2003, P IEEE INT S CIRC SY
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   TOURAPIS AM, 2001, SPIE P VIS COMM IM P
   TU YK, 2003, P IEEE INT C MULT EX
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WIEGAND T, 2002, JVTB118R8 ISOIEC MPE
   XIN J, 2003, P IEEE INT C MULT EX
   ZHOU XS, 2003, SPIE C IM VID COMM P
   ZHOU Z, 2004, IEEE INT S CIRC SYST
   ZHOU Z, 2004, IEEE INT C IM PROC I
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   [No title captured]
NR 22
TC 11
Z9 14
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 243
EP 263
DI 10.1016/j.jvcir.2005.05.003
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000004
DA 2024-07-18
ER

PT J
AU Ha, R
   Zhuang, WH
AF Ha, R
   Zhuang, WH
TI Split-domain video transmission protocol for video streaming over hybrid
   wired-wireless connections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE mobile communication systems; multimedia applications; transport
   protocols; TCP; video streaming
ID CONGESTION CONTROL; TCP; PERFORMANCE; INTERNET
AB The imminent inception of third-generation mobile communication technologies and continual proliferation of wireless local area networks offer an unprecedented opportunity for the development of video streaming applications through wireless Internet access. Different design challenges exist in implementing video streaming connections spanning both wired and wireless domains. This paper proposes a split-domain video transmission protocol to allow streaming video transmission based on adaptive rate encoding over hybrid wired-wireless connections. Computer simulation results are presented to demonstrate the benefits and viability of such a video streaming method over existing transport options. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Univ Waterloo, Dept Elect & Comp Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM rwkha@bbcr.uwaterloo.ca; wzhuang@bbcr.uwaterloo.ca
RI Zhuang, Weihua/AAH-2576-2020
OI Zhuang, Weihua/0000-0003-0488-511X
CR [Anonymous], 2018 RFC IETF
   Bakre AV, 1997, IEEE T COMPUT, V46, P260, DOI 10.1109/12.580423
   Balakrishnan H, 1997, IEEE ACM T NETWORK, V5, P756, DOI 10.1109/90.650137
   Floyd S, 1999, IEEE ACM T NETWORK, V7, P458, DOI 10.1109/90.793002
   Forum WAP, 2001, WAP ARCH
   HA R, 2002, THESIS U WATERLOO
   Hsu CY, 1999, IEEE J SEL AREA COMM, V17, P756, DOI 10.1109/49.768193
   HUANG L, 2002, P 5 ACM INT WORKSH W, P17
   Jacobson V., 1992, 1323 RFC IETF
   KOENEN R, 2001, JTC1SC29WG11 ISO IEC
   POASTEL J, 1981, 0793 RFC IETF
   POSTEL J, 1980, 0789 RFC IETF
   Talluri R, 1998, IEEE COMMUN MAG, V36, P112, DOI 10.1109/35.685373
   Widmer J, 2001, IEEE NETWORK, V15, P28, DOI 10.1109/65.923938
   Yang F, 2004, IEEE J SEL AREA COMM, V22, P777, DOI 10.1109/JSAC.2004.826008
   YU K, 1999, P IEEE MILCOM, V2, P1221
   [No title captured]
NR 17
TC 1
Z9 1
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 450
EP 474
DI 10.1016/j.jvcir.2004.11.011
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600005
DA 2024-07-18
ER

PT J
AU Narroschke, M
AF Narroschke, M
TI Benefits and costs of scalable video coding for internet streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video coding; scalable video coding; scalability; MPEG-4
ID MOTION-COMPENSATION
AB Benefits and costs of scalable hybrid video coding techniques are analyzed with respect to internet streaming. Temporal, spatial, amplitude scalability, and combinations as described in MPEG-4 are considered. Benefits are a reduction of the server storage capacity, a reduction of the netload for multicast delivery and a graceful degradation in case of transmission errors. Costs are ail increasing netload for unicast delivery and ail increasing computational expense in the decoder. The result of an evaluation shows that temporal scalability has minimum costs among all analyzed techniques. It increases the netload for unicast only marginally with no additional Computational expense in the decoder. Temporal scalability provides a reduction of the server storage capacity and netload for multicast by about 30%, and two steps of graceful degradation. All other known standardized and nonstandardized techniques of spatial and amplitude scalability are associated with costs that appear too high to be attractive for internet streaming. Therefore, only temporal scalability is used at the present. Some of the scalable video coding techniques may become of interest for other applications where the investigated costs are less relevant. (c) 2005 Elsevier Inc. All rights reserved.
C1 Leibniz Univ Hannover, Inst Theoret Nachrichtentech & InformatVerarbeitu, D-30167 Hannover, Germany.
C3 Leibniz University Hannover
RP Narroschke, M (corresponding author), Leibniz Univ Hannover, Inst Theoret Nachrichtentech & InformatVerarbeitu, D-30167 Hannover, Germany.
EM narrosch@tnt.uni-hannover.de
CR [Anonymous], JTC1SC29WG11 ISOIEC
   Benzler U, 2000, IEEE T CIRC SYST VID, V10, P1080, DOI 10.1109/76.875512
   BENZLER U, 1999, P PICT COD S PCS 99
   BENZLER U, 1999, 48 MPEG M VANC CAN J
   BENZLER U, 2001, P SYST CYB INF C SCI, V12
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   Côté G, 1998, IEEE T CIRC SYST VID, V8, P849, DOI 10.1109/76.735381
   HANKE K, 2002, 62 MPEG M SHANGH CHI
   HANKE K, 2002, 61 MPEG M KLAG AUSTR
   HE Y, 2002, P ISCAS 2002 PHOEN U, P819
   Hsiang ST, 2001, SIGNAL PROCESS-IMAGE, V16, P705, DOI 10.1016/S0923-5965(01)00002-9
   *ISO IEC, 2003, 14496102003 ISOIEC
   *ITU R, 1995, HILO ITUT
   ITU R, 1995, 601 ITUR
   *ITU T, 2000, H263 ITUT
   LI W, 1998, 45 MPEG M ATL CIT NJ
   LI W, 1999, 47 MPPEG M SEOUL KOR
   *MPEG2 ISO IEC, 1995, JTC1SC29WG11 MPEG2 I
   *MPEG4 FGS ISO IEC, JTC1SC29WG11 MPEG4 F
   *MPEG4 ISO IEC, 2000, JTC1SC29WG11 MPEG4 I
   *MPEG4 ISO IEC, JTC1SC29WG11 MPEG4 I
   NARROSCHKE M, 2003, P PICT COD S PCS03 S
   NARROSCHKE M, 2003, P PICT COD S PCS 03
   OHM JR, 1994, IEEE T IMAGE PROCESS, V3, P559, DOI 10.1109/83.334985
   OHM JR, 2002, 61 MPEG M KLAG AUSTR
   Secker A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1029, DOI 10.1109/ICIP.2001.958672
   STOLBERG HJ, 2002, P IEEE INT C MULT EX, V2, P105
   van der Schaar M, 2002, IEEE T CIRC SYST VID, V12, P360, DOI 10.1109/TCSVT.2002.800319
NR 28
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 397
EP 411
DI 10.1016/j.jvcir.2004.11.010
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600002
DA 2024-07-18
ER

PT J
AU Chan, DY
   Cheng, HY
   Hsieh, HL
AF Chan, DY
   Cheng, HY
   Hsieh, HL
TI Tissue separation in MR images - from supervised to unsupervised
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE oblique subspace projector; maximal signal-to-interference ratio
   projector; noise subspace projector; independent component projector
ID MAGNETIC-RESONANCE IMAGES; INDEPENDENT COMPONENT ANALYSIS; BRAIN IMAGES;
   SEGMENTATION; MODEL; ALGORITHM
AB in this paper, four projectors are constructed to separate the brain tissues from the multispectral magnetic resonance (MR) imagery. The four projectors are the oblique subspace (OB) projector, the maximal signal-to-interference ratio (MSIR) projector, the noise subspace (NS) projector, and independent component (IC) projector, respectively. According to the required amount of a priori knowledge, the designs of proposed projectors are followed from the supervised to the unsupervised requirements. Mean that the OB projector requires all tissue signatures while the IC projector employ no prior information at all for the substance detection. Experimental results have shown that these four projectors are feasible to separate the signatures in magnetic resonance images. Specially, the IC projector has shown the salient ability in detecting the areas of lesions from the abnormal brain MR images. (C) 2003 Elsevier Inc. All rights reserved.
C1 IShou Univ, Dept Elect Engn, Kaohsiung 84008, Taiwan.
   Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan.
C3 I Shou University; National Chiayi University
RP IShou Univ, Dept Elect Engn, 1 Univ Rd, Kaohsiung 84008, Taiwan.
EM dychan@mail.ncyu.edu.tw
CR Aboutanos GB, 1997, PROC SPIE, V3034, P299, DOI 10.1117/12.274098
   Alirezaie J, 1997, IEEE T NUCL SCI, V44, P194, DOI 10.1109/23.568805
   ATKINS MS, 1996, P VISUALIZATION BIOM, V1131, P210
   BEHRENS RT, 1994, IEEE T SIGNAL PROCES, V42, P1413, DOI 10.1109/78.286957
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   CHOI HS, 1991, IEEE T MED IMAGING, V10, P395, DOI 10.1109/42.97590
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   DUTA N, IEEE T MED IMAGING, V17, P12049
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   GRAHN H, 1989, CHEMOMETR INTELL LAB, V5, P311, DOI 10.1016/0169-7439(89)80030-9
   HARSANYI C, IEEE T GEOSCI REMOTE, V32, P779
   HEBERT T, 1989, IEEE T MED IMAGING, V8, P194, DOI 10.1109/42.24868
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Karayiannis NB, 1999, IEEE T MED IMAGING, V18, P172, DOI 10.1109/42.759126
   RAYA SP, 1990, IEEE T MED IMAGING, V9, P327, DOI 10.1109/42.57771
   SANTAGO P, 1993, IEEE T MED IMAGING, V12, P566, DOI 10.1109/42.241885
   SUZUKI H, 1991, COMPUT MED IMAG GRAP, V15, P233, DOI 10.1016/0895-6111(91)90081-6
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P885, DOI 10.1109/42.811268
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   VANVEEN B, IEEE ASSP MAG, P4
   Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665
   Zavaljevski A, 2000, COMPUT MED IMAG GRAP, V24, P87, DOI 10.1016/S0895-6111(99)00042-7
NR 23
TC 2
Z9 2
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 185
EP 202
DI 10.1016/j.jvcir.2003.12.002
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800005
DA 2024-07-18
ER

PT J
AU Pan, SB
   Park, RH
AF Pan, SB
   Park, RH
TI Systolic array architectures for computation of the discrete wavelet
   transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE discrete wavelet transform; VLSI; systolic array architecture
ID VLSI ARCHITECTURE; IMPLEMENTATION
AB For computation of the 1-D and 2-D discrete wavelet transforms (DWTs), this paper proposes systolic array architectures that are independent of the sequence size and the nature of wavelet. The proposed systolic arrays for the 1-D DWT consist of L processing element (PE) arrays, where L denotes the number of levels of the architectures. The proposed PE array computes only the product terms that are required for further computation at higher levels, and the outputs of lowpass and highpass filters are computed by a single architecture in alternate clock cycles. Note that the proposed architectures, suitable for hardware implementation, do not require extra control units such as complex control unit and global interconnection whereas the existing architectures need them. The proposed systolic array for the 2-D DWT consist of a small memory unit and a number of systolic array architectures, each of which computes the 1-D DWT. The required time and hardware cost for computation of the DWT using the proposed systolic arrays are comparable to those of the existing architectures. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea.
C3 Sogang University
RP Park, RH (corresponding author), Sogang Univ, Dept Elect Engn, CPO 1142, Seoul 100611, South Korea.
RI Park, Rae-Hong/Q-7908-2019
OI Park, Rae-Hong/0000-0002-4792-2980
CR [Anonymous], IEEE COMPUTER
   CHAKRABARTI C, 1995, IEEE T SIGNAL PROCES, V43, P759, DOI 10.1109/78.370630
   CHAKRABARTI C, 1996, P IEEE INT C AC SPEE, P3256
   CHEN J, 1995, P VLSI SIGN PROC, V8, P303
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Grzeszczak A, 1996, IEEE T VLSI SYST, V4, P421, DOI 10.1109/92.544407
   KNOWLES G, 1990, ELECTRON LETT, V26, P1184, DOI 10.1049/el:19900766
   Kung S. Y., 1988, VLSI array processors
   LANG R, 1994, P SOC PHOTO-OPT INS, V2242, P925, DOI 10.1117/12.170093
   LEE HJ, 1994, P SOC PHOTO-OPT INS, V2242, P248, DOI 10.1117/12.170029
   LEWIS AS, 1991, ELECTRON LETT, V27, P171, DOI 10.1049/el:19910110
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   PAN SB, 1997, P IEEE INT C AC SPEE, V5, P4113
   Parhi K. K., 1993, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V1, P191, DOI 10.1109/92.238416
   Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217
   SHEU MH, 1996, P IEEE INT S CIRC SY, P352
   VETTERLI M, 1992, IEEE T SIGNAL PROCES, V40, P2207, DOI 10.1109/78.157221
   VISHWANATH M, 1995, IEEE T CIRCUITS-II, V42, P305, DOI 10.1109/82.386170
NR 18
TC 6
Z9 6
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 217
EP 231
DI 10.1016/S1047-3203(03)00004-X
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200002
DA 2024-07-18
ER

PT J
AU Xie, XX
   Li, CF
   Guan, TX
   Zheng, YH
   Wu, XJ
AF Xie, Xinxiu
   Li, Chaofeng
   Guan, Tuxin
   Zheng, Yuhui
   Wu, Xiaojun
TI A novel complex-valued convolutional network for real-world single image
   dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Real-world image dehazing; Complex-valued convolutional network;
   Complex-valued attention; Complex-valued feature learning; Phase
   information
ID VISION
AB Previous deep learning-based single image dehazing methods are implemented by using real-valued convolutional neural network (RV-CNN), which ignore the phase information of the image, and tend to cause models to perform well on synthetic datasets but low generalization on real-world datasets. In this paper, we propose a novel Complex-Valued convolutional Dehazing Network (CVD-Net), which considers both amplitude and phase information of image for haze removal in real-world scenes. Specifically, we construct complex-valued transformation module, including complex-valued convolutional layer and residual block embedded into the middle of the network to extract features of image efficiently, and also design a complex-valued selected fusion module (CVSF) and complex-valued attention module (CVAM) to promote the interaction between different scale features for preserving image detailed information. Both qualitative and quantitative experimental results show that the proposed CVD-Net can effectively remove the haze, and has good generalization in real-world hazy images.
C1 [Xie, Xinxiu; Li, Chaofeng; Guan, Tuxin] Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 200135, Peoples R China.
   [Zheng, Yuhui] Qinghai Normal Univ, Coll Comp, Xining 810016, Peoples R China.
   [Wu, Xiaojun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
C3 Shanghai Maritime University; Qinghai Normal University; Jiangnan
   University
RP Li, CF (corresponding author), Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 200135, Peoples R China.
EM wxlichaofeng@126.com
FU National Natural Science Foundation of China [62176150, U20B2065,
   U22B2056]
FX We thank the financial support of The National Natural Science
   Foundation of China (No. 62176150, U20B2065 and U22B2056) .
CR Anantrasirichai N, 2022, Arxiv, DOI arXiv:2204.06989
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen Guangyao, 2021, P IEEE CVF INT C COM, P458
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Guan TX, 2023, IEEE T MULTIMEDIA, V25, P3934, DOI 10.1109/TMM.2022.3168438
   Guberman N, 2016, Arxiv, DOI arXiv:1602.09046
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirose A, 2003, Complex-Valued Neural Netw.: Theories and App., V5, P1
   Hirose A, 2012, IEEE T NEUR NET LEAR, V23, P541, DOI 10.1109/TNNLS.2012.2183613
   Hong M, 2020, PROC CVPR IEEE, P3459, DOI 10.1109/CVPR42600.2020.00352
   Jain Poornima, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P2093, DOI 10.1109/EMBC48229.2022.9872016
   Jiang YT, 2017, COMPUT VIS IMAGE UND, V165, P17, DOI 10.1016/j.cviu.2017.10.014
   Jojoa M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081893
   Kumar A, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103122
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CF, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116064
   Li CF, 2021, IET IMAGE PROCESS, V15, P443, DOI 10.1049/ipr2.12034
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li LL, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107110
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Mehra A, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103137
   Mei KF, 2019, LECT NOTES COMPUT SC, V11361, P203, DOI 10.1007/978-3-030-20887-5_13
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Quan YH, 2022, IEEE T NEUR NET LEAR, V33, P5387, DOI 10.1109/TNNLS.2021.3070596
   Quan YH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107639
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tu ZZ, 2022, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR52688.2022.00568
   Vasudeva B., 2020, arXiv, DOI 10.48550/arXiv.2002.10523
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xie W, 2020, NEUROCOMPUTING, V388, P255, DOI 10.1016/j.neucom.2020.01.020
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Ye T., 2021, arXiv, DOI DOI 10.48550/ARXIV.2111.09733
   Yu H, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P6645, DOI 10.1145/3503161.3548410
   Zhang JH, 2022, IEEE T INTELL TRANSP, V23, P3087, DOI 10.1109/TITS.2020.3030673
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 48
TC 2
Z9 2
U1 11
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103984
DI 10.1016/j.jvcir.2023.103984
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AO3R3
UT WOS:001119372100001
DA 2024-07-18
ER

PT J
AU Deng, ZL
   Liu, SB
   He, P
   Song, Y
   Tang, Q
   Li, WB
AF Deng, Zelin
   Liu, Shaobao
   He, Pei
   Song, Yun
   Tang, Qiang
   Li, Wenbo
TI A bidirectional fusion branch network with penalty term-based trihard
   loss for person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Person re-identification; Feature pyramid; Bidirectional
   fusion branch network; Penalty term-based trihard loss
AB Person re-identification (Re-ID) is the recognition of the same person in different camera views. Because of the existence of highly similar persons and great differences of the same person in different scenes, and the fact that the features extracted by current mainstream models lose some fine-grained information, it is likely for the models to misidentify the query person. To tackle these challenges, we introduce a bidirectional fusion branch network with penalty term-based trihard loss (BFB-PTT). The BFB-PTT constructs a bidirectional fusion branch (BFB) network based on feature pyramid, where low-level features are transferred to a high-level feature space through fewer convolutional layers than most of the traditional CNN-based models have, thus retaining more local features to discriminate different pedestrians more accurately and effectively. Meanwhile, we propose using the penalty term-based trihard loss (PTT) to optimize the spatial structure of pedestrian's samples, so that the similar samples are drawn closer together in order to reduce the variabilities of the same person in different scenes. We have conducted comprehensive experiments and analyses on the proposed method's effectiveness on three challenging benchmarks, and the results show that our approach achieves competitive performance with the state-of-art models.
C1 [Deng, Zelin; Liu, Shaobao; Song, Yun; Tang, Qiang; Li, Wenbo] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, 960,Sect 2,Wanjiali South Rd, Changsha, Peoples R China.
   [He, Pei] Guangzhou Univ, Sch Comp Sci & Cyber Engn, 230 Waihuan West Rd, Guangzhou, Peoples R China.
C3 Changsha University of Science & Technology; Guangzhou University
RP Liu, SB (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, 960,Sect 2,Wanjiali South Rd, Changsha, Peoples R China.
EM cliuszx@gmail.com
FU National Natural Science Foundation of China [61977018]; Natural-Science
   Foundation of Changsha [kq2202215]; Practica-l Innovation and
   Entrepreneur-ship Enhancement Program for Professional Degree
   Post-graduates of Changsha University of Science and Technology
   [CLSJCX22114]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61977018; Natural Science Foundation
   of Changsha under Grant No. kq2202215; Practica-l Innovation and
   Entrepreneurship Enhancement Program for Professional Degree
   Post-graduates of Changsha University of Science and Technology
   (CLSJCX22114) .
CR Benzine A, 2021, Arxiv, DOI arXiv:2102.09321
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dong HS, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-022-01353-3
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Gong X., 2021, IEEE Trans. Multimedia, V9
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang YK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P365, DOI 10.1145/3343031.3350994
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Li W., 2017, arXiv
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Lu YH, 2023, IMAGE VISION COMPUT, V131, DOI 10.1016/j.imavis.2023.104633
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Ming ZQ, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104394
   Ni XY, 2021, EUR W VIS INF PROCES, DOI 10.1109/EUVIP50544.2021.9484010
   Peng J., 2023, Signal Process. Image Commun.
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tang ZM, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3501405
   Tian H, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3240217
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu JL, 2023, NEUROCOMPUTING, V518, P155, DOI 10.1016/j.neucom.2022.11.009
   Wu X., 2021, IEEE Trans. Cogn. Dev. Syst.
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xie Ben, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12307), P16, DOI 10.1007/978-3-030-60636-7_2
   Xie GS, 2022, NEUROCOMPUTING, V469, P298, DOI 10.1016/j.neucom.2021.10.055
   Yu Z, 2022, NEURAL COMPUT APPL, V34, P8697, DOI 10.1007/s00521-021-06852-4
   Zang XH, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104330
   Zhang Shijie, 2021, ARXIV
   Zhang SF, 2020, IEEE SIGNAL PROC LET, V27, P850, DOI 10.1109/LSP.2020.2994815
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108229
   Zhao Y, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107938
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
NR 52
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103972
DI 10.1016/j.jvcir.2023.103972
EA NOV 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z3DN3
UT WOS:001110913500001
DA 2024-07-18
ER

PT J
AU Perumal, M
   Srinivas, M
AF Perumal, Murukessan
   Srinivas, M.
TI DenSplitnet: Classifier-invariant neural network method to detect
   COVID-19 in chest CT data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Chest-CT-scan images; Novel coronavirus; COVID-19; Deep learning;
   Self-supervised learning; Computer vision
ID DIAGNOSIS; SYSTEM
AB Objective: COVID-19 has made an unprecedented impact on humanity. The Healthcare sector, in an effort to curb COVID-19, could leverage Artificial Intelligence (AI) to its aid, especially in diagnosing it through the classification of Chest-CT scans. However, data scarcity plagues the medical domain. Therefore, any AI solution must be capable of learning from limited data. Also the resulting AI could relieve radiologists from exhaustion and aid medical practitioners as a valuable diagnostic tool.Methods: Our proposed model DenSplitnet uses Dense blocks to learn image features, Self-Supervised Learning for pre-training to learn the context, and a novel two-way split branch at the final classification layer for classifier-invariant generalization ability. Results: DenSplitnet achieves state-of-the-art performance on four benchmark chest-CT scan datasets for COVID-19. The model performs well on the Sars-cov-2 ct-scan dataset. The Test accuracy is 91.92%, F1-Score is 91.30%, Precision is 96.55%, and Recall is 87.04%. The model achieves test accuracy of 86.17%, Precision of 82.94%, Recall of 83.72%, and F1-Score of 83.23% on the Sars-cov-2 ct-scan multiclass dataset. The model obtains a test accuracy of 86.21%, an F1-Score of 83.91%, and an AUC of 0.95 in the Covid-ct-dataset. The model obtains a test accuracy that is 73.11% and an F1-Score of 70.97% in the TransferLearn-ct dataset.Conclusion: The findings support the practical usability of the DenSplitnet as a technological AI assistance to radiologists and other medical professionals, alongside Grad-CAM plots for explainable AI and the theoretical examination of the classifier-invariant generalization capacity of the network. The healthcare sector can benefit from this technology in a number of ways.
C1 [Perumal, Murukessan; Srinivas, M.] Natl Inst Technol, Dept Comp Sci & Engn, Warangal, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Perumal, M (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Warangal, Telangana, India.
EM muruap87@student.nitw.ac.in
OI Perumal, Murukessan/0000-0002-7962-3352
FU Government of India; Ministry of Education, and NIT Warangal
   [NITW/CS/CSE-RSM/2018/908/3118]
FX The authors thank the anonymous reviewers for their thorough reviews and
   valuable comments. This work was partly supported by grants from the
   Government of India, the Ministry of Education, and NIT Warangal under
   the NITW/CS/CSE-RSM/2018/908/3118 project.
CR Abdi M, 2017, Arxiv, DOI arXiv:1609.05672
   Acar ZY, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100706
   Alshazly H, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.655
   Alshazly H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020455
   Alzubaidi L, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00727-2
   Angelov P, 2020, medRxiv, DOI [10.1101/2020.04.24.20078584, 10.1101/2020.04.24.20078584, DOI 10.1101/2020.04.24.20078584]
   Angelov P, 2020, NEURAL NETWORKS, V130, P185, DOI 10.1016/j.neunet.2020.07.010
   Anwar T., 2020, 2020 IEEE 23 INT MUL, P1, DOI DOI 10.1109/INMIC50486.2020.9318212
   Celik G, 2023, APPL SOFT COMPUT, V133, DOI 10.1016/j.asoc.2022.109906
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen YF, 2022, COMPUT METH PROG BIO, V225, DOI 10.1016/j.cmpb.2022.107053
   Commandeur F, 2018, IEEE T MED IMAGING, V37, P1835, DOI 10.1109/TMI.2018.2804799
   Cucinotta Domenico, 2020, Acta Biomed, V91, P157, DOI 10.23750/abm.v91i1.9397
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Feng H, 2020, JPN J RADIOL, V38, P409, DOI 10.1007/s11604-020-00967-9
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Grand-Challenge, 2022, Luna16 lung cancer dataset
   Haghighi F, 2021, IEEE T MED IMAGING, V40, P2857, DOI 10.1109/TMI.2021.3060634
   Hamza A, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1046296
   Hamza A, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.948205
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   He X, 2020, medRxiv, DOI [10.1101/2020.04.13.20063941, 10.1101/2020.04.13.20063941, DOI 10.1101/2020.04.13.20063941]
   Heidari M, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104284
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam MR, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116554
   Jorgensen MD, 2022, EUR J RADIOL, V146, DOI 10.1016/j.ejrad.2021.110073
   Kaggle, 2020, A COVID multiclass dataset of CT scans
   Kaggle, 2022, COVIDx CT: A large-scale chest CT dataset for COVID-19 detection
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kini AS, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/7377502
   Lee Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05069-2
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Morozov SP, 2020, Arxiv, DOI [arXiv:2005.06465, DOI 10.48550/ARXIV.2005.06465]
   Murugan R, 2022, SOFT COMPUT, V26, P1057, DOI 10.1007/s00500-022-06752-2
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Navarro F, 2021, Arxiv, DOI [arXiv:2105.06986, DOI 10.48550/ARXIV.2105.06986]
   Ozdemir O, 2020, IEEE T MED IMAGING, V39, P1419, DOI 10.1109/TMI.2019.2947595
   Patel V, 2019, HEALTH INFORM J, V25, P1398, DOI 10.1177/1460458218769699
   Perumal M, 2022, ISA T, V124, P82, DOI 10.1016/j.isatra.2022.02.033
   Reed CJ, 2021, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR46437.2021.00270
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shurrab S, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1045
   Srinivas M, 2015, BIO-MED MATER ENG, V26, P49, DOI 10.3233/BME-151552
   Srinivas M, 2015, NEUROCOMPUTING, V168, P880, DOI 10.1016/j.neucom.2015.05.036
   Subramanian N, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105233
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2019, I S BIOMED IMAGING, P1251, DOI [10.1109/ISBI.2019.8759553, 10.1109/isbi.2019.8759553]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian CX, 2023, Arxiv, DOI arXiv:2105.08511
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wen Y, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103145
   Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224
   World Health Organization, 2022, WHO statistics on COVID-19
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Yadav M, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110050
   Yang XY, 2020, Arxiv, DOI arXiv:2003.13865
   Yee E, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102000
   Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253
NR 59
TC 2
Z9 2
U1 3
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103949
DI 10.1016/j.jvcir.2023.103949
EA OCT 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X7CJ2
UT WOS:001099983900001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Yin, XH
   Tang, C
   Yue, GH
   Wang, Y
AF Liu, Yun
   Yin, Xiaohua
   Tang, Chang
   Yue, Guanghui
   Wang, Yan
TI A no-reference panoramic image quality assessment with hierarchical
   perception and color features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Omnidirectional images; No-reference quality assessment; Hierarchical
   perception; Color information
ID INFORMATION; STATISTICS
AB The ultimate goal of no-reference omnidirectional image quality assessment (NR-OIQA) is to design a comprehensive perception method that can accurately assess the quality of damaged omnidirectional images without prior knowledge. However, most existing studies cannot attain credible accuracy because of lacking a non-neuroscience-based or non-biology-based model. Inspired by this, an original visual perception-based and neuroscience-based OIQA model by considering the hierarchical perception features of the HVS, which includes specific information, local saliency information, global information, and color information which is often ignored by researchers is proposed in this work. According to the hierarchical process in neuroscience, the high-frequency co-occurrence matrix (HFCM)-based and variance-based specific features are applied to perceive details that are first distorted in the frequency domain. The entropy-based combination of the paranormal saliency map(PSM) and superpixel segmentation with the simple linear iterative clustering (SLIC) algorithm is employed to emphasize the rich quality-aware local saliency information. The global panoramic statistical (GPS) model is utilized to express global semantics distortion as the high-level feature. Visual-aware color texture descriptor with the cross-channel local binary pattern(CCLBP) which effectively reflects the correlation and dependency of pixels between different color channels is employed to map color information. Finally, all above features have been extracted and combined with subjective scores to assess the objective quality scores by support vector regression (SVR). Experiments express that our method has more accuracy and stronger stability on CVIQD2018 and OIQA databases.
C1 [Liu, Yun; Yin, Xiaohua; Wang, Yan] Liaoning Univ, Shenyang, Peoples R China.
   [Tang, Chang] China Univ Geosci, Wuhan, Peoples R China.
   [Yue, Guanghui] Shenzhen Univ, Shenzhen, Peoples R China.
C3 Liaoning University; China University of Geosciences; Shenzhen
   University
RP Yin, XH (corresponding author), Liaoning Univ, Shenyang, Peoples R China.
EM yinxhhhh@163.com
RI Tang, Chang/AAU-8995-2020
OI Tang, Chang/0000-0002-6515-7696
FU Liaoning Province Natural Science Foundation, China [2023-MS-139];
   National Natural Science Foundation of China [61901205, 62076228,
   62001302]; Guangdong Basic and Applied Basic Research Foundation
   [2019A1515111205]
FX This work was supported by the Liaoning Province Natural Science
   Foundation, China under Grant 2023-MS-139, National Natural Science
   Foundation of China under 61901205, 62076228, and 62001302, and
   Guangdong Basic and Applied Basic Research Foundation under Grant
   2019A1515111205. The authors would like to thank Prof. Wei Sun
   forproviding the CVIQD2018 database and Prof. Huiyu Duan for
   providingthe OIQA database.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2020, VR PHOTOGRAPHY
   Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616
   Chen C., 2020, FULL REFERENCE SCREE
   Chen CLZ, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3447393
   Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   Chetouani A, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115963
   De Angelis A, 2009, IEEE T INSTRUM MEAS, V58, P14, DOI 10.1109/TIM.2008.2004982
   Doi E., 2005, RELATIONS STAT REGUL, P1
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Fang YM, 2021, IEEE T MULTIMEDIA, V23, P955, DOI 10.1109/TMM.2020.2991528
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7
   Jabar F., 2019, IEEE J SEL TOP SIGN, P1
   Jiang H, 2021, IEEE T IMAGE PROCESS, V30, P2364, DOI 10.1109/TIP.2021.3052073
   Kusuno Y, 2019, IEEE/SICE I S SYS IN, P325, DOI [10.1109/SII.2019.8700393, 10.1109/sii.2019.8700393]
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Lei JJ, 2016, IEEE T MULTIMEDIA, V18, P1783, DOI 10.1109/TMM.2016.2592325
   Li YF, 2019, IEEE ACCESS, V7, P46706, DOI 10.1109/ACCESS.2019.2909073
   Ling SY, 2018, IEEE INT CON MULTI
   Liu YL, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3050187
   Liu Y, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3549544
   Liu YT, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3414837
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Ma K., 2021, IMAGE QUALITY ASSESS
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shu X, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116392
   Simoncelli E, 1999, STAT MODELS IMAGES C
   Singh S, 2020, IEEE T INSTRUM MEAS, V69, P3855, DOI 10.1109/TIM.2019.2933341
   Sui XJ, 2022, IEEE T VIS COMPUT GR, V28, P3022, DOI 10.1109/TVCG.2021.3050888
   Sun W., 2019, IEEE INT SYMP CIRC S
   Sun W, 2018, IEEE INT WORKSH MULT
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Wainwright M., 2000, WAVELET APPL SIGNAL
   Wang Z., 2014, IMAGE QUALITY ASSESS
   Xia Y., 2019, 2019 IEEE VISUAL COM
   Xu JZ, 2021, IMPACT ASSESS PROJ A, V39, P429, DOI [10.1109/TR.2020.3040191, 10.1080/14615517.2020.1848242]
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang LD, 2022, IEEE T ROBOT, V38, P1531, DOI 10.1109/TRO.2021.3111788
   Yang Y, 2017, IEEE T INSTRUM MEAS, V66, P691, DOI 10.1109/TIM.2017.2658098
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Yue GH, 2019, IEEE T INSTRUM MEAS, V68, P2733, DOI 10.1109/TIM.2018.2868555
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zheng X., 2020, IEEE ACCESS, V8, P1
   Zhou Y, 2022, IEEE T CIRC SYST VID, V32, P1767, DOI 10.1109/TCSVT.2021.3081162
   Zhou YF, 2018, INT CONF SIGN PROCES, P54, DOI 10.1109/ICSP.2018.8652269
   Zhu SP, 2020, IEEE T CIRC SYST VID, V30, P1946, DOI 10.1109/TCSVT.2019.2911396
NR 63
TC 0
Z9 0
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103885
DI 10.1016/j.jvcir.2023.103885
EA JUL 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N9NF4
UT WOS:001040188000001
DA 2024-07-18
ER

PT J
AU Sasipriyaa, N
   Natesan, P
   Gothai, E
AF Sasipriyaa, N.
   Natesan, P.
   Gothai, E.
TI SFGDO: Smart flower gradient descent optimization enabled generative
   adversarial network for recognition of Tamil handwritten character
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Generative adversarial network; Character recognition; Bilateral filter;
   Binarization; Gradient based thresholding
ID BINARY PATTERN
AB The Tamil language is complicated to identify, and thus more efforts are devised in the literary works. The objective is to develop a model called the Smart Flower Gradient Descent optimization-based Generative Adversarial Network (SFGDO-based GAN) for recognising Tamil handwriting. The dataset is first used to acquire the input image. The undesired noises are then pre-processed using a bilateral filter, and the binarization pro-cedure is carried out using gradient-based thresholding. The necessary characteristics are then extracted for further categorization of Tamil characters, including character length, character width, statistical features, Local Binary Pattern (LBP), Convolutional Neural Network (CNN), density features, and Histogram of Oriented Gra-dients (HOG) features. Finally, utilising the proposed SFGDO enabled GAN, Tamil handwritten characters are recognised. The proposed Smart Flower Gradient Descent optimization (SFGDO) algorithm is developed by integrating Smart Flower Optimization Algorithm SFOA) and Gradient Descent Optimization (GDO).
C1 [Sasipriyaa, N.; Natesan, P.; Gothai, E.] Comp Sci & Engn Kongu Engn Coll, Erode 638060, Tamilnadu, India.
RP Sasipriyaa, N (corresponding author), Comp Sci & Engn Kongu Engn Coll, Erode 638060, Tamilnadu, India.
EM nsasipriyaa@gmail.com
CR Abaynarh M., 2015, J THEORETICAL APPL I, V72
   Anoop V, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1370-x
   Arivazhagan S, 2021, J NATL SCI FOUND SRI, V49, P503, DOI 10.4038/jnsfsr.v49i4.9825
   Bhattacharya U, 2007, PROC INT CONF DOC, P511
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Devi SG, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3432330
   Gao YQ, 2019, COMPUT-AIDED CIV INF, V34, P755, DOI 10.1111/mice.12458
   github, TAM ART INT DAT TAK
   Gnanasivam P, 2021, 2021 SIXTH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P84, DOI [10.1109/WiSPNET51692.2021.9419451, 10.1109/WISPNET51692.2021.9419451]
   Hossain M.A., 2019, GLOBAL J COMPUTER SC, V9
   Joshi N, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P444, DOI 10.1109/IWFHR.2004.30
   Kavitha BR, 2022, J KING SAUD UNIV-COM, V34, P1183, DOI 10.1016/j.jksuci.2019.06.004
   Kaya Y, 2014, APPL MATH COMPUT, V243, P209, DOI 10.1016/j.amc.2014.05.128
   Kowsalya S, 2019, MULTIMED TOOLS APPL, V78, P25043, DOI 10.1007/s11042-019-7624-2
   Kundu S, 2020, NEURAL COMPUT APPL, V32, P7879, DOI 10.1007/s00521-019-04235-4
   Lakshmi ND., 2013, Silhouette extraction of a human body based on fusion of HOG and graph-cut segmentation in dynamic backgrounds
   Lincy RB, 2021, MULTIMED TOOLS APPL, V80, P5917, DOI 10.1007/s11042-020-09771-z
   Mustafa WA, 2018, J PHYS CONF SER, V1019, DOI 10.1088/1742-6596/1019/1/012023
   Naz S., 2018, PAK J STAT, V34
   Prakash A. Arun, 2018, 2018 International Conference on Intelligent Computing and Communication for Smart World (I2C2SW). Proceedings, P278, DOI 10.1109/I2C2SW45816.2018.8997144
   Raj MAR, 2020, SOFT COMPUT, V24, P1447, DOI 10.1007/s00500-019-03978-5
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Sattar D, 2021, ENG COMPUT-GERMANY, V37, P2389, DOI 10.1007/s00366-020-00951-x
   Seethalakshmi R., 2005, Journal of Zhejiang University (Science), V6A, P1297, DOI 10.1631/jzus.2005.A1297
   Shafana MS, 2021, J NATL SCI FOUND SRI, V49, P195, DOI 10.4038/jnsfsr.v49i2.9466
   Shanmugam K., 2021, Enhancing offline Tamil handwritten character recognition using optimal newton algorithm based deep convolution extreme learning model
   Shiftleft, HPLAB HANDWR DAT TAK
   Xue Y, 2023, IEEE T IND INFORM, V19, P6804, DOI 10.1109/TII.2022.3184700
   Xue Y, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10152792
   Yang CS, 2017, PATTERN RECOGN LETT, V100, P14, DOI 10.1016/j.patrec.2017.08.005
   Yazid H, 2013, J VIS COMMUN IMAGE R, V24, P926, DOI 10.1016/j.jvcir.2013.06.001
NR 32
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103878
DI 10.1016/j.jvcir.2023.103878
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N5CP3
UT WOS:001037192900001
DA 2024-07-18
ER

PT J
AU Pan, S
   Chen, SB
   Luo, B
AF Pan, Sen
   Chen, Si-Bao
   Luo, Bin
TI A super-resolution-based license plate recognition method for remote
   surveillance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE License plate recognition; Super-resolution; Remote surveillance; Neural
   network; Deep learning
AB With the continuous development of deep learning, neural networks have made great progress in license plate recognition (LPR). Nevertheless, there is still room to improve the performance of license plate recognition for low-resolution and relatively blurry images in remote surveillance scenarios. When it is difficult to enhance the recognition algorithm, we choose super-resolution (SR) to improve the quality of license plate images and thereby provide clearer input for the subsequent recognition stage. In this paper, we propose an automatic super-resolution license plate recognition (SRLPR) network which consists of four parts separately: license plate detection, character detection, single character super-resolution, and recognition. In the training stage, firstly, LP detection model needs to be trained alone and then its detection results will be used to successively train the three subsequent modules. During the test phase, for each input image, the network can get its LP number automatically. We also collect an applicable and challenging LPR dataset called SRLP, which is collected from real remote traffic surveillance. The experimental results demonstrate that our method achieves comprehensive quality of SR images and higher recognition accuracy compared with state-of-the-art methods. The SRLP dataset and the code for training and testing SRLPR network are available at https://pan.baidu.com/s/1vnhRa-c-dBj6jlfBZV5w4g.
C1 [Pan, Sen; Chen, Si-Bao; Luo, Bin] Anhui Univ, Sch Comp Sci & Technol, Prov Key Lab Multimodal Cognit Computat, MOE Key Lab ICSP, Hefei 230601, Peoples R China.
C3 Anhui University
RP Chen, SB (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Prov Key Lab Multimodal Cognit Computat, MOE Key Lab ICSP, Hefei 230601, Peoples R China.
EM sbchen@ahu.edu.cn
RI lu, bin/HPE-4790-2023
OI Chen, Si-Bao/0000-0003-1481-0162
FU NSFC Key Project of International (Regional) Cooperation and Exchanges
   [61860206004]; National Natural Science Foundation of China [61976004]
FX ** This work was supported in part by NSFC Key Project of International
   (Regional) Cooperation and Exchanges (No. 61860206004) and National
   Natural Science Foundation of China (No. 61976004) .
CR Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Azam S, 2016, J VIS COMMUN IMAGE R, V36, P172, DOI 10.1016/j.jvcir.2016.01.015
   Bai HL, 2004, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2004.1334387
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dun YJ, 2021, NEUROCOMPUTING, V443, P47, DOI 10.1016/j.neucom.2021.02.008
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Huang HQ, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P15, DOI 10.1109/FSKD.2008.230
   Jolicoeur-Martineau A., 2019, 7 INT C LEARNING REP
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   LEE ER, 1994, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.1994.413580
   Li H, 2018, IMAGE VISION COMPUT, V72, P14, DOI 10.1016/j.imavis.2018.02.002
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Raghunandan KS, 2018, IEEE T CIRC SYST VID, V28, P2276, DOI 10.1109/TCSVT.2017.2713806
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Silva SM, 2022, IEEE T INTELL TRANSP, V23, P5693, DOI 10.1109/TITS.2021.3055946
   Silva SM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102773
   Silva SM, 2018, LECT NOTES COMPUT SC, V11216, P593, DOI 10.1007/978-3-030-01258-8_36
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wang JL, 2018, NEUROCOMPUTING, V317, P149, DOI 10.1016/j.neucom.2018.08.023
   Wang L, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103300
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Xu ZB, 2018, LECT NOTES COMPUT SC, V11217, P261, DOI 10.1007/978-3-030-01261-8_16
   Yang Y, 2018, IET INTELL TRANSP SY, V12, P213, DOI 10.1049/iet-its.2017.0136
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 41
TC 3
Z9 3
U1 7
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103844
DI 10.1016/j.jvcir.2023.103844
EA MAY 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I3SH2
UT WOS:001002005100001
DA 2024-07-18
ER

PT J
AU Xu, SP
   Cheng, XH
   Luo, J
   Xiao, N
   Xiong, MH
   Zhou, CF
AF Xu, Shaoping
   Cheng, Xiaohui
   Luo, Jie
   Xiao, Nan
   Xiong, Minghai
   Zhou, Changfei
TI Dual-branch deep image prior for image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising Boosting performance Dual-branch architecture Two-stage
   denoising Basic images Unsupervised fusion
AB In this work, we propose a two-stage denoising approach, which includes generation and fusion stages. Specifically, in the generation stage, we first split the expanding path of the UNet backbone of the standard DIP (deep image prior) network into two branches, converting it into a Y-shaped network (YNet). Then we adopt the initial denoised images obtained with DAGL (dynamic attentive graph learning) and Restormer methods together with the given noisy image as the target images. Finally, we utilize the standard DIP online training routine to generate two complementary basic images, whose image quality is quite improved, with the help of a novel automatic iteration termination mechanism. In the fusion stage, we first split the contracting path of the standard UNet network into two branches for receiving the two basic images generated in the previous stage, and obtain a fused image as the final denoised image in a fully unsupervised manner. Extensive experimental results confirm that our method has a significant improvement over the standard DIP or other unsupervised methods, and outperforms recently proposed supervised denoising models. The noticeable performance improvement is attributed to the proposed hybrid strategy, i.e., we first adopt the supervised denoising methods to process the common content of images substantially, then utilize the unsupervised method to fine-tune the specific details. In other words, we take full advantage of the high performance of the supervised methods and the flexibility of the unsupervised methods.
C1 [Xu, Shaoping; Cheng, Xiaohui; Xiao, Nan; Xiong, Minghai; Zhou, Changfei] Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Jiangxi, Peoples R China.
   [Luo, Jie] Nanchang Univ, Affiliated Infect Dis Hosp, Nanchang 330006, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University
RP Xu, SP (corresponding author), Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Jiangxi, Peoples R China.
EM xushaoping@ncu.edu.cn
RI Xu, Shaoping/JAO-3891-2023
FU National Natural Science Foundation of China [62162043]
FX This work was partially supported by the National Natural Science
   Foundation of China under Grant 62162043.
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai HL, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3182-1
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Finn C, 2017, PR MACH LEARN RES, V70
   Gao SH, 2021, PROC CVPR IEEE, P8665, DOI 10.1109/CVPR46437.2021.00856
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Jaakko L., 2018, INT C MACH LEARN ICM
   Jung HC, 2021, IEEE T INFORM THEORY, V67, P4125, DOI 10.1109/TIT.2021.3070789
   Kingma D. P., 2014, arXiv
   Krull A, 2019, PROC CVPR IEEE, P2124, DOI 10.1109/CVPR.2019.00223
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Mou C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4308, DOI 10.1109/ICCV48922.2021.00429
   Pang TY, 2021, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR46437.2021.00208
   Ren C, 2021, PROC CVPR IEEE, P8592, DOI 10.1109/CVPR46437.2021.00849
   Ronneberger O., 2015, PATTERN RECOGN, V2015, p1505.04597, DOI 10.1007/978-3-319-24574-4_28
   Ulyanov D, 2020, INT J COMPUT VISION, V128, P1867, DOI 10.1007/s11263-020-01303-4
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yue Z., 2019, C NEURAL INFORM PROC
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang K, 2022, IEEE T PATTERN ANAL, V44, P6360, DOI 10.1109/TPAMI.2021.3088914
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2021, IEEE T IMAGE PROCESS, V30, P6255, DOI 10.1109/TIP.2021.3093396
   Zhou L, 2020, IEEE T IMAGE PROCESS, V29, P694, DOI 10.1109/TIP.2019.2928144
NR 28
TC 1
Z9 1
U1 9
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103821
DI 10.1016/j.jvcir.2023.103821
EA APR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M0DF8
UT WOS:001026881800001
DA 2024-07-18
ER

PT J
AU Sun, KX
   Zhang, J
   Zhang, P
   Yuan, KX
   Li, G
AF Sun, Kexin
   Zhang, Jie
   Zhang, Peng
   Yuan, Kexin
   Li, Geng
TI TsrNet: A two-stage unsupervised approach for clothing region-specific
   textures style transfer?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object-level fashion texture transfer; TsrNet; Mask-GAN; Drf-module;
   Texture structure loss
ID GAN
AB Style transfer has been widely applied in the fashion industry for design assistance. This paper focuses on object-level image style transfer for specific texture regions on fashion images. The current methods mostly utilize extra conditional inputs to obtain regions of interest in fashion images, which take extensive time and cost to prepare these data. To address this issue, we propose a two-stage unsupervised approach named TsrNet for clothing texture style transfer between images. Firstly, we construct a network named Mask-GAN to unsupervisedly split out the clothing texture region. Secondly, we improve CycleGAN to interchange the texture on specific target regions of the two images. Specifically, considering the diversity of fashion texture, we construct a multiscale module (Drf-module) with dynamic perceptual fields and design an image gradient -based texture structure loss (GTS) to perform texture transfer. Qualitative and quantitative experimental results show the effectiveness of our algorithm for clothing-specific region style transfer.
C1 [Sun, Kexin; Zhang, Jie; Zhang, Peng; Yuan, Kexin; Li, Geng] Donghua Univ, Inst Artificial Intelligence, Shanghai 201620, Peoples R China.
   [Sun, Kexin; Yuan, Kexin; Li, Geng] Donghua Univ, Coll Mech Engn, Shanghai 201620, Peoples R China.
C3 Donghua University; Donghua University
RP Zhang, J (corresponding author), Donghua Univ, Inst Artificial Intelligence, Shanghai 201620, Peoples R China.
EM DHUSun6@outlook.com; mezhangjie@dhu.edu.cn
OI Sun, KeXin/0000-0001-5277-0304
FU National Natural Science Foundation of China [52005099]; National Key R
   and D Program of China [2019YFB1706300]; Shanghai Frontier Science
   Research Center for Modern Textiles, Donghua University, China;
   Fundamental Research Funds for the Central Universities, China
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 52005099, National Key R and D Program of China under
   Grant No. 2019YFB1706300, Shanghai Frontier Science Research Center for
   Modern Textiles, Donghua University, China, and the Fundamental Research
   Funds for the Central Universities, China.
CR Gatys LA, 2016, Arxiv, DOI [arXiv:1606.05897, DOI 10.48550/ARXIV.1606.05897]
   Gatys LA, 2015, Arxiv, DOI arXiv:1508.06576
   Benjdira B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111369
   Bingyang Niu, 2021, 2021 6th International Symposium on Computer and Information Processing Technology (ISCIPT), P486, DOI 10.1109/ISCIPT53667.2021.00104
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cho JH, 2021, PROC CVPR IEEE, P16789, DOI 10.1109/CVPR46437.2021.01652
   Frigo O, 2016, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2016.66
   Gatys LA, 2015, ADV NEUR IN, V28
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han JL, 2021, IEEE COMPUT SOC CONF, P746, DOI 10.1109/CVPRW53098.2021.00084
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jandial Surgan, 2020, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P2171, DOI 10.1109/WACV45572.2020.9093458
   Jeong Y., HANBOK DESIGN IMPROV
   Jiang SH, 2022, IEEE T NEUR NET LEAR, V33, P4538, DOI 10.1109/TNNLS.2021.3057892
   Jo SY, 2019, INT CONF BIG DATA, P664, DOI 10.1109/bigcomp.2019.8679117
   Kim J, 2020, Arxiv, DOI [arXiv:1907.10830, DOI 10.48550/ARXIV.1907.10830]
   Kim S, 2021, IEEE ACCESS, V9, P7930, DOI 10.1109/ACCESS.2021.3049637
   Kim T, 2017, PR MACH LEARN RES, V70
   Lee S., 2021, AAAI C ARTIF INTELL, V2
   Li S., 2021, INT SYMP NEXTGEN, V32, P1
   Liu LL, 2019, NEUROCOMPUTING, V341, P156, DOI 10.1016/j.neucom.2019.03.011
   Liu Y., CONTRASTIVE LEARNING
   Liu Y, 2019, IEEE T MULTIMEDIA, V21, P2209, DOI 10.1109/TMM.2019.2897897
   [刘哲良 Liu Zheliang], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P1283
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mejjati YA, 2018, ADV NEUR IN, V31
   Ning Jia, 2021, 2021 International Conference on Computer Engineering and Application (ICCEA), P1, DOI 10.1109/ICCEA53728.2021.00008
   Pandey N, 2020, NEUROCOMPUTING, V414, P356, DOI 10.1016/j.neucom.2020.07.092
   Park Taesung, 2020, EUR C COMP VIS, P319, DOI [DOI 10.1007/978-3-030-58545-719, DOI 10.1007/978-3-030-58545-7_19]
   Peng DL, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108214
   Pur SF, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P146, DOI [10.1109/ubmk50275.2020.9219541, 10.1109/UBMK50275.2020.9219541]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sbai O., 2018, P EUROPEAN C COMPUTE
   Shao MW, 2021, KNOWL-BASED SYST, V225, DOI 10.1016/j.knosys.2021.107122
   Tang HY, 2021, ISME J, V15, P3084, DOI 10.1038/s41396-021-00990-2
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang RM, 2022, COMPUT COMMUN, V181, P320, DOI 10.1016/j.comcom.2021.10.022
   Wazarkar S, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106517
   Yeo SF, 2022, TECHNOL FORECAST SOC, V177, DOI 10.1016/j.techfore.2022.121551
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yuan LC, 2019, IEEE ACCESS, V7, P30637, DOI 10.1109/ACCESS.2019.2903543
   Yue Yang, 2021, 2021 2nd International Conference on Artificial Intelligence and Education (ICAIE), P58, DOI 10.1109/ICAIE53562.2021.00019
   Yueming Wang, 2021, 2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC), P1221, DOI 10.1109/IMCEC51613.2021.9482055
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
NR 49
TC 1
Z9 1
U1 4
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103778
DI 10.1016/j.jvcir.2023.103778
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9I9KT
UT WOS:000939820400001
DA 2024-07-18
ER

EF