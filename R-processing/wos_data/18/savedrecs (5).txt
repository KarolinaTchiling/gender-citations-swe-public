FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Chen, Y
   Yuan, J
   Li, ZY
   Wu, YQ
   Nouioua, M
   Xie, GQ
AF Chen, Ying
   Yuan, Jin
   Li, Zhiyong
   Wu, Yiqiang
   Nouioua, Mourad
   Xie, Guoqi
TI Person re-identification based on re-ranking with expanded k-reciprocal
   nearest neighbors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Re-ranking; Expanded k-reciprocal neighbors;
   Rank list similarity
ID FUSION
AB In this paper, a robust re-ranking method based on expanded k-reciprocal neighbors is proposed. Our method assumes that if a gallery image is the probe image of the expanded k-reciprocal nearest neighbors, these images are more likely to be of the same person. Specifically, given a probe image, we replace the probe with its expanded reciprocal nearest neighbor and the final distance is computed by the mean value of the corresponding neighbor set. The proposed method is unsupervised, automatic and applicable to other person re-identification problems. Moreover, our method can perform well even with a simple direct rank list where the Euclidean distance was used to compute the distances between the images. Experiments on many public datasets demonstrate the effectiveness and robustness of our re-ranking method. The proposed method achieves 4.9% improvement in Rank-1 on the CUHK03 dataset and a significant improvement of 18.6% in mAP on the Duke dataset. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chen, Ying; Yuan, Jin; Li, Zhiyong; Wu, Yiqiang; Nouioua, Mourad; Xie, Guoqi] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
   [Chen, Ying; Yuan, Jin; Li, Zhiyong; Wu, Yiqiang; Nouioua, Mourad; Xie, Guoqi] Key Lab Embedded & Network Comp Hunan Prov, Changsha, Hunan, Peoples R China.
C3 Hunan University
RP Li, ZY (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
EM zhiyong.li@hnu.edu.cn
RI li, zy/HZM-1892-2023; wu, yi/JEP-1581-2023; Zhang,
   Yanchao/JMB-7717-2023; Wang, Zejun/KBB-8454-2024
FU National Natural Science Foundation of China [61672215, U1613209]
FX This work was partially supported by the National Natural Science
   Foundation of China (No. 61672215, U1613209).
CR Ainam Jean Paul, 2018, ARXIV E PRINTS
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], 2013, IEEE INT C IM PROC D
   [Anonymous], 2007, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2007.382970
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Bai S., 2017, COMPUT VISION PATT R
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   García J, 2016, J VIS COMMUN IMAGE R, V38, P115, DOI 10.1016/j.jvcir.2016.02.009
   Geng YB, 2015, J VIS COMMUN IMAGE R, V29, P89, DOI 10.1016/j.jvcir.2015.02.001
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Karanam S., 2018, COMPUT VISION PATTER
   Li JY, 2017, J SOIL SEDIMENT, V17, P1715, DOI 10.1007/s11368-016-1620-1
   Li W, 2016, J VIS COMMUN IMAGE R, V40, P67, DOI 10.1016/j.jvcir.2016.06.009
   Li ZY, 2015, VISUAL COMPUT, V31, P1319, DOI 10.1007/s00371-014-1014-6
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu CX, 2013, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2013.62
   Nai K., 2018, IEEE T IMAGE PROCESS
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Roth P. M., 2012, IEEE C COMP VIS PATT
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schroff F, 2011, IEEE I CONF COMP VIS, P2494, DOI 10.1109/ICCV.2011.6126535
   Shen X., 2012, IEEE INT C COMP VIS
   Wang HX, 2016, LECT NOTES COMPUT SC, V9908, P405, DOI 10.1007/978-3-319-46493-0_25
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yu R., 2017, BRIT MACH VIS C
   Zheng Liang, 2016, ARXIV
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 41
TC 11
Z9 11
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 486
EP 494
DI 10.1016/j.jvcir.2018.11.044
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100047
DA 2024-07-18
ER

PT J
AU Zheng, LL
   Zhang, Y
   Thing, VLL
AF Zheng, Lilei
   Zhang, Ying
   Thing, Vrizlynn L. L.
TI A survey on image tampering and its detection in real-world photos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image tampering detection; Image forgery detection; Image forensics;
   Image copy-move detection; Image splicing detection
ID FORGERY DETECTION ALGORITHM; EXPOSING DIGITAL FORGERIES; SPLICING
   DETECTION; OBJECT REMOVAL; DCT; LOCALIZATION; FORENSICS; FUSION; MODEL;
   SCALE
AB Editing a real-world photo through computer software or mobile applications is one of the easiest things one can do today before sharing the doctored image on one's social networking sites. Although most people do it for fun, it is suspectable if one concealed an object or changed someone's face within the image. Before questioning the intention behind the editing operations, we need to first identify how and which part of the image has been manipulated. It therefore demands automatic tools for identifying the intrinsic difference between authentic images and tampered images. This survey provides an overview on typical image tampering types, released image tampering datasets and recent tampering detection approaches. It presents a distinct perspective to rethink various assumptions of tampering clues behind different detection approaches. And this further encourages the research community to develop general tampering localization methods in the future instead of adhering to single-type tampering detection. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zheng, Lilei; Zhang, Ying; Thing, Vrizlynn L. L.] Inst Infocomm Res, Cyber Secur & Intelligence, Singapore, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Zhang, Y (corresponding author), Inst Infocomm Res, Cyber Secur & Intelligence, Singapore, Singapore.
EM zhangy@i2r.a-star.edu.sg
FU National Research Foundation, Prime Minister's Office, Singapore, under
   its National Cybersecurity RD Programme [NRF2014NCR-NCR001-034]
FX This material is based on research work supported by the National
   Research Foundation, Prime Minister's Office, Singapore, under its
   National Cybersecurity R&D Programme Award No. NRF2014NCR-NCR001-034.
CR Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2013, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2013-8
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   Amerini I, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-18
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], P SPIE
   [Anonymous], 2004, INFORM HIDING
   [Anonymous], P WIFS
   [Anonymous], ARXIV170607842
   [Anonymous], SITTING PRETTY POSTM
   [Anonymous], P WIFS
   [Anonymous], LECT NOTES COMPUT 1
   [Anonymous], 2014, 14041100 ARXIV
   [Anonymous], P ISM
   [Anonymous], 2010, IEEE T IMAGE PROCESS
   [Anonymous], P ICMLC
   [Anonymous], P CVPR
   [Anonymous], P ISCAS
   [Anonymous], 170902016 ARXIV
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], P WIFS
   [Anonymous], P ICIP
   [Anonymous], 2015, 2015 IEEE INT C MULT
   [Anonymous], 2013, ADOBE PHOTOSHOP CC C
   [Anonymous], 2004, TR2004518 DARTM COLL
   [Anonymous], IFIP INT C DIG FOR
   [Anonymous], ARXIV170601788
   [Anonymous], ART INT OPP IMPL FUT
   [Anonymous], P ELMAR
   [Anonymous], 2016, MAGAZINE MTSTO
   [Anonymous], 2008, BECOMING OURSELVES A
   [Anonymous], P ICASSP
   [Anonymous], COMPUT GRAPH
   [Anonymous], 2016, CRYPTOL INF SEC SER, DOI DOI 10.3233/978-1-61499-617-0-1
   [Anonymous], P IPCV
   [Anonymous], 170701221 ARXIV
   [Anonymous], 2010, IEEE T INF FOREN SEC, DOI DOI 10.1109/TIFS.2010.2078506
   [Anonymous], P ICASSP
   [Anonymous], P ICSIP
   [Anonymous], P ICIS
   [Anonymous], 2018, MACHINE LEARNING YEA
   [Anonymous], P PACIIA
   [Anonymous], P DFRWS CIT
   [Anonymous], FAC SWAP BOOTH PHOTO
   [Anonymous], ISRN SIGNAL PROCESS
   [Anonymous], 2019, ADV HUMAN ERROR RELI, DOI DOI 10.1007/978-3-319-94391-6_1
   [Anonymous], 180309179 ARXIV
   [Anonymous], ARXIV170304615
   [Anonymous], P ICITIS
   [Anonymous], KERR FOND 2004 EL PH
   [Anonymous], OCEANS IEEE
   [Anonymous], P CVPR
   [Anonymous], 2004, DATA SET AUTHENTIC S
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], 2000, Digital Watermarking
   [Anonymous], P AAAI
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Battiato S, 2016, COMPUTER SYSTEMS AND TECHNOLOGIES, COMPSYSTECH'16, P5, DOI 10.1145/2983468.2983470
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen W., 2007, P SPIE
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Conotter V., 2014, Proceedings of the 2014 International ACM Workshop on Crowdsourcing for Multimedia, CrowdMM '14, P49
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dang TT, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1019, DOI 10.1109/GlobalSIP.2014.7032275
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Dong J., 2008, IWDW, P76
   El-Alfy ESM, 2015, PATTERN ANAL APPL, V18, P713, DOI 10.1007/s10044-014-0396-4
   Fan Y., 2016, J INFORM HIDING MULT, V7, P399
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773
   Fontani M, 2013, IEEE T INF FOREN SEC, V8, P593, DOI 10.1109/TIFS.2013.2248727
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   Gallagher A. C., 2008, P CVPRW, P1
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Geng C, 2009, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2009.5413956
   Gloe T., 2010, P SAC 10 2010 ACM S, P1584
   Goh J, 2015, INT J ELECTRON SECUR, V7, P76, DOI 10.1504/IJESDF.2015.067996
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Han JG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023031
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsiao DY, 2005, INT WORK SYS APPR D, P264, DOI 10.1109/SADFE.2005.8
   Hsu Y.F., 2006, P ICME
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hussain M, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015400163
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Junwen Wang, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P907, DOI 10.1109/MINES.2010.193
   Kee E., 2010, P WIFS, P1
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Koehn Philipp, 2004, EMNLP
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P3050, DOI 10.1109/TIFS.2017.2730822
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Li HD, 2012, IEEE IMAGE PROC, P241, DOI 10.1109/ICIP.2012.6466840
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li XH, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-190
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Lin ZC, 2005, PROC CVPR IEEE, P1087
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lukas J., 2006, P SPIE, V6072, P15
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Luo WQ, 2006, INT C PATT RECOG, P746
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Magri L, 2014, PROC CVPR IEEE, P3954, DOI 10.1109/CVPR.2014.505
   Mahalakshmi SD, 2012, DIGIT INVEST, V8, P215, DOI 10.1016/j.diin.2011.06.004
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Moghaddasi Z, 2014, SCI WORLD J, DOI 10.1155/2014/606570
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Nightingale SJ, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0067-2
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan XY, 2010, INT CONF ACOUST SPEE, P1706, DOI 10.1109/ICASSP.2010.5495482
   Park TH, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0136-3
   Peng B., 2017, P CVPRW, P1
   Peng B, 2017, IEEE T INF FOREN SEC, V12, P479, DOI 10.1109/TIFS.2016.2623589
   Pomari T, 2018, IEEE IMAGE PROC, P3788, DOI 10.1109/ICIP.2018.8451227
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Saleh SQ, 2013, LECT NOTES COMPUT SC, V8034, P416, DOI 10.1007/978-3-642-41939-3_40
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P152, DOI 10.1016/j.cag.2017.08.014
   Shi Yun Q., 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P158
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Su B, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-7
   Wall M. E., 2003, PRACTICAL APPROACH M, P91, DOI [10.1007/0-306-47815-35, DOI 10.1007/0-306-47815-3_5]
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Wang W, 2009, LECT NOTES COMPUT SC, V5703, P308, DOI 10.1007/978-3-642-03688-0_27
   Wang W, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND SCIENTIFIC MANAGEMENT, VOLS 1-2, P120
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Xuemin Wu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P600, DOI 10.1109/MINES.2011.135
   Zampoglou M., 2015, P ICMEW, P1
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhang DY, 2018, MULTIMED TOOLS APPL, V77, P11823, DOI 10.1007/s11042-017-4829-0
   Zhang W., 2017, INT J SOCIAL BEHAV E, V11, P231, DOI [10.5281/zenodo.1128985, DOI 10.5281/ZENODO.1128985]
   Zhang YJ, 2015, SECUR COMMUN NETW, V8, P2386, DOI 10.1002/sec.721
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
   Zhao YQ, 2013, OPTIK, V124, P2487, DOI 10.1016/j.ijleo.2012.08.018
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 194
TC 71
Z9 75
U1 9
U2 72
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 380
EP 399
DI 10.1016/j.jvcir.2018.12.022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100038
DA 2024-07-18
ER

PT J
AU Zhang, HB
AF Zhang, Haibo
TI Geometric discriminative deep features for traffic image analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep features; Traffic image analysis
AB Traffic image analysis is an important application in intelligent transportation. For local features' robustness to image variances, such as scale changes and occlusions, they are widely used in image classification. However, how to integrate these local features for modeling traffic images optimally is still a crucial challenge. In this paper, a novel deep learning method, geometric discriminative feature fusion (GDFF), is proposed to tackle this problem. First, we use a variety of data sets to train the general convolutional neural network (CNN), which is used to extract the features of the training and test set after deep level. Deep architecture makes it possible for people to learn more abstract and internal features that are robust to changes in viewpoint and illumination. It can fuse image geometric related local features, such as local regions' RGB histograms, into high level discriminative features, which can be used for better classifying complex scene images. Our framework's central task is to build a structural kernel, called discriminative topological kernel. Firstly, we segment the traffic images into several regions and use a region connected graph (RCG) to model regions location relationships. We use frequent sub graph mining algorithm to mine all frequent sub structures (topologies) occurs in all training RCGs. And a selection algorithm is designed to select the k qualified topologies from the entire mined frequent topologies. We call these selected topologies geometric feature fusers, which are both high discriminative and low redundant structures in all training RCGs. Finally, given a pair of RCGs and to each geometric fuser, we extract all pairs of sub graphs sharing the same topology and calculate distance between them. All k distances are accumulated for the final kernel. The experimental result demonstrates the effectiveness of our method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Haibo] North China Univ Technol, Beijing, Peoples R China.
C3 North China University of Technology
RP Zhang, HB (corresponding author), North China Univ Technol, Beijing, Peoples R China.
EM zhanghaibo1778@126.com
RI Zhang, Haibo/HLP-9266-2023
FU Cross disciplinary cooperation of Beijing Science and Technology Star
   Program
FX Our thanks to ACM SIGCHI for allowing us to modify templates they had
   developed. This work was supported by Cross disciplinary cooperation of
   Beijing Science and Technology Star Program.
CR [Anonymous], P CVPR
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu Xiao, 2013, P CVPR
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Rao WW, 2017, IEEE ICC
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang Luming, 2015, FINE GRAINED IMAGE C
   Zhang Luming, 2014, PERCEPTION GUIDED MU
   Zhang Luming, 2009, FEATURE SELECTION FA
   Zhang Luming, 2015, BIOL INSPIRED MEDIA
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
NR 27
TC 2
Z9 2
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 163
EP 171
DI 10.1016/j.jvcir.2018.10.029
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400019
DA 2024-07-18
ER

PT J
AU Hu, JW
   Lam, KM
   Lou, P
   Liu, Q
   Deng, WP
AF Hu, Jiwei
   Lam, Kin-Man
   Lou, Ping
   Liu, Quan
   Deng, Wupeng
TI Can a machine have two systems for recognition, like human beings?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image annotation; Multi-labeling; Hierarchical tree structure;
   Feature-pool selection
ID IMAGE
AB Artificial Intelligence has attracted much of researchers' attention in recent years. A question we always ask is: "Can machines replace human beings to some extent?" This paper aims to explore the knowledge learning for an image-annotation framework, which is an easy task for humans but a tough task for machines. This paper's research is based on an assumption that machines have two systems of thinking, each of which handles the labels of images at different abstract levels. Based on this, a new hierarchical model for image annotation is introduced. We explore not only the relationships between the labels and the features used, but also the relationships between labels. More specifically, we divide labels into several hierarchies for efficient and accurate labeling, which are constructed using our Associative Memory Sharing method, proposed in this paper. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Hu, Jiwei; Lou, Ping; Liu, Quan; Deng, Wupeng] Wuhan Univ Technol, Sch Informat Engn, Wuhan, Hubei, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Wuhan University of Technology; Hong Kong Polytechnic University
RP Liu, Q (corresponding author), Wuhan Univ Technol, Sch Informat Engn, Wuhan, Hubei, Peoples R China.
EM enkmlam@polyu.edu.hk; quanliu@whut.edu.cn
RI Hu, Jiwei/ISV-4693-2023
FU National Natural Science Foundation of China [51475347, 61401318]
FX This research is fully supported by the National Natural Science
   Foundation of China (Grant Nos. 51475347 and 61401318).
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2007, ICCV
   [Anonymous], 2010, CVPR
   [Anonymous], P 2016 ACM INT C MUL
   [Anonymous], 2016, CVPR
   [Anonymous], ICLR
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2009, ICIVR
   [Anonymous], 2016, CVPR
   [Anonymous], NIPS
   [Anonymous], PAMI
   [Anonymous], IEEE J SEL TOP A
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], P UNC ART INT
   [Anonymous], 2016, CVPR
   [Anonymous], P AS PAC INF SIGN PR
   [Anonymous], J MACH LEARN RES
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JW, 2013, PATTERN RECOGN, V46, P936, DOI 10.1016/j.patcog.2012.09.010
   Hu JW, 2010, IEEE IMAGE PROC, P2349, DOI 10.1109/ICIP.2010.5653434
   Kahneman Daniel, Thinking, fast and slow
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Kim Seyoung, 2010, ICML, P543
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Monay F., 2004, P 12 ANN ACM INT C M, P348, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Su JH, 2011, IEEE T MULTIMEDIA, V13, P530, DOI 10.1109/TMM.2011.2129502
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang MF, 2017, J VIS COMMUN IMAGE R, V48, P310, DOI 10.1016/j.jvcir.2017.07.005
   Wei Yan-bao, 2014, Automation & Instrumentation, V29, P1
   Wu F., 2010, Proceedings of the International Conference on Multimedia (MM'10), P15, DOI DOI 10.1145/1873951.1873957
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhou Dengyong, 2006, 19 INT C NEURAL INFO, V19, P1601
   Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204
   Zhu J, 2015, J VIS COMMUN IMAGE R, V27, P44, DOI 10.1016/j.jvcir.2015.01.003
NR 46
TC 0
Z9 0
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 275
EP 286
DI 10.1016/j.jvcir.2018.09.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500027
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Su, YT
   Bai, X
   Li, W
   Jing, PG
   Zhang, J
   Liu, J
AF Su, Yuting
   Bai, Xu
   Li, Wu
   Jing, Peiguang
   Zhang, Jing
   Liu, Jing
TI Graph regularized low-rank tensor representation for feature selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised feature selection; Low-rank tensor representation; Graph
   embedding; Subspace clustering
ID RECOGNITION; FRAMEWORK
AB Recently, considerable efforts have been made in feature selection to improve the original feature subspace. In this paper, we proposed a graph regularized low-rank tensor representation (GRLTR) for feature selection. We jointly incorporated the low-rank representation and the graph embedding into a unified learning framework to preserve the intrinsic global low-dimension structure and local geometrical structure of data together. According to the wide presence of multidimensional data, our proposed framework is based on tensor, which can faithfully maintain the information. To improve the performance of specific clustering task, we employed the idea of embedded-based feature selection into our model for optimizing the feature representation and clustering result simultaneously. Experimental results on six available datasets suggest our proposed approach produces superior performances compared with several state-of-the-art methods. (C) 2018 Published by Elsevier Inc.
C1 [Li, Wu] Tianjin Univ, Sch Educ, Tianjin, Peoples R China.
   [Su, Yuting; Bai, Xu; Jing, Peiguang; Zhang, Jing; Liu, Jing] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Li, W (corresponding author), Tianjin Univ, Sch Educ, Tianjin, Peoples R China.
EM liwu@tju.edu.cn
RI Liu-Zeng, Jing/F-8582-2011
OI Jing, Peiguang/0000-0003-2648-7358
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], INT JOINT C ART INT
   BELHUMEUR PN, 1996, FISHERFACES RECOGNIT
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cai D., 2010, KDD, P333
   Cai D, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1010
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Fan B, 2016, IEEE IMAGE PROC, P3628, DOI 10.1109/ICIP.2016.7533036
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I
   Li J., 2018, IEEE T CYBERNET, P1
   Li Z., 2012, PROC C ASS ADV ARTIF, P1026, DOI DOI 10.1609/AAAI.V26I1.8289
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu XY, 2016, INT CONF ACOUST SPEE, P2529, DOI 10.1109/ICASSP.2016.7472133
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871
   Nene S.A., 1996, CUS00596 COL U
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Qian F., 2017, EXACT 3D SEISMIC DAT
   Shi L, 2014, IEEE DATA MINING, P977, DOI 10.1109/ICDM.2014.58
   Signoretto M, 2014, MACH LEARN, V94, P303, DOI 10.1007/s10994-013-5366-3
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Xiang Wang, 2017, ACM Transactions on Information Systems, V36, DOI 10.1145/3052774
   Xiao H., 2017, ARXIV170807747
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Xue NN, 2017, EUR SIGNAL PR CONF, P1185, DOI 10.23919/EUSIPCO.2017.8081395
   Xue S., 2017, ARXIV171200704
   Yang YN, 2015, IEEE SIGNAL PROC LET, V22, P1633, DOI 10.1109/LSP.2015.2420592
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Yin M, 2015, IEEE T IMAGE PROCESS, V24, P4918, DOI 10.1109/TIP.2015.2472277
   Zhang HY, 2014, NEUROCOMPUTING, V145, P369, DOI 10.1016/j.neucom.2014.05.022
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhao Q, 2014, PR MACH LEARN RES, V32, P55
   Zhou GX, 2012, IEEE SIGNAL PROC LET, V19, P523, DOI 10.1109/LSP.2012.2205237
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 56
TC 7
Z9 7
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 234
EP 244
DI 10.1016/j.jvcir.2018.09.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500023
DA 2024-07-18
ER

PT J
AU Lee, JT
   Kim, HU
   Lee, C
   Kim, CS
AF Lee, Jun-Tae
   Kim, Han-Ul
   Lee, Chul
   Kim, Chang-Su
TI Photographic composition classification and dominant geometric element
   detection for outdoor scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; Photographic composition; Composition element
   detection; Geometric element detection; Sky detection; Rule of thirds
ID CONTRAST ENHANCEMENT; RANDOM-WALK; IMAGE; REPRESENTATION; MODEL
AB Despite the practical importance of photographic composition for improving or assessing the aesthetical quality of photographs, only a few simple composition rules have been considered for its classification. In this work, we propose novel techniques to classify photographic composition rules of outdoor scenes and detect dominant geometric elements, called composition elements, for each composition class. Specifically, we first categorize composition rules of outdoor photographs into nine classes: RoT, center, horizontal, symmetric, diagonal, curved, vertical, triangle, and pattern. Then, we develop a photographic composition classification algorithm using a convolutional neural network (CNN). To train the CNN, we construct a photographic composition database, which is publicly available. Finally, for each composition class, we propose an effective scheme to locate composition elements, i.e., bounding boxes for main subjects, leading lines, axes of symmetry, triangles, and sky regions. Extensive experimental results demonstrate that the proposed algorithm classifies composition classes reliably and detects composition elements accurately.
C1 [Lee, Jun-Tae; Kim, Han-Ul; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Lee, Chul] Pukyong Natl Univ, Dept Comp Engn, Busan, South Korea.
C3 Korea University; Pukyong National University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM jtlee@mcl.korea.ac.kr; hanulkim@mcl.korea.ac.kr; chullee@pknu.ac.kr;
   changsukim@korea.ac.kr
RI Lee, Chul/W-3762-2019
OI Lee, Chul/0000-0001-9329-7365; Kim, Chang-Su/0000-0002-4276-1831
FU Ministry of Science and ICT (MSIT), Korea, under the Information
   Technology Research Center (ITRC) support program
   [IITP-2018-2016-0-00464]; National Research Foundations of Korea (NRF)
   grant - Korea government (MSIP) [NRF-2015R1A2A1A10055037,
   NRF-2018R1A2B3003896]
FX This work was supported partly by the Ministry of Science and ICT
   (MSIT), Korea, under the Information Technology Research Center (ITRC)
   support program (IITP-2018-2016-0-00464) supervised by the Institute for
   Information & communications Technology Promotion, and the National
   Research Foundations of Korea (NRF) grant funded by the Korea government
   (MSIP) (Nos. NRF-2015R1A2A1A10055037 and NRF-2018R1A2B3003896).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2011, P CVPR 2011 COL SPRI
   Bhattacharya S., 2010, P 18 ACM INT C MULTI, P271
   Chang YY, 2009, IEEE I CONF COMP VIS, P2225, DOI 10.1109/ICCV.2009.5459470
   Cheng DL, 2015, IEEE I CONF COMP VIS, P298, DOI 10.1109/ICCV.2015.42
   Cheng DL, 2014, J OPT SOC AM A, V31, P1049, DOI 10.1364/JOSAA.31.001049
   Chian-Li Wen, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1447, DOI 10.1109/ICMLC.2012.6359578
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Goodale Mark, 2007, PHOTOGRAPHERS EYE CO, P1
   Guo YW, 2012, COMPUT GRAPH FORUM, V31, P2193, DOI 10.1111/j.1467-8659.2012.03212.x
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He SQ, 2018, IEEE T MULTIMEDIA, V20, P496, DOI 10.1109/TMM.2017.2740026
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kim HU, 2016, LECT NOTES COMPUT SC, V9910, P851, DOI 10.1007/978-3-319-46466-4_51
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Koh YJ, 2017, IEEE I CONF COMP VIS, P3621, DOI 10.1109/ICCV.2017.389
   Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Krages B., 2005, Photography: the art of composition
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Lee HJ, 2017, IEEE T MULTIMEDIA, V19, P1921, DOI 10.1109/TMM.2017.2687759
   Lee JT, 2017, IEEE I CONF COMP VIS, P3249, DOI 10.1109/ICCV.2017.350
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long Mai, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P91, DOI 10.1109/ISM.2011.23
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Nam H., 2016, P IEEE C COMP VIS PA, P1794
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliveira M, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2375642
   Rawat YS, 2018, IEEE T MULTIMEDIA, V20, P754, DOI 10.1109/TMM.2017.2750420
   Rawat YS, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808199
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   She JY, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P490, DOI 10.1109/ACPR.2011.6166623
   Su HH, 2012, IEEE T MULTIMEDIA, V14, P833, DOI 10.1109/TMM.2012.2186123
   Tao LT, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531374
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Tong HH, 2006, IEEE DATA MINING, P613
   Tsai YH, 2015, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.2015.7298673
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wang YT, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2770879
   Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 67
TC 21
Z9 22
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 91
EP 105
DI 10.1016/j.jvcir.2018.05.018
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100009
DA 2024-07-18
ER

PT J
AU Ren, YZ
   Chen, C
   Li, SW
   Kuo, CCJ
AF Ren, Yuzhuo
   Chen, Chen
   Li, Shangwen
   Kuo, C-C Jay
TI Context-Assisted 3D (C3D) Object Detection from RGB-D Images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D Object Detection; Indoor Scene Understanding; Convolutional Neural
   Network; Conditional Random Field
ID SCENE
AB We study the problem of 3D object detection from RGB-D images so as to achieve localization (i.e., producing a bounding box around the object) and classification (i.e., determining the object category) simultaneously. Its challenges arise from high intra-class variability, illumination change, background clutter and occlusion. To solve this problem, we propose a novel solution that integrates the 2D information (RGB images), the 3D information (RGB-D images) and the object/scene context information together, and call it the Context-Assisted 3D (C3D) method. In the proposed C3D method, we first use a convolutional neural network (CNN) to jointly detect a 3D object in a scene and its scene category. Then, we improve the detection result furthermore with a Conditional Random Field (CRF) model that incorporates the object potential, the scene potential, the scene/object context, the object/object context, and the room geometry. Extensive experiments are conducted to demonstrate that the proposed C3D method achieves the state-of-the-art performance for 3D object detection against the SUN RGB-D benchmark dataset.
C1 [Ren, Yuzhuo; Chen, Chen; Li, Shangwen; Kuo, C-C Jay] Univ Southern Calif, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Ren, YZ (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.
EM yuzhuore@usc.edu; chen80@usc.edu; shangwel@usc.edu; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 150408083 ARXIV
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-7_8
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], BIG VISUAL DATA ANAL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 2015, LECT NOTES BUS INF P
   [Anonymous], 160304922 ARXIV
   [Anonymous], 2016, P AS C COMP VIS
   [Anonymous], MARVIN MINIMALIST GP
   [Anonymous], BIG VISUAL DATA ANAL
   [Anonymous], 14091556 ARXIV
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Bappy JH, 2016, INT C PATT RECOG, P3386, DOI 10.1109/ICPR.2016.7900157
   Bo L., 2013, EXPT ROBOTICS VOLUME, P387, DOI DOI 10.1007/978-3-319-00065-7
   Chen C, 2017, ASIAPAC SIGN INFO PR, P550, DOI 10.1109/APSIPA.2017.8282094
   Chen Chen., 2016, Big Visual Data Analysis, P65
   Chen Chen., 2016, Big Visual Data Analysis: Scene Classification and Geometric Labeling
   Chen XZ, 2015, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2015.7298874
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gupta S, 2015, PROC CVPR IEEE, P4731, DOI 10.1109/CVPR.2015.7299105
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298
   Lazebnik Svetlana, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2380, DOI 10.1109/CVPRW.2009.5206690
   Li SW, 2018, IEEE WINT CONF APPL, P1774, DOI 10.1109/WACV.2018.00197
   Li SW, 2017, IEEE T PATTERN ANAL, V39, P2423, DOI 10.1109/TPAMI.2017.2651818
   Li SY, 2017, IEEE WINT CONF APPL, P979, DOI 10.1109/WACV.2017.114
   Li Y, 2008, LECT NOTES COMPUT SC, V5305, P409
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Murphy K, 2004, ADV NEUR IN, V16, P1499
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   Qixing Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1953, DOI 10.1109/CVPR.2011.5995571
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Ren YZ, 2017, J VIS COMMUN IMAGE R, V42, P192, DOI 10.1016/j.jvcir.2016.11.004
   Ren Z, 2016, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2016.169
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Xie J, 2015, PROC CVPR IEEE, P1275, DOI 10.1109/CVPR.2015.7298732
   Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739
   Zhou BL, 2014, ADV NEUR IN, V27
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 58
TC 9
Z9 10
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 131
EP 141
DI 10.1016/j.jvcir.2018.05.019
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100012
DA 2024-07-18
ER

PT J
AU Zheng, Q
   Li, HL
   Fan, BD
   Wu, SH
   Xu, JD
AF Zheng, Qiang
   Li, Honglun
   Fan, Baode
   Wu, Shuanhu
   Xu, Jindong
TI Integrating support vector machine and graph cuts for medical image
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Support vector machine; Graph cuts; Medical image segmentation
ID ACTIVE CONTOURS DRIVEN; ENERGY MINIMIZATION; VENTRICLE; REGION; MODEL
AB Medical image segmentation remains a challenged problem because of intensity inhomogeneity and surrounding complex background. In this paper, we propose a novel method for medical image segmentation by integrating support vector machine and graph cuts. Particularly, a novel localized training scheme is proposed to train a classifier for each pixel based on the target image information, and then a novel graph cuts-based segmentation method that combines the constraint information of machine learning result, the edge information, the local information, and the remote-local information is proposed for post-processing. Instead of delineating an initialized curve around the object boundary, we directly draw a narrowband mask for the initialization in the paper. Experiments on synthetic and medical images demonstrate that the proposed method can achieve better performance than the state-of-the-art.
C1 [Zheng, Qiang] Univ Penn, Dept Radiol, Perelman Sch Med, Philadelphia, PA 19104 USA.
   [Zheng, Qiang; Fan, Baode; Wu, Shuanhu; Xu, Jindong] Yantai Univ, Sch Comp & Control Engn, Yantai 264205, Peoples R China.
   [Li, Honglun] Qingdao Univ, Med Coll, Affiliated Yantai Yuhuangding Hosp, Dept Med Oncol, Yantai 264000, Peoples R China.
   [Li, Honglun] Qingdao Univ, Med Coll, Affiliated Yantai Yuhuangding Hosp, Dept Radiol, Yantai 264000, Peoples R China.
   [Xu, Jindong] China Univ Min & Technol, State Key Lab Coal Resources & Safe Min, Xuzhou 21116, Jiangsu, Peoples R China.
C3 University of Pennsylvania; Yantai University; Qingdao University;
   Qingdao University; China University of Mining & Technology
RP Zheng, Q (corresponding author), Univ Penn, Dept Radiol, Perelman Sch Med, Philadelphia, PA 19104 USA.
EM qiang.zheng@uphs.upenn.edu
FU Promotive Research Fund for Excellent Young and Middle-Aged Scientists
   of Shandong Province [BS2014DX012]; China Postdoctoral Science
   Foundation [2015M581203]; International Postdoctoral Exchange Fellowship
   Program [20160032]; Natural Science Foundation of Shandong Province
   [ZR2014FQ026]; Sate Key Laboratory of Coal Resources and Safe Mining
   (China University of Mining and Technology) Open Foundation
   [SKLCRSM16KFD05]
FX This work was supported by Promotive Research Fund for Excellent Young
   and Middle-Aged Scientists of Shandong Province [grant number
   BS2014DX012]; China Postdoctoral Science Foundation [grant number
   2015M581203]; the International Postdoctoral Exchange Fellowship Program
   [grant number 20160032); Natural Science Foundation of Shandong Province
   [grant number ZR2014FQ026]; Sate Key Laboratory of Coal Resources and
   Safe Mining (China University of Mining and Technology) Open Foundation
   [grant number SKLCRSM16KFD05].
CR Arrieta C, 2017, BIOMED SIGNAL PROCES, V33, P88, DOI 10.1016/j.bspc.2016.11.002
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YF, 2012, BIOMED SIGNAL PROCES, V7, P591, DOI 10.1016/j.bspc.2012.04.005
   Dai SF, 2015, NEUROCOMPUTING, V168, P799, DOI 10.1016/j.neucom.2015.05.044
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Hao YF, 2014, HUM BRAIN MAPP, V35, P2674, DOI 10.1002/hbm.22359
   Ju W, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2488902
   Li DY, 2013, J VIS COMMUN IMAGE R, V24, P522, DOI 10.1016/j.jvcir.2013.03.007
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   Liu LM, 2011, SIGNAL PROCESS, V91, P1210, DOI 10.1016/j.sigpro.2010.11.009
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Statnikov A, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-319
   Tao WB, 2012, IEEE T IMAGE PROCESS, V21, P284, DOI 10.1109/TIP.2011.2160955
   Wang T, 2015, J VIS COMMUN IMAGE R, V33, P10, DOI 10.1016/j.jvcir.2015.08.013
   Yuan GX, 2010, J MACH LEARN RES, V11, P3183
   Zhang LC, 2016, MED PHYS, V43, P1175, DOI 10.1118/1.4941011
   Zhao YT, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127486
   Zheng Q., 2017, ARXIV170603372V1
   Zheng Q, 2013, SIGNAL PROCESS, V93, P961, DOI 10.1016/j.sigpro.2012.10.005
   Zhou SP, 2016, NEUROCOMPUTING, V186, P107, DOI 10.1016/j.neucom.2015.12.073
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
NR 30
TC 22
Z9 23
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 157
EP 165
DI 10.1016/j.jvcir.2018.06.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100015
DA 2024-07-18
ER

PT J
AU Guo, D
   Li, CQ
   Wu, L
   Yang, JZ
AF Guo, Dan
   Li, Chuanqing
   Wu, Lu
   Yang, Jianzhong
TI Improved marching tetrahedra algorithm based on hierarchical signed
   distance field and multi-scale depth map fusion for 3D reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D reconstruction; Surface reconstruction; Depth map fusion;
   Hierarchical signed distance field; Feature matching
ID SURFACES; SENSORS
AB 3D reconstruction systems are promoted by developments of both computer hardware and computing technologies. They still remain problems like high expense, low efficiency and inaccuracy. Especially for large-scale scenes, lack of full use of multi-scale depth information will cause blurring and irreal reconstruction results. To solve this problem, we construct the structure of hierarchical signed distance field (H-SDF) and design an improved marching tetrahedra algorithm for multi-scale depth map fusion. In addition, to improve efficiency, we also propose a two-phase search strategy in image feature matching: the bag-of-features model (BOF) is adopted in a coarse search to narrow search scope and then the SIFT descriptor is used in exact matching to pick reconstruction image points. Experiment results indicate that coarse search makes matching time shorter; using the H-SDF to fuse multi-scale depth maps, and isosurface extraction with improved marching tetrahedra algorithm can improve visual effect. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Guo, Dan; Li, Chuanqing] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Wu, Lu] Wuhan Univ Technol, Sch Informat Engn, Wuhan, Hubei, Peoples R China.
   [Yang, Jianzhong] Huazhong Univ Sci & Technol, Wuhan, Hubei, Peoples R China.
C3 Hefei University of Technology; Wuhan University of Technology; Huazhong
   University of Science & Technology
RP Guo, D (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM guodan@hfut.edu.cn; lichuanqing@mail.hfut.edu.cn; wulv@whutedu.cn;
   yangjzh11@mail.hust.edu.cn
OI Guo, Dan/0000-0003-2594-254X
FU National Natural Science Foundation of China (NSFC) [61305062]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under grant 61305062.
CR [Anonymous], READINGS COMPUTER VI, DOI DOI 10.1038/293133A0
   [Anonymous], 2012, INT J COMPUT VISION, DOI DOI 10.1007/s11263-011-0472-9
   [Anonymous], IEEE T CYBERN
   [Anonymous], P 1 CAN C COMP ROB V
   [Anonymous], P S GEOM PROC
   Chen LC, 1997, COMPUT INTEGR MANUF, V10, P49, DOI 10.1016/S0951-5240(96)00019-5
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   DOI A, 1991, IEICE TRANS COMMUN, V74, P214
   Fuhrmann S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024182
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Guan T, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2795234
   HIGUCHI K, 1994, IEEE INT CONF ROBOT, P2248, DOI 10.1109/ROBOT.1994.350951
   Kampel M, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P754, DOI 10.1109/TDPVT.2002.1024154
   KEPPEL E, 1975, IBM J RES DEV, V19, P2, DOI 10.1147/rd.191.0002
   Lequellec JM, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P87, DOI 10.1109/IVS.2000.898323
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Lorensen W.E., 1987, P 14 ANN C COMP GRAP, P163
   Luo YW, 2015, NEUROCOMPUTING, V156, P105, DOI 10.1016/j.neucom.2014.12.079
   Pan HL, 2016, NEUROCOMPUTING, V175, P644, DOI 10.1016/j.neucom.2015.10.104
   Pito R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P397, DOI 10.1109/ICIP.1996.560846
   Sansoni G, 2009, SENSORS-BASEL, V9, P568, DOI 10.3390/s90100568
   Wei BC, 2016, KSII T INTERNET INF, V10, P3272, DOI 10.3837/tiis.2016.07.022
   Wei BC, 2015, MULTIMEDIA SYST, V21, P381, DOI 10.1007/s00530-014-0364-2
   Zach C., 2007, P IEEE 11 INT C COMP, P1
   Zhang Y, 2015, SIGNAL PROCESS, V112, P17, DOI 10.1016/j.sigpro.2014.08.029
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 28
TC 6
Z9 7
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 491
EP 501
DI 10.1016/j.jvcir.2016.12.016
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700043
DA 2024-07-18
ER

PT J
AU Jung, C
   Fu, QT
   Xue, F
AF Jung, Cheolkon
   Fu, Qingtao
   Xue, Fei
TI Perceptual stereoscopic video coding using disparity
   just-noticeable-distortion model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3DTV; Disparity estimation; Human visual system (HVS);
   Just-noticeable-distortion (JND); Perceptual redundancy; Stereo video
   coding
ID FOVEATION; IMAGE
AB In this paper, we propose perceptual stereoscopic video coding using a disparity just-noticeable distortion (JND) model. We obtain the disparity JND model in stereo videos by disparity masking effects of the human visual system (HVS). The disparity JND model represents the maximum distortion of stereo perception that HVS cannot perceive. Based on the disparity JND model, we adjust prediction residuals to remove the perceptual redundancy of stereo videos. Thus, we achieve significant bit-rate saving while maintaining visual quality. Experimental results demonstrate that the proposed method significantly improves coding efficiency without loss of stereoscopic perceptual quality. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Jung, Cheolkon; Fu, Qingtao; Xue, Fei] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Jung, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM zhengzk@xidian.edu.cn; qtfu@stu.xidian.edu.cn;
   2012xuefei@iiip.xidian.edu.cn
FU National Natural Science Foundation of China [61271298]; International
   S&T Cooperation Program of China [2014DFG12780]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61271298) and the International S&T Cooperation Program of
   China (No. 2014DFG12780).
CR Ahumada A. J.  Jr., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1666, P365, DOI 10.1117/12.135982
   [Anonymous], 2012, METH SUBJ ASS QUAL T
   Bjontegaard G., 2001, Document VCEG-M33
   Chen H, 2010, IEEE INT CON MULTI, P713, DOI 10.1109/ICME.2010.5583897
   Chin Y.-J., 1999, CIRCUITS SYST VIDEO, V9, P438, DOI DOI 10.1109/76.754773
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Felzenszwalb P.F., 2004, P IEEE COMP VIS PATT
   Ha H, 2009, IEEE T BROADCAST, V55, P559, DOI 10.1109/TBC.2009.2027624
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Klaus A, 2006, INT C PATT RECOG, P15
   Luo ZY, 2010, IEEE INT SYMP CIRC S, P945, DOI 10.1109/ISCAS.2010.5537392
   Mak CM, 2009, IEEE INT SYMP CIRC S, P609, DOI 10.1109/ISCAS.2009.5117822
   Malo J, 2001, IEEE T IMAGE PROCESS, V10, P1411, DOI 10.1109/83.951528
   Naccari M, 2011, IEEE T CIRC SYST VID, V21, P766, DOI 10.1109/TCSVT.2011.2130430
   Nettravali A.N., 1988, DIGITAL PICTURES REP
   Safranek R. J., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1945, DOI 10.1109/ICASSP.1989.266837
   Tong HHY, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P428, DOI 10.1109/ICIP.1998.999032
   Wang YF, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P330, DOI 10.1109/ICALIP.2014.7009810
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wong CW, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P361
   Wu GL, 2010, IEEE INT CON MULTI, P790, DOI 10.1109/ICME.2010.5582545
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P4892, DOI 10.1109/TIP.2013.2279934
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P845, DOI 10.1016/j.jvcir.2012.04.010
   Wu JJ, 2010, INT CONF ACOUST SPEE, P2454, DOI 10.1109/ICASSP.2010.5496302
   Wu TH, 2009, IEEE INT SYMP CIRC S, P2826, DOI 10.1109/ISCAS.2009.5118390
   Xue J., 2012, P 3 MULT SYST C, P173
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Zhai GT, 2008, IEEE T BROADCAST, V54, P719, DOI 10.1109/TBC.2008.2001720
   Zhang L, 2011, IEEE T BROADCAST, V57, P572, DOI 10.1109/TBC.2011.2131491
NR 34
TC 2
Z9 2
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 195
EP 204
DI 10.1016/j.jvcir.2017.06.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700016
DA 2024-07-18
ER

PT J
AU Mohammadi, MR
   Fatemizadeh, E
   Mahoor, MH
AF Mohammadi, M. R.
   Fatemizadeh, E.
   Mahoor, M. H.
TI A joint dictionary learning and regression model for intensity
   estimation of facial AUs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial action units; Intensity measurement; Spontaneous facial behavior;
   Sparse representation; Supervised dictionary learning
ID ROBUST FACE RECOGNITION; EXPRESSION
AB Automated intensity estimation of spontaneous Facial Action Units (AUs) defined by Facial Action Coding System (FACS) is a relatively new and challenging problem. This paper presents a joint supervised dictionary learning (SDL) and regression model for solving this problem. The model is casted as an optimization function consisting of two terms. The first term in the optimization concerns representing the facial images in a sparse domain using dictionary learning whereas the second term concerns estimating AU intensities using a linear regression model in the sparse domain. The regression model is designed in a way that considers disagreement between raters by a constant biasing factor in measuring the AU intensity values. Furthermore, since the intensity of facial AU is a non-negative value (i.e., the intensity values are between 0 and 5), we impose a non-negative constraint on the estimated intensities by restricting the search space for the dictionary learning and the regression function. Our experimental results on DISFA and FERA2015 databases show that this approach is very promising for automated measurement of spontaneous facial AUs. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Mohammadi, M. R.; Fatemizadeh, E.] Sharif Univ Technol, Tehran, Iran.
   [Mahoor, M. H.] Univ Denver, Denver, CO 80208 USA.
C3 Sharif University of Technology; University of Denver
RP Mohammadi, MR (corresponding author), Sharif Univ Technol, Tehran, Iran.
EM mrmohammadi@ee.sharif.edu; fatemizadeh@sharif.edu; mmahoor@du.edu
RI Mohammadi, Mohammad Reza/P-4031-2018
OI Mohammadi, Mohammad Reza/0000-0002-1016-9243; Mahoor,
   Mohammad/0000-0001-8923-4660
CR Abd-El-Hakeem Mohamed Mohamed, 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7356037
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   [Anonymous], 1983, EMFACS 7 EMOTIONAL F
   [Anonymous], HANDLING DATA IMBALA
   Bro R, 1997, J CHEMOMETR, V11, P393, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L
   Chan-Su Lee, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3548, DOI 10.1109/ICASSP.2014.6854261
   Cohen J., 2013, APPL MULTIPLE REGRES
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 1978, FAC ACT COD SYST FAC
   Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4
   Huang K., 2007, P 19 INT C NEUR INF, P609, DOI DOI 10.7551/MITPRESS/7503.003.0081
   Jeni L.A., 2013, Proc. 10th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit, P1
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Lei H, 2014, PATTERN RECOGN, V47, P899, DOI 10.1016/j.patcog.2013.07.016
   Li Y, 2013, LECT NOTES COMPUT SC, V8206, P1, DOI 10.1007/978-3-642-41278-3_1
   Li YQ, 2013, IEEE T AFFECT COMPUT, V4, P127, DOI 10.1109/T-AFFC.2013.5
   Mahoor Mohammad H., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P336, DOI 10.1109/FG.2011.5771420
   Mavadati SM, 2013, INT CONF IMAG VIS, P59, DOI 10.1109/IVCNZ.2013.6726993
   Mavadati SM, 2014, INT C PATT RECOG, P4648, DOI 10.1109/ICPR.2014.795
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Mohammadi MR, 2014, SIGNAL PROCESS, V100, P42, DOI 10.1016/j.sigpro.2014.01.010
   Mohammadi MR, 2014, IEEE WINT CONF APPL, P1066, DOI 10.1109/WACV.2014.6835986
   Nicolle J., 2015, PROC 11 IEEE INT C W, V6, P1
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Ptucha R, 2013, IMAGE VISION COMPUT, V31, P365, DOI 10.1016/j.imavis.2013.03.003
   Qi Jia, 2011, 2011 International Conference on Multimedia Technology, P4788
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Rudovic O., 2014, IEEE T PATTERN ANAL, P1
   Sadeghi H, 2013, IRAN CONF MACH, P159, DOI 10.1109/IranianMVIP.2013.6779970
   Salim W, 2012, PROCEDIA ENGINEER, V50, P707, DOI 10.1016/j.proeng.2012.10.077
   Sandbach G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P738, DOI 10.1109/ICCVW.2013.101
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Shu K., ARXIV12056391
   Tong Y, 2015, EMOTION RECOGNITION: A PATTERN ANALYSIS APPROACH, P47
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Valstar M.F., 2015, P 2015 IEEE INT C WO, P1
   Velusamy S, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P681, DOI 10.1109/CCNC.2013.6488525
   Wall M. E., 2003, PRACTICAL APPROACH M, P91, DOI [10.1007/0-306-47815-35, DOI 10.1007/0-306-47815-3_5]
   Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang S, 2014, LECT NOTES COMPUT SC, V8888, P269, DOI 10.1007/978-3-319-14364-4_26
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhao KL, 2014, IEEE IMAGE PROC, P1435, DOI 10.1109/ICIP.2014.7025287
NR 50
TC 2
Z9 3
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2017
VL 47
BP 1
EP 9
DI 10.1016/j.jvcir.2017.05.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX8TD
UT WOS:000403522200001
DA 2024-07-18
ER

PT J
AU Yao, H
   Qin, C
   Tang, ZJ
   Tian, Y
AF Yao, Heng
   Qin, Chuan
   Tang, Zhenjun
   Tian, Ying
TI Guided filtering based color image reversible data hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image; Reversible data hiding; Guided filtering predictor; Payload
   partition; Adaptive prediction-error expansion
ID PREDICTION-ERROR EXPANSION; DIFFERENCE EXPANSION; WATERMARKING;
   TRANSFORM; SCHEME
AB In this paper, a color-image-dedicated reversible data hiding (RDH) algorithm is proposed to improve embedding performance by applying a guided filtering predictor and an adaptive prediction-error expansion (PEE) scheme. PEE-based RDH methods can be mainly separated into two stages for each channel embedding, i.e., pixel prediction and prediction-error histogram (PEH) modification. In our work, the inter-channel correlation is exploited at all stages of prediction and modification. Specifically, for predicting the pixels in the current channel with the guidance of pixels from other channels, a linear transform model from reference channels to the current channel is established and its coefficients are determined by the Laplacian minimization criterion. Then, to modify the PEH, an adaptive PEE embedding scheme is conducted by seeking the optimal parameters of the embedding bins and the complexity threshold to minimize distortion. The experimental results demonstrate the proposed method has better performance than the state-of-the-art, color-image RDH methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yao, Heng; Qin, Chuan; Tian, Ying] Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Yao, Heng; Qin, Chuan; Tian, Ying] Univ Shanghai Sci & Technol, Engn Res Ctr Opt Instrument & Syst, Minist Educ, Shanghai 200093, Peoples R China.
   [Tang, Zhenjun] Guangxi Normal Univ, Dept Comp Sci, Guilin 541004, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Guangxi Normal University
RP Yao, H (corresponding author), Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.; Yao, H (corresponding author), Univ Shanghai Sci & Technol, Engn Res Ctr Opt Instrument & Syst, Minist Educ, Shanghai 200093, Peoples R China.
EM hyao@usst.edu.cn
RI Qin, Chuan/C-1106-2017; Yao, Heng/J-9457-2019
OI Qin, Chuan/0000-0002-0370-4623; Yao, Heng/0000-0002-3784-4157
FU National Natural Science Foundation of China [61672354, 61303203,
   61562007]; Innovation Program of Shanghai Municipal Education Commission
   [14YZ087]
FX We would like to thank Dr. Bo Ou and Xiaolong Li for kindly sharing the
   codes and results of their works with us. We would also like to thank
   the three anonymous reviewers for their constructive comments that
   helped us improve this work. This work was supported in part by the
   National Natural Science Foundation of China (61672354, 61303203,
   61562007), and the Innovation Program of Shanghai Municipal Education
   Commission (14YZ087).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kiku D, 2016, IEEE T IMAGE PROCESS, V25, P1288, DOI 10.1109/TIP.2016.2518082
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lu TC, 2014, SIGNAL PROCESS, V104, P152, DOI 10.1016/j.sigpro.2014.04.001
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2012, IMAGING SCI J, V60, P47, DOI 10.1179/1743131X11Y.0000000009
   Wang L, 2015, IEEE SIGNAL PROC LET, V22, P2083, DOI 10.1109/LSP.2015.2458934
   Yang WJ, 2012, INFORM SCIENCES, V190, P208, DOI 10.1016/j.ins.2011.11.046
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
NR 24
TC 40
Z9 43
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 152
EP 163
DI 10.1016/j.jvcir.2017.01.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400015
DA 2024-07-18
ER

PT J
AU Fang, JT
   Chen, ZY
   Lai, CR
   Chang, PC
AF Fang, Jiunn-Tsair
   Chen, Zong-Yi
   Lai, Chang-Rui
   Chang, Pao-Chi
TI Computational complexity allocation and control for inter-coding of high
   efficiency video coding with fast coding unit split decision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High-efficiency video coding (HEVC); Complexity allocation; Complexity
   control; Coding unit; Motion vector
ID MODE DECISION; HEVC; SELECTION; ENCODERS
AB HEVC provides the quadtree structure of the coding unit (CU) with four coding-tree depths to facilitate high coding efficiency. However, compared with previous standards, the HEVC encoder increases computational complexity considerably, thus making it inappropriate for applications in power-constrained devices. This study therefore proposes a computational complexity allocation and control method for the low-delay P-frame configuration of the HEVC encoder. The complexity allocation includes the group of pictures (GOP) layer, the frame layer, and the CU layer in the HEVC encoder. Each layer involved uses individual method to distribute the complexity. In particular, motion vector estimation information is applied for CU complexity allocation and depth split determination. The total computational complexity can thus be reduced to 80% and 60% or even lower. Experiment results revealed that the average BD-PSNR exhibited a decrease of approximately 0.1 dB and a BD-bitrate increment of 2% when the target complexity was reduced to 60%. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Fang, Jiunn-Tsair] Ming Chuan Univ, Dept Elect Engn, 5 Deming Rd, Taoyuan 33348, Taiwan.
   [Chen, Zong-Yi; Lai, Chang-Rui; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
C3 Ming Chuan University; National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
EM pcchang@ce.ncu.edu.tw
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   [Anonymous], 2001, ITU-T SG16/Q6
   [Anonymous], 2012, JCTVCH0213
   [Anonymous], 2013, 14 JCTVC M VIENN AT
   Chien MC, 2008, IEEE IMAGE PROC, P2136, DOI 10.1109/ICIP.2008.4712210
   Correa G., 2012, P IEEE 20 INT C EL C, P937
   Correa G, 2013, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2013.12
   Correa G, 2012, IEEE I C ELECT CIRC, P564, DOI 10.1109/ICECS.2012.6463684
   Corrêa G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P425, DOI 10.1109/PCS.2012.6213378
   Corrêa G, 2011, IEEE T CONSUM ELECTR, V57, P1866, DOI 10.1109/TCE.2011.6131165
   Deng X, 2016, IEEE T CIRC SYST VID, V26, P91, DOI 10.1109/TCSVT.2015.2474075
   Grellert M, 2013, IEEE IMAGE PROC, P1850, DOI 10.1109/ICIP.2013.6738381
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   Lee H, 2015, IEEE T BROADCAST, V61, P388, DOI 10.1109/TBC.2015.2419172
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Martínez-Enríquez E, 2010, IEEE T CONSUM ELECTR, V56, P826, DOI 10.1109/TCE.2010.5506008
   Ren JF, 2008, IEEE T CONSUM ELECTR, V54, P877, DOI 10.1109/TCE.2008.4560174
   Saponara S, 2006, IEEE T CONSUM ELECTR, V52, P232, DOI 10.1109/TCE.2006.1605052
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian GF, 2013, IEICE T FUND ELECTR, VE96A, P780, DOI 10.1587/transfun.E96.A.780
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Zhang L, 2007, IEEE T CONSUM ELECTR, V53, P749, DOI 10.1109/TCE.2007.381755
   Zhang YH, 2013, IEEE IMAGE PROC, P2000, DOI 10.1109/ICIP.2013.6738412
   Zhao TS, 2013, IEEE J-STSP, V7, P1135, DOI 10.1109/JSTSP.2013.2271421
NR 28
TC 4
Z9 4
U1 2
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 34
EP 41
DI 10.1016/j.jvcir.2016.06.004
PN A
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500004
DA 2024-07-18
ER

PT J
AU Ji, HK
   Sun, QS
   Yuan, YH
   Ji, ZX
AF Ji, Hong-Kun
   Sun, Quan-Sen
   Yuan, Yun-Hao
   Ji, Ze-Xuan
TI C<SUP>2</SUP>DMCP: View-consistent collaborative discriminative multiset
   correlation projection for data representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiset correlation projection; View-consistency; Collaborative
   discriminative structure
ID CANONICAL CORRELATION-ANALYSIS; FACE RECOGNITION; IMAGE ANNOTATION;
   SPARSE REPRESENTATION; MULTIVIEW FEATURES; FEATURE-EXTRACTION; FEATURE
   FUSION; CLASSIFICATION; CONSTRAINTS; MATRIX
AB Multiset canonical correlation analysis (MCCA) is a powerful technique for multi-view joint dimensionality reduction by maximizing linear correlat(i)ons among the projections. However, most existing MCCA-related methods fail to discover the intrinsic discriminating structure among data spaces and the correspondence between multiple views. In order to address these problems, we incorporate the collaborative representation structure of data points in each view. Then we construct a view consistent collaborative multiset correlation projection ((CMCP)-M-2) framework, in which the structures among different views are guaranteed to be consistent and preserved in low-dimensional subspaces. Also, by taking within-class and between-class collaborative reconstruction into account to improve discriminative power for the supervised scenario, we then propose a novel algorithm, called view-consistent collaborative discriminative multiset correlation projection ((CDMCP)-D-2), to explicitly consider both between-set cumulative correlations and discriminative structure in multiple representation data. The feasibility and effectiveness of the proposed method has been verified on three benchmark databases, i.e., ETH-80, AR and Extended Yale B, with promising results. (C) 2016 Published by Elsevier Inc.
C1 [Ji, Hong-Kun; Sun, Quan-Sen; Ji, Ze-Xuan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Ji, Hong-Kun] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 637553, Singapore.
   [Yuan, Yun-Hao] Yangzhou Univ, Dept Comp Sci & Technol, Yangzhou 225000, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanyang Technological
   University; Yangzhou University
RP Sun, QS (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM qssun@126.com
FU Graduate Research and Innovation Foundation of Jiangsu Province, China
   [KYLX15_0379]; National Natural Science Foundation of China [61273251,
   61401209, 61402203]; Natural Science Foundation of Jiangsu Province
   [BK20140790]; China Postdoctoral Science Foundation [2014T70525,
   2013M531364]
FX This work is supported in part by Graduate Research and Innovation
   Foundation of Jiangsu Province, China under Grant KYLX15_0379, in part
   by the National Natural Science Foundation of China under Grants
   61273251, 61401209, and 61402203, in part by the Natural Science
   Foundation of Jiangsu Province under Grant BK20140790, and in part by
   China Postdoctoral Science Foundation under Grants 2014T70525 and
   2013M531364.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 2011, INT C MACHINE LEARNI
   [Anonymous], 2011, INT C NEURAL INF PRO
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212
   Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64
   Chu DL, 2013, IEEE T PATTERN ANAL, V35, P3050, DOI 10.1109/TPAMI.2013.104
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Davenport M., 2007, TECHNICAL REPORT
   Dong L, 2015, NEUROIMAGE, V109, P388, DOI 10.1016/j.neuroimage.2015.01.006
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154
   Guan NY, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P51, DOI 10.1109/ICMLA.2012.18
   Hardoon DR, 2011, MACH LEARN, V83, P331, DOI 10.1007/s10994-010-5222-7
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hou SD, 2011, NEURAL PROCESS LETT, V34, P259, DOI 10.1007/s11063-011-9197-6
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Ji Hongkun, 2015, P BRIT MACH VIS C
   Jolliffe I., 1986, PRINCIPLE COMPONENTS
   Kailing K, 2004, LECT NOTES ARTIF INT, V3056, P394
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Lampert CH, 2010, LECT NOTES COMPUT SC, V6312, P566, DOI 10.1007/978-3-642-15552-9_41
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li CG, 2015, IEEE I CONF COMP VIS, P2767, DOI 10.1109/ICCV.2015.317
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Ma Z, 2015, PR MACH LEARN RES, V37, P169
   Martinez A., 1998, AR FACE DATABASE
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Memisevic R, 2012, IEEE T PATTERN ANAL, V34, P778, DOI 10.1109/TPAMI.2011.154
   Mohammadzade H, 2013, IEEE T AFFECT COMPUT, V4, P69, DOI 10.1109/T-AFFC.2012.30
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Peng Y, 2010, NEURAL PROCESS LETT, V31, P1, DOI 10.1007/s11063-009-9123-3
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Rupnik J., 2010, P C DATA MINING DATA, P1
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Su Y, 2012, IEEE T IMAGE PROCESS, V21, P1381, DOI 10.1109/TIP.2011.2169972
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Sun T.K., 2008, P IEEE INT C DAT MIN, P1043, DOI DOI 10.1109/ICDM.2008.28
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Takane Y, 2008, PSYCHOMETRIKA, V73, P753, DOI 10.1007/s11336-008-9065-0
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Waaijenborg S, 2008, STAT APPL GENET MOL, V7
   Wang Wei, 2010, P 27 INT C MACH LEAR, P1135
   Wang WR, 2015, INT CONF ACOUST SPEE, P4590, DOI 10.1109/ICASSP.2015.7178840
   Wang Weiran, 2015, STOCHASTIC OPTIMIZAT
   Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0
   Witten DM, 2009, STAT APPL GENET MOL, V8, DOI 10.2202/1544-6115.1470
   Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yao T, 2015, IEEE I CONF COMP VIS, P28, DOI 10.1109/ICCV.2015.12
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Yuan Y.H., 2015, MULTIVIEW CORRELATIO, P518
   Yuan YH, 2014, PATTERN RECOGN, V47, P3907, DOI 10.1016/j.patcog.2014.06.016
   Yuan YH, 2013, NEUROCOMPUTING, V122, P229, DOI 10.1016/j.neucom.2013.06.029
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Zhang L., 2012, Collaborative representation based classification for face recognition
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Q, 2015, IEEE DATA MINING, P1105, DOI 10.1109/ICDM.2015.82
   Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212
NR 79
TC 6
Z9 6
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 393
EP 405
DI 10.1016/j.jvcir.2016.06.012
PN B
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600001
DA 2024-07-18
ER

PT J
AU Feng, CL
   Zhao, DZ
   Huang, M
AF Feng, Chaolu
   Zhao, Dazhe
   Huang, Min
TI Segmentation of longitudinal brain MR images using bias correction
   embedded fuzzy c-means with non-locally spatio-temporal regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Longitudinal segmentation; Brain atrophy; Non-local means de-noising;
   Intensity inhomogeneity; CUDA
ID RANDOM-FIELD MODEL; MULTIPLE-SCLEROSIS; MEANS ALGORITHM; ATROPHY;
   ROBUST; PROGRESSION; PATTERNS; ACCURATE; LESION; TISSUE
AB We propose an automated method for segmentation of brain tissues in longitudinal MR images. In the proposed method, images acquired at each time point are first separately segmented into white matter, gray matter, and cerebrospinal fluid by bias correction embedded fuzzy c-means. Intensities differences are then defined as similarities of each voxel to the cluster centroids. After being normalized in interclass, the similarities are incorporated into a non-local means de-noising formula to regularize the segmentation in both spatial and temporal dimensions. Non-locally regularization results are used to compute final membership functions for the segmentation. To improve time performance, we accelerate the modified de-noising algorithm using CUDA and obtain a 200x performance improvement. Quantitative comparison with the state-of-the-art methods on BrainWeb dataset demonstrate advantages of the proposed method in terms of segmentation accuracy and the ability to consistently segment brain tissues in an arbitrary number of longitudinal brain MR image series. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Feng, Chaolu; Zhao, Dazhe; Huang, Min] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
   [Feng, Chaolu; Zhao, Dazhe] Northeastern Univ, Minist Educ, Key Lab Med Image Comp, Shenyang 110819, Liaoning, Peoples R China.
   [Huang, Min] Northeastern Univ, State Key Lab Synthet Automat Proc Ind, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   Northeastern University - China
RP Feng, CL (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
EM fengchaolu@cse.neu.edu.cn
RI Min, Huang/KLZ-0497-2024
OI Feng, Chaolu/0000-0002-5575-2328; Feng, Chaolu/0000-0001-7157-8713
FU Fundamental Research Funds for the Central Universities of China
   [N140403006, N140402003, N140407001]; National Science Foundation for
   Distinguished Young Scholars of China [71325002, 61225012]; National
   Science Foundation of China [61172002, 71071028]; Postdoctoral
   Scientific Research Funds of Northeastern University [20150310];
   National Key Technology Research and Development Program of the Ministry
   of Science and Technology of China [2014BAI17B01]; Fundamental Research
   Funds for State Key Laboratory of Synthetical Automation for Process
   Industries [2013ZCX11]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities of China under Grant Nos. N140403006, N140402003,
   and N140407001, the National Science Foundation for Distinguished Young
   Scholars of China under Grant Nos. 71325002 and 61225012, the National
   Science Foundation of China under Grant Nos. 61172002 and 71071028, the
   Postdoctoral Scientific Research Funds of Northeastern University under
   Grant No. 20150310, the National Key Technology Research and Development
   Program of the Ministry of Science and Technology of China under Grant
   2014BAI17B01, and the Fundamental Research Funds for State Key
   Laboratory of Synthetical Automation for Process Industries under Grant
   No. 2013ZCX11. The authors would like to thank the editor for holding
   and considering to publish our paper and would also like to greatly
   appreciate the anonymous reviewers for their valuable comments to
   improve the quality of this paper.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Anderson VM, 2012, NEUROBIOL AGING, V33, P1194, DOI 10.1016/j.neurobiolaging.2010.11.001
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Callisaya ML, 2013, J AM GERIATR SOC, V61, P1074, DOI 10.1111/jgs.12331
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Coupé P, 2006, LECT NOTES COMPUT SC, V4191, P33
   Davatzikos C, 2009, BRAIN, V132, P2026, DOI 10.1093/brain/awp091
   de Boer R, 2010, NEUROIMAGE, V51, P1047, DOI 10.1016/j.neuroimage.2010.03.012
   de Bresser J, 2011, NEUROIMAGE, V54, P760, DOI 10.1016/j.neuroimage.2010.09.060
   Dwyer MG, 2014, NEUROIMAGE, V90, P207, DOI 10.1016/j.neuroimage.2013.12.004
   Eskildsen SF, 2012, NEUROIMAGE, V59, P2362, DOI 10.1016/j.neuroimage.2011.09.012
   Feng CL, 2016, SIGNAL PROCESS, V122, P164, DOI 10.1016/j.sigpro.2015.12.007
   Feng CL, 2015, BIO-MED MATER ENG, V26, pS983, DOI 10.3233/BME-151393
   Feng CL, 2013, LECT NOTES COMPUT SC, V8149, P477, DOI 10.1007/978-3-642-40811-3_60
   Feng CL, 2013, MAGN RESON IMAGING, V31, P1390, DOI 10.1016/j.mri.2013.04.013
   FISCHL B, 2012, FREESURFER NEUROIMAG, V62, P774, DOI [DOI 10.1016/J.NEUROIMAGE.2012.01.021, 10.1016/j.neuroimage.2012.01.021]
   Gao JJ, 2014, MAGN RESON IMAGING, V32, P1058, DOI 10.1016/j.mri.2014.03.006
   Jovicich J, 2013, NEUROIMAGE, V83, P472, DOI 10.1016/j.neuroimage.2013.05.007
   Khan AR, 2008, NEUROIMAGE, V41, P735, DOI 10.1016/j.neuroimage.2008.03.024
   Liao L, 2008, PATTERN RECOGN LETT, V29, P1580, DOI 10.1016/j.patrec.2008.03.012
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Mayer A, 2009, IEEE T MED IMAGING, V28, P1238, DOI 10.1109/TMI.2009.2013850
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Roy S, 2012, MED IMAGE ANAL, V16, P524, DOI 10.1016/j.media.2011.12.001
   Scherrer B, 2009, IEEE T MED IMAGING, V28, P1278, DOI 10.1109/TMI.2009.2014459
   Schwarz C., 2012, LONGITUDINAL TISSUE
   Shattuck DW, 2009, NEUROIMAGE, V45, P431, DOI 10.1016/j.neuroimage.2008.10.066
   Shi F, 2010, LECT NOTES COMPUT SC, V6326, P42
   Shi F, 2010, NEUROIMAGE, V49, P391, DOI 10.1016/j.neuroimage.2009.07.066
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Smith SM, 2002, NEUROIMAGE, V17, P479, DOI 10.1006/nimg.2002.1040
   Smith SM, 2001, J COMPUT ASSIST TOMO, V25, P466, DOI 10.1097/00004728-200105000-00022
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Suganya R., 2012, INT J SCI RES PUBLIC, V2, P1
   Vrenken H, 2013, J NEUROL, V260, P2458, DOI 10.1007/s00415-012-6762-5
   Wang L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064207
   Wang L, 2013, HUM BRAIN MAPP, V34, P956, DOI 10.1002/hbm.21486
   Wang Y, 2014, HUM BRAIN MAPP, V35, P4777, DOI 10.1002/hbm.22511
   Wolz R, 2010, NEUROIMAGE, V52, P109, DOI 10.1016/j.neuroimage.2010.04.006
   Xue Z, 2006, NEUROIMAGE, V30, P388, DOI 10.1016/j.neuroimage.2005.09.054
   Yang JZ, 2013, MAGN RESON IMAGING, V31, P313, DOI 10.1016/j.mri.2012.06.038
   Yang MS, 2008, PATTERN RECOGN LETT, V29, P1713, DOI 10.1016/j.patrec.2008.04.016
   Yi Z, 2009, LECT NOTES COMPUT SC, V5762, P558
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 45
TC 20
Z9 23
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 517
EP 529
DI 10.1016/j.jvcir.2016.03.027
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100044
OA Bronze
DA 2024-07-18
ER

PT J
AU Li, J
   Chen, CX
   Liu, YP
   Chen, X
AF Li, Jian
   Chen, Chunxiao
   Liu, Yuping
   Chen, Xin
TI Small-world brain functional network altered by watching 2D/3DTV
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 2D/3DTV; Visual fatigue; Resting-state fMRI; Brain functional network
ID PARALLEL FRAMEWORK; MUSIC
AB With the development of display technology, the healthy problems caused by watching 2D/3DTV have received more and more attention. This paper utilized resting-state functional magnetic resonance imaging to study the changes of small-world brain network before and after one-hour 2D/3DTV watching, and explored the brain fatigue mechanism caused by watching 2D/3DTV. We conclude that one-hour watching of 2DTV will not increase the burden of brain. On the contrary, one-hour watching of 3DTV requires the brain to regulate the efficiency of brain areas, such as temporal lobe and occipital lobe, which may explain the fact that watching 3DTV can easier cause brain fatigue than watching 2DTV. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Li, Jian; Chen, Chunxiao] Nanjing Univ Aeronaut & Astronaut, Dept Biomed Engn, Nanjing 211106, Jiangsu, Peoples R China.
   [Liu, Yuping; Chen, Xin] Guangdong Prov Tradit Chinese Med Hosp, Dept Radiol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Guangzhou University
   of Chinese Medicine
RP Chen, CX (corresponding author), 169 Sheng Tai West Rd, Nanjing 211106, Jiangsu, Peoples R China.
EM ccxbme@nuaa.edu.cn
RI Li, Jiaai/JCO-0168-2023; wang, xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61171059]
FX This study was supported by the National Natural Science Foundation of
   China (Grant No. 61171059).
CR Achard S, 2007, PLOS COMPUT BIOL, V3, P174, DOI 10.1371/journal.pcbi.0030017
   [Anonymous], 2011, P 3DTV C MAY
   Bassett DS, 2011, P NATL ACAD SCI USA, V108, P7641, DOI 10.1073/pnas.1018985108
   Butz Markus, 2014, Front Synaptic Neurosci, V6, P7, DOI 10.3389/fnsyn.2014.00007
   Chen CX, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/1475-925X-14-S1-S12
   Douw L, 2011, NEUROSCIENCE, V175, P169, DOI 10.1016/j.neuroscience.2010.11.039
   Gregory AM, 2015, EPILEPSY BEHAV, V46, P173, DOI 10.1016/j.yebeh.2015.03.006
   Humphries MD, 2006, P ROY SOC B-BIOL SCI, V273, P503, DOI 10.1098/rspb.2005.3354
   Kim DI, 2011, J IND ENG CHEM, V17, P1, DOI 10.1016/j.jiec.2010.12.010
   Latora V, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.198701
   Li G., 2014, RES BRAIN STRUCTURAL
   Onoda K, 2013, NEUROSCI LETT, V556, P104, DOI 10.1016/j.neulet.2013.10.023
   Stam CJ, 2007, CEREB CORTEX, V17, P92, DOI 10.1093/cercor/bhj127
   [孙俊峰 Sun Junfeng], 2010, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V7, P74
   Sun Y, 2014, BRAIN COGNITION, V85, P220, DOI 10.1016/j.bandc.2013.12.011
   [王嘉辉 Wang Jiahui], 2013, [中山大学学报. 自然科学版, Acta Scientiarum Naturalium Universitatis Sunyatseni], V52, P1
   Wu J, 2013, NEUROSCIENCE, V250, P49, DOI 10.1016/j.neuroscience.2013.06.021
   Wu JJ, 2012, BRAIN RES, V1483, P71, DOI 10.1016/j.brainres.2012.09.014
   [徐光青 Xu Guangqing], 2014, [中国康复医学杂志, Chinese Journal of Rehabilitation Medicine], V29, P316
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yano S, 2004, DISPLAYS, V25, P141, DOI 10.1016/j.displa.2004.09.002
   Yao ZJ, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1001006
   Zhang Y, 2014, MAGN RESON IMAGING, V32, P359, DOI 10.1016/j.mri.2013.12.016
   Zhang Y, 2013, MAGN RESON IMAGING, V31, P1105, DOI 10.1016/j.mri.2013.01.006
   [赵小虎 Zhao Xiaohu], 2011, [中国医学影像技术, Chinese Journal of Medical Imaging Technology], V27, P2118
NR 27
TC 9
Z9 11
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 433
EP 439
DI 10.1016/j.jvcir.2016.03.023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100037
DA 2024-07-18
ER

PT J
AU Tao, SY
   Dong, WD
   Xu, ZH
   Tang, ZM
AF Tao, Shuyin
   Dong, Wende
   Xu, Zhihai
   Tang, Zhenmin
TI Fast total variation deconvolution for blurred image contaminated by
   Poisson noise
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Non-blind image deconvolution; Poisson noise; Total
   variation; Variable splitting and penalty
ID ALTERNATING MINIMIZATION ALGORITHM; RICHARDSON-LUCY ALGORITHM; BLIND
   DECONVOLUTION; AUTOMATIC DECONVOLUTION; PARALLEL FRAMEWORK; EDGE METHOD;
   HEVC; 4PI-MICROSCOPY
AB In this paper, we present a fast non-blind deconvolution method for restoring blurred images contaminated by Poisson noise. The problem is formulated by finding the minimizer of the negative logarithmic Poisson log-likelihood combined with the total variation (TV). To attack the challenging task, we adopt the well-known variable splitting and penalty technique to convert the problem into two easier sub-problems: one is a modified TV regularized deconvolution and the other is a simple convex optimization problem. Experimental results show that the proposed method runs very fast and the quality of the restored image is comparable with that of some state of the art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tao, Shuyin; Tang, Zhenmin] Nanjing Univ Sci & Technol, Key Lab Image & Video Understanding Social Safety, Nanjing 210094, Jiangsu, Peoples R China.
   [Tao, Shuyin; Tang, Zhenmin] Nanjing Univ Sci & Technol, Collaborat Innovat Ctr Social Safety Sci & Techno, Nanjing 210094, Jiangsu, Peoples R China.
   [Dong, Wende] China Elect Technol Grp Corp, Res Inst 28, Nanjing 210007, Jiangsu, Peoples R China.
   [Xu, Zhihai] Zhejiang Univ, State Key Lab Modern Opt Instrumentat, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology; China Electronics Technology Group; Zhejiang
   University
RP Tao, SY (corresponding author), Nanjing Univ Sci & Technol, Key Lab Image & Video Understanding Social Safety, Nanjing 210094, Jiangsu, Peoples R China.
EM taoshuyin@njust.edu.cn
RI Tang, Zhenmin/AAY-6058-2020
OI Tang, Zhenmin/0000-0001-6708-2205
FU Chinese National Natural Science Foundation [61550003, 61275021];
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety (Nanjing University of Science and Technology - China)
   [30920140122007]
FX We thank the editor and the anonymous reviewers for their valuable
   comments which help to improve this paper. The research is supported by
   Chinese National Natural Science Foundation (Nos. 61550003 and 61275021)
   and Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety (Nanjing University of Science and Technology - China, No.
   30920140122007).
CR [Anonymous], MATH PROBL ENG
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], THESIS TU MUNCHEN
   Bardsley JM, 2008, INVERSE PROBL SCI EN, V16, P199, DOI 10.1080/17415970701404235
   Bertero M, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/12/123006
   Bertero M., 1998, Introduction to Inverse Problems in Imaging
   Bioucas-Dias J. M., 2006, 2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Carlavan M, 2012, IEEE T IMAGE PROCESS, V21, P1834, DOI 10.1109/TIP.2011.2175934
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen DQ, 2014, SIAM J IMAGING SCI, V7, P716, DOI 10.1137/130932119
   Chen HS, 2015, J VIS COMMUN IMAGE R, V31, P282, DOI 10.1016/j.jvcir.2015.07.004
   Chen JW, 2013, OPTIK, V124, P3601, DOI 10.1016/j.ijleo.2012.11.004
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   Dong WD, 2011, OPT LASER TECHNOL, V43, P926, DOI 10.1016/j.optlastec.2010.12.012
   Figueiredo Mario, 2009, 2009 IEEE/SP 15th Workshop on Statistical Signal Processing (SSP), P733, DOI 10.1109/SSP.2009.5278459
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   FISH DA, 1995, J OPT SOC AM A, V12, P58, DOI 10.1364/JOSAA.12.000058
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   GREEN PJ, 1990, J ROY STAT SOC B MET, V52, P443
   GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985
   Huang YM, 2008, MULTISCALE MODEL SIM, V7, P774, DOI 10.1137/070703533
   Krishnan Dilip., 2009, NIPS, V22, P1
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605
   Lv XG, 2015, J COMPUT APPL MATH, V290, P553, DOI 10.1016/j.cam.2015.06.006
   Ramani S, 2012, IEEE T MED IMAGING, V31, P677, DOI 10.1109/TMI.2011.2175233
   Ramani S, 2011, IEEE T MED IMAGING, V30, P694, DOI 10.1109/TMI.2010.2093536
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Sawatzky A., 2008, Nuclear Science Symposium Conference Record, P5133, DOI DOI 10.1109/NSSMIC.2008.4774392
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Tao SY, 2013, OPTIK, V124, P6599, DOI 10.1016/j.ijleo.2013.05.068
   Tikhonov A. N., 1995, NUMERICAL METHODS SO
   Tikhonov A. N., 1943, Dokl. Akad. Nauk SSSR, V39, P195
   Viallefont-Robinet F, 2010, OPT EXPRESS, V18, P20845, DOI 10.1364/OE.18.020845
   Viallefont-Robinet F, 2010, OPT EXPRESS, V18, P3531, DOI 10.1364/OE.18.003531
   Vicidomini G, 2010, OPT EXPRESS, V18, P10154, DOI 10.1364/OE.18.010154
   Vicidomini G, 2009, OPT LETT, V34, P3583, DOI 10.1364/OL.34.003583
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang YP, 2010, OPT LASER TECHNOL, V42, P845, DOI 10.1016/j.optlastec.2010.01.001
   Xu ZM, 2009, OPT LETT, V34, P1453, DOI 10.1364/OL.34.001453
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan LX, 2012, OPT LETT, V37, P2778, DOI 10.1364/OL.37.002778
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
NR 49
TC 10
Z9 12
U1 1
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 582
EP 594
DI 10.1016/j.jvcir.2016.04.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100050
DA 2024-07-18
ER

PT J
AU Yu, M
   Zheng, KH
   Jiang, GY
   Shao, F
   Peng, ZJ
AF Yu, Mei
   Zheng, Kaihui
   Jiang, Gangyi
   Shao, Feng
   Peng, Zongju
TI Binocular perception based reduced-reference stereo video quality
   assessment method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo video quality assessment; Binocular vision; Temporal
   characteristics; Reduced-reference frame; Motion intensity
ID IMAGES; VIEW
AB A new reduced-reference (RR) stereo video quality assessment method is proposed in this paper by considering temporal characteristics of video and binocular perception in human visual system (HVS). Firstly, motion intensity is utilized to extract RR frames for the purpose of temporal characteristics in stereo video. Secondly, according to internal generative mechanism of HVS, fusion and rivalry in the process of binocular perception is modeled, and the RR frames are divided into binocular fusion portion and binocular rivalry portion. Then, RR frame quality indicators are computed for these two portions. Finally, the RR frame quality indicators of the original and distorted frames are compared. A temporal pooling strategy is utilized on these quality indicators to obtain final stereo video quality score, where the motion intensity is used for toning the pooling parameters. Experimental results show that the proposed method has better performances when compared to other state-of-the-art quality assessment methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yu, Mei; Zheng, Kaihui; Jiang, Gangyi; Shao, Feng; Peng, Zongju] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Yu, Mei; Jiang, Gangyi] Nanjing Univ, Natl Key Lab Software New Technol, Nanjing 210008, Jiangsu, Peoples R China.
C3 Ningbo University; Nanjing University
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM jianggangyi@126.com
RI Peng, Zongju/AAA-2914-2020; jiang, gang/KII-8233-2024
OI Peng, Zongju/0000-0001-8286-538X; 
FU Natural Science Foundation of China [U1301257, 61271270, 61271021,
   61311140262]; National High-tech R&D Program of China [2015AA015901];
   Natural Science Foundation of Zhejiang Province in China [LY15F010005,
   LY16F010002]; K.C. Wong Magna Fund in Ningbo University
FX This work was supported by the Natural Science Foundation of China under
   Grant Nos. U1301257, 61271270, 61271021 and 61311140262, the National
   High-tech R&D Program of China under Grant No. 2015AA015901, and the
   Natural Science Foundation of Zhejiang Province in China under Grant
   Nos. LY15F010005 and LY16F010002. It is also sponsored by K.C. Wong
   Magna Fund in Ningbo University.
CR [Anonymous], 2011, 2011 IEEE INT INSTRU, DOI DOI 10.1109/IMTC.2011.5944170
   Brunnstrom Kjell, 2009, IEEE Signal Processing Magazine, V26, P96, DOI 10.1109/MSP.2009.932162
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   Dumic Emil, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P65
   Dumic E., 2014, INT S ELMAR ZAD CROA, P1
   Hewage C.T. E. R., 2010, Future Network MobileSummit 2010 Conference Proceedings, P1
   Jimenez D., THESIS
   Jin LN, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-6
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Lin JY, 2015, IEEE INT CONF CL NET, P198, DOI 10.1109/CloudNet.2015.7335305
   Ma L, 2013, IEEE INT CON MULTI
   Malekmohamadi H, 2014, J VIS COMMUN IMAGE R, V25, P534, DOI 10.1016/j.jvcir.2013.12.009
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Rosskopf A., 2014, IEEE Int. Elec. Drives Prod. Conf. (EDPC), P1, DOI [10.1007/s13398-014-01737.2, DOI 10.1016/J.NEUROPSYCHOLOGIA.2015.01.019]
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Seo J, 2012, CIRC SYST SIGNAL PR, V31, P1089, DOI 10.1007/s00034-011-9369-7
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Urvoy M, 2012, INT WORK QUAL MULTIM, P109, DOI 10.1109/QoMEX.2012.6263847
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Yun N, 2013, NEUROCOMPUTING, V120, P121, DOI 10.1016/j.neucom.2012.06.059
   Zhou WJ, 2014, SIGNAL PROCESS-IMAGE, V29, P167, DOI 10.1016/j.image.2013.10.005
   Zhu T, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-5
NR 28
TC 17
Z9 18
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 246
EP 255
DI 10.1016/j.jvcir.2016.03.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100021
DA 2024-07-18
ER

PT J
AU Xiong, TS
   Zhang, L
   Yi, Z
AF Xiong, Taisong
   Zhang, Lei
   Yi, Zhang
TI Double Gaussian mixture model for image segmentation with spatial
   relationships
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Markov random model; Gaussian mixture model; Image segmentation;
   Expectation maximization (EM) algorithm; Gradient descent; Spatial
   relationships; Synthetic noisy grayscale images; Real-world color images
ID RANDOM-FIELD MODEL; PARALLEL FRAMEWORK; MEAN SHIFT
AB In this paper, we present a finite mixture model based on a Gaussian distribution for image segmentation. There are four advantages to the proposed model. First, compared with the standard Gaussian mixture model (GMM), the proposed model effectively incorporates spatially relationships between the pixels using a Markov random field (MRF). Second, the proposed model is similar to GMM, but has a simple representation and is easier to implement than some existing models based on MRF. Third, the contextual mixing proportion of the proposed model is explicitly modelled as a probabilistic vector and can be obtained directly during the inference process. Finally, the expectation maximization algorithm and gradient descent approach are used to maximize the log-likelihood function and infer the unknown parameters of the proposed model. The performance of the proposed model at image segmentation is compared with some state-of-the-art models on various synthetic noisy grayscale images and real world color images. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Xiong, Taisong] Chengdu Univ Informat Technol, Coll Appl Math, Chengdu 610225, Sichuan, Peoples R China.
   [Zhang, Lei; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
C3 Chengdu University of Information Technology; Sichuan University
RP Zhang, L (corresponding author), Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
EM leizhang@scu.edu.cn
FU National Nature Science Foundation of China [61322203, 61332002];
   Foundation of Chengdu University of Information Technology [KYTZ201426]
FX The authors would like to thank the anonymous reviewers for their
   thorough and valuable comments and suggestions, which greatly helped to
   improve the quality of the paper. This work was supported by National
   Nature Science Foundation of China under Grant Nos. 61322203 and
   61332002, and Foundation of Chengdu University of Information Technology
   (No. KYTZ201426).
CR Alfò M, 2008, STAT COMPUT, V18, P137, DOI 10.1007/s11222-007-9044-9
   [Anonymous], INTERDISCIPLINARY IN
   [Anonymous], 2000, WILEY SERIES PROBABI
   [Anonymous], EM ALGORITHM EXTENSI
   [Anonymous], 2011, TEXTS COMPUT SCI
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blanchet J, 2008, IEEE T PATTERN ANAL, V30, P1055, DOI 10.1109/TPAMI.2008.27
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Diplaros A, 2007, IEEE T NEURAL NETWOR, V18, P798, DOI 10.1109/TNN.2007.891190
   Forbes F, 2003, IEEE T PATTERN ANAL, V25, P1089, DOI 10.1109/TPAMI.2003.1227985
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Laferté JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li S. Z., 2009, Markov random field modeling in image analysis
   Nguyen TM, 2010, IEEE T NEURAL NETWOR, V21, P1326, DOI 10.1109/TNN.2010.2054109
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Provost JN, 2004, COMPUT VIS IMAGE UND, V93, P155, DOI 10.1016/j.cviu.2003.07.004
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   Sfikas G., 2008, IEEE C COMPUTER VISI, P1
   Sfikas G, 2010, J MATH IMAGING VIS, V36, P91, DOI 10.1007/s10851-009-0174-x
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Nguyen TM, 2013, SIGNAL PROCESS, V93, P3171, DOI 10.1016/j.sigpro.2013.04.014
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P619, DOI 10.1109/TPAMI.2009.199
   Xiong TS, 2014, MULTIMED TOOLS APPL, V72, P167, DOI 10.1007/s11042-012-1336-1
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 39
TC 11
Z9 18
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 135
EP 145
DI 10.1016/j.jvcir.2015.10.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400012
DA 2024-07-18
ER

PT J
AU De Abreu, A
   Toni, L
   Thomos, N
   Maugey, T
   Pereira, F
   Frossard, P
AF De Abreu, Ana
   Toni, Laura
   Thomos, Nikolaos
   Maugey, Thomas
   Pereira, Fernando
   Frossard, Pascal
TI Optimal layered representation for adaptive interactive multiview video
   streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview video; Layered representation; Navigation window; Depth image
   based rendering (DIBR); Depth maps; Texture; View synthesis; Dynamic
   programming
ID VIEW
AB We consider an interactive multiview video streaming (IMVS) system where clients select their preferred viewpoint in a given navigation window. To provide high quality IMVS, many high quality views should be transmitted to the clients. However, this is not always possible due to the limited and heterogeneous capabilities of the clients. In this paper, we propose a novel adaptive IMVS solution based on a layered multiview representation where camera views are organized into layered subsets to match the different clients constraints. We formulate an optimization problem for the joint selection of the views subsets and their encoding rates. Then, we propose an optimal and a reduced computational complexity greedy algorithms, both based on dynamic-programming. Simulation results show the good performance of our novel algorithms compared to a baseline algorithm, proving that an effective IMVS adaptive solution should consider the scene content and the client capabilities and their preferences in navigation. (C) 2015 Elsevier Inc. All rights reserved.
C1 [De Abreu, Ana; Toni, Laura; Frossard, Pascal] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
   [De Abreu, Ana; Pereira, Fernando] Univ Lisbon, Inst Telecomunicacoes IST UL IT, Inst Super Tecn, P-1049001 Lisbon, Portugal.
   [Maugey, Thomas] Univ Essex, Colchester CO4 3SQ, Essex, England.
   [Maugey, Thomas] Inria Rennes Bretagne Atlant, F-35042 Rennes, France.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Universidade de Lisboa; University of Essex;
   Universite de Rennes
RP De Abreu, A (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
EM ana.deabreu@epfl.ch; laura.toni@epfl.ch; nthomos@essex.ac.uk;
   thomas.maugey@inria.fr; fp@lx.it.pt; pascal.frossard@epfl.ch
RI Pereira, Fernando/K-4046-2012; Frossard, Pascal/AAF-2268-2019; Thomos,
   Nikolaos/AAU-2328-2020; Pereira, Fernando/HNR-7786-2023
OI Bernardo Pereira, Fernando Manuel/0000-0001-6100-947X; Toni,
   Laura/0000-0002-8441-8791; Thomos, Nikolaos/0000-0001-7266-2642
FU Fundacao para a Ciencia e a Tecnologia [SFRH/BD/51443/2011]; Swiss
   National Science Foundation (SNSF) under the CHIST-ERA project CONCERT
   (A Context-Adaptive Content Ecosystem Under Uncertainty) [FNS 20CH21
   151569]; Fundação para a Ciência e a Tecnologia [SFRH/BD/51443/2011]
   Funding Source: FCT
FX The authors would like to thank Gene Cheung from the National Institute
   of Informatics (NII) in Japan for the interesting and fruitful
   discussions that have substantially enriched this work. This work has
   been partially supported by Fundacao para a Ciencia e a Tecnologia,
   under the Grant SFRH/BD/51443/2011 and by the Swiss National Science
   Foundation (SNSF) under the CHIST-ERA project CONCERT (A
   Context-Adaptive Content Ecosystem Under Uncertainty), Project No. FNS
   20CH21 151569.
CR [Anonymous], P IEEE INT C DIG SIG
   [Anonymous], DEPTH IMAGE BASED RE
   Chakareski J, 2015, IEEE J-STSP, V9, P474, DOI 10.1109/JSTSP.2015.2402633
   Chakareski J, 2013, IEEE T IMAGE PROCESS, V22, P3473, DOI 10.1109/TIP.2013.2269801
   Cheung G., 2008, P IEEE MMSP CAIRNS Q
   Cheung G, 2011, IEEE T IMAGE PROCESS, V20, P3179, DOI 10.1109/TIP.2011.2158230
   Cheung G, 2011, IEEE T IMAGE PROCESS, V20, P744, DOI 10.1109/TIP.2010.2070074
   Cheung G, 2010, IEEE IMAGE PROC, P2613, DOI 10.1109/ICIP.2010.5651655
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   De Abreu A., 2013, P PCS SAN JOS CA US
   De Abreu A., 2014, P IEEE VCIP VALL MAL
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   De Abreu A, 2013, IEEE SIGNAL PROC LET, V20, P603, DOI 10.1109/LSP.2013.2259815
   Dröe M, 2006, IEEE IMAGE PROC, P2977
   FEHN C, DEPTH IMAGE BASED RE
   Fiandrotti A., 2010, P VCIP
   Fujihashi T, 2014, IEEE T MULTIMEDIA, V16, P228, DOI 10.1109/TMM.2013.2281588
   Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926
   Liu YW, 2010, J VIS COMMUN IMAGE R, V21, P523, DOI 10.1016/j.jvcir.2010.02.004
   Ozbek N, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P213, DOI 10.1109/ICME.2006.262420
   Rusanovskyy D., 2011, ISO/IEC JTC1/SC29/WG11, Doc. M20028
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Toni L., 2013, P IEEE MMSP PUL IT
   Xiu XY, 2012, IEEE T MULTIMEDIA, V14, P1109, DOI 10.1109/TMM.2012.2191267
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 25
TC 8
Z9 8
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 255
EP 264
DI 10.1016/j.jvcir.2015.09.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700023
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Karimi, N
   Amindavar, H
   Kirlin, RL
   Rajabi, A
AF Karimi, Naser
   Amindavar, Hamidreza
   Kirlin, Rodney Lynn
   Rajabi, Ahad
TI Blind single-image super resolution based on compressive sensing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind single-image super resolution; Point spread function; Compressive
   sensing; Kernel principal component analysis; Feature space; l(1)
   regularization; Alternative minimization; Overcomplete dictionary
ID SUPERRESOLUTION; MAP
AB Blind super resolution is an interesting area in image processing that can restore high resolution (HR) image without requiring prior information of the volatile point spread function (PSF). In this paper, a novel framework is proposed for blind single-image super resolution (SISR) problem based on compressive sensing (CS) framework that is one of the first works that considers general PSFs. The fundamental idea in the proposed approach is to use sparsity on a known sparse transform domain as a powerful regularizer in both the image and blur domains. Therefore, a new cost function with respect to the unknown HR image patch and PSF kernel is presented and minimization is performed based on two subproblems that are modeled similar to that of CS. Simulation results demonstrate the effectiveness of the proposed algorithm that is competitive with methods that use multiple LR images to achieve a single HR image. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Karimi, Naser; Amindavar, Hamidreza; Rajabi, Ahad] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Kirlin, Rodney Lynn] Univ Victoria, Dept Elect Engn, Victoria, BC V8W 2Y2, Canada.
C3 Amirkabir University of Technology; University of Victoria
RP Karimi, N (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, 424,Hafez Ave,POB 15875-4413, Tehran, Iran.
EM naser.karimi@aut.ac.ir
RI Hamidreza, Hamidreza/ABC-1981-2021
OI Hamidreza, Hamidreza/0000-0002-0954-0674
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fei Han, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P399, DOI 10.1109/PSIVT.2010.73
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   He Y, 2009, IMAGE VISION COMPUT, V27, P364, DOI 10.1016/j.imavis.2008.05.010
   Kenig T, 2010, IEEE T PATTERN ANAL, V32, P2191, DOI 10.1109/TPAMI.2010.45
   Kulkarni N, 2012, IEEE T CIRC SYST VID, V22, P778, DOI 10.1109/TCSVT.2011.2180773
   Mika S, 1999, ADV NEUR IN, V11, P536
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P1299, DOI 10.1109/83.941854
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Rajan D, 2003, IEEE T PATTERN ANAL, V25, P1102, DOI 10.1109/TPAMI.2003.1227986
   Rathi Yogesh., 2006, STAT SHAPE ANAL USIN
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sroubek F, 2007, IEEE T IMAGE PROCESS, V16, P2322, DOI 10.1109/TIP.2007.903256
   Sroubek F, 2009, COMPUT J, V52, P142, DOI 10.1093/comjnl/bxm098
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woods NA, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P303
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JL, 2010, IEEE T IMAGE PROCESS, V19, P668, DOI 10.1109/TIP.2009.2036708
   Zhang W, 2008, IEEE IMAGE PROC, P329, DOI 10.1109/ICIP.2008.4711758
NR 25
TC 6
Z9 6
U1 2
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 94
EP 103
DI 10.1016/j.jvcir.2015.09.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700010
DA 2024-07-18
ER

PT J
AU Lin, CH
   Lee, YS
   Chen, TH
AF Lin, Chih-Hung
   Lee, Yao-Sheng
   Chen, Tzung-Her
TI Friendly progressive random-grid-based visual secret sharing with
   adaptive contrast
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; Random grid; Pixel expansion; Friendly;
   Progressive; Chaos; Adaptive contrast; Visual cryptography
ID IMAGE ENCRYPTION; CRYPTOGRAPHY
AB Visual secret sharing (VSS) schemes providing secret communication services are classified into two categories depending on the method of encoding the secret: visual cryptography (VC)-based and random grid (RG)-based schemes. A friendly progressive version of the VC-based VSS scheme was presented in 2008; however, it is marred by pixel expansion, which is the innate deficiency of conventional VC-based VSS schemes. This paper proposes a suitable user-friendly RG-based VSS scheme with progressive secret reconstruction and without pixel expansion. The experimental results of the developed scheme validated its feasibility, and a theoretical analysis demonstrated its visual quality and security. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lin, Chih-Hung] Natl Chiayi Univ, Grad Inst Math & Sci Educ, Chiayi 621, Taiwan.
   [Lee, Yao-Sheng; Chen, Tzung-Her] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan.
C3 National Chiayi University; National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology, R.O.C. [MOST 103-2221-E-415-017,
   MOST 104-2221-E-415-013]
FX This research was partially supported by Ministry of Science and
   Technology, R.O.C., under contract no. MOST 103-2221-E-415-017 and MOST
   104-2221-E-415-013. The authors would like to thank the anonymous
   referees and the associate editor for your valuable suggestions that
   have resulted in the improvement of the correctness and completeness of
   the paper. They also thank I-Chun Weng for her assistance with the
   revision for conducting the further experiments.
CR Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Chen SK, 2009, OPT ENG, V48, DOI 10.1117/1.3262345
   Chen TH, 2006, PATTERN RECOGN, V39, P1530, DOI 10.1016/j.patcog.2006.02.009
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Fang W.-P., 2006, Pattern Recognition and Image Analysis, V16, P632, DOI 10.1134/S1054661806040080
   Fang WP, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2193912
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tsai DS, 2008, IMAGING SCI J, V56, P49, DOI 10.1179/174313107X214330
   Tzung-Her Chen, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P353, DOI 10.1109/IIH-MSP.2009.135
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 21
TC 16
Z9 17
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 31
EP 41
DI 10.1016/j.jvcir.2015.08.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700004
DA 2024-07-18
ER

PT J
AU Liu, Y
   Wang, ZF
AF Liu, Yu
   Wang, Zengfu
TI Dense SIFT for ghost-free multi-exposure fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-exposure fusion; Image fusion; Dense SIFT; Image gradient; High
   dynamic range imaging; Tone mapping; Quality measure; Ghosting artifacts
ID IMAGE FUSION; FILTER
AB Due to the limited capture range of common imaging sensors, a scene with high dynamic range usually cannot be well described by a single still image because some regions in it may be under-exposed or over-exposed. In this paper, a new multi-exposure fusion method based on dense scale invariant feature transform (SIFT) is presented. In our algorithm, the dense SIFT descriptor is first employed as the activity level measurement to extract local details from source images, and then adopted to remove ghosting artifacts when the captured scene is dynamic with moving objects. Furthermore, two popular weight distribution strategies for local contrast extraction, namely, "weighted-average" and "winner-take-all" are studied in this paper. The effects of these two strategies on the fusion results are compared and discussed. Experimental results demonstrate the effectiveness of the proposed method in terms of both visual quality and objective evaluation. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liu, Yu; Wang, Zengfu] Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China.
   [Wang, Zengfu] Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Hefei Institutes of Physical
   Science, CAS
RP Wang, ZF (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China.
EM liuyu1@mail.ustc.edu.cn; zfwang@ustc.edu.cn
RI Liu, Yu/HKF-4917-2023
OI Liu, Yu/0000-0003-2211-3535
FU National Natural Science Foundation of China [61472393]; National
   Science and Technology Projects [2012GB102007]
FX The authors would like to thank the editors and anonymous reviewers for
   their detailed review, valuable comments and constructive suggestions.
   The authors would also like to thank Dr. Rui Shen for providing us with
   the executable file of the GRW method [6]. This work is supported by the
   National Natural Science Foundation of China (No. 61472393) and the
   National Science and Technology Projects (No. 2012GB102007).
CR An J, 2011, INT CONF ACOUST SPEE, P1565
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Granados M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508410
   Gu B, 2012, J VIS COMMUN IMAGE R, V23, P604, DOI 10.1016/j.jvcir.2012.02.009
   Hadziabdic K., 2013, Proceedings of the 29th Spring Conference on Computer Graphics, P21
   Hadziabdic K., 2014, P 2 INT C SME WORKSH
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jinno T, 2012, IEEE T IMAGE PROCESS, V21, P358, DOI 10.1109/TIP.2011.2160953
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Petrovic V, 2007, INFORM FUSION, V8, P208, DOI 10.1016/j.inffus.2005.05.001
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Piella G, 2009, INT J COMPUT VISION, V83, P1, DOI 10.1007/s11263-009-0206-4
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Shen R, 2013, IEEE T IMAGE PROCESS, V22, P2469, DOI 10.1109/TIP.2012.2236346
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001
   Stathaki T, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P1
   Tomaszewska A, 2007, WSCG 2007, FULL PAPERS PROCEEDINGS I AND II, P49
   Wang CM, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P904, DOI 10.1109/CISP.2013.6745293
   Ward G., 2003, Journal of Graphics Tools, V8, P17, DOI 10.1080/10867651.2003.10487583
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
NR 40
TC 105
Z9 123
U1 9
U2 61
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 208
EP 224
DI 10.1016/j.jvcir.2015.06.021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600019
DA 2024-07-18
ER

PT J
AU Verma, VS
   Jha, RK
   Ojha, A
AF Verma, Vivek Singh
   Jha, Rajib Kumar
   Ojha, Aparajita
TI Digital watermark extraction using support vector machine with principal
   component analysis based feature reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lifting wavelet transform; Support vector machine; Coefficient
   difference; Feature reduction; Watermarking; Attacks; PCA; Digital image
   watermarking
ID IMAGE WATERMARKING; LIFTING SCHEME; TRANSFORM; INTERPOLATION;
   CONSTRUCTION; ALGORITHM
AB This paper proposes a new approach for watermark extraction using support vector machine (SVM) with principal component analysis (PCA) based feature reduction. In this method, the original cover image is decomposed up to three level using lifting wavelet transform (LWT), and lowpass subband is selected for data hiding purpose. The lowpass subband is divided into small blocks, and a binary watermark is embedded into the original cover image by quantizing the two maximum coefficients of the block. In order to extract watermark bits with maximum correlation, SVM based binary classification approach is incorporated. The training and testing patterns are constructed by employing a reduced set of features along with block coefficients. Firstly, different features are obtained by evaluating the statistical parameters of each block coefficients, and then PCA is utilized to reduce this feature set. As far as security is concerned, randomization of coefficients, blocks, and watermark bits enhances the security of system. Furthermore, energy compaction property of LWT increases the robustness in comparison to conventional wavelet transform. A comparison of the proposed method with some of the recent techniques shows remarkable improvement in terms of robustness and security of the watermark. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Verma, Vivek Singh; Ojha, Aparajita] Indian Inst Informat Technol Design & Mfg, PDPM, Jabalpur 482005, India.
   [Jha, Rajib Kumar] Indian Inst Technol Patna, Patna 800013, Bihar, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Patna
RP Jha, RK (corresponding author), Indian Inst Technol Patna, Patna 800013, Bihar, India.
EM viveksv10@gmail.com; jharajib@gmail.com; aparajitaojha@gmail.com
RI Verma, Vivek Singh/HLH-7169-2023; Ojha, Aparajita/Q-3902-2016; Verma,
   Vivek/AAE-4391-2020
OI Verma, Vivek Singh/0000-0002-1497-2754; Ojha,
   Aparajita/0000-0003-1567-8378; 
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   Bohra A, 2009, AEU-INT J ELECTRON C, V63, P703, DOI 10.1016/j.aeue.2008.05.010
   Chang CH, 2005, IEEE T CIRC SYST VID, V15, P65, DOI 10.1109/TCSVT.2004.839992
   Chen DY, 2000, IEEE T CONSUM ELECTR, V46, P404, DOI 10.1109/30.883385
   Claypoole RL, 1998, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.1998.681737
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Fu YG, 2013, OPTIK, V124, P517, DOI 10.1016/j.ijleo.2011.12.042
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Gu QL, 2013, DIGIT SIGNAL PROCESS, V23, P213, DOI 10.1016/j.dsp.2012.07.013
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Jackson J. E., 2005, USERS GUIDE PRINCIPA
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mardia KV, 1979, MULTIVARIATE ANAL
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   PETITCOLAS FAP, 1997, WEAKNESS EXISTING WA
   Ramanjaneyulu K, 2012, IET IMAGE PROCESS, V6, P364, DOI 10.1049/iet-ipr.2010.0347
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Verma VS, 2014, SIGNAL IMAGE VIDEO P, P1
   Wang FX, 2008, INT CONF SIGN PROCES, P2194
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang XY, 2008, SIGNAL PROCESS, V88, P2193, DOI 10.1016/j.sigpro.2008.03.005
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
NR 41
TC 40
Z9 43
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 75
EP 85
DI 10.1016/j.jvcir.2015.06.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600007
DA 2024-07-18
ER

PT J
AU Hu, LJ
   Nooshabadi, S
AF Hu, Linjia
   Nooshabadi, Saeid
TI G-SHOT: GPU accelerated 3D local descriptor for surface matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D Object local descriptor; Point signature; Surface matching; SHOT;
   Computer vision; Point cloud library; Parallel algorithm; GPU; Real-time
   processing; Point cloud
ID OBJECT RECOGNITION; IMAGES
AB Signature of histogram of orientations (SHOT) as a novel 3D object local descriptor can achieves a good balance between descriptiveness and robustness in surface matching. However, its computation workload is much higher than the other 3D local descriptors. This paper investigates the development of suitable massively parallel algorithms on the graphics processing unit (GPU) for computation of high density and large scale 3D object local descriptors through two alternative parallel algorithms; one exact, and one approximate. Both algorithms exhibit outstanding speedup performance. The exact parallel descriptor comes at no cost to the descriptiveness, with a speedup factor of up to 40.70, with respect to the serial SHOT on the central processing unit (CPU). The approximate version achieves a corresponding speedup factor of up to 54 with minor degradation in descriptiveness. The proposed algorithms are integrated into point cloud library (PCL), a open source project for image and point cloud. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hu, Linjia; Nooshabadi, Saeid] Michigan Technol Univ, Dept Comp Sci, Houghton, MI 49931 USA.
C3 Michigan Technological University
RP Nooshabadi, S (corresponding author), Michigan Technol Univ, Dept Comp Sci, Houghton, MI 49931 USA.
EM linjiah@mtu.edu; saeid@mtu.edu
CR [Anonymous], FERMI COMP ARCH WHIT
   [Anonymous], 2006, WORKSH EDG COMP US N
   [Anonymous], 2011, IEEE INT C ROBOTICS
   [Anonymous], 2011, NVIDIA CUDA Compute Unified Device Architecture, Programming Guide
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Frome A., 2004, EUR C COMP VIS ECCV
   Fung J., 2005, 13th Annual ACM International Conference on Multimedia, P849, DOI 10.1145/1101149.1101334
   Ha P.H., 2008, P INT S DISTR COMP D
   HARRIS MJ, 2002, P SIGGRAPH EUR WORKS
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kitaaki Yasuo, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P3055, DOI 10.1109/SICE.2008.4655188
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Novatnack J., 2008, EUR C COMP VIS ECCV
   NVIDIA, 2009, NVIDIA FERM GTX570 C
   Qiu DY, 2009, LECT NOTES COMPUT SC, V5815, P194
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Stein F., 1992, IEEE T PATTERN ANAL, V5, P1645
   Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634
   Tombari F., 2011, IEEE INT C INT ROBOT
   Volkov V., 2010, GPU TECHN C GTC SAN
   Zhong Y., 2009, INT C COMP VIS WORKS
NR 24
TC 4
Z9 7
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 343
EP 349
DI 10.1016/j.jvcir.2015.05.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900030
DA 2024-07-18
ER

PT J
AU Ji, ZJ
   Wang, WQ
AF Ji, Zhangjian
   Wang, Weiqiang
TI Object tracking based on local dynamic sparse model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Local dynamic sparsity; Multi-task sparse model;
   Occlusion detection; Weighted likelihood probability; Accelerated
   proximal gradient; Particle filter; Sparse representation
ID VISUAL TRACKING; ROBUST; OCCLUSION
AB Sparse representation has been widely applied in many objecting tracking methods. In this paper, we present a robust and effective object tracking approach based on the local dynamic sparse model, called Local Dynamic Sparse Tracking (LDST). In the proposed method, the local patches of a tracked object are linearly represented by their respective dictionary updated online, and the inter-frame correlation between sparse representations of corresponding patches are modeled in the time domain. To further improve its robustness, the dependency of sparse coefficients between patches in each frame is also characterized by the 12 mixed norms. In addition, for each patch, different weights are exploited in calculating the likelihood probability, in order to eliminate the effect of occluded patches when updating templates. The evaluation experiments on the challenging sequences demonstrate that the proposed method has the better performance compared with some typical state-of-the-art methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ji, Zhangjian; Wang, Weiqiang] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Wang, WQ (corresponding author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
EM jizhangjian08@mails.ucas.ac.cn; wqwang@ucas.ac.cn
OI Ji, Zhangjian/0000-0002-9407-2878
FU National Natural Science Foundation of China [61232013, 61271434,
   61175115]
FX This work is supported by the National Natural Science Foundation of
   China Under Grant Nos. 61232013, 61271434, 61175115. The authors also
   would like to thank the anonymous reviewers for their valuable
   suggestions.
CR Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Ayvaci Alper., 2010, Advances_in_neural_information_processing systems, P100
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Balan A.O., 2006, COMPUTER VISION PATT, V1, P758
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Charles A., 2011, 45th Annual Conference on Information Sciences and Systems (CISS), P1
   Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Han BY, 2005, IEEE I CONF COMP VIS, P1492
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Hu WM, 2011, INT J COMPUT VISION, V91, P303, DOI 10.1007/s11263-010-0399-6
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Kwon J, 2008, LECT NOTES COMPUT SC, V5302, P387, DOI 10.1007/978-3-540-88682-2_30
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nesterov Y., 2007, Gradient methods for minimizing composite objective function
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou XZ, 2010, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR.2010.5539856
NR 34
TC 12
Z9 13
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 44
EP 52
DI 10.1016/j.jvcir.2015.01.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000006
DA 2024-07-18
ER

PT J
AU Zhang, H
   Liu, Y
   Xie, BJ
   Yu, J
AF Zhang, Hui
   Liu, Yi
   Xie, Bojun
   Yu, Jian
TI Spatially constrained sparse coding scheme for natural scene
   categorization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene categorization; Receptive fields learning; Boosting; Sparse
   coding; k-nearest neighbor; Voting; Image classification; Pooling
ID RECEPTIVE-FIELDS; IMAGE; MODEL
AB Coding and pooling, the major two sequential procedures in sparse coding based scene categorization systems, have drawn much attention in recent years. Yet improvements have been made for coding or pooling separately, this paper proposes a spatially constrained scheme for sparse coding on both steps. Specifically, we employ the m-nearest neighbors of a local feature in the image space to improve the consistency of coding. The benefit is that similar image features will be encoded with similar codewords, which reduced the stochasticity of a conventional coding strategy. We also show that the Viola-Jones algorithm, which is well-known in face detection, can be tailored to learning receptive fields, embedding the spatially constrained information on the pooling step. Extensive experiments on the URIC sport event, 15 natural scenes and the Caltech 101 database suggests that scene categorization performance of several popular algorithms can be ubiquitously improved by incorporating the proposed two spatially constrained sparse coding scheme. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Hui; Liu, Yi; Xie, Bojun; Yu, Jian] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
   [Zhang, Hui; Xie, Bojun] Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding, Hebei, Peoples R China.
C3 Beijing Jiaotong University; Hebei University
RP Liu, Y (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
EM yiliu@bjtu.edu.cn
RI Yu, Jian/HJY-2670-2023
FU Natural Science Foundation of China [61300072, 61033013]; Beijing
   Jiaotong University [2014RC048, 2012RC042]; Fundamental Research Funds
   for the Central Universities [2014JBZ005]; PhD Programs Foundation of
   the Ministry of Education of China [20120009110006]; Beijing Committee
   of Science and Technology, China [Z131110002813118]
FX The authors acknowledge support from the Natural Science Foundation of
   China (Nos. 61300072, 61033013), from Beijing Jiaotong University (Nos.
   2014RC048, 2012RC042), from the Fundamental Research Funds for the
   Central Universities (No. 2014JBZ005), from the PhD Programs Foundation
   of the Ministry of Education of China (No. 20120009110006) and from the
   Beijing Committee of Science and Technology, China (No.
   Z131110002813118).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], BMVC
   Benbouzid D, 2012, J MACH LEARN RES, V13, P549
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Busa-Fekete R., 2010, Proceedings of the International Conference on Machine Learning, P143
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fei-Fei L., 2004, P CVPR
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Goh H, 2012, LECT NOTES COMPUT SC, V7576, P298, DOI 10.1007/978-3-642-33715-4_22
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang Y., 2011, P CVPR, P2486
   Hyvärinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Lazebnik S., 2006, Proceedings of conference on computer vision and pattern recognition, P21692178
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Liu L., 2011, P ICCV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Shabou A, 2012, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2012.6248107
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yan SY, 2012, LECT NOTES COMPUT SC, V7575, P473, DOI 10.1007/978-3-642-33765-9_34
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yu J, 2014, PATTERN RECOGN, V47, P3512, DOI 10.1016/j.patcog.2014.05.002
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang H, 2013, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2013.6738055
NR 34
TC 5
Z9 5
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 28
EP 35
DI 10.1016/j.jvcir.2015.01.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000004
DA 2024-07-18
ER

PT J
AU Galdran, A
   Pardo, D
   Picón, A
   Alvarez-Gila, A
AF Galdran, Adrian
   Pardo, David
   Picon, Artzai
   Alvarez-Gila, Aitor
TI Automatic Red-Channel underwater image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image restoration; Color correction; Image dehazing; Contrast
   enhancement; Visibility recovery; Dark Channel; Artificial lighting;
   Attenuation; Underwater image degradation
ID COLOR; MOSAICS
AB Underwater images typically exhibit color distortion and low contrast as a result of the exponential decay that light suffers as it travels. Moreover, colors associated to different wavelengths have different attenuation rates, being the red wavelength the one that attenuates the fastest. To restore underwater images, we propose a Red Channel method, where colors associated to short wavelengths are recovered, as expected for underwater images, leading to a recovery of the lost contrast. The Red Channel method can be interpreted as a variant of the Dark Channel method used for images degraded by the atmosphere when exposed to haze. Experimental results show that our technique handles gracefully artificially illuminated areas, and achieves a natural color correction and superior or equivalent visibility improvement when compared to other state-of-the-art methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Galdran, Adrian; Picon, Artzai; Alvarez-Gila, Aitor] TECNALIA Res & Innovat, E-48170 Zamudio, Spain.
   [Galdran, Adrian; Pardo, David] Univ Basque Country, Dept Appl Math Stat & Operat Res, E-48940 Leioa, Spain.
   [Pardo, David] Basque Ctr Appl Math, Bcam Bilbao, Spain.
   [Pardo, David] Ikerbasque, Basque Fdn Sci, E-48011 Bilbao, Spain.
C3 University of Basque Country; Basque Center for Applied Mathematics
   (BCAM); Basque Foundation for Science
RP Galdran, A (corresponding author), Tecnalia, Comp Vis Grp, Parque Cient Tecnol Bizkaia,C Geldo Edificio 700, E-48160 Derio, Spain.
EM adrian.galdran@tecnalia.com
RI Pardo, David/A-7457-2009
OI Pardo, David/0000-0002-1101-2248; Picon, Artzai/0000-0002-3316-6571;
   Galdran, Adrian/0000-0002-5992-1520; Alvarez-Gila,
   Aitor/0000-0002-5955-3211
FU Project of the Spanish Ministry of Economy and Competitiveness
   [MTM2013-40824-P]; BCAM "Severo Ochoa" accreditation of excellence
   [SEV-2013-0323]; CYTED [712RT0449]; Basque Government Consolidated
   Research Group Grant on "Mathematical Modeling, Simulation, and
   Industrial Applications (M2SI)" [IT649-13]
FX David Pardo was partially funded by the Project of the Spanish Ministry
   of Economy and Competitiveness with reference MTM2013-40824-P, the BCAM
   "Severo Ochoa" accreditation of excellence SEV-2013-0323, the CYTED 2011
   Project 712RT0449, and the Basque Government Consolidated Research Group
   Grant IT649-13 on "Mathematical Modeling, Simulation, and Industrial
   Applications (M2SI)".
CR Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Bazeille S., 2006, P CMM 06
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chambah M, 2004, PROC SPIE, V5293, P157
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Costa MJ., 2012, OCEANS, P1, DOI DOI 10.1109/0CEANS.2012.6404915
   Gracias N, 2000, COMPUT VIS IMAGE UND, V79, P66, DOI 10.1006/cviu.2000.0848
   Gracias N, 2009, IMAGE VISION COMPUT, V27, P597, DOI 10.1016/j.imavis.2008.04.014
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Henke B, 2013, INT SYMP IMAGE SIG, P20
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Kaftory R., 2007, P IEEE C COMP VIS PA, P1
   Koschmieder H., 1925, Theorie der horizontalen Sichtweite: Kontrast und Sichtweite
   Lévesque D, 2009, IMAGE VISION COMPUT, V27, P19, DOI 10.1016/j.imavis.2006.10.012
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Ludvigsen M, 2007, OCEANOGRAPHY, V20, P140, DOI 10.5670/oceanog.2007.14
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Palma-Amestoy R, 2009, IEEE T PATTERN ANAL, V31, P458, DOI 10.1109/TPAMI.2008.86
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Schechner Y., 2004, P 2004 IEEE COMP SOC, V1
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   STRACHAN NJC, 1993, IMAGE VISION COMPUT, V11, P2, DOI 10.1016/0262-8856(93)90027-E
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
NR 28
TC 566
Z9 641
U1 15
U2 234
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 132
EP 145
DI 10.1016/j.jvcir.2014.11.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000012
OA Green Accepted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Chiu, YH
   Chung, KL
   Lin, CH
AF Chiu, Yung-Hsiang
   Chung, Kuo-Liang
   Lin, Chien-Hsiung
TI An improved universal subsampling strategy for compressing mosaic videos
   with arbitrary RGB color filter arrays in H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 4:2:0 subsampling format; Arbitrary RGB color filter arrays;
   Compression; H.264/AVC; Mosaic videos; RGB color deviation problem;
   Subsampling strategy; Y luma component modification
ID SUPERRESOLUTION; DEMOSAICKING; SEQUENCES
AB This work proposes an improved version of Yang et al.'s universal subsampling strategy for compressing mosaic videos with arbitrary red-green-blue (RGB) color filter arrays in H.264/AVC. For the subsampled images with 4:2:0 format, Yang et al.'s work retains the original Y luma component, but samples the proper U and V chroma components according to the corresponding mosaic structure for better reconstructing R and B pixels. However, Yang et al.'s strategy suffers from the RGB color deviations due to the U and V chroma subsampling, which results in the quality degradation of the reconstructed mosaic videos. We propose a novel modification for the Y luma component instead of only retaining the Y luma component such that the RGB color deviation problem can be resolved. Experimental results demonstrate that the proposed improved universal subsampling strategy delivers better quality of the reconstructed mosaic and full-color videos, when compared with Yang et al.'s one. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chiu, Yung-Hsiang; Chung, Kuo-Liang; Lin, Chien-Hsiung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM d9409301@mail.ntust.edu.tw
FU National Science Council of Taiwan [NSC101-2221-E-011-139-MY3,
   NSC102-2221-E-011-055-MY3]
FX This work was supported by the National Science Council of Taiwan, under
   the Contracts NSC101-2221-E-011-139-MY3 and NSC102-2221-E-011-055-MY3.
CR [Anonymous], 2005, Image Sensors and Signal Processing for Digital Still Cameras
   [Anonymous], P SPIE
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bjotegaard G., 2001, VCEGM33
   Chen H, 2009, IEEE T CIRC SYST VID, V19, P1891, DOI 10.1109/TCSVT.2009.2031370
   Doutre C, 2008, IEEE T CIRC SYST VID, V18, P725, DOI 10.1109/TCSVT.2008.919111
   Doutre C, 2009, IEEE IMAGE PROC, P3401, DOI 10.1109/ICIP.2009.5413873
   Farsiu S, 2006, IEEE T IMAGE PROCESS, V15, P141, DOI 10.1109/TIP.2005.860336
   Gastaldi F., 2005, P 13 EUR SIGN PROC C, P983
   Gunturk BK, 2005, IEEE SIGNAL PROC MAG, V22, P44, DOI 10.1109/MSP.2005.1407714
   Heiss-Czedik D, 2009, J VIS COMMUN IMAGE R, V20, P389, DOI 10.1016/j.jvcir.2009.04.003
   Karch BK, 2013, OPT EXPRESS, V21, P18820, DOI 10.1364/OE.21.018820
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Lukac R, 2005, PATTERN RECOGN, V38, P2208, DOI 10.1016/j.patcog.2005.04.008
   Lukac R, 2004, IEEE T CONSUM ELECTR, V50, P15, DOI 10.1109/TCE.2004.1277836
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Yang WJ, 2013, IEEE T CIRC SYST VID, V23, P591, DOI 10.1109/TCSVT.2012.2210805
NR 17
TC 5
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1791
EP 1799
DI 10.1016/j.jvcir.2014.07.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100028
DA 2024-07-18
ER

PT J
AU Huang, C
   Han, TX
   He, ZH
AF Huang, Chen
   Han, Tony X.
   He, Zhihai
TI Multi-scale embedded descriptor for shape classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape descriptor; Feature extraction; Running angle; 2-D description
   image; Subband decomposition; Wavelet transformation; Object
   recognition; Image classification
ID NONRIGID SHAPES; RECOGNITION
AB We present a new shape descriptor that are robust to deformation and capture part details. In our framework, the shape descriptor is generated by (1) using running angle to transforming a shape into a 2-D description image in the position and scale space and (2) performing circular wavelet-like sub-band decomposition of this 2-D description image based on its periodic convolution with orthogonal kernel functions. Each sub-band is described by the histogram of its decomposition coefficients. To capture unique and discriminative part, we compare the decomposition coefficients across sub-band to detect singularity in the position and scale space. The singularity information is encoded with a tree of binary bits. The coded feature vectors of all sub-bands and singularity trees are pooled together to form the descriptor of the shape. The shapes are classified with linear SVM. Our performance evaluations on several public datasets, demonstrating that the proposed method significantly outperforms state-of-the-art methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Huang, Chen; Han, Tony X.; He, Zhihai] Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
C3 University of Missouri System; University of Missouri Columbia
RP He, ZH (corresponding author), Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
EM chenhuang@mail.missouri.edu; hantx@missouri.edu; HeZhi@missouri.edu
RI Huang, Chen/AAY-4934-2020; He, Zhihai/A-5885-2019
FU Div Of Biological Infrastructure; Direct For Biological Sciences
   [1062354] Funding Source: National Science Foundation
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6
   Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Felzenszwalb PF, 2007, PROC CVPR IEEE, P367
   HOLSCHNEIDER M, 1990, J MATH PHYS, V31, P39, DOI 10.1063/1.528825
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Latecki LJ, 2007, PATTERN RECOGN, V40, P3069, DOI 10.1016/j.patcog.2007.03.004
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772
   Soderkvist O., 2001, COMPUTER VISION CLAS
   Temlyakov A, 2010, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2010.5539912
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Yu Cao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2345, DOI 10.1109/CVPR.2011.5995588
NR 21
TC 5
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1640
EP 1646
DI 10.1016/j.jvcir.2014.08.005
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100015
DA 2024-07-18
ER

PT J
AU Wang, HL
   Du, H
   Lin, WY
   Kwong, S
   Au, OC
   Wu, J
   Wei, ZH
AF Wang, Hanli
   Du, Han
   Lin, Weiyao
   Kwong, Sam
   Au, Oscar C.
   Wu, Jun
   Wei, Zhihua
TI Early detection of all-zero 4 x 4 blocks in High Efficiency Video Coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Zero coefficients; DCT; Quantization; Fast encoding; Video
   quality; Compression efficiency; Early detection
ID QUANTIZED DCT COEFFICIENTS; DECISION METHOD; PREDICTION; COMPLEXITY;
   ALGORITHM; MODEL
AB Similar to previous video coding standards, transform and quantization are employed in the most recent video coding standard High Efficiency Video Coding (HEVC), and there exist a large number of transform coefficients being quantized to zeros. In order to reduce the computations in transform and quantization, a novel prediction algorithm is designed to early detect all-zero 4 x 4 blocks prior to transform and quantization. A theoretical analysis is performed on the 4 x 4 Discrete Cosine Transform (DCT) and the related quantization functions in HEVC; consequently, two sufficient conditions to early detect all-zero 4 x 4 blocks are derived and the proposed prediction algorithm is developed while balancing the detection efficiency and computational overheads. Experimental results demonstrate that the proposed algorithm is able to efficiently predict all-zero 4 x 4 blocks and reduce redundant DCT and quantization computations while maintaining the same coding performance in terms of video quality and bit rates. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Hanli; Du, Han; Wu, Jun; Wei, Zhihua] Tongji Univ, Minist Educ, Key Lab Embedded Syst & Serv Comp, Dept Comp Sci & Technol, Shanghai 200092, Peoples R China.
   [Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Au, Oscar C.] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Tongji University; Shanghai Jiao Tong University; City University of
   Hong Kong; Hong Kong University of Science & Technology
RP Wang, HL (corresponding author), Tongji Univ, Minist Educ, Key Lab Embedded Syst & Serv Comp, Dept Comp Sci & Technol, Shanghai 200092, Peoples R China.
EM hanliwang@tongji.edu.cn; 1233703@tongji.edu.cn; hellomikelin@gmail.com;
   cssamk@cityu.edu.hk; eeau@ust.hk; wujun@tongji.edu.cn;
   Zhihua_Wei@tongji.edu.cn
RI Wang, Hanli/K-5717-2019; Wang, Hanli/G-5111-2014; Kwong, Sam/C-9319-2012
OI Wang, Hanli/0000-0002-9999-4871; Wang, Hanli/0000-0002-9999-4871; Kwong,
   Sam/0000-0001-7484-7261
FU National Natural Science Foundation of China [61102059, 61472281,
   61471235]; "Shu Guang" project of Shanghai Municipal Education
   Commission; Shanghai Education Development Foundation [12SG23]; Program
   for Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning; Fundamental Research Funds for the
   Central Universities [0800219158, 0800219270]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61102059, 61472281 and 61471235, the
   "Shu Guang" project of Shanghai Municipal Education Commission and
   Shanghai Education Development Foundation under Grant 12SG23, the
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning, the Fundamental Research Funds
   for the Central Universities under Grants 0800219158 and 0800219270.
CR [Anonymous], 2005, 14496102005E ISOIEC
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Bross B, 2013, JCTVCL1003V34
   Chen KH., 2012, SAE Int., V1, P1, DOI DOI 10.4271/2012-01-0645
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Choi K, 2012, ELECTRON LETT, V48, P689, DOI 10.1049/el.2012.0277
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   JCT-VC, 2012, SUBV REP HEVC TEST M
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   [李保松 Li Baosong], 2011, [高分子通报, Polymer Bulletin], P1
   Li J, 2012, IEEE T CIRC SYST VID, V22, P249, DOI 10.1109/TCSVT.2011.2160749
   Moon YH, 2005, IEEE T CIRC SYST VID, V15, P1053, DOI 10.1109/TCSVT.2005.852411
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Sampaio F., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P657, DOI 10.1109/ICME.2012.37
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sinangil ME, 2013, IEEE J-STSP, V7, P1017, DOI 10.1109/JSTSP.2013.2273658
   Sousa LA, 2000, ELECTRON LETT, V36, P306, DOI 10.1049/el:20000272
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P509, DOI 10.1109/PCS.2012.6213266
   Wang HL, 2007, IMAGE VISION COMPUT, V25, P922, DOI 10.1016/j.imavis.2006.07.007
   Wang HL, 2007, IEEE T MULTIMEDIA, V9, P728, DOI 10.1109/TMM.2007.893336
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Wiegand T, 1996, IEEE T CIRC SYST VID, V6, P182, DOI 10.1109/76.488825
   Wige E, 2014, IEEE T CIRC SYST VID, V24, P1142, DOI 10.1109/TCSVT.2014.2302377
   Yu A, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P21, DOI 10.1145/266180.266326
   Zhang MJ, 2009, IEEE T CIRC SYST VID, V19, P103, DOI 10.1109/TCSVT.2008.2009239
   Zhou X, 1998, ELECTRON LETT, V34, P1839, DOI 10.1049/el:19981308
NR 31
TC 18
Z9 18
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1784
EP 1790
DI 10.1016/j.jvcir.2014.08.007
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100027
DA 2024-07-18
ER

PT J
AU Kieu, TD
   Rudder, A
   Goodridge, W
AF The Duc Kieu
   Rudder, Andrew
   Goodridge, Wayne
TI A reversible steganographic scheme for VQ indices based on locally
   adaptive coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Information hiding; Steganography; Watermarking; Reversible data
   embedding; Vector quantization; Image compression; Locally adaptive
   coding; Lossless data hiding
ID DATA HIDING SCHEME; EXPANSION
AB Achieving a high embedding capacity and low compression rate with a reversible data hiding method in the vector quantization (VQ) compressed domain is a technically challenging problem. This paper proposes a novel reversible steganographic scheme for VQ compressed images based on a locally adaptive data compression method. The proposed method embeds n secret bits into one VQ index of an index table in Hilbert-curve scan order. The experimental results show that the proposed method can achieve the different average embedding rates of 0.99, 1.68, 2.28, and 3.04 bit per index (bpi) and average compression rates of 0.45, 0.46, 0.5, and 0.56 bit per pixel (bpp) for n = 1, 2, 3, and 4, respectively. These results indicate that the proposed scheme is superior to Chang et al.'s scheme 1 [19], Yang and Lin's scheme [21], and Chang et al.'s scheme 2 [24]. (C) 2014 Elsevier Inc. All rights reserved.
C1 [The Duc Kieu; Rudder, Andrew; Goodridge, Wayne] Univ W Indies, Fac Sci & Technol, Dept Comp & Informat Technol, St Augustine, Trinidad Tobago.
C3 University West Indies Mona Jamaica; University West Indies Saint
   Augustine
RP Kieu, TD (corresponding author), Univ W Indies, Fac Sci & Technol, Dept Comp & Informat Technol, St Augustine, Trinidad Tobago.
EM ktduc0323@yahoo.com.au; andrew.rudder@sta.uwi.edu;
   wayne.goodridge@sta.uwi.edu
RI Rudder, Andrew/AEX-8439-2022
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Cox, 2007, DIGITAL WATERMARKING
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Li X., IEEE T IMAGE PROCESS, V20
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Pan JS, 2004, IEICE T FUND ELECTR, VE87A, P1839
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Salomon D., 2009, HDB DATA COMPRESSION
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Yang C.H., IEEE T INF FORENSICS, V3
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
NR 25
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1378
EP 1386
DI 10.1016/j.jvcir.2014.06.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100008
DA 2024-07-18
ER

PT J
AU Wang, C
   Ma, KK
AF Wang, Chen
   Ma, Kai-Kuang
TI Bipartite graph-based mismatch removal for wide-baseline image matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Wide-baseline image matching; Region correspondence; Point
   correspondence; Coherent region pair; SIFT feature descriptor; Bipartite
   graph matching; Region similarity measurement metric; Hungarian method
AB The conventional wide-baseline image matching aims to establish point-to-point correspondence pairs across the two images under matching. This is normally accomplished by identifying those feature points with most similar local features represented by feature descriptors and measuring the feature-vector distance based on the nearest neighbor matching criterion. However, a large number of mismatches would be incurred especially when the two images under comparison have a large viewpoint variation with respect to each other or involve very different backgrounds. In this paper, a new mismatch removal method is proposed by utilizing the bipartite graph to first establish one-to-one coherent region pairs (CRPs), which are then used to verify whether each point-to-point matching pair is a correct match or not. The generation of CRPs is achieved by applying the Hungarian method to the bipartite graph, together with the use of the proposed region-to-region similarity measurement metric. Extensive experimental results have demonstrated that our proposed mismatch removal method is able to effectively remove a significant number of mismatched point-to-point correspondences. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Chen; Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Ma, KK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM wa0002en@e.ntu.edu.sg; ekkma@ntu.edu.sg
RI Ma, Kai-Kuang/KBA-9411-2024
CR [Anonymous], P INT C COMP VIS
   Berg AC, 2005, PROC CVPR IEEE, P26
   Bin Gao, 2005, 13th Annual ACM International Conference on Multimedia, P112
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Diestel R., 2005, GRAPH THEORY
   Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ferrari V, 2003, PROC CVPR IEEE, P718
   Fischer B, 2003, IEEE T PATTERN ANAL, V25, P513, DOI 10.1109/TPAMI.2003.1190577
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Kolmogorov V., 2001, P INT C COMP VIS, P78
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Pritchett P., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P78
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Xiang SM, 2010, IEEE T IMAGE PROCESS, V19, P3024, DOI 10.1109/TIP.2010.2052268
   Xiang SM, 2009, IEEE T IMAGE PROCESS, V18, P1623, DOI 10.1109/TIP.2009.2018570
   Zhou W., 2011, Proceedings of ACM Multimedia, P1349, DOI DOI 10.1145/2072298.2072012
   Zhou W., 2010, P 18 ACM INT C MULTI, P511
NR 24
TC 7
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1416
EP 1424
DI 10.1016/j.jvcir.2013.12.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100011
DA 2024-07-18
ER

PT J
AU Dahmani, D
   Larabi, S
AF Dahmani, Djamila
   Larabi, Slimane
TI User-independent system for sign language finger spelling recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand posture; Shape recognition; Hand segmentation; Tchebichef moments;
   Hu moments; Sign language; Recognition; Classification
ID HAND POSTURES; GESTURE; MOMENTS
AB We propose in this paper a framework for recognizing the sign language alphabet. To separate hand images from complex backgrounds, We use skin colour and texture attributes with neural networks. The recognition process is based on the combination of three shape descriptors: Discrete orthogonal Tchebichef moments applied on both internal and external outlines hand, Hu moments and a set of geometric features derived from the convex hull that encloses the hand shape taking into account the hand orientation.
   The recognition is carried out using KNN and SVM classifiers. The proposed descriptors are combined in several sequential and parallel manners and applied on different datasets. The obtained results are compared to existing works. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Dahmani, Djamila; Larabi, Slimane] Univ Sci & Technol Houari, Dept Comp Sci, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Larabi, S (corresponding author), Univ Sci & Technol Houari, Dept Comp Sci, Algiers, Algeria.
EM slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI larabi, slimane/0000-0001-8994-5980
CR Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   Al-Rousan M., 2001, International Journal of Computers and Their Applications, V8, P80
   AL-Rousan M, 2009, APPL SOFT COMPUT, V9, P990, DOI 10.1016/j.asoc.2009.01.002
   [Anonymous], 2011, Visual Analysis of Humans: Looking at People, DOI DOI 10.1007/978-0-85729-997-027
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], ADV LARGE MARGIN CLA
   [Anonymous], WORKSH INT GEST LANG
   [Anonymous], TECHNOL DISABILITY
   [Anonymous], AAAI FALL S DIS CAMB
   Aran O, 2009, PATTERN RECOGN, V42, P812, DOI 10.1016/j.patcog.2008.09.010
   Assaleh K, 2005, EURASIP J APPL SIG P, V2005, P2136, DOI 10.1155/ASP.2005.2136
   Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332
   Bauer B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P440, DOI 10.1109/AFGR.2000.840672
   Bowden R., 2004, P 8 EUROPEAN C COMPU, P391
   Chang CC, 2006, J INF SCI ENG, V22, P1047
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Gao W, 2004, PATTERN RECOGN, V37, P2389, DOI [10.1016/S0031-3203(04)00165-7, 10.1016/j.patcog.2004.04.008]
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   Gu LZ, 2008, IEEE INT CONF ROBOT, P3088, DOI 10.1109/ROBOT.2008.4543680
   Haralick R.M., 1973, IEEETRANSACTIONS SYS, V3, P610621
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hwang CL, 2011, IEEE SYS MAN CYBERN, P2056, DOI 10.1109/ICSMC.2011.6083975
   Ilea DE, 2011, PATTERN RECOGN, V44, P2479, DOI 10.1016/j.patcog.2011.03.005
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Kim JS, 1996, IEEE T SYST MAN CY B, V26, P354, DOI 10.1109/3477.485888
   Last A, 2002, PATTERN ANAL APPL, V5, P385, DOI 10.1007/s100440200034
   Licsár A, 2005, IMAGE VISION COMPUT, V23, P1102, DOI 10.1016/j.imavis.2005.07.016
   Ma lima A., 2006, 14 IEEE C SIGNAL PRO, P1
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Premaratne P, 2013, NEUROCOMPUTING, V116, P242, DOI 10.1016/j.neucom.2011.11.039
   Priyal S.P., 2010, P INT C SIGN PROC CO, P1
   Samir A., 2010, CAN J ARTIF INTELL M, V1, P1
   See KW, 2007, APPL MATH COMPUT, V193, P346, DOI 10.1016/j.amc.2007.03.080
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Wee CY, 2010, PATTERN RECOGN, V43, P4055, DOI 10.1016/j.patcog.2010.05.026
NR 42
TC 47
Z9 48
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1240
EP 1250
DI 10.1016/j.jvcir.2013.12.019
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200048
DA 2024-07-18
ER

PT J
AU Mohammadi, MR
   Fatemizadeh, E
   Mahoor, MH
AF Mohammadi, M. R.
   Fatemizadeh, E.
   Mahoor, M. H.
TI PCA-based dictionary building for accurate facial expression recognition
   via sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Basic emotions; Sparse representation;
   Dictionary building; Dictionary learning; Difference image; Principal
   Component Analysis; Generalization power
ID FACE RECOGNITION; DECOMPOSITION; RECONSTRUCTION; SYSTEMS
AB Sparse representation is a new approach that has received significant attention for image classification and recognition. This paper presents a PCA-based dictionary building for sparse representation and classification of universal facial expressions. In our method, expressive facials images of each subject are subtracted from a neutral facial image of the same subject. Then the PCA is applied to these difference images to model the variations within each class of facial expressions. The learned principal components are used as the atoms of the dictionary. In the classification step, a given test image is sparsely represented as a linear combination of the principal components of six basic facial expressions. Our extensive experiments on several publicly available face datasets (QC+, MMI, and Bosphorus datasets) show that our framework outperforms the recognition rate of the state-of-the-art techniques by about 6%. This approach is promising and can further be applied to visual object recognition. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Mohammadi, M. R.; Fatemizadeh, E.] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Mahoor, M. H.] Univ Denver, Dept Elect & Comp Engn, Denver, CO 80208 USA.
C3 Sharif University of Technology; University of Denver
RP Mohammadi, MR (corresponding author), Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
EM mrmohammadi@ee.sharif.edu; fatemizadeh@sharif.edu; mmahoor@du.edu
RI Mohammadi, Mohammad Reza/P-4031-2018
OI Mohammadi, Mohammad Reza/0000-0002-1016-9243; Mahoor,
   Mohammad/0000-0001-8923-4660
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahonen T, 2008, ICPR2009, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   [Anonymous], 2005, ICME
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], 2010, 2010 3 INT C IM SIGN
   [Anonymous], EMFACS 7 EMOTI UNPUB
   [Anonymous], ARXIV08093083
   Babu P, 2010, IEEE SIGNAL PROC LET, V17, P40, DOI 10.1109/LSP.2009.2032489
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Calder AJ, 2005, NAT REV NEUROSCI, V6, P641, DOI 10.1038/nrn1724
   Candes E.J., 2005, l1-MAGIC: Recovery of sparse signals via convex programming
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cotter S. F., 2010, WEIGHTED VOTING SPAR
   Cotter SF, 2010, INT CONF ACOUST SPEE, P838, DOI 10.1109/ICASSP.2010.5494903
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Huang K., 2007, P 19 INT C NEUR INF, P609, DOI DOI 10.7551/MITPRESS/7503.003.0081
   Jeni L.A., 2013, Proc. 10th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit, P1
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Li JW, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P1313, DOI 10.1109/IMCCC.2012.309
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Liu WF, 2012, I C CONT AUTOMAT ROB, P1402, DOI 10.1109/ICARCV.2012.6485394
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mahoor Mohammad H., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P336, DOI 10.1109/FG.2011.5771420
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Maronidis A, 2011, NEURAL NETWORKS, V24, P814, DOI 10.1016/j.neunet.2011.05.015
   Miao YQ, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P326, DOI 10.1109/ICMLA.2012.178
   Mohammadi MR, 2014, SIGNAL PROCESS, V100, P42, DOI 10.1016/j.sigpro.2014.01.010
   Mohammadi M.R., 2013, 8 IR C MACH VIS IM P
   Mohammadi M.R., 2014, IEEE WINT C APPL COM
   Mohammadi M.R., 2012, AISP 2012
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Sadeghi H., 2013, 8 IR C MACH VIS IM P
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shu K., ARXIV12056391
   Do TT, 2012, INT CONF ACOUST SPEE, P1301, DOI 10.1109/ICASSP.2012.6288128
   Wang Z, 2012, 2012 IEEE INFORMATION THEORY WORKSHOP (ITW), P222, DOI [10.1109/ICNC.2012.6234551, 10.1109/ITW.2012.6404663]
   Wohlberg B, 2003, IEEE T SIGNAL PROCES, V51, P3053, DOI 10.1109/TSP.2003.819006
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zafeiriou S., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, P32
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zisheng Li, 2010, Information and Media Technologies, V5, P1003
NR 59
TC 74
Z9 86
U1 2
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1082
EP 1092
DI 10.1016/j.jvcir.2014.03.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200034
DA 2024-07-18
ER

PT J
AU Yang, XD
   Tian, YL
AF Yang, Xiaodong
   Tian, YingLi
TI Effective 3D action recognition using EigenJoints
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; RGBD camera; Depth data; Skeleton joints; 3D action
   feature representation; Accumulated motion energy; Informative frame
   selection; Naive-Bayes-Nearest-Neighbor
ID MOTION
AB In this paper, we propose an effective method to recognize human actions using 3D skeleton joints recovered from 3D depth data of RGBD cameras. We design a new action feature descriptor for action recognition based on differences of skeleton joints, i.e.,EigenJoints which combine action information including static posture, motion property, and overall dynamics. Accumulated Motion Energy (AME) is then proposed to perform informative frame selection, which is able to remove noisy frames and reduce computational cost. We employ non-parametric Naive-Bayes-Nearest-Neighbor (NBNN) to classify multiple actions. The experimental results on several challenging datasets demonstrate that our approach outperforms the state-of-the-art methods. In addition, we investigate how many frames are necessary for our method to perform classification in the scenario of online action recognition. We observe that the first 30-40% frames are sufficient to achieve comparable results to that using the entire video sequences on the MSR Action3D dataset. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yang, Xiaodong; Tian, YingLi] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 City University of New York (CUNY) System; City College of New York
   (CUNY)
RP Tian, YL (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM xyang02@ccny.cuny.edu; ytian@ccny.cuny.edu
OI Tian, Yingli/0000-0003-4458-360X
FU NSF [IIS-0957016]; PSC-CUNY [64720-00 42]; Microsoft Research
FX This work was supported in part by NSF grant IIS-0957016, PSC-CUNY
   #64720-00 42, and Microsoft Research. The authors thank the anonymous
   reviewers for their constructive comments and insightful suggestions
   that improved the quality of this paper.
CR [Anonymous], P ACM INT C MULT
   [Anonymous], 2012, TRECVID
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587730
   Arya S, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P379
   Bian W, 2012, IEEE T SYST MAN CY B, V42, P298, DOI 10.1109/TSMCB.2011.2166761
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Cheng HY, 2011, J VIS COMMUN IMAGE R, V22, P673, DOI 10.1016/j.jvcir.2011.07.001
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Klaser A., 2008, BRIT MACHINE VISION
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li W., 2010, IEEE CVPR WORKSH HUM
   Liu HW, 2011, J VIS COMMUN IMAGE R, V22, P432, DOI 10.1016/j.jvcir.2011.03.010
   McCann S, 2012, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2012.6248111
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Xia L., 2012, IEEE CVPR WORKSH HUM
   Yang X., 2012, IEEE CVPR WORKSH HUM
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhang C., 2013, INT C AUT FAC GEST R
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
NR 31
TC 250
Z9 283
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 2
EP 11
DI 10.1016/j.jvcir.2013.03.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900002
DA 2024-07-18
ER

PT J
AU Bissi, L
   Baruffa, G
   Placidi, P
   Ricci, E
   Scorzoni, A
   Valigi, P
AF Bissi, Lucia
   Baruffa, Giuseppe
   Placidi, Pisana
   Ricci, Elisa
   Scorzoni, Andrea
   Valigi, Paolo
TI Automated defect detection in uniform and structured fabrics using Gabor
   filters and PCA
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Automated textile inspection; Fabric defect detection; Gabor filters;
   Principa Component Analysis; TILDA; Manual defect annotation; Detection
   rate; False alarm rate
ID COMPUTER-VISION; TEXTURE
AB This paper describes an algorithm for texture defect detection in uniform and structured fabrics, which has been tested on the TILDA image database. The proposed approach is structured in a feature extraction phase, which relies on a complex symmetric Gabor filter bank and Principal Component Analysis (PCA), and on a defect identification phase, which is based on the Euclidean norm of features and on the comparison with fabric type specific parameters. Our analysis is performed on a patch basis, instead of considering single pixels. The performance has been evaluated with uniformly textured fabrics and fabrics with visible texture and grid-like structures, using as reference defect locations identified by human observers. The results show that our algorithm outperforms previous approaches in most cases, achieving a detection rate of 98.8% and a false alarm rate as low as 0.20-0.37%, whereas for heavily structured yarns misdetection rate can be as low as 5%. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Bissi, Lucia; Baruffa, Giuseppe; Placidi, Pisana; Ricci, Elisa; Scorzoni, Andrea; Valigi, Paolo] Univ Perugia, Elect & Informat Engn Dept, I-06125 Perugia, Italy.
C3 University of Perugia
RP Baruffa, G (corresponding author), Univ Perugia, Elect & Informat Engn Dept, I-06125 Perugia, Italy.
EM baruffa@diei.unipg.it
RI Ricci, Elisa/IYS-6532-2023; Valigi, Paolo/AAI-8912-2020; Scorzoni,
   Andrea/O-2467-2013
OI Valigi, Paolo/0000-0002-0486-7678; Ricci, Elisa/0000-0002-0228-1147;
   Baruffa, Giuseppe/0000-0003-3496-0395; Scorzoni,
   Andrea/0000-0003-4368-5233
FU Fondazione Cassa di Risparmio di Perugia
FX The authors wish to thank W. Bernardini of DiES S.r.l. for helpful
   discussion and for providing the TILDA image database. The financial
   support of the Fondazione Cassa di Risparmio di Perugia is gratefully
   acknowledged.
CR Alimohamadi H, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING, PROCEEDINGS, P26, DOI 10.1109/ICCAE.2009.43
   [Anonymous], 2004, A Course in Modern Mathematical Physics : Groups, Hiibert Spaces and D ifferential Geometry
   Basibüyük K, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P348, DOI 10.1109/ISCCSP.2008.4537248
   Basturk A., 2007, 2007 9th International Symposium on Signal Processing and Its Applications, P1
   Beirao CL, 2004, LECT NOTES COMPUT SC, V3212, P841
   Bissi L, 2012, IEEE IMTC P, P240
   Bodnarova A, 2002, PATTERN RECOGN, V35, P2973, DOI 10.1016/S0031-3203(02)00017-1
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chen CC, 1996, PATTERN RECOGN LETT, V17, P1069, DOI 10.1016/0167-8655(96)00065-7
   Chen Q, 2007, J VIS COMMUN IMAGE R, V18, P119, DOI 10.1016/j.jvcir.2006.11.001
   Escofet J, 1998, OPT ENG, V37, P2297, DOI 10.1117/1.601751
   HUART J, 1994, P SOC PHOTO-OPT INS, V2183, P155, DOI 10.1117/12.171205
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kamarainen J, 2002, INT C PATT RECOG, P628, DOI 10.1109/ICPR.2002.1044822
   Kolhe S., 2009, Adv. Comput. Res, V1, P18
   Kothari V., 2010, AUTOMATIC FABRIC INS
   Krüger V, 2000, INT C PATT RECOG, P127, DOI 10.1109/ICPR.2000.905289
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2000, OPT ENG, V39, P3176, DOI 10.1117/1.1327837
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Liangzhong Fan, 2010, Proceedings 2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering (ISKE 2010), P173, DOI 10.1109/ISKE.2010.5680817
   Liu Hui-xia, 2006, 2006 Chinese Control Conference (IEEE Cat. No. 06EX1310)
   Mak KL, 2008, ROBOT CIM-INT MANUF, V24, P359, DOI 10.1016/j.rcim.2007.02.019
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ngan HYT, 2005, PATTERN RECOGN, V38, P559, DOI 10.1016/j.patcog.2004.07.009
   Sezer OG, 2007, PATTERN RECOGN, V40, P121, DOI 10.1016/j.patcog.2006.05.023
   Shen L, 2007, IMAGE VISION COMPUT, V25, P553, DOI 10.1016/j.imavis.2006.05.002
   Sungshin Kim, 1999, ISIE '99. Proceedings of the IEEE International Symposium on Industrial Electronics (Cat. No.99TH8465), P1406, DOI 10.1109/ISIE.1999.796918
   Wang SS, 2012, J VIS COMMUN IMAGE R, V23, P1008, DOI 10.1016/j.jvcir.2012.06.011
   Xuezhi Y., 2005, P 2005 INT C INFORM, V2005, P54
   Zhang Y, 2010, LECT NOTES COMPUT SC, V5995, P635
   Zhu ZF, 2007, J VIS COMMUN IMAGE R, V18, P68, DOI 10.1016/j.jvcir.2006.10.001
NR 34
TC 77
Z9 88
U1 0
U2 70
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 838
EP 845
DI 10.1016/j.jvcir.2013.05.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700010
DA 2024-07-18
ER

PT J
AU Almeida, J
   Leite, NJ
   Torres, RD
AF Almeida, Jurandy
   Leite, Neucimar J.
   Torres, Ricardo da S.
TI Online video summarization on compressed domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video abstraction; Video summary; Video skimming; Compressed domain;
   Progressive generation; Online processing; TRECVID 2007; BBC rushes
   summarization
AB Recent advances in technology have increased the availability of video data, creating a strong requirement for efficient systems to manage those materials. Making efficient use of video information requires that data to be accessed in a user-friendly way. Ideally, one would like to understand a video content, without having to watch it entirely. This has been the goal of a quickly evolving research area known as video summarization. In this paper, we present a novel approach for video summarization that works in the compressed domain and allows the progressive generation of a video summary. The proposed method relies on exploiting visual features extracted from the video stream and on using a simple and fast algorithm to summarize the video content. Experiments on a TRECVID 2007 dataset show that our approach presents high quality relative to the state-of-the-art solutions and in a computational time that makes it suitable for online usage. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Almeida, Jurandy; Leite, Neucimar J.; Torres, Ricardo da S.] Univ Estadual Campinas, UNICAMP, Inst Comp, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Almeida, J (corresponding author), Univ Estadual Campinas, UNICAMP, Inst Comp, BR-13083852 Campinas, SP, Brazil.
EM jurandy.almeida@ic.unicamp.br; neucimar@ic.unicamp.br;
   rtorres@ic.unicamp.br
RI Leite, Neucimar J/H-7299-2012; Torres, Ricardo da S./C-4526-2012;
   Almeida, Jurandy/I-2177-2012
OI Almeida, Jurandy/0000-0002-4998-6996; Torres,
   Ricardo/0000-0001-9772-263X
FU FAPESP [07/52015-0, 08/50837-6, 09/18438-7]; CNPq [311309/2006-2,
   472402/2007-2, 306587/2009-2]; CAPES [01P-05866/2007]; Fundacao de
   Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [09/18438-7] Funding
   Source: FAPESP
FX This research was supported by Brazilian agencies FAPESP (Grant
   07/52015-0, 08/50837-6, and 09/18438-7), CNPq (Grant 311309/2006-2,
   472402/2007-2, and 306587/2009-2), and CAPES (Grant 01P-05866/2007).
CR Almeida Jurandy, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3673, DOI 10.1109/ICIP.2011.6116516
   Almeida J., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P113, DOI 10.1109/ISM.2010.25
   Almeida J., 2010, P IEEE INT C SYST SI, P348
   Almeida J, 2011, LECT NOTES COMPUT SC, V7042, P71, DOI 10.1007/978-3-642-25085-9_8
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   Almeida J, 2009, LECT NOTES COMPUT SC, V5875, P435, DOI 10.1007/978-3-642-10331-5_41
   Almeida J, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1180
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   [Anonymous], 2007, TRECVID WORKSH VID S, DOI [10.1145/1290031.1290045, DOI 10.1145/1290031.1290045]
   Benini S., 2007, P 8 INT WORKSH IM AN, P6
   Bhaskaran Vasudev, 1997, Image and video compression standards: algorithms and architectures
   Bouch A., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P297, DOI 10.1145/332040.332447
   Bredin H., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P45
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Chasanis V., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P75
   Chew CM, 2001, LECT NOTES COMPUT SC, V2195, P490
   Di Stefano L, 2005, PATTERN RECOGN LETT, V26, P2129, DOI 10.1016/j.patrec.2005.03.022
   Dumont E, 2010, MULTIMED TOOLS APPL, V48, P51, DOI 10.1007/s11042-009-0374-9
   Erol B, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P25
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Hampapur A, 1997, P SOC PHOTO-OPT INS, V3022, P188, DOI 10.1117/12.263407
   Herranz L, 2009, IEEE INT CON MULTI, P654, DOI 10.1109/ICME.2009.5202581
   Houle M., 2008, Statistical Analysis and Data Mining, V1, P157, DOI DOI 10.1002/sam.10013
   Kleban J., 2007, P INT WORKSH TRECVID, P84
   Le D., 2007, Proceedings of 15th ACM International Conference on Multimedia, Workshop on TRECVID Video Summarization, P70
   Le D.-D., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P100, DOI [DOI 10.1145/1463563.1463581, 10.1145/1463563.1463581]
   Lie WN, 2004, LECT NOTES COMPUT SC, V3332, P246
   Martin J., 1995, INT C INT AUT SYST I
   Mattoccia S, 2008, IEEE IMAGE PROC, P849, DOI 10.1109/ICIP.2008.4711888
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Over P., 2008, Proc. of the 2nd ACM TRECVid Video Summarization Workshop, P1, DOI [DOI 10.1145/1463563.1463564, 10.1145/1463563.1463564]
   Over P., 2007, TVS '07: Proc. of the International Workshop on TRECVID Video Summarization, P1, DOI DOI 10.1145/1290031.1290032
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Peker KA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2055, DOI 10.1109/ICME.2004.1394669
   Ponceleon D., 1998, Proceedings ACM Multimedia 98, P99, DOI 10.1145/290747.290760
   Stehling R.O., 2002, MULTIMEDIA MINING, V22, P61
   Sugano M, 2002, IEEE IMAGE PROC, P956
   Sun CM, 2002, IMAGE VISION COMPUT, V20, P981, DOI 10.1016/S0262-8856(02)00112-9
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2525, DOI 10.1016/S0167-8655(03)00098-9
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yu JCS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P329
NR 45
TC 49
Z9 52
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 729
EP 738
DI 10.1016/j.jvcir.2012.01.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900010
DA 2024-07-18
ER

PT J
AU Yan, B
   Yang, B
AF Yan, Bo
   Yang, Bo
TI An effective error resilient 3D view synthesis method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE View synthesis; Corona; Pinhole; Ghost; 3D Video; Multiview video
   coding; Depth map; Interpolation projection
ID INTERPOLATION
AB View synthesis is a crucial process in current 3D video applications. Currently, the existing view synthesis techniques may introduce visual artifacts such as corona, pinholes and ghosts into pictures, which degrade the visual experience greatly. In this paper, we will introduce an error resilient 3D view synthesis approach, which is able to effectively remove these artifacts. Specifically, we first detect the regions mixed with foreground and background pixels to avoid corona artifacts. Then, we resize images and conduct projection on the resized images to reduce pinhole artifacts. Finally, an improved view blending algorithm is proposed to reduce ghosting artifacts. Simulation results demonstrate that our proposed method outperforms others significantly in removing view artifacts. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Yan, Bo; Yang, Bo] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Yan, B (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
EM byan@fudan.edu.cn
RI Yan, Bo/AFQ-7025-2022
OI Yan, Bo/0000-0002-7775-1270
FU NSFC [61073067]
FX This work is supported by NSFC (61073067).
CR [Anonymous], 2002, Methodology for the subjective assessment of the quality of television pictures
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Avidan S., P IEEE C COMP VIS PA, P1034
   Chen G., P IEEE C COMP VIS PA, V00, P74
   Chen S.-E., P 20 ANN C COMP GRAP, P279
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   ISO/IEC/JTC/SC29/WG11, 2008, N9596 ISOIECJTCSC29W
   KATAYAMA A, 1995, P SOC PHOTO-OPT INS, V2409, P11, DOI 10.1117/12.205854
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Klaus A, 2006, INT C PATT RECOG, P15
   Konrad J, 2007, IEEE SIGNAL PROC MAG, V24, P97, DOI 10.1109/MSP.2007.905706
   McVeigh JS, 1996, SIGNAL PROCESS-IMAGE, V9, P21, DOI 10.1016/S0923-5965(96)00005-7
   MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6
   Morimoto M., P IEEE INT S COMM IN, V2, P853
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Oh JD, 2007, IEEE INT SYMP CIRC S, P993, DOI 10.1109/ISCAS.2007.378136
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D., P IEEE C COMP VIS PA, P852
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Tung T, 2009, PROC CVPR IEEE, P469, DOI 10.1109/CVPRW.2009.5206823
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 23
TC 3
Z9 3
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 669
EP 677
DI 10.1016/j.jvcir.2012.04.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900004
DA 2024-07-18
ER

PT J
AU Wang, JP
   Fan, JY
   Li, HH
   Wu, DP
AF Wang, Jiangping
   Fan, Jieyan
   Li, Huanghuang
   Wu, Dapeng
TI Kernel-based feature extraction under maximum margin criterion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature extraction; Kernel method; Pattern classification; RELIEF;
   Maximum margin criterion; LFE; KLFE; Nonlinear transformation
AB In this paper, we study the problem of feature extraction for pattern classification applications. RELIEF is considered as one of the best-performed algorithms for assessing the quality of features for pattern classification. Its extension, local feature extraction (LFE), was proposed recently and was shown to outperform RELIEF. In this paper, we extend LFE to the nonlinear case, and develop a new algorithm called kernel LFE (KLFE). Compared with other feature extraction algorithms, KLFE enjoys nice properties such as low computational complexity, and high probability of identifying relevant features; this is because KLFE is a nonlinear wrapper feature extraction method and consists of solving a simple convex optimization problem. The experimental results have shown the superiority of KLFE over the existing algorithms. Published by Elsevier Inc.
C1 [Wang, Jiangping; Fan, Jieyan; Li, Huanghuang; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Li, HH (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM lihh@ufl.edu
OI Wu, Dapeng/0000-0003-1755-0183
FU US Air Force Office of Scientific Research [FA9550-09-1-0132]
FX This work was supported in part by the US Air Force Office of Scientific
   Research under Grant FA9550-09-1-0132.
CR [Anonymous], 1998, UCI REPOSITORY MACHI
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Cao B., 2007, P 24 INT C MACHINE L, P121, DOI DOI 10.1145/1273496.1273512
   Dasarathy B., 1990, Nearest neighbor: pattern classification techniques
   Dietterich TG, 1997, AI MAG, V18, P97
   Duda R., 1973, Pattern Classification and Scene Analysis
   KIRA K, 1992, MACHINE LEARNING /, P249
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Sun Y, 2008, P 2008 SIAM INT C DA, ppp188
   Sun Y., 2006, Proceedings of the 23rd international conference on Machine learning, P913, DOI [10.1145/1143844.1143959, DOI 10.1145/1143844.1143959]
   SUN Y, 2009, STAT ANAL DATA MININ, V2, P34
   Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256
NR 14
TC 4
Z9 5
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 53
EP 62
DI 10.1016/j.jvcir.2011.08.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Martin, A
   Fuchs, JJ
   Guillemot, C
   Thoreau, D
AF Martin, Aurelie
   Fuchs, Jean-Jacques
   Guillemot, Christine
   Thoreau, Dominique
TI Sparse representations for spatial prediction and texture refinement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatial prediction; H.264/AVC; Sparse representations; Extrapolation;
   Phase refinement; Video compression; Scalable coding; Redundant
   dictionaries
AB In this work, we propose a novel approach for signal prediction based on the use of sparse signal representations and Matching Pursuit (MP) techniques. The paper first focuses on spatial texture prediction in a conventional block-based hybrid coding scheme and secondly addresses inter-layer prediction in a scalable video coding (SVC) framework. For spatial prediction the signal reconstruction of the block to predict is based on basis functions selected with the MP iterative algorithm, to best match a causal neighborhood. Inter-layer MP based prediction employs base layer upsampled components additionally to the causal neighborhood in order to improve the representation of high frequencies. New solutions are proposed for efficiently deriving and exploiting the atoms dictionary through phase refinement and mono-dimensional basis functions. Experimental results indicate noticeable improvement of rate/distortion performance compared to the standard prediction methods as specified in H.264/AVC and its extension SVC. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Martin, Aurelie; Fuchs, Jean-Jacques; Guillemot, Christine] Univ Rennes 1, IRISA, F-35042 Rennes, France.
   [Martin, Aurelie; Thoreau, Dominique] Technicolor Res & Innovat Labs, F-35510 Cesson Sevigne, France.
C3 Universite de Rennes; Technicolor SA
RP Martin, A (corresponding author), Univ Rennes 1, IRISA, Campus Beaulieu, F-35042 Rennes, France.
EM aurelie.martin1@free.fr
OI Guillemot, Christine/0000-0003-1604-967X
CR Aharon M., 2007, SIAM J IMAGING SCI
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2001, ITU T VCEG M AUST TE
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Desai UY, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA558
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Fuchs JJ, 2001, IEEE T SIGNAL PROCES, V49, P702, DOI 10.1109/78.912914
   Granai L, 2004, EURASIP J APPL SIG P, V2004, P2705, DOI 10.1155/S1110865704407136
   i Ventura R. Figueras, 2004, MATCHING PURSUIT FUL
   Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Maria S., 2006, P ICASSP
   Neff R., 1995, Proceedings. DCC '95 Data Compression Conference (Cat. No.95TH8037), P411, DOI 10.1109/DCC.1995.515531
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall A., 2006, JVTU042 ISOIEC MPEG
   Sun S., 2006, JVTR006 ISOIEC MPEG
   TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9
   Ventura RMFI, 2006, IEEE T IMAGE PROCESS, V15, P726, DOI 10.1109/TIP.2005.860596
   Wang BB, 2006, IEEE IMAGE PROC, P3149, DOI 10.1109/ICIP.2006.312941
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zepeda J., 2010, P IEEE INT WORKSH MM
NR 22
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 712
EP 720
DI 10.1016/j.jvcir.2011.01.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200004
DA 2024-07-18
ER

PT J
AU Dai, F
   Tong, LL
   Zhang, YD
   Li, JT
AF Dai, Feng
   Tong, Lingling
   Zhang, Yongdong
   Li, Jintao
TI Restricted H.264/AVC video coding for privacy protected video scrambling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Coding efficiency; Drift error; H.264/AVC; Privacy protection;
   Restricted video coding; Security; Video surveillance; Video scrambling
AB The issue of personal privacy has garnered significant attention with the extensive application of video surveillance systems. Privacy region scrambling is an effective method to protect privacy in video. To ensure that nonprivacy regions are not affected by scrambling, particular methods must be taken to prevent drift error in privacy protected video scrambling. However, existing methods have significantly reduced the coding efficiency. In this paper, we focus on improving coding efficiency while preventing drift error in privacy protected H.264/AVC video scrambling, which is the state-of-the-art coding standard. A restricted video coding scheme is proposed, which involves three parts of Mode Restricted Intra Prediction (MRIP), Search Window Restricted Motion Estimation (SWRME) and Boundary Strength Restricted Deblocking Filtering (BSRDF). Experimental results show that the proposed restricted video coding scheme prevents drift error with higher coding efficiency than others. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Dai, Feng; Tong, Lingling; Zhang, Yongdong; Li, Jintao] Chinese Acad Sci, Inst Comp Technol, Multimedia Comp Grp, Beijing, Peoples R China.
   [Tong, Lingling] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Tong, LL (corresponding author), 6 Kexueyuan S Rd, Beijing 100190, Peoples R China.
EM fdai@ict.ac.cn; tonglingling@ict.ac.cn; zhyd@ict.ac.cn; jtli@ict.ac.cn
FU National Nature Science Foundation of China [60802028]; National Basic
   Research Program of China (973 Program) [2007CB311100]; National High
   Technology and Research Development Program of China (863 Program)
   [2007AA01Z416]; Beijing New Star Project on Science Technology
   [2007B071]; Beijing Municipal Education Commission
FX This work was supported in part by the National Nature Science
   Foundation of China (60802028), the National Basic Research Program of
   China (973 Program, 2007CB311100), the National High Technology and
   Research Development Program of China (863 Program, 2007AA01Z416), the
   Beijing New Star Project on Science & Technology (2007B071) and the
   Co-building Program of Beijing Municipal Education Commission.
CR Boult TE, 2006, COMPUTER VISION FOR INTERACTIVE AND INTELLIGENT ENVIRONMENTS, P27
   Carrillo P., 2008 IEEE INT C MULT, P273
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   Dufaux F, 2008, IEEE IMAGE PROC, P1688, DOI 10.1109/ICIP.2008.4712098
   Dufaux Frederic., 2006, C COMPUTER VISION PA, P160
   Li GZ, 2008, IEEE IMAGE PROC, P1372, DOI 10.1109/ICIP.2008.4712019
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Martin K, 2008, IEEE T CIRC SYST VID, V18, P1152, DOI 10.1109/TCSVT.2008.927110
   Martin K, 2008, IEEE IMAGE PROC, P1360, DOI 10.1109/ICIP.2008.4712016
   Martinez-Ponte Isabel, 2005, P INT WORKSH IM AN M
   Sweeney L., 2005, IEEE T KNOWLEDGE DAT, V17, pFeb
   Tong L, 2010, ELECTRON LETT, V46, P47, DOI 10.1049/el.2010.2068
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   ZHANG W, 2005, P IEEE INT C IM PROC
   [No title captured]
NR 15
TC 11
Z9 15
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 479
EP 490
DI 10.1016/j.jvcir.2011.05.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000003
DA 2024-07-18
ER

PT J
AU Duanggate, C
   Uyyanonvara, B
   Makhanov, SS
   Barman, S
   Williamson, T
AF Duanggate, Cattleya
   Uyyanonvara, Bunyarit
   Makhanov, Stanislav S.
   Barman, Sarah
   Williamson, Tom
TI Object detection with feature stability over scale space
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scale-space theory; Scale-space tree; Object segmentation; Object
   detection; Feature stability; Feature vector; Blob's lifetime; Blob
   attributes
ID EDGE-DETECTION
AB This paper proposes a novel segmentation method based on the scale space techniques endowed with a feature stability approach. The novelty of the paper is the lifetime of the space-scale blobs measured not only by their presence and disappearance but by the stability of the features characterizing the objects of interest as well. Our numerical experiments show that the algorithm outperforms the conventional space scale algorithm applied to variable size and variable shape objects. The proposed algorithm can be used as a preprocessing step in object or pattern recognition applications to produce seeds for more accurate image segmentation methods such as the snakes or the level set techniques. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Duanggate, Cattleya; Uyyanonvara, Bunyarit; Makhanov, Stanislav S.] Thammasat Univ, SIIT, Sch Informat Comp & Commun Technol, Muang 12000, Pathumthani, Thailand.
   [Barman, Sarah] Kingston Univ, Fac Comp Informat Syst & Math, Surrey KT1 2EE, England.
   [Williamson, Tom] St Thomas Hosp, Dept Ophthalmol, London SE1 7EH, England.
C3 Thammasat University; Kingston University; Guy's & St Thomas' NHS
   Foundation Trust
RP Duanggate, C (corresponding author), Thammasat Univ, SIIT, Sch Informat Comp & Commun Technol, 131 Moo 5,Tiwanont Rd, Muang 12000, Pathumthani, Thailand.
EM D5022300403@studentmail.siit.tu.ac.th; bunyarit@siit.tu.ac.th;
   makhanov@sitt.tu.ac.th; s.barman@kingston.ac.uk; tom@retinasurgery.co.uk
RI Makhanov, Stanislav/AAT-6430-2020; williamson, tom/AAP-3801-2020;
   S.Makhanov/ABA-3316-2020
OI S.Makhanov/0000-0002-1906-0359; Barman, Sarah/0000-0001-5302-0169
FU Guy's Trust UK; St. Thomas' Hospital Special Trust UK; Thailand Toray
   Science Foundation (TTSF); Thailand Office of Higher Education
   Commission
FX This project is funded by Guy's and St. Thomas' Hospital Special
   Trustees, UK and Thailand Toray Science Foundation (TTSF) and National
   Research University Project of Thailand Office of Higher Education
   Commission.
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   BOLTZ S, 2010, P EUR C COMP VIS
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   Carvalho MAG, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P376, DOI 10.1109/SIBGRA.2003.1241033
   Damerval C, 2007, IEEE SIGNAL PROC LET, V14, P39, DOI 10.1109/LSP.2006.879830
   Forbes LA, 2000, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2000.854859
   Gatica-Perez D, 2001, IEEE T IMAGE PROCESS, V10, P1332, DOI 10.1109/83.941857
   GOMEZMORENO H, 2001, 6 INT WORK C ART NAT, P685
   GONZALEZ RC, 2008, DIGITAL IMAGE PROCES, P533
   Jahne B, 2005, DIGITAL IMAGE PROCES, P537
   Jalba AC, 2006, IEEE T IMAGE PROCESS, V15, P331, DOI 10.1109/TIP.2005.860606
   Kawaguchi T, 2000, INT C PATT RECOG, P1109, DOI 10.1109/ICPR.2000.905666
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, The Kluwer International Series in Engineering and Computer Science
   Manay S, 2003, IEEE T IMAGE PROCESS, V12, P1310, DOI 10.1109/TIP.2003.818039
   Mégret R, 2002, IEEE MULTIMEDIA, V9, P34, DOI 10.1109/93.998053
   Ming A., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P364, DOI 10.1145/1282280.1282335
   NIXON MS, 2008, FEATURE EXTRACTION I, P312
   Sopharak A, 2008, COMPUT MED IMAG GRAP, V32, P720, DOI 10.1016/j.compmedimag.2008.08.009
   THOUHO C, 2007, 2 INT C INN COMP INF, P238
   Wang Q, 2009, LECT NOTES COMPUT SC, V5414, P542, DOI 10.1007/978-3-540-92957-4_47
   Wang SA, 2007, I S INTELL SIG PROC, P331
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   XINTING G, 2005, 5 INT C INF COMM SIG, P683
   YANAI K, 2005, P 13 ANN ACM INT C M, P419
NR 27
TC 4
Z9 4
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2011
VL 22
IS 4
BP 345
EP 352
DI 10.1016/j.jvcir.2011.02.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 751AG
UT WOS:000289589100005
DA 2024-07-18
ER

PT J
AU Rahman, ZU
   Jobson, DJ
   Woodell, GA
AF Rahman, Zia-ur
   Jobson, Daniel J.
   Woodell, Glenn A.
TI Investigating the relationship between image enhancement and image
   compression in the context of the multi-scale retinex
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image enhancement; Inverting image transforms; Compression; Multi-scale
   retinex; End-to-end systems analysis; Image retrieval; Visual
   communications channel design; Survey of image compression usage in
   space imaging
ID ADVANCED LAND IMAGER; COLOR; PERFORMANCE; ORBITER; MISSION
AB Image enhancement and data compression methods arose from the distinct and largely separate disciplines of image processing and communications respectively, yet both are important components of current and future digital imaging systems technology. Here we examine the relationship of these two components with special emphasis on image enhancement and lossy JPEG image compression. When transmission channel capacity is limited, image/data compression is often performed to increase the data throughput. However, this compression has a significant impact on the quality of the final data that is received. In most cases, image enhancement performed after image compression tends to bring out the artifacts injected into the data due to the compression. However, if image enhancement is performed before image compression, there are two issues that arise: (i) image enhancement typically increases the contrast-amount of observable detail-in an image which leads to poorer compression ratios; and (ii) the radiometric information in the original data is typically irretrievably lost. In this paper we address the impact of image enhancement, specifically that of the multi-scale retinex with color restoration (MSRCR) on image compression, and vice versa. We also look at the impact of compression on recovering original data from enhanced imagery given certain parameters about the enhancement process. In this context, we also develop an inversion process for the MSRCR. (C) 2011 Published by Elsevier Inc.
C1 [Jobson, Daniel J.; Woodell, Glenn A.] NASA, Langley Res Ctr, Electromagnet & Sensors Branch, Hampton, VA 23681 USA.
   [Rahman, Zia-ur] Old Dominion Univ, Dept Elect & Comp Engn, Virginia Modeling Anal & Simulat Ctr, Norfolk, VA 23529 USA.
C3 National Aeronautics & Space Administration (NASA); NASA Langley
   Research Center; Old Dominion University
RP Jobson, DJ (corresponding author), NASA, Langley Res Ctr, Electromagnet & Sensors Branch, Mailstop 473, Hampton, VA 23681 USA.
EM zrahman@odu.edu; daniel.j.jobson@nasa.gov; glenn.a.woodell@nasa.gov
RI cai, bo/G-1491-2010; Rahman, Zia Ur/R-7068-2018; Rahman, Mohammad
   Masudur/KHY-3819-2024
OI Rahman, Zia Ur/0000-0002-4948-3870; 
FU NASA [NNL07AA02A]
FX The authors thank the NASA Aviation Safety Program for the funding which
   made this work possible. In particular, Dr. Rahman's work was supported
   under NASA cooperative agreement NNL07AA02A.
CR [Anonymous], P SPIE
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], DIGITAL IMAGE PROCES
   Barnes WL, 1998, IEEE T GEOSCI REMOTE, V36, P1088, DOI 10.1109/36.700993
   Bicknell WE, 1999, P SOC PHOTO-OPT INS, V3750, P80, DOI 10.1117/12.363501
   Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0
   Chen B, 1999, IMAGE VISION COMPUT, V17, P913, DOI 10.1016/S0262-8856(98)00165-6
   Christensen PR, 2004, SPACE SCI REV, V110, P85, DOI 10.1023/B:SPAC.0000021008.16305.94
   Goetz A. F. H., 1991, International Journal of Imaging Systems and Technology, V3, P131, DOI 10.1002/ima.1850030209
   GOETZ AFH, 1989, IEEE T GEOSCI REMOTE, V27, P136, DOI 10.1109/36.20291
   GOPINATH RA, 1994, P 1994 IEEE INT C IM, V2, P913
   Graf JE, 2005, ACTA ASTRONAUT, V57, P566, DOI 10.1016/j.actaastro.2005.03.043
   Hines G, 2004, P SOC PHOTO-OPT INS, V5438, P13, DOI 10.1117/12.544500
   Hines GD., 2004, P GSPX
   HINES GD, 2005, P SOC PHOTO-OPT INS, V5802, P13
   HINES GD, 2005, THESIS COLL WILLIAM
   HINES GD, 2006, P SPIE, V6226
   IWATA T, 2008, P SPIE, V7106
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Jobson DJ, 2002, P SOC PHOTO-OPT INS, V4736, P25, DOI 10.1117/12.477589
   Jobson DJ, 2001, PROC SPIE, V4388, P117, DOI 10.1117/12.438249
   JOBSON DJ, 2004, P SPIE, V5438
   JOBSON DJ, 2003, P SPIE, V5108
   Kopilovic I, 2005, OPT ENG, V44, DOI 10.1117/1.1849242
   KUNDU A, 1995, P INT C IM PROC, V1, P23
   Lai YK, 1996, P SOC PHOTO-OPT INS, V2727, P1484, DOI 10.1117/12.233224
   Lencioni DE, 1999, P SOC PHOTO-OPT INS, V3870, P269, DOI 10.1117/12.373195
   LUO J, 1997, P 1997 IEEE INT S CI, V2, P1081
   MALIN MC, 1992, J GEOPHYS RES-PLANET, V97, P7699, DOI 10.1029/92JE00340
   Malin MC, 2001, J GEOPHYS RES-PLANET, V106, P17651, DOI 10.1029/1999JE001145
   MAYER J, 2002, P INT C IM PROC 2002, V1
   MCEWEN A, 2005, AM GEOPH UN FALL M 2
   Miers T. H., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4169, P362, DOI 10.1117/12.417141
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   RAHMAN Z, 2005, P SPIE, V5817
   RAHMAN Z, 2004, P SPIE, V5438
   Rahman ZU, 2008, PROC SPIE, V6978, DOI 10.1117/12.778053
   Rahman ZU, 2006, PROC SPIE, V6246, DOI 10.1117/12.664605
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   ROCKEY DE, 1990, P SOC PHOTO-OPT INS, V1298, P93, DOI 10.1117/12.21340
   STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782
   Tao L, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2136903
   TAO L, 2006, THESIS OLD DOMINION
   TESCHER AG, 1972, APPL OPTICS, V11, P919, DOI 10.1364/AO.11.000919
   WATKINSON J, 2001, MPEG HDB
   WOODELL GA, Patent No. 6842543
   Yong SS, 2007, PROC SPIE, V6744, DOI 10.1117/12.740069
   Zurek RW, 2007, J GEOPHYS RES-PLANET, V112, DOI 10.1029/2006JE002701
NR 49
TC 23
Z9 40
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 237
EP 250
DI 10.1016/j.jvcir.2010.12.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300004
DA 2024-07-18
ER

PT J
AU Ren, JC
   Jiang, JM
   Feng, Y
AF Ren, Jinchang
   Jiang, Jianmin
   Feng, Yue
TI Activity-driven content adaptation for effective video summarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Activity-driven content adaptation; Content of interest; Activity level;
   Video summarization; Compressed-domain processing; Frame categorization;
   Fuzzy decision; MPEG; Video signal processing
ID CONTENT REPRESENTATION; ABSTRACTION; EXTRACTION; FRAMEWORK; HIGHLIGHTS
AB In this paper, we present a novel method for content adaptation and video summarization fully implemented in compressed-domain. Firstly, summarization of generic videos is modeled as the process of extracted human objects under various activities/events. Accordingly, frames are classified into five categories via fuzzy decision including shot changes (cut and gradual transitions), motion activities (camera motion and object motion) and others by using two inter-frame measurements. Secondly, human objects are detected using Haar-like features. With the detected human objects and attained frame categories, activity levels for each frame are determined to adapt with video contents. Continuous frames belonging to same category are grouped to form one activity entry as content of interest (COI) which will convert the original video into a series of activities. An overall adjustable quota is used to control the size of generated summarization for efficient streaming purpose. Upon this quota, the frames selected for summarization are determined by evenly sampling the accumulated activity levels for content adaptation. Quantitative evaluations have proved the effectiveness and efficiency of our proposed approach, which provides a more flexible and general solution for this topic as domain-specific tasks such as accurate recognition of objects can be avoided. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Ren, Jinchang; Jiang, Jianmin; Feng, Yue] Univ Bradford, Digital Media & Syst Res Inst, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford
RP Ren, JC (corresponding author), Univ Bradford, Digital Media & Syst Res Inst, Bradford BD7 1DP, W Yorkshire, England.
EM j.ren@bradford.ac.uk; jjiang1@bradford.ac.uk; y.feng2@bradford.ac.uk
RI Feng, Yue/C-1302-2011
OI Ren, Jinchang/0000-0001-6116-3194
FU EU [IST-216709, IST-225353]
FX The authors wish to acknowledge the financial support from the EU IST
   Framework Research Programme under both HERMES project (Contract No.
   IST-216709) and MICIE project (Contract No. IST-225353).
CR [Anonymous], 2007, P CIVR
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Bescós J, 2007, SIGNAL PROCESS-IMAGE, V22, P651, DOI 10.1016/j.image.2007.05.009
   Calic J, 2007, IEEE T CIRC SYST VID, V17, P931, DOI 10.1109/TCSVT.2007.897466
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Chen LH, 2003, J VIS COMMUN IMAGE R, V14, P358, DOI 10.1016/S1047-3203(03)00036-1
   Cheung SCS, 2005, IEEE T MULTIMEDIA, V7, P524, DOI 10.1109/TMM.2005.846906
   Cheung SCS, 2003, IEEE T CIRC SYST VID, V13, P59, DOI 10.1109/TCSVT.2002.808080
   Dimitrova N, 2004, IEEE MULTIMEDIA, V11, P7, DOI 10.1109/MMUL.2004.6
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Drew MS, 2003, IMAGE VISION COMPUT, V21, P705, DOI 10.1016/S0262-8856(03)00065-9
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Fonseca PM, 2004, SIGNAL PROCESS-IMAGE, V19, P685, DOI 10.1016/j.image.2004.04.005
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Hanjalic A, 2007, IEEE T CIRC SYST VID, V17, P261, DOI 10.1109/TCSVT.2007.890833
   Hatzigiorgaki M, 2003, PROC SPIE, V5150, P439, DOI 10.1117/12.507669
   Ju SX, 1998, IEEE T CIRC SYST VID, V8, P686, DOI 10.1109/76.718513
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Li Z, 2005, IEEE T IMAGE PROCESS, V14, P1550, DOI 10.1109/TIP.2005.854477
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   REN J, 2007, P INT C IM PROC, V1, P481
   Ren JC, 2009, IEEE T MULTIMEDIA, V11, P906, DOI 10.1109/TMM.2009.2021782
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zhu XQ, 2005, IEEE T MULTIMEDIA, V7, P648, DOI 10.1109/TMM.2005.850977
   Zhu XQ, 2004, MULTIMEDIA SYST, V10, P98, DOI 10.1007/s00530-004-0142-7
   Zhu XQ, 2003, MULTIMEDIA SYST, V9, P31, DOI 10.1007/s00530-003-0076-5
NR 42
TC 8
Z9 11
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 930
EP 938
DI 10.1016/j.jvcir.2010.09.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500016
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zamarin, M
   Milani, S
   Zanuttigh, P
   Cortelazzo, GM
AF Zamarin, M.
   Milani, S.
   Zanuttigh, P.
   Cortelazzo, G. M.
TI A novel multi-view image coding scheme based on view-warping and 3D-DCT
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view image coding; 3D warping; 3D-DCT; Multi-view plus depth;
   3DTV; 3D spatial prediction; Disparity compensation; Hole filling
ID VIDEO; H.264/AVC
AB Efficient compression of multi-view images and videos is an open and interesting research issue that has been attracting the attention of both academic and industrial world during the last years. The considerable amount of information produced by multi-camera acquisition systems requires effective coding algorithms in order to reduce the transmitted data while granting good visual quality in the reconstructed sequence. The classical approach of multi-view coding is based on an extension of the H.264/AVC standard, still based on motion prediction techniques. In this paper we present a novel approach that tries to fully exploit the redundancy between different views of the same scene considering both texture and geometry information. The proposed scheme replaces the motion prediction stage with a 3D warping procedure based on depth information. After the warping step, a joint 3D-DCT encoding of all the warped views is provided, taking advantage of the strong correlation among them. Finally, the transformed coefficients are conveniently quantized and entropy coded. Occluded regions are also taken into account with ad-hoc interpolation and coding strategies. Experimental results performed with a preliminary version of the proposed approach show that at low bitrates it outperforms the H.264 MVC coding scheme on both real and synthetic datasets. Performance at high bitrates are also satisfactory provided that accurate depth information is available. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Milani, S.] Univ Padua, Dept Informat Engn, Digital Signal & Image Proc Lab, I-35131 Padua, Italy.
   [Zamarin, M.; Zanuttigh, P.; Cortelazzo, G. M.] Univ Padua, Dept Informat Engn, Multimedia Technol & Telecommun Lab, I-35131 Padua, Italy.
C3 University of Padua; University of Padua
RP Zamarin, M (corresponding author), Univ Padua, Dept Informat Engn, Multimedia Technol & Telecommun Lab, Via Gradenigo 6-B, I-35131 Padua, Italy.
EM zamarinm@dei.unipd.it; simone.milani@dei.unipd.it;
   pietro.zanuttigh@dei.unipd.it; corte@dei.unipd.it
RI Zanuttigh, Pietro/AAB-9555-2019
OI Zanuttigh, Pietro/0000-0002-9502-2389; Milani,
   Simone/0000-0001-8266-5839
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Dufaux F, 2007, SPIE DEF SEC S DSS 2
   Fryza T, 2007, 2007 17TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA, VOLS 1 AND 2, P212
   Guo X, 2006, IEEE T CIRC SYST VID, V16, P1527, DOI 10.1109/TCSVT.2006.885724
   HO YS, 2007, P INT WORKSH SYST SI, P5
   *ISO IEC MPEG, 2008, JOINT DRAFT 8 0 MULT
   Li J, 2007, I S INTELL SIG PROC, P510
   Li L, 2007, MEDIA CONVERGENCE: MOVING TO THE NEXT GENERATION, P59
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Martinian E, 2006, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2006.312963
   MILANI S, 2008, P 6 EUR SIGN PROC C
   Ozaktas H.M., 2008, Three-Dimensional Television: Capture, Transmission, Display
   RAYMOND KW, 1997, INT C VIRT SYST MULT, P188
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sgouros NP, 2005, 2005 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), Vols 1 and 2, P180
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   WIEGAND T, 2001, IEEE INT C IM PROC I
   WIEGAND T, 2004, JOINT VID TEAM ISO I
   Yang WX, 2006, IEEE T CIRC SYST VID, V16, P1385, DOI 10.1109/TCSVT.2006.884571
   YEO BL, 1995, IEEE T VIS COMPUT GR, V1, P29, DOI 10.1109/2945.468390
   Zanuttigh P., 2009, 3DTV C TRUE VIS CAPT, P1
   Zanuttigh P, 2006, SIGNAL PROCESS-IMAGE, V21, P787, DOI 10.1016/j.image.2006.06.003
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 23
TC 7
Z9 8
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 462
EP 473
DI 10.1016/j.jvcir.2009.09.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Heiss-Czedik, D
   Huber-Mörk, R
   Soukup, D
   Penz, H
   García, BL
AF Heiss-Czedik, Dorothea
   Huber-Moerk, Reinhold
   Soukup, Daniel
   Penz, Harald
   Garcia, Beatriz Lopez
TI Demosaicing algorithms for area- and line-scan cameras in print
   inspection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Industrial print inspection; Color filter array (CFA); Demosaicing;
   Line-Scan camera; Time delay and integration (TDI); Weighted
   interpolation; Least squares approximation; Color image acquisition;
   Bayer pattern
ID COLOR; DESIGN
AB Most color image sensors use color filter arrays (CFA). With this sensor design the captured information at each sensor pixel position is restricted to a specific spectral portion (typically red, green and blue bands). To obtain the missing color responses at each pixel position, so-called CFA demosaicing algorithms are commonly used. We propose two new CFA demosaicing algorithms, which are well suited for industrial print inspection with respect to the requirements in accuracy and speed. As a main contribution, we introduce novel demosaicing algorithms for specific high-speed color digital time delay and integration (DTDI) CFA line-scan cameras. We compare the suggested CFA demosaicing algorithms to state-of-the art algorithms for area and line-scan camera operation modes. We show that the two new algorithms perform superior to conventional algorithms as indicated by reconstruction error. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Heiss-Czedik, Dorothea; Huber-Moerk, Reinhold; Soukup, Daniel; Penz, Harald; Garcia, Beatriz Lopez] Austrian Inst Technol, Dept Safety & Secur, Business Unit High Performance Image Proc, A-2444 Seibersdorf, Austria.
C3 Austrian Institute of Technology (AIT)
RP Huber-Mörk, R (corresponding author), Austrian Inst Technol, Dept Safety & Secur, Business Unit High Performance Image Proc, A-2444 Seibersdorf, Austria.
EM Reinhold.Huber@arcs.ac.at
CR ADAMS JE, 1995, P SOC PHOTO-OPT INS, V2416, P144
   [Anonymous], HPL2003164R1
   BAYER B, 1974, Patent No. 3971065
   BENNET EP, 2006, P EUR C COMP VIS, P508
   Chang E, 1999, P SOC PHOTO-OPT INS, V3650, P36, DOI 10.1117/12.342861
   Cok D. R., 1987, US Patent, Patent No. [4,642,678, 4642678]
   COLLETTE ML, 1994, Patent No. 5570146
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   FREEMAN WT, 1988, Patent No. 4724395
   FURTLER J, 2007, P EL IM C MACH VIS A
   Hamilton Jr J. F., 1997, US Patent, Patent No. [5,629,734, 5629734]
   Hubel PM, 2004, P SOC PHOTO-OPT INS, V5301, P402, DOI 10.1117/12.561568
   Huber-Moerk R, 2007, PATTERN RECOGN LETT, V28, P2037, DOI 10.1016/j.patrec.2007.06.008
   Kimmel R, 1999, IEEE T IMAGE PROCESS, V8, P1221, DOI 10.1109/83.784434
   Laroche C., 1994, United States Patent, Patent No. 5373322
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Malvar H., 2004, P INT C AC SPEECH SI
   Narasimhan SG, 2005, IEEE T PATTERN ANAL, V27, P518, DOI 10.1109/TPAMI.2005.76
   NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017
   Ramanath R, 2002, J ELECTRON IMAGING, V11, P306, DOI 10.1117/1.1484495
   WONG HS, 1992, IBM J RES DEV, V36, P83, DOI 10.1147/rd.361.0083
   Wu YM, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P90
   2006, VISION SYSTEMS DESIG, V11, pD20
   [No title captured]
NR 24
TC 9
Z9 10
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 389
EP 398
DI 10.1016/j.jvcir.2009.04.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900003
DA 2024-07-18
ER

PT J
AU Peng, WH
   Zao, JK
   Huang, HT
   Wang, TW
   Huang, LS
AF Peng, Wen-Hsiao
   Zao, John K.
   Huang, Hsueh-Ting
   Wang, Tse-Wei
   Huang, Lin-Shung
TI A rate-distortion optimization model for SVC inter-layer encoding and
   bitstream extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable Video Coding; Bitstream extraction; Inter-layer dependency;
   H.264/AVC; Rate-distortion optimization; Steepest-descent search;
   Multiple adaptation; Video streaming; Subjective quality; Quality metric
AB The Scalable Video Coding (SVC) standard enables viewing devices to adapt their video reception using bitstream extraction. Since SVC offers spatial, temporal, and quality combined scalability, extracting proper bitstreams for different viewing devices can be a non-trivial task, and naive choices usually produce poor playback quality. In this paper, we propose a two-prong approach to achieve rate-distortion (R-D) optimal extraction of SVC bitstreams. For SVC encoding, we developed a set of adaptation rules for setting the quantization parameters and the inter-layer dependencies among the SVC coding layers. A well-adapted SVC bitstream thus produced manifests good R-D trade-offs when its scalable layers are extracted along extraction paths consisting of successive refinement steps. For extracting R-D optimized bitstreams for different viewing devices, we formalized the notion of optimal and near-optimal extraction paths and devised computationally efficient strategies to search for the extraction paths. Experiment results demonstrated that our R-D optimized adaptation schemes and extraction strategies offer significant improvement in playback picture quality among heterogeneous viewing devices. Particularly, our adaptation rules promise R-D convexity along optimal extraction paths and permit the use of steepest-descent strategy to discover the optimal/near-optimal paths. This simple search strategy performs only half of the computation necessary for an exhaustive search. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Peng, Wen-Hsiao; Zao, John K.; Huang, Hsueh-Ting; Wang, Tse-Wei; Huang, Lin-Shung] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Peng, WH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 30010, Taiwan.
EM pawn@mail.si2lab.org; jkzao@cs.nctu.edu.tw
OI PENG, WEN-HSIAO/0000-0002-4421-8031
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   Huang HC, 2007, IEEE COMMUN MAG, V45, P68, DOI 10.1109/MCOM.2007.284540
   Kim YS, 2006, P SOC PHOTO-OPT INS, V6077, P7723, DOI 10.1117/12.643505
   Li ZG, 2006, IEEE T CIRC SYST VID, V16, P1449, DOI 10.1109/TCSVT.2006.885176
   LIM J, 2006, JTC11SC291WG11 ISOIE
   LIU J, 2005, IEEE T PARALL DISTR, V16, P6
   PENG WH, 2008, IEEE INT C IM PROC I
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   REICHEL J, 2007, JTCISC29WG11 ISOIEC
   SCHWARZ H, 2007, JTCISC29WG11 ISOIEC
   SCHWARZ H, 2006, IEEE INT C IM PROC I
   TAUBMAN D, 1999, IEEE INT C IM PROC I
   Wang YK, 2007, IEEE T CIRC SYST VID, V17, P1149, DOI 10.1109/TCSVT.2007.906827
   Wiegand T., 2007, JTCISC29WG11 ISOIEC
   Yao W, 2007, IEEE INT SYMP CIRC S, P1759, DOI 10.1109/ISCAS.2007.378012
NR 15
TC 9
Z9 9
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 543
EP 557
DI 10.1016/j.jvcir.2008.08.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300008
DA 2024-07-18
ER

PT J
AU Chaikalis, D
   Sgouros, N
   Maroulis, D
   Papageorgas, P
AF Chaikalis, D.
   Sgouros, N.
   Maroulis, D.
   Papageorgas, P.
TI Hardware implementation of a disparity estimation scheme for real-time
   compression in 3D imaging applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D imaging; Integral Photography; autostereoscopic display; hardware;
   FPGA; real-time; compression
AB This paper presents a novel hardware implementation of a disparity estimation scheme targeted to real-time Integral Photography (IP) image and video sequence compression. The software developed for IP image compression achieves high quality ratios over classic methodologies by exploiting the inherent redundancy that is present in IP images. However, there are certain time constraints to the software approach that must be confronted in order to address real-time applications. Our main effort is to achieve real-time performance by implementing in hardware the most time-consuming parts of the compression algorithm. The proposed novel digital architecture features minimized memory read operations and extensive simultaneous processing, while taking into concern the memory and data bandwidth limitations of a single FPGA implementation. Our results demonstrate that the implemented hardware system can successfully process high resolution IP video sequences in real-time, addressing a vast range of applications, from mobile systems to demanding desktop displays. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Chaikalis, D.; Sgouros, N.; Maroulis, D.] Natl & Kapodistrian Univ Athens, Dept Informat Telecommun, Athens 15784, Greece.
   [Papageorgas, P.] Technol Educ Inst Piraeus, Dept Elect, Athens 12244, Greece.
C3 National & Kapodistrian University of Athens; University of West Attica
RP Chaikalis, D (corresponding author), Natl & Kapodistrian Univ Athens, Dept Informat Telecommun, Athens 15784, Greece.
EM dhaik@di.uoa.gr; nsg@di.uoa.gr; dmarou@di.uoa.gr; ppapag@teipir.gr
RI Sgouros, Nicholas/AAZ-9852-2021; Papageorgas, Panagiotis G./C-4808-2019
OI Papageorgas, Panagiotis/0000-0003-0515-9961; Sgouros,
   Nicholas/0000-0001-8945-3492; Maroulis, Dimitris/0000-0002-2721-9219
CR *CEL, RC1000PP DEV BOARD H
   CHAIKALIS D, 2004, INT C SIGN EL SYST I, P309
   Harman P, 2000, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2000.900877
   Konrad J, 2001, IEEE COMMUN MAG, V39, P126, DOI 10.1109/35.894386
   Liao H., 2001, LNCS, V2208, P392
   Lippmann G, 1908, CR HEBD ACAD SCI, V146, P446
   Martina M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA177
   Moshnyaga VG, 1997, IPPS PROC, P28, DOI 10.1109/IPPS.1997.580838
   OHM JR, 1998, COMMUNICATION    JAN
   PENNEBAKER WB, 1993, JPEG IMAGE COMPRESSI
   RAMACHANDRAN S, 2001, 9 INT S FPGAS MONT C
   RATHNAM S, 1996, COMPCON 96 TECHN INF, P319
   ROMA N, 2003, P 3 INT C FIELD PROG, P745
   SGOUROS N, 2003, 3 INT S IM SIGN PROC
   *STER, 1997, DEV HDB
   Wong S, 2002, EUROMICRO CONF PROC, P183, DOI 10.1109/EURMIC.2002.1046155
   WONG S, 2002, IEEE I C FIELD PROGR
   WOODS R, 1996, IEEE S FPGAS CUST CO
   ZAHARIA R, 2002, IMAGE COMMUN, V17, P231
   ZANDONAI D, 2001, 7 WORKSH IB IWS 2001, V1, P90
   [No title captured]
NR 21
TC 11
Z9 12
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2008
VL 19
IS 1
BP 1
EP 11
DI 10.1016/j.jvcir.2007.09.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 257SY
UT WOS:000252820000001
DA 2024-07-18
ER

PT J
AU Jung, YM
   Shen, JH
AF Jung, Yoon Mo
   Shen, Jianhong (Jackie)
TI First-order modeling and stability analysis of illusory contours
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE illusion; illusory contours; energy model; local stability; contour
   decomposition; real and imaginary; kinks; spans; turns; level-set
   method; supervision
ID CURVATURE; FOUNDATIONS
AB In visual cognition, illusions help elucidate certain intriguing latent perceptual functions of the human vision system, and their proper mathematical modeling and computational simulation are therefore deeply beneficial to both biological and computer vision. Inspired by existent prior works, the current paper proposes a first-order energy-based model for analyzing and simulating illusory contours. The lower complexity of the proposed model facilitates rigorous mathematical analysis on the detailed geometric structures of illusory contours. After being asymptotically approximated by classical active contours, the proposed model is then robustly computed using the celebrated level-set method of Osher and Sethian [S. Osher, J.A. Sethian, Fronts propagating with curvature-dependent speed: algorithms based on Hamilton-Jacobi formulations, J. Comput. Phys., 79 (12) (1988) 12-49] with a natural supervising scheme. Potential cognitive implications of the mathematical results are addressed, and generic computational examples are demonstrated and discussed. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Jung, Yoon Mo; Shen, Jianhong (Jackie)] Univ Minnesota, Sch Math, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Shen, JH (corresponding author), Univ Minnesota, Sch Math, 206 Church St SE, Minneapolis, MN 55455 USA.
EM jhshen@math.umn.edu
OI Shen, Jackie/0000-0003-0653-3951
CR Adelson E. H., 2000, NEW COGNITIVE NEUROS, P339, DOI DOI 10.1068/P230869
   [Anonymous], 1979, Organization in vision
   [Anonymous], NEW COGNITIVE NEUROS
   [Anonymous], 2005, 0309 UCLA CAM
   [Anonymous], IMAGE PROCESSING ANA
   Aubert G., 2001, MATH PROBLEMS IMAGE
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   Folland G.B., 1999, Pure and Applied Mathe- matics, Vsecond
   FREEMAN WT, 1994, NATURE, V368, P542, DOI 10.1038/368542a0
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KELLEY JL, 1997, GEN TOPOLOGY
   Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537
   KNILL DC, 1991, NATURE, V351, P228, DOI 10.1038/351228a0
   MATHER G, 1989, VISION RES, V29, P143, DOI 10.1016/0042-6989(89)90181-8
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   MUMFORD D., 1994, ALGEBRAIC GEOMETRY I, P491, DOI DOI 10.1007/978-1-4612-2628-4_31
   NITZBERG M, 1993, LECT NOTES COMP SCI, V662
   Oppenheim A.V., 2014, Signals and systems
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Osher Stanley., 2002, GEOMETRIC LEVEL SET
   Petry S., 1987, PERCEPTION ILLUSORY
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sarti A, 2002, INT J COMPUT VISION, V46, P201, DOI 10.1023/A:1014028906229
   Sethian J., 1999, LEVEL SET METHODS FA
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Shen JH, 2006, J MATH IMAGING VIS, V24, P5, DOI 10.1007/s10851-005-3600-8
   Shen JH, 2004, SIAM J APPL MATH, V64, P1691, DOI 10.1137/S0036139902418699
   Shen JH, 2003, PHYSICA D, V175, P241, DOI 10.1016/S0167-2789(02)00734-0
   VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501
   VONDERHEYDT R, 1989, J NEUROSCI, V9, P1731
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837
   ZHU W, 2003, 0365 UCLA CAM
NR 38
TC 10
Z9 10
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2008
VL 19
IS 1
BP 42
EP 55
DI 10.1016/j.jvcir.2007.07.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 257SY
UT WOS:000252820000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kaminsky, E
   Grois, D
   Hadar, O
AF Kaminsky, E.
   Grois, D.
   Hadar, O.
TI Dynamic computational complexity and bit allocation for optimizing
   H.264/AVC video compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE computational complexity allocation; bit allocation; coding modes
   selection; video compression; H.264/AVC
AB In this work, we present a novel approach for optimizing H.264/AVC video compression by dynamically allocating computational complexity (such as a number of CPU clocks) and bits for encoding each coding element (basic unit) within a video sequence, according to its predicted MAD (mean absolute difference). Our approach is based on a computational complexity rate-distortion (C-R-D) analysis, which adds a complexity dimension to the conventional rate-distortion (R-D) analysis. Both theoretically and experimentally, we prove that by implementing the proposed approach for the dynamic allocation better results are achieved. We also prove that the optimal computational complexity allocation along with optimal bit allocation is better than the constant computational complexity allocation along with optimal bit allocation. In addition, we present a method and system for implementing the proposed approach, and for controlling computational complexity and bit allocation in real-time and off-line video coding. We divide each frame into one or more basic units, wherein each basic unit consists of at least one macroblock (MB), whose contents are related to a number of coding modes. We determine how much computational complexity and bits should be allocated for encoding each basic unit, and then allocate a corresponding group of coding modes and a quantization step-size, according to the estimated distortion (calculated by a linear regression model) of each basic unit and according to the remaining computational complexity and bits for encoding remaining basic units. For allocating the corresponding group of coding modes and the quantization step-size, we develop computational complexity-complexity step-rate (C-I-R) and rate-quantization step-size-computational complexity (R-Q-C) models. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Grois, D.] Ben Gurion Univ Negev, Electroopt Unit Engn Dept, IL-84105 Beer Sheva, Israel.
   [Kaminsky, E.] Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-84105 Beer Sheva, Israel.
   [Hadar, O.] Ben Gurion Univ Negev, Commun Syst Engn Dept, IL-84105 Beer Sheva, Israel.
C3 Ben Gurion University; Ben Gurion University; Ben Gurion University
RP Grois, D (corresponding author), Ben Gurion Univ Negev, Electroopt Unit Engn Dept, IL-84105 Beer Sheva, Israel.
EM evgenyk@ee.bgu.ac.il; grois@ee.bgu.ac.il; hadar@cse.bgu.ac.it
OI Grois, Dan/0000-0002-7659-0129; Hadar, Ofer/0000-0002-6089-8401
CR CHEUNG G, 1998, THESIS ELECT ENG COM
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   CHOI JH, 1994, IEEE T IMAGE PROCESS, V3, P546, DOI 10.1109/83.334986
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Grecos C, 2003, IEEE T CIRC SYST VID, V13, P519, DOI 10.1109/TCSVT.2003.813424
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   KANNANGARA CS, 2005, P VLBV 2005 C GLASG, P379
   MA S, 2003, P INT S CIRC SYST IS, V2, P892
   ORTEGA A, 1994, IEEE T IMAGE PROCESS, V3, P26, DOI 10.1109/83.265978
   Reimers U, 1998, IEEE COMMUN MAG, V36, P104, DOI 10.1109/35.685371
   Ribas-Corbera J, 2003, IEEE T CIRC SYST VID, V13, P674, DOI 10.1109/TCSVT.2003.814965
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   *VCODEX, H 264 TUT WHIT PAP
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958171
NR 15
TC 15
Z9 15
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2008
VL 19
IS 1
BP 56
EP 74
DI 10.1016/j.jvcir.2007.05.002
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 257SY
UT WOS:000252820000006
DA 2024-07-18
ER

PT J
AU Yi, XQ
   Ling, N
AF Yi, Xiaoquan
   Ling, Nam
TI Improved H.264 rate control by enhanced MAD-based frame complexity
   prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; rate control; quadratic rate-distortion model; frame
   complexity prediction; video coding
AB This paper presents a revised rate control scheme based on an improved frame complexity measure. Rate control adopted by both MPEG-4 VM18 and H.264/AVC use a quadratic ratedistortion (R-D) model that determines quantization parameters (QPs). Classical quadratic R-D model is suitable for MPEG-4 but it performs poorly for H.264/AVC because one of the important parameters, mean absolute difference (MAD), is predicted through a linear model, whereas the MAD used in MPEG-4 VM 18 is the actual MAD. Inaccurately predicted MAD results in wrong QP and consequently degrades rate-distortion optimization (RDO) performance'in H.264. To overcome the limitation of the existing rate control schemes, we introduce an enhanced linear model for predicting MAD, utilizing some knowledge of current frame complexity. Moreover, we propose a more accurate frame complexity measure, namely, normalized MAD, to replace the current use of MAD parameter. Normalized MAD has a stronger correlation with optimally allocated bits than that of the predicted MAD. To minimize video quality variations, we also propose a novel long-term QP limiter (LTQPL). Finally, a dynamic bit allocation scheme among basic units is implemented. Extensive simulation results show that our method, with inexpensive computational complexity added, improves the average peak signal-to-noise ratio (PSNR) and reduces video quality variations considerably. (c) 2005 Elsevier Inc. All rights reserved.
C1 Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
C3 Santa Clara University
RP Ling, N (corresponding author), Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
EM nling@scu.edu
CR He Z., 2003, INT C INF TECHN RES
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   Jiang MQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P813
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Li Z. G., 2003, 7 M PATT 2 THAIL
   Li ZG, 2003, IEEE T CIRC SYST VID, V13, P472, DOI 10.1109/TCSVT.2003.813420
   Ribas-Corbera J, 2000, IEEE T CIRC SYST VID, V10, P1154, DOI 10.1109/76.875518
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Sullivan G., 2003, JVTI049
   Vetro A, 1999, IEEE T CIRC SYST VID, V9, P186, DOI 10.1109/76.744285
   *VID GROUP, 2001, COD MOV PICT ASS AUD
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WIEGAND T, 2003, JVTG050R1
   Xie B, 2002, IEEE IMAGE PROC, P77
   XU J, 2004, P INT S CIRS SYST MA, V3, P809
   Yi XQ, 2004, 2004 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS DESIGN AND IMPLEMENTATION, PROCEEDINGS, P263
NR 16
TC 15
Z9 17
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 407
EP 424
DI 10.1016/j.jvcir.2005.04.005
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000012
DA 2024-07-18
ER

PT J
AU De Stefano, A
   Collis, B
   White, P
AF De Stefano, Antonio
   Collis, Bill
   White, Paul
TI Synthesising and reducing film grain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE film grain; synthesis; reduction; wavelet transform; non-linear
   filtering
ID WAVELET SHRINKAGE; NOISE; TRANSFORM; RESTORATION; ENHANCEMENT; PRIORS
AB This paper describes some tools for adding and removing film grain. The film grain is represented using an additive signal-depen dent model. The approach adopted for artificial grain synthesis avoids subjectivity and an assumption of Gaussianity. The grain within a user-defined plain area is analysed and the synthesis routine generates grain with matching spatial structure having the same probability distribution function as the original. The grain reduction method is based on manipulation of the coefficients achieved using a bi-orthogonal undecimated wavelet decomposition and is extremely advantageous for real-time implementation. The scheme for modifying the coefficient is derived from Bayesian estimation and approximates a range of optimal non-linear functions. Training to deduce parameter values is conducted by contaminating several nominally noise-free images with various realisations of grain noise. Using real and synthetically generated grain noise demonstrated an improvement of objective and visual qualities of the image. The ability of the technique to adapt with respect to image and noise characteristics is also clear. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Southampton, ISVR, Highfield S017 1BJ, Hants, England.
   Foundry, London W1F 7JE, England.
C3 University of Southampton
RP De Stefano, A (corresponding author), Univ Southampton, ISVR, Highfield S017 1BJ, Hants, England.
EM ads@isvr.soton.ac.uk
OI White, Paul/0000-0002-4787-8713
CR ABRAMOVICH F, 1995, WAVELEETS STAT
   [Anonymous], 1998, Wavelet Analysis: the Scalable Structure of Information
   ASHIKHMIN A, 2001, S INT 3D GRAPH
   BRUCE A, 1996, IEEE SPECTRUM    OCT, P26
   COIFMANN RR, 1995, WAVELETS STAT
   DESTEFANO A, 2000, ICIP 2000 IEEE C VAN
   DESTEFANO A, 2000, THESIS ISVR U SOUTH
   DESTEFANO A, 2000, P 5 IMA C SIGN P WAR
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301
   DUTTILLEUX P, 1989, WAVELET TIME FREQUEN, P298
   EGIAZARIAN K, 2000, P SOC PHOTO-OPT INS, V4170, P13
   EGIAZARIAN K, 1968, 01CH37221 IEEE, V3, P1869
   ERFROS AA, 2001, ACM SIGGRAPH 01
   FALCONER DG, 1970, OPT ACTA, V17, P693, DOI 10.1080/713818360
   Fischer M, 2002, IEEE T IMAGE PROCESS, V11, P717, DOI [10.1109/TIP.2002.800893, 10.1109/TIP2002.800893]
   FISCHER M, 2000, P 10 EUR SIGN PROC C, V1, P1
   HUNT BR, 1977, IEEE T COMPUT, V26, P219, DOI 10.1109/TC.1977.1674810
   Jansen M, 1999, P SOC PHOTO-OPT INS, V3813, P580, DOI 10.1117/12.366813
   KASTURI R, 1984, P 7 C PATT REC, V1, P148
   Kay S. M., 1987, MODERN SPECTRAL ESTI
   KINGSBURY N, 2000, IEE C, P1
   Lepage R., 1992, EXPLORING LIMITS BOO
   Lina JM, 1997, P SOC PHOTO-OPT INS, V3169, P67, DOI 10.1117/12.279680
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MCLEAN I, 2001, 01049 IEE, V2, P1
   Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332
   Öktem R, 1999, ELECTRON LETT, V35, P1830, DOI 10.1049/el:19991261
   OKTEM R, 2001, 00CH37100 IEEE, V4, P2063
   Press W. H., 1988, Numerical Recipes
   SCHMAKER LL, 1994, RECENT ADV WAVELET A
   SHARMA A, 2001, DIGITAL PHOTO TECHNI, P62
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Soon IY, 1998, SPEECH COMMUN, V24, P249, DOI 10.1016/S0167-6393(98)00019-3
   Stroebel Leslie., 1986, Photographic materials and processes
   TAVILDAR AS, 1985, SIGNAL PROCESS, V8, P363, DOI 10.1016/0165-1684(85)90112-4
   TAVILDAR AS, 1984, SIGNAL PROCESS, V6, P225
   VANROOSMALEN PMB, 1996, IEEE INT C IM PROC, V1, P375
   WEI D, 1995, IEEE T IMAGE PROCESS, V1, P610
   YAN J, 2000, IEE P VISION IMAGE S, V147
NR 41
TC 2
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 163
EP 182
DI 10.1016/j.jvcir.2005.06.002
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900010
DA 2024-07-18
ER

PT J
AU Imiya, A
   Saito, M
AF Imiya, A.
   Saito, M.
TI Thinning by curvature flow
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE thinning; skeleton; digital geometry; curvature flow; topology; binary
   images and objects
ID DISTANCE TRANSFORMS; DISCRETE OBJECTS; SKELETONIZATION; TOPOLOGY; SHAPE
AB In this paper, we define digital curvature flow for spatial digital objects. We define the principal normal vectors for points on the digital boundary of a binary spatial object. We apply the discrete curvature flow for the skeletonisation of binary objects in a space, and develop a transform which yields the curve-skeletons of binary objects in a space. (c) 2005 Elsevier Inc. All rights reserved.
C1 Chiba Univ, IMIT, Inage Ku, Chiba 2638522, Japan.
   Chiba Univ, Sch Sci & Technol, Inage Ku, Chiba 2638522, Japan.
C3 Chiba University; Chiba University
RP Imiya, A (corresponding author), Chiba Univ, IMIT, Inage Ku, Yayoi Cho 1-33, Chiba 2638522, Japan.
EM imiya@faculty.chib-u.jp
CR Amenta N, 1998, GRAPH MODEL IM PROC, V60, P125, DOI 10.1006/gmip.1998.0465
   [Anonymous], 1996, Level Set Methods: Evolving Interfaces in Computational Geometry, Fluid Mechanics, Computer Vision, and Materials Science
   Attali D, 1997, COMPUT VIS IMAGE UND, V67, P261, DOI 10.1006/cviu.1997.0536
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   BOOKSTEIN FL, 1979, CVGIP, V11, P1233
   Bruckstein AM, 1995, INT J PATTERN RECOGN, V9, P991, DOI 10.1142/S0218001495000407
   di Baja GS, 2000, LECT NOTES COMPUT SC, V1876, P387
   Francon J, 1996, THEOR COMPUT SCI, V156, P159, DOI 10.1016/0304-3975(95)00059-3
   Giblin P. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P385, DOI 10.1109/ICCV.1999.791246
   HILDITCH J, 1969, MACH INTELL, V4, P403
   Imiya A, 1999, COMPUT VIS IMAGE UND, V75, P307, DOI 10.1006/cviu.1999.0791
   Imiya A, 1999, LECT NOTES COMPUT SC, V1682, P477
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   NYSTROM I, 2001, LECT NOTES COMPUTER, V2059, P229
   ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1
   Svensson S, 2002, IMAGE VISION COMPUT, V20, P529, DOI 10.1016/S0262-8856(02)00042-2
   Svensson S, 1999, J VIS COMMUN IMAGE R, V10, P379, DOI 10.1006/jvci.1999.0425
   Svensson S, 2002, PATTERN RECOGN LETT, V23, P1419, DOI 10.1016/S0167-8655(02)00102-2
   TORIWAKI J, 1988, DIGITAL IMAGE PROCES, V2
   TORIWAKI JI, 1988, DIGITAL IMAGE PROCES, V1
NR 20
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 27
EP 41
DI 10.1016/j.jvcir.2005.03.008
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900002
DA 2024-07-18
ER

PT J
AU Díaz-Báñez, JM
   Hurtado, F
   López, MA
   Sellarès, JA
AF Díaz-Báñez, JM
   Hurtado, F
   López, MA
   Sellarès, JA
TI Optimal projections onto grids and finite resolution images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE projections; finite resolution images; optimal images
ID ALGORITHMS; POINTS
AB The problem of determining nice (regular, simple, minimum crossing, and monotonic) and non-degenerate (with distinct x-coordinate, non-collinear, non-cocircular, and non-parallel) orthogonal and perspective images of a set of points or a set of disjoint line segments has been studied extensively in the literature for the theoretical case of infinite resolution images [J. Vis. Commun. Image Represent. 10 (2) (1999) 155; Int. J. Math. Algorithms 2 (2001) 227; J. Vis. Commun. Image Represent. 12 (4) (2001) 387; J. Vis. Commun. Image Represent.]. In this paper we propose to extend the study of this type of problems to the case where the images have finite resolution. Applications dealing with such images are common in practice, in fields such as computer graphics and computer vision. We derive algorithms that solve three related problems, both exactly and approximately. Given a set P in the plane or in the space, find a graduated line, a line partitioned into unit length intervals, so that the maximum number of points of P that are projected into a single interval is minimized. In space we also study the variant where we want to project P onto a graduated plane, a plane partitioned into unit squares. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Girona, Inst Informat & Aplicac, Girona, Spain.
   Univ Seville, Dept Matemat Aplicada 2, Seville, Spain.
   UPC, Dept Matemat Aplicada 2, Barcelona, Spain.
   Univ Denver, Dept Comp Sci, Denver, CO USA.
C3 Universitat de Girona; University of Sevilla; Universitat Politecnica de
   Catalunya; University of Denver
RP Sellarès, JA (corresponding author), Univ Girona, Inst Informat & Aplicac, Girona, Spain.
EM sellares@ima.udg.es
RI Diaz-Banez, Jose Miguel/L-1996-2014; Sellares, J. Antoni/K-5001-2014
OI Diaz-Banez, Jose Miguel/0000-0002-4031-4309; Sellares, J.
   Antoni/0000-0002-8764-7178
CR Agarwal PK, 2002, ALGORITHMICA, V32, P521, DOI 10.1007/s00453-001-0084-9
   ASANO T, 1993, ALGORITHMICA, V9, P572, DOI 10.1007/BF01190156
   Bose P, 1999, J VIS COMMUN IMAGE R, V10, P155, DOI 10.1006/jvci.1999.0415
   BOSE P, 2001, P 17 EUR WORKSH COMP, P74
   CHAZELLE B, 1989, LECT NOTES COMPUT SC, V372, P179
   Gómez F, 2002, J VIS COMMUN IMAGE R, V13, P401, DOI 10.1006/jvci.2001.0503
   Gómez F, 2001, J VIS COMMUN IMAGE R, V12, P387, DOI 10.1006/jvci.2001.0488
   GOMEZ F, 2001, INT J MATH ALGORITHM, V2, P227
   SHARIER M, 1995, DAVENPORT SCHINZEL S
   SHARIR M, 2000, LECT NOTES COMPUTER, V1738, P1
NR 10
TC 0
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 233
EP 249
DI 10.1016/j.jvcir.2004.11.001
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500001
DA 2024-07-18
ER

PT J
AU Kanjanawanishkul, K
   Uyyanonvara, B
AF Kanjanawanishkul, K
   Uyyanonvara, B
TI Novel fast color reduction algorithm for time-constrained applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE color quantization; sub-sampling quantizer; value representing
   variance-; centroid mapping; squared Euclidean distance
ID IMAGE QUANTIZATION; VARIANCE
AB In this paper, we propose a new adaptive approach of color quantization. It can significantly reduce the time consumption during the process compared with available methods but still maintains a good quality (greater than 30 dB of PSNR). It is implemented as a part of the media stream compression algorithms for a True Color Signboard System. We adapt and create some techniques to speed up the process. We start with a sampling technique on an RGB color space before constructing the 3D histogram of color distribution, and then we use the dynamic programming based on Wu's algorithm to construct the cumulative moment distribution. Then, we put the cutting plane through the centroid of that box. This plane is perpendicular to the axis, on which the sum of the squared Euclidean distances between the centroid of both of sub-boxes and the centroid of the box is the greatest. The sub-box, which contains the greatest value representing variance, is repeatedly sub-divided into the smaller sub-boxes until reaching the desired number of the representative colors. From our whole process, we gain approximately up to 50% less time consumption than Wu's quantizer [ACM Trans. Graph. 11 (1992) 3481 and it is significantly faster than existing algorithms as shown in the result. (C) 2004 Elsevier Inc. All rights reserved.
C1 Kasetsart Univ, Dept Elect Engn, Chon Buri 20230, Thailand.
   Thammasat Univ, Dept Informat Technol, Sirindhorn Int Inst Technol, Muang Pathumthani 12000, Thailand.
C3 Kasetsart University; Thammasat University
RP Kasetsart Univ, Dept Elect Engn, Siracha Campus 199,Moo 5,Sukhumwit Rd Thung Sukhl, Chon Buri 20230, Thailand.
EM kiattisin@eng.src.ku.ac.th; bunyarit@siit.tu.ac.th
RI Uyyanonvara, Bunyarit/A-6061-2011
CR [Anonymous], SIMPLE METHOD COLOR
   BALASUBRAMANIAN R, 1995, IEEE T IMAGE PROCESS, V4, P1282, DOI 10.1109/83.413172
   BALASUBRAMANIAN R, 1991, J IMAGING TECHNOL, V17, P284
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Heckbert P., 1982, Computer Graphics, V16, P297, DOI 10.1145/965145.801294
   Kohonen, 1989, SELF ORG ASS MEMORY
   LIM YW, 1990, PATTERN RECOGN, V23, P935, DOI 10.1016/0031-3203(90)90103-R
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   LIU GL, 1968, INTRO COMBINATION MA
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MCGOWAN JOHN, 2000, J MCGOWANS AVI OVERV
   ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417
   Papamarkos N, 2002, IEEE T SYST MAN CY B, V32, P44, DOI 10.1109/3477.979959
   Sangwine S. J., 1998, The colour image processing handbook
   Scheunders P, 1997, PATTERN RECOGN LETT, V18, P1379, DOI 10.1016/S0167-8655(97)00116-5
   Scheunders P, 1997, PATTERN RECOGN, V30, P859, DOI 10.1016/S0031-3203(96)00131-8
   Sirisathitkul Y, 2004, PATTERN RECOGN LETT, V25, P1025, DOI 10.1016/j.patrec.2004.02.012
   Verevka O., 1995, Proceedings Graphics Interface '95, P128
   WAN SJ, 1990, COLOR RES APPL, V15, P52, DOI 10.1002/col.5080150109
   WU XL, 1992, ACM T GRAPHIC, V11, P348, DOI 10.1145/146443.146475
   ZENG WJ, 1995, IEEE T CIRC SYST VID, V5, P236, DOI 10.1109/76.401101
NR 22
TC 31
Z9 32
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 311
EP 332
DI 10.1016/j.jvcir.2004.07.002
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500005
DA 2024-07-18
ER

PT J
AU Kuo, CM
   Hsieh, CH
   Huang, YR
AF Kuo, CM
   Hsieh, CH
   Huang, YR
TI Automatic extraction of moving objects for head-shoulder video sequence
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE object-based; video object; segmentation; temporal-activity; MAP
ID RANDOM-FIELDS; SEGMENTATION; IMAGE; NOISY
AB Recently, video object extraction has received great attention because it is a critical technique in object-based video processing. This paper presents a temporal-to-spatial segmentation technique to extract object from a video sequence. The temporal phase employs a simple blockwise temporal-activity measure to approximately locate the object boundary. And then a block-based maximum a posteriori (MAP) scheme, which exploits spatial features of image blocks around the approximated boundary, is adopted to refine the temporal segmentation result. The proposed technique achieves good segmentation quality with very low computational cost for head-and-shoulder sequences with static background. (C) 2004 Elsevier Inc. All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
CR ALATAN AA, IEEE T CIRCUITS SYST, V9, P1204
   CHIARIGLION L, IEEE T CIRCUITS SYST, V7, P5
   CHOI JG, 1998, MPEGM3349 ISOIEC JTC
   CORTEZ D, 1995, SIGNAL PROCESS-IMAGE, V6, P485, DOI 10.1016/0923-5965(94)00031-D
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   DERIN H, GRAPH IMAGE PROCESS, V32, P72
   Diehl N., 1991, Signal Processing: Image Communication, V3, P23, DOI 10.1016/0923-5965(91)90028-Z
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   HERRMANN S, IEEE T CIRCUITS SYST, V9, P1204
   Hotter M., 1990, Signal Processing: Image Communication, V2, P409, DOI 10.1016/0923-5965(90)90027-F
   *ISO IEC, 1998, 144962 ISOIEC
   Koenen R, 1997, SIGNAL PROCESS-IMAGE, V9, P295, DOI 10.1016/S0923-5965(97)00003-9
   KUO CM, INT C IM PROC ICIP 9, V2, P639
   MEIER T, IEEE T CIRCUITS SYST, V8, P523
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   *MPEG VID GROUP, 2001, N3908 MPEG VID GROUP
   *MPEG VID GROUP, 2001, N3675 MPEG VID GROUP
   MUSMANN HG, SIGNAL PROCESS IMAGE, V1, P117
   Paragios N, 1999, SIGNAL PROCESS-IMAGE, V14, P277, DOI 10.1016/S0923-5965(98)00011-3
   PARK JW, P ICIP 96, V2, P501
   Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153
   SALEMBIER P, 1995, P IEEE, V83, P843, DOI 10.1109/5.387088
   SALEMBIR P, IEEE T IMAGE PROCESS, V5, P881
   VINCENT L, IEEE T PATTERN ANAL, V113, P583
   WANG JYA, SPIE P IMAGE VIDEO P, V2, P2182
   Won CS, 1998, IEEE T CIRC SYST VID, V8, P592, DOI 10.1109/76.718506
   WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C
   WON CS, OPT ENG, V35, P2204
NR 29
TC 6
Z9 8
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2005
VL 16
IS 1
BP 68
EP 92
DI 10.1016/j.jvcir.2004.01.004
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 885SN
UT WOS:000226177300005
DA 2024-07-18
ER

PT J
AU Lei, B
   Li, JM
   Wang, NN
   Yu, HY
AF Lei, Bo
   Li, Jinming
   Wang, Ningning
   Yu, Haiyan
TI An efficient adaptive Masi entropy multilevel thresholding algorithm
   based on dynamic programming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Multilevel thresholding; Masi entropy; Dynamic
   programming
ID IMAGE; OPTIMIZATION
AB Masi entropy multilevel thresholding can utilize additive and non-extensive information in images to effectively segment a complex image. However, the entropy index of Masi entropy cannot be selected automatically, and the time complexity of the multilevel algorithm by exhaustive searching grows exponentially with the increase of the threshold numbers. To address these two problems, an adaptive entropy index selection strategy based on image histogram information is proposed first. To improve the computation efficiency, an efficient solution for the adaptive Masi entropy multilevel thresholding algorithm based on dynamic programming (DP + AMasi) is also proposed. The DP + AMasi algorithm is compared with the Masi entropy multilevel thresholding algorithm by exhaustive search and state-of-the-art metaheuristic algorithms on three benchmark datasets. The effectiveness of the DP + AMasi is verified by fitness function values, Uniformity Measure, Davies Bouldin index, and CPU run time. In addition, the Wilcoxon test is used to analyze the differences between algorithms.
C1 [Lei, Bo; Li, Jinming; Wang, Ningning; Yu, Haiyan] Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Peoples R China.
   [Lei, Bo; Wang, Ningning; Yu, Haiyan] Xian Univ Posts & Telecommun, Ctr Image & Informat Proc, Xian 710121, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications
RP Li, JM (corresponding author), Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Peoples R China.
EM leileibo@xupt.edu.cn; lijm556@stu.xupt.edu.cn;
   2101200030@stu.xupt.edu.com; yuhaiyan2010@126.com
RI Yu, Haiyan/K-2644-2014; 李, 金明/GWZ-6274-2022; Wang,
   Ningning/ABB-1378-2021
OI 李, 金明/0000-0003-0708-6743; 
FU Natural Science Basic Research Plan in Shaanxi Province of China
   [2022JM-370]; National Natural Science Foundation of China [62071378,
   62071379, 62071380, 62106196]; New Star Team of Xi 'an University of
   Posts and Telecommunications, China [xyt2016-01]
FX This work is supported by the Natural Science Basic Research Plan in
   Shaanxi Province of China (No. 2022JM-370) , the National Natural
   Science Foundation of China (No. 62071378, 62071379, 62071380, 62106196)
   , and 'New Star Team of Xi 'an University of Posts and
   Telecommunications, China', No. xyt2016-01.
CR Abdel-Basset M, 2022, ARTIF INTELL REV, V55, P6389, DOI 10.1007/s10462-022-10157-w
   Akay R, 2022, NEURAL COMPUT APPL, V34, P1161, DOI 10.1007/s00521-021-06437-1
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bhargavi K., 2014, INT J INNOV RES DEV, V3, P234
   Cocosco C.A., 1997, NeuroImage
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dong W., 2022, Math. Probl. Eng., V2022, P1
   Houssein EH, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103401
   Huo FC, 2022, MULTIMED TOOLS APPL, V81, P2189, DOI 10.1007/s11042-021-11644-y
   Jun W., 2022, Int. J. Adv. Comput. Sci. Appl., V13
   Kandhway P, 2019, CIRC SYST SIGNAL PR, V38, P3058, DOI 10.1007/s00034-018-0993-3
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khairuzzaman AKM, 2019, MULTIMED TOOLS APPL, V78, P33573, DOI 10.1007/s11042-019-08117-8
   Khehra Baljit Singh, 2022, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), P1619, DOI 10.1007/s40031-022-00740-8
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Li HB, 2020, IEEE ACCESS, V8, P213130, DOI 10.1109/ACCESS.2020.3040177
   Luessi M, 2006, IEEE IMAGE PROC, P773, DOI 10.1109/ICIP.2006.312426
   Luessi M, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3073891
   Ma GY, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104960
   Ma ZQ, 2023, SWARM EVOL COMPUT, V77, DOI 10.1016/j.swevo.2023.101248
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Merzban MH, 2019, EXPERT SYST APPL, V116, P299, DOI 10.1016/j.eswa.2018.09.008
   Mousavirad SJ, 2023, KNOWL-BASED SYST, V272, DOI 10.1016/j.knosys.2023.110587
   Mousavirad SJ, 2022, KNOWL-BASED SYST, V245, DOI 10.1016/j.knosys.2022.108610
   Mousavirad SJ, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24010008
   Mousavirad SJ, 2019, APPL SOFT COMPUT, V78, P209, DOI 10.1016/j.asoc.2019.02.009
   Mousavirad SJ, 2017, APPL INTELL, V47, P850, DOI 10.1007/s10489-017-0903-6
   Naik MK, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107955
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patra S, 2014, APPL SOFT COMPUT, V23, P122, DOI 10.1016/j.asoc.2014.06.016
   Ray S, 2022, MULTIMED TOOLS APPL, V81, P4073, DOI 10.1007/s11042-021-11633-1
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Saleh S., 2010, J. Comput., V2, P2151
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Si T, 2023, PATTERN ANAL APPL, V26, P201, DOI 10.1007/s10044-022-01099-8
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115759
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Vijh S, 2023, MULTIMED TOOLS APPL, V82, P4979, DOI 10.1007/s11042-022-12168-9
   Wang ST, 2008, PATTERN RECOGN, V41, P117, DOI 10.1016/j.patcog.2007.03.029
   Wang Yanbo, 2022, 2022 7th International Conference on Intelligent Computing and Signal Processing (ICSP), P516, DOI 10.1109/ICSP54964.2022.9778663
   Wunnava A, 2022, J KING SAUD UNIV-COM, V34, P3011, DOI 10.1016/j.jksuci.2020.05.001
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Zuodong Niu, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022122
NR 50
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104008
DI 10.1016/j.jvcir.2023.104008
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DZ6G4
UT WOS:001135951000001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Shen, YX
   Wang, TT
   Niu, PP
AF Wang, Xiangyang
   Shen, Yixuan
   Wang, Tingting
   Niu, Panpan
TI Blind image watermark decoder in NSST-FPCET domain using Weibull
   Mixtures-HMT
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking; NSST-FPCET magnitudes; Weibull Mixtures-HMT;
   Otsu-Canny edge detection; Maximum likelihood decision
ID DETECTOR
AB Balancing imperceptibility, robustness, and data payload is a key topic in digital watermarking technology. Many contributions point to statistical modeling as an effective solution to this problem. On the basis of this, in this paper, we devise a hybrid domain image watermark decoder based on Weibull mixtures based hidden Markov tree (Weibull Mixtures-HMT) model. In the embedding phase, Otsu-Canny edge detection method is used to map the positions of high entropy blocks to the target subband obtained by non-subsampled shearlet transform (NSST), and fast polar complex exponential transform (FPCET) is computed in the target blocks to obtain the NSST-FPCET domain. The watermark signals are embedded into NSST-FPCET magnitudes by a linear method. In the extraction phase, NSST-FPCET magnitude coefficients are modeled by Weibull Mixtures-HMT model, which describes the distribution characteristics as well as the dependencies of NSST-FPCET magnitudes. The efficient variance reduced stochastic expectation maximization method is employed for estimating the parameters of Weibull Mixtures-HMT model. A statistical image watermark decoder in NSST-FPCET domain is finally achieved by the maximum likelihood decision. Massive experiments are performed so as to confirm the superiority of the designed scheme in trade-off among the data payload, imperceptibility, and robustness.
C1 [Wang, Xiangyang; Shen, Yixuan; Wang, Tingting; Niu, Panpan] Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian 116029, Peoples R China.
   [Wang, Xiangyang; Niu, Panpan] Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian 116029, Liaoning, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University
RP Wang, XY; Niu, PP (corresponding author), Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian 116029, Liaoning, Peoples R China.
EM wxy37@126.com; niupanpan3333@163.com
RI Niu, Panpan/Q-9953-2017
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKZZ20220115]; LiaoNing Revitalization Talents Program [XLYC2203032];
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKMZ20221420]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212) , Key Scientific Research
   Project of Liaoning Provincial Education Department (No. LJKZZ20220115)
   , LiaoNing Revitalization Talents Program (No. XLYC2203032) , and
   Scientific Research Project of Liaoning Provincial Education Department
   (No. LJKMZ20221420) .
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akpinar S, 2009, ENERG CONVERS MANAGE, V50, P877, DOI 10.1016/j.enconman.2009.01.007
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Bakhsh FY, 2018, J INF SECUR APPL, V41, P12, DOI 10.1016/j.jisa.2018.05.003
   Begum M., 2021, SN Comput. Sci, V2, P221, DOI [10.1007/s42979-021-00608-6, DOI 10.1007/S42979-021-00608-6]
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Cai LF, 2017, IEEE T NEUR NET LEAR, V28, P122, DOI 10.1109/TNNLS.2015.2505086
   Chen J., 2018, NEURIPS, P7978
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Dai Congying, 2022, 2022 International Conference on Data Analytics, Computing and Artificial Intelligence (ICDACAI), P200, DOI 10.1109/ICDACAI57211.2022.00048
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Ernawan F, 2021, IEEE ACCESS, V9, P45474, DOI 10.1109/ACCESS.2021.3067245
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Fang H, 2021, IEEE T CIRC SYST VID, V31, P1436, DOI 10.1109/TCSVT.2020.3009349
   Fang M, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P109
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Hatami E, 2023, MULTIMED TOOLS APPL, V82, P2021, DOI 10.1007/s11042-022-13197-0
   Hatoum M., 2021, Image Commun., V90
   Jebreel NM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11030999
   Khajouei MA, 2018, IEEE J-STARS, V11, P3918, DOI 10.1109/JSTARS.2018.2868899
   Li CX, 2020, IEEE SIGNAL PROC LET, V27, P346, DOI 10.1109/LSP.2020.2970580
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Pimpalkhute VA, 2021, IEEE T IMAGE PROCESS, V30, P1962, DOI 10.1109/TIP.2021.3049961
   Roy R, 2018, VIS INFORM, V2, P125, DOI 10.1016/j.visinf.2018.03.001
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Shaik A, 2023, MULTIMED TOOLS APPL, V82, P9223, DOI 10.1007/s11042-022-14137-8
   Singh AK, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382772
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang XY, 2022, SIGNAL PROCESS, V192, DOI 10.1016/j.sigpro.2021.108371
   Wang XY, 2021, PATTERN ANAL APPL, V24, P1025, DOI 10.1007/s10044-021-00968-y
   Wang XY, 2019, J VIS COMMUN IMAGE R, V62, P309, DOI 10.1016/j.jvcir.2019.05.012
   Wang XY, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103779
   Xia ZQ, 2023, J FRANKLIN I, V360, P4493, DOI 10.1016/j.jfranklin.2023.02.028
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   You JK, 2022, IEEE T CIRC SYST VID, V32, P483, DOI 10.1109/TCSVT.2021.3065199
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
NR 40
TC 1
Z9 1
U1 5
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103986
DI 10.1016/j.jvcir.2023.103986
EA NOV 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CV1N2
UT WOS:001127920900001
DA 2024-07-18
ER

PT J
AU Xu, HH
   Xu, SC
   Yang, WZ
AF Xu, Haohao
   Xu, Shuchang
   Yang, Wenzhen
TI Unsupervised industrial anomaly detection with diffusion models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomaly detection; Diffusion model; Image reconstruction; Unsupervised
   learning
AB Due to the limitations of autoencoders and generative adversarial networks, the performance of reconstruction -based unsupervised image anomaly detection methods are not satisfactory. In this paper, we aim to explore the potential of a more powerful generative model, the diffusion model, in the anomaly detection problem. Specifically, we design a Reconstructed Diffusion Models (RecDMs) based on conditional denoising diffusion implicit models for image reconstruction. To eliminate the stochastic nature of the generation process, our key idea is to use a learnable encoder to extract meaningful semantic representations, which are then used as signal conditions in an iterative denoising process to guide the model in recovering the image, while avoiding falling into an "identical shortcut" to meaningless image reconstruction. To accurately locate anomaly regions, we introduce a discriminative network to obtain the pixel-level anomaly segmentation map based on the reconstructed image. Our experiments demonstrate the effectiveness of the proposed method, achieving a new state-of-the-art image-level AUC score of 98.1% and a pixel-level AUC score of 94.6% on the MVTec AD dataset, among all reconstruction-based methods. We also show the significant potential and promising future of our method on the challenging real-world dataset, the CHL AD dataset.
C1 [Xu, Haohao; Xu, Shuchang] HangZhou Normal Univ, Sch Informat Sci & Technol, Hangzhou, Peoples R China.
   [Yang, Wenzhen] Zhejiang Lab, Intelligent Percept Res Inst, Hangzhou, Peoples R China.
C3 Hangzhou Normal University; Zhejiang Laboratory
RP Xu, SC (corresponding author), HangZhou Normal Univ, Sch Informat Sci & Technol, Hangzhou, Peoples R China.
EM xusc@hznu.edu.cn; ywz@zhejianglab.edu.cn
RI Yang, Wenzhen/HHY-7607-2022
OI Yang, Wenzhen/0000-0002-0068-1497; Xu, Haohao/0009-0008-2612-1472
FU National Key Research and De-velopment Program of China
   [2021YFF0600203]; Major Scientific Research Project of the Zhejiang
   Laboratory [2022MG0AC04]
FX This paper is supported by the National Key Research and De-velopment
   Program of China (2021YFF0600203) ; the Major Scientific Research
   Project of the Zhejiang Laboratory (2022MG0AC04) .
CR Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   An J., 2015, Special Lecture on IE, V2, P1
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bergmann P, 2019, Arxiv, DOI arXiv:1807.02011
   Bergmann P, 2019, PROC CVPR IEEE, P9584, DOI 10.1109/CVPR.2019.00982
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhariwal P, 2021, ADV NEUR IN, V34
   Hendrycks D, 2019, PR MACH LEARN RES, V97
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Ho JAT, 2022, Arxiv, DOI arXiv:2207.12598
   Huh M, 2016, Arxiv, DOI arXiv:1608.08614
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kadkhodaie Z, 2021, Arxiv, DOI arXiv:2007.13640
   Li CL, 2021, PROC CVPR IEEE, P9659, DOI 10.1109/CVPR46437.2021.00954
   Liang YF, 2023, Arxiv, DOI arXiv:2203.00259
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu XM, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104213
   Perera P, 2019, IEEE T IMAGE PROCESS, V28, P5450, DOI 10.1109/TIP.2019.2917862
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Preechakul K, 2022, PROC CVPR IEEE, P10609, DOI 10.1109/CVPR52688.2022.01036
   Reiss T, 2021, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR46437.2021.00283
   Rippel O, 2021, INT C PATT RECOG, P6726, DOI 10.1109/ICPR48806.2021.9412109
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth K, 2022, PROC CVPR IEEE, P14298, DOI 10.1109/CVPR52688.2022.01392
   Ruff L, 2018, PR MACH LEARN RES, V80
   Saharia C, 2023, IEEE T PATTERN ANAL, V45, P4713, DOI 10.1109/TPAMI.2022.3204461
   Saharia Chitwan, 2022, ACM SIGGRAPH 2022 C, P1
   Salehi M, 2022, Arxiv, DOI arXiv:2008.12959
   Sasaki H., 2021, arXiv
   Schlegl T, 2019, MED IMAGE ANAL, V54, P30, DOI 10.1016/j.media.2019.01.010
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shuchang Xu H.X, 2023, The Crazy Horse Leather (CHL) AD dataset
   Song Jiaming, 2020, INT C LEARNING REPRE
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolleb J, 2022, LECT NOTES COMPUT SC, V13438, P35, DOI 10.1007/978-3-031-16452-1_4
   Wyatt J, 2022, IEEE COMPUT SOC CONF, P649, DOI 10.1109/CVPRW56347.2022.00080
   Xia X., 2021, arXiv
   Yang MH, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2023.105835
   Zavrtanik V, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8310, DOI 10.1109/ICCV48922.2021.00822
   Zhang L, 2023, Arxiv, DOI arXiv:2302.05543
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 45
TC 0
Z9 0
U1 24
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103983
DI 10.1016/j.jvcir.2023.103983
EA NOV 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FZ2W5
UT WOS:001149621800001
DA 2024-07-18
ER

PT J
AU Cao, SH
   Wang, T
   Li, T
   Mao, ZH
AF Cao, Shihai
   Wang, Ting
   Li, Tao
   Mao, Zehui
TI UAV small target detection algorithm based on an improved YOLOv5s model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE UAV; Small target detection; Deep learning; Attention mechanism; YOLOv5
AB The targets of UAV target detection are usually small targets, and the backgrounds are complex. In this work, aiming at the problem that small targets are easy to be missed or misdetected during the UAV detection, an improved YOLOv5s_MSES target detection algorithm based on YOLOv5s is proposed. First of all, to solve the problem of UAV's difficulty in detecting small targets, the detection layer is ameliorated into the small target detection layer STD, which makes the model more easily detect the small targets. Then, the multi-scale feature fusion module is added to improve the detection accuracy of the small targets. Furthermore, by combining multi-scale module and attention module, a new connection method is proposed to retain the large scale of feature information. Finally, in contrast with some existent methods, the experimental results of VisDrone2019 UAV target detection dataset show that our proposed YOLOv5s_MSES can achieve the better detection effect, and more effectively complete the small target detection task for UAV aerial photography images.
C1 [Cao, Shihai; Li, Tao; Mao, Zehui] Nanjing Univ Aeronaut & Astronaut, Sch Automat Engn, Nanjing 211106, Jiangsu, Peoples R China.
   [Wang, Ting] Nanjing Forestry Univ, Sch Informat Sci & Technol, Nanjing 210037, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing Forestry
   University
RP Li, T (corresponding author), Nanjing Univ Aeronaut & Astronaut, Sch Automat Engn, Nanjing 211106, Jiangsu, Peoples R China.
EM autolito@nuaa.edu.cn
FU National Natural Science Foundations of China [62073164, 61922042];
   Project of Key Research & Development Plan of Jiangsu Province, China
   [BE2021016-5]
FX This work was supported by the National Natural Science Foundations of
   China (Nos. 62073164, 61922042) , and the Project of Key Research &
   Development Plan of Jiangsu Province, China (No. BE2021016-5) .
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Castellano G, 2023, NEUROCOMPUTING, V526, P169, DOI 10.1016/j.neucom.2023.01.059
   Cheng QQ, 2022, INT CONF WIRE COMMUN, P122, DOI 10.1109/WCSP55476.2022.10039127
   Dai J, 2022, IEEE PHOTONICS J, V14, DOI 10.1109/JPHOT.2022.3185304
   Dong XD, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104914
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hamzenejadi MH, 2023, EXPERT SYST APPL, V231, DOI 10.1016/j.eswa.2023.120845
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Koyun OC, 2022, SIGNAL PROCESS-IMAGE, V104, DOI 10.1016/j.image.2022.116675
   Li RH, 2023, SIGNAL PROCESS, V208, DOI 10.1016/j.sigpro.2023.108962
   Li SF, 2022, COMPUT ELECTRON AGR, V202, DOI 10.1016/j.compag.2022.107363
   Lin H, 2020, NEUROCOMPUTING, V411, P364, DOI 10.1016/j.neucom.2020.06.011
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu C, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15010083
   Liu QH, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107576
   Liu W, 2022, IEEE J-STARS, V15, P8085, DOI 10.1109/JSTARS.2022.3206399
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mekhalfi ML, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3085139
   Mittal P, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117106
   Niu R, 2021, 2021 2ND INTERNATIONAL CONFERENCE ON BIG DATA & ARTIFICIAL INTELLIGENCE & SOFTWARE ENGINEERING (ICBASE 2021), P25, DOI 10.1109/ICBASE53849.2021.00012
   Qian YX, 2023, J VIS COMMUN IMAGE R, V92, DOI 10.1016/j.jvcir.2023.103797
   Qiao YL, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107579
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren K, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170334
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma VK, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103774
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang H, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3196954
   Wang J, 2019, J VIS COMMUN IMAGE R, V60, P44, DOI 10.1016/j.jvcir.2019.01.017
   Wang M, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2023.103752
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xing LJ, 2022, INT J DISAST RISK RE, V76, DOI 10.1016/j.ijdrr.2022.102972
   Xu C, 2022, LECT NOTES COMPUT SC, V13669, P526, DOI 10.1007/978-3-031-20077-9_31
   Xue YJ, 2021, INFRARED PHYS TECHN, V118, DOI 10.1016/j.infrared.2021.103906
   Yang CHY, 2022, PROC CVPR IEEE, P13658, DOI 10.1109/CVPR52688.2022.01330
   Yang LX, 2021, PR MACH LEARN RES, V139
   Zhan W, 2022, SOFT COMPUT, V26, P361, DOI 10.1007/s00500-021-06407-8
   Zhang KK, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106064
   Zhang Q, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e11570
   Zhao T, 2019, CHIN CONT DECIS CONF, P3342, DOI [10.1109/CCDC.2019.8832517, 10.1109/ccdc.2019.8832517]
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
NR 48
TC 3
Z9 3
U1 128
U2 191
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103936
DI 10.1016/j.jvcir.2023.103936
EA SEP 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U6NA7
UT WOS:001085938900001
DA 2024-07-18
ER

PT J
AU Yang, YJ
   Fu, HY
   Kuo, CCJ
AF Yang, Yijing
   Fu, Hongyu
   Kuo, C. -C. Jay
TI Design of supervision-scalable learning systems: Methodology and
   performance benchmarking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Subspace learning; Weak supervision; Scalable learning systems; Image
   classification
AB The design of robust learning systems that offer stable performance under a wide range of supervision degrees is investigated in this work. We choose the image classification problem as an illustrative example and focus on the design of modularized systems that consist of three learning modules: representation learning, feature learning and decision learning. We discuss ways to adjust each module so that the design is robust with respect to different training sample numbers. Based on these ideas, we propose two families of learning systems. One adopts the classical histogram of oriented gradients (HOG) features while the other uses successive-subspace-learning (SSL) features. We test their performance against LeNet-5, which is an end-to-end optimized neural network, for MNIST and Fashion-MNIST datasets. The number of training samples per image class goes from the extremely weak supervision condition (i.e., 1 labeled sample per class) to the strong supervision condition (i.e., 4096 labeled sample per class) with gradual transition in between (i.e., 2n, n=0,1,MIDLINE HORIZONTAL ELLIPSIS,12). Experimental results show that the two families of modularized learning systems have more robust performance than LeNet-5. They both outperform LeNet-5 by a large margin for small n and have performance comparable with that of LeNet-5 for large n.
C1 [Yang, Yijing; Fu, Hongyu; Kuo, C. -C. Jay] Univ Southern Calif, Los Angeles, CA 90007 USA.
C3 University of Southern California
RP Kuo, CCJ (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM cckuo@sipi.usc.edu
RI yang, yijing/JWO-8234-2024; Kuo, C.-C. Jay/A-7110-2011
CR Angluin D., 1988, Machine Learning, V2, P343, DOI 10.1007/BF00116829
   [Anonymous], 2009, Technical report
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen H.-S., 2021, 2021 IEEE INT C MULT, P1, DOI [DOI 10.1109/ICME51207.2021.9428361, 10.1109/icme51207.2021.9428361]
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chen YB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9042, DOI 10.1109/ICCV48922.2021.00893
   Chen YR, 2020, IEEE IMAGE PROC, P3294, DOI 10.1109/ICIP40778.2020.9191012
   Chen YR, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2019.102749
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fink Michael, 2004, Advances in neural information processing systems, V17
   Foulds J, 2010, KNOWL ENG REV, V25, P1, DOI 10.1017/S026988890999035X
   Frénay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Haussmann E, 2020, IEEE INT VEH SYM, P1430, DOI 10.1109/IV47402.2020.9304793
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kadam P, 2022, IEEE T IMAGE PROCESS, V31, P2710, DOI 10.1109/TIP.2022.3160609
   Kadam P, 2020, IEEE I C VI COM I PR, P5, DOI 10.1109/vcip49819.2020.9301874
   Krizhevsky A., 2009, Tech. Rep.
   Kuo CCJ, 2018, J VIS COMMUN IMAGE R, V50, P237, DOI 10.1016/j.jvcir.2017.11.023
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Kuo CCJ, 2019, J VIS COMMUN IMAGE R, V60, P346, DOI 10.1016/j.jvcir.2019.03.010
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Rouhsedaghat M, 2021, Arxiv, DOI arXiv:2103.00121
   Rouhsedaghat M, 2020, Arxiv, DOI arXiv:2007.09510
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   Wei XS, 2017, IEEE T NEUR NET LEAR, V28, P975, DOI 10.1109/TNNLS.2016.2519102
   Xiao H., 2017, ARXIV170807747
   Yang YJ, 2022, Arxiv, DOI arXiv:2203.11924
   Yang YJ, 2021, ASIAPAC SIGN INFO PR, P1475
   Zhang KT, 2021, Arxiv, DOI arXiv:2105.03797
   Zhang M, 2020, IEEE I C VI COM I PR, P144, DOI 10.1109/vcip49819.2020.9301786
   Zhang M, 2020, IEEE IMAGE PROC, P3319, DOI 10.1109/ICIP40778.2020.9190740
   Zhang M, 2020, IEEE T MULTIMEDIA, V22, P1744, DOI 10.1109/TMM.2019.2963592
   Zhang ZY, 2022, IEEE T KNOWL DATA EN, V34, P5854, DOI 10.1109/TKDE.2021.3061215
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhou ZH, 2010, KNOWL INF SYST, V24, P415, DOI 10.1007/s10115-009-0209-z
   Zhu X., 2009, Synth. Lect. Artif. Intell. Mach. Learn, V3, P1, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]
NR 38
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103925
DI 10.1016/j.jvcir.2023.103925
EA AUG 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y7DI8
UT WOS:001106825600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, HK
   Zhang, LM
   Yu, L
   Yang, HL
   Yin, HB
   Ding, ST
   Xu, HF
   Wang, H
AF Wang, Hongkui
   Zhang, Lianmin
   Yu, Li
   Yang, Hailang
   Yin, Haibing
   Ding, Sitong
   Xu, Haifeng
   Wang, He
TI Learning-based JNCD prediction for quality-wise perceptual quantization
   in HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Just noticeable coding distortion (JNCD); prediction; Perceptual
   quantization; Video coding
ID JND ESTIMATION; VIDEO; MODEL; CODER
AB In visual perception, human only perceive discrete-scale quality levels over a wide range of coding bitrate. More clearly, the videos compressed with a series of quantization parameters (QPs) only have limited perceived quality levels. In this paper, perceptual quantization is transformed into the problem of how to determine the just perceived QP for each quality level, and a just noticeable coding distortion (JNCD) based perceptual quantization scheme is proposed. Specifically, multiple visual masking effects are analyzed and a linear regression (LR) based JNCD model is proposed to predict JNCD thresholds for all quality levels at first. According to the JNCD prediction model, the frame-level perceptual QPs for all quality levels are then derived on the premise of that coding distortions are infinitely close to the predicted JNCD thresholds. Based on the predicted frame-level perceptual QPs, the perceived QPs of all quality levels for each coding unit (CU) are finally determined according to a perceptual modulation function. Experimental results show that the proposed quality-wise perceptual quantization scheme is superior to the existing perceptual video coding algorithms significantly, i.e., the proposed perceptual quantization could save more bitrate with better quality.
C1 [Wang, Hongkui; Zhang, Lianmin; Yin, Haibing; Ding, Sitong; Xu, Haifeng; Wang, He] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
   [Wang, Hongkui; Zhang, Lianmin; Yin, Haibing; Ding, Sitong; Xu, Haifeng; Wang, He] Hangzhou Dianzi Univ, Lishui Inst, Lishui 323010, Peoples R China.
   [Yu, Li; Yang, Hailang] Huazhong Univ Sci & Technol, Coll Elect Informat & Commun, Wuhan 430074, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; Huazhong
   University of Science & Technology
RP Yin, HB (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
EM wanghk@hdu.edu.cn; zlm18790473779@163.com; hustlyu@hust.edu.cn;
   hailangyang@hust.edu.cn; yhb@hdu.edu.cn; 19081710@hdu.edu.cn;
   xuhaifeng@hdu.edu.cn; w_h@hdu.edu.cn
FU Pioneer"and "Leading Goose"Ramp;D Program of Zhejiang Province
   [2022C01068, 2023C01149]; NSFC [62202134, 61871437, 61972123]; Zhejiang
   Provincial Natural Science Foundation of China [LDT23F01011F01]
FX This work was supported in part by the Pioneer"and "Leading Goose"R &
   amp;D Program of Zhejiang Province under Grant No. 2022C01068, No.
   2023C01149; in part by the NSFC under Grant No. 62202134, No. 61871437,
   No. 61972123; in part by the Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LDT23F01011F01.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2002, BT.500-11,
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P3343, DOI 10.1109/TIP.2016.2568459
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P3227, DOI 10.1109/TIP.2014.2327808
   Bjontegaard G., 2001, Document VCEG-M33
   Bross B., 2018, Document JVET-K1001
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Cui J, 2019, IEEE DATA COMPR CONF, P565, DOI 10.1109/DCC.2019.00077
   Cui J, 2017, IEEE T IMAGE PROCESS, V26, P3802, DOI 10.1109/TIP.2017.2703112
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215
   Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7
   Hu RZ, 2023, IEEE T CYBERNETICS, V53, P3651, DOI 10.1109/TCYB.2021.3128023
   Hu RZ, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102045
   Jiang QP, 2022, Arxiv, DOI arXiv:2108.05058
   Kamaci N, 2005, IEEE T CIRC SYST VID, V15, P994, DOI 10.1109/TCSVT.2005.852400
   Ki S, 2018, IEEE T IMAGE PROCESS, V27, P3178, DOI 10.1109/TIP.2018.2818439
   Kim J, 2015, IEEE T CIRC SYST VID, V25, P1786, DOI 10.1109/TCSVT.2015.2389491
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Lee B, 2011, IEEE SIGNAL PROC LET, V18, P571, DOI 10.1109/LSP.2011.2163935
   Li X, 2009, IEEE T CIRC SYST VID, V19, P193, DOI 10.1109/TCSVT.2008.2009255
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Lin JY, 2015, PROC SPIE, V9599, DOI 10.1117/12.2188389
   Liu HH, 2020, IEEE T IMAGE PROCESS, V29, P641, DOI 10.1109/TIP.2019.2933743
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Ma L, 2011, SIGNAL PROCESS-IMAGE, V26, P162, DOI 10.1016/j.image.2011.02.002
   Naccari M, 2011, IEEE T CIRC SYST VID, V21, P766, DOI 10.1109/TCSVT.2011.2130430
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tian T, 2020, IEEE T BROADCAST, V66, P690, DOI 10.1109/TBC.2020.2977542
   Wallisch P, 2008, NEURON, V60, P195, DOI 10.1016/j.neuron.2008.10.008
   Wang H., 2021, DATA COMPRESSION C
   Wang HG, 2016, IEEE IMAGE PROC, P1509, DOI 10.1109/ICIP.2016.7532610
   Wang HK, 2021, IEEE T IMAGE PROCESS, V30, P487, DOI 10.1109/TIP.2020.3037525
   Wang HK, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102850
   Wang HK, 2020, IEEE SIGNAL PROC LET, V27, P181, DOI 10.1109/LSP.2019.2957647
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Wu YX, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102103
   Yang EH, 2014, IEEE T IMAGE PROCESS, V23, P1303, DOI 10.1109/TIP.2014.2300818
   Yang HL, 2020, IEEE DATA COMPR CONF, P404, DOI 10.1109/DCC47342.2020.00071
   Yang KF, 2015, SIGNAL PROCESS-IMAGE, V31, P10, DOI 10.1016/j.image.2014.11.005
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yin H., 2023, FEEDFORWARD FEEDBACK, V19, P1551
   Zhang L, 2011, IEEE T BROADCAST, V57, P572, DOI 10.1109/TBC.2011.2131491
   Zhang Y., 2021, IEEE T CIRC SYST VID, P1
NR 50
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103877
DI 10.1016/j.jvcir.2023.103877
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N7IU3
UT WOS:001038711900001
DA 2024-07-18
ER

PT J
AU Shao, YH
   Zhang, X
   Liao, KS
   Chu, HY
AF Shao, Yanhua
   Zhang, Xiao
   Liao, Kuisheng
   Chu, Hongyu
TI Real-time and robust visual tracking with scene-perceptual memory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Correlation filter; Scene-perceptual memory; Unmanned
   aerial vehicle; Aerial object tracking
ID CORRELATION FILTERS
AB Unmanned aerial vehicle (UAV) based aerial visual tracking is one of the research hotspots in computer vision. However, the mainstream trackers for UAV still have two shortcomings: (1) the accuracy of correlation filter tracker is greatly improved with more complex model, it impedes accuracy-speed trade-off. (2) object occlusion and camera motion in the aerial tracking scene also seriously restrict the application of aerial tracking. To address these problems, and inspired by AutoTrack tracker, we propose an aerial correlation filtering tracker based on scene-perceptual memory, Fast-AutoTrack. Firstly, to perceive and judge tracking anomalies, such as object occlusion and camera motion, inspired by the peak sidelobe ratio and AutoTrack, a confidence score is designed by perceiving and remembering the changing trend of the confidence and the local historical confidence. Secondly, after tracking anomaly occurring, several search regions are predicted based on the local object motion trend and the Spatio-temporal context information for object re-detection. Finally, to accelerate the model updating, the perceptual hashing algorithm (PHA) is used to obtain the similarity of the search regions between two adjacent frames. On typical aerial tracking datasets UAVDT, UAV123@10fps, and DTB70, Fast-AutoTrack run 71.4% faster than AutoTrack with almost equal accuracy and show favorable accuracy-speed trade-off.
C1 [Shao, Yanhua; Zhang, Xiao; Liao, Kuisheng; Chu, Hongyu] Southwest Univ Sci & Technol, Sch Informat Engn, Mianyang 621010, Peoples R China.
C3 Southwest University of Science & Technology - China
RP Shao, YH (corresponding author), Southwest Univ Sci & Technol, Sch Informat Engn, Mianyang 621010, Peoples R China.
EM syh@cqu.edu.cn
OI shao, yanhua/0000-0001-9454-7442
FU National Natural Science Founda-tion of China [61601382]
FX This work was supported by the National Natural Science Founda-tion of
   China (NSFC No. 61601382) .
CR Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fu C., 2022, arXiv, DOI DOI 10.1007/S10462-023-10558-5
   Fu CH, 2019, IEEE INT C INT ROBOT, P4415, DOI [10.1109/iros40897.2019.8967674, 10.1109/IROS40897.2019.8967674]
   Fu CH, 2022, IEEE GEOSC REM SEN M, V10, P125, DOI 10.1109/MGRS.2021.3072992
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Guo DQ, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103484
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Jing YC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5281, DOI 10.1109/ICCV48922.2021.00525
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li F, 2017, IEEE INT CONF COMP V, P2001, DOI 10.1109/ICCVW.2017.234
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li YM, 2020, IEEE INT CONF ROBOT, P193, DOI 10.1109/icra40945.2020.9196943
   Liao JW, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103422
   Liu YY, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103505
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Wang C, 2018, AAAI CONF ARTIF INTE, P4179
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wang XC, 2014, LECT NOTES COMPUT SC, V8689, P17, DOI 10.1007/978-3-319-10590-1_2
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu JH, 2019, J VIS COMMUN IMAGE R, V62, P182, DOI 10.1016/j.jvcir.2019.05.014
   Yan B, 2021, PROC CVPR IEEE, P15175, DOI 10.1109/CVPR46437.2021.01493
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang XY, 2022, Arxiv, DOI arXiv:2210.17409
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Yiding, 2020, ADV NEURAL INF PROCE, V33, P20286
   Ye JW, 2022, LECT NOTES COMPUT SC, V13671, P87, DOI 10.1007/978-3-031-20083-0_6
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
NR 47
TC 0
Z9 0
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103825
DI 10.1016/j.jvcir.2023.103825
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H7ZR5
UT WOS:000998104100001
DA 2024-07-18
ER

PT J
AU Li, WS
   Zhu, JY
AF Li, Weisheng
   Zhu, Junye
TI Siamese visual tracking with multilayer feature fusion and corner
   distance IoU loss
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual Tracking Siamese network; Multilayer feature fusion; Intersection
   over union (IoU) loss
ID ONLINE OBJECT TRACKING; NETWORKS
AB The tracker based on the Siamese network regards tracking tasks as solving a similarity problem between the target template and search area. Using shallow networks and offline training, these trackers perform well in simple scenarios. However, due to the lack of semantic information, they have difficulty meeting the accuracy requirements of the task when faced with complex backgrounds and other challenging scenarios. In response to this problem, we propose a new model, which uses the improved ResNet-22 network to extract deep features with more semantic information. Multilayer feature fusion is used to obtain a high-quality score map to reduce the influence of interference factors in the complex background on the tracker. In addition, we propose a more powerful Corner Distance IoU (intersection over union) loss function so that the algorithm can better regression to the bounding box. In the experiments, the tracker was extensively evaluated on the object tracking benchmark data sets, OTB2013 and OTB2015, and the visual object tracking data sets, VOT2016 and VOT2017, and ach-ieved competitive performance, proving the effectiveness of this method.
C1 [Li, Weisheng; Zhu, Junye] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Li, WS (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
EM liws@cqupt.edu.cn
FU National Natural Science Foundation of China; National Key Research and
   Development Program of China; Natural Science Foundation of Chongqing; 
   [61972060];  [U1713213];  [62027827];  [2019YFE0110800]; 
   [cstc2020jcyj-zdxmX0025];  [cstc2019cxcyljrc-td0270]
FX This work was supported by the National Natural Science Foundation of
   China [Nos. 61972060, U1713213 and 62027827] , National Key Research and
   Development Program of China (Nos. 2019YFE0110800) , Natural Science
   Foundation of Chongqing [cstc2020jcyj-zdxmX0025,
   cstc2019cxcyljrc-td0270] .
CR [Anonymous], 2016, ARXIV160207360
   [Anonymous], 2017, End-to-end representation learning for correlation filter based tracking
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Danelljan M., 2016, EFFICIENT CONVOLUTIO
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan Martin, 2014, BRIT MACH VIS C
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong X., 2017, QUADRUPLET NETWORK O
   Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han WC, 2021, PROC CVPR IEEE, P16565, DOI 10.1109/CVPR46437.2021.01630
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Heikkilä J, 2004, IMAGE VISION COMPUT, V22, P563, DOI 10.1016/j.imavis.2003.09.010
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jung I, 2020, AAAI CONF ARTIF INTE, V34, P11205
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lautissier J, 2003, P ANN INT IEEE EMBS, V25, P739, DOI 10.1109/IEMBS.2003.1279870
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shen JB, 2022, IEEE T PATTERN ANAL, V44, P8896, DOI 10.1109/TPAMI.2021.3127492
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Wang N, 2013, P ADV NEURAL INFORM
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xingping Dong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P378, DOI 10.1007/978-3-030-58565-5_23
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang P, 2017, NEUROCOMPUTING, V257, P115, DOI 10.1016/j.neucom.2016.10.073
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zheng LY, 2019, IEEE I CONF COMP VIS, P4019, DOI 10.1109/ICCV.2019.00412
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 58
TC 2
Z9 2
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103687
DI 10.1016/j.jvcir.2022.103687
EA NOV 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600004
DA 2024-07-18
ER

PT J
AU Hu, YS
   Yin, DC
   Wang, YW
   Chen, ZZ
   Luo, C
AF Hu, Yaosi
   Yin, Dacheng
   Wang, Yuwang
   Chen, Zhenzhong
   Luo, Chong
TI Decomposing style, content, and motion for videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video decomposition; Video synthesis; Self-supervised learning
AB In this paper, we present the first video decomposition framework, named SyCoMo, that factorizes a video into style, content, and motion. Such a fine-grained decomposition enables flexible video editing, and for the first time allows for tripartite video synthesis. SyCoMo is a unified and domain-agnostic learning framework which can process videos of various object categories without domain-specific design or supervision. Different from other motion decomposition work, SyCoMo derives motion from style-free content by isolating style from content in the first place. Content is organized into subchannels, each of which corresponds to an atomic motion. This design naturally forms an information bottleneck which facilitates a clean decomposition. Experiments show that SyCoMo decomposes videos of various categories into interpretable content subchannels and meaningful motion patterns. Ablation studies also show that deriving motion from style-free content makes the keypoints or landmarks of the object more accurate. We demonstrate the photorealistic quality of the novel tripartite video synthesis in addition to three bipartite synthesis tasks named as style, content, and motion transfer.
C1 [Hu, Yaosi; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
   [Yin, Dacheng] Univ Sci & Technol China, Hefei 230026, Anhui, Peoples R China.
   [Wang, Yuwang; Luo, Chong] Microsoft Res Asia, Beijing 100102, Peoples R China.
C3 Wuhan University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS; Microsoft Research Asia; Microsoft
RP Hu, YS (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM ys_hu@whu.edu.cn
RI Yin, Dacheng/GXG-5760-2022; Hu, Yaosi/GRY-6324-2022; Chen,
   Zhenzhong/C-2529-2015
OI Hu, Yaosi/0000-0003-2784-6738; 
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Baevski A., 2020, INT C LEARNING REPRE
   Baevski Alexei, 2020, Advances in neural information processing systems
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cao Z., 2017, P IEEE C COMP VIS PA, P7291
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Denton Emily, 2017, P ADV NEUR INF PROC, P4417
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Engstrom L., 2016, Fast style transfer
   Eslami SMA, 2016, 30 C NEURAL INFORM P, V29
   Gao QZ, 2021, PR MACH LEARN RES, V139
   Geng ZL, 2019, PROC CVPR IEEE, P9813, DOI 10.1109/CVPR.2019.01005
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hsieh JT, 2018, ADV NEUR IN, V31
   Hu T, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102812
   Jian Ren, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P262, DOI 10.1007/978-3-030-67070-2_16
   Kabra R, 2021, Advances in Neural Information Processing Systems, V34
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kotovenko D, 2019, IEEE I CONF COMP VIS, P4421, DOI 10.1109/ICCV.2019.00452
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Lin SY, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103572
   Liu L, 2021, AAAI CONF ARTIF INTE, V35, P2145
   Liu W, 2019, IEEE I CONF COMP VIS, P5903, DOI 10.1109/ICCV.2019.00600
   Lorenz D, 2019, PROC CVPR IEEE, P10947, DOI 10.1109/CVPR.2019.01121
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   Mokady R, 2021, Arxiv, DOI arXiv:2106.09679
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Ren J, 2021, PROC CVPR IEEE, P10790, DOI 10.1109/CVPR46437.2021.01065
   Ren XC, 2021, IEEE INT CONF COMP V, P1823, DOI 10.1109/ICCVW54120.2021.00209
   Sengar SS, 2017, J VIS COMMUN IMAGE R, V49, P89, DOI 10.1016/j.jvcir.2017.08.007
   Siarohin A, 2019, ADV NEUR IN, V32
   Siarohin A, 2021, PROC CVPR IEEE, P13648, DOI 10.1109/CVPR46437.2021.01344
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Van Steenkiste Sjoerd, 2018, INT C LEARN REPR
   Villegas Ruben, 2017, ICLR
   Wang YH, 2020, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR42600.2020.00531
   Wiles O., 2018, P ECCV, P670
   Wu W., 2019, INT C LEARNING REPRE
   Xie JW, 2020, AAAI CONF ARTIF INTE, V34, P12442
   Xiong W, 2018, PROC CVPR IEEE, P2364, DOI 10.1109/CVPR.2018.00251
   Ye WJ, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103378
   Yin D., 2022, INT C LEARNING REPRE
   Zablotskaia P., 2019, 30 BRIT MACHINE VISI, P51
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang HK, 2019, IEEE I CONF COMP VIS, P1725, DOI 10.1109/ICCV.2019.00181
NR 51
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103686
DI 10.1016/j.jvcir.2022.103686
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600010
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Liang, Q
   Ma, RX
   Nie, WZ
   Su, YT
AF Zhao, Yue
   Liang, Qi
   Ma, Ruixin
   Nie, Weizhi
   Su, Yuting
TI JFLN: Joint Feature Learning Network for 2D sketch based 3D shape
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sketch-based 3D shape retrieval; Attention mechanism; Cross-modal
   retrieval
AB Cross-modal retrieval attracts much research attention due to its wide applications in numerous search systems. Sketch based 3D shape retrieval is a typical challenging cross-modal retrieval task for the huge divergence between sketch modality and 3D shape view modality. Existing approaches project the sketches and shapes into a common space for feature update and data alignment. However, these methods contain several disadvantages: Firstly, the majority approaches ignore the modality-shared information for divergence compensation in descriptor generation process. Secondly, traditional fusion method of multi-view features introduces much redundancy, which decreases the discrimination of shape descriptors. Finally, most approaches only focus on the cross-modal alignment, which omits the modality-specific data relevance. To address these limitations, we propose a Joint Feature Learning Network (JFLN). Firstly, we design a novel modality-shared feature extraction network to exploit both modality-specific characteristics and modality-shared information for descriptor generation. Subsequently, we introduce a hierarchical view attention module to gradually focus on the effective information for multiview feature updating and aggregation. Finally, we propose a novel cross-modal feature learning network, which can simultaneously contribute to modality-specific data distribution and cross-modal data alignment. We conduct exhaustive experiments on three public databases. The experimental results validate the superiority of the proposed method. Full Codes are available at https: //github.com/dlmuyy/JFLN.
C1 [Zhao, Yue; Nie, Weizhi; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Liang, Qi] Tianjin Nav Instrument Res Inst, Tianjin 300131, Peoples R China.
   [Ma, Ruixin] Dalian Maritime Univ, Key Lab Marine Simulat & Control, Dalian 116026, Peoples R China.
   [Ma, Ruixin] MOT, Tianjin Res Inst Water Transport Engn, Tianjin 300456, Peoples R China.
C3 Tianjin University; Dalian Maritime University; Tianjin Research
   Institute for Water Transport Engineering
RP Nie, WZ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM weizhinie@tju.edu.cn
OI nie, weizhi/0000-0002-0578-8138
FU National Key Research and Development Program of China; Na-tional
   Natural Science Foundation of China; Tianjin Research Innova-tion
   Project for Postgraduate Student; Tianjin Municipal Education
   Commission;  [2020YFB1711704];  [61872267];  [61702471];  [61772359]; 
   [2021YJSB154]
FX Acknowledgments This work was supported in part by the National Key
   Research and Development Program of China (2020YFB1711704) , and the
   Na-tional Natural Science Foundation of China (61872267, 61702471,
   61772359) . This work was supported by the Tianjin Research Innova-tion
   Project for Postgraduate Student (Project Number: 2021YJSB154) , Tianjin
   Municipal Education Commission.
CR [Anonymous], 2013, SHREC' 13 track: large scale sketchbased 3D shape retrieval
   [Anonymous], 2018, P EUR C COMP VIS
   Bai J, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040369
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen JX, 2019, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2019.00088
   Chen KX, 2020, IEEE T NEUR NET LEAR, V31, P1747, DOI 10.1109/TNNLS.2019.2927224
   Cheng MM, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3389547
   Cheraghian A, 2019, IEEE WINT CONF APPL, P1194, DOI 10.1109/WACV.2019.00132
   Dai GX, 2018, IEEE T IMAGE PROCESS, V27, P3374, DOI 10.1109/TIP.2018.2817042
   Deng J., 2009, IEEE C COMP VIS PATT
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Furuya T, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P274, DOI 10.1109/CW.2013.60
   Gao Y, 2022, IEEE T PATTERN ANAL, V44, P2548, DOI 10.1109/TPAMI.2020.3039374
   Gong B, 2020, IEEE T IMAGE PROCESS, V29, P8381, DOI 10.1109/TIP.2020.3013138
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   Han ZZ, 2019, IEEE T CYBERNETICS, V49, P481, DOI 10.1109/TCYB.2017.2778764
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang CK, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102165
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lei YJ, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106981
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li Bo, 2014, EUROGRAPHICS WORKSHO
   Li Bo., 2012, Proceedings of EuroGraphics 3DOR, P119, DOI 10.2312/3DOR/3DOR12/119-126
   Li WQ, 2020, ENERGY TECHNOL-GER, V8, DOI 10.1002/ente.201900871
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Liu ZJ, 2019, ADV NEUR IN, V32
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Ma C, 2019, IEEE T MULTIMEDIA, V21, P1169, DOI 10.1109/TMM.2018.2875512
   Naffouti SE, 2017, SIGNAL PROCESS-IMAGE, V58, P228, DOI 10.1016/j.image.2017.07.005
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Saavedra J.M., 2012, 3DOR, P47
   Savva M., 2016, P EUR WORKSH 3D OBJ, P89, DOI DOI 10.2312/3DOR.20161092
   Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Tatsuma A., 2012, Signal Information Processing Association Annual Summit and Conference (APSIPA ASC), 2012 Asia-Pacific, P1
   Wang C, 2019, NEUROCOMPUTING, V323, P139, DOI 10.1016/j.neucom.2018.09.075
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie J, 2017, PROC CVPR IEEE, P3615, DOI 10.1109/CVPR.2017.385
   Xu YZ, 2020, IEEE T MULTIMEDIA, V22, P2950, DOI 10.1109/TMM.2020.2966882
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zeng H, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102136
   Zhang DL, 2020, IEEE T CYBERNETICS, V50, P3033, DOI 10.1109/TCYB.2019.2905157
   Zhang YF, 2023, IEEE T PATTERN ANAL, V45, P2613, DOI 10.1109/TPAMI.2022.3163709
   Zhu L., 2021, ACM T INF SYST TOIS, V40, P1
NR 53
TC 3
Z9 3
U1 2
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103668
DI 10.1016/j.jvcir.2022.103668
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600006
DA 2024-07-18
ER

PT J
AU Yang, YK
   Wang, AH
   Bu, DH
   Feng, ZW
   Liang, J
AF Yang, Yakun
   Wang, Anhong
   Bu, Donghan
   Feng, Zewen
   Liang, Jie
TI AS-Net: An attention-aware downsampling network for point clouds
   oriented to classification tasks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Point cloud; Downsampling; Attention; Constraint match; Classification
   task
AB 3D point cloud has tremendous potential in many application tasks. However, the huge amount of data limits this potential. To simplify point clouds and improve their downstream application efficiency, this paper proposes AS-Net, an attention-aware downsampling network oriented to classification tasks. AS-Net realizes downsampling through an Attention-aware Sampling Module, which including an Input Embedding Module and an Attention Module. The former is designed to extract the global and local features of the point cloud, the latter is to generate the Sampling-Map to simulate the differentiable downsampling. Thanks to the attention mechanism, AS-Net may select the critical points of the original point cloud for classification tasks. In addition, AS-Net designs a Constraint Matching Module to match the sampled points to be a subset of the original point cloud at the inference phase. For end-to-end training, AS-Net construct a joint loss function that includes a task loss, a sampling loss, and a constraint loss. Extensive experiments on the ModelNet10/40 and ShapeNet datasets demonstrate that AS-Net achieves a good performance on the point cloud classification task. Especially when the downsampling size is small, the result is better than the referenced methods.
C1 [Yang, Yakun; Wang, Anhong; Bu, Donghan; Feng, Zewen] Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
   [Liang, Jie] Simon Fraser Univ, Sch Engn Sci, 8888 Univ Dr, Burnaby, BC, Canada.
C3 Taiyuan University of Science & Technology; Simon Fraser University
RP Wang, AH (corresponding author), Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
EM yyk@tyust.edu.cn; wah_ty@163.com; budonghan@qq.com; bigwon2n@gmail.com;
   jiel@sfu.ca
FU National Natural Science Foundation of China [62072325]; Postgraduate
   Innovation Project of Shanxi, China [2021Y669]; Shanxi S&T Major
   Project, China [20191102010]; Shanxi University S&T Achievements
   Transformation Cultivation Project, China [20191042]; Shanxi S&T
   Achievements Transformation Project [201804D131035]; Shanxi Key Core
   Technology& Common Technology Research and Development Project, China
   [20201102011]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62072325), the Postgraduate Innovation Project of Shanxi,
   China (No. 2021Y669), Shanxi S&T Major Project, China(20191102010),
   Shanxi University S&T Achievements Transformation Cultivation Project,
   China (20191042), Shanxi S&T Achievements Transformation Project
   (201804D131035), Shanxi Key Core Technology& Common Technology Research
   and Development Project, China(20201102011).
CR Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cao C, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338130
   Chaudhari S, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465055
   Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng HW, 2019, PROC CVPR IEEE, P3239, DOI 10.1109/CVPR.2019.00336
   Dovrat O, 2019, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2019.00287
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Guo M., 2021, ABS211107624 CORR
   Guo Meng-Hao, 2020, ABS201209688 CORR
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hinks T, 2013, J SURV ENG, V139, P72, DOI 10.1061/(ASCE)SU.1943-5428.0000097
   Jing YC, 2022, Arxiv, DOI arXiv:2207.11681
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing Yongcheng, 2021, P IEEE CVF INT C COM, P5301
   Katz S, 2013, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2013.23
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Lang Itai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7575, DOI 10.1109/CVPR42600.2020.00760
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li Y., 2018, Adv. Neural Inf. Process. Syst., V31
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Linsen L., 2001, POINT CLOUD REPRESEN
   Liu ZJ, 2019, ADV NEUR IN, V32
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Moenning C., 2003, Technical Report
   Nezhadarya Ehsan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12953, DOI 10.1109/CVPR42600.2020.01297
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Qian Y, 2021, Arxiv, DOI arXiv:2005.00383
   Qingyong Hu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11105, DOI 10.1109/CVPR42600.2020.01112
   Qi CR, 2017, Arxiv, DOI [arXiv:1706.02413, DOI 10.48550/ARXIV.1706.02413]
   Schnabel R., 2006, P S POINT BAS GRAPH, V6, P111, DOI DOI 10.2312/SPBG/SPBG06/111-120
   Sharma R, 2021, Arxiv, DOI arXiv:2102.13391
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xie Haozhe, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P365, DOI 10.1007/978-3-030-58545-7_21
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563
   Yang JC, 2019, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2019.00344
   Yang XY, 2022, Arxiv, DOI arXiv:2207.03337
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Yiding, 2020, ADV NEURAL INF PROCE, V33, P20286
   Ying X, 2013, IEEE T VIS COMPUT GR, V19, P1425, DOI 10.1109/TVCG.2013.63
   Zhang YX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6279, DOI 10.1109/ICASSP.2018.8462291
   Zhang Z., 2020, Virtual Real Intell Hardw, V2, P222, DOI DOI 10.1016/J.VRIH.2020.05.002
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zitian Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7659, DOI 10.1109/CVPR42600.2020.00768
NR 51
TC 3
Z9 3
U1 12
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103639
DI 10.1016/j.jvcir.2022.103639
EA OCT 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300001
DA 2024-07-18
ER

PT J
AU Zhang, TC
   Yang, CJ
   Weng, SW
   Hou, TS
AF Zhang, Tiancong
   Yang, Caijie
   Weng, Shaowei
   Hou, Tanshuai
TI Adaptive multi-histogram reversible data hiding with contrast
   enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; FCM clustering; Multiple histograms; Reversible
   data hiding; F Genetic algorithm
ID SELECTION
AB Unlike existing reversible data hiding with contrast enhancement (RDHCE) methods, which excessively improve the image contrast for achieving the required capacity, the proposed method improves the image contrast appropriately while providing satisfactory embedding capacity. To this end, an adaptive multi-histogram RDHCE method is proposed in this study to improve the local and global contrast by considering the local properties of the histograms. On the one hand, fuzzy C-means clustering combining multiple features that are deliberately designed for contrast enhancement is employed to generate seven sharply-distributed prediction error histograms (PEHs). Subsequently, the genetic algorithm is utilized to adaptively select the optimal pairs achieving the best embedding performance for each PEH according to the local characteristics of PEH distribution, resulting in improving the local contrast adaptively and embedding significant amount of data. Additionally, two-sided histogram shifting (HS) is utilized to improve the global contrast appropriately while embedding reasonable amount of data. The experimental results demonstrate that the proposed method achieves better local and global contrast while providing a high embedding capacity compared with other existing RDHCE methods.
C1 [Zhang, Tiancong; Weng, Shaowei] Fujian Univ Technol, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350108, Peoples R China.
   [Zhang, Tiancong; Weng, Shaowei; Hou, Tanshuai] Fujian Univ Technol, Sch Elect Elect Engn & Phys, Fuzhou 350108, Peoples R China.
   [Yang, Caijie] Fujian Univ Technol, Sch Comp Sci & Math, Fuzhou 350118, Peoples R China.
C3 Fujian University of Technology; Fujian University of Technology; Fujian
   University of Technology
RP Weng, SW (corresponding author), Fujian Univ Technol, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350108, Peoples R China.
EM wswweiwei@126.com
RI tian'cong, zhang/IQU-9892-2023
OI tian'cong, zhang/0000-0002-5343-6233
FU National NSF of China; Fujian Science Fund for Distinguished Young
   Scholars;  [61872095];  [61571139];  [61872128];  [202006043]
FX Acknowledgments This work was supported in part by the National NSF of
   China under Grant 61872095, Grant 61571139, Grant 61872128, in part by
   Fujian Science Fund for Distinguished Young Scholars under Grant
   202006043.
CR [Anonymous], 2004, Uncompressed colour image database
   [Anonymous], 1997, USC SIPI IMAGE DATAB
   [Anonymous], 1992, R. woods digital image processing
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Chen HS, 2016, SIGNAL PROCESS-IMAGE, V46, P1, DOI 10.1016/j.image.2016.04.006
   Gao M.-Z., 2013, Adv. Intell. Syst. Appl., V2, P331, DOI [10.1007/978-3-642-35473-133, DOI 10.1007/978-3-642-35473-133]
   Gordon R., 2015, APPL OPTICS, V23, P56
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jafar IF, 2016, J VIS COMMUN IMAGE R, V39, P239, DOI 10.1016/j.jvcir.2016.06.002
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P2271, DOI 10.1109/TCSVT.2018.2869935
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Mansouri S, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103359
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2020, IEEE T CIRC SYST VID, V30, P2329, DOI 10.1109/TCSVT.2019.2921812
   Qi WF, 2020, IEEE T CIRC SYST VID, V30, P2300, DOI 10.1109/TCSVT.2019.2942489
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Weng SW, 2021, INFORM SCIENCES, V549, P13, DOI 10.1016/j.ins.2020.10.063
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Zhao L, 1999, PATTERN RECOGN, V32, P547, DOI 10.1016/S0031-3203(98)00119-8
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 29
TC 2
Z9 2
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103637
DI 10.1016/j.jvcir.2022.103637
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5K3LX
UT WOS:000869631900004
DA 2024-07-18
ER

PT J
AU Fu, T
   Chen, LQ
   Fu, ZJ
   Yu, KL
   Wang, Y
AF Fu, Tong
   Chen, Liquan
   Fu, Zhangjie
   Yu, Kunliang
   Wang, Yu
TI CCNet: CNN model with channel attention and convolutional pooling
   mechanism for spatial image steganalysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganalysis; Convolutional neural network; Channel attention;
   Convolutional pooling
ID STEGANOGRAPHY
AB Image steganalysis based on convolutional neural networks(CNN) has attracted great attention. However, existing networks lack attention to regional features with complex texture, which makes the ability of discrimination learning miss in network. In this paper, we described a new CNN designed to focus on useful features and improve detection accuracy for spatial-domain steganalysis. The proposed model consists of three modules: noise extraction module, noise analysis module and classification module. A channel attention mechanism is used in the noise extraction module and analysis module, which is realized by embedding the SE(Squeeze-and-Excitation) module into the residual block. Then, we use convolutional pooling instead of average pooling to aggregate features. The experimental results show that detection accuracy of the proposed model is significantly better than those of the existing models such as SRNet, Zhu-Net and GBRAS-Net. Compared with these models, our model has better generalization ability, which is critical for practical application.
C1 [Fu, Tong; Chen, Liquan; Yu, Kunliang; Wang, Yu] Southeast Univ, Sch Cyber Sci & Engn, Nanjing 211189, Peoples R China.
   [Fu, Zhangjie] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Southeast University - China; Nanjing University of Information Science
   & Technology
RP Chen, LQ (corresponding author), Southeast Univ, Sch Cyber Sci & Engn, Nanjing 211189, Peoples R China.
EM Lqchen@seu.edu.cn
OI Fu, Tong/0000-0001-6292-8881
FU National Key Research and Development Program of China [2020YFE0200600];
   Na-tional Natural Science Foundation of China [61571110]
FX Acknowledgments This research was supported by the National Key Research
   and Development Program of China (grant no. 2020YFE0200600) , the
   Na-tional Natural Science Foundation of China (grant no. 61571110)
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2008, BOWS 2
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen X, 2020, COMPUT MATH METHOD M, V2020, P1
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussain I, 2020, KSII T INTERNET INF, V14, P1228, DOI 10.3837/tiis.2020.03.017
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Reinel TS, 2021, IEEE ACCESS, V9, P14340, DOI 10.1109/ACCESS.2021.3052494
   Singhal A, 2021, MULTIMED TOOLS APPL, V80, P13931, DOI 10.1007/s11042-020-10353-2
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Wu ST, 2020, IEEE T MULTIMEDIA, V22, P256, DOI 10.1109/TMM.2019.2920605
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang HW, 2021, IEEE T NETW SCI ENG, V8, P1084, DOI 10.1109/TNSE.2020.2996612
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Yu KL, 2020, IET IMAGE PROCESS, V14, P4229, DOI 10.1049/iet-ipr.2020.1105
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zou Y, 2019, J VIS COMMUN IMAGE R, V60, P266, DOI 10.1016/j.jvcir.2019.02.034
NR 35
TC 13
Z9 13
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103633
DI 10.1016/j.jvcir.2022.103633
EA SEP 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800001
DA 2024-07-18
ER

PT J
AU Tan, L
   Li, L
   Liu, WQ
   An, SJ
   Munyard, K
AF Tan, Lu
   Li, Ling
   Liu, Wan-Quan
   An, Sen-Jian
   Munyard, Kylie
TI Unsupervised learning of multi-task deep variational model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised learning; Integration approach; Deep neural networks;
   Variational general frameworks; Diverse applications
ID NEURAL-NETWORK; FAST ALGORITHM; RESTORATION; IMAGES; TV
AB We propose a general deep variational model (reduced version, full version as well as the extension) via a comprehensive fusion approach in this paper. It is able to realize various image tasks in a completely unsupervised way without learning from samples. Technically, it can properly incorporate the CNN based deep image prior (DIP) architecture into the classic variational image processing models. The minimization problem solving strategy is transformed from iteratively minimizing the sub-problem for each variable to automatically minimizing the loss function by learning the generator network parameters. The proposed deep variational (DV) model contributes to the high order image edition and applications such as image restoration, inpainting, decomposition and texture segmentation. Experiments conducted have demonstrated significant advantages of the proposed deep variational model in comparison with several powerful techniques including variational methods and deep learning approaches.
C1 [Tan, Lu] Hong Kong Baptist Univ, Dept Math, Hong Kong, Peoples R China.
   [Li, Ling; An, Sen-Jian] Curtin Univ, Sch Elect Engn Comp & Math Sci, Perth, WA, Australia.
   [Liu, Wan-Quan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen, Peoples R China.
   [Munyard, Kylie] Curtin Univ, Sch Pharm & Biomed Sci, Perth, WA, Australia.
C3 Hong Kong Baptist University; Curtin University; Sun Yat Sen University;
   Curtin University
RP Liu, WQ (corresponding author), Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen, Peoples R China.
EM liuwq63@mail.sysu.edu.cn
RI Zhao, YuHan/KIE-0813-2024; An, Senjian/H-8746-2014; Huang,
   Liping/KIB-4430-2024; zhu, yujie/KBC-4009-2024
OI Munyard, Kylie/0000-0002-5113-8646; Li, Ling/0000-0001-9722-9503
FU National Natural Science Foundation of China [62188101]
FX This work was supported by the National Natural Science Foundation of
   China (62188101).
CR Batard T, 2021, SIAM J IMAGING SCI, V14, P1816, DOI 10.1137/20M1378697
   Belkin Mikhail, 2018, ADV NEURAL INFORM PR, P2300, DOI [DOI 10.5555/3327144.3327157, DOI 10.48550/ARXIV.1806.05161]
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Brinkmann EM, 2019, J MATH IMAGING VIS, V61, P571, DOI 10.1007/s10851-018-0861-6
   Brook A, 2003, J MATH IMAGING VIS, V18, P247, DOI 10.1023/A:1022895410391
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chakravarty A, 2019, IEEE J BIOMED HEALTH, V23, P1151, DOI 10.1109/JBHI.2018.2852635
   Chen X, 2019, PROC CVPR IEEE, P11624, DOI 10.1109/CVPR.2019.01190
   Cheng ZZ, 2019, PROC CVPR IEEE, P5438, DOI 10.1109/CVPR.2019.00559
   Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Duan JM, 2016, DIGIT SIGNAL PROCESS, V49, P162, DOI 10.1016/j.dsp.2015.10.010
   Gandelsman Y, 2019, PROC CVPR IEEE, P11018, DOI 10.1109/CVPR.2019.01128
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Le THN, 2018, IEEE T IMAGE PROCESS, V27, P2393, DOI 10.1109/TIP.2018.2794205
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Kim Y, 2019, IEEE T IMAGE PROCESS, V28, P2692, DOI 10.1109/TIP.2018.2889531
   Lai RJ, 2013, SIAM J SCI COMPUT, V35, pA675, DOI 10.1137/110846634
   Le THN, 2018, LECT NOTES COMPUT SC, V11072, P646, DOI 10.1007/978-3-030-00931-1_74
   Li Y, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00543
   Liu JM, 2019, INT CONF ACOUST SPEE, P7715, DOI 10.1109/ICASSP.2019.8682856
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Mataev G, 2019, CVPR WORKSH
   Meyer Y., 2001, Memoirs of the American Mathematical Society
   Ng MK, 2013, IEEE T IMAGE PROCESS, V22, P2233, DOI 10.1109/TIP.2013.2246520
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Tai XC, 2011, SIAM J IMAGING SCI, V4, P313, DOI 10.1137/100803730
   Tan L, 2020, J MATH IMAGING VIS, V62, P98, DOI 10.1007/s10851-019-00920-0
   Tan L, 2019, MULTIMED TOOLS APPL, V78, P10449, DOI 10.1007/s11042-018-6546-8
   Tan L, 2018, APPL MATH MODEL, V61, P280, DOI 10.1016/j.apm.2018.04.017
   Tan L, 2018, J MATH IMAGING VIS, V60, P1, DOI 10.1007/s10851-017-0735-3
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Vese L.A., 2006, 2006 8 INT S SYMB NU, P103
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhang Chiyuan, 2017, P INT C LEARNING REP
   Zhang HL, 2019, INFORM SCIENCES, V493, P152, DOI 10.1016/j.ins.2019.04.048
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhong Q., 2020, P IEEECVF C COMPUTER, P9474
   Zhu W, 2013, INVERSE PROBL IMAG, V7, P1409, DOI 10.3934/ipi.2013.7.1409
NR 46
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103588
DI 10.1016/j.jvcir.2022.103588
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S1ZS
UT WOS:000839401800002
DA 2024-07-18
ER

PT J
AU Sushma, B
   Aparna, P
AF Sushma, B.
   Aparna, P.
TI Deep chroma prediction of Wyner-Ziv frames in distributed video coding
   of wireless capsule endoscopy video*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributedvideocoding; Chromaprediction; Convolutionalneuralnetworks;
   Videocompression; Wirelesscapsuleendoscopy
ID COLOR-REPRODUCTION; IMAGE COMPRESSOR; IMPLEMENTATION; ALGORITHM; SYSTEM
AB Compression of captured video frames is crucial for saving the power in wireless capsule endoscopy (WCE). A low complexity encoder is desired to limit the power consumption required for compressing the WCE video. Distributed video coding (DVC) technique is best suitable for designing a low complexity encoder. In this technique, frames captured in RGB colour space are converted into YCbCr colour space. Both Y and CbCr representing luma and chroma components of the Wyner-Ziv (WZ) frames are processed and encoded in existing DVC techniques proposed for WCE video compression. In the WCE video, consecutive frames exhibit more similarity in texture and colour properties. The proposed work uses these properties to present a method for processing and encoding only the luma component of a WZ frame. The chroma components of the WZ frame are predicted by an encoder-decoder based deep chroma prediction model at the decoder by matching luma and texture information of the keyframe and WZ frame. The proposed method reduces the computations required for encoding and transmitting of WZ chroma component. The results show that the proposed DVC with a deep chroma prediction model performs better when compared to motion JPEG and existing DVC systems for WCE at the reduced encoder complexity.
C1 [Sushma, B.; Aparna, P.] Natl Inst Technol Karnataka, Mangalore 575025, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Sushma, B (corresponding author), Natl Inst Technol Karnataka, Mangalore 575025, India.
EM sushmabg.177ec012@nitk.edu.in
OI B, Sushma/0000-0002-4581-1128
CR [Anonymous], 2017, KID VIDEOS
   [Anonymous], 2007, PICT COD S
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Belyaev E, 2020, IN 2020 IEEE 22 INT, P1, DOI [10.1109/MMSP48831.2020.9287147, DOI 10.1109/MMSP48831.2020.9287147]
   Blanch MG, 2020, IEEE IMAGE PROC, P783, DOI 10.1109/ICIP40778.2020.9191050
   Boudechiche DE, 2017, J VIS COMMUN IMAGE R, V49, P14, DOI 10.1016/j.jvcir.2017.07.007
   Chen XK, 2009, IEEE T BIOMED CIRC S, V3, P11, DOI 10.1109/TBCAS.2008.2006493
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Ciuti Gastone, 2011, IEEE Rev Biomed Eng, V4, P59, DOI 10.1109/RBME.2011.2171182
   Deligiannis N, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-106
   Deligiannis N, 2011, IEEE IMAGE PROC, P1813, DOI 10.1109/ICIP.2011.6115816
   Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485
   Eliakim R, 2013, CURR OPIN GASTROEN, V29, P133, DOI 10.1097/MOG.0b013e32835bdc03
   Fante KA, 2016, CIRC SYST SIGNAL PR, V35, P1677, DOI 10.1007/s00034-015-0136-z
   Freedman D, 2010, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2010.5540201
   Gowda SN, 2019, LECT NOTES COMPUT SC, V11364, P581, DOI 10.1007/978-3-030-20870-7_36
   Gu YK, 2012, ELECTRON LETT, V48, DOI 10.1049/el.2012.3470
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Imtiaz MS, 2014, MID EAST CONF BIO, P135, DOI 10.1109/MECBME.2014.6783224
   Ishikura K, 2018, IEEE T IMAGE PROCESS, V27, P703, DOI 10.1109/TIP.2017.2767288
   Khan T, 2015, HEALTHC TECHNOL LETT, V2, P52, DOI 10.1049/htl.2014.0086
   Khan TH, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-015-1612-4
   Khan TH, 2011, VLSI DES, DOI 10.1155/2011/343787
   Khan TH, 2011, IEEE T CIRC SYST VID, V21, P1534, DOI 10.1109/TCSVT.2011.2163985
   Kumar M, 2021, IEEE W SP LANG TECH, P966, DOI 10.1109/SLT48900.2021.9383495
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Lin MC, 2006, BIOMED ENG ONLINE, V5, DOI 10.1186/1475-925X-5-14
   Lin MC, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/257095
   Lin WY, 2020, IEEE MULTIMEDIA, V27, P12, DOI 10.1109/MMUL.2020.2990863
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luo SH, 2018, LECT NOTES COMPUT SC, V11301, P96, DOI 10.1007/978-3-030-04167-0_9
   Malathkar NV, 2019, BIOMED SIGNAL PROCES, V48, P197, DOI 10.1016/j.bspc.2018.10.016
   Meyer M, 2019, INT CONF ACOUST SPEE, P1607, DOI [10.1109/icassp.2019.8682846, 10.1109/ICASSP.2019.8682846]
   Paul S, 2020, I S BIOMED IMAGING, P221, DOI [10.1109/isbi45749.2020.9098634, 10.1109/ISBI45749.2020.9098634]
   Peng Lu, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P3210, DOI 10.1145/3394171.3413594
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   ROBERTSON AR, 1990, COLOR RES APPL, V15, P167, DOI 10.1002/col.5080150308
   Shi YY, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P329, DOI 10.1109/ICECT.2009.116
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sushma B, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101940
   Swain P, 2003, GUT, V52, P48
   Tai YW, 2005, PROC CVPR IEEE, P747
   Toennies JL, 2010, P I MECH ENG C-J MEC, V224, P1397, DOI 10.1243/09544062JMES1879
   Turcza P, 2017, BIOMED SIGNAL PROCES, V38, P1, DOI 10.1016/j.bspc.2017.04.006
   Turcza P, 2013, IEEE J BIOMED HEALTH, V17, P1046, DOI 10.1109/JBHI.2013.2266101
   Turcza P, 2011, SENSOR ACTUAT A-PHYS, V172, P552, DOI 10.1016/j.sna.2011.09.026
   Wahid K, 2008, IEEE IJCNN, P2761, DOI 10.1109/IJCNN.2008.4634186
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao CF, 2020, COMPUT GRAPH FORUM, V39, P20, DOI 10.1111/cgf.13659
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yu HT, 2005, IEEE T CIRCUITS-I, V52, P2707, DOI 10.1109/TCSI.2005.857869
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zeitoun JD, 2007, WORLD J GASTROENTERO, V13, P1451, DOI 10.3748/wjg.v13.i9.1451
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhu LW, 2021, IEEE T CIRC SYST VID, V31, P3168, DOI 10.1109/TCSVT.2020.3035356
NR 62
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103578
DI 10.1016/j.jvcir.2022.103578
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100001
DA 2024-07-18
ER

PT J
AU Yang, JC
   Zhou, YS
   Zhao, Y
   Wen, JB
AF Yang, Jiachen
   Zhou, Yanshuang
   Zhao, Yang
   Wen, Jiabao
TI Blind quality assessment of tone-mapped images using multi-exposure
   sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range; Tone-mapped image; Image quality assessment (IQA)
ID ENHANCEMENT; INDEX
AB The tone mapping operator (TMO) enables high dynamic range (HDR) images to be presented on low dynamic range (LDR) consumer electronic devices. However, the results obtained by this method are not always ideal due to the reduced number of bits. In comparison, the multi-exposure image fusion (MEF) bypasses the intermediate HDR image composition and directly produces an image presented on standard devices. Inspired by this, this paper proposes a quality assessment method for tone-mapped image (TMI) based on generating multi-exposure sequences. Specifically, the method uses a generative adversarial network (GAN) to generate a set of sequences with different exposure levels based on the TMIs. Then a two-branch convolutional neural network (CNN) is used to extract features from the tone-mapped images and the multi-exposure reference sequences, respectively. Finally, the transformer is used to mine the intrinsic connections between TMIs and multi-exposure sequences and learn the mapping relationships from feature space to quality space. We conducted extensive experiments on the ESPL-LIVE HDR database. The applicability and effectiveness of the proposed method are verified by comparing and analyzing relevant features and model configurations with existing mainstream evaluation algorithms.
C1 [Yang, Jiachen; Zhou, Yanshuang; Zhao, Yang; Wen, Jiabao] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Zhao, Y (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM yangzhao321@tju.edu.cn
RI chen, xi/GXH-3653-2022
OI , Yang/0000-0002-7302-7787
FU National Natural Science Foundation of China [61871283]
FX Acknowledgments This work was partially supported by National Natural
   Science Foundation of China (No. 61871283) .
CR [Anonymous], 2014, Computer Science
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cai H, 2019, J VIS COMMUN IMAGE R, V61, P250, DOI 10.1016/j.jvcir.2019.04.006
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen PF, 2019, PATTERN RECOGN, V89, P108, DOI 10.1016/j.patcog.2019.01.010
   Chi BW, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102752
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Hadizadeh H, 2018, IEEE T MULTIMEDIA, V20, P392, DOI 10.1109/TMM.2017.2740023
   Hancheng Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14131, DOI 10.1109/CVPR42600.2020.01415
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang GY, 2018, IEEE ACCESS, V6, P2231, DOI 10.1109/ACCESS.2017.2782320
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P4725, DOI 10.1109/TIP.2017.2713945
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Li QH, 2017, NEUROCOMPUTING, V236, P93, DOI 10.1016/j.neucom.2016.09.105
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Mahmoudpour S, 2020, IEEE T MULTIMEDIA, V22, P1939, DOI 10.1109/TMM.2019.2950570
   Min XK, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3470970
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3805, DOI 10.1109/TIP.2020.2966082
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3790, DOI 10.1109/TIP.2020.2966081
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Ok J, 2017, J VIS COMMUN IMAGE R, V43, P61, DOI 10.1016/j.jvcir.2016.12.008
   Ozcinar C, 2018, J VIS COMMUN IMAGE R, V55, P166, DOI 10.1016/j.jvcir.2018.06.003
   Pan D, 2018, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2018.00667
   Sarmah MJ, 2017, IEEE I C COMP INT CO, P1
   Su EY, 2018, IEEE ACCESS, V6, P47001, DOI 10.1109/ACCESS.2018.2866997
   Sun T, 2015, ADV INTELL SYST, V329, P381, DOI 10.1007/978-3-319-12286-1_39
   Thai BC, 2019, J VIS COMMUN IMAGE R, V58, P589, DOI 10.1016/j.jvcir.2018.12.024
   Tsai HC, 2015, J VIS COMMUN IMAGE R, V33, P165, DOI 10.1016/j.jvcir.2015.09.012
   Wang XJ, 2021, IEEE T MULTIMEDIA, V23, P692, DOI 10.1109/TMM.2020.2986583
   Wen S., 2021, A strong baseline for image and video quality assessment
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang JC, 2022, PLANT METHODS, V18, DOI 10.1186/s13007-022-00866-2
   Yang JC, 2021, IEEE T INF FOREN SEC, V16, P4234, DOI 10.1109/TIFS.2021.3102487
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
   Yang JC, 2021, IEEE T BROADCAST, V67, P696, DOI 10.1109/TBC.2021.3064266
   Yang JC, 2020, IEEE T CIRC SYST VID, V30, P3608, DOI 10.1109/TCSVT.2019.2948383
   Yanping Lu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457862
   Yao Susu, 2007, 2007 IEEE INT C IMAG, V3
   Yue GH, 2020, IEEE T IND INFORM, V16, P1764, DOI 10.1109/TII.2019.2927527
   Yue GH, 2019, IEEE T IND ELECTRON, V66, P3784, DOI 10.1109/TIE.2018.2851984
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
NR 57
TC 2
Z9 2
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103553
DI 10.1016/j.jvcir.2022.103553
EA JUN 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H5UY
UT WOS:000814360600001
DA 2024-07-18
ER

PT J
AU Sun, Z
   Chiong, R
   Hu, ZP
   Dhakal, S
AF Sun, Zhe
   Chiong, Raymond
   Hu, Zheng-ping
   Dhakal, Sandeep
TI A dynamic constraint representation approach based on cross-domain
   dictionary learning for expression recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Cross-domain dictionary learning; Dynamic
   constraint representation
ID FACIAL EXPRESSIONS; FACE RECOGNITION; K-SVD; CLASSIFICATION; ROBUST
AB Facial expression recognition (FER) is an active research area that has attracted much attention from both academics and practitioners of different fields. In this paper, we investigate an interesting and challenging issue in FER, where the training and testing samples are from a cross-domain dictionary. In this context, the data and feature distribution are inconsistent, and thus most of the existing recognition methods may not perform well. Given this, we propose an effective dynamic constraint representation approach based on cross-domain dictionary learning for expression recognition. The proposed approach aims to dynamically represent testing samples from source and target domains, thereby fully considering the feature elasticity in a cross-domain dictionary. We are therefore able to use the proposed approach to predict class information of unlabeled testing samples. Comprehensive experiments carried out using several public datasets confirm that the proposed approach is superior compared to some state-of-the-art methods.
C1 [Sun, Zhe; Hu, Zheng-ping] Yanshan Univ, Dept Informat Sci & Engn, Qinhuangdao 066000, Hebei, Peoples R China.
   [Chiong, Raymond; Dhakal, Sandeep] Univ Newcastle, Sch Informat & Phys Sci, Callaghan, NSW 2308, Australia.
C3 Yanshan University; University of Newcastle
RP Hu, ZP (corresponding author), Yanshan Univ, Dept Informat Sci & Engn, Qinhuangdao 066000, Hebei, Peoples R China.
EM hzp@ysu.edu.cn
RI Dhakal, Sandeep/HCH-4450-2022
OI Dhakal, Sandeep/0000-0001-7413-2530; Chiong, Raymond/0000-0002-8285-1903
FU National Natural Science Foundation of China [62001413, 61771420];
   Natural Science Foundation of Hebei Province, China [F2020203064];
   Doctoral Foundation of Yanshan University, China [BL18033]
FX Acknowledgments This work is supported by the National Natural Science
   Foundation of China under Grants 62001413 and 61771420, the Natural
   Science Foundation of Hebei Province, China under Grant F2020203064, and
   the Doctoral Foundation of Yanshan University, China under Grant
   BL18033.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alrubaish HA, 2020, INFORMATION, V11, DOI 10.3390/info11100485
   Andre T.L., 2017, PATTERN RECOGN, V61, P610
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Flynn M, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00070
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Iqbal A, 2018, IEEE T BIO-MED ENG, V65, P2519, DOI 10.1109/TBME.2018.2806958
   Liao MM, 2019, DIGIT SIGNAL PROCESS, V90, P110, DOI 10.1016/j.dsp.2019.04.006
   Lin GJ, 2018, PATTERN RECOGN, V81, P341, DOI 10.1016/j.patcog.2018.03.021
   Liu B, 2021, INFORM SCIENCES, V576, P157, DOI 10.1016/j.ins.2021.06.069
   Liu DY, 2021, NEUROCOMPUTING, V438, P34, DOI 10.1016/j.neucom.2020.09.088
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mattavelli G, 2021, J NEUROPSYCHOL, V15, P46, DOI 10.1111/jnp.12209
   Moeini A, 2017, J VIS COMMUN IMAGE R, V45, P20, DOI 10.1016/j.jvcir.2017.02.007
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Shi ZL, 2016, NEURAL NETWORKS, V83, P21, DOI 10.1016/j.neunet.2016.07.003
   Song Y, 2018, NEUROCOMPUTING, V310, P277, DOI 10.1016/j.neucom.2018.05.036
   Sun Z, 2018, NEUROCOMPUTING, V316, P1, DOI 10.1016/j.neucom.2018.07.045
   Sun Z, 2019, ARTIF INTELL REV, V51, P1, DOI 10.1007/s10462-017-9554-6
   Sun Z, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618501219
   Tang Y, 2018, IEEE ACCESS, V6, P42532, DOI 10.1109/ACCESS.2018.2858278
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu X, 2017, PATTERN RECOGN, V66, P404, DOI 10.1016/j.patcog.2016.12.001
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Yan HB, 2018, PATTERN RECOGN, V75, P33, DOI 10.1016/j.patcog.2017.02.031
   Yan OY, 2015, NEUROCOMPUTING, V149, P71, DOI 10.1016/j.neucom.2014.03.073
   Yazdani R, 2014, OPT LETT, V39, P1505, DOI 10.1364/OL.39.001505
   Yitzhak N, 2020, CORTEX, V126, P343, DOI 10.1016/j.cortex.2020.01.019
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang GQ, 2020, NEUROCOMPUTING, V391, P177, DOI 10.1016/j.neucom.2020.01.101
   Zhang HC, 2012, IEEE T AERO ELEC SYS, V48, P2481, DOI 10.1109/TAES.2012.6237604
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3798, DOI 10.1109/TNNLS.2017.2740224
NR 42
TC 5
Z9 5
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103458
DI 10.1016/j.jvcir.2022.103458
EA MAR 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600009
DA 2024-07-18
ER

PT J
AU Moradi, M
   Bayat, F
   Charmi, M
AF Moradi, Morteza
   Bayat, Farhad
   Charmi, Mostafa
TI A salient object detection framework using linear quadratic regulator
   controller*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Control system; Linear quadratic regulator;
   Optimal control; Angular embedding
ID IMAGE; SEGMENTATION
AB In this paper, a novel salient object detection framework based on Linear Quadratic Regulator (LQR) controller is proposed. The major goal of this research is to take advantage of optimal control theory for improving the performance of detecting salient objects in images. In this regard, for the sake of detection of salient and non salient regions, two LQR-based control systems are employed. In the proposed framework, for the initialization of the control systems, background and foreground estimations have been done with two different strategies. Doing so, we would ultimately have more effective distinction between those regions. After the initialization step, the control systems refine both estimations in parallel until reaching a steady state for each of them. Within the mentioned process, by using optimal control concept, specifically LQR controller (for the first time in the field), control signals which are in charge of determining saliency values, would be constantly optimized. At the end, the raw saliency map will be generated by combination of background and foreground optimized initial maps. Finally, the integrated saliency map will be refined by using angular embedding method. The experimental evaluations on three benchmark datasets shows that the proposed framework performs well and introduces comparable results with some deep learning based methods.
C1 [Moradi, Morteza; Bayat, Farhad; Charmi, Mostafa] Univ Zanjan, Dept Elect Engn, Zanjan, Iran.
C3 University Zanjan
RP Bayat, F (corresponding author), Univ Zanjan, Dept Elect Engn, Zanjan, Iran.
EM morteza.moradi@znu.ac.ir; bayat.farhad@znu.ac.ir;
   charmi.mostafa@znu.ac.ir
RI Charmi, Mostafa/I-8402-2018
OI Charmi, Mostafa/0000-0002-5166-1779
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Afzali S, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P3191
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], 1995, DISCRETE TIME CONTRO
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Bredies K, 2005, IFIP C SYST MOD OPT, P249
   Chakraborty S, 2016, COMPUT VIS IMAGE UND, V145, P1, DOI 10.1016/j.cviu.2015.12.005
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen W, 2014, COMPUT ELECTR ENG, V40, P227, DOI 10.1016/j.compeleceng.2014.04.008
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cheng SC, 2018, NEURAL NETWORKS, V101, P101, DOI 10.1016/j.neunet.2018.01.012
   Das L, 2017, AICHE J, V63, P3311, DOI 10.1002/aic.15689
   Deng C, 2020, IEEE T MULTIMEDIA, V22, P885, DOI 10.1109/TMM.2019.2934833
   Duncan K, 2012, IET COMPUT VIS, V6, P514, DOI 10.1049/iet-cvi.2012.0032
   Filieri A, 2015, 2015 IEEE/ACM 10TH INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR ADAPTIVE AND SELF-MANAGING SYSTEMS, P71, DOI 10.1109/SEAMS.2015.12
   Gao ZG, 2018, IEEE ACCESS, V6, P71422, DOI 10.1109/ACCESS.2018.2882014
   Ghanbarpour K, 2020, INT J ELEC POWER, V118, DOI 10.1016/j.ijepes.2019.105802
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hsu KJ, 2019, PROC CVPR IEEE, P8838, DOI 10.1109/CVPR.2019.00905
   Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65
   Huo SW, 2018, IEEE T MULTIMEDIA, V20, P1350, DOI 10.1109/TMM.2017.2769801
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Joshi A, 2020, IEEE ACCESS, V8, P190487, DOI 10.1109/ACCESS.2020.3032288
   Gil-González WJ, 2020, IEEE T POWER SYST, V35, P2002, DOI 10.1109/TPWRS.2019.2948360
   Kaur B, 2018, COMPUT ELECTR ENG, V71, P692, DOI 10.1016/j.compeleceng.2018.08.018
   Kimia B., 1994, Geometry-driven diffusion in computer vision, P307
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lopez-Alanis A, 2020, APPL INTELL, V50, P1745, DOI 10.1007/s10489-019-01582-6
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Ma WP, 2021, INT J AUTOM COMPUT, V18, P73, DOI 10.1007/s11633-020-1246-z
   Moradi Morteza, 2019, International Journal of Crowd Science, V3, DOI 10.1108/IJCS-03-2019-0012
   Moradi M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114428
   Moradi M, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P221, DOI [10.1109/ICWR.2019.8765247, 10.1109/icwr.2019.8765247]
   Nawaz M., 2020, IEEE T MULTIMEDIA
   Peng HJ, 2020, IEEE T IND ELECTRON, V67, P3819, DOI 10.1109/TIE.2019.2916390
   Pni T, 2020, NONLINEAR DYNAM, V102, P1965, DOI 10.1007/s11071-020-05980-1
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2020, IEEE T IMAGE PROCESS, V29, P1879, DOI 10.1109/TIP.2019.2942434
   Qin Y, 2018, INT J COMPUT VISION, V126, P751, DOI 10.1007/s11263-017-1062-2
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ristic-Durrant D., 2008, AUTOMATIC CONTROL RO, V7, P27
   Rubagotti M, 2019, IEEE ROBOT AUTOM LET, V4, P2746, DOI 10.1109/LRA.2019.2917707
   Savarni KRVR, 2019, 2019 FIFTH INDIAN CONTROL CONFERENCE (ICC), P39, DOI [10.1109/INDIANCC.2019.8715583, 10.1109/indiancc.2019.8715583]
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi PT, 2020, COMPUT GRAPH-UK, V91, P83, DOI 10.1016/j.cag.2020.06.007
   Shokri M, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102769
   Singh VK, 2020, ARTIF INTELL REV, V53, P3731, DOI 10.1007/s10462-019-09777-6
   Sran PK, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102964
   Sun XB, 2020, NEUROCOMPUTING, V411, P393, DOI 10.1016/j.neucom.2020.06.003
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tsay C, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67459-8
   Tu ZZ, 2020, IEEE T MULTIMEDIA, V22, P160, DOI 10.1109/TMM.2019.2924578
   Wang LH, 2019, NEUROCOMPUTING, V329, P433, DOI 10.1016/j.neucom.2018.10.061
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wu Y, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102761
   Yamamoto Y., 2005, Australian Journal of Electrical & Electronics Engineering, V2, P141
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yan S., 2020, MATH PROBL ENG
   Yan YJ, 2018, PATTERN RECOGN, V79, P65, DOI 10.1016/j.patcog.2018.02.004
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang Z., 2019, J VIS COMMUN IMAGE R
   Yu C, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2420, DOI 10.1109/WCICA.2016.7578738
   Yu SX, 2012, IEEE T PATTERN ANAL, V34, P158, DOI 10.1109/TPAMI.2011.107
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang M., 2017, IEEE T CYBERNET, V49, P580
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhou Q., 2020, 2 EAI INT C ROB SENS, P201
   Zhu LJ, 2018, IEEE T AUTOMAT CONTR, V63, P3276, DOI 10.1109/TAC.2018.2792328
   Zhu X, 2018, ARXIV PREPRINT ARXIV
   Zhu XZ, 2018, NEUROCOMPUTING, V312, P239, DOI 10.1016/j.neucom.2018.05.106
NR 85
TC 5
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103259
DI 10.1016/j.jvcir.2021.103259
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800010
DA 2024-07-18
ER

PT J
AU Zhan, Y
   Zhao, WL
AF Zhan, Yu
   Zhao, Wan-Lei
TI Instance search via instance level segmentation and feature
   representation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Instance search; Instance segmentation; CNN
ID IMAGE RETRIEVAL
AB Instance search is an interesting task as well as a challenging issue due to the lack of effective feature representation. In this paper, an instance level feature representation built upon fully convolutional instanceaware segmentation is proposed. The feature is ROI-pooled from the segmented instance region. So that instances in various sizes and layouts are represented by deep features in uniform length. This representation is further enhanced by the use of deformable ResNeXt blocks. Superior performance is observed in terms of its distinctiveness and scalability on a challenging evaluation dataset built by ourselves. In addition, the proposed enhancement on the network structure also shows superior performance on the instance segmentation task.
C1 [Zhan, Yu; Zhao, Wan-Lei] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Zhao, WL (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China.
EM yeezytaughtme@stu.xmu.edu.cn; wlzhao@xmu.edu.cn
FU National Natural Science Foundation of China [61572408, 61972326];
   Xiamen University, PR China [20720180074]
FX This work is supported by National Natural Science Foundation of China
   under grants 61572408 and 61972326, and the grants of Xiamen University,
   PR China 20720180074.
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Arandjelovic R., 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2711011
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Awad G, 2017, INT J MULTIMED INF R, V6, P1, DOI 10.1007/s13735-017-0121-3
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Raveaux R, 2013, J VIS COMMUN IMAGE R, V24, P1252, DOI 10.1016/j.jvcir.2013.08.010
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reta C, 2018, J VIS COMMUN IMAGE R, V54, P39, DOI 10.1016/j.jvcir.2018.04.009
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Tolias G., 2016, Conference Track Proceedings,
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xie LX, 2016, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2016.36
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Zhang J, 2015, J VIS COMMUN IMAGE R, V26, P37, DOI 10.1016/j.jvcir.2014.10.007
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
NR 40
TC 5
Z9 6
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103253
DI 10.1016/j.jvcir.2021.103253
EA JUL 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, YQ
   Liu, Y
   Zhou, HY
   Li, WH
AF Zhou, Yaqian
   Liu, Yu
   Zhou, Heyu
   Li, Wenhui
TI Wasserstein distance feature alignment learning for 2D image-based 3D
   model retrieval*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D model retrieval; Multi-view learning; Cross-domain retrieval
AB 2D image-based 3D model retrieval has become a hotspot topic in recent years. However, the current existing methods are limited by two aspects. Firstly, they are mostly based on the supervised learning, which limits their application because of the high time and cost consuming of manual annotation. Secondly, the mainstream methods narrow the discrepancy between 2D and 3D domains mainly by the image-level alignment, which may bring the additional noise during the image transformation and influence cross-domain effect. Consequently, we propose a Wasserstein distance feature alignment learning (WDFAL) for this retrieval task. First of all, we describe 3D models through a series of virtual views and use CNNs to extract features. Secondly, we design a domain critic network based on the Wasserstein distance to narrow the discrepancy between two domains. Compared to the image-level alignment, we reduce the domain gap by the feature-level distribution alignment to avoid introducing additional noise. Finally, we extract the visual features from 2D and 3D domains, and calculate their similarity by utilizing Euclidean distance. The extensive experiments can validate the superiority of the WDFAL method.
C1 [Zhou, Yaqian; Liu, Yu] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
   [Zhou, Yaqian] Peoples Daily Online, State Key Lab Commun Content Cognit, Beijing 100733, Peoples R China.
   [Zhou, Heyu; Li, Wenhui] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Li, Wenhui] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
C3 Tianjin University; Tianjin University; Chinese Academy of Sciences
RP Zhou, HY; Li, WH (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.; Li, WH (corresponding author), Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
EM zhy_std@163.com; liwenhui@tju.edu.cn
RI LU, lpp pp/JFJ-9011-2023; Lu, Wang/JVO-0416-2024; LI,
   Wenhui/JCD-9947-2023; Zeng, Yun/JFK-6190-2023
OI Liu, Yu/0000-0002-5949-6587; , Heyu Zhou/0000-0001-9451-5600
FU Yunnan provincial major science and technology special plan projects
   [202002AD080001]; National Key Research and Development Program of China
   [2020YFB1406602]; Open Funding Project of the State Key Laboratory of
   Communication Content Cognition [20K04]; Key Laboratory of
   Electromagnetic Space Information, Chinese Academy of Sciences
   (Theoretical Research on Video Semantic Analysis for Content Security of
   Social Networks)
FX This work was supported in part by Yunnan provincial major science and
   technology special plan projects (202002AD080001), the National Key
   Research and Development Program of China (2020YFB1406602), Open Funding
   Project of the State Key Laboratory of Communication Content
   Cognition(Grant No. 20K04), the Key Laboratory of Electromagnetic Space
   Information, Chinese Academy of Sciences (Theoretical Research on Video
   Semantic Analysis for Content Security of Social Networks).
CR Arjovsky M., 2017, ABS170107875
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Gong R., 2019, P IEEE CVF C COMP VI
   Guo K, 2018, GRAPH MODELS, V96, P30, DOI 10.1016/j.gmod.2018.02.001
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426
   Gulrajani I, 2017, ADV NEUR IN, V30
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S, 2019, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2019.00018
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu AA, 2019, IEEE ACCESS, V7, P153021, DOI 10.1109/ACCESS.2019.2947245
   Liu AA, 2019, IEEE T CIRC SYST VID, V29, P868, DOI 10.1109/TCSVT.2018.2810191
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P828
   Liu Y., 2020, NEURAL PROCESS LETT, V52
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Matsuda T, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P100, DOI 10.1109/BigMM.2015.66
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nie WZ, 2019, IEEE T CIRC SYST VID, V29, P1619, DOI 10.1109/TCSVT.2018.2852310
   Nie WZ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3344684
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Panaretos VM, 2019, ANNU REV STAT APPL, V6, P405, DOI 10.1146/annurev-statistics-030718-104938
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shen J, 2018, AAAI CONF ARTIF INTE, P4058
   Shu Y, 2019, AAAI CONF ARTIF INTE, V33, P4951
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Volpi R., 2018, 2018 IEEE C COMP VIS
   Wang DX, 2018, AAAI CONF ARTIF INTE, P443
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   You HX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1310, DOI 10.1145/3240508.3240702
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhou HY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P839
   Zhou HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1667, DOI 10.1145/3343031.3351011
   Zhu J, 2019, PATTERN RECOGN LETT, V119, P24, DOI 10.1016/j.patrec.2017.09.041
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 48
TC 7
Z9 8
U1 1
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103197
DI 10.1016/j.jvcir.2021.103197
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100006
DA 2024-07-18
ER

PT J
AU Li, M
   Ren, H
   Xiang, Y
   Zhang, YS
AF Li, Ming
   Ren, Hua
   Xiang, Yong
   Zhang, Yushu
TI Reversible data hiding in encrypted color images using cross-channel
   correlations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; Cross-channel correlation;
   Homomorphism
ID SCHEME
AB In recent years, the increasing requirements in cloud storage and cloud computing have made it necessary to encrypt digital images for privacy protection. Meanwhile, many reversible data hiding (RDH) algorithms in the encrypted domain have been proposed. However, most of these algorithms are for gray-level images, and the intrinsic cross-channel correlations of color images cannot be utilized to improve the embedding capacity. In this paper, we propose a novel data hiding method for encrypted color images. In the encryption stage, the homomorphic property of encryption is achieved by basic modular addition. During the data hiding process, the crosschannel correlations between R, G and B channels are generated in encrypted domain, and data hiding is performed by the difference histogram shifting. Analysis and experiments demonstrate that the proposed method is secure and the RDH performance is superior.
C1 [Li, Ming] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.
   [Ren, Hua] Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
   [Xiang, Yong] Deakin Univ, Sch Informat Technol, Geelong, Vic 3125, Australia.
   [Zhang, Yushu] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
C3 Henan Normal University; Beijing University of Posts &
   Telecommunications; Deakin University; Nanjing University of Aeronautics
   & Astronautics
RP Li, M (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.; Xiang, Y (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3125, Australia.
EM liming@htu.edu.cn; renhuahtu@163.com; yxiang@deakin.edu.au;
   yushuboshi@163.com
RI Li, Ming/Q-6532-2016
OI Li, Ming/0000-0003-3385-8364; Xiang, Yong/0000-0003-3545-7863
FU Science and Technology Research Project of Henan Province
   [212102210413]; Key Research Projects of Henan Higher Schools
   [20A413007]; Doctoral Talents Research Initiation Project of Henan
   Normal University [20190319]; National Natural Science Foundation of
   China [61602158]
FX This work was supported by the Science and Technology Research Project
   of Henan Province (No.212102210413), the Key Research Projects of Henan
   Higher Schools (No. 20A413007), the Doctoral Talents Research Initiation
   Project of Henan Normal University (No. 20190319), and the National
   Natural Science Foundation of China (No.61602158).
CR [Anonymous], 2009, EURASIP J INF SECUR
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li M, 2015, ELECTRON LETT, V51, P690, DOI 10.1049/el.2014.4476
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Long M, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107703
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Nikolaidis A, 2016, MULTIMED TOOLS APPL, V75, P1869, DOI 10.1007/s11042-014-2377-4
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Puteaux P., 2018, IEEE T INF FOREN SEC, P1
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Rivest Ronald L., 1978, Found. Secure Comput., V4, P169
   Romero Grecia, 2017, SIGNAL IMAGE PROCESS
   Tuncer T, 2016, DISPLAYS, V41, P1, DOI 10.1016/j.displa.2015.10.005
   Wu H.T., 2016, REVERSIBLE DATA HIDI
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Yin ZX, 2014, SCI WORLD J, DOI 10.1155/2014/604876
   Yu J., 2016, LNCS, V7809, P441, DOI [10.1007/978-3-642-40099-5_32, DOI 10.1007/978-3-642-40099-5_32]
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 27
TC 8
Z9 9
U1 6
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103166
DI 10.1016/j.jvcir.2021.103166
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LW
UT WOS:000674617500004
DA 2024-07-18
ER

PT J
AU Xu, W
   Qiu, S
   Huang, KY
   Liu, W
   Zuo, JZ
   Guo, HM
AF Xu, Wei
   Qiu, Song
   Huang, Kunyao
   Liu, Wei
   Zuo, Junzhe
   Guo, Haoming
TI Image deraining with Adversarial Residual Refinement Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deraining; Deep learning; GAN
ID RAIN; VISION; INFORMATION
AB Prior image deraining works mainly have two problems: (1) they do not generalize well to various datasets; (2) too much detail information is lost in the heavy rain area of the rain image. To overcome these two problems, we propose a new two-stage Adversarial Residual Refinement Network (ARRN) to deal with heavy rain images. Specifically, for the first problem, we first introduce a new implicit rain model to model a rain image as a composition of a background image and a residual image. Based on the proposed implicit model, we then propose the ARRN which consists of an image decomposition stage and an image refinement stage. For the second problem, a new attention Wasserstein Generative Adversarial Networks (WGAN) loss in the refinement stage is introduced to force the network to focus on refining heavily degraded areas. Comprehensive experiments demonstrate the effectiveness of the proposed approach.
C1 [Xu, Wei; Qiu, Song; Huang, Kunyao; Guo, Haoming] East China Normal Univ, Sch Commun & Elect Engn, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.
   [Liu, Wei] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5000, Australia.
   [Zuo, Junzhe] East China Normal Univ, Sch Phys & Elect, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.
C3 East China Normal University; University of Adelaide; East China Normal
   University
RP Qiu, S (corresponding author), East China Normal Univ, Sch Commun & Elect Engn, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.
EM wxu@sist.ecnu.edu.cn; sqiu@ee.ecnu.edu.cn; 51171214027@stu.ecnu.edu.cn;
   wei.liu02@adelaide.edu.au; 10175300328@stu.ecnu.edu.cn;
   51191214008@stu.ecnu.edu.cn
OI Xu, Wei/0009-0001-9354-0297
FU National Key R&D Program of China [2018YFB2101302]; Dean's Fund of
   Engineering Research Center of Software/Hardware Codesign Technology and
   Application, Ministry of Education (East China Normal University);
   National Science Foundation, China [615723156151101179]
FX This work is partly supported by the National Key R&D Program of China
   (No. 2018YFB2101302) , the Dean's Fund of Engineering Research Center of
   Software/Hardware Codesign Technology and Application, Ministry of
   Education (East China Normal University) and National Science
   Foundation, China (No: 615723156151101179) .
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chang Y, 2017, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2017.191
   Du SL, 2018, PATTERN RECOGN, V79, P303, DOI 10.1016/j.patcog.2018.02.016
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XW, 2019, PROC CVPR IEEE, P8014, DOI 10.1109/CVPR.2019.00821
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079
   Jangblad M, 2018, OBJECT DETECTION INF
   Jin X, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107143
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2013, IEEE IMAGE PROC, P914, DOI 10.1109/ICIP.2013.6738189
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Li D, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107085
   Li G, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1056, DOI 10.1145/3240508.3240636
   Li RT, 2019, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2019.00173
   Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Lin HX, 2020, IEEE T IMAGE PROCESS, V29, P7668, DOI 10.1109/TIP.2020.3005517
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nazeri K., 2019, ARXIV190100212
   Radford A., 2015, ARXIV151106434
   Ren DW, 2020, IEEE T IMAGE PROCESS, V29, P6852, DOI 10.1109/TIP.2020.2994443
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santhaseelan V, 2015, INT J COMPUT VISION, V112, P71, DOI 10.1007/s11263-014-0759-8
   Simonyan K., 2014, 14091556 ARXIV
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Tripathi AK, 2014, SIGNAL IMAGE VIDEO P, V8, P1421, DOI 10.1007/s11760-012-0373-6
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Ulyanov Dmitry, 2016, arXiv
   Wang H, 2020, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR42600.2020.00317
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang Q, 2019, PATTERN RECOGN, V88, P493, DOI 10.1016/j.patcog.2018.11.020
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wang YL, 2017, IEEE T IMAGE PROCESS, V26, P3936, DOI 10.1109/TIP.2017.2708502
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu F, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107335
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xu W, 2019, NEUROCOMPUTING, V362, P147, DOI 10.1016/j.neucom.2019.06.072
   Xu W, 2018, NEUROCOMPUTING, V309, P134, DOI 10.1016/j.neucom.2018.04.075
   Xu W, 2018, SIGNAL PROCESS-IMAGE, V64, P59, DOI 10.1016/j.image.2018.02.013
   Xu W, 2017, IEEE IMAGE PROC, P3705, DOI 10.1109/ICIP.2017.8296974
   Xu W, 2015, INT CONF ACOUST SPEE, P1151, DOI 10.1109/ICASSP.2015.7178150
   Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574
   Yang WH, 2021, IEEE T PATTERN ANAL, V43, P4059, DOI 10.1109/TPAMI.2020.2995190
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yang WH, 2019, IEEE T IMAGE PROCESS, V28, P2948, DOI 10.1109/TIP.2019.2892685
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhao LJ, 2019, PATTERN RECOGN, V88, P356, DOI 10.1016/j.patcog.2018.11.028
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 62
TC 2
Z9 2
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103133
DI 10.1016/j.jvcir.2021.103133
EA MAY 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400002
DA 2024-07-18
ER

PT J
AU Sahu, G
   Seal, A
   Krejcar, O
   Yazidi, A
AF Sahu, Geet
   Seal, Ayan
   Krejcar, Ondrej
   Yazidi, Anis
TI Single image dehazing using a new color channel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Atmospheric light; Radiance; Illuminance scaling factor
ID VISIBILITY
AB Images with hazy scene suffer from low-contrast, which reduces the visible quality of the scene, thus making object detection a more challenging task. Low-contrast can result from foggy weather conditions during image acquisition. Dehazing is a process of removal of haze from the photography of a hazy scene. Single-image dehazing based on dark channel priors are well-known techniques in this field. However, the performance of such techniques is limited to priors or constraints. Moreover, this type of method fails when images have sky-region. So, a method is proposed, which can restore the visibility of hazy images. First, a hazy image is divided into blocks of size 32 x 32, then the score of each block is calculated to select a block having the highest score. Atmospheric light is calculated from the selected block. A new color channel is considered to remove atmospheric scattering, obtained channel value and atmospheric light are then used to calculate the transmission map in the second step. Third, radiance is computed using a transmission map and atmospheric light. The illumination scaling factor is adopted to enhance the quality of a dehazed image in the final step. Experiments are performed on six datasets namely, I-HAZE, O-HAZE, BSDS500, FRIDA, RESIDE dataset and natural images from Google. The proposed method is compared against 11 state-of-the-art methods. The performance is analyzed using fourteen quantitative evaluation metrics. All the results demonstrate that the proposed method outperforms 11 state-of-the-art methods in most of the cases.
C1 [Sahu, Geet; Seal, Ayan] PDPM Indian Inst Informat Technol, Design & Mfg, Jabalpur 482005, India.
   [Seal, Ayan; Krejcar, Ondrej] Univ Hradec Kralove, Ctr Basic & Appl Sci, Fac Informat & Management, Rokitanskeho 62, Hradec Kralove 50003, Czech Republic.
   [Krejcar, Ondrej] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
   [Yazidi, Anis] Oslo Metropolitan Univ, Res Grp Appl Artificial Intelligence, N-460167 Oslo, Norway.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; University of Hradec Kralove; Universiti Teknologi Malaysia;
   Oslo Metropolitan University (OsloMet)
RP Seal, A (corresponding author), PDPM Indian Inst Informat Technol, Design & Mfg, Jabalpur 482005, India.
EM ayan@iiitdmj.ac.in
RI Seal, Ayan/AAI-1929-2020; Sahu, Geet/HHY-9855-2022; Krejcar,
   Ondrej/A-8639-2008
OI Seal, Ayan/0000-0002-9939-2926; Krejcar, Ondrej/0000-0002-5992-2574
FU Computer Science and Engineering, PDPM Indian Institute of Information
   Technology, Design and Manufacturing, Jabalpur India [SPARC-MHRD-231];
   Grant Agency of Excellence, University of Hradec Kralove, Faculty of
   Informatics and Management, Czech Republic [2020/2204]; Universiti
   Teknologi Malaysia (UTM) under Research University [Vot-20H04]; Malaysia
   Research University Network (MRUN) [Vot 4L876]; Fundamental Research
   Grant Scheme (FRGS) under Ministry of Education Malaysia [Vot5F073]
FX This work is partially supported by the project "Prediction of diseases
   through computer assisted diagnosis system using images captured by
   minimally-invasive and non-invasive modalities'', Computer Science and
   Engineering, PDPM Indian Institute of Information Technology, Design and
   Manufacturing, Jabalpur India (under ID: SPARC-MHRD-231). This work is
   also partially supported by the project at (2020/2204), Grant Agency of
   Excellence, University of Hradec Kralove, Faculty of Informatics and
   Management, Czech Republic and by the project at Universiti Teknologi
   Malaysia (UTM) under Research University Grant Vot-20H04, Malaysia
   Research University Network (MRUN) Vot 4L876 and the Fundamental
   Research Grant Scheme (FRGS) Vot5F073 supported under Ministry of
   Education Malaysia for the completion of the research.
CR Al-Sammaraie MF, 2015, INT CONF COMP SCI ED, P95, DOI 10.1109/ICCSE.2015.7250224
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], 2011, BERKELEY SEGMENTATIO
   [Anonymous], 2012, OPEN J APPL SCI
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen G, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 2, PROCEEDINGS, P53, DOI 10.1109/SNPD.2007.350
   Cheng YJ, 2013, IEEE SYS MAN CYBERN, P3627, DOI 10.1109/SMC.2013.618
   Ciaburro G., 2017, Neural Networks With R: Smart Models Using CNN, RNN, Deep Learning, and Artificial Intelligence Principles
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P518, DOI 10.1109/LGRS.2007.896328
   Fang FM, 2014, SIAM J IMAGING SCI, V7, P969, DOI 10.1137/130919696
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Ge GY, 2015, OPTIK, V126, P3245, DOI 10.1016/j.ijleo.2015.07.138
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Gui B, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102792
   Guo F, 2020, NEUROCOMPUTING, V378, P9, DOI 10.1016/j.neucom.2019.09.094
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou Guojia, MULTIMEDIA TOOLS APP, P1
   [胡韦伟 Hu Weiwei], 2010, [工程图学学报, Journal of Engineering Graphics], V31, P104
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Khmag A, 2018, VISUAL COMPUT, V34, P675, DOI 10.1007/s00371-017-1406-5
   Koschmieder H., 1924, Beitraege Phys. Atmosp., P33
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li BY, 2018, AAAI CONF ARTIF INTE, P7016
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li YA, 2016, NEUROCOMPUTING, V182, P221, DOI 10.1016/j.neucom.2015.12.032
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P132
   Luyan Tong, 2020, Artificial Intelligence and Security. 6th International Conference (ICAIS 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12239), P339, DOI 10.1007/978-3-030-57884-8_30
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pang J., 2011, P APSIPA ASC, P1
   Panigrahy C, 2020, APPL OPTICS, V59, P5642, DOI 10.1364/AO.391234
   Panigrahy C, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106141
   Panigrahy C, 2020, IEEE SIGNAL PROC LET, V27, P690, DOI 10.1109/LSP.2020.2989054
   Pei YT, 2018, LECT NOTES COMPUT SC, V11214, P697, DOI 10.1007/978-3-030-01249-6_42
   Qi M, 2015, OPTIK, V126, P3400, DOI 10.1016/j.ijleo.2015.07.114
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   Sahu Geet, 2019, 2019 International Conference on Information Technology (ICIT), P388, DOI 10.1109/ICIT48102.2019.00075
   Salazar-Colores S, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0447-2
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Seal A, 2018, INT J NUMER METH BIO, V34, DOI 10.1002/cnm.2933
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Sengupta A, 2020, IEEE ACCESS, V8, P88385, DOI 10.1109/ACCESS.2020.2993607
   Shabna D., 2016, INT J INNOV RES SCI, V5
   Shu Ting, 2015, Jishou Daxue Xuebao (Ziran Kexue Ban), V36, P40, DOI 10.3969/j.issn.1007-2985.2015.01.010
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Sudhakar M., 2019, WIREL NETW, P1
   Tan ZM, 2014, FUJITSU SCI TECH J, V50, P60
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Wang Z, 2018, IET COMPUT VIS, V12, P393, DOI 10.1049/iet-cvi.2017.0318
   Xia P, 2016, OPTIK, V127, P7350, DOI 10.1016/j.ijleo.2016.05.071
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2225, DOI 10.1109/ICACCI.2014.6968569
   Yan J., 2019, ARXIV PREPRINT ARXIV
   Yang J, 2017, ATMOS MEAS TECH, V10, P1191, DOI 10.5194/amt-10-1191-2017
   Yang Wanting, 2010, J COMPUT AIDED DES C, V6
   Yeh CH, 2013, OPT EXPRESS, V21, P27127, DOI 10.1364/OE.21.027127
   Zarges C., 2019, ARXIV PREPRINT ARXIV
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
   Zoran LF, 2009, UNIV POLIT BUCHAR S, V71, P37
NR 71
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500009
DA 2024-07-18
ER

PT J
AU Wang, MH
   Wang, Q
AF Wang, Minghua
   Wang, Qiang
TI Hypergraph-regularized sparse representation for single color image
   super resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image super resolution; Alternating Direction Method of
   Multipliers (ADMM); Joint Color Dictionary Training (JCDT); Hypergraph
   regularization; Self-channel and cross-channel information
ID SELF-SIMILARITY; SUPERRESOLUTION; INTERPOLATION; REGRESSION; SMOOTHNESS
AB Sparsity-based single image super resolution method generates the High-Resolution (HR) output via a corresponding dictionary from the Low-Resolution (LR) input. However, most of these existing methods ignore the complementary information from color channels, which causes the loss of a valid prior and the limitation of HR image quality improvement. In this paper, hypergraph regularization is first incorporated with Joint Color Dictionary Training (JCDT) model and HR image reconstruction (HRIR) model. A novel Hypergraph-regularized Sparse coding-based Super Resolution (HG-ScSR) is proposed. This regularization can not only focus on the illuminance information, but also exploit the self-channel and cross-channel information of three color RGB channels from high-resolution image patches. Especially, the complex relationship is explored among every color image patch pixel and the consistency of the similar pixels is enforced. Both simulated and real data experiments verify the higher performance of the proposed HG-ScSR.
C1 [Wang, Minghua; Wang, Qiang] Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, MH (corresponding author), Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Peoples R China.
EM minghuawang1993@163.com
RI Wang, Minghua/J-5829-2018; Wang, Qiang/B-1053-2012; wang,
   minghua/GPK-4840-2022
OI Wang, Qiang/0000-0002-9654-0268; 
FU China Scholarship Council (CSC); National Natural Science Foundations of
   China [61876054]
FX Thanks for the support provided by China Scholarship Council (CSC). This
   work of the paper is supported by National Natural Science Foundations
   of China(No.61876054). Thanks the authors of [16,18,19,29] for providing
   their codes. Our codes are available online at: https
   ://github.com/minghuawang666/HG-ScSR2.0.
CR [Anonymous], 2006, ADV NEURAL INF PROCE
   Berge C., HYPERGRAPHS COMBINAT, P45
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chang H., IEEE COMP SOC C COMP
   Chen HG, 2018, SIGNAL PROCESS-IMAGE, V66, P1, DOI 10.1016/j.image.2018.04.012
   Chen HG, 2016, SIGNAL PROCESS-IMAGE, V43, P68, DOI 10.1016/j.image.2016.01.007
   Chen HY, 2012, J VIS COMMUN IMAGE R, V23, P343, DOI 10.1016/j.jvcir.2011.11.006
   Cheng M, 2015, IET IMAGE PROCESS, V9, P461, DOI 10.1049/iet-ipr.2014.0313
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fan Y., 2018, WIDE ACTIVATED DEEP, P2621
   Fan Y, 2017, 2017 INTERNATIONAL CONFERENCE ON SOCIAL SCIENCES, ARTS AND HUMANITIES (SSAH 2017), P163
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gong WG, 2017, NEUROCOMPUTING, V249, P157, DOI 10.1016/j.neucom.2017.03.067
   Hong CQ, 2013, NEUROCOMPUTING, V101, P94, DOI 10.1016/j.neucom.2012.09.001
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V158, P35, DOI 10.1016/j.isprsjprs.2019.09.008
   Hong DF, 2015, NEUROCOMPUTING, V151, P511, DOI 10.1016/j.neucom.2014.09.013
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Huang SD, 2019, PATTERN RECOGN, V88, P174, DOI 10.1016/j.patcog.2018.11.007
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Kang J., IEEE T NEURAL NETW L
   Karimi N, 2015, J VIS COMMUN IMAGE R, V33, P94, DOI 10.1016/j.jvcir.2015.09.004
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li XY, 2014, NEUROCOMPUTING, V139, P310, DOI 10.1016/j.neucom.2014.02.026
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   LIU HM, 2017, IEICE T INF SYST, P150
   Liu MX, 2017, NEUROCOMPUTING, V237, P185, DOI 10.1016/j.neucom.2016.10.031
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mousavi HS, 2017, IEEE T IMAGE PROCESS, V26, P5094, DOI 10.1109/TIP.2017.2704443
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Qiao LS, 2018, NEUROCOMPUTING, V312, P336, DOI 10.1016/j.neucom.2018.05.084
   Rasti B., IEEE GEOSCI REMOTE S
   Rousseau F, 2010, MED IMAGE ANAL, V14, P594, DOI 10.1016/j.media.2010.04.005
   Sajjad M, 2015, J VIS COMMUN IMAGE R, V26, P50, DOI 10.1016/j.jvcir.2014.10.012
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang QZ, 2016, IEEE T IMAGE PROCESS, V25, P1425, DOI 10.1109/TIP.2016.2521180
   Wang WH, 2016, IEEE J-STARS, V9, P681, DOI 10.1109/JSTARS.2015.2508448
   Wang YK, 2018, J VIS COMMUN IMAGE R, V57, P152, DOI 10.1016/j.jvcir.2018.10.028
   Wu Z., 2017, IEEE INT INSTRUM MEA, V9, P1
   Xie C, 2017, NEUROCOMPUTING, V260, P92, DOI 10.1016/j.neucom.2017.03.073
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2011, IEEE INT CON MULTI
   Zhang KB, 2016, SIGNAL PROCESS, V123, P53, DOI 10.1016/j.sigpro.2015.11.025
NR 58
TC 3
Z9 3
U1 2
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102951
DI 10.1016/j.jvcir.2020.102951
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I2ON
UT WOS:000779264200002
DA 2024-07-18
ER

PT J
AU Li, XH
   Chen, L
   Li, S
   Zhou, X
AF Li, Xiaohan
   Chen, Lu
   Li, Shuang
   Zhou, Xiang
TI Depth segmentation in real-world scenes based on U-V disparity analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth scene segmentation; U-V disparity map; Projection characteristics
   analysis; Object detection; RANSAC algorithm
ID MOTION
AB Depth segmentation has the challenge of separating the objects from their supporting surfaces in a noisy environment. To address the issue, a novel segmentation scheme based on disparity analysis is proposed. First, we transform a depth scene into the corresponding U-V disparity map. Then, we conduct a region-based detection method to divide the object region into several targets in the processed U-disparity map. Thirdly, the horizontal plane regions may be mapped as slant lines in the V-disparity map, the Random Sample Consensus (RANSAC) algorithm is improved to fit such multiple lines. Moreover, noise regions are reduced by image processing strategies during the above processes. We respectively evaluate our approach on both real-world scenes and public data sets to verify the flexibility and generalization. Sufficient experimental results indicate that the algorithm can efficiently segment and label a full-view scene into a group of valid regions as well as removing surrounding noise regions.
C1 [Li, Xiaohan; Chen, Lu; Li, Shuang; Zhou, Xiang] Xi An Jiao Tong Univ, Sch Mech Engn, 28 Xianning West Rd, Xian 710049, Peoples R China.
   [Zhou, Xiang] Xi An Jiao Tong Univ, Sch Food Equipment Engn & Sci, 28 Xianning West Rd, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Li, XH; Zhou, X (corresponding author), Xi An Jiao Tong Univ, Sch Mech Engn, 28 Xianning West Rd, Xian 710049, Peoples R China.; Zhou, X (corresponding author), Xi An Jiao Tong Univ, Sch Food Equipment Engn & Sci, 28 Xianning West Rd, Xian 710049, Peoples R China.
EM lixiaohan1993@stu.xjtu.edu.cn; zhouxiang@xjtu.edu.cn
RI Li, Xiaohan/GRY-1499-2022; xiang, zhou/D-5985-2012
FU National Science and Technology Major Project of China [2017ZX04002001]
FX This work was supported by the National Science and Technology Major
   Project of China (No. 2017ZX04002001).
CR Abramov A., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P457, DOI 10.1109/WACV.2012.6163000
   Alahari K, 2013, IEEE I CONF COMP VIS, P2112, DOI 10.1109/ICCV.2013.263
   Camplani M, 2014, J VIS COMMUN IMAGE R, V25, P122, DOI 10.1016/j.jvcir.2013.03.009
   Chang HH, 2009, NEUROIMAGE, V47, P122, DOI 10.1016/j.neuroimage.2009.03.068
   Chen YB, 2013, J VIS COMMUN IMAGE R, V24, P829, DOI 10.1016/j.jvcir.2013.05.010
   Cinque L, 2015, LECT NOTES COMPUT SC, V9280, P56, DOI 10.1007/978-3-319-23234-8_6
   Dai YR, 2013, IEEE INT VEH SYM, P1137, DOI 10.1109/IVS.2013.6629619
   Danielczuk M, 2019, IEEE INT CONF ROBOT, P7283, DOI [10.1109/icra.2019.8793744, 10.1109/ICRA.2019.8793744]
   Deng J, 2019, OPT LASER ENG, V122, P284, DOI 10.1016/j.optlaseng.2019.06.016
   Du H, 2019, MULTIMED TOOLS APPL, V78, P12125, DOI 10.1007/s11042-018-6736-4
   Fan R., 2019, IEEE T IMAGE PROCESS
   Feng SJ, 2018, OPT LASER ENG, V103, P127, DOI 10.1016/j.optlaseng.2017.12.001
   Frick A, 2009, 3DTV CONF, P45
   Gao Y, 2011, IEEE INT VEH SYM, P957, DOI 10.1109/IVS.2011.5940425
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guindon B, 2017, CAN J REMOTE SENS, V43, P48, DOI 10.1080/07038992.2017.1259557
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Harakeh A, 2015, IEEE INT C INT ROBOT, P695, DOI 10.1109/IROS.2015.7353448
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Hu ZC, 2005, 2005 IEEE Intelligent Vehicles Symposium Proceedings, P48
   Hu ZC, 2005, Fifth International Conference on 3-D Digital Imaging and Modeling, Proceedings, P204
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Karpinsky N, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.2.024105
   Kolmogorov V, 2005, PROC CVPR IEEE, P407
   Labayrade R, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P646
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Leng JX, 2020, IEEE T INTELL TRANSP, V21, P1560, DOI 10.1109/TITS.2019.2909275
   Li T. T., 2010, 2010 IEEE 16 INT S H, P1, DOI DOI 10.1109/IWISA.2010.5473428
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Schwarz M, 2018, INT J ROBOT RES, V37, P437, DOI 10.1177/0278364917713117
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Mendes CCT, 2016, IEEE INT CONF ROBOT, P3174, DOI 10.1109/ICRA.2016.7487486
   Wang L, 2012, INT J COMPUT VISION, V97, P104, DOI 10.1007/s11263-011-0471-x
   Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9
   Wei Y, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P262, DOI 10.1109/ACPR.2017.106
   Weinmann M., ISPRS INT ARCH PHOT, VXL, P121
   Yin W, 2019, OPT EXPRESS, V27, P2411, DOI 10.1364/OE.27.002411
   Zanuttigh P., 2016, TIME OF FLIGHT STRUC, DOI DOI 10.1007/978-3-319-30973-6
   Zhang YG, 2018, IEEE T IMAGE PROCESS, V27, P2176, DOI 10.1109/TIP.2018.2792910
   Zhang YH, 2018, PROC CVPR IEEE, P6810, DOI 10.1109/CVPR.2018.00712
NR 41
TC 6
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102920
DI 10.1016/j.jvcir.2020.102920
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200005
DA 2024-07-18
ER

PT J
AU Li, Q
   Li, LL
   Zhong, J
   Huang, LF
AF Li, Qing
   Li, Lili
   Zhong, Jiang
   Huang, L. Frank
TI Real-time sepsis severity prediction on knowledge graph deep learning
   networks for the intensive care unit
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep neural networks; Sepsis; Intensive care units; Clinical
   informatics; Illness severity prediction; Knowledge graph
ID CHRONIC HEALTH EVALUATION; ACUTE PHYSIOLOGY; SEPTIC SHOCK; MORTALITY;
   CLASSIFICATION; SYSTEM; APACHE; MODEL; SCORE
AB Sepsis is the third-highest mortality disease in intensive care units (ICUs). In this paper, we proposed a deep learning model for predicting the severity of sepsis patients. Most existing models based on attention mechanisms do not fully utilize knowledge graph based information for different organ systems, such that might constitute crucial features for predicting the severity of sepsis patients. Therefore, we have employed a medical knowledge graph as a reliable and robust source of side information. End-to-end neural networks that incorporate analyses of various organ systems simultaneously and intuitively were developed in the proposed model to reflect upon the condition of patients in a timely fashion. We have developed a pre-training technique in the proposed model to combine it with labeled data by multi-task learning. Experimental results on realworld clinical datasets, MIMIC-III and eIR, demonstrate that our model outperforms state-of-the-art models in predicting the severity of sepsis patients.
C1 [Li, Qing; Huang, L. Frank] Cincinnati Childrens Hosp Med Ctr, Div Expt Hematol & Canc Biol, Brain Tumor Ctr, Cincinnati, OH 45229 USA.
   [Li, Lili] Chongqing Univ, Sch Civil Engn, Chongqing, Peoples R China.
   [Zhong, Jiang] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
C3 Cincinnati Children's Hospital Medical Center; Chongqing University;
   Chongqing University
RP Huang, LF (corresponding author), Cincinnati Childrens Hosp Med Ctr, Div Expt Hematol & Canc Biol, Brain Tumor Ctr, Cincinnati, OH 45229 USA.
EM Frank.Huang@cchmc.org
CR [Anonymous], 2017, ARXIV170307771
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, ARXIV170106675
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 2016, SECONDARY ANAL ELECT, DOI DOI 10.1007/978-3-319-43742-2_20
   [Anonymous], 2019, ARXIV190111504
   Byrne L, 2017, ANN INTENSIVE CARE, V7, DOI 10.1186/s13613-016-0231-8
   Caruana R, 1996, ADV NEUR IN, V8, P959
   Che ZP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24271-9
   Chen WT, 2018, IEEE DATA MINING, P917, DOI 10.1109/ICDM.2018.00111
   Collins FS, 2015, NEW ENGL J MED, V372, P793, DOI 10.1056/NEJMp1500523
   Cooper GF, 1997, ARTIF INTELL MED, V9, P107, DOI 10.1016/S0933-3657(96)00367-3
   Dabek F, 2015, LECT NOTES ARTIF INT, V9250, P252, DOI 10.1007/978-3-319-23344-4_25
   Ghassemi M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P75, DOI 10.1145/2623330.2623742
   Gotts JE, 2016, BMJ-BRIT MED J, V353, DOI 10.1136/bmj.i1585
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hammerla NY, 2015, AAAI CONF ARTIF INTE, P1742
   Henry J, 2016, ONC DATA BRIEF, V35, P1
   Huang L, 2014, BIOINFORMATICS, V30, P228, DOI 10.1093/bioinformatics/btu278
   Johnson A. E., 2017, MACH LEARN HEALTHC C, P361
   Johnson AEW, 2018, CRIT CARE MED, V46, P494, DOI 10.1097/CCM.0000000000002965
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Johnson AEW, 2013, CRIT CARE MED, V41, P1711, DOI 10.1097/CCM.0b013e31828a24fe
   KNAUS WA, 1981, CRIT CARE MED, V9, P591, DOI 10.1097/00003246-198108000-00008
   KNAUS WA, 1991, CHEST, V100, P1619, DOI 10.1378/chest.100.6.1619
   KNAUS WA, 1992, CHEST, V102, P1920, DOI 10.1016/S0012-3692(16)40910-4
   Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5
   LeGall JR, 1996, JAMA-J AM MED ASSOC, V276, P802, DOI 10.1001/jama.276.10.802
   LEGALL JR, 1993, JAMA-J AM MED ASSOC, V270, P2957, DOI 10.1001/jama.270.24.2957
   Lipton ZC, 2016, Machine Learning for Healthcare
   Liu Q, 2019, GENES-BASEL, V10, DOI 10.3390/genes10080602
   Liu V, 2014, JAMA-J AM MED ASSOC, V312, P90, DOI 10.1001/jama.2014.5804
   Marik PE, 2015, ACTA ANAESTH SCAND, V59, P561, DOI 10.1111/aas.12479
   McCullagh P, 2019, GEN LINEAR MODELS, DOI DOI 10.1201/9780203753736
   Nemati S, 2018, CRIT CARE MED, V46, P547, DOI [10.1097/CCM.0000000000002936, 10.1097/ccm.0000000000002936]
   Oellrich A, 2016, BRIEF BIOINFORM, V17, P819, DOI 10.1093/bib/bbv083
   Purushotham S., 2017, Variational recurrent adversarial deep domain adaptation
   Saeed M, 2011, CRIT CARE MED, V39, P952, DOI 10.1097/CCM.0b013e31820a92c6
   Shann F, 1997, INTENS CARE MED, V23, P201, DOI 10.1007/s001340050317
   Singer M, 2016, JAMA-J AM MED ASSOC, V315, P801, DOI 10.1001/jama.2016.0287
   Vaswani A, 2017, ADV NEUR IN, V30
   Vincent JL, 2006, CRIT CARE MED, V34, P344, DOI 10.1097/01.CCM.0000194725.48928.3A
   Vincent JL, 1996, INTENS CARE MED, V22, P707, DOI 10.1007/BF01709751
   Waechter J, 2014, CRIT CARE MED, V42, P2158, DOI 10.1097/CCM.0000000000000520
   Wang S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003729
   Wang S, 2016, IEEE T KNOWL DATA EN, V28, P3191, DOI 10.1109/TKDE.2016.2605687
   Weng W.-H., 2017, ARXIV171200654
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
NR 52
TC 11
Z9 11
U1 5
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102901
DI 10.1016/j.jvcir.2020.102901
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400014
DA 2024-07-18
ER

PT J
AU Chen, YM
   Yu, L
   Wang, HK
   Li, TS
   Wang, SW
AF Chen, Yamei
   Yu, Li
   Wang, Hongkui
   Li, Tiansong
   Wang, Shengwei
TI A novel fast intra mode decision for versatile video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile video coding; Intra mode decision; Mode correlation; Sorted
   candidate list; Early termination
ID CU SIZE DECISION; HEVC; ALGORITHM
AB The latest video coding standard Versatile Video Coding (VVC) obtains superior coding efficiency compared to the High Efficiency Video Coding (HEVC), which is achieved by incorporating more effective and complex new coding tools. In this paper, we propose a novel fast intra mode decision algorithm for VVC, including following two strategies: (1) the correlation between the optimal modes of the adjacent blocks and the modes selected in the rough modes decision (RMD) process is analyzed and applied to reduce the modes in the candidate list; (2) modes in the candidate list are sorted in ascending order according to the modes' cost calculated in the RMD process. An early termination method is proposed for terminating the optimal prediction mode decision process based on this new order early. These two strategies are incorporated into intra coding to reduce the coding complexity. Since these two strategies do not add any additional computational complexity, the proposed fast algorithm can achieve more complexity reduction. The experimental results show that the complexity reduction of the proposed algorithm is up to 44.74% compared to VVC reference software VTM2.0, and averagely 30.59% encoding time saving with 0.86% BDBR increase. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Chen, Yamei; Yu, Li; Wang, Hongkui; Li, Tiansong; Wang, Shengwei] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Yu, L (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
EM ymchen_hust@hust.edu.cn; hustlyu@hust.edu.cn; hkwang@hust.edu.cn;
   tiansongli@hust.edu.cn; kadinwan-g@hust.edu.cn
RI Wang, HK W/GQQ-8378-2022
FU National Natural Science Foundation of China [61871437]; Natural Science
   Foundation of Hubei Province of China [2019CFA022]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61871437 and the Natural Science
   Foundation of Hubei Province of China under Grant 2019CFA022.
CR Bjontegaard G., 2001, Document VCEG-M33
   Bossen F., 2020, JVETT0003
   Bross B., 2018, JOINT VIDEO EXPERTS
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Duanmu F, 2016, IEEE J EM SEL TOP C, V6, P517, DOI 10.1109/JETCAS.2016.2597698
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Q, 2016, IEEE T MULTIMEDIA, V18, P379, DOI 10.1109/TMM.2015.2512799
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laude T., 2016, IEEE PICT COD S PCS, P1
   Lei M, 2019, IEEE IMAGE PROC, P4120, DOI [10.1109/ICIP.2019.8803421, 10.1109/icip.2019.8803421]
   Li TY, 2017, IEEE INT CON MULTI, P1255, DOI 10.1109/ICME.2017.8019316
   Ma X., 2018, JOINT VIDEO EXPERTS
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Miso Park, 2015, Journal of Advances in Computer Networks, V3, P162, DOI 10.7763/JACN.2015.V3.160
   Pakdaman F, 2017, MULTIMED TOOLS APPL, V76, P9891, DOI 10.1007/s11042-016-3584-y
   Piao Y., 2018, JCT VC ISO IEC ITU T
   Ruiz D, 2016, SIGNAL PROCESS-IMAGE, V44, P12, DOI 10.1016/j.image.2016.03.002
   Said A, 2016, IEEE IMAGE PROC, P534, DOI 10.1109/ICIP.2016.7532414
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Suehring K., 2018, VVC TEST MODEL VTM R
   Suhring K., 2016, JOINT VIDEO EXPERTS
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yu XY, 2015, IEEE IMAGE PROC, P1285, DOI 10.1109/ICIP.2015.7351007
   Yuan H, 2017, IEEE T MULTIMEDIA, V19, P1416, DOI 10.1109/TMM.2017.2669858
   Yuan H, 2010, OPT ENG, V49, DOI 10.1117/1.3377968
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2018, IEEE T CIRC SYST VID, V28, P3208, DOI 10.1109/TCSVT.2017.2747659
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao Y., 2018, DOCUMENT JVET K0137
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
NR 38
TC 18
Z9 19
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102849
DI 10.1016/j.jvcir.2020.102849
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400011
DA 2024-07-18
ER

PT J
AU Su, SZ
   Fang, XJ
   Yang, GM
   Ge, B
   Zheng, P
AF Su, Shuzhi
   Fang, Xianjin
   Yang, Gaoming
   Ge, Bin
   Zheng, Ping
TI Clustering adaptive canonical correlations for high-dimensional
   multi-modal data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Canonical correlation analysis; Joint dimension reduction; Clustering
   adaptive; High-dimensional data
ID RECOGNITION; ALGORITHMS; REDUCTION; FRAMEWORK
AB Multi-modal canonical correlation analysis (MCCA) is an important joint dimension reduction method and has been widely applied to clustering tasks of multi-modal data. MCCA-based clustering is usually dimension reduction of high-dimensional data followed by clustering of low-dimensional data. However, the two-stage clustering is difficult to ensure the adaptability of dimension reduction and clustering, which will affect the final clustering performance. To solve the issue, we propose a novel clustering adaptive multi-modal canonical correlations (CAMCCs) method, which constructs a unified optimization model of multi-modal correlation learning and clustering. The method not only realizes discriminant learning of correlation projection directions under unsupervised cases, but also is able to directly obtain class labels of multi-modal data. Additionally, the method also realizes out-of-sample extension in class labels. Solutions of CAMCCs are optimized by an iterative way, and we analyze its convergence. Extensive experimental results on various datasets have demonstrated the effectiveness of the method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Su, Shuzhi; Fang, Xianjin; Yang, Gaoming; Ge, Bin; Zheng, Ping] Anhui Univ Sci & Technol, Coll Comp Sci & Engn, Huainan 232001, Anhui, Peoples R China.
C3 Anhui University of Science & Technology
RP Fang, XJ (corresponding author), Anhui Univ Sci & Technol, Coll Comp Sci & Engn, Huainan 232001, Anhui, Peoples R China.
EM sushuzhi@foxmail.com; xjfang@aust.edu.cn; gmyang@aust.edu.cn;
   bge@aust.edu.cn; pzheng@aust.edu.cn
RI wang, shuo/KCL-3379-2024
OI Yang, Gaoming/0000-0002-7666-1038
FU National Natural Science Foundation of China [61806006, 61572034,
   61240023]; Natural Science Research Project of Colleges and Universities
   in Anhui Province [KJ2018A0083]; Anhui Natural Science Foundation
   [1808085MG221]; Youth Science Research Project of Anhui University of
   Science Technology [QN2017208]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61806006, 61572034 and 61240023), the Natural Science
   Research Project of Colleges and Universities in Anhui Province (Grant
   No. KJ2018A0083), Anhui Natural Science Foundation (Grant No.
   1808085MG221), and Youth Science Research Project of Anhui University of
   Science & Technology (Grant No. QN2017208).
CR Asif U, 2018, IEEE T PATTERN ANAL, V40, P2051, DOI 10.1109/TPAMI.2017.2747134
   De la Torre F., 2006, P 23 INT C MACH LEAR, P241, DOI DOI 10.1145/1143844.1143875
   Desai N, 2018, PATTERN RECOGN LETT, V111, P101, DOI 10.1016/j.patrec.2018.04.038
   Ding C., 2007, P 24 INT C MACH LEAR, P521
   Fahad A, 2014, IEEE T EMERG TOP COM, V2, P267, DOI 10.1109/TETC.2014.2330519
   Gao L, 2018, IEEE T IMAGE PROCESS, V27, P1951, DOI 10.1109/TIP.2017.2765820
   Guo X, 2018, PATTERN RECOGN, V81, P36, DOI 10.1016/j.patcog.2018.03.013
   Han L, 2018, NEUROCOMPUTING, V275, P1087, DOI 10.1016/j.neucom.2017.09.045
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hong K, 2018, PATTERN RECOGN, V77, P140, DOI 10.1016/j.patcog.2017.12.013
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hou CP, 2015, IEEE T NEUR NET LEAR, V26, P1287, DOI 10.1109/TNNLS.2014.2337335
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Li M, 2015, IEEE T NEUR NET LEAR, V26, P152, DOI 10.1109/TNNLS.2014.2359798
   Liu HF, 2017, IEEE T KNOWL DATA EN, V29, P1129, DOI 10.1109/TKDE.2017.2650229
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Long Y, 2018, INFORM SCIENCES, V430, P634, DOI 10.1016/j.ins.2017.10.042
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Qin JH, 2017, IEEE T CYBERNETICS, V47, P772, DOI 10.1109/TCYB.2016.2526683
   Shen XB, 2018, J VIS COMMUN IMAGE R, V53, P161, DOI 10.1016/j.jvcir.2018.03.004
   Shen XB, 2015, NEURAL PROCESS LETT, V42, P301, DOI 10.1007/s11063-014-9358-5
   Shen XB, 2014, J VIS COMMUN IMAGE R, V25, P1894, DOI 10.1016/j.jvcir.2014.09.004
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Su SZ, 2018, SIGNAL PROCESS-IMAGE, V60, P173, DOI 10.1016/j.image.2017.10.005
   Su SZ, 2016, J VIS COMMUN IMAGE R, V41, P47, DOI 10.1016/j.jvcir.2016.09.004
   Su SZ, 2016, INFRARED PHYS TECHN, V78, P233, DOI 10.1016/j.infrared.2016.08.010
   Su SZ, 2016, J VIS COMMUN IMAGE R, V36, P69, DOI 10.1016/j.jvcir.2016.01.007
   Suganya R., 2012, INT J SCI RES PUBLIC, V2, P1
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Trigeorgis G, 2018, IEEE T PATTERN ANAL, V40, P1128, DOI 10.1109/TPAMI.2017.2710047
   Wang S, 2016, J VIS COMMUN IMAGE R, V35, P209, DOI 10.1016/j.jvcir.2015.12.001
   Wang S, 2016, NEUROCOMPUTING, V171, P425, DOI 10.1016/j.neucom.2015.06.043
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   Xu Linli, 2005, ADV NEURAL INFORM PR, V17
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yang ZS, 2018, NEUROIMAGE, V169, P240, DOI 10.1016/j.neuroimage.2017.12.025
   Yuan YH, 2014, PATTERN RECOGN, V47, P3907, DOI 10.1016/j.patcog.2014.06.016
   Zhou F, 2016, IEEE T PATTERN ANAL, V38, P279, DOI 10.1109/TPAMI.2015.2414429
NR 40
TC 4
Z9 4
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102815
DI 10.1016/j.jvcir.2020.102815
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400015
DA 2024-07-18
ER

PT J
AU Sun, Z
   Hu, ZP
   Zhao, MY
   Li, SF
AF Sun, Zhe
   Hu, Zheng-ping
   Zhao, Mengyao
   Li, Shufang
TI Multi-scale active patches fusion based on spatiotemporal LBP-TOP for
   micro-expression recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Micro-expression; Multi-scale active patches; Weighted sparse
   representation; LBP-TOP
AB Micro-expressions are spontaneous emotions appearing on a face that is hard to conceal and thus making them different from normal facial expressions both in duration and subtlety. This paper investigates a challenging issue in micro-expression, where not all facial regions contribute equally to effective representation. Consequently, we proposed a multi-scale active patches fusion-based spatiotemporal LBP-TOP descriptor that considers the active contributions for different region area in faces. For the feature procedure, we exploit the average value of all patches under each scale to obtain the threshold that selectively fuses the local and global features. On the other hand, an improved weighted sparse representation based dual augmented Lagrange multiplier is adopted for the classification to remit the problem of sparse coefficients obtained by the traditional sparse representation algorithm. We conduct comprehensive experiments on CASME II and SAMM datasets and the accuracies respectively reach 77.30% and 58.82% using LOSO cross-validation. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Sun, Zhe; Hu, Zheng-ping; Zhao, Mengyao; Li, Shufang] Yanshan Univ, Dept Informat Sci & Engn, Qinhuangdao 066000, Hebei, Peoples R China.
   [Li, Shufang] Hebei Univ Environm Engn, Dept Informat Engn, Qinhuangdao 066000, Hebei, Peoples R China.
C3 Yanshan University; Hebei University of Environmental Engineering
RP Hu, ZP (corresponding author), Yanshan Univ, Dept Informat Sci & Engn, Qinhuangdao 066000, Hebei, Peoples R China.
EM hzp_ysu@163.com
FU National Natural Science Foundation of China [61071199, 61771420];
   National Natural Science Foundation of Hebei Province [F2020203064];
   China Postdoctoral Science Foundation [2018M641674]; Doctoral Foundation
   in Yanshan University [BL18033]
FX This work is supported by the National Natural Science Foundation of
   China under Grants 61071199 and 61771420, the National Natural Science
   Foundation of Hebei Province under Grants F2020203064, the China
   Postdoctoral Science Foundation funded project under Grants 2018M641674
   and the Doctoral Foundation in Yanshan University under Grants BL18033.
CR Andreani R, 2008, SIAM J OPTIMIZ, V18, P1286, DOI 10.1137/060654797
   [Anonymous], 2016, 2016 INT C ADV COMP
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Duan XD, 2016, NEUROCOMPUTING, V217, P27, DOI 10.1016/j.neucom.2016.03.090
   Fan ZZ, 2015, NEUROCOMPUTING, V151, P304, DOI 10.1016/j.neucom.2014.09.035
   Gonçalves H, 2014, IEEE IMAGE PROC, P4907, DOI 10.1109/ICIP.2014.7025994
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Jain D.K., 2018, PATTERN RECOGN LETT, P1
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Li X., 2017, IEEE Transactions on Affective Computing
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Liong ST, 2015, LECT NOTES COMPUT SC, V9009, P644, DOI 10.1007/978-3-319-16631-5_47
   Liu Y., 2018, IEEE T CONTR SYST T, V12, P254, DOI [10.1109/taffc.2018.2854166, DOI 10.1109/TCST.2018.2884226]
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lu H, 2018, SIGNAL PROCESS-IMAGE, V67, P108, DOI 10.1016/j.image.2018.05.014
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Meng HY, 2016, IEEE T CYBERNETICS, V46, P916, DOI 10.1109/TCYB.2015.2418092
   Mohanty A, 2018, PATTERN RECOGN, V79, P97, DOI 10.1016/j.patcog.2018.01.035
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103
   Perveen N, 2018, IEEE T IMAGE PROCESS, V27, P5575, DOI 10.1109/TIP.2018.2856373
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Xia Z., 2018, 2018 8 INT C IMAGE P, P1, DOI DOI 10.1109/IPTA.2018.8608119
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Zarbakhsh P, 2018, SIGNAL IMAGE VIDEO P, V12, P1611, DOI 10.1007/s11760-018-1318-5
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 41
TC 6
Z9 6
U1 1
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102862
DI 10.1016/j.jvcir.2020.102862
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000007
DA 2024-07-18
ER

PT J
AU Wu, MY
   Ting, PW
   Tang, YH
   Chou, ET
   Fu, LC
AF Wu, Min-Yu
   Ting, Pai-Wen
   Tang, Ya-Hui
   Chou, En-Te
   Fu, Li-Chen
TI Hand pose estimation in object-interaction based on deep learning for
   virtual reality applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand pose estimation; Deep learning; Convolutional neural network;
   Spherical part model
AB Hand Pose Estimation aims to predict the position of joints on a hand from an image, and it has become popular because of the emergence of VR/AR/MR technology. Nevertheless, an issue surfaces when trying to achieve this goal, since a hand tends to cause self-occlusion or external occlusion easily as it interacts with external objects. As a result, there have been many projects dedicated to this field for a better solution of this problem. This paper develops a system that accurately estimates a hand pose in 3D space using depth images for VR applications. We propose a data-driven approach of training a deep learning model for hand pose estimation with object interaction. In the convolutional neural network (CNN) training procedure, we design a skeleton-difference loss function, which effectively can learn the physical constraints of a hand. Also, we propose an object-manipulating loss function, which considers knowledge of the hand-object interaction, to enhance performance.
   In the experiments we have conducted for hand pose estimation under different conditions, the results validate the robustness and the performance of our system and show that our method is able to predict the joints more accurately in challenging environmental settings. Such appealing results may be attributed to the consideration of the physical joint relationship as well as object information, which in turn can be applied to future VR/AR/MR systems for more natural experience. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wu, Min-Yu; Ting, Pai-Wen; Tang, Ya-Hui; Chou, En-Te; Fu, Li-Chen] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Fu, Li-Chen] Natl Taiwan Univ, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Fu, LC (corresponding author), Natl Taiwan Univ, Dept Elect Engn & Comp Sci & Informat Engn, Taipei, Taiwan.
EM lichen@ntu.edu.tw
FU Joint Research Center for AI Technology and All Vista Healthcare under
   Ministry of Science and Technology of Taiwan; Center for Artificial
   Intelligence AMP; Advanced Robotics, National Taiwan University
   [108-2634-F-002-016, 108-2634-F-002-017]
FX This research was supported by the Joint Research Center for AI
   Technology and All Vista Healthcare under Ministry of Science and
   Technology of Taiwan, and Center for Artificial Intelligence & Advanced
   Robotics, National Taiwan University, under the grant numbers of
   108-2634-F-002-016 and 108-2634-F-002-017.
CR Chen T.-Y., 2017, IEEE INT C ROB AUT I
   Chen TY, 2016, INT C PATT RECOG, P615, DOI 10.1109/ICPR.2016.7899702
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Draelos M, 2015, IEEE IMAGE PROC, P2520, DOI 10.1109/ICIP.2015.7351256
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Ge LH, 2019, IEEE T PATTERN ANAL, V41, P956, DOI 10.1109/TPAMI.2018.2827052
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krainin M, 2011, INT J ROBOT RES, V30, P1311, DOI 10.1177/0278364911403178
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kyriazis N, 2014, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2014.438
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Oberweger M., 2015, Hands deep in deep learning for hand pose estimation, P21, DOI DOI 10.1177/0093650215617505
   Oberweger M, 2020, IEEE T PATTERN ANAL, V42, P1898, DOI 10.1109/TPAMI.2019.2907951
   Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379
   Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483
   Panteleris P., 2015, BRIT MACH VIS C
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero J, 2010, IEEE INT CONF ROBOT, P458, DOI 10.1109/ROBOT.2010.5509753
   Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450
   Sridhar S, 2016, LECT NOTES COMPUT SC, V9906, P294, DOI 10.1007/978-3-319-46475-6_19
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Tang DH, 2015, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2015.380
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tekin B, 2019, PROC CVPR IEEE, P4506, DOI 10.1109/CVPR.2019.00464
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Pham TH, 2015, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2015.7298898
   Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4
   Tzionas D, 2015, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2015.90
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Ye Q, 2016, LECT NOTES COMPUT SC, V9912, P346, DOI 10.1007/978-3-319-46484-8_21
   Yuan SX, 2018, PROC CVPR IEEE, P2636, DOI 10.1109/CVPR.2018.00279
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 38
TC 26
Z9 28
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102802
DI 10.1016/j.jvcir.2020.102802
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900017
DA 2024-07-18
ER

PT J
AU Zhao, L
   Li, ZH
   Men, CG
   Liu, YM
AF Zhao, Li
   Li, Zhihui
   Men, Chaoguang
   Liu, Yongmei
TI Superpixels extracted via region fusion with boundary constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Superpixel; Initial segmentation; Edge closing; Gaussian belief
   propagation; Region fusion
ID SEGMENTATION; CONVERGENCE; SHIFT
AB In this paper, we present an accurate superpixel algorithm by region fusion with boundary constraint (RFBC). Superpixels with regular shape and high boundary adherence can be generated in weak boundary and complex texture regions through our algorithm. RFBC includes two steps which are initial segmentation and region fusion respectively. In initial segmentation, broken Canny edges are connected through edge closing algorithm. Subsequently, the closed Canny edges and SLIC superpixel edges are combined together to form the incipient superpixels. In region fusion, gray Gaussian distribution and adjacent relation are used as priori to compute the degree of similarity across incipient superpixels in GBP algorithm. For concreteness, the information of similarity is propagated between regions and the most similar regions are fused, which are accomplished alternatingly to preserve accurate boundaries. Extensive experiments on the Berkeley segmentation benchmark show that the proposed algorithm outperforms the most state-of-the-art algorithms. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhao, Li; Li, Zhihui; Men, Chaoguang; Liu, Yongmei] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Men, CG (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM zhaoli54@hrbeu.edu.cn; lizhihui@hrbeu.edu.cn; menchaoguang@hrbeu.edu.cn;
   liuyongmei@hrbeu.edu.cn
OI zhao, Li/0000-0003-2956-3539
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Aksac A, 2017, PATTERN RECOGN, V66, P268, DOI 10.1016/j.patcog.2017.01.010
   [Anonymous], 2009, IEEE I CONF COMP VIS, DOI 10.1109/ICCV.2009.5459175
   Bauchet JP, 2018, PROC CVPR IEEE, P3146, DOI 10.1109/CVPR.2018.00332
   Bishop C. M., 2006, PATTERN RECOGN
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Hsu CY, 2012, INT CONF SIGN PROCES, P1, DOI 10.1109/ICoSP.2012.6491517
   Lee SH, 2017, PROC CVPR IEEE, P5863, DOI 10.1109/CVPR.2017.621
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232
   Liu MY, 2011, PROC CVPR IEEE
   Liu ZQ, 2014, IEEE J OCEANIC ENG, V39, P788, DOI 10.1109/JOE.2013.2285658
   Malioutov DM, 2006, J MACH LEARN RES, V7, P2031
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Moallemi CC, 2009, IEEE T INFORM THEORY, V55, P2413, DOI 10.1109/TIT.2009.2016055
   Moore AP, 2010, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2010.5539890
   Peng JT, 2016, IEEE T CYBERNETICS, V46, P1616, DOI 10.1109/TCYB.2015.2453091
   Peng JT, 2016, IEEE T CIRC SYST VID, V26, P917, DOI 10.1109/TCSVT.2015.2430631
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Schick A, 2012, INT C PATT RECOG, P930
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Shen JB, 2017, IEEE T IMAGE PROCESS, V26, P4911, DOI 10.1109/TIP.2017.2722691
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T CIRC SYST VID, V24, P1088, DOI 10.1109/TCSVT.2014.2302545
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Su QL, 2015, IEEE T SIGNAL PROCES, V63, P1144, DOI 10.1109/TSP.2015.2389755
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vargas-Muñoz JE, 2019, IEEE T IMAGE PROCESS, V28, P3477, DOI 10.1109/TIP.2019.2897941
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wang H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9030031
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Zhang YX, 2017, IEEE T CIRC SYST VID, V27, P1502, DOI 10.1109/TCSVT.2016.2539839
   Zhang YH, 2011, IEEE I CONF COMP VIS, P1387, DOI 10.1109/ICCV.2011.6126393
NR 39
TC 4
Z9 4
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102743
DI 10.1016/j.jvcir.2019.102743
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200015
DA 2024-07-18
ER

PT J
AU Cai, CC
   Xu, HH
AF Cai, Chongchao
   Xu, Huahu
TI A topic sentiment based method for friend recommendation in online
   social networks via matrix factorization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sentiment analysis; Matrix factorization; Social network; Recommendation
   system
ID TRUST
AB Data sparsity and prediction quality have been recognized as the crucial challenges in recommender system. With the expansion of social network data, social network analysis is becoming more and more important. Traditional Recommendation System assumes that users are independent and distributed equally, which ignores the social interaction or connection among users. In order to solve the prediction quality of friend recommendation in social networks, a user recommendation algorithm for social networks based on sentiment analysis and matrix factorization is proposed in this paper. This method is based on the traditional matrix factorization model. By integrating Sentiment (S), Important (I) and Objective (O) of user topic content in the social network, this paper proposes the approach base on sentiment analysis and matrix factorization to solve the poor prediction accuracy by employing social network. SIO model solves the problem that users in social networks can't score the content of topics. Usertopic matrix is constructed by SIO model. Combining the SIO model with matrix factorization, algorithm called SIO-TMF algorithm is proposed. Applying this method on social network, comparing with some traditional recommendation algorithms from four aspects: accuracy, diversity, novelty and coverage, the experimental results show that the proposed method improves the prediction quality of recommender system. (C) 2019 Published by Elsevier Inc.
C1 [Cai, Chongchao; Xu, Huahu] Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
   [Cai, Chongchao] Huzhou Vocat & Tech Coll, Coll Logist & Informat Engn, Huzhou, Peoples R China.
C3 Shanghai University; Huzhou Vocational & Technical College
RP Xu, HH (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
CR [Anonymous], 2016, 30 AAAI C ART INT
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Chen JL, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P201, DOI 10.1145/1518701.1518735
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Fan C., 2018, LATENT VARIABLE BAYE, P971
   Fan M., 2014, COMPUTER SCI
   Ganu G., 2009, 12 INT WORKSH WEB DA
   Groh G., 2012, SOCIAL RECOMMENDER S, P3, DOI 10.1007/978-3-642-25694-3_l
   Gurini D.F., 2017, FUTURE GENERAT COMPU
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774
   Koren Y., 2008, ACM SIGKDD INT C KNO
   Lin Li, 2018, CHIN J COMPUT, V427, P131
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu Q, 2016, IEEE DATA MINING, P1053, DOI [10.1109/ICDM.2016.0135, 10.1109/ICDM.2016.13]
   Massa P, 2004, LECT NOTES COMPUT SC, V2995, P221
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Mukherjee S, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P47
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Sriman B, 2019, J VIS COMMUN IMAGE R, V62, P23, DOI 10.1016/j.jvcir.2019.04.007
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wang ML, 2016, SOFT COMPUT, V20, P3981, DOI 10.1007/s00500-015-1734-1
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Zhang Tong, 2004, P 21 INT C MACH LEAR, P116, DOI DOI 10.1145/1015330.1015332
NR 25
TC 6
Z9 6
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102657
DI 10.1016/j.jvcir.2019.102657
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700001
DA 2024-07-18
ER

PT J
AU Peng, SN
   Dong, Y
   Wang, WS
   Hu, JY
   Dong, WY
AF Peng Shuna
   Dong Yang
   Wang Weisha
   Hu Jieyi
   Dong Weiyang
TI The affective facial recognition task: The influence of cognitive styles
   and exposure times
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Pattern recognition; Cognitive style; Face emotion
ID FACE-RECOGNITION; MEMORY; INHIBITION; ACTIVATION; RETRIEVAL; STIMULI
AB The main task of emotional facial recognition is to understand human emotion expression through the recognition of facial expressions, so as to achieve more effective communication and interpersonal communication. Therefore, facial recognition plays an important role in people's daily lives. In addition, the research of facial recognition is also helpful to understand the human perception processing mode, and promote the development of pattern recognition, cognitive science, neural network and other fields. With the development of cognitive science, facial recognition technology has been continuously improved, and emotional facial recognition tasks have received attention in the fields of pattern recognition and artificial intelligence, and have become a research hotspot. Among them, pattern recognition is a cognitive system applied to many fields. For the first time, we confirmed the effects of facial memory time, personal cognitive style, and emotions associated with the target face on facial recognition patterns. This study measured the impact of time, cognitive style, and emotional type of 62 qualified college students. The research results show that cognitive style and facial emotional content are of great significance for face pattern recognition. Specifically, students classified as "dependent" have achieved good results in face pattern recognition, and positive and negative strong emotional faces have left behind those who show neutral emotions. A deeper impression. Finally, an unusual phenomenon was discovered, which indicates that the shorter the time spent on the face of the memory, the higher the recognition score. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Peng Shuna] Jiaying Univ, Dept Psychol, Meizhou, Peoples R China.
   [Dong Yang; Hu Jieyi] City Univ Hong Kong, Dept Social & Behav Sci, Hong Kong, Peoples R China.
   [Wang Weisha] Univ Southampton, Dept Southampton Business Sch, Southampton, Hants, England.
   [Dong Weiyang] Taiyuan Normal Univ, Dept Biol, Taiyuan, Shanxi, Peoples R China.
C3 Jiaying University; City University of Hong Kong; University of
   Southampton; Taiyuan Normal University
RP Dong, Y (corresponding author), City Univ Hong Kong, Dept Social & Behav Sci, Hong Kong, Peoples R China.
EM yangdong3-c@my.cityu.edu.hk; wjd@jyu.edu.cn; jieyihu2-c@my.cityu.edu.hk
RI Wang, Weisha/GZH-2459-2022
OI DONG, Yang/0000-0002-6020-3251; Hu, Jieyi/0000-0003-1852-178X; Wang,
   Weisha/0000-0002-2985-3416
FU Faculty of Social Science of Meizhou City [mz-ybxm-2019018]
FX There is no conflict of interest. The work described in this paper was
   supported by the Faculty of Social Science of Meizhou City for 2019
   project (Project ID: mz-ybxm-2019018).
CR Adolphs R, 2002, J COGNITIVE NEUROSCI, V14, P1264, DOI 10.1162/089892902760807258
   González-Garrido AA, 2015, NEUROSCI LETT, V585, P43, DOI 10.1016/j.neulet.2014.11.014
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Balconi M, 2003, INT J PSYCHOPHYSIOL, V49, P67, DOI 10.1016/S0167-8760(03)00081-3
   Batty M, 2003, COGNITIVE BRAIN RES, V17, P613, DOI 10.1016/S0926-6410(03)00174-5
   Berger C, 2015, J ALZHEIMERS DIS, V44, P439, DOI 10.3233/JAD-141848
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Braver T.S., 2007, VARIATION WORKING ME, P76, DOI DOI 10.1093/ACPROF:OSO/9780195168648.003.0004
   Chen O., 2017, Educational Psychology Review, V29, P393, DOI DOI 10.1007/S10648-016-9359-1
   Decety J, 2003, CONSCIOUS COGN, V12, P577, DOI 10.1016/S1053-8100(03)00076-X
   Florin D., 2013, FRONT PSYCHOL, V4
   Happé F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   HERMANS D, 1994, COGNITION EMOTION, V8, P515, DOI 10.1080/02699939408408957
   Hubl D, 2001, NEUROIMAGE, V13, pS1058
   Hur Juyoen, 2017, Cogn Emot, V31, P1294, DOI 10.1080/02699931.2016.1213703
   Jiang Changhao, CHINESE J CLIN PSYCH, V16, P237
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Klein RM, 2006, PSYCHON B REV, V13, P294, DOI 10.3758/BF03193846
   Lane RD, 2000, PSYCHOSOM MED, V62, P492, DOI 10.1097/00006842-200007000-00007
   Macrae CN, 2002, PSYCHOL SCI, V13, P194, DOI 10.1111/1467-9280.00436
   NEELY JH, 1977, J EXP PSYCHOL GEN, V106, P226, DOI 10.1037/0096-3445.106.3.226
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Thomas L.A., 2010, DEVELOPMENTAL SCI, V10, P547
   Wen He, 2001, PSYCHOL SCI, V24, P631
   Zhang Y, 2011, VISION RES, V51, P147, DOI 10.1016/j.visres.2010.10.022
   Zhou Hongzhen, 2005, RES APPL EVENT RELAT, V25, P921
   Zhou Q, 2008, CHILD DEV, V79, P493, DOI 10.1111/j.1467-8624.2008.01139.x
NR 30
TC 1
Z9 1
U1 3
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102674
DI 10.1016/j.jvcir.2019.102674
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA JU0WA
UT WOS:000501398700022
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Li, JY
   Wu, L
   Wen, GQ
   Li, Z
AF Li, Jiaye
   Wu, Lin
   Wen, Guoqiu
   Li, Zhi
TI Exclusive feature selection and multi-view learning for Alzheimer's
   Disease
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Alzheimer's Disease; Multi-view; Exclusive lasso learning; Feature
   selection; Sparse learning
ID UNSUPERVISED FEATURE-SELECTION; REGRESSION
AB In Alzheimer's Disease (AD) studies, high dimension and small sample size have been always an issue and it is common to apply a dimension reduction method to predict the early diagnosis of AD. In this paper, we propose a multi-view feature selection algorithm embedded with exclusive lasso learning and sparse learning. It extracts the feature subsets that best represent the symptoms of patients through feature selection, so as to reduce the dimension and achieve a better diagnosis rate. Firstly, in order to overcome the limitation of non-overlapping, the features under different view are clustered by fuzzy C-means clustering. Then, the exclusive group lasso learning is performed according to the clustering results and each view is sparsely learned through the l(2,1)-norm, resulting in better removal of redundant features. Finally, the results of each view are combined to obtain the final features subsets. This exclusive lasso learning combined through multiple views is novel in clinical practice and can effectively target AD. At the same time, the experimental results show that our method could achieve better results compared to its competing methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Jiaye; Wu, Lin; Wen, Guoqiu; Li, Zhi] Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China.
   [Li, Jiaye; Wu, Lin; Wen, Guoqiu; Li, Zhi] Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Wen, GQ (corresponding author), Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China.
EM guoqiuwen@mailbox.gxnu.edu.cn
RI Li, Zhi/AAQ-6566-2020; Wu, Lin/GOE-3613-2022; Wang, Guang/JFS-8374-2023
OI Wu, Lin/0000-0002-3188-0640; 
FU China Key Research Program [2016YFB1000905]; Key Program of the National
   Natural Science Foundation of China [61836016]; Natural Science
   Foundation of China [61876046, 61573270, 81701780, 61672177]; Project of
   Guangxi Science and Technology [GuiKeAD17195062]; Guangxi Natural
   Science Foundation [2015GXNSFCB139011, 2017GXNSFBA198221]; Guangxi
   Collaborative Innovation Center of Multi-Source Information Integration
   and Intelligent Processing; Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents; Research Fund of Guangxi
   Key Lab of Multisource Information Mining Security [18-A-0101]; PhD
   research startup foundation of Guangxi Normal University [2017BQ17];
   Innovation Project of Guangxi Graduate Education [YCSW2019073]
FX Jiaye Li and Lin Wu contributed equally to this work. This work is
   partially supported by the China Key Research Program (Grant No:
   2016YFB1000905), the Key Program of the National Natural Science
   Foundation of China (Grant No: 61836016), the Natural Science Foundation
   of China (Grants No: 61876046, 61573270, 81701780 and 61672177), the
   Project of Guangxi Science and Technology (GuiKeAD17195062), the Guangxi
   Natural Science Foundation (Grant No: 2015GXNSFCB139011,
   2017GXNSFBA198221), the Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing; the
   Guangxi High Institutions Program of Introducing 100 High-Level Overseas
   Talents, the Research Fund of Guangxi Key Lab of Multisource Information
   Mining & Security (18-A-0101), the PhD research startup foundation of
   Guangxi Normal University (Grants No: 2017BQ17), and Innovation Project
   of Guangxi Graduate Education (grants No: YCSW2019073).
CR [Anonymous], 2018, ACM T GRAPH, DOI DOI 10.1145/3137609
   Bin Y., 2018, IEEE T CYBERNET
   Chen X., 2017, IJCAI, V2017, P1525
   Cheng B, 2019, BRAIN IMAGING BEHAV, V13, P138, DOI 10.1007/s11682-018-9846-8
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Fujimaki, 2014, INT C MACH LEARN, P503
   Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5
   Gao Y, 2005, BIOINFORMATICS, V21, P3970, DOI 10.1093/bioinformatics/bti653
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Ji SW, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P407
   Jie B, 2013, LECT NOTES COMPUT SC, V8149, P275, DOI 10.1007/978-3-642-40811-3_35
   Karpagam S.N., 2019, J COMPUT THEOR NANOS, V16, P682
   Kong D., 2014, ADV NEURAL INFORM PR, P1655
   Kuang LQ, 2019, HUM BRAIN MAPP, V40, P1062, DOI 10.1002/hbm.24383
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Li J, 2016, PROCEEDINGS OF 2016 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2016), P384
   Li Z., 2012, P AAAI C ART INT, P1026
   Liu F, 2014, NEUROIMAGE, V84, P466, DOI 10.1016/j.neuroimage.2013.09.015
   Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154
   Luo X, 2019, IEEE T IMAGE PROCESS, V28, P2962, DOI 10.1109/TIP.2019.2892703
   Mao Q, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P765, DOI 10.1145/2783258.2783309
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nunomura A, 1999, J NEUROSCI, V19, P1959
   Ruiz E., 2018, J ALZHEIMERS DIS, P1
   Shao WX, 2016, IEEE DATA MINING, P1203, DOI [10.1109/ICDM.2016.134, 10.1109/ICDM.2016.0160]
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang RL, 2018, WORLD WIDE WEB, V21, P1745, DOI 10.1007/s11280-017-0508-3
   Wang RL, 2018, WORLD WIDE WEB, V21, P1575, DOI 10.1007/s11280-017-0510-9
   Wang RL, 2018, PATTERN RECOGN LETT, V109, P120, DOI 10.1016/j.patrec.2018.01.013
   Wang SH, 2015, AAAI CONF ARTIF INTE, P470
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou K, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081372
   Zhou P, 2017, KNOWL-BASED SYST, V136, P187, DOI 10.1016/j.knosys.2017.09.006
   ZHOU X, 2018, GRAPH CONVOLUTIONAL
   Zhou Y., 2010, JMLR WORKSHOP C P, P988
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2014.395
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P264, DOI 10.1007/978-3-319-46720-7_31
   Zu C, 2018, I S BIOMED IMAGING, P1542, DOI 10.1109/ISBI.2018.8363867
NR 51
TC 10
Z9 10
U1 3
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102605
DI 10.1016/j.jvcir.2019.102605
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600034
DA 2024-07-18
ER

PT J
AU Kaljahi, MA
   Shivakumara, P
   Idris, MYI
   Anisi, MH
   Blumenstein, M
AF Kaljahi, Maryam Asadzadeh
   Shivakumara, Palaiahnakote
   Idris, Mohd Yamani Idna
   Anisi, Mohammad Hossein
   Blumenstein, Michael
TI A new image size reduction model for an efficient visual sensor network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual sensor network; Image size reduction; Inter-redundancy;
   Intra-redundancy; Energy consumption; Quality of the image
ID PARALLEL FRAMEWORK; TRACKING
AB Image size reduction for energy-efficient transmission without losing quality is critical in Visual Sensor Networks (VSNs). The proposed method finds overlapping regions using camera locations, which eliminate unfocussed regions from the input images. The sharpness for the overlapped regions is estimated to find the Dominant Overlapping Region (DOR). The proposed model partitions further the DOR into sub-DORs according to capacity of the cameras. To reduce noise effects from the sub-DOR, we propose to perform a Median operation, which results in a Compressed Significant Region (CSR). For non-DOR, we obtain Sobel edges, which reduces the size of the images down to ambinary form. The CSR and Sobel edges of the non-DORs are sent by a VSN. Experimental results and a comparative study with the state-of-the-art methods shows that the proposed model outperforms the existing methods in terms of quality, energy consumption and network lifetime. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kaljahi, Maryam Asadzadeh; Shivakumara, Palaiahnakote; Idris, Mohd Yamani Idna] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Anisi, Mohammad Hossein] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
   [Blumenstein, Michael] UTS, Sydney, NSW, Australia.
C3 Universiti Malaya; University of Essex; University of Technology Sydney
RP Idris, MYI (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.; Anisi, MH (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
EM asadzadeh@um.edu.my; shiva@um.edu.my; yamani@um.edu.my;
   m.anisi@essex.ac.uk; michael.blumenstein@uts.edu.au
RI Anisi, Mohammad Hossein/L-3718-2016; Palaiahnakote,
   Shivakumara/ITU-6488-2023; Idris, Mohd. Yamani Idna/GPP-2401-2022;
   Idris, Mohd. Yamani Idna/B-5232-2010; Palaiahnakote,
   Shivakumara/B-6261-2013
OI Anisi, Mohammad Hossein/0000-0001-8414-2708; Idris, Mohd. Yamani
   Idna/0000-0003-4894-0838; 
FU Faculty of Computer System and Information Technology at the University
   of Malaya [RP036B-15AET, PG063-2016 A.]
FX This research work was supported by the Faculty of Computer System and
   Information Technology at the University of Malaya under grant numbers:
   RP036B-15AET and PG063-2016 A.
CR Abdul-Salaam G, 2017, IEEE SENS J, V17, P2289, DOI 10.1109/JSEN.2017.2665663
   Al-Ariki H. D. E., 2016, WIREL NETW, P1
   Bhandary V, 2016, J ENG-NY, V2016, DOI 10.1155/2016/9608757
   Cagri Gungor V., 2013, IND WIRELESS SENSOR
   Cosar S, 2015, COMPUT VIS IMAGE UND, V139, P40, DOI 10.1016/j.cviu.2015.04.010
   Cosar S, 2014, J VIS COMMUN IMAGE R, V25, P864, DOI 10.1016/j.jvcir.2014.02.004
   Costa D. G., 2017, ELECT ELECT ENG INFO
   Felemban E, 2014, AD HOC NETW, V23, P65, DOI 10.1016/j.adhoc.2014.06.003
   Imara M., 2013, P NESEA
   Imran A, 2010, PROCEEDINGS OF THE 5TH FRONTIERS IN BIOMEDICAL DEVICES CONFERENCE AND EXPOSITION, 2010, P1
   Jayashhree A., 2012, COMPUT APPL, V46
   Kaljahi MA, 2019, MULTIMED TOOLS APPL, V78, P5791, DOI 10.1007/s11042-018-6151-x
   Khursheed K., 2012, 2012 IEEE 8th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob 2012), P705, DOI 10.1109/WiMOB.2012.6379153
   Lin K, 2011, IEEE SYST J, V5, P495, DOI 10.1109/JSYST.2011.2165599
   Liu JB, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906148
   Lu XY, 2011, IMAGE VISION COMPUT, V29, P104, DOI 10.1016/j.imavis.2010.08.001
   Mammeri Abdelhamid, 2012, ISRN Sensor Networks, DOI 10.5402/2012/760320
   Nandgini S. A., 2016, P SIGN PROC NETW WIS
   Navimipour N. J., 2016, WIRELESS PERS COMMUN, V1-28, P2016
   Nirmala D E., 2013, Electronics, Computing and Communication Technologies (CONECCT), International Conference on, IEEE, P1
   Ozger M, 2016, IEEE T MOBILE COMPUT, V15, P2221, DOI 10.1109/TMC.2015.2493526
   Padwalker U., 2013, COMPUT APPL
   Peak J., 2015, IEEE SYST J, V99, P1
   Redondi A., 2016, IEEE T MOBILE COMPUT, P15
   Rein S, 2016, J VIS COMMUN IMAGE R, V40, P418, DOI 10.1016/j.jvcir.2016.07.006
   Sastra N. P., 2015, J NETW
   Shen H, 2016, J NETW COMPUT APPL, V71, P30, DOI 10.1016/j.jnca.2016.05.013
   Sofi SA, 2016, P INT C WIR COMM SIG
   Sukumaran AN, 2015, COMPUT ELECTR ENG, V44, P51, DOI 10.1016/j.compeleceng.2015.02.008
   Wang D., 2010, IEEE T WIREL COMMUN, V8, P757
   Wang H., 2007, P TEL C GLOBECOM
   Wang P, 2007, IEEE ICC, P3616, DOI 10.1109/ICC.2007.596
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yap F.G.H., 2015, IEEE SYST J, VPP, P1
   ZainEldin H, 2015, AIN SHAMS ENG J, V6, P481, DOI 10.1016/j.asej.2014.11.001
NR 37
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102573
DI 10.1016/j.jvcir.2019.102573
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Nan, LD
   Rui, H
   Qiang, L
   Ning, ZN
   Rui, G
   Yi, L
AF Nan, Liu Dun
   Rui, Hou
   Qiang, Li
   Ning, Zhao Ning
   Rui, Ge
   Yi, Lu
TI Research on fuzzy enhancement algorithms for infrared image recognition
   quality of power internet of things equipment based on membership
   function
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Power internet of things; Image recognition quality; Membership
   function; Image enhancement; Quality model
AB With the development of society, the demand for power is increasing, but the inefficiency of the original power grid has gradually become an obstacle to social development, so it is urgent to reform the power grid, and the power Internet of things is an important means of power reform. Effective infrared image recognition of power Internet of Things equipment can achieve real-time monitoring of equipment status. The quality of image recognition is not only related to recognition methods, but also to the quality of the image itself. In order to improve the quality of image recognition, an image enhancement algorithm based on membership function is proposed in this paper. Firstly, piecewise linear transformation is introduced, and on the basis of it, an improved piecewise linear transformation method is proposed. Secondly, an image enhancement algorithm based on membership function is proposed by improving the traditional fuzzy enhancement method. Finally, based on the image enhancement algorithm of membership function, an improved piecewise linear transformation method is introduced to form an image blur enhancement system. Through the simulation experiment, we can find that the two image enhancement algorithms are improved in this paper, which can enhance the image enhancement effect of the original two enhancement algorithms, and the image fuzzy enhancement system composed of two improved enhancement methods can enhance the image enhancement effect again, and effectively improve the infrared image recognition quality of power Internet of things equipment. (C) 2019 Published by Elsevier Inc.
C1 [Nan, Liu Dun; Rui, Hou; Ning, Zhao Ning] North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
   [Nan, Liu Dun] North China Elect Power Univ, Beijing Key Lab New Energy & Low Carbon Dev, Beijing 102206, Peoples R China.
   [Qiang, Li] China Acad Elect Power Sci Co Ltd, Beijing 100192, Peoples R China.
   [Rui, Ge] Natl Elect Power Dispatching & Control Ctr, Beijing 100031, Peoples R China.
   [Yi, Lu] Sichuan Elect Power Co, Chengdu 610041, Peoples R China.
C3 North China Electric Power University; North China Electric Power
   University
RP Rui, H (corresponding author), North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
EM liudunnan@163.com; hankrui201905@126.com; liq@epri.sgcc.com.cn;
   ge-rui@sgcc.com.cn
FU Key Projects of Philosophy and Social Sciences Research, Ministry of
   Education [18JZD032]; Fundamental Research Funds for the Central
   Universities [JB2019078]; Science and Technology Project of State Grid
   Corporation of China [SGTYHT/16-JS-198]
FX Key Projects of Philosophy and Social Sciences Research, Ministry of
   Education: 18JZD032.; Fundamental Research Funds for the Central
   Universities: JB2019078.; Science and Technology Project of State Grid
   Corporation of China: SGTYHT/16-JS-198.
CR ARGOUL F, 1989, PHYS LETT A, V135, P327, DOI 10.1016/0375-9601(89)90003-0
   Artioli M, 2004, IEEE T INSTRUM MEAS, V53, P933, DOI 10.1109/TIM.2004.831465
   Carron G, 2001, IEEE T CONSUM ELECTR, V47, P63, DOI 10.1109/30.920421
   Chojnowski M., 2017, REUMATOLOGIA, V1, P46
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He G, 2010, IBM J RES DEV, V54, DOI 10.1147/JRD.2010.2085461
   Hiramoto M., 2010, SYST COMPUT JPN, V38, P15
   Hu QR, 2015, IEEE T EDUC, V58, P32, DOI 10.1109/TE.2014.2321529
   [黄宇晴 Huang Yuqing], 2017, [北京航空航天大学学报, Journal of Beijing University of Aeronautics and Astronautics], V43, P592
   Kazemi MS, 2016, APPL SOFT COMPUT, V40, P507, DOI 10.1016/j.asoc.2015.11.021
   Kilic N, 2010, J MED SYST, V34, P1083, DOI 10.1007/s10916-009-9326-1
   KRAUSE U, 1993, NONLINEAR ANAL-THEOR, V20, P855, DOI 10.1016/0362-546X(93)90074-3
   López-Valcarce R, 2012, IEEE J SEL AREA COMM, V30, P1566, DOI 10.1109/JSAC.2012.120923
   Martinez F., 2013, PSYCHON SCI, V22, P124
   Monacelli Claudia., 2001, The Translator, V7, P265, DOI DOI 10.1080/13556509.2001.10799105
   Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464
   Shih F. Y., 1992, Journal of Visual Communication and Image Representation, V3, P104, DOI 10.1016/1047-3203(92)90009-I
   Shuman DI, 2016, IEEE T SIGNAL PROCES, V64, P2119, DOI 10.1109/TSP.2015.2512529
   Ushakov VM, 2009, RUSS J NONDESTRUCT+, V45, P627, DOI 10.1134/S1061830909090058
   Watunyuta W, 1997, OPT COMMUN, V140, P110, DOI 10.1016/S0030-4018(97)00009-6
   Yuan B, 2018, J SEMICOND, V39, DOI 10.1088/1674-4926/39/9/094008
   Yung DE, 2017, ENDOSCOPY, V49, P258, DOI 10.1055/s-0042-122015
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang D., 2016, MULTIMED TOOLS APPL, V76, P1
   Zuo JL, 2010, BLOOD PRESS MONIT, V15, P268, DOI 10.1097/MBP.0b013e3283386866
NR 25
TC 5
Z9 5
U1 2
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 359
EP 367
DI 10.1016/j.jvcir.2019.06.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600033
DA 2024-07-18
ER

PT J
AU Aguilar, E
   Bolaños, M
   Radeva, P
AF Aguilar, Eduardo
   Bolanos, Marc
   Radeva, Petia
TI Regularized uncertainty-based multi-task learning model for food
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-task models; Uncertainty modeling; Convolutional neural networks;
   Food image analysis; Food recognition; Food group recognition;
   Ingredients recognition; Cuisine recognition
AB Food plays an important role in several aspects of our daily life. Several computer vision approaches have been proposed for tackling food analysis problems, but very little effort has been done in developing methodologies that could take profit of the existent correlation between tasks. In this paper, we propose a new multi-task model that is able to simultaneously predict different food-related tasks, e.g. dish, cuisine and food categories. Here, we extend the homoscedastic uncertainty modeling to allow single-label and multi-label classification and propose a regularization term, which jointly weighs the tasks as well as their correlations. Furthermore, we propose a new Multi-Attribute Food dataset and a new metric, Multi-Task Accuracy. We prove that using both our uncertainty-based loss and the class regularization term, we are able to improve the coherence of outputs between different tasks. Moreover, we outperform the use of task-specific models on classical measures like accuracy or F-1. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Aguilar, Eduardo] Univ Catolica Norte, Dept Ingn Sistemas & Computac, Ave Angamos 0610, Antofagasta, Chile.
   [Aguilar, Eduardo; Bolanos, Marc; Radeva, Petia] Univ Barcelona, Dept Matemat & Informat, Gran Via Corts Catalanes 585, E-08007 Barcelona, Spain.
   [Bolanos, Marc; Radeva, Petia] Comp Vis Ctr, Bellaterra 08193, Barcelona, Spain.
C3 Universidad Catolica del Norte; University of Barcelona; Centre de Visio
   per Computador (CVC)
RP Aguilar, E (corresponding author), Univ Catolica Norte, Dept Ingn Sistemas & Computac, Ave Angamos 0610, Antofagasta, Chile.
EM eaguilar02@ucn.cl
RI Aguilar Torres, Eduardo/JDD-8273-2023
OI Bolanos, Marc/0000-0001-9838-1435; Aguilar, Eduardo/0000-0002-2463-0301
FU Nestore; La MaratoTV3 [20141510]; CERCA Programme/Generalitat de
   Catalunya; CONICYT Becas Chile; FPU fellowship [FPU15/01347]; ICREA
   Academia 2014; NVIDIA Corporation;  [TIN2015-66951-C2-1-R];  [2017 SGR
   1742]
FX This work was partially funded by TIN2015-66951-C2-1-R, 2017 SGR 1742,
   Nestore, 20141510 (La MaratoTV3) and CERCA Programme/Generalitat de
   Catalunya. E. Aguilar acknowledges the support of CONICYT Becas Chile
   and M. Bolanos acknowledges the support of an FPU fellowship (Ref.
   FPU15/01347). P. Radeva is partially supported by ICREA Academia 2014.
   We acknowledge the support of NVIDIA Corporation with the donation of
   the Titan Xp GPU.
CR Aguilar E, 2018, IEEE T MULTIMEDIA, V20, P3266, DOI 10.1109/TMM.2018.2831627
   Aguilar E, 2018, LECT NOTES COMPUT SC, V10672, P339, DOI 10.1007/978-3-319-74727-9_40
   Aguilar E, 2017, LECT NOTES COMPUT SC, V10485, P213, DOI 10.1007/978-3-319-68548-9_20
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P 19 INT C HUM COMP
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2015, P IEEE INT C MULT EX
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], ARXIV170507115
   [Anonymous], 2017, P 26 INT C WORLD WID
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], TECH REP
   [Anonymous], 2018, CORR
   Bolaños M, 2017, LECT NOTES COMPUT SC, V10590, P394, DOI 10.1007/978-3-319-70742-6_37
   Bolaños M, 2016, INT C PATT RECOG, P3140, DOI 10.1109/ICPR.2016.7900117
   Bosch M, 2011, IEEE IMAGE PROC, P1789, DOI 10.1109/ICIP.2011.6115809
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen M, 2009, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2009.5413511
   Ege T, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P198, DOI 10.23919/MVA.2017.7986835
   Farinella GM, 2016, COMPUT BIOL MED, V77, P23, DOI 10.1016/j.compbiomed.2016.07.006
   Güngör C, 2017, SIG PROCESS COMMUN
   Hassannejad H, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P41, DOI 10.1145/2986035.2986042
   Joutou T, 2009, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2009.5413400
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Kendall A., 2017, Advances in Neural Information Processing Systems, V30, P5574
   Li SJ, 2014, IEEE COMPUT SOC CONF, P488, DOI 10.1109/CVPRW.2014.78
   Li X, 2015, JMLR WORKSH CONF PRO, V38, P635
   Liu C, 2016, LECT NOTES COMPUT SC, V9677, P37, DOI 10.1007/978-3-319-39601-9_4
   Liu WW, 2015, AAAI CONF ARTIF INTE, P2800
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Singla A, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P3, DOI 10.1145/2986035.2986039
   Su H, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P565, DOI 10.1145/2638728.2641335
   Waxman A, 2004, PUBLIC HEALTH NUTR, V7, P381, DOI 10.1079/PHN2004623
   Wu H, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P172, DOI 10.1145/2964284.2967205
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang XJ, 2016, J COMPUT SCI TECH-CH, V31, P489, DOI 10.1007/s11390-016-1642-6
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 48
TC 28
Z9 30
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 360
EP 370
DI 10.1016/j.jvcir.2019.03.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000039
DA 2024-07-18
ER

PT J
AU Chang, YF
AF Chang, Yanfen
TI Research on de-motion blur image processing based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Image processing; Blurred image
ID RECOGNITION
AB In recent years, with the rapid development of computer technology and network technology, computer vision has been widely used in various scientific fields. Human motion recognition, as an important branch of computer vision, is essentially to classify human motion information in motion images correctly. It has great significance in intelligent monitoring and security, human-computer interaction, motion analysis and other fields. At present, there are still some problems in human motion recognition methods. Firstly, how to extract and characterize the motion information in images has been one of the difficulties in this field; secondly, with the appearance of kinect and other depth cameras, researchers have provided the depth information of human motion images, and how to effectively use these depth information to achieve human motion recognition and classification is also an important research issue; finally, when the amount of sample data is small, how to use the deep learning network model to achieve a higher human motion recognition rate? Based on UTD-MHAD database, this paper studies the human motion recognition of RGB image and depth image captured simultaneously by kinect, and carries out relevant discussion and analysis on the above problems, using micro-inertial sensors (MTi-G-700 developed by Xsens and Android mobile phones, tablets and other personal mobile devices come with MEMS gyroscopes and accelerometers) to correct the image to motion blur, build a new mathematical model, use the inertial data obtained by MIMU in a short time to estimate the position, attitude and speed of camera motion, correct the image pixel position, perform image de-motion blur processing, and then perform image processing such as denoising to solve the image motion blur problem. A new algorithm is developed and its science is verified by MATLAB simulation. (C) 2019 Published by Elsevier Inc.
C1 [Chang, Yanfen] Ningbo Univ Finance & Econ, Sch Informat Engn, Ningbo, Zhejiang, Peoples R China.
C3 Ningbo University of Finance & Economics
RP Chang, YF (corresponding author), Ningbo Univ Finance & Econ, Sch Informat Engn, Ningbo, Zhejiang, Peoples R China.
EM cyf511@163.com
CR Agatonovic-Kustrin S, 2000, J PHARMACEUT BIOMED, V22, P717, DOI 10.1016/S0731-7085(99)00272-1
   Bourlard  H., 1988, BIOL CYBERN, V4
   Cortes  Corinna, 1995, MACH LEARN, V3
   Crawford B., 2014, SCI WORLD J, V2014, P8, DOI DOI 10.1155/2014/189164
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ebrahimi Zade Amir, 2014, Journal of Industrial Engineering International, V10, P185, DOI 10.1007/s40092-014-0076-4
   Gers Felix A., 2000, NEURAL COMPUT, V10
   Guo XF, 2014, FOOD HYDROCOLLOID, V35, P217, DOI 10.1016/j.foodhyd.2013.05.010
   Hinton G. E., 2007, LEARNING MULTIPLE LA, V11
   Hinton Geoffrey E., 2006, NEURAL COMPUT, V7
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   KARNES J, 1977, J NEUROL SCI, V34, P43, DOI 10.1016/0022-510X(77)90090-9
   Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153
   KHOTANZAD A, 1990, PATTERN RECOGN, V23, P1089, DOI 10.1016/0031-3203(90)90005-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le QuocV., 2012, BUILDING HIGH LEVEL
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LIU K, 1993, PATTERN RECOGN, V26, P903, DOI 10.1016/0031-3203(93)90056-3
   Liu  Qingfeng, 2010, INT J PHARM
   McCulloch Warren S., 1990, B MATH BIOL, V1
   Poon TC, 1999, APPL OPTICS, V38, P370, DOI 10.1364/AO.38.000370
   Qian  Ning, 1998, NEURAL NETWORKS
   Qin  Huaili, 2005, POLYMER, V9
   Shaffer S. L., 2002, PHOTOCOLLAGE GENERAT
   Wang ZF, 2007, J FOOD ENG, V79, P502, DOI 10.1016/j.jfoodeng.2006.02.012
   Wang  Zhengfu, 2009, J FOOD ENG
   Xie  Shaobo, 2007, NEOHELICON
   Xie  Shaobo, 2005, POLYMER
   Xie  Shaobo, 2007, COMPOS SCI TECHNOL, V11
   Xie  Shaobo, 2009, MATER LETT
   Xie  Shaobo, 2005, POLYM INT
   Xie  Shaobo, 2012, INT SOC SCI J, P207
   Xie  Shaobo, 2015, ENERGY, V14
   Zhang BH, 2014, FOOD RES INT, V62, P326, DOI 10.1016/j.foodres.2014.03.012
   Zhang L, 2015, J POWER SOURCES, V274, P899, DOI 10.1016/j.jpowsour.2014.10.170
   Zhang  Qing, 2012, FOOD CHEM
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
NR 37
TC 15
Z9 16
U1 3
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 371
EP 379
DI 10.1016/j.jvcir.2019.02.030
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000040
DA 2024-07-18
ER

PT J
AU Ji, CB
   Duan, GJ
   Ma, HY
   Zhang, L
   Xu, HY
AF Ji, CuiBin
   Duan, Guijiang
   Ma, HanYong
   Zhang, Long
   Xu, HuanYun
TI Modeling of image, video and text fusion quality data packet system for
   aerospace complex products based on business intelligence
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Balanced scorecard; Business intelligence; Data warehouse; Quality data
   package; Polymorphic data; Complex product
AB For the construction of image, video and text fusion quality data packet system during the whole life of complex products, a business intelligence-based logic modeling method is proposed in this paper. As the amount of Polymorphic data from multiple distributed sources continues to grow exponentially, automation tools are becoming critical to decision makers. The balanced scorecard method is used as the basis for modeling, and the traditional dimensions are modified slightly to meet the requirements of quality data management in aerospace enterprises. A data warehouse with predefined fact and dimension tables is created, and a technical solution is provided to meet the requirements and scales of enterprises. In terms of model applications, any enterprise quality manager can extract value from data in the quality data package system for improvement. Online analytical processing (OLAP) cubes support major tasks, such as key quality feature source tracing and analysis, quality issue data mining and integrated quality data delivery. (C) 2018 Published by Elsevier Inc.
C1 [Ji, CuiBin; Duan, Guijiang] Beihang Univ, Sch Mech Engn & Automat, Beijing, Peoples R China.
   [Ma, HanYong; Zhang, Long; Xu, HuanYun] Hubei Jiangshan Heavy Ind Co Ltd, Xiangyang 441057, Hubei, Peoples R China.
C3 Beihang University
RP Ji, CB (corresponding author), Beihang Univ, Sch Mech Engn & Automat, Beijing, Peoples R China.
EM beginyxgz@163.com
RI DUAN, GUIJIANG/AAC-5629-2022
CR Andreescu A, 2013, INT CONF INFORM ECON, P371
   Baan P., 2013, Enterprise Information Management, P1
   Gao Y., 2017, AEROSPACE IND MANAGE, V01, P21
   Hou Jie, 2016, Computer Integrated Manufacturing Systems, V22, P202, DOI 10.13196/j.cims.2016.01.019
   Hudek M, 2017, TEH VJESN, V24, P821, DOI 10.17559/TV-20160205121415
   Jiang W., 2009, SHIP SCI TECHNOL, V02
   Kimball Ralph, 2013, DATA WAREHOUSE TOOLK
   Kumar N, 2017, 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT)
   Lahrmann G., 2010, 7 C IT AIS ITAIS 201
   Lv H., 2007, THESIS
   Muntean M, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10020335
   Novák V, 2017, P INT CONF STRAT MAN, P445
   Roebuck K, 2012, DATA DEDUPLICATION H
   Wang M., 2012, GROUP TECHNOLOGY PRO, V03
   Xie X., 2016, MOD IND EC INFORM, V08, P111
   Yang Y., 2013, AEROSP MANUF TECHNOL, V04, P55
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zheng Y., 2013, GROUP TECHNOL PROD M, V04, P35
   Zhou X., 2011, MECH SCI TECHNOL, V04, P532
NR 23
TC 0
Z9 0
U1 0
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 439
EP 447
DI 10.1016/j.jvcir.2018.12.053
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600047
DA 2024-07-18
ER

PT J
AU Passos, LA
   de Souza, LA
   Mendel, R
   Ebigbo, A
   Probst, A
   Messmann, H
   Palm, C
   Papa, JP
AF Passos, Leandro A.
   de Souza, Luis A., Jr.
   Mendel, Robert
   Ebigbo, Alanna
   Probst, Andreas
   Messmann, Helmut
   Palm, Christoph
   Papa, Joao Paulo
TI Barrett's esophagus analysis using infinity Restricted Boltzmann
   Machines
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Barrett's esophagus; Infinity Restricted Boltzmann Machines;
   Meta-heuristics; Deep learning
ID NEURAL-NETWORKS; ADENOCARCINOMA; DYSPLASIA; FEATURES
AB The number of patients with Barret's esophagus (BE) has increased in the last decades. Considering the dangerousness of the disease and its evolution to adenocarcinoma, an early diagnosis of BE may provide a high probability of cancer remission. However, limitations regarding traditional methods of detection and management of BE demand alternative solutions. As such, computer-aided tools have been recently used to assist in this problem, but the challenge still persists. To manage the problem, we introduce the infinity Restricted Boltzmann Machines (iRBMs) to the task of automatic identification of Barrett's esophagus from endoscopic images of the lower esophagus. Moreover, since iRBM requires a proper selection of its meta-parameters, we also present a discriminative iRBM fine-tuning using six meta-heuristic optimization techniques. We showed that iRBMs are suitable for the context since it provides competitive results, as well as the meta-heuristic techniques showed to be appropriate for such task. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Passos, Leandro A.; de Souza, Luis A., Jr.] Univ Fed Sao Carlos, UFSCAR, Dept Comp, BR-13565905 Sao Carlos, SP, Brazil.
   [Ebigbo, Alanna; Probst, Andreas; Messmann, Helmut] Klinikum Augsburg III, Med Klin, D-86156 Augsburg, Germany.
   [Mendel, Robert; Palm, Christoph] OTH Regensburg, Ostbayer Tech Hsch Regensburg, Regensburg Med Image Comp ReMIC, D-93053 Regensburg, Germany.
   [Mendel, Robert; Palm, Christoph] OTH Regensburg, Regensburg Ctr Hlth Sci & Technol, D-93053 Regensburg, Germany.
   [Papa, Joao Paulo] Sao Paulo State Univ, UNESP, Dept Comp, BR-17033360 Bauru, Brazil.
C3 Universidade Federal de Sao Carlos; Klinikum Augsburg; Universidade
   Estadual Paulista
RP Papa, JP (corresponding author), Sao Paulo State Univ, UNESP, Dept Comp, BR-17033360 Bauru, Brazil.
EM leandropassosjr@gmail.com; luis.souza@dc.ufscar.br;
   robert.mendel@st.oth-regensburg.de; alana.ebigbo@klinikum-augsburg.de;
   andreas.probst@klinikum-augsburg.de;
   helmut.messmann@klinikum-augsburg.de; christoph.palm@oth-regensburg.de;
   papa@fc.unesp.br
RI Messmann, Helmut/AAB-6758-2020; Palm, Christoph/F-4943-2014; Messmann,
   Helmut/AAQ-3568-2021; Passos, Leandro/AAV-9635-2020; Ebigbo,
   Alanna/ACP-0443-2022; Papa, Joao Paulo/ABC-6283-2020
OI Palm, Christoph/0000-0001-9468-2871; Passos,
   Leandro/0000-0003-3529-3109; Papa, Joao Paulo/0000-0002-6494-7514; Souza
   Jr., Luis Antonio/0000-0002-7060-6097
FU FAPESP [2013/07375-0, 2014/16250-9, 2014/12236-1, 2015/25739-4,
   2016/21243-7]; Capes; CNPq [306166/2014-3, 307066/2017-7];
   Capes/Alexander von Humboldt Foundation [BEX 0581-16-0]; Intel Al
   Academy program under FUNDUNESP [2597.2017]
FX The authors would like to thank FAPESP grants #2013/07375-0,
   #2014/16250-9, #2014/12236-1, #2015/25739-4 and #2016/21243-7, as well
   as Capes, and CNPq grants #306166/2014-3, #307066/2017-7 and
   Capes/Alexander von Humboldt Foundation grant #BEX 0581-16-0. This
   material is based upon work supported in part by funds provided by Intel
   Al Academy program under FUNDUNESP Grant No. 2597.2017.
CR [Anonymous], 2015, P GENETIC EVOLUTIONA
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Côté MA, 2016, NEURAL COMPUT, V28, P1265, DOI 10.1162/NECO_a_00848
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   da Silva LA, 2016, IADIS-INT J COMPUT S, V11, P99
   de Souza LA, 2018, COMPUT BIOL MED, V96, P203, DOI 10.1016/j.compbiomed.2018.03.014
   Dent J, 2011, J GASTROEN HEPATOL, V26, P11, DOI 10.1111/j.1440-1746.2010.06535.x
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fiore U, 2013, NEUROCOMPUTING, V122, P13, DOI 10.1016/j.neucom.2012.11.050
   Geem ZW, 2009, STUD COMPUT INTELL, V191, P113
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Johnston MH, 2005, GASTROINTEST ENDOSC, V62, P842, DOI 10.1016/j.gie.2005.05.008
   Lagergren J., 2010, BMJ, V341
   Larochelle H., 2008, P 25 INT C MACH LEAR, P536
   Larochelle H, 2012, J MACH LEARN RES, V13, P643
   Lepage C, 2008, AM J GASTROENTEROL, V103, P2694, DOI 10.1111/j.1572-0241.2008.02191.x
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mendel R., 2017, BARRETTS ESOPHAGUS A
   Montufar G, 2011, NEURAL COMPUT, V23, P1306, DOI 10.1162/NECO_a_00113
   Overholt BF, 2003, GASTROINTEST ENDOSC, V58, P183, DOI 10.1067/mge.2003.327
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Papa J.P., ARXIV170405174
   Papa JP, 2015, J COMPUT SCI-NETH, V9, P14, DOI 10.1016/j.jocs.2015.04.014
   Papa JP, 2012, PATTERN RECOGN, V45, P512, DOI 10.1016/j.patcog.2011.07.013
   Papa JP, 2016, APPL SOFT COMPUT, V46, P875, DOI 10.1016/j.asoc.2015.08.043
   Passos LA, 2017, SIBGRAPI, P63, DOI 10.1109/SIBGRAPI.2017.15
   Peng X., ARXIV170903239
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Phoa KN, 2016, GUT, V65, P555, DOI 10.1136/gutjnl-2015-309298
   Rodrigues D, 2016, BIO-INSPIRED COMPUTATION AND APPLICATIONS IN IMAGE PROCESSING, P47, DOI 10.1016/B978-0-12-804536-7.00003-X
   Rodrigues D., 2015, Recent Advances in Swarm Intelligence and Evolutionary Computation, P85, DOI [10.1007/978-3-319-13826-8_5, DOI 10.1007/978-3-319-13826-8_5]
   Rosa G., 2016, LEARNING PARAMETERS
   Rosa G, 2015, LECT NOTES COMPUT SC, V9423, P683, DOI 10.1007/978-3-319-25751-8_82
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shaheen NJ, 2009, NEW ENGL J MED, V360, P2277, DOI 10.1056/NEJMoa0808145
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Shi YH, 2011, LECT NOTES COMPUT SC, V6728, P303, DOI 10.1007/978-3-642-21515-5_36
   Souza Jr LA, 2017, Bildverarbeitung Fur die Medizin 2017, P141
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   Tieleman T., 2008, P 25 INT C MACHINE L, V307, P1064, DOI 10.1145/1390156
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
NR 52
TC 10
Z9 10
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 475
EP 485
DI 10.1016/j.jvcir.2019.01.043
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600051
DA 2024-07-18
ER

PT J
AU Halstead, MA
   Denman, S
   Sridharan, S
   Tian, YL
   Fookes, C
AF Halstead, Michael A.
   Denman, Simon
   Sridharan, Sridha
   Tian, YingLi
   Fookes, Clinton
TI Multimodal clothing recognition for semantic search in unconstrained
   surveillance imagery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Soft biometrics; Dempster-Shafer theory; Surveillance; Semantic person
   search
AB To date, surveillance based person search has focused on locating a person of interest from an image query, distinct from the law enforcement task of locating a person from a description.
   In this paper, we introduce a novel probabilistic framework that combines multiple traits whilst incorporating their uncertainty to tackle the emerging challenge: locating a person from a semantic query. In addressing this, we improve clothing texture recognition by leveraging Dempster-Shafer theory against an ensemble of support vector machines; achieving state-of-the-art performance for high and low resolution clothing textures.
   Our proposed person search framework combines information from clothing texture and colour in the torso and leg regions to produce a probabilistic match between unknown subjects and the designated target query. Results are presented on a newly created 520 subject surveillance dataset which is made available to researchers. This multi-modal person search technique achieves promising results for locating target subjects, without the requirement of pre-search target enrollment. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Halstead, Michael A.; Denman, Simon; Sridharan, Sridha; Fookes, Clinton] Queensland Univ Technol, 2 George St, Brisbane, Qld 4000, Australia.
   [Tian, YingLi] CUNY, City Coll, New York, NY 10031 USA.
C3 Queensland University of Technology (QUT); City University of New York
   (CUNY) System; City College of New York (CUNY)
RP Halstead, MA; Denman, S (corresponding author), Queensland Univ Technol, 2 George St, Brisbane, Qld 4000, Australia.
EM m.halstead@qut.edu.au; s.denman@qut.edu.au; s.sridharan@qut.edu.au;
   ytian@ccny.cuny.edu; c.foookes@qut.edu.au
RI TIAN, YI/KHU-9704-2024; Fookes, Clinton/I-9786-2012
OI Sridharan, Sridha/0000-0003-4316-9001; Tian, Yingli/0000-0003-4458-360X
FU Australian Research Council (ARC) [LP140100282]; Australian Research
   Council [LP140100282] Funding Source: Australian Research Council
FX This research was supported by an Australian Research Council (ARC)
   Linkage grant LP140100282. We would also like to acknowledge High
   Performance Computing and Research Support for supplying the computing
   resources.
CR [Anonymous], 2015, PROC CVPR IEEE
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Bertillon A., 1896, Signaletic Instructions Including the Theory and Practice of Anthropometrical Identification
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   Denman S, 2015, PATTERN RECOGN LETT, V68, P306, DOI 10.1016/j.patrec.2015.06.015
   Denman S, 2015, INT CONF ACOUST SPEE, P1568, DOI 10.1109/ICASSP.2015.7178234
   Denman S, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P196, DOI 10.1109/DICTA.2009.38
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Feris R., 2014, P INT C MULT RETR, P153, DOI [10.1145/2578726.2578732, DOI 10.1145/2578726.2578732]
   Halstead M, 2014, INT C PATT RECOG, P4501, DOI 10.1109/ICPR.2014.770
   Hu M, 2012, IET BIOMETRICS, V1, P55, DOI 10.1049/iet-bmt.2011.0004
   Jaha E., 2016, T INFORMAT FORENSICS, P1
   Jain A. K., 2004, INT C BIOM AUTH, P717
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Nguyen K, 2015, IEEE T HUM-MACH SYST, V45, P132, DOI 10.1109/THMS.2014.2361437
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Liang X., 2016, T PAMIDOI, DOI [10.1109/TPAMI.2016.2537339, DOI 10.1109/TPAMI.2016.2537339]
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329
   Park U, 2006, INT C PATT RECOG, P1204
   Perlin HA, 2015, PATTERN RECOGN LETT, V68, P250, DOI 10.1016/j.patrec.2015.07.012
   Rakowsky UK, 2007, INT J RELIAB QUAL SA, V14, P579, DOI 10.1142/S0218539307002817
   Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219
   Samangooei S., 2008, BIOMETRICS THEORY AP
   Satta R, 2014, ADV COMPUT VIS PATT, P371, DOI 10.1007/978-1-4471-6296-4_18
   Thornton J., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P55, DOI 10.1109/THS.2011.6107847
   Vaquero D. A., 2009, WORKSH WACV
   Wang Q, 2017, ADV OPT PHOTONICS, V9, P1, DOI 10.1364/AOP.9.000001
   Yamaguchi K, 2015, IEEE T PATTERN ANAL, V37, P1028, DOI 10.1109/TPAMI.2014.2353624
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang XD, 2014, IEEE T HUM-MACH SYST, V44, P234, DOI 10.1109/THMS.2014.2302814
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
NR 34
TC 4
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 439
EP 452
DI 10.1016/j.jvcir.2018.12.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100043
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, K
AF Kumar, Krishan
TI EVS-DK: Event video skimming using deep keyframe
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Clustering; Deep learning; Event summarization; Highly connected
   subgraph; Key-frames; Video; Graph
ID SYSTEM; GRAPH
AB In this automation era, video surveillance becomes an essential component and omnipresent at ATMs, public places, airports, railways, roadways, etc. There are many challenges to store and access such massive data generated by video surveillance. Therefore, a novel technique is required to manage the comprehensive view of the content. In this work, we propose an event summarization technique using Deep learning framework for monocular videos. A spatiotemporal similarity function is developed to construct a similarity matrix based on the visual features. Video frames are represented by the sparse matrix as graph vertices based on an objective function, where Highly Connected Subgraphs (HCS) are constructed as clusters. Finally, events are obtained from such clusters assuming that the centroid of the cluster is a key-frame of the event. Consequently, this approach does not require assumption to determine the number of clusters. Due to this advantage, users can select the number of keyframes without incurring an extra computational cost. Experimental results on two benchmark datasets show that the proposed model outperforms the state-of-the-art models on Precision and F-measure and also cover the major contents of the original video. (C) 2018 Elsevier Inc, All rights reserved.
C1 [Kumar, Krishan] Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Srinagar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, K (corresponding author), Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Srinagar, India.
EM kkberwal@nituk.ac.in
RI Kumar, Krishan/AAE-1656-2021; Berwal, Krishan/AAC-3473-2020
OI Berwal, Krishan/0000-0002-7068-6541
CR Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   [Anonymous], 1961, Journal of the London Mathematical Society, DOI DOI 10.1112/JLMS/S1-36.1.445
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Ben Aoun N, 2014, J VIS COMMUN IMAGE R, V25, P329, DOI 10.1016/j.jvcir.2013.11.003
   Ben Hamida A, 2016, MULTIMED TOOLS APPL, V75, P17187, DOI 10.1007/s11042-015-2987-5
   Bolaños M, 2018, J VIS COMMUN IMAGE R, V50, P205, DOI 10.1016/j.jvcir.2017.11.022
   Boudechiche DE, 2017, J VIS COMMUN IMAGE R, V49, P14, DOI 10.1016/j.jvcir.2017.07.007
   Chen X, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P315, DOI 10.1145/3077136.3080776
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   CUNNINGHAM WH, 1985, J ACM, V32, P549, DOI 10.1145/3828.3829
   Edmunds T, 2018, J VIS COMMUN IMAGE R, V50, P314, DOI 10.1016/j.jvcir.2017.12.004
   Fan YX, 2018, J VIS COMMUN IMAGE R, V51, P70, DOI 10.1016/j.jvcir.2018.01.002
   Fleck S, 2008, P IEEE, V96, P1698, DOI 10.1109/JPROC.2008.928765
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Hüffner F, 2015, LECT NOTES COMPUT SC, V8939, P254, DOI 10.1007/978-3-662-46078-8_21
   Jiang GY, 2018, J VIS COMMUN IMAGE R, V50, P247, DOI 10.1016/j.jvcir.2017.12.001
   Jiang ZL, 2012, PROC CVPR IEEE, P3418, DOI 10.1109/CVPR.2012.6248082
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Kumar KP, 2017, ADV BUS STRATEGY COM, P1, DOI 10.4018/978-1-5225-1008-6.ch001
   Mehmood I, 2016, NEUROCOMPUTING, V174, P393, DOI 10.1016/j.neucom.2015.05.126
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Norris C., 2009, REV INCREASED USE CC, V419
   OVP, 2016, VID OP PROJ STOR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sargent G, 2016, MULTIMED TOOLS APPL, V75, P9073, DOI 10.1007/s11042-015-2863-3
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Sun ZZ, 2014, MULTIMED TOOLS APPL, V73, P151, DOI 10.1007/s11042-012-1262-2
   TRUBIN VA, 1993, CYBERN SYST ANAL+, V29, P379, DOI 10.1007/BF01125543
   Vijaya Kumar K., 2018, Int. J. of Nanopart. Res., V2, P1
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 38
TC 34
Z9 34
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 345
EP 352
DI 10.1016/j.jvcir.2018.12.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100034
DA 2024-07-18
ER

PT J
AU Mu, N
   Xu, X
   Zhang, XL
AF Mu, Nan
   Xu, Xin
   Zhang, Xiaolong
TI A spatial-frequency-temporal domain based saliency model for low
   contrast video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Low contrast videos; Multimodal fusion; Region
   covariance; Incremental learning
ID LOW-RANK; OBJECT DETECTION; OPTIMIZATION
AB The last few decades have witnessed rapid development of visual saliency detection, as it can detect object-of-interest from clutter environments to substantially facilitate a wide range of applications. However, traditional visual saliency detection models primarily rely on image features, which may face great challenges in low contrast video stream captured from low lighting scenarios. This paper proposes a dynamic multimodal fusion based visual saliency detection model towards low contrast videos, which combines saliency information from spatial, frequency, and temporal domains. In spatial domain, super-pixel covariance is utilized to compute the region dissimilarity under low lighting scenarios; in frequency domain, the amplitude spectrum tuned method is used to suppress the background noise; in temporal domain, the incremental learning is employed to efficiently update background model from high dimensional video streams. Extensive experiments have been conducted to validate the effectiveness of the proposed model. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Mu, Nan; Xu, Xin; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
   [Xu, Xin; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology
RP Xu, X (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
EM xuxin0336@gmail.com
RI Mu, Nan/W-1313-2019; Xu, Xin/JRW-5800-2023; ARSLAN, Okan/AAA-3232-2020;
   ZHANG, XIAOLONG/IZQ-4553-2023
FU Natural Science Foundation of China [61602349, 61440016, 61273225];
   Hubei Chengguang Talented Youth Development Foundation [2015B22];
   Educational Research Project from the Educational Commission of Hubei
   Province [2016234]
FX This work was supported by the Natural Science Foundation of China
   (61602349, 61440016, and 61273225), Hubei Chengguang Talented Youth
   Development Foundation (2015B22), and the Educational Research Project
   from the Educational Commission of Hubei Province (2016234).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Akamine K, 2012, COMPUT J, V55, P3, DOI 10.1093/comjnl/bxq075
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], P IEEE INT C SIGN PR
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], SPIE IS T ELECT IMAG
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen Z, 2016, OPT LASER TECHNOL, V80, P1, DOI 10.1016/j.optlastec.2015.12.013
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P639, DOI 10.1145/3178876.3186145
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Forstner W, 2003, Geodesy-the Challenge of the 3rd Millennium, P299, DOI [10.1007/978-3-662-05296-9_31, DOI 10.1007/978-3-662-05296-9_31]
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo F., 2017, IEEE T CYBERNET, P1
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Huang L, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P218, DOI [10.1109/CIS.2016.0058, 10.1109/CIS.2016.57]
   Huang Z., 2018, IEEE T NEURAL NETWOR, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang P, 2015, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2015.33
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Li J., 2018, IEEE T CYBERNET, P1
   Loy CC., 2012, International symposium on communications control and signal processing p, P1
   Ma C, 2017, IEEE T MULTIMEDIA, V19, P2415, DOI 10.1109/TMM.2017.2694219
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Mu N, 2018, NEURAL COMPUT APPL, V29, P181, DOI 10.1007/s00521-017-2870-6
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Rodriguez P, 2016, J MATH IMAGING VIS, V55, P1, DOI 10.1007/s10851-015-0610-z
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wu Z, 2016, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-40991-7
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xu J, 2015, IEEE MILIT COMMUN C, P157, DOI 10.1109/MILCOM.2015.7357435
   Xu X, 2016, MULTIMED TOOLS APPL, V75, P2667, DOI 10.1007/s11042-015-2570-0
   Xu X, 2015, IEEE IMAGE PROC, P3126, DOI 10.1109/ICIP.2015.7351379
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JR, 2016, 2016 IEEE CHINESE GUIDANCE, NAVIGATION AND CONTROL CONFERENCE (CGNCC), P2473, DOI 10.1109/CGNCC.2016.7829181
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang J, 2018, IEEE SIGNAL PROC LET, V25, P333, DOI 10.1109/LSP.2017.2748604
   Zhang J, 2016, IEEE T NEUR NET LEAR, V27, P1177, DOI 10.1109/TNNLS.2015.2464316
   Zhang yan-bang, 2015, Application Research of Computers, V32, P284, DOI 10.3969/j.issn.1001-3695.2015.01.066
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 58
TC 1
Z9 1
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 79
EP 88
DI 10.1016/j.jvcir.2018.11.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100009
DA 2024-07-18
ER

PT J
AU Chong, SC
   Ong, TS
   Teoh, ABJ
AF Chong, Siew-Chin
   Ong, Thian-Song
   Teoh, Andrew Beng Jin
TI Discriminative kernel-based metric learning for face verification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face verification; Metric learning; Kernel machine; Discriminant
   analysis
ID RECOGNITION; SVM
AB This paper outlines a simplistic formulation for doublet constrained discriminative metric learning framework for face verification. The Mahalanobis distance metric of the framework is formulated by leveraging the within-class scatter matrix of the doublet and a quadratic kernel function. Unlike existing metric learning methods, the proposed framework admits efficient solution attributed to the convexity nature of the kernel machines. We demonstrate three realizations of the proposed framework based on the well-known kernel machine instances, namely Support Vector Machine, Kernel Ridge Regression and Least Squares Support Vector Machine. Due to wide availability of off-the-shelf kernel learner solvers, the proposed method can be easily trained and deployed. We evaluate the proposed discriminative kernel-based metric learning with two types of face verification setup: standard and unconstrained face verification through three benchmark datasets. The promising experimental results corroborate the feasibility and robustness of the proposed framework. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chong, Siew-Chin; Ong, Thian-Song] Multimedia Univ, Fac Informat Sci & Technol, Cyberjaya, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Sch Elect & Elect Engn, Seoul, South Korea.
C3 Multimedia University; Yonsei University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul, South Korea.
EM chong.siew.chin@mmu.edu.my; tsong@mmu.edu.my; bjteoh@yonsei.ac.kr
RI CHONG, SIEW CHIN/B-3508-2010; Teoh, Andrew Beng Jin/F-4422-2010; Ong,
   Thian Song/Q-6932-2018
OI Ong, Thian Song/0000-0002-5867-9517
FU Fundamental Research Grant Scheme (FRGS) of Malaysia [MMUE/140026]
FX This research is supported by Fundamental Research Grant Scheme (FRGS)
   of Malaysia under grants MMUE/140026.
CR Anila S., 2012, GLOBAL J COMPUT SCI
   [Anonymous], 2014, ARXIV150200873
   [Anonymous], 2014, COMPUTER VISION PATT
   [Anonymous], 2009, INT C BIOM
   [Anonymous], P CVPR
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], P ECCV
   [Anonymous], 1994, P NIPS
   [Anonymous], P INT C MS 07 IND 3
   [Anonymous], 2007, CVPR
   Arashloo S., 2013, BIOMETRICS THEORY AP
   Balcan MF, 2008, MACH LEARN, V72, P89, DOI 10.1007/s10994-008-5059-5
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Bellet A., 2013, SURVEY METRIC LEARNI
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen D, 2017, IEEE T PARALL DISTR, V28, P1091, DOI 10.1109/TPDS.2016.2613054
   Chen J. C., 2016, APPL COMP VIS WACV 2
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456
   Davis J., 2007, Information-theoretic metric learning
   Do A. Huyen, 2012, INT C ART INT STAT
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang C., 2011, 115 NEC
   Kan M., 2011, P BRIT MACH VISION, V11, P1
   Kedem D., 2012, Advances in Neural Information Processing Systems, P2573
   Kittler Josef, 2014, IEEE T INF FORENSICS
   Lee Wei-Han., 2016, Springer Information Systems Security and Privacy, V576, P160
   Li H., 2013, Cvpr
   Liu Meizhu, 2012, Comput Vis ECCV, V7575, P646
   Martines A. M., 1998, 24 CVC
   Meng FM, 2013, IEEE T IMAGE PROCESS, V22, P4809, DOI 10.1109/TIP.2013.2278461
   Meng Fanman, 2016, IEEE T CIRCUITS SYST
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Nguyen Hieu V., 2011, P AS C COMP VIS, P709, DOI DOI 10.1007/978-3-642-19309-5_55
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pinto N., 2009, CVPR
   Qi Guo-Jun, 2009, P 26 INT C MACH LEAR
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shen C., 2009, ARXIV09102279
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Suykens Johan, 2003, ESANN 2003, P1
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Vandewalle J, 2002, LEAST SQUARES SUPPOR, DOI DOI 10.1142/5089
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wang F., 2013, ARXIV1305823
   Weinberger K.Q., 2008, Proceedings of the 25th international conference on Machine learning, P1160, DOI DOI 10.1145/1390156.1390302
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wolf Lior, 2008, ECCV
   Xiong T, 2005, IEEE IJCNN, P1455
   Xu Felix, 2015, SPARTANS SINGLE SAMP
   Xu Z., 2012, ARXIV12083422
   Ye J., 2007, P 24 ICML
   Yi Sun, 2013, COMPUTER VISION PATT
   Ying YM, 2012, J MACH LEARN RES, V13, P1
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang P, 2004, INT C PATT RECOG, P176, DOI 10.1109/ICPR.2004.1334050
NR 64
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 207
EP 219
DI 10.1016/j.jvcir.2018.09.017
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500021
DA 2024-07-18
ER

PT J
AU Liu, D
   Wang, YB
   Chen, ZZ
AF Liu, Di
   Wang, Yingbin
   Chen, Zhenzhong
TI Joint foveation-depth just-noticeable-difference model for virtual
   reality environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Just-noticeable-difference; Depth; Foveation; Stereoscopic images;
   Virtual reality environment
ID IMAGE; DISTORTION; MASKING; CONTRAST
AB In this paper, we develop a joint foveation-depth just-noticeable-difference (FD-JND) model to quantify the perceptual redundancy of image in the VR display environment. The proposed FD-JND model is developed with considerations on the effects of both foveation and depth. More specifically, experiments for the VR environment on synthesized stimuli are conducted based on luminance masking and contrast masking and the FD-JND model is developed accordingly. Subjective quality discrimination experiments between the noise contaminated images and original ones validate favorableness of the proposed FD-JND model. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Di; Wang, Yingbin; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM dliu@whu.edu.cn; zzchen@whu.edu.cn
RI Wang, Yingbin/AGA-2216-2022; Chen, Zhenzhong/C-2529-2015
OI Wang, Yingbin/0000-0003-0233-4322; 
FU National Hightech RAMP;D Program of China (863 Program) [2015AA015903];
   National Natural Science Foundation of China [61471273, 61771348]; Wuhan
   Morning Light Plan of Youth Science and Technology [2017050304010302]
FX This work was supported in part by National Hightech R&D Program of
   China (863 Program) under Grant No. 2015AA015903, National Natural
   Science Foundation of China under Grant No. 61471273 and No. 61771348,
   and Wuhan Morning Light Plan of Youth Science and Technology under Grant
   No. 2017050304010302.
CR Alfonso JF, 2007, J CATARACT REFR SURG, V33, P1930, DOI 10.1016/j.jcrs.2007.06.067
   Blake R, 2002, NAT REV NEUROSCI, V3, P13, DOI 10.1038/nrn701
   Chen ZZ, 2006, IEEE T MULTIMEDIA, V8, P1117, DOI 10.1109/TMM.2006.884633
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   De Silva V, 2011, IEEE T MULTIMEDIA, V13, P498, DOI 10.1109/TMM.2011.2129500
   Fernando W. A. C., P IEEE INT C IM PROC, P4013
   Hachicha W, 2013, IEEE IMAGE PROC, P113, DOI 10.1109/ICIP.2013.6738024
   Ho CC, 2005, IEEE T CIRC SYST VID, V15, P1365, DOI 10.1109/TCSVT.2005.856929
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jansen L, 2009, J VISION, V9, DOI 10.1167/9.1.29
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Jung SW, 2013, IEEE T IMAGE PROCESS, V22, P3892, DOI 10.1109/TIP.2013.2263150
   Jung SW, 2012, IEEE T IMAGE PROCESS, V21, P3624, DOI 10.1109/TIP.2012.2191569
   Kyuel T., 1998, IEEE T SYST MAN CYB, V29, P235
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Li X., VIS COMMUN IMAGE PRO, P1
   Li YM, 2016, J VIS COMMUN IMAGE R, V40, P600, DOI 10.1016/j.jvcir.2016.07.025
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   Ma L, 2010, IEEE IMAGE PROC, P2501, DOI 10.1109/ICIP.2010.5649188
   Pelekanos V, 2015, VISION RES, V110, P87, DOI 10.1016/j.visres.2015.02.010
   Schofield AJ, 1999, VISION RES, V39, P2697, DOI 10.1016/S0042-6989(98)00284-3
   Tan E. L., 2015, COMPUTATIONAL MODELS
   WALLACE RS, 1994, INT J COMPUT VISION, V13, P71, DOI 10.1007/BF01420796
   Wang JL, 2012, J EYE MOVEMENT RES, V5
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang SQ, 2016, IEEE T IMAGE PROCESS, V25, P3838, DOI 10.1109/TIP.2016.2573597
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   Wardle S. G., 2010, J VIS, V10, P71
   Wu HR, 2013, P IEEE, V101, P2025, DOI 10.1109/JPROC.2013.2262911
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P4892, DOI 10.1109/TIP.2013.2279934
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
NR 41
TC 6
Z9 6
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 73
EP 82
DI 10.1016/j.jvcir.2018.07.015
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500006
DA 2024-07-18
ER

PT J
AU Ozcinar, C
   Lauga, P
   Valenzise, G
   Dufaux, F
AF Ozcinar, Cagri
   Lauga, Paul
   Valenzise, Giuseppe
   Dufaux, Frederic
TI Spatio-temporal constrained tone mapping operator for HDR video
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range; Video compression; Tone mapping operator; Convex
   optimization
ID HIGH-DYNAMIC-RANGE; IMAGE; REPRODUCTION; VISIBILITY; FUTURE
AB With the growing popularity of high dynamic range (HDR) imaging, efficient compression techniques are demanded, as HDR video entails typically higher raw data rate than traditional video. For this purpose, we introduce a hybrid spatially and temporally constrained content-adaptive tone mapping operator (TMO) to convert the input HDR video into a tone mapped video sequence, which is then encoded using the high efficiency video coding (HEVC) standard. The proposed TMO simultaneously exploits infra-frame spatial redundancies and preserves inter-frame temporal coherence of the tone mapped video sequence. Extensive experimental results show that the developed spatio-temporal TMO (ST-TMO) solution yields higher coding performance than existing frame-by-frame TMO's, and compares favorably with state-of-the-art methods based on a fixed transfer function.
C1 [Ozcinar, Cagri] TCD, SCSS, V SENSE, Dublin, Ireland.
   [Ozcinar, Cagri; Lauga, Paul] Univ Paris Saclay, Telecom ParisTech, LTCI, Paris, France.
   [Valenzise, Giuseppe; Dufaux, Frederic] Univ Paris Sud, Cent Supelec, CNRS, L2S, Orsay, France.
C3 Trinity College Dublin; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; Universite Paris Cite; Universite
   Paris Saclay; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS); Universite Paris Cite
RP Ozcinar, C (corresponding author), TCD, SCSS, V SENSE, Dublin, Ireland.
EM ozcinarc@scss.tcd.ie; giuseppe.valenzise@12s.centralesupelec.fr;
   frederic.dufaux@12s.centralesupelec.fr
RI Dufaux, Frederic/HJJ-1496-2023
OI Dufaux, Frederic/0000-0001-6388-4112; Ozcinar, Cagri/0000-0003-4915-2251
FU BPIFrance; Region Ile de France
FX The authors would like to thank the MPEG group for providing the test
   sequences available for this paper. The work presented in this document
   was partially supported by BPIFrance and Region Ile de France, in the
   framework of the FUI 18 Plein Phare project.
CR [Anonymous], ARXIV12105844
   [Anonymous], VCEG M ITU T SG16 Q
   [Anonymous], 1999, P 910 ITU T REC SUBJ
   [Anonymous], 2012, 2012 ANN TECHN C EXH, DOI DOI 10.5594/M001446
   [Anonymous], 2017, Quality and User Experience, DOI DOI 10.1007/S41233-017-0007-4
   [Anonymous], 2011, Recommendation ITU-R BT.601-7 Studio Encoding Parameters of Digital Television for Standard 4:3 and Wide Screen 16:9 Aspect Ratios
   Aydin T.O., 2008, HUMAN VISION ELECT I, Vxiii
   Aydin TO, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661268
   Barten PGJ, 2004, P SOC PHOTO-OPT INS, V5294, P231, DOI 10.1117/12.537476
   Boitard R., 2013, P EUSIPCO MARR, P1
   Boitard R., 2012, SPIE C SERIES
   Boitard R, 2014, IEEE INT CON MULTI
   Boitard R, 2015, IEEE CONSUM ELECTR M, V4, P72, DOI 10.1109/MCE.2015.2463294
   Boitard R, 2014, SIGNAL PROCESS-IMAGE, V29, P229, DOI 10.1016/j.image.2013.10.001
   Borer T., 2014, TECHNICAL REPORT ITU
   Cai JF, 2012, J AM MATH SOC, V25, P1033, DOI 10.1090/S0894-0347-2012-00740-1
   Chalmers A, 2017, SIGNAL PROCESS-IMAGE, V54, P49, DOI 10.1016/j.image.2017.02.003
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Combettes P. L., 2011, SET-VALUED VAR ANAL, V20, P307
   Combettes P.L., 2011, FIXED POINT ALGORITH
   DESIMONE F, 2014, IEEE GLOB C SIGN INF, P1063
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Dufaux F., 2016, High Dynamic Range Video: From Acquisition, to Display and Applications
   François E, 2016, IEEE T CIRC SYST VID, V26, P63, DOI 10.1109/TCSVT.2015.2461911
   Gaetano R., 2012, P IEEE VIS COMM IM P, P1
   Garbas JU, 2011, INT CONF ACOUST SPEE, P829
   Hanhart P, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0091-4
   Kerofsky L, 2016, IEEE IMAGE PROC, P879, DOI 10.1109/ICIP.2016.7532483
   Kim I.-K., 2013, JTC1SC29WG11 ISOIEC
   Koz A, 2014, SIGNAL PROCESS-IMAGE, V29, P274, DOI 10.1016/j.image.2013.08.017
   Larson GW, 1998, SIXTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P214
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Lauga P, 2014, EUR SIGNAL PR CONF, P1607
   Le Pendu Mikael, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7367, DOI 10.1109/ICASSP.2014.6855031
   Luthra A., 2015, MPEG2011N12036
   Mai ZC, 2013, IEEE T MULTIMEDIA, V15, P1503, DOI 10.1109/TMM.2013.2266633
   Mai ZC, 2011, IEEE T IMAGE PROCESS, V20, P1558, DOI 10.1109/TIP.2010.2095866
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Minoo K, 2016, JCTVCW0031
   MOTRA A, 2010, 17 IEEE INT C IM PRO, P2061
   Narwaria M., 2014, PROC VPQM, P1
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Ozcinar C, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P43, DOI 10.1109/DMIAF.2016.7574900
   Pesquet JC, 2012, PAC J OPTIM, V8, P273
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Samuelsson J., 2015, M36581 MPEG
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin P., 2014, HDR DEM 110 MPEG M
   Zerman Emin, 2017, P 9 INT C QUAL MULT, P1
   Zhang Y, 2013, PICT COD SYMP, P353, DOI 10.1109/PCS.2013.6737756
   Zhang Y, 2011, IEEE IMAGE PROC, P1321, DOI 10.1109/ICIP.2011.6115679
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
NR 56
TC 6
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 166
EP 178
DI 10.1016/j.jvcir.2018.06.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, L
   Cheng, H
   Liu, ZC
AF Wang, Ling
   Cheng, Hong
   Liu, Zicheng
TI A set-to-set nearest neighbor approach for robust and efficient face
   recognition with image sets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Set-to-set; Robust analysis; Weighted correlation
   analysis
ID CANONICAL CORRELATION-ANALYSIS; HIGHLY PARALLEL FRAMEWORK; HEVC MOTION
   ESTIMATION; DISTANCE; ANGLES
AB Set-to-set face recognition has drawn much attention thanks to its rich set information. We propose a robust and efficient Set-to-Set Nearest Neighbor Classification (S2S-NNC) approach for face recognition by using the maximum weighted correlation between sets in low-dimensional projection subspaces. A pair of face sets is represented as two sets of Mutual Typical Samples (MTS) based on their maximum weighted correlation, and the S2S distance is equivalent to that between two sets of MTS. For the variation of objects within a set, the faces are partitioned into patches and projected onto a correlation subspace to find the MTS between two sets. Furthermore, we develop a S2S-NNC approach for image set-based face recognition. Compared with existing approaches, the S2S-NNC unifies the image-to-image, image-to-set and set-to-set recognition problems into one model. Experimental results show the S2S-NNC approach significantly outperforms the state-of-art approaches on large video samples and small occluded samples.
C1 [Wang, Ling] Univ Elect Sci & Technol China, Sch Elect Engn, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Cheng, Hong] Univ Elect Sci & Technol China, Ctr Robot, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Liu, Zicheng] Microsoft Res Redmond, One Microsoft Way, Redmond, WA 98052 USA.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Microsoft
RP Cheng, H (corresponding author), Univ Elect Sci & Technol China, Ctr Robot, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
EM eewangling@uestc.edu.cn; hcheng@uestc.edu.cn; zliu@microsoft.com
RI Wang, Ling/JJD-5612-2023
FU National Natural Science Foundation of China - China (NSFC) [61603077,
   61273256, 61305033, U1233103F01]
FX This work is supported by the grant from "National Natural Science
   Foundation of China - China (NSFC)" (No. 61603077, No. 61273256, No.
   61305033 and No. U1233103F01).
CR [Anonymous], IEEE CVPR
   Arandjelovic O., 2005, IEEE CVPR, V1
   BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662
   Boiman O, 2008, IEEE CVPR
   Cevikalp H., 2010, IEEE CVPR
   Chen YC, 2013, IEEE INT CONF AUTOMA
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hayat M., 2013, IEEE CVPR
   Hu HF, 2015, IEEE T CIRC SYST VID, V25, P1599, DOI 10.1109/TCSVT.2014.2367357
   Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283
   Huang Z., 2014, IEEE CVPR
   Kim M., 2008, IEEE CVPR, P1
   Kim T.-K., 2006, ECCV
   Kim TK, 2007, PATTERN RECOGN, V40, P2475, DOI 10.1016/j.patcog.2006.12.030
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2010, IEEE T IMAGE PROCESS, V19, P1067, DOI 10.1109/TIP.2009.2038621
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee K.-C., 2003, IEEE CVPR, V1
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lu J., 2013, IEEE ICCV
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4042, DOI 10.1109/TIP.2017.2713940
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Ma JH, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P223, DOI 10.1109/ICIVC.2017.7984550
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Meng Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163108
   Scholkopft B., NEURAL NETWORKS SIGN
   Shakhnarovich G., 2011, HDB FACE RECOGNITION
   Vemulapalli R., 2013, IEEE CVPR
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang LW, 2006, PATTERN RECOGN, V39, P456, DOI 10.1016/j.patcog.2005.08.015
   Wang R., 2012, IEEE CVPR
   Wang R., 2009, IEEE CVPR
   Wang RP, 2012, IEEE T IMAGE PROCESS, V21, P4466, DOI 10.1109/TIP.2012.2206039
   Wei X., 2013, IEEE INT CONF AUTOMA
   Wolf L., 2013, IEEE CVPR
   Wolf L, 2011, IEEE IMAGE PROC
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Yamaguchi O., 1998, IEEE C AUT FAC GEST
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang AP, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P1314, DOI 10.1109/FSKD.2015.7382133
   Yang M, 2013, IEEE INT CONF AUTOMA
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Yuan PY, 2017, IEEE ACCESS, V5, P10012, DOI 10.1109/ACCESS.2017.2710360
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhu P., 2013, IEEE ICCV
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 50
TC 4
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 13
EP 19
DI 10.1016/j.jvcir.2018.02.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800002
DA 2024-07-18
ER

PT J
AU Furnari, A
   Battiato, S
   Farinella, GM
AF Furnari, Antonino
   Battiato, Sebastiano
   Farinella, Giovanni Maria
TI Personal-location-based temporal segmentation of egocentric videos for
   lifelogging applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Egocentric Vision; Lifelogging; Personal locations; Temporal
   segmentation
ID SCENE DETECTION; SHOT
AB Temporal video segmentation is useful to exploit and organize long egocentric videos. Previous work has focused on general purpose methods designed to deal with data acquired by different users. In contrast, egocentric video tends to be very personal and meaningful for the specific user who acquires it. We propose a method to segment egocentric video according to the personal locations visited by the user. The method aims at providing a personalized output and allows the user to specify which locations he wants to keep track of. To account for negative locations (i.e., locations not specified by the user), we propose a negative rejection method which does not require any negative sample at training time. For the experiments, we collected a dataset of egocentric videos in 10 different personal locations, plus various negative ones. Results show that the method is accurate and compares favorably with the state of the art.
C1 [Furnari, Antonino; Battiato, Sebastiano; Farinella, Giovanni Maria] Univ Catania, Dept Math & Comp Sci, Catania, Italy.
C3 University of Catania
RP Furnari, A (corresponding author), Univ Catania, Dept Math & Comp Sci, Catania, Italy.
EM fumari@dmi.unict.it; battiato@dmi.unict.it; gfarinella@dmi.unict.it
RI Furnari, Antonino/J-2358-2019; Battiato, Sebastiano/ABI-1584-2020;
   Battiato, Sebastiano/O-7799-2019; FARINELLA, Giovanni Maria/L-8555-2015
OI Furnari, Antonino/0000-0001-6911-0302; Battiato,
   Sebastiano/0000-0001-6127-2470; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432
FU PON MISE - Horizon 2020, VEDI Project [457, F/050457/01-03/X32]
FX This research is supported by PON MISE - Horizon 2020, VEDI Project,
   Rif. N. 457, Prog. n. F/050457/01-03/X32. We gratefully acknowledge the
   support of NVIDIA Corporation with the donation of the Titan X Pascal
   GPU used for this research.
CR Aizawa K, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P398, DOI 10.1109/ICIP.2001.958135
   Alletto S., 2016, P ACM MULT C, P476
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2015, IEEE INT CONF MULTI, DOI DOI 10.1109/ICMEW.2015.7169863
   [Anonymous], EURASIP J IMAGE VIDE
   [Anonymous], 2016 IEEE Winter Conf. Appl. Comput. Vision, DOI [DOI 10.1109/WACV.2016.7477708, 10.1109/WACV.2016.7477708]
   [Anonymous], WORKSH ASS COMP VIS
   [Anonymous], ELECT IMAGING 2006
   [Anonymous], WORKSH PERC US INT
   Apostolidis Evlampios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6583, DOI 10.1109/ICASSP.2014.6854873
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9256, P801, DOI 10.1007/978-3-319-23192-1_67
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9117, P395, DOI 10.1007/978-3-319-19390-8_45
   Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Castro D, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P75, DOI 10.1145/2802083.2808398
   Chasanis VT, 2009, IEEE T MULTIMEDIA, V11, P89, DOI 10.1109/TMM.2008.2008924
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Dimiccoli M, 2017, COMPUT VIS IMAGE UND, V155, P55, DOI 10.1016/j.cviu.2016.10.005
   Doherty Aiden R., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P20, DOI 10.1109/WIAMIS.2008.32
   Farinella GM, 2015, PATTERN RECOGN, V48, P1086, DOI 10.1016/j.patcog.2014.05.014
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   Furnari A, 2017, J VIS COMMUN IMAGE R, V46, P165, DOI 10.1016/j.jvcir.2017.03.019
   Furnari A, 2017, IEEE T HUM-MACH SYST, V47, P6, DOI 10.1109/THMS.2016.2612002
   Furnari A, 2017, IEEE T IMAGE PROCESS, V26, P696, DOI 10.1109/TIP.2016.2627816
   Furnari A, 2014, IEEE IMAGE PROC, P5681, DOI 10.1109/ICIP.2014.7026149
   Gal Y., DROPOUT BAYESIAN APP
   Gurrin C., 2014, LifeLogging: Personal Big Data. Foundations and Trends (R) in Informational Retrieval, V8, P1
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Kitani K. M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3241, DOI 10.1109/CVPR.2011.5995406
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ortis A, 2017, PATTERN RECOGN, V72, P207, DOI 10.1016/j.patcog.2017.07.010
   Ortis A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1179, DOI 10.1145/2733373.2806311
   Paci Francesco, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P589, DOI 10.1007/978-3-319-46604-0_42
   Peleg S., 2014, CVPR, P2537, DOI DOI 10.1109/CVPR.2014.325
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Rhinehart N, 2016, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2016.69
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354
   Starner T, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P50, DOI 10.1109/ISWC.1998.729529
   Su YC, 2016, LECT NOTES COMPUT SC, V9909, P454, DOI 10.1007/978-3-319-46454-1_28
   Talavera E, 2015, LECT NOTES COMPUT SC, V9117, P327, DOI 10.1007/978-3-319-19390-8_37
   Tetnpleman R, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23014
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Varini P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P539, DOI 10.1145/2671188.2749343
   Vendrig J, 2002, IEEE T MULTIMEDIA, V4, P492, DOI 10.1109/TMM.2002.802021
   Wray Michael, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P532, DOI 10.1007/978-3-319-46604-0_38
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Zhou B., PLACES IMAGE DATABAS
NR 55
TC 19
Z9 20
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 1
EP 12
DI 10.1016/j.jvcir.2018.01.019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300001
DA 2024-07-18
ER

PT J
AU Jing, LL
   Yang, XD
   Tian, YL
AF Jing, Longlong
   Yang, Xiaodong
   Tian, Yingli
TI Video you only look once: Overall temporal convolutions for action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video understanding; Video classification; Action recognition;
   Convolutional neural network
AB In this paper, we propose an efficient and straightforward approach, video you only look once (VideoYOLO), to capture the overall temporal dynamics from an entire video in a single process for action recognition. It remains an open question for action recognition on how to deal with the temporal dimension in videos. Existing methods subdivide a whole video into either individual frames or short clips and consequently have to process these fractions multiple times. A post process is then used to aggregate the partial dynamic cues to implicitly infer the whole temporal information. On the contrary, in VideoYOLO, we first generate a proxy video by selecting a subset of frames to roughly reserve the overall temporal dynamics presented in the original video. A 3D convolutional neural network (3D-CNN) is employed to learn the overall temporal characteristics from the proxy video and predict action category in a single process. Our proposed method is extremely fast. VideoYOLO-32 is able to process 36 videos per second that is 10 times and 7 times faster than prior 2D-CNN (Two-stream (Simonyan and Zisserman, 2014)) and 3D-CNN (C3D (Tran et al., 2015)) based models, respectively, while still achieves superior or comparable classification accuracies on the benchmark datasets, UCF101 and HMDB51.
C1 [Jing, Longlong; Tian, Yingli] CUNY, Grad Ctr, New York, NY USA.
   [Yang, Xiaodong] NVIDIA RES, Santa Clara, CA USA.
   [Tian, Yingli] CUNY, City Coll New York, New York, NY 10021 USA.
C3 City University of New York (CUNY) System; City University of New York
   (CUNY) System; City College of New York (CUNY)
RP Tian, YL (corresponding author), CUNY, City Coll New York, New York, NY 10021 USA.
EM ljing@gradcenter.cuny.edu; xiaodongy@nvidia.com; ytian@ccny.cuny.edu
RI Yang, Xiaodong/GSJ-1255-2022; TIAN, YI/KHU-9704-2024
OI Tian, Yingli/0000-0003-4458-360X
FU NSF [EFRI-1137172, IIS-1400802]; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [1400802] Funding
   Source: National Science Foundation; Directorate For Engineering;
   Emerging Frontiers & Multidisciplinary Activities [1137172] Funding
   Source: National Science Foundation
FX This work was supported in part by NSF Grants EFRI-1137172 and
   IIS-1400802.
CR [Anonymous], 2016, ECCV
   [Anonymous], 2004, ECCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2014, **DROPPED REF**
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], 2015, ICCV
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], ICIP
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, NIPS
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], ARXIV160908675
   [Anonymous], 2015, ICML
   [Anonymous], LONG TERM TEMPORAL C
   [Anonymous], 2017, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], CVPR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2014, CVPR
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Donahue J., 2015, CVPR
   Feichtenhofer Christoph., 2014, CVPR
   Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Park E., 2016, WACV
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Peng XJ, 2014, IEEE SIGNAL PROC LET, V21, P1022, DOI 10.1109/LSP.2014.2320530
   Ren XF, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2009.5204360
   Shroff N., 2010, CVPR
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Soomro K., 2012, ARXIV12120402CS
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
NR 40
TC 21
Z9 24
U1 3
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 58
EP 65
DI 10.1016/j.jvcir.2018.01.016
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300006
DA 2024-07-18
ER

PT J
AU Zhang, M
   Pang, Y
   Wu, YH
   Du, Y
   Sun, H
   Zhang, K
AF Zhang, Ming
   Pang, Yu
   Wu, Yunhe
   Du, Yue
   Sun, Hui
   Zhang, Ke
TI Saliency detection via local structure propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Coarse-to-fine; Local structure propagation; Color
   distribution map; Global and local information; Multi-prior
ID OBJECT DETECTION; MODEL
AB Saliency detection is a popular topic in computer vision, especially propagation-based method. This paper proposes a novel and effective coarse-to-fine saliency detection framework. In the coarse map stage, color spatial distribution map based on hue cue and central compactness rule is proposed, and integrated with texture boundary contrast information and background information to construct multi-prior coarse saliency map. In the refining stage, saliency values are updated under the comprehensive guidance of local structure propagation which is a novel algorithm to preserve local structural integrity during saliency propagation. With the global and local information, the detection procedure enhances the correctness of salient object gradually. Demonstrated in the extensive experiments on the public benchmark datasets, the performance of the proposed framework is superior to the state-of-the-art methods.
C1 [Zhang, Ming; Pang, Yu; Wu, Yunhe; Du, Yue; Zhang, Ke] Northeast Normal Univ, Sch Informat Sci & Technol, Changchun 130117, Jilin, Peoples R China.
   [Sun, Hui] Northeast Normal Univ, Coll Humanities & Sci, Changchun 130024, Jilin, Peoples R China.
   [Zhang, Ke] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Jilin, Peoples R China.
   [Zhang, Ming; Pang, Yu; Wu, Yunhe; Du, Yue] Northeast Normal Univ, Key Lab Intelligent Informat Proc, Changchun 130117, Jilin, Peoples R China.
C3 Northeast Normal University - China; Northeast Normal University -
   China; Changchun University of Science & Technology; Northeast Normal
   University - China
RP Zhang, K (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Jilin, Peoples R China.
EM zhangk113@nenu.edu.cn
RI Wu, Yunhe/JWA-3597-2024
OI Wu, Yunhe/0000-0001-7049-7161
FU National Natural Science Foundation of China [61672150]; Fund of Jilin
   Provincial Science and Technology Department [20160204047GX]; Fund of
   Research Contract, Jilin Provincial Education Department [571[2015]]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61672150), the Fund of Jilin Provincial Science and
   Technology Department (Grant No. 20160204047GX), the Fund of Research
   Contract, Jilin Provincial Education Department (Grant No. 571[2015]).
CR Achanta R., 2010, TECHNICAL REPORT, P2
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Advani S, 2013, INT CONF ACOUST SPEE, P2596, DOI 10.1109/ICASSP.2013.6638125
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], MIT Saliency Benchmark
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gopalakrishnan V, 2009, PROC CVPR IEEE, P1698, DOI 10.1109/CVPRW.2009.5206767
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Huo LN, 2016, PATTERN RECOGN, V49, P162, DOI 10.1016/j.patcog.2015.07.005
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kummerer M., 2015, P INT C LEARN REPR, P1
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Marchesotti L., COMPUTER VISION, P2232
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi YJ, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.061113
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang K., 2016, J ELECTRON IMAGING
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang M, 2014, J VIS COMMUN IMAGE R, V25, P1574, DOI 10.1016/j.jvcir.2014.06.016
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 46
TC 23
Z9 23
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 131
EP 142
DI 10.1016/j.jvcir.2018.01.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300013
DA 2024-07-18
ER

PT J
AU Meditskos, G
   Plans, PM
   Stavropoulos, TG
   Benois-Pineau, J
   Buso, V
   Kompatsiaris, I
AF Meditskos, Georgios
   Plans, Pierre-Marie
   Stavropoulos, Thanos G.
   Benois-Pineau, Jenny
   Buso, Vincent
   Kompatsiaris, Ioannis
TI Multi-modal activity recognition from egocentric vision, semantic
   enrichment and lifelogging applications for the care of dementia
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Instrumental activity recognition; Egocentric camera; Mechanical
   measurements; Visual cues; Ontologies; Semantic knowledge graphs
ID FRAMEWORK; SENSORS; MODEL; HEVC
AB We describe a framework for lifelogging monitoring in the scope of dementia care, based on activity recognition from egocentric vision and semantic context-enrichment. As pure vision-based approaches appear to be already saturating in terms of recognition accuracy, we propose their enhancement with wearable bracelet accelerometer information. For that purpose, we design and study appropriate early and late fusion schemes to increase accuracy. The incorporation of mechanical variables, such as jerk, improves the recognition accuracy of activities that require fine motion. In addition, we describe a framework for semantic activity representation and interpretation, using Semantic Web technologies for building interoperable activity graphs. The system is personalized, as deployment-specific activity models are authored, while problems related to the disease are detected by rules. Complemented by lifelogging applications, the system is able to support interventions by clinicians, and endorse a feeling of safety and inclusion for end-users and their carers.
C1 [Meditskos, Georgios; Stavropoulos, Thanos G.; Kompatsiaris, Ioannis] Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki, Greece.
   [Plans, Pierre-Marie; Benois-Pineau, Jenny; Buso, Vincent] Univ Bordeaux, LABRI, Bordeaux, France.
C3 Centre for Research & Technology Hellas; Universite de Bordeaux; Centre
   National de la Recherche Scientifique (CNRS)
RP Meditskos, G (corresponding author), Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki, Greece.
EM gmeditsk@iti.gr; pplans@labri.fr; athstavr@iti.gr;
   jenny.benois@labri.fr; vincent.buso@labri.fr; ikom@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015; Stavropoulos, Thanos G./O-5056-2019;
   Benois-Pineau, Jenny/ABG-6325-2020; Meditskos, Georgios/AGO-3230-2022
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Stavropoulos, Thanos
   G./0000-0003-2389-4329; Benois-Pineau, Jenny/0000-0003-0659-8894;
   Meditskos, Georgios/0000-0003-4242-5245
FU EU [288199]
FX This work has been supported by the EU FP7 project Dem@Care: Dementia
   Ambient Care - Multi-Sensing Monitoring for Intelligent Remote
   Management and Decision Support under contract No. 288199.
CR Alletto S, 2015, PATTERN RECOGN, V48, P4082, DOI 10.1016/j.patcog.2015.06.006
   [Anonymous], 2009, P 2009 IEEE POW EN S
   Baader F., 2003, DESCRIPTION LOGIC HD
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Chen LM, 2009, INT J WEB INF SYST, V5, P410, DOI 10.1108/17440080911006199
   Crispim CF Jr, 2016, IEEE T PATTERN ANAL, V38, P1598, DOI 10.1109/TPAMI.2016.2537323
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dovgalecs V, 2013, ADV MULTIMED, V2013, DOI 10.1155/2013/175064
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Furber C., 2010, Using SPARQL and SPIN for Data Quality Management on the Semantic Web, P35
   Gaidon A., 2009, BRIT MACH VIS C
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Gonzalez Diaz I., 2013, Proceedings of the 1st ACM international workshop on Multimedia indexing and information retrieval for healthcare, P11, DOI DOI 10.1145/2505323.2505328
   Gonzalez-Diaz I., 2015, HLTH MONITORING PERS
   Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001
   Harris S., 2013, W3C Recommendation
   Hong CQ, 2017, MULTIMED TOOLS APPL, V76, P10919, DOI 10.1007/s11042-016-3312-7
   Jain R, 2014, IEEE MULTIMEDIA, V21, P100, DOI 10.1109/MMUL.2014.63
   Karaman S, 2014, MULTIMED TOOLS APPL, V69, P743, DOI 10.1007/s11042-012-1117-x
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   König A, 2015, J ALZHEIMERS DIS, V44, P675, DOI 10.3233/JAD-141767
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lazarou I., 2016, J ALZHEIMERS DIS, P1
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Liming Chen, 2012, IEEE Transactions on Knowledge and Data Engineering, V24, P961, DOI 10.1109/TKDE.2011.51
   Maria K., 2012, S CRETA SMART CLASSR, P67
   MEDITSKOS G, 2014, PROCEEDINGS PART 2, V8797, P260
   Mocanu I., 2011, P 1 INT C AMB COMP A, P23
   Morerio P, 2015, IEEE SIGNAL PROC LET, V22, P469, DOI 10.1109/LSP.2014.2362852
   Ngoc K. A. P., 2005, OWL BASED USER PREFE, P1615
   Okeyo G., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1763, DOI 10.1109/TrustCom.2012.34
   Okeyo G, 2011, ATL AMB PERVAS INTEL, V4, P237
   Okeyo G, 2010, LECT NOTES COMPUT SC, V6406, P67, DOI 10.1007/978-3-642-16355-5_8
   Pan J. Z, 2009, RESOURCE DESCRIPTION, P71
   Pinquier J, 2012, INT C PATT RECOG, P3192
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Platt JC, 2000, ADV NEUR IN, P61
   Riboni D, 2011, PERVASIVE MOB COMPUT, V7, P379, DOI 10.1016/j.pmcj.2011.02.001
   Riboni D, 2011, PERS UBIQUIT COMPUT, V15, P271, DOI 10.1007/s00779-010-0331-7
   Schneider M., 2013, P 10 INT WORKSH OWL
   Smeaton AF, 2012, J AMB INTEL SMART EN, V4, P335, DOI 10.3233/AIS-2012-0155
   Stavropoulos TG, 2017, PERVASIVE MOB COMPUT, V34, P126, DOI 10.1016/j.pmcj.2016.06.006
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Strat ST, 2014, ADV COMPUT VIS PATT, P53, DOI 10.1007/978-3-319-05696-8_3
   Studer R, 1998, DATA KNOWL ENG, V25, P161, DOI 10.1016/S0169-023X(97)00056-6
   Sundararn S, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2009.5204355
   van Hage WR, 2011, J WEB SEMANT, V9, P128, DOI 10.1016/j.websem.2011.03.003
   Wongpatikaseree K, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE, INFORMATION AND CREATIVITY SUPPORT SYSTEMS (KICSS 2012), P50, DOI 10.1109/KICSS.2012.26
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Ye J, 2015, PERVASIVE MOB COMPUT, V23, P1, DOI 10.1016/j.pmcj.2014.12.009
NR 60
TC 25
Z9 27
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 169
EP 190
DI 10.1016/j.jvcir.2018.01.009
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500017
DA 2024-07-18
ER

PT J
AU Salloum, R
   Ren, YZ
   Kuo, CCJ
AF Salloum, Ronald
   Ren, Yuzhuo
   Kuo, C. -C. Jay
TI Image Splicing Localization using a Multi-task Fully Convolutional
   Network (MFCN)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image splicing; Image forensics; Convolutional neural network (CNN);
   Fully convolutional network (FCN); Multi-task network
ID FORGERIES; FEATURES
AB In this work, we propose a technique that utilizes a fully convolutional network (FCN) to localize image splicing attacks. We first evaluated a single-task FCN (SFCN)trained only on the surface label. Although the SFCN is shown to provide superior performance over existing methods, it still provides a coarse localization output in certain cases. Therefore, we propose the use of a multi-task FCN (MFCN) that utilizes two output branches for multi-task learning. One branch is used to learn the surface label, while the other branch is used to learn the edge or boundary of the spliced region. We trained the networks using the CASIA v2.0 dataset, and tested the trained models on the CASIA v1.0, Columbia Uncompressed, Carvalho, and the DARPA/NIST Nimble Challenge 2016 SCI datasets. Experiments show that the SFCN and MFCN outperform existing splicing localization algorithms, and that the MFCN can achieve finer localization than the SFCN.
C1 [Salloum, Ronald; Ren, Yuzhuo; Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90007 USA.
C3 University of Southern California
RP Salloum, R (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90007 USA.
EM rsalloum@usc.edu; yuzhuore@usc.edu; jckuo@usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU DARPA; Air Force Research Laboratory (AFRL) [FA8750-16-2-0173]
FX This material is based on research sponsored by DARPA and Air Force
   Research Laboratory (AFRL) under agreement number FA8750-16-2-0173. The
   U.S. Government is authorized to reproduce and distribute reprints for
   Governmental purposes notwithstanding any copyright notation thereon.
   The views and conclusions contained herein are those of the authors and
   should not be interpreted as necessarily representing the official
   policies or endorsements, either expressed or implied, of DARPA and Air
   Force Research Laboratory (AFRL) or the U.S. Government. Credits for the
   use of the CASIA Image Tampering Detection Evaluation Database (CASIA
   TIDE) v1.0 and v2.0 are given to the National Laboratory of Pattern
   Recognition, Institute of Automation, Chinese Academy of Science, Corel
   Image Database and the photographers http://forensics.idealtest.org.
CR Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2015, ARXIV151100561
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], 2016, 2016 IEEE INT WORKSH, DOI DOI 10.1109/WIFS.2016.7823911
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 2007 IEEE INT C AC S
   [Anonymous], 2016, P AS C COMP VIS
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Cao H, 2012, IEEE T INF FOREN SEC, V7, P992, DOI 10.1109/TIFS.2012.2185696
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D., 2017, Recasting Residual-based Local Descriptors as Convolutional Neural Networks: an Application to Image Forgery Detection
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fan Wu, 2015, 2015 IEEE Transportation Electrification Conference and Expo (ITEC), P1, DOI 10.1109/ITEC.2015.7165785
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krawetz N., 2007, HACKER FACTOR SOLUTI, P1
   Li CT, 2012, IEEE T CIRC SYST VID, V22, P260, DOI 10.1109/TCSVT.2011.2160750
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Wang W., 2010, INT WORKSH DIG WAT I, P120
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zampoglou M., 2016, MULTIMEDIA TOOLS APP, P1
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
NR 44
TC 194
Z9 227
U1 7
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 201
EP 209
DI 10.1016/j.jvcir.2018.01.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500019
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Lee, MH
   Park, IK
AF Lee, Man Hee
   Park, In Kyu
TI Performance evaluation of local descriptors for maximally stable
   extremal regions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local feature; Feature descriptor; Performance evaluation;
   Affine-invariant region detectors; MSER
ID INTEREST POINT DETECTORS; IMAGE FEATURES; PATTERN; SCALE
AB Visual feature descriptors are widely used in most computer vision applications. Over the past several decades, local feature descriptors that are robust to challenging environments have been proposed. Because their characteristics differ according to the imaging condition, it is necessary to compare their performance consistently. However, no pertinent research has attempted to establish a benchmark for performance evaluation, especially for affine region detectors, which are mainly used in object classification and recognition. This paper presents an intensive and informative performance evaluation of local descriptors for the state-of-the-art affine-invariant region detectors, i.e., maximally stable extremal region detectors. We evaluate patch-based and binary descriptors, including SIFT, SURF, BRIEF, FREAK, the shape descriptor, LIOP, DAISY, GSURF, RFDg, and CNN descriptors. The experimental results reveal the relative performance and characteristics of each descriptor. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Lee, Man Hee] Elect & Telecommun Res Inst, Daejeon 34129, South Korea.
   [Park, In Kyu] Inha Univ, Incheon 22212, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI); Inha
   University
RP Park, IK (corresponding author), Inha Univ, Incheon 22212, South Korea.
EM mheelee@etri.re.kr; pik@inha.ac.kr
RI Park, In Kyu/B-5967-2013
OI Lee, Man Hee/0000-0002-5529-7548
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2016R1A2B4014731]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (No.
   NRF-2016R1A2B4014731).
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2013, IMAGE VISION COMPUT, V31, P103, DOI 10.1016/j.imavis.2012.11.001
   [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], 2013, 18 INT C DIG SIGN PR
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Dahl A. L., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P318, DOI 10.1109/3DIMPVT.2011.47
   Dickscheid T, 2011, INT J COMPUT VISION, V94, P154, DOI 10.1007/s11263-010-0340-z
   Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981
   Fischer P., ABS14055769 CORR
   Forssén PE, 2007, IEEE I CONF COMP VIS, P1530
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Gbèhounou S, 2016, J VIS COMMUN IMAGE R, V38, P276, DOI 10.1016/j.jvcir.2016.03.009
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Hajati A., 2008, P SPIE SAN DIEGO CAL, P1
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Hong CQ, 2011, NEUROCOMPUTING, V74, P3565, DOI 10.1016/j.neucom.2011.06.025
   Kaneva B, 2011, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2011.6126508
   Karlsson N, 2005, IEEE INT CONF ROBOT, P24
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee M. L., 2014, P INT S VLSI DES AUT, P1
   Lee MH, 2016, ETRI J, V38, P502, DOI 10.4218/etrij.16.0115.0631
   Lee MH, 2015, PATTERN RECOGN LETT, V68, P76, DOI 10.1016/j.patrec.2015.08.016
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Miksik O, 2012, INT C PATT RECOG, P2681
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Restrepo MI, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.46
   Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Wang Y, 2016, J VIS COMMUN IMAGE R, V34, P108, DOI 10.1016/j.jvcir.2015.11.001
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263
NR 40
TC 5
Z9 9
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2017
VL 47
BP 62
EP 72
DI 10.1016/j.jvcir.2017.05.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX8TD
UT WOS:000403522200006
DA 2024-07-18
ER

PT J
AU Mohammadi, FG
   Sajedi, H
AF Mohammadi, F. Ghareh
   Sajedi, H.
TI Region based Image Steganalysis using Artificial Bee Colony
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image steganalysis; Artificial Bee Colony (ABC); Swarm intelligent;
   Feature selection; Information hiding
ID PERFORMANCE
AB Steganalysis is the art and skill of discriminating stego images from cover images. Image steganalysis algorithms can be divided into two broad categories, specific and universal. In this paper, a novel universal image steganalysis algorithm is proposed which is called RISAB, Region based Image Steganalysis using Artificial Bee colony. The goal of the proposed method is to realize a sub-image from stego and cover images through ABC with respect to density according to the cover, stego and difference images. In our method, we look for the best sub-image, which contains the highest density with respect to the changed embedding pixels. Furthermore, after selecting the best sub-image, we extract the features, which have been selected by IFAB, Image steganalysis based on Feature selection using Artificial Bee colony. At the end, both selected features by IFAB and extracted features by RISAB are combined. As a result, a feature vector is generated which improves accuracy of steganalysis. Experimental results show that our proposed method outperforms other approaches. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Sajedi, H.] Univ Tehran, Coll Sci, Dept Math Stat & Comp Sci, Tehran, Iran.
   [Mohammadi, F. Ghareh] Tarbiat Modares Univ, Fac Elect & Comp Engn, Tehran, Iran.
C3 University of Tehran; Tarbiat Modares University
RP Sajedi, H (corresponding author), Univ Tehran, Coll Sci, Dept Math Stat & Comp Sci, Tehran, Iran.
EM f.garemohammadi@modares.ac.ir; hhsaje-di@ut.ac.ir
RI Sajedi, Hedieh/Y-3803-2019
OI sajedi, hedieh/0000-0003-4782-9222
FU Irannian National Science Foundation (INSF) [87041894]
FX This research has been supported by Irannian National Science Foundation
   (INSF) (Contract No. 87041894).
CR Akay B, 2015, SIGNAL IMAGE VIDEO P, V9, P967, DOI 10.1007/s11760-015-0758-4
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2012, RECENT ADV STEGANOGR
   [Anonymous], P 11 ACM MULT SEC WO
   [Anonymous], 1999, Swarm Intelligence
   Avcibas I, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P645, DOI 10.1109/ICIP.2002.1039053
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Das N.S., 2015, INT C CIRC POW COMP, P1
   Farid H., 2002, INT C IM PROC, V2, P11
   Fazio Nelly, 2014, Topics in Cryptology - CT-RSA 2014. The Cryptographers Track at the RSA Conference 2014. Proceedings: LNCS 8366, P64, DOI 10.1007/978-3-319-04852-9_4
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Geetha S., 2010, ARXIV10082824
   Goljan M., 2015, 2015 National Conference on Parallel Computing Technologies (PARCOMPTECH), P185
   Kamley S., 2014, BRIT J MATH COMPUT S, V4, P2502
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Li X, 2014, MULTIMED TOOLS APPL, V73, P1487, DOI 10.1007/s11042-013-1654-y
   Lu JC, 2015, DIGIT INVEST, V12, P1, DOI 10.1016/j.diin.2014.12.001
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Mohammadi FG, 2014, J INTELL FUZZY SYST, V27, P1445, DOI 10.3233/IFS-131111
   Moldovan D, 2015, LECT NOTES ARTIF INT, V9166, P368, DOI 10.1007/978-3-319-21024-7_25
   Oplatkova Z., 2013, HDB OPTIMIZATION, P821
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   PevuSr T., 2007, P SPIE ELECT IMAGING, V6505
   Rodriguez F, 2015, LECT NOTES COMPUT SC, V9423, P83, DOI 10.1007/978-3-319-25751-8_11
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Sullivan K, 2006, IEEE T INF FOREN SEC, V1, P275, DOI 10.1109/TIFS.2006.873595
   Tavoli R, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P773, DOI 10.1109/TSP.2013.6614043
   Wang PF, 2016, MULTIMED TOOLS APPL, V75, P2897, DOI 10.1007/s11042-015-2521-9
   Wang R, 2015, MULTIMED TOOLS APPL, V74, P5725, DOI 10.1007/s11042-014-1880-y
   Zhang H, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4793-x
   Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007
NR 35
TC 17
Z9 20
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 214
EP 226
DI 10.1016/j.jvcir.2016.12.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600018
OA Bronze
DA 2024-07-18
ER

PT J
AU Yang, CN
   Liao, JK
   Wang, DS
AF Yang, Ching-Nung
   Liao, Jung-Kuo
   Wang, Dao-Shun
TI New privilege-based visual cryptography with arbitrary privilege levels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Visual secret sharing; Threshold scheme; Privilege
   level; Contrast
ID SCHEMES; SECRET; CONSTRUCTIONS
AB Recently, Hou et al. introduced a novel (2, n) privilege-based visual cryptography scheme (PVCS) with various privilege levels of shadow images. In this scheme, a shadow with a higher privilege contributes more recovered information, while a lower privileged shadow has the less recovery capability. Moreover, the visual quality of stacked result depends on the total sum of privilege levels for all involved shadows in reconstruction. Unfortunately, the PVC scheme has the inconsistency of the contrast of recovered image and the sum of privilege levels. Accordingly, an enhanced Hou et al.'s (2,n)-PVC scheme (EPVCS) is proposed to solve this inconsistency problem. However, the EPVCS is not a general solution to implement all PVCSs with arbitrary privilege levels, and it also has the unequal whiteness of shadows. In this paper, we first extend Hou et al.'s (2, n)-EPVCS with a correct privilege levels achieving the consistency of the contrast and the sum of privilege levels. Then we construct a (2,n)-PVCS to allow arbitrary privilege levels and provide the equal whiteness for each shadow. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yang, Ching-Nung; Liao, Jung-Kuo] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
   [Wang, Dao-Shun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Wang, Dao-Shun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 National Dong Hwa University; Tsinghua University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Wang, DS (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM daoshun@mail.tsinghua.edu.cn
RI Yang, Ching-Nung/HKV-1639-2023
OI Yang, Ching-Nung/0000-0002-3881-7329
FU Ministry of Science and Technology [105-2221-E-259-015-MY2]; National
   Natural Science Foundation of China [61373020, 61272435, U1536102,
   U1536116]; project of State Key Laboratory of information Security,
   Institute of Information Engineering Chinese Academy of Sciences
   [015-MS-13]
FX This research was supported in part by Ministry of Science and
   Technology, under grant 105-2221-E-259-015-MY2, in part by the National
   Natural Science Foundation of China under grant nos. 61373020, 61272435,
   U1536102 and U1536116, and in part by the project of State Key
   Laboratory of information Security, Institute of Information Engineering
   Chinese Academy of Sciences under grant 015-MS-13.
CR Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Hou YC, 2015, J VIS COMMUN IMAGE R, V33, P358, DOI 10.1016/j.jvcir.2015.10.005
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Shyu SJ, 2012, IEEE T CIRC SYST VID, V22, P769, DOI 10.1109/TCSVT.2011.2180769
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Wang DS, 2011, INFORM SCIENCES, V181, P2189, DOI 10.1016/j.ins.2011.01.019
   Yan XH, 2014, LECT NOTES COMPUT SC, V8836, P636, DOI 10.1007/978-3-319-12643-2_77
   Yang CN, 2015, ETRI J, V37, P979, DOI 10.4218/etrij.15.0114.0327
   Yang CN, 2015, INFORM SCIENCES, V312, P131, DOI 10.1016/j.ins.2015.03.024
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 20
TC 13
Z9 13
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 121
EP 131
DI 10.1016/j.jvcir.2016.10.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200010
DA 2024-07-18
ER

PT J
AU Pi, L
   Wang, W
   Ng, M
AF Pi, Ling
   Wang, Wei
   Ng, Michael
TI A spatially variant total variational model for chromatic aberration
   correction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Chromatic aberration; Spatially variant; Total variational; Iterative
   algorithm
ID REMOVAL; IMAGES
AB In this paper, we propose a spatially variant total variational model to correct chromatic aberration (CA) that causes false color artifacts near edges in captured images. In general, it may be very difficult to determine suitably CA regions in captured images. Instead of using local image processing methods, our idea is to make use of spatially variant model to control the gradient and intensity matching between the red and blue color channels and the green color channel at the edges. The total variation regularization is also employed to constraint the change of the intensity of red and blue color channels during the gradient and intensity matching. We present both theoretical results and algorithms for the proposed model. Experimental results are given to illustrate the effectiveness of the proposed model and algorithm and show that their corrected images are visually better than those corrected by the other testing methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pi, Ling] Shanghai Jiao Tong Univ, Dept Math, Shanghai, Peoples R China.
   [Wang, Wei] Tongji Univ, Dept Math, Shanghai, Peoples R China.
   [Ng, Michael] Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China.
C3 Shanghai Jiao Tong University; Tongji University; Hong Kong Baptist
   University
RP Ng, M (corresponding author), Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China.
EM mng@math.hkbu.edu.hk
RI Ng, Michael/B-7189-2009; NG, Michael/AAG-9117-2020
OI Ng, Michael/0000-0001-6833-5227; 
FU National Natural Science Foundation of China [11201341]; HKRGC GRF [HKBU
   202013, HKBU FRG2/14-15/087]
FX Research supported by National Natural Science Foundation of China
   (Grant No. 11201341) and HKRGC GRF HKBU 202013 and HKBU FRG2/14-15/087.
CR Chang J, 2013, IEEE T IMAGE PROCESS, V22, P1186, DOI 10.1109/TIP.2012.2228489
   KRUGER PB, 1993, VISION RES, V33, P1397, DOI 10.1016/0042-6989(93)90046-Y
   Mallon J, 2007, PATTERN RECOGN LETT, V28, P125, DOI 10.1016/j.patrec.2006.06.013
   MARIMONT DH, 1994, J OPT SOC AM A, V11, P3113, DOI 10.1364/JOSAA.11.003113
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   THIBOS LN, 1990, VISION RES, V30, P33, DOI 10.1016/0042-6989(90)90126-6
NR 6
TC 9
Z9 9
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 296
EP 304
DI 10.1016/j.jvcir.2016.10.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000026
DA 2024-07-18
ER

PT J
AU Bacha, S
   Allili, MS
   Benblidia, N
AF Bacha, Siham
   Allili, Mohand Said
   Benblidia, Nadjia
TI Event recognition in photo albums using probabilistic graphical models
   and feature relevance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Photo albums; Event recognition; Object/scene relevance; Probabilistic
   graphical models (PGM)
ID PARALLEL FRAMEWORK; CONTEXT; ANNOTATION; PERCEPTION
AB This paper proposes a method for event recognition in photo albums which aims at predicting the event categories of groups of photos. We propose a probabilistic graphical model (PGM) for event prediction based on high-level visual features consisting of objects and scenes, which are extracted directly from images. For better discrimination between different event categories, we develop a scheme to integrate feature relevance in our model which yields a more powerful inference when album images exhibit a large number of objects and scenes. It allows also to mitigate the influence of non-informative images usually contained in the albums. The performance of the proposed method is validated using extensive experiments on the recently-proposed PEC dataset containing over 61 000 images. Our method obtained the highest accuracy which outperforms previous work. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Bacha, Siham; Benblidia, Nadjia] Saad Dahlab Univ Blida1, LRDSI Lab, Blida, Algeria.
   [Allili, Mohand Said] Univ Quebec Outaouais, Dept Comp Sci & Engn, Hull, PQ J8X 3X7, Canada.
C3 University of Quebec; University Quebec Outaouais
RP Allili, MS (corresponding author), Univ Quebec Outaouais, Dept Comp Sci & Engn, Hull, PQ J8X 3X7, Canada.
EM mohandsaid.allili@uqo.ca
RI Nadjia, BENBLIDIA/J-6296-2019; Allili, Mohand Said/AAB-2958-2022
OI Benblidia, Nadjia/0000-0003-4609-0139
FU University Saad Dahlab of Blida1 (Algeria); Natural Sciences and
   Engineering Research Council of Canada (NSERC)
FX This work has been achieved thanks to the support of the University Saad
   Dahlab of Blida1 (Algeria) and partially support of Natural Sciences and
   Engineering Research Council of Canada (NSERC).
CR Allili M.S., 2007, IEEE Conf. on Computer Vision and pattern Recognition, P1
   Allili MS, 2012, IEEE T IMAGE PROCESS, V21, P1452, DOI 10.1109/TIP.2011.2170701
   [Anonymous], 2013, GEOSPATIAL VISUALIZA, DOI 10.1007/978-3-642-12289-7_10
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ACM INTL CONF ON MUL
   [Anonymous], COGN SCI
   [Anonymous], P CVPR
   [Anonymous], 2009, P 17 ACM INT C MULT, DOI DOI 10.1145/1631272.1631371
   [Anonymous], AAAI C ART INT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C MACH LEARN CYB
   [Anonymous], CLASSICAL PSYCHOL SE
   Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151
   Boster J.S., 2005, Handbook of categorization in cognitive science, P313
   Bowers JS, 2012, PSYCHOL BULL, V138, P389, DOI 10.1037/a0026450
   Brenner Markus, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P340, DOI 10.1007/978-3-319-04114-8_29
   Cao LL, 2009, IEEE T MULTIMEDIA, V11, P208, DOI 10.1109/TMM.2008.2009693
   Dao MS, 2014, MULTIMED TOOLS APPL, V70, P25, DOI 10.1007/s11042-012-1153-6
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819
   Dyck M, 2015, NEUROPSYCHOLOGIA, V72, P43, DOI 10.1016/j.neuropsychologia.2015.04.023
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Heeyoung Kwon, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P51, DOI 10.1109/CVPRW.2015.7301336
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang W, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P313, DOI 10.1109/ICME.2008.4607434
   Kasper D, 2011, IEEE INT VEH SYM, P673, DOI 10.1109/IVS.2011.5940468
   Lariviere G., 2012, 2012 Canadian Conference on Computer and Robot Vision, P86, DOI 10.1109/CRV.2012.19
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu MY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P274, DOI 10.1109/ICCVW.2015.44
   Ma WJ, 2012, TRENDS COGN SCI, V16, P511, DOI 10.1016/j.tics.2012.08.010
   Mudrik L, 2010, NEUROPSYCHOLOGIA, V48, P507, DOI 10.1016/j.neuropsychologia.2009.10.011
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Paninski L, 2003, NEURAL COMPUT, V15, P1191, DOI 10.1162/089976603321780272
   Robert C. P., 2001, The Bayesian choice
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P295, DOI 10.1109/ICCVW.2015.47
   Salvador A, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301334
   Simonyan K., 2014, 14091556 ARXIV
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Swallow KM, 2009, J EXP PSYCHOL GEN, V138, P236, DOI 10.1037/a0015631
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang F, 2011, INT CONF ACOUST SPEE, P877
   Tankoyeu I., 2011, Proceedings of the 2011 joint ACM work- shop on Modeling and representing events, P1
   Tsai S.-F., 2011, ACM Multimedia, P1361
   Tsai SJ, 2011, PROG MOL BIOL TRANSL, V103, P1, DOI 10.1016/B978-0-12-415906-8.00008-X
   Ulges A, 2011, IEEE T MULTIMEDIA, V13, P330, DOI 10.1109/TMM.2010.2101051
   Wu ZF, 2015, IEEE T MULTIMEDIA, V17, P1960, DOI 10.1109/TMM.2015.2477681
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yuan JS, 2010, IEEE T MULTIMEDIA, V12, P705, DOI 10.1109/TMM.2010.2051868
   Zacks JM, 2007, PSYCHOL BULL, V133, P273, DOI 10.1037/0033-2909.133.2.273
   Zhang X, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522978
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
   Zhou BL, 2014, ADV NEUR IN, V27
   Zigkolis C, 2014, MULTIMED TOOLS APPL, V70, P89, DOI 10.1007/s11042-012-1154-5
NR 60
TC 9
Z9 9
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 546
EP 558
DI 10.1016/j.jvcir.2016.07.021
PN B
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600013
DA 2024-07-18
ER

PT J
AU Kong, FQ
   Li, YS
   Guo, WJ
AF Kong, Fanqiang
   Li, Yunsong
   Guo, Wenjun
TI Regularized MSBL algorithm with spatial correlation for sparse
   hyperspectral unmixing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral unmixing; Sparse Bayesian learning; Total variation;
   Multiple measurement vectors model
ID SIGNAL RECOVERY
AB Sparse unmixing is a promising approach that is formulated as a linear regression problem by assuming that observed signatures can be expressed as a linear combination of a few endmembers in the spectral library. Under this formulation, a novel regularized multiple sparse Bayesian learning model, which is constructed via Bayesian inference with the conditional posterior distributions of model parameters under a hierarchical Bayesian model, is proposed to solve the sparse unmixing problem. Then, the total variation regularization and the non-negativity constraint are incorporated into the model, thus exploiting the spatial information and the physical property in hyperspectral images. The optimal problem of the model is decomposed into several simpler iterative optimization problems that are solved via the alternating direction method of multipliers, and the model parameters are updated adaptively from the algorithm. Experimental results on both synthetic and real hyperspectral data demonstrate that the proposed method outperforms the other algorithms. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kong, Fanqiang; Guo, Wenjun] Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
   [Li, Yunsong] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Xidian University
RP Kong, FQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
EM kongfq@nuaa.edu.cn; ysli@mail.xidian.edu.cn; nuaaguowenjun@126.com
FU National Natural Science Foundation of China [61401200]
FX This work was supported by a grant from the National Natural Science
   Foundation of China (No. 61401200). The authors would like to thank
   M.-D. Iordache, J. Bioucas-Dias, and A. Plaza for sharing the simulated
   data sets and their codes for the algorithms of SUnSAL and SUnSAL-TV.
   The authors would also like to thank Z. Shi, W. Tang, Z. Duren, and Z.
   Jiang for sharing their code for the algorithm of SMP. Moreover, the
   authors would also like to thank the anonymous reviewers for their
   helpful comments regarding the improvement of this paper.
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Boardman J. W., 1993, SUMM 4 ANN JPL AIRB, V1, P11
   Clark R. N., 2007, USGS DIGITAL SPECTRA
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Iordache MD, 2011, IEEE T GEOSCI REMOTE, V49, P2014, DOI 10.1109/TGRS.2010.2098413
   Iordache MD, 2014, IEEE T GEOSCI REMOTE, V52, P341, DOI 10.1109/TGRS.2013.2240001
   Iordache MD, 2012, IEEE T GEOSCI REMOTE, V50, P4484, DOI 10.1109/TGRS.2012.2191590
   Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Li HL, 2011, IEEE T GEOSCI REMOTE, V49, P4223, DOI 10.1109/TGRS.2011.2162098
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI [10.1162/neco.1992.4.3.415, 10.1162/neco.1992.4.3.448]
   Nascimento J.M., IEEE T GEOSCI REMOTE, V43
   Plaza J, 2003, INT GEOSCI REMOTE SE, P291
   Rakotomamonjy A, 2011, SIGNAL PROCESS, V91, P1505, DOI 10.1016/j.sigpro.2011.01.012
   Ren H, 2003, IEEE T AERO ELEC SYS, V39, P1232, DOI 10.1109/TAES.2003.1261124
   Shi ZW, 2014, IEEE T GEOSCI REMOTE, V52, P3256, DOI 10.1109/TGRS.2013.2272076
   Tang W, 2015, IEEE T GEOSCI REMOTE, V53, P770, DOI 10.1109/TGRS.2014.2328336
   Tang W, 2014, IEEE T GEOSCI REMOTE, V52, P5271, DOI 10.1109/TGRS.2013.2287795
   Themelis KE, 2012, IEEE T SIGNAL PROCES, V60, P585, DOI 10.1109/TSP.2011.2174052
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Winter ME, 1999, PROC SPIE, V3753, P266, DOI 10.1117/12.366289
   Wipf D.P., IEEE T SIGNAL PROCES, V55
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 32
TC 2
Z9 2
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 525
EP 537
DI 10.1016/j.jvcir.2016.07.019
PN B
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600011
DA 2024-07-18
ER

PT J
AU Lim, KM
   Tan, AWC
   Tan, SC
AF Lim, Kian Ming
   Tan, Alan W. C.
   Tan, Shing Chiang
TI Block-based histogram of optical flow for isolated sign language
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sign language recognition; Block-based; Histogram of optical flow
ID PARALLEL FRAMEWORK; TRACKING; DECISION; SYSTEM
AB In this paper, we propose a block-based histogram of optical flow (BHOF) to generate hand representation in sign language recognition. Optical flow of the sign language video is computed in a region centered around the location of the detected hand position. The hand patches of optical flow are segmented into M spatial blocks, where each block is a cuboid of a segment of a frame across the entire sign gesture video. The histogram of each block is then computed and normalized by its sum. The feature vector of all blocks are then concatenated as the BHOF sign gesture representation. The proposed method provides a compact scale-invariant representation of the sign language. Furthermore, block-based histogram encodes spatial information and provides local translation invariance in the extracted optical flow. Additionally, the proposed BHOF also introduces sign language length invariancy into its representation, and thereby, produce promising recognition rate in signer independent problems. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lim, Kian Ming; Tan, Shing Chiang] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
   [Tan, Alan W. C.] Multimedia Univ, Fac Engn & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
C3 Multimedia University; Multimedia University
RP Lim, KM (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
EM kmlim@mmu.edu.my; wctan@mmu.edu.my; sctan@mmu.edu.my
RI Tan, SC/E-6463-2010; Lim, Kian Ming/AGV-8623-2022
OI Tan, SC/0000-0002-1267-1894; Lim, Kian Ming/0000-0003-1929-7978
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], TECHNOLOGY DISSABILI
   Athitsos Vassilis, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563181
   Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Belgacem S, 2012, LECT NOTES COMPUT SC, V7594, P288, DOI 10.1007/978-3-642-33564-8_35
   Bowden R, 2004, LECT NOTES COMPUT SC, V3021, P390
   Campr P., ENTERFACE 08
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dreuw P, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P293
   ELMEZAIN M, 2010, WASET, V3, P131
   Fang GL, 2004, IEEE T SYST MAN CY A, V34, P305, DOI 10.1109/TSMCA.2004.824852
   Fang GL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P312, DOI 10.1109/AFGR.2002.1004172
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FELS SS, 1993, IEEE T NEURAL NETWOR, V4, P2, DOI 10.1109/72.182690
   Gaus Y. F. A., 2012, Proceedings of the 2012 3rd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2012), P262, DOI 10.1109/ISMS.2012.67
   Grobel K, 1997, IEEE SYS MAN CYBERN, P162, DOI 10.1109/ICSMC.1997.625742
   Hadfield S, 2014, IEEE T PATTERN ANAL, V36, P564, DOI 10.1109/TPAMI.2013.162
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Kadous M W., 1996, P WORKSHOP INTEGRATI, P165
   Kelly D, 2011, IEEE T SYST MAN CY B, V41, P526, DOI 10.1109/TSMCB.2010.2065802
   Kim JS, 1996, IEEE T SYST MAN CY B, V26, P354, DOI 10.1109/3477.485888
   Kong WW, 2008, PATTERN RECOGN, V41, P1638, DOI 10.1016/j.patcog.2007.10.016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Lim KM, 2016, EXPERT SYST APPL, V54, P208, DOI 10.1016/j.eswa.2016.01.047
   Lo BPL, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P158, DOI 10.1109/ISIMP.2001.925356
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ni XB, 2013, COMM COM INF SC, V391, P263
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paulraj MP, 2008, ICED: 2008 INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN, VOLS 1 AND 2, P5
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   Starner T., 1997, Motion-Based Recognit, P227
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Tanibata N., 2002, PROC INT C VISION IN, P391
   Valli C., 2005, GALLAUDET DICT AM SI
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   Wilbur R., 2006, Purdue rvl-slll american sign language database
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zahedi M, 2005, LECT NOTES COMPUT SC, V3663, P401
   Zaki MM, 2011, PATTERN RECOGN LETT, V32, P572, DOI 10.1016/j.patrec.2010.11.013
   Zhou Q., 2001, Proceedings of IEEE Workshop on Performance Evaluation of Tracking and Surveillance, P46
NR 48
TC 27
Z9 29
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 538
EP 545
DI 10.1016/j.jvcir.2016.07.020
PN B
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600012
DA 2024-07-18
ER

PT J
AU Qi, SH
   Jing, PG
   Wang, X
   Nie, LQ
AF Qi, Shuhan
   Jing, Peiguang
   Wang, Xuan
   Nie, Liqiang
TI Quality biased multimedia data retrieval in microblogs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Microblog retrieval; Quality model; Multiview embedding
AB With the rapid development of social media platforms, huge amount of user generated contents (UGC) are generated ceaselessly. In recent years, content based microblog retrieval has attracted extensive research attention. Effective microblog retrieval services complex analysis of short text and multimedia contents. In this paper, we present a quality biased multimedia microblog retrieval framework. First, we develop an anchor graph based multiview embedding framework which maps the multimedia content features into a unified latent space. Then, the content matching scores of testing microblogs related to the query are obtained by a Markov random field. Further, we employ an quality model to incorporate both microblog quality and content matching. As compared with the state-of-art methods, experimental results demonstrate the effectiveness of the proposed approach. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Qi, Shuhan; Wang, Xuan] Harbin Inst Technol, ShenZhen Grad Sch, Comp Applicat Res Ctr, Shenzhen, Peoples R China.
   [Jing, Peiguang] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Nie, Liqiang] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Harbin Institute of Technology; Tianjin University; National University
   of Singapore
RP Wang, X (corresponding author), Harbin Inst Technol, ShenZhen Grad Sch, Comp Applicat Res Ctr, Shenzhen, Peoples R China.
EM wangxuan@cs.hitsz.edu.cn
RI wang, xuan/GXF-3679-2022; wang, xuan/JBJ-6948-2023
CR Allan J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P37, DOI 10.1145/290941.290954
   [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], 2007, P 9 WEBKDD 1 SNA KDD, DOI [10.1145/1348549.1348556, DOI 10.1145/1348549.1348556]
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], 1980, Markov Random Fields and Their Applications, volume 1 of Contemporary Mathematics
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], P 5 ACM C MULT SYST
   Bendersky M., 2011, P 4 ACM INT C WEB SE, P95, DOI DOI 10.1145/1935826.1935849
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Choi J., 2012, P 21 ACM INT C INFOR, P1834, DOI DOI 10.1145/2396761.2398527
   Chunmei Gu, 2012, 2012 International Conference on Business Computing and Global Informatization (BCGIN), P537, DOI 10.1109/BCGIN.2012.146
   Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57
   Hu Y., 2014, J VIS COMMUN IMAGE R
   Huang M., 2011, Proc. of 5th Int. Joint Conf. on Natural Language Process, P373
   Ihler AT, 2005, J MACH LEARN RES, V6, P905
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu, 2010, P 27 INT C MACH LEAR, P679, DOI DOI 10.1007/s11263-007-0090-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu GY, 2015, IEEE I CONF COMP VIS, P2434, DOI 10.1109/ICCV.2015.280
   Lu GY, 2015, MULTIMED TOOLS APPL, V74, P479, DOI 10.1007/s11042-014-1977-3
   Metzler D., 2011, P TEXT RETR C TREC
   Naveed Nasir., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P183
   Nie WN, 2016, MASS SPECTROM REV, V35, P331, DOI 10.1002/mas.21439
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qi SH, 2015, NEUROCOMPUTING, V158, P225, DOI 10.1016/j.neucom.2015.01.041
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sui Yue, 2010, 2010 Second International Conference on Communication Systems, Networks and Applications (ICCSNA 2010), P164, DOI 10.1109/ICCSNA.2010.5588676
   Wang W, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P211, DOI 10.1145/2671188.2749337
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Wang Y., 2012, Proceedings of the 20th ACM International Conference on Multimedia, P865, DOI [DOI 10.1145/2393347.239633216, 10.1145/2393347.239633216]
   Weerkamp W., 2008, Proceedings of ACL-08: HLT, P923
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhang L., 2015, IEEE T AUTOM SCI ENG
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhang L, 2015, LECT NOTES ELECTR EN, V322, P491, DOI 10.1007/978-3-319-08991-1_51
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 43
TC 2
Z9 2
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 838
EP 846
DI 10.1016/j.jvcir.2016.08.015
PN B
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600037
DA 2024-07-18
ER

PT J
AU Ulhaq, A
   Yin, XX
   He, J
   Zhang, YC
AF Ulhaq, Anwaar
   Yin, Xiaoxia
   He, Jing
   Zhang, Yanchun
TI FACE: Fully Automated Context Enhancement for night-time video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-spectral video fusion; Night vision; Color morphing; Global and
   local contextual features
ID IMAGE QUALITY ASSESSMENT; MANY-CORE PROCESSORS; STRUCTURAL SIMILARITY;
   PARALLEL FRAMEWORK; COLORIZATION; COLOR; RECOGNITION; FUSION
AB Unfavorable lighting conditions pose significant challenges to imaging devices. Use of multiple sensor fusion and false colorization has been demonstrated by many recent works. However, semi-automatic nature of these approaches make them less attractive. To address these shortcomings, we present a color night vision system, named FACE (Fully Automated Context Enhancement). It uses enhanced multi spectral video fusion and fully automated color transform based color morphing to process multiple video streams captured by infrared (IR) and low light visible (VIS) sensors. At first, we introduce glare-suppressed inter-channel fusion in RGB color space to negate the ghost-like effect produced by IR channel. We then introduce color value imputation with deep KNN framework for. joint classification of grayscale and color imagery. A suitable color transform is then sought to give a day-like color appearance to night vision imagery. Objective quality evaluation indicates the effectiveness of our framework for context enhancement at nighttime. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ulhaq, Anwaar; He, Jing] Victoria Univ, Coll Engn & Sci, Melbourne, Vic 8001, Australia.
   [Yin, Xiaoxia; Zhang, Yanchun] Victoria Univ, Ctr Appl Informat, Melbourne, Vic 8001, Australia.
C3 Victoria University; Victoria University
RP Ulhaq, A (corresponding author), Victoria Univ, Coll Engn & Sci, Melbourne, Vic 8001, Australia.
EM anwaar.ulhaq@vu.edu.au
RI Ulhaq, Anwaar/AAN-5714-2020; Yin, Xiaoxia/R-9289-2019
OI Ulhaq, Anwaar/0000-0002-5145-7276; He, Jing/0000-0001-6488-1052
CR Anwaar-ul-Haq, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P435, DOI 10.1109/DICTA.2010.80
   Anwaar-ul-Haq, 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P399, DOI 10.1109/ISCC.2010.5546579
   Anwaar-ul-Haq, 2005, IEEE: 2005 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES, PROCEEDINGS, P138, DOI 10.1109/ICET.2005.1558869
   Chen GH, 2006, IEEE IMAGE PROC, P2929, DOI 10.1109/ICIP.2006.313132
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Cvejic N., 2005, INT J SIGNAL PROCESS, V2, P178
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fay D.A., 2000, PROC 3 INT C INF FUS, P1
   Haq Anwaar-ul, 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P529, DOI 10.1109/ISCC.2010.5546791
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Hogervorst M. A., 2007, INF FUS 2007 10 INT, P1
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Klein L. A., 2004, SENSOR DATA FUSION T, V324
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li G., 2007, DEF SEC S
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Petrovic V, 2005, OPT ENG, V44, DOI 10.1117/1.2009764
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Russakoff DB, 2004, LECT NOTES COMPUT SC, V3023, P596
   Toet A., 2003, Information Fusion, V4, P155, DOI 10.1016/S1566-2535(03)00038-1
   Toet A., 2014, IS T SPIE ELECT IMAG, V53
   Wang L, 2007, INT S MULT IM PROC P
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WAXMAN AM, 1995, P SOC PHOTO-OPT INS, V2463, P58, DOI 10.1117/12.212755
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Zhang XQ, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING SYSTEMS, P258, DOI 10.1109/ICSPS.2009.72
   Zheng Y, 2008, INFORM FUSION, V9, P186, DOI 10.1016/j.inffus.2007.02.002
NR 39
TC 9
Z9 9
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 682
EP 693
DI 10.1016/j.jvcir.2016.08.008
PN B
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600023
DA 2024-07-18
ER

PT J
AU Ullah, A
   Chen, W
   Sun, HG
   Khan, MA
AF Ullah, Asmat
   Chen, Wen
   Sun, HongGuang
   Khan, Mushtaq Ahmad
TI A modified multi-grid algorithm for a novel variational model to remove
   multiplicative noise
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Maximum a posteriori (MAP); Total variation; Additive operator
   splitting; Multi-grid; Multiplicative noise; Convex function
ID IMAGES
AB This paper proposes a novel variational model and a fast algorithm for its numerical approximation to remove multiplicative noise from digital images. By applying a maximum a posteriori (MAP), we obtained a strictly convex objective functional whose minimization leads to non-linear partial differential equations. As a result, developing a fast numerical scheme is difficult because of the high nonlinearity and stiffness of the associated Euler-Lagrange equation and standard unilevel iterative methods are not appropriate. To this end, we develop an efficient non-linear multi-grid algorithm with an improved smoother. We also discuss a local Fourier analysis of the associated smoothers which leads to a new and more effective smoother. Experimental results using both synthetic and realistic images, illustrate advantages of our proposed model in visual improvement as well as an increase in the peak signal-to-noise ratio over comparing to related recent corresponding PDE methods. We compare numerical results of new multigrid algorithm via modified smoother with traditional time marching schemes and with multigrid method via (local and global) fixed point smoother as well. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ullah, Asmat; Chen, Wen; Sun, HongGuang; Khan, Mushtaq Ahmad] Hohai Univ, Coll Mech & Mat, State Key Lab Hydrol Water Resources & Hydraul En, Ctr Numer Simulat Software Engn & Sci, Nanjing 210098, Jiangsu, Peoples R China.
C3 Hohai University
RP Ullah, A; Chen, W (corresponding author), Hohai Univ, Coll Mech & Mat, State Key Lab Hydrol Water Resources & Hydraul En, Ctr Numer Simulat Software Engn & Sci, Nanjing 210098, Jiangsu, Peoples R China.
EM asmatullah@hhu.edu.cn; chenwen@hhu.edu.cn
RI Heisenberg, X/K-9096-2015; Sun, HongGuang/A-9385-2010; Ullah, Md
   Asmat/GYU-9827-2022
OI Ullah, Md Asmat/0000-0003-4308-4200
FU National Science Funds of China [11572111, 11372097]; 111 Project
   [B12032]
FX The work described in this paper was supported by the National Science
   Funds of China (Grant Nos. 11572111, 11372097) and the 111 Project
   (Grant No. B12032).
CR [Anonymous], 2002, COMPUTATIONAL METHOD
   [Anonymous], 1992, An Introduction to Multigrid Methods
   Ascher UM, 2006, SIAM J SCI COMPUT, V28, P339, DOI 10.1137/040617261
   AUBERT G., 2000, Mathematical Problems in Image Processing: Partial Differential Equations and the Calculus of Variations, V147
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Badshah N, 2008, COMMUN COMPUT PHYS, V4, P294
   Badshah N, 2010, COMMUN COMPUT PHYS, V7, P759, DOI 10.4208/cicp.2009.09.026
   Badshah N, 2009, IEEE T IMAGE PROCESS, V18, P1097, DOI 10.1109/TIP.2009.2014260
   Badshah Noor., 2012, IOSR J MATH, V2, P1, DOI [10.9790/5728-0220108, DOI 10.9790/5728-0220108]
   Bioucas D, 2009, P IEEE INT C IM PROC
   BRANDT A, 1977, MATH COMPUT, V31, P333, DOI 10.1090/S0025-5718-1977-0431719-X
   Brito-Loeza C, 2010, SIAM J IMAGING SCI, V3, P363, DOI 10.1137/080737903
   BURCKHARDT CB, 1978, IEEE T SON ULTRASON, V25, P1, DOI 10.1109/T-SU.1978.30978
   Chambolle A, 2008, INTRO TOTAL VARIATIO, V4, P2278
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chan T.F., 2006, SIAM J SCI COMPUT, V20, P387
   Chen K, 2007, J SCI COMPUT, V33, P115, DOI 10.1007/s10915-007-9145-9
   Chen YJ, 2014, IEEE SIGNAL PROC LET, V21, P1370, DOI 10.1109/LSP.2014.2337274
   Chumchob N, 2013, INT J COMPUT MATH, V90, P140, DOI 10.1080/00207160.2012.709625
   Dong YQ, 2013, E ASIAN J APPL MATH, V3, P263, DOI 10.4208/eajam.240713.120813a
   Dong YQ, 2013, SIAM J IMAGING SCI, V6, P1598, DOI 10.1137/120870621
   Durand S., 2009, SCALE SPACE VARIATIO
   Feng WS, 2014, IEEE T IMAGE PROCESS, V23, P1831, DOI 10.1109/TIP.2014.2308432
   Glowinski R, 2003, COMPUT PHYS COMMUN, V152, P242, DOI 10.1016/S0010-4655(02)00823-8
   Goodman J., 1975, LASER SPECKLE RELATE, P9, DOI [DOI 10.1007/978-3-662-43205-1_2, DOI 10.1088/0335-7368/6/1/301]
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   Guang Xial, 2013, MATH PROBL ENG, V2013
   Hirakawa K, 2006, IEEE T IMAGE PROCESS, V15, P2730, DOI 10.1109/TIP.2006.877352
   Huang LL, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/250768
   Huang YM, 2013, SIAM J SCI COMPUT, V35, pA2856, DOI 10.1137/120898693
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Jin ZM, 2010, J MATH ANAL APPL, V362, P415, DOI 10.1016/j.jmaa.2009.08.036
   Liu GJ, 2009, SIGNAL PROCESS, V89, P2233, DOI 10.1016/j.sigpro.2009.04.042
   Liu P., 2014, SIAM J IMAGING SCI, Vxx, P1
   Longa Z, DENOISING IMAGES MUL
   MUNSON DC, 1989, IEEE T ACOUST SPEECH, V37, P2131, DOI 10.1109/29.45556
   Osher S., 2005, SIMULATION, V02, P460
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Savage J, 2005, INT J COMPUT MATH, V82, P1001, DOI 10.1080/00207160500069904
   Shen JH, 2003, PHYSICA D, V175, P241, DOI 10.1016/S0167-2789(02)00734-0
   Sheng C, 2005, TOTAL VARIATION BASE, V36, P245
   Shi BL, 2012, J VIS COMMUN IMAGE R, V23, P126, DOI 10.1016/j.jvcir.2011.08.003
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Trottenberg U., 2001, MULTIGRID I ALGORITH
   Ullah A, 2016, COMPUT MATH APPL, V71, P2034, DOI 10.1016/j.camwa.2016.03.024
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Zhao XL, 2014, SIAM J IMAGING SCI, V7, P456, DOI 10.1137/13092472X
NR 50
TC 7
Z9 7
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 485
EP 501
DI 10.1016/j.jvcir.2016.07.016
PN B
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600008
DA 2024-07-18
ER

PT J
AU Boudhane, M
   Nsiri, B
AF Boudhane, Mohcine
   Nsiri, Benayad
TI Underwater image processing method for fish localization and detection
   in submarine environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Image denoising; Scene understanding; Underwater image
   processing
AB Object detection is an important process in image processing, it aims to detect instances of semantic objects of a certain class in digital images and videos. Object detection has applications in many areas of computer vision such as underwater fish detection. In this paper we present a method for preprocessing and fish localization in underwater images. We are based on a Poisson Gauss theory, because it can accurately describe the noise present in a large variety of imaging systems. In the preprocessing step we denoise and restore the raw images. These images are split into regions utilizing the mean shift algorithm. For each region, statistical estimation is done independently in order to combine regions into objects. The method is tested under different underwater conditions. Experimental results show that the proposed approach outperforms state of the art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Boudhane, Mohcine] Univ Appl Sci, Fac Comp Sci & Elect Engn, Grenzstr 5, D-24149 Kiel, Germany.
   [Boudhane, Mohcine; Nsiri, Benayad] Univ Hassan 2, Fac Sci, Ainchock BP 5366, Casablanca 20000, Morocco.
C3 Hassan II University of Casablanca
RP Boudhane, M (corresponding author), Univ Appl Sci, Fac Comp Sci & Elect Engn, Grenzstr 5, D-24149 Kiel, Germany.
EM mrboudhane@gmail.com
OI NSIRI, Benayad/0000-0003-3885-9534; Boudhane,
   Mohcine/0000-0003-1197-4719
CR Buades A., 2011, IMAGE PROC LINE, V1
   Chang CC, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P346, DOI 10.1109/IITA.2008.259
   Chang PCY, 2003, APPL OPTICS, V42, P2794, DOI 10.1364/AO.42.002794
   Cui Y, 2012, PROCEEDINGS OF CIE 2012 LIGHTING QUALITY AND ENERGY EFFICIENCY, P1
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dasgupta S., 1999, 40th Annual Symposium on Foundations of Computer Science (Cat. No.99CB37039), P634, DOI 10.1109/SFFCS.1999.814639
   Foi A, 2011, I S BIOMED IMAGING, P1809, DOI 10.1109/ISBI.2011.5872758
   Forand J.L., 1993, P OCEANS 93
   Gruev V, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P62, DOI 10.1109/LISSA.2009.4906710
   Jezierska A., 2014, IEEE T IMAGE PROCESS, V22, P91
   Jin L., 2006, P INT S MET 06 HANGZ, P72
   Jordan M., 2006, Information science and statistics
   Kirkwood WJ., 2008, OCEANS 2008 MTS IEEE, P15, DOI [10.1109/OCEANSKOBE.2008.4530879, DOI 10.1109/OCEANSKOBE.2008.4530879]
   Kocak DM, 2005, MAR TECHNOL SOC J, V39, P5, DOI 10.4031/002533205787442576
   Legris M., 2003, GRETSI
   Liang D., 2007, P IEEE ICIP 07 SOUTH, P369
   Liu F, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P1454
   Mäkitalo M, 2013, IEEE T IMAGE PROCESS, V22, P91, DOI 10.1109/TIP.2012.2202675
   Nath A, 2013, INT CONF COMM SYST, P157, DOI 10.1109/CSNT.2013.43
   Ouyang B, 2013, IEEE J OCEANIC ENG, V38, P566, DOI 10.1109/JOE.2012.2229066
   Prabhakar C. J., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P322, DOI 10.1109/ICSIP.2010.5697491
   Rabbani H, 2006, Proceedings ELMAR-2006, P85, DOI 10.1109/ELMAR.2006.329521
   Rodriguez G., 2007, Lecture Notes on Generalized Linear Models
   Srisamosorn V, 2013, PROC SICE ANN CONF, P655
   Sun Feifei, 2011, 2011 International Conference on Intelligent Computation Technology and Automation (ICICTA), P417, DOI 10.1109/ICICTA.2011.388
   Swartz B., 1991, SPIE, V42, P42
   Yang SB, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P95, DOI 10.1109/ICCSE.2009.5228518
   Yong Lei, 2009, Proceedings of the 2009 9th International Conference on Electronic Measurement & Instruments (ICEMI 2009), P1, DOI 10.1109/ICEMI.2009.5274772
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
NR 29
TC 44
Z9 47
U1 6
U2 92
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 226
EP 238
DI 10.1016/j.jvcir.2016.05.017
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900022
DA 2024-07-18
ER

PT J
AU Mattheij, R
   Groeneveld, K
   Postma, E
   van den Herik, HJ
AF Mattheij, Ruud
   Groeneveld, Kim
   Postma, Eric
   van den Herik, H. Jaap
TI Depth-based detection with region comparison features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face detection; Person detection; Depth data; Haar-like features; Random
   forest classifier; Integral image representation; Region comparion;
   Kinect
ID HUMAN POSE ESTIMATION
AB Most object detection approaches proposed over the years rely on visual features that help to segregate objects from their backgrounds. For instance, segregation may be facilitated by depth features because they provide direct access to the third dimension. Such access enables accurate object-background segregation. Although they provide a rich source of information, depth images are sensitive to background noise. This paper addresses the issue of handling background noise for accurate foreground-background segregation. It presents and evaluates the Region Comparison (RC) features for fast and accurate body part detection. RC features are depth features inspired by the well-known Viola Jones detector. Their performances are compared to the recently proposed Pixel Comparison (PC) features, which were designed for fast and accurate object detection from Kinect-generated depth images. The results of our evaluation reveal that RC features outperform PC features in detection accuracy and computational efficiency. From these results we may conclude that RC features are to be preferred over PC features to achieve accurate and fast object detection in noisy depth images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Mattheij, Ruud; Groeneveld, Kim; Postma, Eric; van den Herik, H. Jaap] Tilburg Univ, Tilburg Ctr Cognit & Commun TiCC, POB 90153, NL-5000 LE Tilburg, Netherlands.
C3 Tilburg University
RP Mattheij, R (corresponding author), Tilburg Univ, Tilburg Ctr Cognit & Commun TiCC, POB 90153, NL-5000 LE Tilburg, Netherlands.
EM R.J.H.Mattheij@tilburguniversity.edu;
   K.Groeneveld@tilburguniversity.edu; E.O.Postma@tilburguniversity.edu;
   hj.vandenherik@law.leidenuniv.nl
OI van den Herik, Jaap/0000-0001-9751-761X
FU Agentschap.nl under the EOS program for Long Term research; Human
   Technology Interaction group4 from Eindhoven University
FX We gratefully thank Dr. Jamie Shotton for his advice regarding our
   implementation of their PC features. The research described in this
   paper is carried out with a grant from Agentschap.nl under the EOS
   program for Long Term research, for which we would like to express our
   gratitude. Moreover, we would like thank (1) the Human Technology
   Interaction group<SUP>4</SUP> from Eindhoven University, and (2) our
   colleagues from the Smart Homes Foundation<SUP>5</SUP> for their
   collaboration and support.
CR Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   [Anonymous], 2000, GEOMATIC METHOD ANAL, DOI DOI 10.1007/3-540-45597-3_
   [Anonymous], 2010, SURVEY RECENT ADV FA
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.241
   [Anonymous], 2014, Appl Comput Inform, DOI DOI 10.1016/J.ACI.2014.04.001
   Baak A., 2013, Consumer Depth Camerasfor Computer Vision: Research Topics and Applications, P71, DOI DOI 10.1007/978-1-4471-4640-7_5
   Bergboer N., 2007, SIKS DISSERTATION SE
   Brandao A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P367
   Breiman L., 2001, RANDOM FORESTS, V45
   Brodersen Kay H., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3121, DOI 10.1109/ICPR.2010.764
   Brunton A, 2014, COMPUT VIS IMAGE UND, V128, P1, DOI 10.1016/j.cviu.2014.05.005
   Burgin W, 2011, ACMIEEE INT CONF HUM, P119, DOI 10.1145/1957656.1957690
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941
   Carrillo H., 2014, ROBOT2013 1 IB ROB C, V1, P347
   Chan KC, 2013, IEEE INT CONF ROBOT, P1623, DOI 10.1109/ICRA.2013.6630787
   Chang JY, 2013, ETRI J, V35, P949, DOI 10.4218/etrij.13.2013.0063
   Criminisi A., 2012, DECISION FORESTS UNI, V7
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Dal Mutto C, 2012, SPRBRIEF ELECT, P93
   de Croon G.C.H.E., 2011, ADAPTIVE GAZE CONTRO, V3, P264
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fanello SR, 2014, PROC CVPR IEEE, P1709, DOI 10.1109/CVPR.2014.221
   Gu JS, 1996, INT J SYST SCI, V27, P623, DOI 10.1080/00207729608929258
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hg RI, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P42, DOI 10.1109/SITIS.2012.17
   Hoiem D., 2006, CVPR
   Jiang FJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1100, DOI 10.1016/j.image.2013.07.006
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Lee MunWai., 2007, WMVC, P23
   Liao S., 2012, MSUCSE1215
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu SG, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P251, DOI 10.1109/ACPR.2013.35
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Omary Z., 2010, INT J INFONOMICS IJI, V3
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Powers DM., 2011, SIE07001 FLIND U
   Riche Nicolas, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P143, DOI 10.1007/978-3-642-23968-7_15
   Shotton J, 2013, Commun. ACM, V56, P119, DOI [DOI 10.1145/2398356.2398381, 10.1145/2398356.2398381]
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Smisek J., 2013, 3D with Kinect Consumer Depth Cameras for Computer Vision, P3, DOI [DOI 10.1007/978-1-4471-4640-7_1, 10.1007/978-1-4471-4640-7-1, DOI 10.1007/978-1-4471-4640-7-1]
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Tang YQ, 2014, COMPUT VIS IMAGE UND, V128, P18, DOI 10.1016/j.cviu.2014.05.008
   Vijayanagar KR, 2014, MOBILE NETW APPL, V19, P414, DOI 10.1007/s11036-013-0458-7
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P., 2005, DETECTING PEDESTRIAN, V63, P153
   Wang J., 2014, HIGH ACCURACY HOLE F
   Wu B., 2007, DETECTION TRACKING M, V75, P247
   Wu J, 2013, MEAS SCI REV, V13, P122, DOI 10.2478/msr-2013-0021
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao W., 2003, FACE RECOGNITION LIT, V35, P399
NR 53
TC 2
Z9 2
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 82
EP 99
DI 10.1016/j.jvcir.2016.02.008
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100009
DA 2024-07-18
ER

PT J
AU Pribyl, B
   Chalmers, A
   Zemcík, P
   Hooberman, L
   Cadík, M
AF Pribyl, Bronislav
   Chalmers, Alan
   Zemcik, Pavel
   Hooberman, Lucy
   Cadik, Martin
TI Evaluation of feature point detection in high dynamic range imagery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature point detection; Interest point detection; Corner point
   detection; Repeatability rate; Distribution of feature points; High
   dynamic range imagery; HDR; Tone mapping
ID TONE REPRODUCTION; DESCRIPTORS
AB This paper evaluates the suitability of High Dynamic Range (HDR) imaging techniques for Feature Point (FP) detection under demanding lighting conditions. The FPs are evaluated in HDR, tone mapped HDR, and traditional Low Dynamic Range (LDR) images. Eleven global and local tone mapping operators are evaluated and six widely used FP detectors are used in the experiments (Harris, Shi-Tomasi, DoG, Fast Hessian, FAST, and BRISK). The distribution and repeatability rate of FPs are studied under changes of camera viewpoint, camera distance, and scene lighting. The results of the experiments show that current FP detectors cannot cope with HDR images well. The best contemporary solution is thus tone mapping of HDR images using a local tone mapper as a pre-processing step. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pribyl, Bronislav; Zemcik, Pavel; Cadik, Martin] Brno Univ Technol, Fac Informat Technol, Dept Comp Graph & Multimedia, Bozetechova 2, Brno 61266, Czech Republic.
   [Chalmers, Alan; Hooberman, Lucy] Univ Warwick, WMG, Coventry CV4 7AL, W Midlands, England.
C3 Brno University of Technology; University of Warwick
RP Pribyl, B (corresponding author), Brno Univ Technol, Fac Informat Technol, Dept Comp Graph & Multimedia, Bozetechova 2, Brno 61266, Czech Republic.
EM ipribyl@fit.vutbr.cz; alan.chalmers@warwick.ac.uk; zemcik@fit.vutbr.cz;
   l.hooberman@warwick.ac.uk; cadik@fit.vutbr.cz
RI Cadik, Martin/O-4824-2014; Zemcik, Pavel/G-6439-2010
OI Cadik, Martin/0000-0001-7058-9912; Zemcik, Pavel/0000-0001-7969-5877
FU Technology Agency of the Czech Republic [TE01020415]; Ministry of
   Education, Youth and Sports of the Czech Republic from the National
   Programme of Sustainability (NPU II) project "IT4Innovations excellence
   in science" [LQ1602]; SoMoPro II grant from the EU 7 FP People Programme
   Marie Curie Actions [REA 291782]; SoMoPro II grant from the South
   Moravian Region; EU [IC1005]; Royal Society Industrial Fellowship
FX This work was supported by the Technology Agency of the Czech Republic
   by project TE01020415 "V3C" and by The Ministry of Education, Youth and
   Sports of the Czech Republic from the National Programme of
   Sustainability (NPU II) project "IT4Innovations excellence in science -
   LQ1602". The research was further supported by SoMoPro II grant
   (financial contribution from the EU 7 FP People Programme Marie Curie
   Actions, REA 291782, and from the South Moravian Region). The work was
   also partially supported by the EU ICT COST Action IC1005 "HDRi: The
   digital capture, storage, transmission and display of real-world
   lighting". Alan Chalmers is supported by a Royal Society Industrial
   Fellowship.
CR [Anonymous], 5 INT S TURK GERM JO
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BROWN M., 2002, BRIT MACHINE VISION, P656, DOI [10.5244/C.16.23, DOI 10.5244/C.16.23]
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Fattal R., 2012, EDGE AVOIDING WAVELE
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Fraundorfer F., 2005, Proceedings of computer vision and pattern recognition-CVPR workshops, P33
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Green W. B., 1983, ELECT COMPUTER SCI E
   Harris C., 1988, ALVEY VISION C, P147151
   Heidrich Wolfgang, ERIK REINHARD
   Jazayeri I., 2008, INT ARCH PHOTOGRAMME, V37, P69
   Jazayeri I, 2010, PHOTOGRAMM REC, V25, P24, DOI 10.1111/j.1477-9730.2009.00559.x
   Kiser C., 2012, P IEEE INT C IM PROC, V134, P2749
   Kontogianni G, 2015, INT ARCH PHOTOGRAMM, V40-5, P325, DOI 10.5194/isprsarchives-XL-5-W4-325-2015
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   May M., 2009, THEORY PRACTICE COMP
   May M, 2011, LECT NOTES COMPUT SC, V7087, P289, DOI 10.1007/978-3-642-25367-6_26
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Palmer S., 1999, VISION SCI PHOTONS P
   Petit J., 2012, Virtual Reality, P1
   Pribyl B., 2015, SUPPLEMENTARY DATA R
   Pribyl B., 2012, SPRING C COMP GRAPH, P156
   Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   WALLIS KF, 1974, J AM STAT ASSOC, V69, P18, DOI 10.2307/2285495
   Yan Cui, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P226, DOI 10.1007/978-3-642-23123-0_23
   Yates R, 2008, IEEE SIGNAL PROC MAG, V25, P132, DOI 10.1109/MSP.2007.914713
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 45
TC 22
Z9 24
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 141
EP 160
DI 10.1016/j.jvcir.2016.02.007
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100013
DA 2024-07-18
ER

PT J
AU Hu, YX
   Nie, LQ
AF Hu, Yuxing
   Nie, Liqiang
TI An aerial image recognition framework using discrimination and
   redundancy quality measure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Aerial image; Categorization; Discriminative; Subgraph; Data mining;
   Image recognition; Framework; Quality measure
ID PREDICTION; ALGORITHM; FUSION; CUES
AB Aerial image categorization plays an indispensable role in remote sensing and artificial intelligence. In this paper, we propose a new aerial image categorization framework, focusing on organizing the local patches of each aerial image into multiple discriminative subgraphs. These meaningful subgraphs reflect both the geometric property and the color distribution of an aerial image. First, each aerial image is decomposed into a collection of regions in terms of their color intensities. Thereby region connected graph (RCG), which models the connection between the spatial neighboring regions, is constructed to encode the spatial context of an aerial image. Second, a novel subgraph mining technique is adopted to discover the frequent structures in the RCGs constructed from the training aerial images. Thereafter, a set of refined structures is selected among the frequent ones toward being highly discriminative and low redundant. Lastly, given a new aerial image, its sub-RCGs corresponding to the refined structures are extracted. They are further quantized into a discriminative vector for SVM classification. Thorough experimental results validate the effectiveness of the proposed method. In addition, the visualized mined subgraphs show that the discriminative topologies of each aerial image are discovered. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hu, Yuxing] Tsinghua Univ, Sch Aerosp, Beijing, Peoples R China.
   [Nie, Liqiang] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 Tsinghua University; National University of Singapore
RP Hu, YX (corresponding author), Tsinghua Univ, Sch Aerosp, Beijing, Peoples R China.
EM thuyuxinghu@gmail.com
CR [Anonymous], ACM T PROGRAM LANG S
   [Anonymous], P IEEE C PATT REC SE
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], IEEE T NEUR IN PRESS
   [Anonymous], 2010, ADV NEURAL PROCESSIN
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P SPIE IM SIGN PROC
   [Anonymous], IEEE T NEUR IN PRESS
   [Anonymous], P IEEE INT COMP VIS
   Berg A. C., 2007, PROC IEEE INT COMP V, P1
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   Chen C, 2014, IEEE J-STARS, V7, P1047, DOI 10.1109/JSTARS.2013.2295610
   Chen HM, 2013, IEEE J-STARS, V6, P1834, DOI 10.1109/JSTARS.2012.2225097
   Cormen TH, 2001, Introduction to algorithms, P540
   Cristianini N, 2002, AI MAG, V23, P31
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   Jia S, 2014, IEEE J-STARS, V7, P1023, DOI 10.1109/JSTARS.2013.2282161
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Jurie F, 2004, PROC CVPR IEEE, P90
   Kuramochi M, 2004, IEEE T KNOWL DATA EN, V16, P1038, DOI 10.1109/TKDE.2004.33
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Luo B, 2013, IEEE J-STARS, V6, P1899, DOI 10.1109/JSTARS.2012.2228254
   Makarau A, 2013, IEEE J-STARS, V6, P969, DOI 10.1109/JSTARS.2012.2219507
   Maloof MA, 2003, MACH LEARN, V53, P157, DOI 10.1023/A:1025623527461
   Porway J, 2008, PROC CVPR IEEE, P141
   Shervashidze Nino, 2009, P INT C ART INT STAT, P488
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tong YX, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P54
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yao B., 2007, EMMCVPR
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
NR 43
TC 2
Z9 2
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 53
EP 62
DI 10.1016/j.jvcir.2015.04.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Akinlar, C
   Chome, E
AF Akinlar, Cuneyt
   Chome, Edward
TI PEL: A Predictive Edge Linking algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edge detection; Edge linking; Edge segment detection; Canny; CannySR;
   Edge Drawing (ED); Contour detection; gPb
ID REAL-TIME EDGE; SEGMENTATION; DETECTOR
AB We propose an edge linking algorithm that takes as input a binary edge map generated by a traditional edge detection algorithm and converts it to a set of edge segments; filling in one pixel gaps in the edge map, cleaning up noisy edge pixel formations and thinning multi-pixel wide edge segments in the process. The proposed edge linking algorithm walks over the edge map based on the predictions generated from its past movements; thus the name Predictive Edge Linking (PEL). We evaluate the performance of PEL both qualitatively using visual experiments and quantitatively within the precision-recall framework of the Berkeley Segmentation Dataset and Benchmark (BSDS 300). Both visual experiments and quantitative evaluation results show that PEL greatly improves the modal quality of binary edge maps produced by traditional edge detectors, and takes a very small amount of time to execute making it suitable for real-time image processing and computer vision applications. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Akinlar, Cuneyt; Chome, Edward] Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
C3 Anadolu University
RP Akinlar, C (corresponding author), Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
EM cakinlar@anadolu.edu.tr; edwardchome@anadolu.edu.tr
RI Akinlar, Cuneyt/U-5132-2019; Akinlar, Cuneyt/AAH-7483-2019
OI Chome, Edward/0000-0002-2065-1498; AKINLAR, CUNEYT/0000-0002-0961-7790
CR Akinlar C., 2015, IEEE INT S INN INT S
   Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020
   Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BASAK J, 1994, IEEE T SYST MAN CYB, V24, P413, DOI 10.1109/21.278991
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   Desolneux A., 2008, From gestalt theory to image analysis a probabilistic approach
   Desolneux A., 2004, GESTALT THEORY COMPU
   FARAG AA, 1995, PATTERN RECOGN, V28, P611, DOI 10.1016/0031-3203(94)00131-5
   Flores JL, 2013, OPTIK, V124, P3260, DOI 10.1016/j.ijleo.2012.10.036
   Ghita O, 2002, J ELECTRON IMAGING, V11, P479, DOI 10.1117/1.1501574
   Guan T, 2015, J INF SCI ENG, V31, P43
   Hajjar A, 1999, IEEE T PATTERN ANAL, V21, P89, DOI 10.1109/34.745740
   Jevtic A, 2009, IEEE IND ELEC, P3177, DOI 10.1109/IECON.2009.5415195
   Ji X., 2013, 1 INT C GEOINF
   Lu DS, 2008, PATTERN RECOGN LETT, V29, P416, DOI 10.1016/j.patrec.2007.10.021
   Luo Q., 2012, J SOFTWARE, V6, P428
   Maeda J, 1998, PATTERN RECOGN, V31, P1993, DOI 10.1016/S0031-3203(98)00056-9
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   Papari G, 2008, IEEE T IMAGE PROCESS, V17, P1950, DOI 10.1109/TIP.2008.2002306
   Qing Lin, 2010, P 2 INT C COMP RES D, P725
   Ren X., 2012, NIPS
   Saber E, 1997, IMAGE VISION COMPUT, V15, P769, DOI 10.1016/S0262-8856(97)00019-X
   Sappa AD, 2008, MULTIMED SYST APPL, P115
   Shih FY, 2004, INFORM SCIENCES, V167, P9, DOI 10.1016/j.ins.2003.07.020
   SNYDER WE, 1992, IMAGE VISION COMPUT, V10, P523, DOI 10.1016/0262-8856(92)90073-C
   Topal C, 2012, J VIS COMMUN IMAGE R, V23, P862, DOI 10.1016/j.jvcir.2012.05.004
   Wang ZJ, 2008, IEEE ASME INT C ADV, P151, DOI 10.1109/AIM.2008.4601650
   XIE M, 1992, PATTERN RECOGN LETT, V13, P647, DOI 10.1016/0167-8655(92)90121-F
   Zhu QM, 1996, IMAGE VISION COMPUT, V14, P59, DOI 10.1016/0262-8856(95)01040-8
NR 34
TC 12
Z9 13
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 159
EP 171
DI 10.1016/j.jvcir.2016.01.017
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200014
DA 2024-07-18
ER

PT J
AU Liu, YF
   Zou, L
   Li, J
   Yan, J
   Shi, WX
   Deng, DX
AF Liu, Yifeng
   Zou, Lian
   Li, Jie
   Yan, Jia
   Shi, Wenxuan
   Deng, Dexiang
TI Segmentation by weighted aggregation and perceptual hash for pedestrian
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pedestrian detection; Intra-class variation; Segmentation by weighted
   aggregation; Probability measure; Perceptual hash; BING; Estimation
   proposals; HASP
ID SUPPORT VECTOR MACHINES; HISTOGRAMS; GRADIENTS
AB Main challenges of pedestrian detection are caused by the intra-class variation of pedestrians in clothing, scales, deformations, occlusions, and backgrounds. The prevalent detection frameworks employ a series of dense sliding windows, which are time-consuming. In this work, we equip the detection framework with another new strategy, and extract the new features, to eliminate the above requirements. Segmentation by weighted aggregation (SWA) provides a probability measure to segment objects from complex backgrounds. Perceptual hash (pHash) has shown its power in similar image retrieval because it is modification-tolerant and scale-invariant. The proposed approach uses binarized normed gradients (BING) to efficiently generate a small set of estimation proposals, and formulates SWA and pHash into a joint descriptor, called HASP, to improve the detection performance significantly. Experimental results both on INRIA dataset and ETH dataset have demonstrated the effectiveness and efficiency of the proposed approach. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Yifeng; Zou, Lian; Li, Jie; Yan, Jia; Deng, Dexiang] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
   [Shi, Wenxuan] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University
RP Zou, L (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
EM zoulian@whu.edu.cn
RI WANG, JINGYI/GSJ-1241-2022; Liu, Yi/HTN-4916-2023; liu, yi/GXE-9662-2022
FU Fundamental Research Funds for the Central Universities [2014212020202];
   National Natural Science Foundation of China [61501334]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (Project No. 2014212020202) and National Natural Science
   Foundation of China (Project No. 61501334).
CR Alonso-Atienza F, 2012, EXPERT SYST APPL, V39, P1956, DOI 10.1016/j.eswa.2011.08.051
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], THESIS INRIA RHONE A
   [Anonymous], 2008, CVPR
   [Anonymous], 2012, IEEE TPAMI
   [Anonymous], 2010, CVPR
   [Anonymous], 2013, IJCV
   [Anonymous], 2007, ICCV
   [Anonymous], 2012, CVPR
   Barbu T, 2014, COMPUT ELECTR ENG, V40, P1072, DOI 10.1016/j.compeleceng.2013.12.004
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   BILGIC B, 2010, FAST HUMAN DETECTION
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CCCC., 2011, LIB SUPPORT VECTOR M
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., 2012, ECCV
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Foroughi Homa, 2014 IEEE INT C AC S
   Gepperth A., 2013, IEEE ITSC
   Gerónimo D, 2007, LECT NOTES COMPUT SC, V4477, P418
   Hu HM, 2015, J VIS COMMUN IMAGE R, V26, P168, DOI 10.1016/j.jvcir.2014.11.009
   Hua CS, 2013, IEICE T INF SYST, VE96D, P1376, DOI 10.1587/transinf.E96.D.1376
   Jafari Omid Hosseini, 2014 IEEE INT C ONRO
   Jeong MR, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, IMAGING AND VISUALIZATION (CGIV): NEW TECHNIQUES AND TRENDS, P69, DOI 10.1109/CGiV.2014.25
   Liu YF, 2014, SIGNAL IMAGE VIDEO P, V8, pS125, DOI 10.1007/s11760-014-0649-0
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390
   Yu Guan, 2013, P INT WORKSH BIOM FO
   Zauner Christoph, 2010, Master's thesis
NR 34
TC 6
Z9 10
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 80
EP 89
DI 10.1016/j.jvcir.2016.01.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200007
DA 2024-07-18
ER

PT J
AU Su, YH
   Lin, JY
   Kuo, CCJ
AF Su, Yuanhang
   Lin, Joe Yuchieh
   Kuo, C. -C. Jay
TI A model-based approach to camera's auto exposure control
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Auto exposure control; Convex function; Digital cameras; Numerical
   analysis; Control systems; Robust systems; Fast convergence; Secant
   method; CMOS digital cameras; HDR
ID SYSTEM
AB A fast and robust camera's auto exposure (AE) technique is proposed in this work. It is achieved by modeling the luminance characteristics of the imaging sensor as a concave or convex function of a control parameter (e.g., exposure time or speed) and the optimal control parameter is computed using a modified secant algorithm with fast convergence. Furthermore, the proposed solution is able to adjust the control parameter automatically in the presence of erroneous exposure. Its superior performance is confirmed by experimental results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Su, Yuanhang] Shanghai Aerosp Elect Technol Inst, 1777 Zhongchun Rd, Shanghai, Peoples R China.
   [Lin, Joe Yuchieh; Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, 3740 McClintock Ave, Los Angeles, CA USA.
C3 University of Southern California
RP Su, YH (corresponding author), 5-A-201 Changxing Hao Rizi, Changzhou, Jiangsu, Peoples R China.
EM suyuanhang@hotmail.com
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035; SU, YUANHANG/0000-0002-0115-1877
CR Cho MH, 1999, P SOC PHOTO-OPT INS, V3650, P93, DOI 10.1117/12.342853
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Haruki T., 1992, P IEEE INT C CONS EL, P322
   Kao WC, 2011, IEEE T INSTRUM MEAS, V60, P1206, DOI 10.1109/TIM.2010.2087835
   Kiran B.R., 2013, INT J COMPUT APPL, V83, P7
   Kuno T, 1998, IEEE T CONSUM ELECTR, V44, P192, DOI 10.1109/30.663747
   Lee JS, 2001, IEEE T CONSUM ELECTR, V47, P694, DOI 10.1109/30.964165
   Liang JY, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P725, DOI 10.1109/ICASIC.2007.4415733
   Mitsunaga T., 1999, Proc. IEEE CVPR '99, P472
   Murakami M, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P2181, DOI 10.1109/FUZZY.1996.553538
   Schulz S., 2007, WSEAS Transactions on Systems and Control, V2, P93
   Shimizu S., 2007, IEEE T CONSUM ELECTR, V2, P93
   Su YH, 2015, I SYMP CONSUM ELECTR, P13, DOI 10.1109/ICCE.2015.7066300
   Yousefi S, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P149, DOI 10.1109/ICCE.2012.6161783
NR 14
TC 15
Z9 17
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 122
EP 129
DI 10.1016/j.jvcir.2016.01.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200010
DA 2024-07-18
ER

PT J
AU Weng, SW
   Pan, JS
AF Weng, Shaowei
   Pan, Jeng-Shyang
TI Integer transform based reversible watermarking incorporating block
   selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible watermark; Invariability of mean value; Histogram shifting;
   Block selection; Integer transform; Difference expansion (DE);
   Smoothness classification; Optimal-threshold-determination of combined
   embedding
ID IMAGE WATERMARKING; EXPANSION
AB We propose a new scheme based on integer Haar wavelet transform (IHWT), which utilizes block selection and difference expansion (DE) (or histogram shifting (HS)). IHWT has the characteristic that the average of a block remains unchanged before and after watermark embedding. Hence, this invariability can be used for determining whether a block is located in a smooth region or not. Specifically, for a block, its mean value and the neighborhood surrounding it are used for estimating the correlation between it and its neighborhood. In this way, only a reduced size location map is needed, and the block size can also be set to a small value. Since small blocks have stronger intra-block correlation than large ones, the embedding distortion caused by modifying small blocks is lower. Otherwise, if the difference between any two neighboring pixels in a block is large, then the distortion produced by directly expanding it is also high. To decrease the class of distortions, DE (or HS) is introduced into the proposed method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Weng, Shaowei] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Fujian Univ Technol, Coll Informat Sci & Engn, Fuzhou, Peoples R China.
   [Pan, Jeng-Shyang] Harbin Inst Technol, Shenzhen Grad Sch, Harbin, Peoples R China.
C3 Guangdong University of Technology; Fujian University of Technology;
   Harbin Institute of Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61201393, 61272498, 61571139]; New Star of Pearl
   River on Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (Nos. 61201393,
   61272498, 61571139), New Star of Pearl River on Science and Technology
   of Guangzhou (No. 2014J2200085).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CP, 2015, J TISSUE ENG, V6, DOI 10.1177/2041731415586318
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2010, P ICIP
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang Z., 2013, IEEE T INF FOREN SEC, V13, P600
   Weng SW, 2014, MULTIMED TOOLS APPL, V72, P3063, DOI 10.1007/s11042-013-1585-7
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xuan GR, 2004, P IWDW, V5, P23
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 38
TC 14
Z9 17
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 25
EP 35
DI 10.1016/j.jvcir.2015.11.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600003
DA 2024-07-18
ER

PT J
AU Abdelali, HA
   Essannouni, F
   Essannouni, L
   Aboutajdine, D
AF Ait Abdelali, Hamd
   Essannouni, Fedwa
   Essannouni, Leila
   Aboutajdine, Driss
TI Fast and robust object tracking via Accept-Reject color histogram-based
   method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Real-time; Object tracking; Adaptive scale;
   Bhattacharyya kernel; Integral image; ROC; Accept-Reject
ID MEAN-SHIFT; PARTICLE FILTER
AB We present a new framework for real-time tracking method of complex non-rigid objects. This new method successfully coped with camera motion, partial occlusions, and target scale variations. The shape of the object tracker is approximated by an ellipse and its appearance by histogram based features derived from local image properties. We use an efficient search scheme (Accept-Reject color histogram-based method (AR), using Bhattacharyya kernel as a similarity measure) to find the image region with a histogram most similar to the target of object tracker. In this paper, we address the problem of scale/shape adaptation and orientation changes of the target. The proposed approach is compared with recent state-of-the-art algorithms. Extensive experiments are performed to testify the proposed method and validate its robustness and effectiveness to track the scale and orientation changes of the target in real-time. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ait Abdelali, Hamd; Essannouni, Fedwa; Essannouni, Leila; Aboutajdine, Driss] Mohammed V Univ, CNRST URAC 29, GSCM LRIT Lab Associate Unit, Fac Sci Rabat, BP 1014, Rabat, Morocco.
C3 Centre National de la Recherche Scientifique & Technologique (CNRST);
   Mohammed V University in Rabat
RP Abdelali, HA (corresponding author), Mohammed V Univ, CNRST URAC 29, GSCM LRIT Lab Associate Unit, Fac Sci Rabat, BP 1014, Rabat, Morocco.
EM hamd.abdelali@gmail.com
RI aboutajdine, driss/AAP-9051-2020
OI Ait Abdelali, Hamd/0000-0003-2212-8665; essannouni,
   leila/0000-0002-5931-8131
CR [Anonymous], 2000, P IEEE C COMP VIS PA
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Carreira-Perpiñán MA, 2007, IEEE T PATTERN ANAL, V29, P767, DOI 10.1109/TPAMI.2007.1057
   Chang HW, 2010, PROC CVPR IEEE, P3043, DOI 10.1109/CVPR.2010.5540056
   Chen Y, 2008, 2008 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT, VOL 1, PROCEEDINGS, P285, DOI 10.1109/CCCM.2008.288
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Das S, 2012, IEEE T IMAGE PROCESS, V21, P2340, DOI 10.1109/TIP.2011.2174370
   Fashing M, 2005, IEEE T PATTERN ANAL, V27, P471, DOI 10.1109/TPAMI.2005.59
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Higham NJ, 2009, WILEY INTERDISCIP RE, V1, P251, DOI 10.1002/wics.18
   Husz ZL, 2011, IEEE T SYST MAN CY B, V41, P1571, DOI 10.1109/TSMCB.2011.2157680
   Jebara T, 2004, J MACH LEARN RES, V5, P819
   Jebara T, 2003, LECT NOTES ARTIF INT, V2777, P57, DOI 10.1007/978-3-540-45167-9_6
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Klein DA, 2010, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2010.5650583
   Lee L.-K., 2011, IECON 2011 37 ANN C
   Li J, 2007, IMAGE VISION COMPUT, V25, P544, DOI 10.1016/j.imavis.2006.05.001
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Porikli F.M., 2005, CVPR
   Rajamani M.R., 2007, Data-based techniques to improve state estimation in model predictive control
   Salhi A., 2012, WORLD ACAD SCI ENG T, V64, P674
   Schreiber D, 2007, PATTERN RECOGN LETT, V28, P1483, DOI 10.1016/j.patrec.2007.03.007
   Vadakkepat P, 2006, IEEE T INSTRUM MEAS, V55, P1823, DOI 10.1109/TIM.2006.881569
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vojir T., 2014, PATTERN RECOGNIT LET
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Welch G., 2001, P SIGGRAPH, P9
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zivkovic Z., 2004, P 2004 IEEE COMP SOC, V1, P1
   Zivkovic Z, 2009, COMPUT VIS IMAGE UND, V113, P743, DOI 10.1016/j.cviu.2008.12.008
NR 35
TC 7
Z9 8
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 219
EP 229
DI 10.1016/j.jvcir.2015.11.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400019
DA 2024-07-18
ER

PT J
AU Shao, WZ
   Li, HB
   Elad, M
AF Shao, Wen-Ze
   Li, Hai-Bo
   Elad, Michael
TI Bi-l<sub>0</sub>-l<sub>2</sub>-norm regularization for blind motion
   deblurring
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Camera shake removal; Blind deblurring; Blur-kernel estimation;
   l(0)-l(2)-minimization; Operator splitting; Augmented Lagrangian; Motion
   deblurring; Image deconvolution
ID PARALLEL FRAMEWORK; IMAGE; CAMERA; SPARSE
AB In blind motion deblurring, leading methods today tend towards highly non-convex approximations of the l(0)-norm, especially in the image regularization term. In this paper, we propose a simple, effective and fast approach for the estimation of the motion blur-kernel, through a bi-l(0)-l(2)-norm regularization imposed on both the intermediate sharp image and the blur-kernel. Compared with existing methods, the proposed regularization is shown to be more effective and robust, leading to a more accurate motion blur-kernel and a better final restored image. A fast numerical scheme is deployed for alternatingly computing the sharp image and the blur-kernel, by coupling the operator splitting and augmented Lagrangian methods. Experimental results on both a benchmark image dataset and real-world motion blurred images show that the proposed approach is highly competitive with state-of-the-art methods in both deblurring effectiveness and computational efficiency. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Shao, Wen-Ze; Elad, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
   [Li, Hai-Bo] KTH Royal Inst Technol, Sch Comp Sci & Commun, S-10044 Stockholm, Sweden.
C3 Technion Israel Institute of Technology; Royal Institute of Technology
RP Shao, WZ (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
EM shaowenze1010@163.com; haiboli@kth.se; elad@cs.technion.ac.il
RI , Miki/AAH-4640-2019
FU European Research Council under EU's 7th Framework Program; ERC
   [320649]; Google Faculty Research Award; Intel Collaborative Research
   Institute for Computational Intelligence; Natural Science Foundation
   (NSF) of China [61402239]; NSF of Government of Jiangsu Province
   [BK20130868]; NSF for Jiangsu Advanced Institutions [13KJB510022];
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety (Nanjing University of Science and Technology) [30920140122007];
   European Research Council (ERC) [320649] Funding Source: European
   Research Council (ERC)
FX We would like to show our gratitude to the authors of Refs. [3,5,12-14]
   for their provided image dataset and software used in this paper. The
   first author Wen-Ze Shao is grateful to Professor Zhi-Hui Wei, Professor
   Yi-Zhong Ma and Dr. Min Wu, and Mr. Ya-Tao Zhang for their kind support
   in the past years. This research was supported by the European Research
   Council under EU's 7th Framework Program, ERC Grant agreement No.
   320649, the Google Faculty Research Award, the Intel Collaborative
   Research Institute for Computational Intelligence, and the Natural
   Science Foundation (NSF) of China (61402239), the NSF of Government of
   Jiangsu Province (BK20130868), the NSF for Jiangsu Advanced Institutions
   (13KJB510022), and the Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology, 30920140122007).
CR Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   Amizic B, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-20
   [Anonymous], ARXIV14051594
   [Anonymous], 2012, LECT NOTES COMPUT SC
   [Anonymous], ARXIV13114029
   [Anonymous], DIG SIG PRO IN PRESS
   Babacan SD, 2008, IEEE T IMAGE PROCESS, V17, P326, DOI 10.1109/TIP.2007.916051
   Benichoux A, 2013, INT CONF ACOUST SPEE, P6108, DOI 10.1109/ICASSP.2013.6638838
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shao WZ, 2014, SIGNAL IMAGE VIDEO P, V8, P975, DOI 10.1007/s11760-012-0370-9
   Simoncelli EeroP., 1999, Bayesian Denoising of Visual Images in the Wavelet Domain"
   Storath M, 2014, IEEE T SIGNAL PROCES, V62, P3654, DOI 10.1109/TSP.2014.2329263
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang R., 2014, ARXIV PREPRINT ARXIV
   Weiss Y., 2007, P INT C COMPUTER VIS, P1
   Wipf David, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P40, DOI 10.1007/978-3-642-40395-8_4
   Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 35
TC 38
Z9 43
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 42
EP 59
DI 10.1016/j.jvcir.2015.08.017
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xie, J
   Hsu, YF
   Feris, RS
   Sun, MT
AF Xie, Jun
   Hsu, Yu-Feng
   Feris, Rogerio Schmidt
   Sun, Ming-Ting
TI Fine registration of 3D point clouds fusing structural and photometric
   information using an RGB-D camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE ICP; Outlier rejection; Dynamic weighting; 3D modeling; Fine
   registration; Point cloud alignment; SIFT; RGB-D
AB We address the problem of accurate and efficient alignment of 3D point clouds captured by an RGB-D (Kinect-style) camera from different viewpoints. While the Iterative Closest Point (ICP) algorithm has been widely used for dense point cloud matching, it is limited in its ability to produce accurate results in challenging scenarios involving objects that lack structural features and have significant camera view changes. In this paper, we introduce a new cost function with dynamic weights for the ICP algorithm to tackle this problem. It balances the significance of structural and photometric features with dynamically adjusted weights to improve the error minimization process. Our algorithm also includes a novel outlier rejection method, which adopts adaptive thresholding at each ICP iteration, using both the structural information of the object and the spatial distances of sparse SIFT feature pairs. The effectiveness of our proposed approach is demonstrated by experimental results from various challenging scenarios. We obtained superior registration accuracy than related previous methods, at the same time maintaining low computational requirements. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Xie, Jun; Sun, Ming-Ting] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   [Hsu, Yu-Feng] Ind Technol Res Inst, Hsinchu, Taiwan.
   [Feris, Rogerio Schmidt] IBM TJ Watson Res Ctr, Hawthorne, NY USA.
C3 University of Washington; University of Washington Seattle; Industrial
   Technology Research Institute - Taiwan; International Business Machines
   (IBM)
RP Xie, J (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
EM junx@uw.edu
CR Andreasson H., 2007, EUR C MOB ROB ECMR
   Andreasson H., 2012, SEM PERC MAPP EXPL W
   [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], 2001, 3 INT C 3D DIG IM MO
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Chui H, 2004, IEEE T PATTERN ANAL, V26, P160, DOI 10.1109/TPAMI.2004.1262178
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Druon S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P249, DOI 10.1109/ICIA.2006.306004
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Inomata R., 2011, LECT NOTES COMPUTER, V6938, P325
   Jaiswal M., 2014, AS PAC SIGN INF PROC, P1
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P234, DOI 10.1109/IM.1997.603871
   Kashani AH, 2010, INT J ROBOT RES, V29, P1338, DOI 10.1177/0278364909359316
   Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974
   Klein George, 2007, P1
   Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lemuz-López R, 2006, LECT NOTES COMPUT SC, V4292, P502
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lulu He, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1985, DOI 10.1109/ICIP.2011.6115864
   Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446
   Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x
   Pandey G, 2011, IEEE INT CONF ROBOT, P2660
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Phillips JM, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tam G., 2013, IEEE T VIS COMPUT GR, V19
   Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775
   Xie J, 2013, IEEE INT SYMP CIRC S, P2904, DOI 10.1109/ISCAS.2013.6572486
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 37
TC 8
Z9 14
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 194
EP 204
DI 10.1016/j.jvcir.2015.08.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300016
DA 2024-07-18
ER

PT J
AU Ren, JC
   Vlachos, T
   Zhang, Y
   Zheng, JB
   Jiang, JM
AF Ren, Jinchang
   Vlachos, Theodore
   Zhang, Yi
   Zheng, Jiangbin
   Jiang, Jianmin
TI Gradient-based subspace phase correlation for fast and effective image
   alignment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image registration; Sub-pixel alignment; Phase correlation; Interference
   terms; Subspace projection; Fourier transform; Motion estimation; Fast
   algorithm
ID REGISTRATION METHODS; EXTENSION; ALGORITHM
AB Phase correlation is a well-established frequency domain method to estimate rigid 2-D translational motion between pairs of images. However, it suffers from interference terms such as noise and non-overlapped regions. In this paper, a novel variant of the phase correlation approach is proposed, in which 2-D translation is estimated by projection-based subspace phase correlation (SPC). Conventional wisdom has suggested that such an approach can only amount to a compromise solution between accuracy and efficiency. In this work, however, we prove that the original SPC and the further introduced gradient-based SPC can provide robust solution to zero-mean and non-zero-mean noise, and the latter is also used to model the interference term of non-overlapped regions. Comprehensive results from synthetic data and MRI images have fully validated our methodology. Due to its substantially lower computational complexity, the proposed method offers additional advantages in terms of efficiency and can lend itself to very fast implementations for a wide range of applications where speed is at a premium. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Ren, Jinchang] Univ Strathclyde, Ctr Excellence Signal & Image Proc, Glasgow, Lanark, Scotland.
   [Vlachos, Theodore] Ionian Univ, Dept Audiovisual Arts, Corfu, Greece.
   [Zhang, Yi] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
   [Zheng, Jiangbin] Northwestern Polytech Univ, Sch Comp Software & Microelect, Xian 710072, Peoples R China.
   [Jiang, Jianmin] Shenzhen Univ, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 University of Strathclyde; Ionian University; Tianjin University;
   Northwestern Polytechnical University; Shenzhen University
RP Ren, JC (corresponding author), Univ Strathclyde, Ctr Excellence Signal & Image Proc, Glasgow, Lanark, Scotland.
EM Jinchang.Ren@strath.ac.uk; t.vlachos@ionio.gr; yizhang@tju.edu.cn;
   zhengjb@nwpu.edu.cn; min.jiang@szu.edu.cn
OI Ren, Jinchang/0000-0001-6116-3194
CR Abdou IE, 1998, P SOC PHOTO-OPT INS, V3653, P371, DOI 10.1117/12.334685
   ALLINEY S, 1986, IEEE T PATTERN ANAL, V8, P222, DOI 10.1109/TPAMI.1986.4767775
   Althof RJ, 1997, IEEE T MED IMAGING, V16, P308, DOI 10.1109/42.585765
   Balci M, 2006, IEEE T IMAGE PROCESS, V15, P1965, DOI 10.1109/TIP.2006.873457
   Bentoutou Y, 2005, IEEE T GEOSCI REMOTE, V43, P2127, DOI 10.1109/TGRS.2005.853187
   Cain SC, 2001, IEEE T IMAGE PROCESS, V10, P1860, DOI 10.1109/83.974571
   Caner G, 2006, IEEE T IMAGE PROCESS, V15, P3053, DOI 10.1109/TIP.2006.877514
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Dawn S, 2010, LECT NOTES COMPUT SC, V6134, P103, DOI 10.1007/978-3-642-13681-8_13
   DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Hoge WS, 2003, IEEE T MED IMAGING, V22, P277, DOI 10.1109/TMI.2002.808359
   Humblot F., 2005, P PSIP PHYS SIGN IM
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   Keller Y, 2007, SIGNAL PROCESS, V87, P124, DOI 10.1016/j.sigpro.2006.04.013
   Keller Y, 2005, IEEE T PATTERN ANAL, V27, P969, DOI 10.1109/TPAMI.2005.128
   Markelj P, 2012, MED IMAGE ANAL, V16, P642, DOI 10.1016/j.media.2010.03.005
   Ojansivu V, 2007, IEEE SIGNAL PROC LET, V14, P449, DOI 10.1109/LSP.2006.891338
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Ren JC, 2007, IEEE IMAGE PROC, P481
   Ren JC, 2010, IEEE T IMAGE PROCESS, V19, P1379, DOI 10.1109/TIP.2009.2039056
   Ren JC, 2009, IEEE T CIRC SYST VID, V19, P1234, DOI 10.1109/TCSVT.2009.2022707
   Ren JC, 2009, IEEE T MULTIMEDIA, V11, P906, DOI 10.1109/TMM.2009.2021782
   Robinson D, 2004, IEEE T IMAGE PROCESS, V13, P1185, DOI 10.1109/TIP.2004.832923
   Robinson D., 2001, P 35 AS C SIGN SYST, P1425
   Santamaría J, 2011, COMPUT VIS IMAGE UND, V115, P1340, DOI 10.1016/j.cviu.2011.05.006
   Sauer K, 1996, IEEE T CIRC SYST VID, V6, P513, DOI 10.1109/76.538933
   Shekarforoush H, 1996, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.1996.517123
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Stone HS, 2001, IEEE T GEOSCI REMOTE, V39, P2235, DOI 10.1109/36.957286
   Tzimiropoulos G, 2010, IEEE T PATTERN ANAL, V32, P1899, DOI 10.1109/TPAMI.2010.107
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   Zeng L., 2012, SIGNAL IMAGE VIDEO P
   Zeng L., 2013, MACH VIS APPL
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zokai S, 2005, IEEE T IMAGE PROCESS, V14, P1422, DOI 10.1109/TIP.2005.854501
NR 37
TC 24
Z9 24
U1 0
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1558
EP 1565
DI 10.1016/j.jvcir.2014.07.001
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hsieh, LC
   Wu, GL
   Hsu, YM
   Hsu, W
AF Hsieh, Liang-Chi
   Wu, Guan-Long
   Hsu, Yu-Ming
   Hsu, Winston
TI Online image search result grouping with MapReduce-based image
   clustering and graph construction for large-scale photos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image search result grouping; Image clustering; Representative image;
   Graph construction; MapReduce; Large-scale photos; Parallel affinity
   propagation; Image graphs
AB Current image search system uses paged image list to show search results. However, the problems such as query ambiguity make users hard to find search targets in such image list. In this work, we propose an image search result grouping system that summarizes image search results in semantic and visual groups. We use MapReduce-based image graph construction and image clustering methods to deal with scalability problem on this system. By precomputing image graphs and image clusters at offline stage, this system can be efficient at responding user query. The experiments on two large scale Flickr image datasets are conducted for our system. Compared with using single machine, our graph construction method is 69 times faster. We conduct a comprehensive user study to compare our approach with state-of-the-art baseline methods. We find that our approach generates competent image groups with a 2-100 times speeded-up. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hsieh, Liang-Chi; Wu, Guan-Long; Hsu, Yu-Ming; Hsu, Winston] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
   [Hsu, Winston] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Hsu, W (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
EM viirya@gmail.com; garywgl@csie.ntu.edu.tw; leafwind.cs@gmail.com;
   winston@csie.ntu.edu.tw
RI Hsu, Yu-Ming/AGE-7997-2022
OI Hsu, Yu-Ming/0000-0001-5337-0791
FU National Science Council of Taiwan [NSC 101-2628-E-002-027-MY2];
   Excellent Research Projects of National Taiwan University [AE00-00-05];
   III Innovative and Prospective Technologies Project of the Institute for
   Information Industry; Ministry of Economy Affairs of Taiwan
FX This work was supported in part by grants from the National Science
   Council of Taiwan, under Contracts NSC 101-2628-E-002-027-MY2, Excellent
   Research Projects of National Taiwan University, AE00-00-05, and the III
   Innovative and Prospective Technologies Project of the Institute for
   Information Industry, subsidized by the Ministry of Economy Affairs of
   Taiwan.
CR [Anonymous], 2008, ACM MULTIMEDIA
   [Anonymous], P 17 ACM INT C MULT
   Bayardo R. J., 2007, P 16 INT C WORLD WID, P131, DOI [DOI 10.1145/1242572.1242591, 10.1145/1242572.1242591]
   Ben-Haim N., 2006, SLAM06, P106
   Blasberg R., 2008, HPCF20087 UMBC U MAR
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cal D., 2004, P 12 ANN ACM INT C M
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Elsayed T., 2008, P 46 ANN M ASS COMPU, P265, DOI DOI 10.3115/1557690.1557767
   Fischer I., 2004, IDSIA1204 HEBR U
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Jia Y., 2008, ACM International Conference on Multimedia (MM), P639
   Jing F., 2006, ACM MULT
   Jing Y., 2007, P 6 ACM INT C IM VID
   Jing Y., 2008, 17 INT WORLD WID WEB
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kuo Yin-Hsi., 2009, ACM Multimedia, P65
   Lejsek H, 2009, IEEE T PATTERN ANAL, V31, P869, DOI 10.1109/TPAMI.2008.130
   Li X., 2009, IEEE INT C AC SPEECH
   Liu Ting, 2007, 2007 IEEE WORKSHOP A, P28, DOI DOI 10.1109/WACV.2007.18
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Osinski S, 2005, IEEE INTELL SYST, V20, P48, DOI 10.1109/MIS.2005.38
   Papadopoulos S., 2011, ICMR
   Papadopoulos S., 2012, ICMR
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   Sigurbjornsson B., 2008, Proceeding of the 17th International Conference on World Wide Web
   Simon I, 2007, IEEE I CONF COMP VIS, P274
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   van Leuken ReinierH., 2009, WWW
   Wang W., 2008, INT C HYBR LEARN
   Yang L., 2010, INT J MULTIMEDIA TOO
   Yang Y.-H., 2008, ACM MULT
NR 33
TC 10
Z9 13
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 384
EP 395
DI 10.1016/j.jvcir.2013.12.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300015
DA 2024-07-18
ER

PT J
AU Kuanar, SK
   Panda, R
   Chowdhury, AS
AF Kuanar, Sanjay K.
   Panda, Rameswar
   Chowdhury, Ananda S.
TI Video key frame extraction through dynamic Delaunay clustering with a
   structural constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video summarization; Delaunay graphs; Edge pruning; Deviation ratio;
   Information-theoretic pre-sampling; Feature extraction; Key frame
   visualization; Clustering
ID FEATURE FUSION; SCHEME
AB Key frame based video summarization has emerged as an important area of research for the multimedia community. Video key frames enable an user to access any video in a friendly and meaningful way. In this paper, we propose an automated method of video key frame extraction using dynamic Delaunay graph clustering via an iterative edge pruning strategy. A structural constraint in form of a lower limit on the deviation ratio of the graph vertices further improves the video summary. We also employ an information-theoretic pre-sampling where significant valleys in the mutual information profile of the successive frames in a video are used to capture more informative frames. Various video key frame visualization techniques for efficient video browsing and navigation purposes are incorporated. A comprehensive evaluation on 100 videos from the Open Video and YouTube databases using both objective and subjective measures demonstrate the superiority of our key frame extraction method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Kuanar, Sanjay K.; Panda, Rameswar; Chowdhury, Ananda S.] Jadavpur Univ, Dept Elect & Telecommun Engn, Kolkata 700032, India.
C3 Jadavpur University
RP Chowdhury, AS (corresponding author), Jadavpur Univ, Dept Elect & Telecommun Engn, Kolkata 700032, India.
EM sanjay.kuanar@gmail.com; rameswar183@gmail.com;
   aschowdhury@etce.jdvu.ac.in
RI Panda, Rameswar/AAY-9834-2020; Kuanar, Dr. Sanjay/C-7247-2019
OI Panda, Rameswar/0000-0003-4359-2475; Chowdhury,
   Ananda/0000-0002-5799-3467; Kuanar, Dr. Sanjay/0000-0001-8229-2956
CR Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   [Anonymous], 2002, P SPRING C COMP GRAP
   Atkins C.B., 2008, P 16 ACM INT C MULTI, P821
   Bow S.-T., 2002, Pattern Recognition and Image Processiong, VSecond
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Chiu P., 2004, P INT C MULT EXP
   Chowdhury AS, 2012, INT C PATT RECOG, P3108
   Ciocca G., 2006, J REAL-TIME IMAGE PR, V1, P69, DOI DOI 10.1007/s11554-012-0278-1
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Herranz L, 2009, IEEE INT CON MULTI, P654, DOI 10.1109/ICME.2009.5202581
   Komlodi A., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P118, DOI 10.1145/276675.276688
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Liu T, 2003, SIGNAL PROCESS-IMAGE, V18, P221, DOI 10.1016/S0923-5965(02)00141-8
   Liu TY, 2004, PATTERN RECOGN LETT, V25, P1451, DOI 10.1016/j.patrec.2004.05.020
   Manjunath B.S., 2000, IEEE T CIRCUITS SYST, V6
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   O'-Rourke, 2008, COMPUTATIONAL GEOMET
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Ponceleon D., 1998, Proceedings ACM Multimedia 98, P99, DOI 10.1145/290747.290760
   POTHEN A, 1990, ACM T MATH SOFTWARE, V16, P303, DOI 10.1145/98267.98287
   Rother C., 2006, ACM SIGGRAGPH
   SAHOURIA E, 1999, IEEE T CIRCUITS SYST, V9
   Schaeffer SE, 2007, COMPUT SCI REV, V1, P27, DOI 10.1016/j.cosrev.2007.05.001
   Slaney M, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.50
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TONOMURA Y, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P131
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Wang T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1479
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang J, 2002, PATTERN RECOGN, V35, P295, DOI 10.1016/S0031-3203(01)00152-2
   Yeung M.M., 1997, IEEE T CIRCUIT SYSTE, V7
   Yu JCS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P329
NR 44
TC 65
Z9 77
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1212
EP 1227
DI 10.1016/j.jvcir.2013.08.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700044
DA 2024-07-18
ER

PT J
AU Lin, CY
   Kang, LW
   Kao, JH
   Lu, CS
   Wu, YT
AF Lin, Chih-Yang
   Kang, Li-Wei
   Kao, Jau-Hong
   Lu, Chun-Shien
   Wu, Yi-Ta
TI Multi-camera invariant appearance modeling for non-rigid object
   identification in a real-time environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Appearance model; Identification; Invariant features; Surveillance;
   Multi-camera; Real-time system; Gaussian mixture model; Hierarchical
   tree structures
AB Surveillance of wide areas requires a system of multiple cameras to keep observing people, the non-rigid objects. In such a multiple view system, the appearance of people obtained in one camera is usually different from the appearance obtained in other cameras. In order to correctly identify people, the unique appearance model of each specific object should be invariant to such changes. Unlike previous methods building an appearance model by using only single camera, our appearance modeling, in this paper, is based on the multi-camera environment to fit real cases. Our appearance model is represented by two hierarchical tree structures that are responsible for color and texture information, respectively, where each layer of a tree is maintained by a Gaussian mixture model (GMM). The identification process is performed with a delicate voting scheme without complicated computations to meet the requirements of real-time applications. Experimental results show that our unique appearance model is robust to translation, rotation, scaling, and shape variations. Furthermore, it is equipped with automatic model updating, and it achieves a high precision rate and high processing performance. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Lin, Chih-Yang] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Kang, Li-Wei; Lu, Chun-Shien] Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
   [Kao, Jau-Hong; Wu, Yi-Ta] Ind Technol Res Inst, Adv Technol Ctr, Hsinchu, Taiwan.
C3 Asia University Taiwan; Academia Sinica - Taiwan; Industrial Technology
   Research Institute - Taiwan
RP Kang, LW (corresponding author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
EM lwkang@iis.sinica.edu.tw
RI Lin, Chih-Yang/HOF-2583-2023
OI Lin, Chih-Yang/0000-0002-0401-8473
FU National Science Council, Taiwan [NSC 100-2221-E-468-021, NSC
   100-2218-E-001-007-MY3]; Ministry of Economic Affairs, Taiwan
   [B301AR2420]
FX This work was supported by National Science Council, Taiwan, under
   Grants NSC 100-2221-E-468-021, NSC 100-2218-E-001-007-MY3, and by
   Ministry of Economic Affairs, Taiwan, Project B301AR2420.
CR Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hu JS, 2006, IEEE T SYST MAN CY B, V36, P403, DOI 10.1109/TSMCB.2005.859084
   Huang CH, 2008, LECT NOTES COMPUT SC, V5353, P906, DOI 10.1007/978-3-540-89796-5_111
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Kao JH, 2008, LECT NOTES COMPUT SC, V5353, P553
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khalid S, 2010, PATTERN RECOGN, V43, P3636, DOI 10.1016/j.patcog.2010.05.006
   Lee R. C. T., 1976, IEEE Transactions on Software Engineering, VSE-2, P185, DOI 10.1109/TSE.1976.225946
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy CC, 2011, PATTERN RECOGN, V44, P117, DOI 10.1016/j.patcog.2010.07.023
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647
   Mitchell T. M., 1997, MACHINE LEARNING
   Morioka K, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2644, DOI 10.1109/IROS.2006.281946
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Senior A., 2002, PROC IEEE INT WORKSH, P48
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Thome N, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P528
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 22
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 717
EP 728
DI 10.1016/j.jvcir.2012.01.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900009
DA 2024-07-18
ER

PT J
AU Rahmat, R
   Malik, AS
   Kamel, N
   Nisar, H
AF Rahmat, Roushanak
   Malik, Aamir Saeed
   Kamel, Nidal
   Nisar, Humaira
TI 3D shape from focus using LULU operators and discrete pulse transform in
   the presence of noise
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape from focus; LULU operators; Discrete pulse transform
ID DEPTH MAP; OPTIMIZATION
AB 3D shape recovery is an interesting and challenging area of research. Recovering the depth information of an object from a sequence of 2D images with varying focus is known as shape from focus. Focus value of an image carries information about the object and shape from focus is a method which depends on different focused value images. It reconstructs the shape/surface/depth of an object based on the different focused values of the object. These different focused valued images should be captured from the same angle. Calculating the shape of the object from different images with different focused values can be done by applying sharpness detection methods to maximize and detect the focused values. In this paper, we propose new 3D shape recovery techniques based on LULU operators and discrete pulse transform. LULU operators are nonlinear rank selector operators that are efficient with low complexity. They hold consistent separation, total variation and shape preservation properties. Discrete pulse transform is a transform that decomposes image into pulses. Therefore selection of right pulses, give sharpest focus values. The proposed techniques provide better result than traditional techniques in a noisy environment. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Rahmat, Roushanak; Malik, Aamir Saeed; Kamel, Nidal] Univ Teknol, Dept Elect & Elect Engn, PETRONAS, Tronoh 31750, Perak, Malaysia.
   [Nisar, Humaira] Univ Tunku Abdul Rahman, Fac Engn & Green Technol, Dept Elect Engn, Kampar 31900, Perak, Malaysia.
C3 Universiti Teknologi Malaysia; Petronas; Universiti Teknologi Petronas;
   Universiti Tunku Abdul Rahman (UTAR)
RP Malik, AS (corresponding author), Univ Teknol, Dept Elect & Elect Engn, PETRONAS, Tronoh 31750, Perak, Malaysia.
EM aamir_saeed@petronas.com.my
RI Nisar, Humaira/A-5188-2009; Malik, Aamir S/C-6904-2009
OI Nisar, Humaira/0000-0003-2026-5666; Malik, Aamir S/0000-0003-1085-3157
CR Ahmad MB, 2005, IEEE T CIRC SYST VID, V15, P566, DOI 10.1109/TCSVT.2005.844450
   Anguelov B., 2008, P 19 INT C PATT REC, P1
   Anguelov R, 2010, IEEE T IMAGE PROCESS, V19, P3012, DOI 10.1109/TIP.2010.2050639
   Asada N, 1998, INT J COMPUT VISION, V26, P153, DOI 10.1023/A:1007996810301
   Asif M, 2001, IEEE T IMAGE PROCESS, V10, P1670, DOI 10.1109/83.967395
   Conradie WJ, 2006, J COMPUT APPL MATH, V186, P253, DOI 10.1016/j.cam.2005.03.073
   Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282
   de Wet T., 2006, P ICOTS7 2006 7 INT
   DILLON C, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P562, DOI 10.1109/ICPR.1992.201624
   ERTEZA A, 1976, APPL OPTICS, V15, P877, DOI 10.1364/AO.15.000877
   Fabris-Rotelli I., 2009, P 12 ANN S PATT REC
   GROSSMANN P, 1987, PATTERN RECOGN LETT, V5, P63, DOI 10.1016/0167-8655(87)90026-2
   Helmli FS, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P188, DOI 10.1109/ISPA.2001.938626
   Horn B. K. P., 1968, FOCUSSING
   JARVIS RA, 1976, MICROSCOPE, V24, P163
   Joungil Yun, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P910, DOI 10.1109/ICIP.1999.817287
   Malik A.S., 2011, DEPTH MAP 3D IMAGING
   Malik AS, 2008, PATTERN RECOGN, V41, P2200, DOI 10.1016/j.patcog.2007.12.014
   Malik AS, 2007, PATTERN RECOGN, V40, P154, DOI 10.1016/j.patcog.2006.05.032
   Malik AS, 2011, APPL SOFT COMPUT, V11, P1837, DOI 10.1016/j.asoc.2010.05.030
   MORALES A, 1995, IEEE T IMAGE PROCESS, V4, P965, DOI 10.1109/83.392337
   MULLER RA, 1974, J OPT SOC AM, V64, P1200, DOI 10.1364/JOSA.64.001200
   Nayar S. K., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P218, DOI 10.1109/ROBOT.1990.125976
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Pei SC, 1997, GRAPH MODEL IM PROC, V59, P109, DOI 10.1006/gmip.1996.0416
   Pentland A. P., 1985, P IJCAI 85 LOS ANGEL, V9, P988
   Pierre du Toit J., 2007, THESIS U STELLENBOSC
   Rohwer C. H., 2005, SIAM J MATH ANAL, V38, P1
   Subbarao M., 1992, 920904 STAT U NEW YO
   Tenebaum J. M., 1970, THESIS STANFORD U
   Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977
   Zhang Y, 2000, IMAGE VISION COMPUT, V18, P959, DOI 10.1016/S0262-8856(00)00038-X
NR 32
TC 7
Z9 9
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 303
EP 317
DI 10.1016/j.jvcir.2013.01.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200009
DA 2024-07-18
ER

PT J
AU Niu, Y
   Wu, XL
   Zhang, XJ
   Shi, GM
AF Niu, Yi
   Wu, Xiaolin
   Zhang, Xiangjun
   Shi, Guangming
TI Model-based adaptive resolution upconversion of degraded images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image interpolation; Image restoration; Image upconversion; Arbitrary
   scale factor; Image deblurring; Autoregressive process; Nonlinear
   estimation; Structured total least squares
ID INTERPOLATION; LOSSLESS
AB Resolution upconversion of a degraded image is an ill-posed inverse problem that is even harder than video superresolution due to lack of redundant observations from reference frames. To overcome this difficulty an adaptive 2D piecewise autoregressive (PAR) model is used to strengthen the constraints on the solution of the inverse problem. The PAR model can be fit to local image waveforms by adjusting its parameters. But estimating the model parameters needs the knowledge of the very original high-resolution pixels to be estimated by the model. We resolve this chicken-and-egg dilemma by adaptive nonlinear least-squares joint estimation of both model parameters and original pixels. This non-linear estimation problem is solved by the method of structured total least-squares, constrained by the degradation function (e.g., the point spread function of a camera plus noises) that forms the observed low-resolution image. As such, this work offers a unified general framework for joint upsampling, deconvolution, and denoising. Moreover, the upsampling can be carried out at an arbitrary scale rather than power of two. Experiments show that the proposed NEARU technique outperforms current methods in both PSNR and subjective visual quality, and its advantage becomes greater for larger scaling factors. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Niu, Yi; Shi, Guangming] Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
   [Niu, Yi; Wu, Xiaolin; Zhang, Xiangjun] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
C3 Xidian University; McMaster University
RP Niu, Y (corresponding author), Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
EM niuyi@mail.xidian.edu.cn; xwu@ece.mcmaster.ca; gmshi@ece.mcmaster.ca
FU NSFC [61033004, 61070138, 61072104]
FX This work was supported by NSFC Grants (Nos. 61033004, 61070138,
   61072104).
CR [Anonymous], 2010, IEEE T IMAGE PROCESS
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Golub G, 2003, INVERSE PROBL, V19, pR1, DOI 10.1088/0266-5611/19/2/201
   JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Katsaggelos A. K., 1988, Signal Processing IV: Theories and Applications. Proceedings of EUSIPCO-88. Fourth European Signal Processing Conference, P1585
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Matsuda I., 2002, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ85D-II, P448
   MEYER B, 1997, P 1997 PICT COD S BE
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Muresan DD, 2004, IEEE T IMAGE PROCESS, V13, P690, DOI 10.1109/TIP.2004.826097
   Nemirovsky S., 2009, SIGNAL PROCESSING IM
   Reeves SJ, 1992, IEEE T IMAGE PROCESS, V1, P301, DOI 10.1109/ICASSP.1992.226241
   Rosen JB, 1998, SIAM J MATRIX ANAL A, V20, P14, DOI 10.1137/S0895479896301662
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Wu XL, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P901, DOI 10.1109/ICIP.1998.727397
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 21
TC 3
Z9 4
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1144
EP 1157
DI 10.1016/j.jvcir.2012.07.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900016
DA 2024-07-18
ER

PT J
AU Yousefi, S
   Kehtarnavaz, N
   Cao, Y
   Razlighi, QR
AF Yousefi, S.
   Kehtarnavaz, N.
   Cao, Y.
   Razlighi, Q. R.
TI Bilateral Markov mesh random field and its application to image
   restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Markov random fields; Bilateral Markov mesh random field; Image
   modeling; Image restoration; Image processing; Texture analysis; Causal
   Markov random field; Stochastic image analysis
ID SEGMENTATION
AB This paper introduces bilateral Markov mesh random field to overcome the shortcomings of the conventional Markov random fields in image modeling. These shortcomings consist of (a) the computational intractability of such fields when expressing the image probability function in the form of the Gibbs distribution function, and (b) the formulation of the image probability function via the product of low-dimensional densities at the expense of obtaining non-symmetrical image models. The properties of bilateral Markov mesh random field are presented and used to derive an image model to address the above shortcomings. As an application, a framework for image restoration is then provided. Restoration results based on this new bilateral Markov mesh random field are compared to the conventional fields to demonstrate its effectiveness. Published by Elsevier Inc.
C1 [Yousefi, S.; Kehtarnavaz, N.] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
   [Cao, Y.] Univ Texas Dallas, Dept Math Sci, Richardson, TX 75083 USA.
   [Razlighi, Q. R.] Columbia Univ, Dept Mol Imaging & Neuropathol, New York, NY 10027 USA.
C3 University of Texas System; University of Texas Dallas; University of
   Texas System; University of Texas Dallas; Columbia University
RP Yousefi, S (corresponding author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
EM s.yousefi@utdallas.edu
RI Razlighi, Qolamreza/HLP-7646-2023
CR ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827
   [Anonymous], 2001, COMP SCI W
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Boyok Y., 2001, IEEE T PATTERN ANAL, V23, P1222
   Champagnat F, 1998, IEEE T INFORM THEORY, V44, P2901, DOI 10.1109/18.737521
   Cressie N., 2001, Methodology and Computing in Applied Probability, V3, P5, DOI 10.1023/A:1011461923517
   DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   Devijver P. A., 1998, PATTERN RECOGN, V301, P131
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GRAY AJ, 1994, IEEE T PATTERN ANAL, V16, P507, DOI 10.1109/34.291447
   Hemmersley J.M., 1971, MARKOV FIELD UNPUB
   Kinderniann R., 1980, CONT MATH, V1
   Pearl J., 2001, Causality: Models, Reasoning, and Inference, V2nd
   PICKARD DK, 1980, ADV APPL PROBAB, V12, P655, DOI 10.2307/1426425
   PICKARD DK, 1977, J APPL PROBAB, V14, P717, DOI 10.2307/3213345
   Razlighi QR, 2009, IEEE T IMAGE PROCESS, V18, P2629, DOI 10.1109/TIP.2009.2029988
   Razlighi R., 2009, P SPIE C VISUAL COMM, V7257
   Sinha A, 2010, IEEE T IMAGE PROCESS, V19, P561, DOI 10.1109/TIP.2009.2036685
   VERHAGEN AMW, 1977, J CHEM PHYS, V67, P5060, DOI 10.1063/1.434730
   Wang Y, 2010, IEEE T IMAGE PROCESS, V19, P2491, DOI 10.1109/TIP.2010.2048970
   Yousefi S, 2011, ELECTRON LETT, V47, P1224, DOI 10.1049/el.2011.1364
   Yousefi S, 2011, INT CONF ACOUST SPEE, P1285
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
NR 25
TC 3
Z9 3
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1051
EP 1059
DI 10.1016/j.jvcir.2012.06.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900009
DA 2024-07-18
ER

PT J
AU Fiorucci, F
   Baruffa, G
   Frescura, F
AF Fiorucci, Federico
   Baruffa, Giuseppe
   Frescura, Fabrizio
TI Objective and subjective quality assessment between JPEG XR with overlap
   and JPEG 2000
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE JPEG XR; JPEG 2000; Overlap operator; Subjective assessment; Stimulus
   comparison; Digital projection; VIF; Coding complexity
ID DYNAMIC-RANGE IMAGES; STATISTICAL EVALUATION; TRANSFORMS
AB JPEG XR (eXtended Range) is a recently standardized format for still images compression. It adopts a Lapped Biorthogonal Transform (LBT) that helps in reducing visual artifacts, in particular those due to blocking effects. In this paper, we compare JPEG XR with JPEG 2000, in terms of both objective and subjective visual quality. The adopted objective parameters are the computational complexity and the PSNR. In order to improve the analysis, and to evaluate if JPEG XR can be a feasible alternative to JPEG 2000, subjective tests in a projector-based environment have been set up, from which the benefits of the overlap operator of JPEG XR have been assessed, especially at high compression ratios. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Fiorucci, Federico; Baruffa, Giuseppe; Frescura, Fabrizio] DIEI Univ Perugia, I-06125 Perugia, Italy.
C3 University of Perugia
RP Fiorucci, F (corresponding author), DIEI Univ Perugia, Via G Duranti 93, I-06125 Perugia, Italy.
EM federico.fiorucci@diei.unipg.it; baruffa@diei.unip-g.it;
   frescura@diei.unipg.it
OI Baruffa, Giuseppe/0000-0003-3496-0395
CR [Anonymous], 1544412004 ISOIEC
   [Anonymous], 7ETHOD SUBJ ASS QUAL
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   De Simone F., 2007, SPIE OPTICS PHOTONIC, V6696
   De Simone F., 2009, P SPIE OPT PHOT APPL, V7443
   Digital Cinema Initiatives LLC (DCI), 2007, DIG CIN SYST SPEC V1
   Fenimore C, 2004, P SOC PHOTO-OPT INS, V5558, P503, DOI 10.1117/12.563519
   Husak W, 2004, SIGNAL PROCESS-IMAGE, V19, P921, DOI 10.1016/j.image.2004.06.006
   ISO/IEC, 291992 ISOIEC
   ISO/IEC JTC1/SC29/WG1 (JPEC) AIC AhG, 2009, WG1N5001 ISOIEC JTC1
   Maalouf A., 2009, P INT C IM PROC 2009
   Malvar HS, 1998, IEEE T SIGNAL PROCES, V46, P1043, DOI 10.1109/78.668555
   MALVAR HS, 1988, P ICASSP, P781
   Mantiuk R, 2005, PROC SPIE, V5666, P204, DOI 10.1117/12.586757
   Mantiuk R, 2004, IEEE SYS MAN CYBERN, P2763
   Okarma K, 2010, LECT NOTES ARTIF INT, V6113, P539, DOI 10.1007/978-3-642-13208-7_67
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Richter T, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P493
   Richter T, 2008, IEEE IMAGE PROC, P2888, DOI 10.1109/ICIP.2008.4712398
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shi BX, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P725, DOI 10.1109/ICME.2008.4607537
   Taubman D.S., 2002, JPEG 2000: Image Compression Fundamentals, Standards and Practice, DOI 10.1007/978-1-4615-0799-4
   Tu CJ, 2008, P SOC PHOTO-OPT INS, V7073, DOI 10.1117/12.797097
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 27
TC 7
Z9 7
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 835
EP 844
DI 10.1016/j.jvcir.2012.04.011
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900001
DA 2024-07-18
ER

PT J
AU Wang, CT
   Yu, HF
AF Wang, Cheng-Tzu
   Yu, Hsiang-Fu
TI A Markov-based reversible data hiding method based on histogram shifting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Information theory; Markov; Watermarking;
   Histogram shifting; Lossless; Embedding data; Man-made picture
ID DIFFERENCE EXPANSION; WATERMARKING; IMAGE; TRANSFORM; SCHEME; VIDEO
AB Applying information theory, this work considers an image as a stream of symbols emitted by a Markov information source. With the Markov model, a reversible data-hiding scheme based on the histogram modification technique is proposed to provide an efficient tradeoff between hiding capacity and quality of a marked image by changing the order of the Markov model. The larger the order is, the higher the capacity is but the lower the quality is, and vice versa. The experimental results show that the proposed scheme yields not only much larger hiding capacity but also smaller image distortion than other reversible data-hiding schemes reported in the literature. This work also proposes two feasible approaches to reduce the overhead yielded during the data embedding. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Wang, Cheng-Tzu; Yu, Hsiang-Fu] Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
C3 National Taipei University of Education
RP Yu, HF (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM yu@dslab.csie.ncu
FU National Science Council, Taiwan [NSC 100-2221-E-152-002,
   100-2221-E-152-005]
FX The work was financially supported by National Science Council, Taiwan
   under a research grant number NSC 100-2221-E-152-002 and
   100-2221-E-152-005.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 1963, Information Theory and Coding
   Center for Image Processing Research Rensselaer Polytechnic Institute, IM DAT
   Chang C.-C., 2007, IEEE T INFORM FORENS, V2
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Fridrich J, 2001, P 4 INF HID WORKSH P, V2137, P27
   Grimaldi R., 1998, Discrete and Combinatorial Mathematics: An Applied Introduction
   Horowitz E., 2007, Fundamentals of Data Structures in C++
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Zeng, 1998, P INT C INF SYST AN, V3, P223
NR 24
TC 9
Z9 9
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 798
EP 811
DI 10.1016/j.jvcir.2012.04.009
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400010
DA 2024-07-18
ER

PT J
AU Dhara, BC
   Chanda, B
AF Dhara, Bibhas Chandra
   Chanda, Bhabatosh
TI A fast progressive image transmission scheme using block truncation
   coding by pattern fitting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compression; Image transmission; Grayscale progressive image
   transmission; Color image progressive transmission; Block truncation
   coding; Pattern fitting; BTC-PF coding; Full-search progressive
   transmission tree; Reversible color transformation
ID RECONSTRUCTION METHOD; LOSSLESS
AB In this paper, we have proposed a novel progressive image transmission scheme. In the present method, the concept of the BTC-PF is used for faster decoding. Here, images are decomposed into a number of blocks based on smoothness criterion. The smooth blocks are encoded by block means and the others are by BTC-PF method. To encode a block by BTC-PF method, the codebook is organized like a full search progressive transmission tree which helps greatly in efficient progressive transmission. The present method provides good image quality at low bit-rate and faster decoding compared to other spatial domain progressive transmission methods. We extend this method for color images also. In color image coding, each color plane is encoded separately and then the encoded information of the planes are transmitted in interleaving manner to obtain color images right from the early stages. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Dhara, Bibhas Chandra] Jadavpur Univ, Dept Informat Technol, Kolkata, India.
   [Chanda, Bhabatosh] Indian Stat Inst, Kolkata, India.
C3 Jadavpur University; Indian Statistical Institute; Indian Statistical
   Institute Kolkata
RP Dhara, BC (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata, India.
EM bibhas@it.jusl.ac.in; chanda@isical.ac.in
RI Dhara, Bibhas Chandra/ABF-9007-2020
CR Aiazzi B, 1996, IEEE T COMMUN, V44, P18, DOI 10.1109/26.476090
   Chang C.C., P 5 AS PAC C COMM 4, P892
   Chang CC, 2003, VISUAL COMPUT, V19, P342, DOI 10.1007/s00371-002-0186-7
   Chang CC, 2001, LECT NOTES COMPUT SC, V2105, P383
   Chang CC, 1998, IEEE T CONSUM ELECTR, V44, P1225, DOI 10.1109/30.735821
   Chen C.C., P INT C COMM TECHN, P1774
   Chen T.S., P 3 IEEE PAC RIM C M, P720
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Christopoulos C., 2002, SIGNAL PROCESSING IM, V17
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   Dhara BC, 2007, PATTERN RECOGN, V40, P2408, DOI 10.1016/j.patcog.2006.12.022
   GOLDBERG M, 1991, IEEE T COMMUN, V39, P540, DOI 10.1109/26.81742
   Guo JM, 2010, DIGIT SIGNAL PROCESS, V20, P97, DOI 10.1016/j.dsp.2009.04.007
   Hu YC, 2005, REAL-TIME IMAGING, V11, P59, DOI 10.1016/j.rti.2005.04.005
   Hwang WJ, 1997, IEEE T CONSUM ELECTR, V43, P17, DOI 10.1109/30.580380
   Komatsu K, 1996, P SOC PHOTO-OPT INS, V2727, P1094, DOI 10.1117/12.233182
   Nakachi T., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P453, DOI 10.1109/ICIP.1999.821650
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Qiu GP, 1999, IEEE T IMAGE PROCESS, V8, P109, DOI 10.1109/83.736699
   RISKIN EA, 1994, IEEE T IMAGE PROCESS, V3, P307, DOI 10.1109/83.287025
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Salomon David., 2000, DATA COMPRESSION COM, V2nd
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Skodras AN, 2001, PATTERN RECOGN LETT, V22, P1337, DOI 10.1016/S0167-8655(01)00079-4
   Tabuman D., 2001, JPEG2000 IMAGE COMPR
   Tsai P, 2004, SIGNAL PROCESS-IMAGE, V19, P285, DOI 10.1016/j.image.2003.10.005
   Tung C.L., P 5 INT S MULT SOFT, P180
   TZOU KH, 1987, OPT ENG, V26, P581, DOI 10.1117/12.7974121
   WANG L, 1988, IEE PROC-F, V135, P421, DOI 10.1049/ip-f-1.1988.0049
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 31
TC 16
Z9 17
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 313
EP 322
DI 10.1016/j.jvcir.2011.11.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900009
DA 2024-07-18
ER

PT J
AU Chen, ZX
   Goto, S
AF Chen, Zhenxing
   Goto, Satoshi
TI Efficient motion vector prediction algorithm using pattern matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion estimation; Motion vector coding; Motion vector spatial
   correlation; Motion vector temporal correlation; Motion vector
   prediction (MVP); Median prediction; Mode indicator; Motion vector
   pattern matching (MV-PM)
AB The state-of-the-art median prediction scheme is widely used for predicting motion vectors (MVs) in recent video standards. By exploiting the spatial correlations among MVs, median prediction scheme predicts MV for current block from three neighboring blocks. When MV is obtained from motion estimation, MV difference (MVD) is calculated and then transmitted. This process for predicting MV and calculating MVD is known as MV coding process. For MV coding, the performance depends on how efficient both the spatial and the temporal correlations among MVs are being exploited. Median prediction scheme applies a sophisticated way including some special rules to exploit the spatial correlations, however the temporal correlations among successive MVs are not exploited. In this paper, a new algorithm named MV pattern matching (MV-PM) exploiting both the spatial and temporal correlations is proposed. Various kinds of experimental results show that the proposed MV-PM algorithm outperforms the median prediction and the other related prediction schemes. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chen, Zhenxing; Goto, Satoshi] Waseda Univ, Grad Sch Informat Prod & Syst, Tokyo, Japan.
C3 Waseda University
RP Chen, ZX (corresponding author), Waseda Univ, Grad Sch Informat Prod & Syst, Tokyo, Japan.
EM chenzhenxing@akane.waseda.jp
FU Waseda University of Ministry of Education, Culture, Sports, Science and
   Technology, Japan
FX This work is supported by "Ambient SoC Global COE Program of Waseda
   University" of Ministry of Education, Culture, Sports, Science and
   Technology, Japan.
CR [Anonymous], 2003, ADV VID COD GEN AUD
   Bjotegaard G., 2001, VCEGM33
   International Telecommunication Union Telecommunication Standardization Sector (ITU-T) and International Organization for Standardization/International Electrotechnical Commission (ISO/IEC) JTC 1, 2003, ADV VID COD GEN AUD
   Ismaeil I., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P70, DOI 10.1109/ICIP.1999.821568
   Kim SD, 1999, IEEE T IMAGE PROCESS, V8, P1117, DOI 10.1109/83.777091
   Laroche G, 2008, IEEE T CIRC SYST VID, V18, P1681, DOI 10.1109/TCSVT.2008.2004921
   Liu JQ, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1
   Zhou DJ, 2009, IEICE T FUND ELECTR, VE92A, P1978, DOI 10.1587/transfun.E92.A.1978
NR 8
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 727
EP 733
DI 10.1016/j.jvcir.2011.05.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200006
DA 2024-07-18
ER

PT J
AU Lee, JS
   De Simone, F
   Ebrahimi, T
AF Lee, Jong-Seok
   De Simone, Francesca
   Ebrahimi, Touradj
TI Efficient video coding based on audio-visual focus of attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Audio-visual focus of attention; Quality of experience;
   Audio-visual source localization; H.264/AVC; Flexible macroblock
   ordering (FMO); Canonical correlation analysis; Subjective quality
   assessment
ID MULTIMODAL SPEAKER DETECTION; SPATIAL ATTENTION; TRACKING; LINKS;
   INTEGRATION; FOVEATION
AB This paper proposes an efficient video coding method using audio-visual focus of attention, which is based on the observation that sound-emitting regions in an audio-visual sequence draw viewers' attention. First, an audio-visual source localization algorithm is presented, where the sound source is identified by using the correlation between the sound signal and the visual motion information. The localization result is then used to encode different regions in the scene with different quality in such a way that regions close to the source are encoded with higher quality than those far from the source. This is implemented in the framework of H.264/AVC by assigning different quantization parameters for different regions. Through experiments with both standard and high definition sequences, it is demonstrated that the proposed method can yield considerable coding gains over the constant quantization mode of H.264/AVC without noticeable degradation of perceived quality. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lee, Jong-Seok; De Simone, Francesca; Ebrahimi, Touradj] Ecole Polytech Fed Lausanne, Inst Elect Engn, Multimedia Signal Proc Grp MMSPG, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Lee, JS (corresponding author), Ecole Polytech Fed Lausanne, Inst Elect Engn, Multimedia Signal Proc Grp MMSPG, CH-1015 Lausanne, Switzerland.
EM jong-seok.lee@epfl.ch; francesca.desimone@epfl.ch;
   touradj.ebrahimi@epfl.ch
RI Lee, Jong-Seok/AAF-5197-2020
OI Lee, Jong-Seok/0000-0001-5255-4425; De Simone,
   Francesca/0000-0001-5272-9221; Ebrahimi, Touradj/0000-0002-9900-3687
FU European Community [FP7/2007-2011, 21644]; Swiss National Foundation for
   Scientific Research
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7/2007-2011) under
   Grant Agreement No. 21644 (PetaMedia) and the Swiss National Foundation
   for Scientific Research in the framework of the NCCR Interactive
   Multimodal Information Management (IM2).
CR [Anonymous], 2002, METH SUBJ ASS QUAL T
   Besson P, 2008, IEEE T MULTIMEDIA, V10, P63, DOI 10.1109/TMM.2007.911302
   Boccignone G, 2008, IEEE T CIRC SYST VID, V18, P1727, DOI 10.1109/TCSVT.2008.2005798
   Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P1200, DOI 10.1109/TCSVT.2005.854240
   Chen Q, 2008, IEEE INT SYMP CIRC S, P268, DOI 10.1109/ISCAS.2008.4541406
   Cutler R, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1589, DOI 10.1109/ICME.2000.871073
   Driver J, 1998, TRENDS COGN SCI, V2, P254, DOI 10.1016/S1364-6613(98)01188-7
   Gatica-Perez D, 2007, IEEE T AUDIO SPEECH, V15, P601, DOI 10.1109/TASL.2006.881678
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Joint Video Team (JVI) of ISO/IEC MPEG & ITU-T VCEG, 2008, H 264 AVC JM REF SOF
   Kidron E, 2007, IEEE T SIGNAL PROCES, V55, P1390, DOI 10.1109/TSP.2006.888095
   Lee J.-S., 2009, P INT C MULT SIGN PR, P1
   Lee JS, 2009, IEEE INT CON MULTI, P57, DOI 10.1109/ICME.2009.5202435
   Lee JS, 2009, INT WORK QUAL MULTIM, P13, DOI 10.1109/QOMEX.2009.5246983
   Macaluso E, 2005, TRENDS NEUROSCI, V28, P264, DOI 10.1016/j.tins.2005.03.008
   Mazza V, 2007, NEUROPSYCHOLOGIA, V45, P514, DOI 10.1016/j.neuropsychologia.2006.02.010
   McDonald JJ, 2003, J COGNITIVE NEUROSCI, V15, P10, DOI 10.1162/089892903321107783
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Pavlovic V, 2000, PROC CVPR IEEE, P34, DOI 10.1109/CVPR.2000.854730
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Sharma R, 1998, P IEEE, V86, P853, DOI 10.1109/5.664275
   Spence C, 1996, J EXP PSYCHOL HUMAN, V22, P1005, DOI 10.1037/0096-1523.22.4.1005
   Spence C, 1997, PERCEPT PSYCHOPHYS, V59, P1, DOI 10.3758/BF03206843
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tellinghuisen DJ, 2003, PERCEPT PSYCHOPHYS, V65, P817, DOI 10.3758/BF03194817
   Vroomen J, 2000, J EXP PSYCHOL HUMAN, V26, P1583, DOI 10.1037/0096-1523.26.5.1583
   Vroomen J., 2004, HDB MULTISENSORY PRO, P141, DOI [DOI 10.7551/MITPRESS/3422.003.0012, 10.7551/mitpress/3422.003.0012]
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Zhou HY, 2008, IEEE J-STSP, V2, P503, DOI 10.1109/JSTSP.2008.2001429
NR 31
TC 27
Z9 29
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 704
EP 711
DI 10.1016/j.jvcir.2010.11.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200003
OA Green Published
DA 2024-07-18
ER

PT J
AU Chen, DQ
   Cheng, LZ
AF Chen, Dai-Qiang
   Cheng, Li-Zhi
TI Deconvolving Poissonian images by a novel hybrid variational model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total variation; Frame coefficients; Split Bregman method;
   Douglas-Rachford splitting; Poisson noise; Maximum a posteriori
   estimator; Hybrid model; Image deconvolution
ID TOTAL VARIATION MINIMIZATION; ITERATIVE ALGORITHMS; SIGNAL RECOVERY;
   TIGHT FRAMES; RESTORATION; DECONVOLUTION; REPRESENTATIONS;
   RECONSTRUCTION; REGULARIZATION; OPTIMIZATION
AB In this paper, we propose a novel hybrid variational model for deconvolving Poissonian images by describing the original image as two parts - a cartoon part characterized by total variation, and a detailed part which has sparse representation over the wavelet basis. Fast and efficient iterative algorithms based on the split Bregman method are then employed. Under some conditions we prove the convergence properties of the iterative algorithms. Experiments demonstrate that the proposed hybrid model efficiently removes the noise and avoids the staircase effect simultaneously, which leads to a visually pleasant deconvolution result. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chen, Dai-Qiang; Cheng, Li-Zhi] Natl Univ Def Technol, Dept Math & Syst, Sch Sci, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Chen, DQ (corresponding author), Natl Univ Def Technol, Dept Math & Syst, Sch Sci, Changsha 410073, Hunan, Peoples R China.
EM chener050@sina.com; clzcheng@vip.sina.com
FU National Science Foundation of China [10601068, 61072118]; Foundation
   for the Author of National Excellent Doctoral Dissertation of Peoples
   Republic of China [2005043]
FX We are appreciative for the anonymous reviewers constructive comments,
   with which great improvements have been made in this manuscript. The
   research was supported by the National Science Foundation of China (Nos.
   10601068 and 61072118) and the Foundation for the Author of National
   Excellent Doctoral Dissertation of Peoples Republic of China (No.
   2005043).
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   [Anonymous], 2006, Astronomical Image and Data Analysis, Astronomy and Astrophysics Library
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bioucas-Dias JM, 2006, IEEE T IMAGE PROCESS, V15, P937, DOI 10.1109/TIP.2005.863972
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Boyd S., 2004, CONVEX OPTIMIZATION
   Brune C, 2011, INT J COMPUT VISION, V92, P211, DOI 10.1007/s11263-010-0339-5
   Brune C, 2009, LECT NOTES COMPUT SC, V5567, P235, DOI 10.1007/978-3-642-02256-2_20
   Cai JF, 2008, SIAM J SCI COMPUT, V30, P1205, DOI 10.1137/040615298
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Cai JF, 2009, SIAM J IMAGING SCI, V2, P226, DOI 10.1137/080733371
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chaux C, 2009, SIAM J IMAGING SCI, V2, P730, DOI 10.1137/080727749
   Chen DQ, 2010, OPT ENG, V49, DOI 10.1117/1.3463019
   Chen DQ, 2010, IET IMAGE PROCESS, V4, P353, DOI 10.1049/iet-ipr.2009.0186
   CHEN DQ, 2011, J COMPUT APPL MATH, V235
   Coifman RR, 2000, APPL COMPUT HARMON A, V9, P1, DOI 10.1006/acha.2000.0299
   Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   Dupé FX, 2009, IEEE T IMAGE PROCESS, V18, P310, DOI 10.1109/TIP.2008.2008223
   Durand S, 2003, SIAM J SCI COMPUT, V24, P1754, DOI 10.1137/S1064827501397792
   Durand S, 2007, MULTISCALE MODEL SIM, V6, P547, DOI 10.1137/06065828X
   Durand S, 2010, J MATH IMAGING VIS, V36, P201, DOI 10.1007/s10851-009-0180-z
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Esser E., 0931 UCLA CAM
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Figueiredo MAT, 2001, IEEE T IMAGE PROCESS, V10, P1322, DOI 10.1109/83.941856
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Lintner S, 2004, INVERSE PROBL, V20, P815, DOI 10.1088/0266-5611/20/3/010
   Malgouyres F, 2002, IEEE T IMAGE PROCESS, V11, P1450, DOI 10.1109/TIP.2002.806241
   OPIAL Z, 1967, B AM MATH SOC, V73, P591, DOI 10.1090/S0002-9904-1967-11761-0
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sarder P, 2006, IEEE SIGNAL PROC MAG, V23, P32, DOI 10.1109/MSP.2006.1628876
   Sawatzky A., 2008, Nuclear Science Symposium Conference Record, P5133, DOI DOI 10.1109/NSSMIC.2008.4774392
   Selesnick IW, 2004, APPL COMPUT HARMON A, V17, P211, DOI 10.1016/j.acha.2004.05.003
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wen YW, 2008, SIAM J SCI COMPUT, V30, P2655, DOI 10.1137/070683374
   Yin WT, 2007, J VIS COMMUN IMAGE R, V18, P240, DOI 10.1016/j.jvcir.2007.01.004
   Zeng TY, 2010, COMMUN COMPUT PHYS, V8, P976, DOI 10.4208/cicp.210709.180310a
   Zeng TY, 2010, IEEE T IMAGE PROCESS, V19, P821, DOI 10.1109/TIP.2009.2034701
NR 47
TC 16
Z9 17
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 643
EP 652
DI 10.1016/j.jvcir.2011.07.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800007
DA 2024-07-18
ER

PT J
AU Grewenig, S
   Zimmer, S
   Weickert, J
AF Grewenig, Sven
   Zimmer, Sebastian
   Weickert, Joachim
TI Rotationally invariant similarity measures for nonlocal image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Block matching; Similarity measures; Moment invariants; Rotational
   invariance; Nonlocal means; Denoising; Rotation estimation; Structure
   tensor
ID PATTERN-RECOGNITION; REGULARIZATION; ALGORITHM
AB Many natural or texture images contain structures that appear several times in the image. One of the denoising filters that successfully take advantage of such repetitive regions is NL means. Unfortunately, the block matching of NL means cannot handle rotation or mirroring. in this paper, we analyse two natural approaches for a rotationally invariant similarity measure that will be used as an alternative to, respectively a modification of the well-known block matching algorithm in nonlocal means denoising. The first approach is based on moment invariants whereas the second one estimates the rotation angle, rotates the block via interpolation and then uses a standard block matching. In contrast to the standard method, the presented algorithms can find similar regions or patches in an image even if they appear in several rotated or mirrored instances. Hence, one can find more suitable regions for the weighted average and yield improved results. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Grewenig, Sven; Weickert, Joachim] Univ Saarland, Math Image Anal Group, D-66123 Saarbrucken, Germany.
   [Zimmer, Sebastian] Katholieke Univ Leuven, ESAT PSI VISICS, B-3001 Louvain, Belgium.
C3 Saarland University; KU Leuven
RP Grewenig, S (corresponding author), Univ Saarland, Math Image Anal Group, Bldg E1-1, D-66123 Saarbrucken, Germany.
EM grewenig@mia.uni-saarland.de
FU German Research Foundation (DFG) [We 2602/7-1]
FX The first author gratefully acknowledges funding by the German Research
   Foundation (DFG), project We 2602/7-1.
CR Alexander SK, 2008, LECT NOTES COMPUT SC, V5112, P192, DOI 10.1007/978-3-540-69812-8_19
   ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], 1995, P MUSTERERKENNUNG 19
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P13
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   BUADES A, P 2005 IEEE COMP SOC, V2, P60
   BURT PJ, P C COMP VIS PATT RE, P246
   Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Coupé P, 2006, LECT NOTES COMPUT SC, V4191, P33
   CRIMINISI A, P IEEE C COMP VIS PA, V2, P721
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   EFROS AA, P INT C COMP VIS ICC, V2, P1033
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   FORSTNER W, P ISPRS INT WORKSH F, P281
   GILBOA G, 2006, CAM0657 U CAL LOS AN
   Gilboa G, 2007, MULTISCALE MODEL SIM, V6, P595, DOI 10.1137/060669358
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   GREWENIG S, 2010, 265 SAARL U DEP MATH
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ji ZX, 2009, INFORM PROCESS LETT, V109, P1238, DOI 10.1016/j.ipl.2009.09.007
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Kervrann C, 2008, INT J COMPUT VISION, V79, P45, DOI 10.1007/s11263-007-0096-2
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   KLEINSCHMIDT O, P INT WORKSH LOC NON, P103
   Liu YL, 2008, J COMPUT SCI TECH-CH, V23, P270, DOI 10.1007/s11390-008-9129-8
   LOU Y, 2009, CAM0826 U CAL LOS AN
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Mrázek P, 2006, COMP IMAG VIS, P335
   Pizarro L, 2010, INT J COMPUT VISION, V90, P62, DOI 10.1007/s11263-010-0337-7
   Schultz T, 2009, MATH VIS, P263, DOI 10.1007/978-3-540-88378-4_13
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tikhonov A.N., 1963, SOV MATH DOKL, V5, P1035, DOI DOI 10.1111/J.1365-246X.2012.05699.X
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   TORROBA PL, 1994, OPT ENG, V33, P528, DOI 10.1117/12.152006
   TSCHUMPERLE D, P INT WORKSH LOC NON, P32
   VOSS K, 1995, ADAPTIVE MODELLE INV
   Yaroslavsky L.P., 1985, Digital Picture Processing: An Introduction
   ZIMMER S, P INT WORKSH LOC NON, P135
NR 44
TC 60
Z9 73
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 117
EP 130
DI 10.1016/j.jvcir.2010.11.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gouiffès, M
   Zavidovique, B
AF Gouiffes, Michele
   Zavidovique, Bertrand
TI Body color sets: A compact and reliable representation of images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color; Topographic map; Dichromatic model; Level lines; Level sets;
   Color lines; Robust features; Body colors
ID CURVES
AB This paper proposes a novel definition of color sets, called body color sets and lines. The proposed technique refers to the dichromatic reflectance model, which states that the colors of a uniform lambertian object are roughly located around straight vectors going from the black to the body color, in relation to physical properties of the object. Ends of body vectors are robustly detected, from the clearest to the darkest through a multi-level histogram analysis, a key step of the algorithm. Finally, instead of defining the topographic map along the one and only luminance direction, body lines are designed along each body vector. The resulting topographic map is more compact and requires less executing times and resources than in previous works [gouiffes08]. Experimental results show that this approach provides a better trade-off between compactness and quality of a topographic map. Furthermore, it provides increased stability under temperature changes of the illuminant. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Gouiffes, Michele; Zavidovique, Bertrand] Univ Paris 11, Inst Elect Fondamentale, CNRS, UMR 8622, F-91405 Orsay, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS)
RP Gouiffès, M (corresponding author), Univ Paris 11, Inst Elect Fondamentale, CNRS, UMR 8622, F-91405 Orsay, France.
EM michele.gouiffes@ief.u-psud.fr
CR Angulo J, 2010, J VIS COMMUN IMAGE R, V21, P33, DOI 10.1016/j.jvcir.2009.10.002
   Ballester C, 2007, J MATH IMAGING VIS, V27, P5, DOI 10.1007/s10851-006-7252-0
   Bouchafa S, 2006, IMAGE VISION COMPUT, V24, P70, DOI 10.1016/j.imavis.2005.09.013
   Cao F, 2005, J MATH IMAGING VIS, V22, P159, DOI 10.1007/s10851-005-4888-0
   Caselles V, 2002, J MATH IMAGING VIS, V16, P89, DOI 10.1023/A:1013943314097
   Caselles V, 1999, INT J COMPUT VISION, V33, P5, DOI 10.1023/A:1008144113494
   COLL B, 2000, 15 ICPR INT C PATT R, P3613
   Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196
   Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885
   FROMENT J, 2000, IEEE INT C IMAGE PRO, V2, P112
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   GOUIFFES M, 2009, 6 ICINO INT C INF CO, P433
   GOUIFFES M, 2007, IEEE INT C IM PROC S, V6, P145
   Gouiffès M, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/824195
   HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311
   Kervrann C, 2002, J MATH IMAGING VIS, V17, P153, DOI 10.1023/A:1020685520659
   Klinker G.J., 1988, SPIE APPL ARTIFICIAL, V937, P229
   KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441
   Lacassagne L, 2011, J REAL-TIME IMAGE PR, V6, P117, DOI 10.1007/s11554-009-0134-0
   Lu XH, 2006, IEEE INT CONF ROBOT, P3411, DOI 10.1109/ROBOT.2006.1642223
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113
   OMER I, 2004, IEEE INT C COMP VIS
   Serra J., 1983, IMAGE ANAL MATH MORP
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   SUVONVORN N, 2006, INT C COMP VIS THEOR, P257
   Tominaga S, 1996, COLOR RES APPL, V21, P104, DOI 10.1002/(SICI)1520-6378(199604)21:2<104::AID-COL4>3.0.CO;2-Y
   TREMEAU A, 2004, IMAGE NUMERIQUE COUL
   Zhang X., 1997, Journal of the Society for Information Display, V5, P61, DOI 10.1889/1.1985127
NR 30
TC 11
Z9 13
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 48
EP 60
DI 10.1016/j.jvcir.2010.10.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300005
DA 2024-07-18
ER

PT J
AU Poppe, C
   De Bruyne, S
   Paridaens, T
   Lambert, P
   Van de Walle, R
AF Poppe, Chris
   De Bruyne, Sarah
   Paridaens, Tom
   Lambert, Peter
   Van de Walle, Rik
TI Moving object detection in the H.264/AVC compressed domain for video
   surveillance applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving object detection; Compressed domain analysis; Video surveillance;
   Object Segmentation; MPEG video; Block-based video coding; H. 264/AVC;
   Signal processing
AB In this paper a novel method is presented to detect moving objects in H.264/AVC [T. Wiegand, G. Sullivan, G. Bjontegaard, G. Luthra, Overview of the H.264/AVC video coding standard, IEEE Transactions on Circuits and Systems for Video Technology, 13 (7) (2003) 560-576] compressed video surveillance sequences. Related work, within the H.264/AVC compressed domain, analyses the motion vector field to find moving objects. However, motion vectors are created from a coding perspective and additional complexity is needed to clean the noisy field. Hence, an alternative approach is presented here, based on the size (in bits) of the blocks and transform coefficients used within the video stream. The system is restricted to the syntax level and achieves high execution speeds, up to 20 times faster than the related work. To show the good detection results, a detailed comparison with related work is presented for different challenging video sequences. Finally, the influence of different encoder settings is investigated to show the robustness of our system. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Poppe, Chris; De Bruyne, Sarah; Paridaens, Tom; Lambert, Peter; Van de Walle, Rik] Univ Ghent, IBBT, Multimedia Lab, Dept Elect & Informat Syst, Gaston Crommenlaan 8, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Poppe, C (corresponding author), Univ Ghent, IBBT, Multimedia Lab, Dept Elect & Informat Syst, Gaston Crommenlaan 8, B-9050 Ledeberg Ghent, Belgium.
EM Chris.Poppe@ugent.be
RI Lambert, Peter/D-7776-2016
OI Lambert, Peter/0000-0001-5313-4158
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], P IEEE INT WORKSH PE
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Davis J., 2006, P 23 INT C MACH LEAR
   *INT ORG STAND, 2002, JTCISC29WG11 ISOIEC
   Jamrozik ML, 2002, IEEE IMAGE PROC, P113
   Kwon SK, 2006, J VIS COMMUN IMAGE R, V17, P186, DOI 10.1016/j.jvcir.2005.05.010
   Liu Z, 2007, OPT ENG, V46, DOI 10.1117/1.2431374
   Long L, 2008, PROCEEDINGS OF THE 27TH CHINESE CONTROL CONFERENCE, VOL 6, P605, DOI 10.1109/CHICC.2008.4605782
   Mittal A, 2000, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2000.854767
   Poppe C, 2008, OPT ENG, V47, DOI 10.1117/1.3002325
   THILAK V, 2004, P SOC PHOTO-OPT INS, P281
   Tiburzi F., 2007, P INT WORKSH IM AN M, P42
   Wang HL, 2003, J VIS COMMUN IMAGE R, V14, P150, DOI 10.1016/S1047-3203(03)00019-1
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   YANG G, 2006, P PICT COD S
   Yang H, 2007, IEEE IMAGE PROC, P1513
   Zen H., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P25, DOI 10.1109/ICIP.1999.819460
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
   AUTONOMOUS AGENTS ON
NR 21
TC 53
Z9 65
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 428
EP 437
DI 10.1016/j.jvcir.2009.05.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900007
OA Green Published
DA 2024-07-18
ER

PT J
AU Singhal, N
   Lee, YY
   Kim, CS
   Lee, SU
AF Singhal, Nitin
   Lee, Young-Yoon
   Kim, Chang-Su
   Lee, Sang-Uk
TI Robust image watermarking using local Zernike moments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image watermarking; Digital right management; Local Zernike
   moments; Feature point detection; Image normalization; Content-based
   synchronization; Salient region parameters; Geometric distortions
ID DIGITAL WATERMARKING; SCALE
AB In this work, we propose a robust image watermarking algorithm using local Zernike moments, which are computed over circular patches around feature points. The proposed algorithm locally computes Zernike moments and modifies them to embed watermarks, achieving robustness against cropping and local geometric attacks. Moreover, to deal with scaling attacks, the proposed algorithm extracts salient region parameters, which consist of an invariant centroid and a salient scale, and transmits them to the decoder. The parameters are used at the decoder to normalize a suspect image and detect watermarks. Extensive simulation results show that the proposed algorithm detects watermarks with low error rates, even if watermarked images are distorted by various geometric attacks as well as signal processing attacks. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Singhal, Nitin; Lee, Young-Yoon] Samsung Elect Co Ltd, Suwon, South Korea.
   [Lee, Sang-Uk] Seoul Natl Univ, Sch Elect Engn, Signal Proc Lab, Seoul 151, South Korea.
   [Lee, Sang-Uk] Seoul Natl Univ, INMC, Seoul 151, South Korea.
C3 Korea University; Samsung; Samsung Electronics; Seoul National
   University (SNU); Seoul National University (SNU)
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM changsukim@korea.ac.kr
RI lee, Young Yoon/AAJ-2933-2020
OI Kim, Chang-Su/0000-0002-4276-1831
FU Ministry of Knowledge Economy, Korea; Institute of Information
   Technology Advancement [ITA-2009-C-1090-09020017]; Korea government
   (MEST) [R012008-000-20292-0]
FX This work was supported partly by the Ministry of Knowledge Economy,
   Korea, under the Information Technology Research Center support program
   supervised by the Institute of Information Technology Advancement (Grant
   No.]ITA-2009-C-1090-09020017) and partly by the Korea Science and
   Engineering Foundation (KOSEF) grant funded by the Korea government
   (MEST) (No. R012008-000-20292-0).
CR Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   Alghoniemy M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1291, DOI 10.1109/ICME.2000.871003
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bum-Soo Kim, 2003, Digital Watermarking. First International Workshop, IWDW 2002. Revised Papers (Lecture Notes Computer Science Vol.2613), P202
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Dittmann J, 2000, PROC SPIE, V3971, P176, DOI 10.1117/12.384971
   Dong P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P493, DOI 10.1109/ICIP.2002.1039015
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lin S., 2004, Error Control Coding, Vsecond
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   O'Ruanaidh J., 1998, Signal Processing, V66, P303, DOI DOI 10.1016/S0165-1684(98)00012-7
   Papakostas GA, 2007, INFORM SCIENCES, V177, P2802, DOI 10.1016/j.ins.2007.01.010
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   PETITCOLAS FAP, 1998, P 2 WORKSH INF HID P, V1525, P218
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   Singhal N, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P401, DOI 10.1109/MMSP.2007.4412901
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   TEAGUE MR, 1979, J OPT SOC AM, V69, P1468
   Viet Quoc Pham, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P473
   XIN Y, 2004, INT C PATT REC ICPR, V4, P861
   YANG X, 2005, IEEE INT WORKSH MULT, P1
   Zernike F, 1934, PHYSICA, V1, P689
   Zhenjiang M., 2000, Pattern Recognition Letters, V21, P169
NR 31
TC 34
Z9 39
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 408
EP 419
DI 10.1016/j.jvcir.2009.04.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900005
DA 2024-07-18
ER

PT J
AU Chen, CS
   Yeh, CW
   Yin, PY
AF Chen, Chin-Sheng
   Yeh, Chun-Wei
   Yin, Peng-Yeng
TI A novel Fourier descriptor based image alignment algorithm for automatic
   optical inspection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fourier descriptor; Image alignment; Automatic optical inspection;
   Component detection; Contour tracing; Run length encoding; Blobs tables;
   Phase-shifted technique
ID SHAPE; RETRIEVAL; ROTATION
AB This paper presents a Fourier descriptor based image alignment algorithm (FDBIA) for applications of automatic optical inspection (AOI) performed in real-time environment. It deliberates component detection and contour tracing algorithms and uses the magnitude and phase information of Fourier descriptors to establish correspondences between the target objects detected in the reference and the inspected images, so the parameters for aligning the two images can be estimated accordingly. To enhance the computational efficiency, the proposed component detection and contour tracing algorithms use the run length encoding (RLE) and Blobs tables to represent the pixel information in the regions of interest. The Fourier descriptors derived from the component boundaries are used to match the target objects. Finally, the transformation parameters for aligning the inspected image with the reference image are estimated based on a novel phase-shifted technique. Experimental results show that the proposed FDBIA algorithm sustains similar accuracy as achieved by the commercial software Easyfind against various rotation and translation conditions. Also, the computational time consumed by the FDBIA algorithm is significantly shorter than that by Easyfind. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Chen, Chin-Sheng; Yeh, Chun-Wei] Natl Taipei Univ Technol, Inst Automat Technol, Taipei 10608, Taiwan.
   [Yin, Peng-Yeng] Natl Chi Nan Univ, Dept Informat Management, Puli, Nantou, Taiwan.
C3 National Taipei University of Technology; National Chi Nan University
RP Chen, CS (corresponding author), Natl Taipei Univ Technol, Inst Automat Technol, NTUT Box 4325,1,Sec 3,Chung Hsiao E Rd, Taipei 10608, Taiwan.
EM saint@ntut.edu.tw
RI cai, bo/G-1491-2010; Chen, Chin Sheng/ABG-6314-2021
OI Chen, Chin Sheng/0000-0001-7060-1344
CR Chang F, 2004, COMPUT VIS IMAGE UND, V93, P206, DOI 10.1016/j.cviu.2003.09.002
   CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C
   Chen CJ, 2005, P SOC PHOTO-OPT INS, V5679, P53, DOI 10.1117/12.587553
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   Fiorio C, 1996, THEOR COMPUT SCI, V154, P165, DOI 10.1016/0304-3975(94)00262-2
   HAIG TD, 1992, IEE PROC-I, V139, P206, DOI 10.1049/ip-i-2.1992.0029
   He LF, 2008, IEEE T IMAGE PROCESS, V17, P749, DOI 10.1109/TIP.2008.919369
   Hu QM, 2005, COMPUT VIS IMAGE UND, V99, P414, DOI 10.1016/j.cviu.2005.04.001
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Huttenlocher DP, 1999, IEEE T PATTERN ANAL, V21, P951, DOI 10.1109/34.790437
   Kunttu I, 2007, IET IMAGE PROCESS, V1, P231, DOI 10.1049/iet-ipr:20060113
   Kunttu I, 2006, MACH VISION APPL, V17, P211, DOI 10.1007/s00138-006-0030-6
   Kwon OK, 2001, PATTERN RECOGN, V34, P2005, DOI 10.1016/S0031-3203(00)00132-1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martín-Herrero J, 2007, MACH VISION APPL, V18, P1, DOI 10.1007/s00138-006-0041-3
   Martín-Herrero J, 2004, J PHYS A-MATH GEN, V37, P9377, DOI 10.1088/0305-4470/37/40/004
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Shima Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P655, DOI 10.1109/ICPR.1990.118183
   SUZUKI K, 2004, COMPUTER VISION IMAG, V89, P1
   Tang Y. Y., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P25, DOI 10.1142/S0218001491000053
   Tsai DM, 2002, PATTERN RECOGN LETT, V23, P191, DOI 10.1016/S0167-8655(01)00099-X
   Wu KS, 2005, PROC SPIE, V5747, P1965, DOI 10.1117/12.596105
   Yang Y, 2003, IMAGE VISION COMPUT, V21, P459, DOI 10.1016/S0262-8856(03)00015-5
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhang DS, 2003, J VIS COMMUN IMAGE R, V14, P41, DOI 10.1016/S1047-3203(03)00003-8
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 28
TC 21
Z9 24
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2009
VL 20
IS 3
BP 178
EP 189
DI 10.1016/j.jvcir.2008.11.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 424VD
UT WOS:000264595500002
DA 2024-07-18
ER

PT J
AU Liu, Y
   Chen, X
   Zhang, CC
   Sprague, A
AF Liu, Ying
   Chen, Xin
   Zhang, Chengcui
   Sprague, Alan
TI Semantic clustering for region-based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic clustering; Content-based image retrieval; Outlier detection;
   Network flow; Region-based retrieval; Semantic gap; Kd-tree; Multiple
   instance learning (MIL)
AB With the proliferation of applications that demand content-based image retrieval, two merits are becoming more desirable. The first is the reduced search space, and the second is the reduced "semantic gap." This paper proposes a semantic clustering scheme to achieve these two goals. By performing clustering before image retrieval, the search space can be significantly reduced. The proposed method is different from existing image clustering methods as follows: (1) it is region based, meaning that image subregions, instead of the whole image, are grouped into. The semantic similarities among image regions are collected over the user query and feedback history: (2) the clustering scheme is dynamic in the sense that it can evolve to include more new semantic categories. Ideally, one cluster approximates one semantic concept or a small set of closely related semantic concepts, based on which the "semantic gap" in the retrieval is reduced. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Liu, Ying; Chen, Xin; Zhang, Chengcui; Sprague, Alan] Univ Alabama Birmingham, Dept Comp & Informat Sci, Birmingham, AL 35294 USA.
C3 University of Alabama System; University of Alabama Birmingham
RP Zhang, CC (corresponding author), Univ Alabama Birmingham, Dept Comp & Informat Sci, CH 127,1530 3rd Ave S, Birmingham, AL 35294 USA.
EM liuyi@cis.uab.edu; chengxin@cis.uab.edu; zhang@cis.uab.edu;
   sprague@cis.uab.edu
FU UAB ADVANCE program; NSF [DBI-0649894]
FX The work of Chengcui Zhang was supported in part by the UAB ADVANCE
   program and NSF DBI-0649894.
CR [Anonymous], 1979, Graph Algorithms
   Barnett V., 1984, Wiley Series in Probability and Mathematical Statistics: Applied Probability and Statistics
   BENDOR A, 1999, J COMPUTATIONAL BIOL
   Bilen C, 2002, J COMPUT GRAPH STAT, V11, P311, DOI 10.1198/106186002760180536
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chapra S.C., 2006, Numerical Methods for Engineers
   Duan LJ, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1581
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   GOMORY RE, 1961, J SOC IND APPL MATH, V9, P551, DOI 10.1137/0109047
   GONG Z, 2005, P ODBASE, P1416
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   HAI Z, 2004, J SYST SOFTWARE, V73, P455
   HAN EH, 1997, P WORKSH RES ISS DAT
   Hodge V., 2004, A survey of outlier detection methodologies
   JING F, 2006, P ACM MM DEM
   Johnson T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P224
   Knorr E. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P219
   Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392
   Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211
   Liu GJ, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.194
   LIU Y, 2004, P INT C MACH LEARN A
   LIU Y, 2006, P IEEE INT C MULT EX
   Maron O., 1998, ADV NATURAL INFORM P, V10
   Patino-Escarcina Raquel E., 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P74, DOI 10.1109/ICSC.2008.81
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Sheikholeslami G, 2002, IEEE T KNOWL DATA EN, V14, P988, DOI 10.1109/TKDE.2002.1033769
   Song YQ, 2005, IEEE IJCNN, P1142
   Yin X, 2003, P INT S CIRC SYST IS
NR 30
TC 17
Z9 17
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 157
EP 166
DI 10.1016/j.jvcir.2008.11.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800009
DA 2024-07-18
ER

PT J
AU Guan, C
   Hassebrook, LG
   Lau, DL
   Yalla, V
AF Guan, Chun
   Hassebrook, Laurence G.
   Lau, Daniel L.
   Yalla, Veeraganesh
TI Near-infrared composite pattern projection for continuous motion
   hand-computer interaction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE structured light; augmented reality; virtual reality; human-computer
   interaction; 3D data acquisition
ID STRUCTURED LIGHT; RECOGNITION; GESTURES
AB Traditional structured light techniques require multiple patterns to be projected onto a scene and captured for three-dimensional (3D) reconstruction without ambiguity and resistance to variation of albedo. However, multi-pattern techniques can be corrupted by the object movement during the sequential projection. We have introduced a single projected pattern which efficiently combines multiple patterns into a single composite pattern projection-allowing for video rate three-dimensional data acquisition. Attaining low cost 3D video acquisition would have a profound impact on applications such as human-computer interaction and assistive technology. So far the composite pattern technique has only been performed with visible light which would cause user annoyances for these applications. To solve the problem, we use near-infrared to project the pattern. But this raises another more general issue of spatial skin response. In this study, near-infrared illumination is used for imperceptible measurement of hand pose. In particular, we are studying continuous motion depth acquisition for tracking hand motion and rotation as an interface to a virtual reality. Applications include advanced cockpit controls and computer interfacing for the disabled. (C) 2006 Elsevier Inc. All rights reserved.
C1 Univ Kentucky, Dept Elect & Comp Engn, Lexington, KY 40506 USA.
C3 University of Kentucky
RP Hassebrook, LG (corresponding author), Univ Kentucky, Dept Elect & Comp Engn, 453 AH, Lexington, KY 40506 USA.
EM cguan@engr.uky.edu; lgh@engr.uky.edu; dllau@engr.uky.edu;
   ganesh@engr.uky.edu
RI Lau, Daniel/O-5169-2014
OI Lau, Daniel/0000-0003-1377-4622; Yalla, Veera Ganesh/0009-0009-9948-4861
CR AKSOY B, 2003, P TAPPI SPR TECH C T
   [Anonymous], ELECT BASEL
   ASSAN M, 1997, VIDEOBASED SIGN LANG
   BERGASA LM, 1999, GUIDANCE WHEELCHAIR
   BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869
   Chauhan V., 2001, 12 SCAND C IM AN BER
   Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1
   Cipolla R, 1996, IMAGE VISION COMPUT, V14, P171, DOI 10.1016/0262-8856(96)84056-X
   DeCarlo D, 1996, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.1996.517079
   Delamarre Q, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P585, DOI 10.1109/AFGR.1998.671011
   Fang Q, 1997, APPL OPTICS, V36, P2401, DOI 10.1364/AO.36.002401
   Frueh C, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P318, DOI 10.1109/3DIM.2005.26
   GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861
   Guan C, 2003, PROC SPIE, V5097, P40, DOI 10.1117/12.487276
   Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406
   HAUPTMANN AG, 1993, INT J MAN MACH STUD, V38, P231, DOI 10.1006/imms.1993.1011
   KNOINCKX T, 2004, 3DPVT 2004, P413
   LI JL, 2000, SPIE P VISUAL INFORM, V9, P68
   Malassiotis S, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P190, DOI 10.1109/TDPVT.2002.1024061
   Mazo M, 2001, IEEE ROBOT AUTOM MAG, V8, P46, DOI 10.1109/100.924361
   MUNK KH, 1997, USE CONTEXT PRIORI K
   OGASAWARA T, 2001, P 10 IEEE INT WORKSH, P262
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Rehg J.M., 1994, Proceeding 3rd European Conf on Computer Vision, P35
   Schumeyer RP, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P531, DOI 10.1109/MMSP.1997.602689
   SNOWDON DN, 1993, 2 INT C INT REAL VIR, P399
   SRINIVASAN V, 1985, APPL OPTICS, V24, P185, DOI 10.1364/AO.24.000185
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Starner T, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P87, DOI 10.1109/ISWC.2000.888469
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Wren CR, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P22, DOI 10.1109/AFGR.1998.670920
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   Yang RG, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P255, DOI 10.1109/AFGR.2002.1004163
NR 33
TC 6
Z9 12
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 141
EP 150
DI 10.1016/j.jvcir.2006.11.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700005
DA 2024-07-18
ER

PT J
AU Fu, CM
   Hwang, WL
   Huang, CL
AF Chih-Ming Fu
   Wen-Liang Hwang
   Chung-Lin Huang
TI A joint source and channel coding algorithm for error-resilient
   SPIHT-coded video bitstreams
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE joint source channel coding; video transmission
ID IMAGE COMPRESSION; TRANSMISSION; PROTECTION
AB We propose an analytical rate-distortion optimized joint source and channel coding algorithm for error-resilient scalable encoded video for lossy transmission. A video is encoded into multiple independent substreams to avoid error propagation and is assigned forward error correction (FEC) codes and source bits using Lagrange optimization. Our method separates video coding and packetization into different tiers which can be easily incorporated into any coding structure that generates a set of independent compressed bit-streams. To demonstrate the performance, we use the 2-state Markov model to describe the burst loss channel and Reed-Solomon codes as forward error correction codes. Simulation results show that the proposed channel incorporated rate-distortion optimization approach have better performance. (C) 2006 Elsevier Inc. All rights reserved.
C1 Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu, Taiwan.
   Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
C3 National Tsing Hua University; Academia Sinica - Taiwan
RP Fu, CM (corresponding author), Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu, Taiwan.
EM chihming.fu@gmail.com
RI Hwang, Wen-Liang/B-2500-2013
OI Hwang, Wen-Liang/0000-0002-5546-6575
CR Alatan AA, 2000, IEEE J SEL AREA COMM, V18, P814, DOI 10.1109/49.848235
   Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   Boulgouris NV, 2003, IEEE T CIRC SYST VID, V13, P1170, DOI 10.1109/TCSVT.2003.819187
   Cho S, 2002, IEEE T CIRC SYST VID, V12, P157
   Cosman PC, 2000, IEEE T IMAGE PROCESS, V9, P982, DOI 10.1109/83.846241
   Creusere CD, 1997, IEEE T IMAGE PROCESS, V6, P1436, DOI 10.1109/83.624967
   Dumitrescu S, 2004, IEEE T MULTIMEDIA, V6, P230, DOI 10.1109/TMM.2003.822793
   Farshchian M, 2004, IEEE SIGNAL PROC LET, V11, P780, DOI 10.1109/LSP.2004.835470
   Fu CM, 2005, INT CONF ACOUST SPEE, P305
   Horn U, 1999, SIGNAL PROCESS-IMAGE, V15, P77, DOI 10.1016/S0923-5965(99)00025-9
   Hung BF, 2003, IEEE J SEL AREA COMM, V21, P1595, DOI 10.1109/JSAC.2003.815229
   Kim J, 2003, IEEE T IMAGE PROCESS, V12, P121, DOI 10.1109/TIP.2003.809006
   Lee TWA, 2002, IEEE T CIRC SYST VID, V12, P1059, DOI 10.1109/TCSVT.2002.806816
   Man H, 1997, IEEE SIGNAL PROC LET, V4, P227, DOI 10.1109/97.611284
   Moccagatta I, 2000, IEEE J SEL AREA COMM, V18, P899, DOI 10.1109/49.848245
   Proakis J. G., 1995, DIGITAL COMMUNICATIO
   REDMILL DW, 1994, IEEE IMAGE PROC, P95, DOI 10.1109/ICIP.1994.413282
   Sherwood PG, 1997, IEEE SIGNAL PROC LET, V4, P189, DOI 10.1109/97.596882
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Thie J, 2004, EURASIP J APPL SIG P, V2004, P207, DOI 10.1155/S1110865704308024
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
NR 22
TC 4
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1164
EP 1177
DI 10.1016/j.jvcir.2006.03.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200003
DA 2024-07-18
ER

PT J
AU Peng, JL
   Kim, CS
   Kuo, CCJ
AF Peng, Jingliang
   Kim, Chang-Su
   Kuo, C. -C. Jay
TI Technologies for 3D mesh compression: A survey
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE 3D mesh compression; single-rate mesh coding; progressive mesh coding;
   MPEG-4
ID GEOMETRIC COMPRESSION; CONNECTIVITY
AB Three-dimensional (313) meshes have been widely used in graphic applications for the representation of 3D objects. They often require a huge amount of data for storage and/or transmission in the raw data format. Since most applications demand compact storage, fast transmission, and efficient processing of 3D meshes, many algorithms have been proposed to compress 3D meshes efficiently since early 1990s. In this survey paper, we examine 3D mesh compression technologies developed over the last decade, with the main focus on triangular mesh compression technologies. In this effort, we classify various algorithms into classes, describe main ideas behind each class, and compare the advantages and shortcomings of the algorithms in each class. Finally, we address some trends in the 3D mesh compression technology development. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ So Calif, Dept Elect Engn, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.
C3 University of Southern California; Chinese University of Hong Kong
RP Kim, CS (corresponding author), Univ So Calif, Dept Elect Engn, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
EM jingliap@usc.edu; cskim@ieee.org; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Ahn JH, 2001, ELECTRON LETT, V37, P1445, DOI 10.1049/el:20010993
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   ALLIEZ P, 2001, EUROGRAPHICS, P480
   ALLIEZ P, 2003, P S MULT GEOM MOD SE
   [Anonymous], ACM SIGGRAPH 1997 C
   [Anonymous], ACM SIGGRAPH 1996 C
   Arkin EM, 1996, VISUAL COMPUT, V12, P429
   Bajaj C., 1998, Compression and coding of large cad models
   Bajaj C. L., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P307, DOI 10.1109/VISUAL.1999.809902
   Bajaj CL, 1996, GRAPH MODEL IM PROC, V58, P524, DOI 10.1006/gmip.1996.0044
   Bajaj CL, 1999, COMP GEOM-THEOR APPL, V14, P167, DOI 10.1016/S0925-7721(99)00026-7
   Breen DE, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P7, DOI 10.1109/SVV.1998.729579
   Briceno H.M., 2003, Dans SCA '03, P136
   Chou PH, 2002, IEEE T VIS COMPUT GR, V8, P373, DOI 10.1109/TVCG.2002.1044522
   Chow MM, 1997, VISUALIZATION '97 - PROCEEDINGS, P347, DOI 10.1109/VISUAL.1997.663902
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   Cohen-Or D., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P67
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DEERING M, 1995, ACM SIGGRAPH, P13
   Devillers O, 2000, IEEE VISUAL, P319, DOI 10.1109/VISUAL.2000.885711
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Edelsbrunner H., 2001, Geometry and Topology for Mesh Generation
   Evans F, 1996, IEEE VISUAL, P319, DOI 10.1109/VISUAL.1996.568125
   Evans F., 1996, Completing Sequential Triangulations is Hard
   Gandoin PM, 2002, ACM T GRAPHIC, V21, P372, DOI 10.1145/566570.566591
   Gersho A., 2003, Vector Quantization and Signal Compression
   Gieng TS, 1998, IEEE T VIS COMPUT GR, V4, P145, DOI 10.1109/2945.694956
   Gotsman C, 2002, TUTORIALS ON MULTIRESOLUTION IN GEOMETRIC MODELLING, P319
   Gross J.L., 1998, GRAPH THEORY ITS APP, VSecond
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Guéziec A, 1998, VISUALIZATION '98, PROCEEDINGS, P383, DOI 10.1109/VISUAL.1998.745327
   GUMHOLD S, 1998, ACM SIGGRAPH, P133
   GUMHOLD S, 1999, ERL WORKSH 99 VIS MO
   GUMHOLD S, 1999, IEEE VISUALIZATION, P51
   Gumhold Stefan, 2000, WSI20001 U TUB
   GUSKOV I, 2000, ACM SIGGRAPH, P5
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Heckbert P., 1997, Multiresolution Surface Modeling Course Notes of SIGGRAPH '97
   Hoppe H, 2005, MATH VIS, P27, DOI 10.1007/3-540-26808-1_2
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Hoppe H, 1998, COMPUT GRAPH-UK, V22, P27, DOI 10.1016/S0097-8493(97)00081-2
   Ibarria L., 2003, Dans SCA '03, P126
   Isenburg M, 2002, PROC GRAPH INTERF, P161
   Isenburg M, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P284, DOI 10.1109/PCCGA.2002.1167872
   Isenburg M, 2000, COMP GRAPH, P263, DOI 10.1145/344779.344919
   Isenburg M, 2000, PROC GRAPH INTERF, P197
   ISENBURG M, 2000, 12 CAN C COMP GEOM, P247
   Isenburg M., 2005, IEEE VISUALIZATION
   *ISO IEC JTCI SC29, 2001, MPEG 4 AN FRAM EXT A
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Kahn DonaldW., 1995, Topology: An Introduction to the Point-Set and Algebraic Areas
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   KARNI Z, 2001, P GRAPH INT, P1
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   Khodakovsky A., 2002, Geometric Modeling for Scientific Visualization
   Khodavosky A, 2002, GRAPH MODELS, V64, P147, DOI 10.1006/gmod.2002.0575
   KING D, 1999, TR9936 GVU
   KING D, 1999, 11 CAN C COMP GEOM, P146
   Laney D, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P470, DOI 10.1109/TDPVT.2002.1024102
   LEE AWF, 1998, ACM SIGGRAPH, P95
   Lee ES, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P225, DOI 10.1109/PCCGA.2000.883945
   LEE H, 2003, ACM SIGGRAPH
   LEE H, 2002, EUR 02 C P, P383
   LENGYEL J, 1999, ACM 1999 S INT 3D GR
   Li JK, 1998, P IEEE, V86, P1052, DOI 10.1109/5.687829
   Loop C, 1987, THESIS U UTAH
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Luebke DP, 2001, IEEE COMPUT GRAPH, V21, P24, DOI 10.1109/38.920624
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Pajarola R, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P173, DOI 10.1109/CGI.2000.852332
   PAJAROLA R, 1999, UCIICS9943
   PAJAROLA R, 1999, IEEE VIS 99 C P, P299
   PENG J, 2005, IN PRESS SIGGRAPH
   Popovic J., 1997, ACM SIGGRAPH, P217
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Rossignac J, 1999, COMP GEOM-THEOR APPL, V14, P119, DOI 10.1016/S0925-7721(99)00028-0
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SANDER P, 2002, MSRTR200227
   Saupe D, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P384, DOI 10.1109/TDPVT.2002.1024088
   SAUPE D, 2001, P VIS MOD VIS, P333
   Schindler M, 1998, IEEE DATA COMPR CONF, P572, DOI 10.1109/DCC.1998.672314
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   SHIKHARE D, 2000, STATE ART GEOMETR CO
   Soucy M, 1996, COMPUT VIS IMAGE UND, V63, P1, DOI 10.1006/cviu.1996.0001
   Speckmann B., 1997, Proceedings of 9th Canadian Conference on Computational Geometry, P239
   Szymczak A., 2000, Proceedings of the 12th Annual Canadian Conference on Computational Geometry, P257
   Szymczak Andrzej., 1999, Proceedings of the 5th ACM Symposium on Solid Modeling and Applications, P54
   Taubin G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P451, DOI 10.1109/VISUAL.2002.1183807
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   Taubin G, 1998, P IEEE, V86, P1228, DOI 10.1109/5.687837
   TAUBIN G, 1999, EUROGRAPHICS
   TAUBIN G, 1995, ACM SIGGRAPH, P351
   TAUBIN G., 1998, ACM SIGGRAPH, P123
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   TURAN G, 1984, DISCRETE APPL MATH, V8, P289, DOI 10.1016/0166-218X(84)90126-4
   TUTTE WT, 1962, CANADIAN J MATH, V14, P21, DOI 10.4153/CJM-1962-002-9
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Xiang X., 1999, ACM Symposium on Interactive 3D Graphics, P71
   Yang JH, 2002, IEEE T CIRC SYST VID, V12, P1178, DOI 10.1109/TCSVT.2002.806814
   YANG JH, 2004, UNPUB IEEE T IMAGE P
   YANG JH, 2004, P ICIP
   Yang SN, 2002, VISUAL COMPUT, V18, P54, DOI 10.1007/s003710100147
   ZHANG J, 2005, P IEEE INT C INF TEC
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
   Zhang XY, 2001, IEEE 2001 SYMPOSIUM ON PARALLEL AND LARGE-DATA VISUALIZATION AND GRAPHICS, PROCEEDINGS, P51, DOI 10.1109/PVGS.2001.964404
   2001, 144962 ISO IEC
   1997, 147721 ISO IEC
NR 111
TC 212
Z9 251
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2005
VL 16
IS 6
BP 688
EP 733
DI 10.1016/j.jvcir.2005.03.001
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JQ
UT WOS:000242026600004
DA 2024-07-18
ER

PT J
AU Cai, JF
   Wu, JH
   Ngan, KN
   He, ZH
AF Cai, JF
   Wu, JH
   Ngan, KN
   He, ZH
TI Joint mode selection and unequal error protection for bitplane coded
   video transmission over wireless channels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE joint source-channel coding; bitplane based video coding; mode
   selection; unequal error protection; wireless video; fine granularity
   scalability
AB In this paper, we study joint source channel coding for bitplane based video coding over wireless channels. We consider using frame-level intra-mode to stop error propagation and using unequal error protection (UEP) to combat channel errors. Our focus is on how to optimally select coding modes and find UEP solutions for bitplane based video coding. In particular, we propose an overall end-to-end rate-distortion (R-D) function, which considers not only the source distortion and the channel distortion introduced in the current frame but also the propagated channel distortion from the previous frames. Based on this end-to-end R-D function, we are able to find the optimal solutions for both mode selection and UEP so that an optimal tradeoff between efficiency and robustness can be achieved. Experimental results demonstrate the significant performance gain. (c) 2005 Elsevier Inc. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   Univ Missouri, Dept Elect Engn, Columbia, MO 65211 USA.
C3 Nanyang Technological University; Chinese University of Hong Kong;
   University of Missouri System; University of Missouri Columbia
RP Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM asjfcai@ntu.edu.sg; pg02320384@ntu.edu.sg; knngan@ee.cuhk.edu.hk;
   HeZhi@missouri.edu
RI Ngan, N/E-8240-2014; He, Zhihai/A-5885-2019; Cai, Jianfei/A-3691-2011
OI Ngan, N/0000-0003-1946-3235; Cai, Jianfei/0000-0002-9444-3763
CR [Anonymous], 1996, WIRELESS COMMUNICATI
   Chande V, 2000, IEEE J SEL AREA COMM, V18, P850, DOI 10.1109/49.848239
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Huang HC, 2002, IEEE T CIRC SYST VID, V12, P372, DOI 10.1109/TCSVT.2002.800314
   ICKER SB, 1995, ERROR CONTROL SYSTEM
   *ITUT, 1997, H263 ITU T
   Kim J, 2003, IEEE T IMAGE PROCESS, V12, P121, DOI 10.1109/TIP.2003.809006
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Nosratinia A, 2003, IEEE T COMMUN, V51, P186, DOI 10.1109/TCOMM.2003.809256
   Peng WS, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P993, DOI 10.1109/ICIP.2001.958663
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SCHAAR M, 2000, JTC1SC29WG11 ISOIEC
   SCHAAR M, 2001, IEEE T MULTIMEDIA, P381
   SCHAAR M, 2002, IEEE T CIRCUITS SYST, P360
   STANKOVIC V, 2003, P IEEE WCNC 03 NEW O, V1, P317
   STOCKHAMMER T, 2002, P IEEE ICIP 2002 ROC, V2, P169
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   STUHLMULLER K, 1999, PACK VID WORKSH 99 A
   Taubman DS, 2002, P IEEE, V90, P1336, DOI 10.1109/JPROC.2002.800725
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
   WU Z, 2002, P IEEE ICIP 2002, V1, P213
   Yang XK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P737
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   ZHANG XM, 2003, IEEE T CIRCUITS SYST, P12
NR 26
TC 2
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 412
EP 431
DI 10.1016/j.jvcir.2004.11.012
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600003
DA 2024-07-18
ER

PT J
AU Sun, XM
   Kim, CS
   Kuo, CCJ
AF Sun, XM
   Kim, CS
   Kuo, CCJ
TI MPEG video markup language and its applications to robust video
   transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MPEG video; markup language; XML; MPEG-4; robust video transmission;
   video multicast
ID ERROR; PERFORMANCE; MULTICAST
AB In this research, we develop the MPEG video markup language (MPML) to describe MPEG-4 video contents. As an XML designed specifically for MPEG-4 bitstreams, MPML provides a friendly Support for random access, portability, interoperability, flexibility, and extendibility. We propose an efficient compression algorithm to reduce the amount of storage space for MPML documents. Then, as two applications, we show how to use MPML for error-resilient video transmission over wireless channels and video multicast over Internet. It is demonstrated that the MPML-based decoding algorithm can protect image quality effectively against transmission errors over noisy channels by using the random access support of MPML. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
   Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.
C3 University of Southern California; University of Southern California;
   Chinese University of Hong Kong
RP Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
EM sunx@pollux.usc.edu; cskim@ieee.org; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR AIGN S, 1995, P IEEE INT C COMM, V3, P1778, DOI DOI 10.1109/ICC.1995.524505
   [Anonymous], ACM SIGCOMM
   [Anonymous], EXT MARK LANG XML 1
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Cheney J, 2001, IEEE DATA COMPR CONF, P163, DOI 10.1109/DCC.2001.917147
   COOMBS JH, 1987, COMMUN ACM, V30, P933, DOI 10.1145/32206.32209
   Crow BP, 1997, IEEE COMMUN MAG, V35, P116, DOI 10.1109/35.620533
   GILBERT EN, 1960, BELL SYST TECH J, V39, P1253, DOI 10.1002/j.1538-7305.1960.tb03959.x
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   Gringeri S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P113, DOI 10.1145/319463.319478
   KIM JG, 2000, P SPIE APPL DIGITAL, V23, P214
   KIM M, 2000, P ACM WORKSH MULT, P71
   Li X, 1999, IEEE NETWORK, V13, P46, DOI 10.1109/65.768488
   Liefke Hartmut., 2000, P 2000 ACM SIGMOD IN, P153
   Lin S., 1983, Error Control Coding: Fundamentals and Applications
   *MPEG4 VID GROUP, 1998, JTC1SC29WG11 ISOIEC
   *MPEG4 VID GROUP, 2001, JTC1SC29WG11 ISOIEC
   PRICE R, 1998, P ACM DIG LIB C ACM, P172
   Salembier P, 2001, IEEE T CIRC SYST VID, V11, P748, DOI 10.1109/76.927435
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   SUN X, 2002, P IEEE INT S CIRC SY, V2, P676
   SUN X, 2003, P IEEE INT S CIRCUIT, V2, P820
   Sun Xiaoming., 2004, Design and Application of MPEG Video Markup Language
   Sun XM, 2003, PROC SPIE, V5241, P111, DOI 10.1117/12.510921
   Sun XM, 2003, P SOC PHOTO-OPT INS, V5108, P263, DOI 10.1117/12.486722
   Sun XM, 2003, P SOC PHOTO-OPT INS, V5018, P284, DOI 10.1117/12.476181
   Sun XM, 2002, P SOC PHOTO-OPT INS, V4736, P139, DOI 10.1117/12.477574
   *W3C REC, SYNCHR MULT INT LANG
   *W3C REC, SCAL VECT GRAPH 1 0
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   *WEB3D CONS, 14772200X IEC WEB3D
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   YAN R, 2001, P 3 INT C INF
   YEE JR, 1995, IEEE T COMMUN, V43, P2316, DOI 10.1109/26.403764
NR 34
TC 4
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 589
EP 620
DI 10.1016/j.jvcir.2005.03.007
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600012
DA 2024-07-18
ER

PT J
AU Kim, SD
   Ra, JB
AF Kim, SD
   Ra, JB
TI Efficient block-based video encoder embedding a Wiener filter for noisy
   video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE pre-filtering; noise removal; DCT-domain filtering
ID FAST ALGORITHMS; MOTION; TRANSFORM; IMAGES
AB Since pre-filtering removes camera noise and improves coding efficiency dramatically, its efficient implementation has been an important issue in video sequence coding. Based on the approximated generalized Wiener filtering and two-dimensional discrete cosine transform (DCT) factorization, this paper introduces a novel pre-filtering scheme that is performed inside a video encoder. The proposed pre-filtering is performed, by scaling the DCT coefficients of original image blocks for intra block coding and those of motion-compensated error blocks for inter block coding, respectively. Even though the pre-filtering operation is embedded in a video encoder, its additional computational complexity is marginal for given signal-to-noise ratio (SNR) estimates, and the overall architecture of the conventional video encoder is maintained. Notwithstanding its simplicity, the proposed pre-filtering scheme gives good filtering and coding performance for noisy video sequences. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Korea Adv Inst Sci & Technol, Dept EECS, Yusong Gu, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Korea Adv Inst Sci & Technol, Dept EECS, Yusong Gu, 373-1 Kusongdong, Taejon 305701, South Korea.
EM jbra@ee.kaist.ac.kr
RI Beom, Jong/C-1958-2011
CR Al-Shaykh OK, 1998, IEEE T IMAGE PROCESS, V7, P1641, DOI 10.1109/83.730376
   Boo KJ, 1998, IEEE T CIRC SYST VID, V8, P287, DOI 10.1109/76.678623
   CHEN CF, 1993, IEEE T CIRCUITS-II, V40, P393, DOI 10.1109/82.277884
   FEIG E, 1992, IEEE T SIGNAL PROCES, V40, P2174, DOI 10.1109/78.157218
   *ISO IEC JTC 1SC, 1997, 11N1796 ISO IEC JTC
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   JONSSON RH, 1997, P INT C IM PROC SANT, V2, P366
   Kim SD, 1999, IEEE T CIRC SYST VID, V9, P156, DOI 10.1109/76.744282
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Merhav N, 1997, IEEE T CIRC SYST VID, V7, P468, DOI 10.1109/76.585926
   Ng MK, 2001, MULTIDIM SYST SIGN P, V12, P143, DOI 10.1023/A:1011136812633
   Niehsen T, 1999, IEEE T CIRC SYST VID, V9, P536, DOI 10.1109/76.767119
   PRATT WK, 1972, IEEE T COMPUT, VC 21, P636, DOI 10.1109/T-C.1972.223567
   VASCONCELOS N, 1997, P INT C IM PROC SANT, V2, P291
NR 14
TC 15
Z9 16
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2003
VL 14
IS 1
BP 22
EP 40
DI 10.1016/S1047-3202(02)00012-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 665TZ
UT WOS:000182138500002
DA 2024-07-18
ER

PT J
AU Wei, J
   Wang, W
AF Wei, Jia
   Wang, Wei
TI Facial attribute editing method combined with parallel GAN for attribute
   separation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial attribute editing; Generative adversarial network; Semantic
   consistency; Attribute mask
AB Facial attribute editing encounters problems of incorrect changes to face regions and artifacts in generated images. We propose a facial attribute editing method combined with parallel GAN for attribute separation. First, the method integrates the U2-net encoder and Trans-GAN decoder as a model encoder to extract and generate facial spatial information effectively. Second, RGB images and semantic mask images are used to train a parallel generator and discriminator respectively. Semantic consistency loss is introduced to ensure that the two branches have consistent semantic output and achieve the effect of convergence in the same direction parallel generator and discriminator. The proposed model, trained on the CelebAMask-HQ original dataset and verified by the CelebA dataset, adopts the separation of the face mask image and the background mask image, to improve the correct rate of face attribute editing. Compared with existing facial attribute editing methods, the proposed method is capable of balancing attribute editing ability and details preservation ability. It can accurately edit the target attribute area and greatly improve the quality of facial images.
C1 [Wei, Jia; Wang, Wei] Xian Polytech Univ, Sch Comp Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an Polytechnic University
RP Wang, W (corresponding author), Xian Polytech Univ, Sch Comp Sci, Xian 710048, Shaanxi, Peoples R China.
EM 1508251169@qq.com
RI Wei, Wang/GYU-4649-2022
OI Wei, Wang/0000-0002-1717-5785
FU Innovation Fund of Chinese Universities [2021ALA02002]; The 2021 "Light
   of Textile" Higher Education Teaching Reform Research Project of China
   National Textile Industry Council [2021BKJGLX004]; Higher Education
   Research Project of Xi 'an Polytechnic University [20GJ05]; Xi'an
   Polytechnic University 2021 Graduate Innovation Fund;  [chd2021027]
FX This work was supported in part by Innovation Fund of Chinese
   Universities (2021ALA02002) , 2021 "Light of Textile" Higher Education
   Teaching Reform Research Project of China National Textile Industry
   Council (2021BKJGLX004) , Higher Education Research Project of Xi 'an
   Polytechnic University (20GJ05) , Xi'an Polytechnic University 2021
   Graduate Innovation Fund (chd2021027) . The authors are thankful to
   those individuals who provided language help to improve the manu-script
   during the research.
CR [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2017, Attgan: facial attribute editing by only changing what you want
   Bodur R., 2021, A Unified Architecture of Semantic Segmentation and Hierarchical Generative Adversarial Networks for Expression Manipulation
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao Meng, 2019, Journal of Software, V30, P2188, DOI 10.13328/j.cnki.jos.005837
   Chen P, 2019, 2019 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE BIG DATA AND INTELLIGENT SYSTEMS (HPBD&IS), P97, DOI [10.1109/hpbdis.2019.8735455, 10.1109/HPBDIS.2019.8735455]
   Chen YC, 2018, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2018.00373
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Gardner J.R., 2015, Deep Manifold Traversal: Changing Labels with Convolutional Features
   Girolami M., 2015, Riemann manifold Langevin and Hamiltonian Monte Carlo methods, V73, P123
   He H.Q., 2022, J. Comput. Appl., V42, P1
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu Wenting, 2022, Computer Engineering and Applications, P1, DOI 10.3778/j.issn.1002-8331.2106-0442
   MacGregor BD, 2022, J REAL ESTATE RES, V44, P491, DOI 10.1080/08965803.2022.2033398
   Shaham U., Conditional Generative Adversarial Nets
   Song XX, 2020, SIGNAL IMAGE VIDEO P, V14, P1217, DOI 10.1007/s11760-020-01660-0
   Tong Jing, 2007, Journal of Computer Applications, V27, P1013
   Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645
   Wang T.J., 2017, Dig. Educ., V3, P1
   Weng L., 2019, From gan to wgan
   Zhang Q., 2016, Improved salient object detection based upon graph-based manifold ranking
   Zhang Z., 2013, Eyeglasses removal from facial image based on MVLR
   Zhu JY, 2017, IEEE GLOB COMM CONF
   Zhu Z., 2014, Recover Canonical-View Faces in the Wild with Deep Neural Networks
NR 25
TC 0
Z9 0
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104031
DI 10.1016/j.jvcir.2023.104031
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FF1M3
UT WOS:001144256700001
DA 2024-07-18
ER

PT J
AU Zhao, GJ
   Li, FY
   Yao, H
   Qin, C
AF Zhao, Gejian
   Li, Fengyong
   Yao, Heng
   Qin, Chuan
TI TASTNet: An end-to-end deep fingerprinting net with two-dimensional
   attention mechanism and spatio-temporal weighted fusion for video
   content authentication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robust video fingerprinting; Discrimination; Two-dimensional attention;
   Spatio-temporal fusion
AB In this paper, a robust fingerprinting scheme for video content authentication with two-dimensional attention mechanism and spatio-temporal weighted fusion called TASTNet is proposed, which can automatically extracts key spatio-temporal features from the input video and maps them to the corresponding fingerprint. Detailedly, the two-dimensional attention mechanism is applied to resist different kinds of digital manipulations for robustness enhancement. To incorporate perceptual characteristics, a spatio-temporal weighted fusion method based on LTSM is presented to integrate frame-level features into video-level features while retaining the temporal order. In the process of fusion, key frames are allocated with larger weights according to inter-frame correlation. With these two steps, we can obtain representative video features that contain principal perception information. In addition, the proposed scheme utilizes deep metric learning for training, and we design multiple constraints to make the generated fingerprint more compact and discriminable. Extensive experiments demonstrate that our scheme can achieve superior performances with respect to robustness and discrimination compared with some state-of-the-art schemes.
C1 [Zhao, Gejian; Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Li, Fengyong] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
C3 University of Shanghai for Science & Technology; Shanghai University of
   Electric Power
RP Qin, C (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM 202430387@st.usst.edu.cn; fyli@shiep.edu.cn; hyao@usst.edu.cn;
   qin@usst.edu.cn
RI Yao, Heng/J-9457-2019; Qin, Chuan/C-1106-2017
OI Yao, Heng/0000-0002-3784-4157; Qin, Chuan/0000-0002-0370-4623
FU National Natural Sci-ence Foundation of China [62172280, U20B2051,
   62172281]; Natural Science Foundation of Shanghai, China [21ZR1444600,
   20ZR1421600]; STCSM Capability Construction Project for Shanghai
   Municipal Universities [20060502300]
FX <B>Acknowledgments</B> This work was supported in part by the National
   Natural Sci-ence Foundation of China under Grants 62172280, U20B2051 and
   62172281, in part by the Natural Science Foundation of Shanghai, China
   under Grants 21ZR1444600 and 20ZR1421600, and in part by the STCSM
   Capability Construction Project for Shanghai Municipal Universities
   under Grant 20060502300.
CR [Anonymous], 2016, P 24 ACM INT C MULT
   Anuranji R, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102729
   Awad George, 2021, arXiv
   Chen L, 2020, LECT NOTES COMPUT SC, V11961, P802, DOI 10.1007/978-3-030-37731-1_65
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Dong Z, 2018, PATTERN RECOGN, V81, P357, DOI 10.1016/j.patcog.2018.04.014
   Fan JP, 2001, J VIS COMMUN IMAGE R, V12, P306, DOI 10.1006/jvci.2001.0471
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ZQ, 2023, IEEE T DEPEND SECURE, V20, P463, DOI 10.1109/TDSC.2021.3136163
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   Khelifi F, 2019, IEEE T CIRC SYST VID, V29, P50, DOI 10.1109/TCSVT.2017.2776159
   Kingma D. P., 2014, arXiv
   Kordopatis-Zilos G, 2017, IEEE INT CONF COMP V, P347, DOI 10.1109/ICCVW.2017.49
   Li JF, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P363, DOI 10.1109/CIS.2015.94
   Li XR, 2022, IEEE T INF FOREN SEC, V17, P1404, DOI 10.1109/TIFS.2022.3161149
   Liang XP, 2023, IEEE T MULTIMEDIA, V25, P1085, DOI 10.1109/TMM.2021.3139217
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1209, DOI 10.1109/TMM.2016.2645404
   Liu XC, 2013, IEEE SIGNAL PROC LET, V20, P1253, DOI 10.1109/LSP.2013.2287006
   Luo X, 2023, ACM T KNOWL DISCOV D, V17, DOI 10.1145/3532624
   Mihcak M., 2001, Information Hiding, V2137, P51
   Nie XS, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5528-6
   Nie XS, 2015, J VIS COMMUN IMAGE R, V32, P120, DOI 10.1016/j.jvcir.2015.08.001
   Rao NS, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P477, DOI 10.1109/CTCEEC.2017.8455022
   Rogaway P, 2004, LECT NOTES COMPUT SC, V3017, P371
   Sandeep R, 2020, PROCEEDINGS OF THE 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS-2020)
   Sandeep R, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Shen Q, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107244
   Smaira L., 2020, arXiv, DOI DOI 10.48550/ARXIV.2010.10864
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang ZJ, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103209
   Tang ZJ, 2020, COMPUT J, V63, P1017, DOI 10.1093/comjnl/bxz060
   Tang ZJ, 2017, SIGNAL PROCESS, V137, P240, DOI 10.1016/j.sigpro.2017.02.008
   Uchida Y, 2012, INT CONF ACOUST SPEE, P1029, DOI 10.1109/ICASSP.2012.6288061
   Wang J, 2012, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2012.6466942
   Wang KH, 2021, INT C PATT RECOG, P5360, DOI 10.1109/ICPR48806.2021.9412710
   Wang XF, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103124
   Yang GB, 2012, COMPUT SECUR, V31, P33, DOI 10.1016/j.cose.2011.11.004
NR 42
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103913
DI 10.1016/j.jvcir.2023.103913
EA AUG 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X1CR0
UT WOS:001095901100001
DA 2024-07-18
ER

PT J
AU Kshirsagar, AP
   Azath, H
AF Kshirsagar, Aniruddha Prakash
   Azath, H.
TI YOLOv3-based human detection and heuristically modified-LSTM for
   abnormal human activities detection in ATM machine
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human tracking; Abnormal human activities detection; Bank-automated
   teller machines; You only look once; Version 3; Enhanced long short-term
   memory; Hybrid spider monkey-chicken swarm optimization
ID ACTIVITY RECOGNITION; VIDEO SURVEILLANCE; FEATURES; SYSTEM
AB In existing works, accurately analyzing human activities is a complicated problem in public places. Consequently, the detection of human activities becomes challenging the computer vision technology. The major scope of the research is to develop an abnormal Human Activity Recognition (HAR) model using deep structured architectures for detecting the suspicious activities of humans in the ATM using the video surveillance system. The classification phase utilizes the enhanced deep learning approach named improved Long Short-Term Memory (LSTM) by optimizing certain parameters in LSTM by hybrid optimization algorithm for accurately classifying the normal and abnormal activities of humans. This hybrid optimization algorithm is developed and termed Hybrid Spider Monkey-Chicken Swarm Optimization (HSM-CSO) for achieving the effective performance of the deep learning-based classification. Hence, the designed HAR model in ATM is proven that it helps to improve the system performance and also give relief from prohibited activities or crimes and false alarms for humans.
C1 [Kshirsagar, Aniruddha Prakash; Azath, H.] VIT Bhopal Univ, Bhopal, India.
C3 VIT Bhopal University
RP Kshirsagar, AP (corresponding author), VIT Bhopal Univ, Bhopal, India.
OI Kshirsagar, Mr. A.P./0000-0002-9093-6720
CR Agrawal V, 2018, INT J SYST ASSUR ENG, V9, P929, DOI 10.1007/s13198-017-0685-6
   Ahad Md. Atiqur Rahman, 2018, BIOMED SOFT COMPUT H, V23
   Ambati L.S., 2021, J. Midwest Assoc. Inf. Syst., V1
   Beddiar Djamila Romaissa, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P548, DOI 10.1109/ICITECH.2017.8080057
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Candás JLC, 2014, PERVASIVE MOB COMPUT, V15, P228, DOI 10.1016/j.pmcj.2014.09.007
   Pham C, 2020, IEEE ACCESS, V8, P86934, DOI 10.1109/ACCESS.2020.2991731
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Fu Y, 2019, INT C INTEL HUM MACH, P301, DOI 10.1109/IHMSC.2019.00076
   Helmi AM, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23081065
   Himeur Y, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105698
   Huan RH, 2021, MULTIMED TOOLS APPL, V80, P36159, DOI 10.1007/s11042-021-11363-4
   Huang WB, 2023, ACM T EMBED COMPUT S, V22, DOI 10.1145/3551486
   Huang WB, 2023, IEEE T MOBILE COMPUT, V22, P5064, DOI 10.1109/TMC.2022.3174816
   Imtiaz H., 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1627
   Jain Aman, 2021, MATER TODAY-PROC
   Khaire P, 2022, FORENS SCI INT-DIGIT, V40, DOI 10.1016/j.fsidi.2022.301346
   Khaire PA, 2021, J REAL-TIME IMAGE PR, V18, P1789, DOI 10.1007/s11554-021-01155-2
   Khatiwada Pankaj, 2021, MACH LEARN
   Konheim AG, 2016, J CRYPTOGR ENG, V6, P1, DOI 10.1007/s13389-015-0104-3
   Kuncan F, 2022, J SUPERCOMPUT, V78, P1048, DOI 10.1007/s11227-021-03921-2
   Lahiri D, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Lee WK, 2018, EXPERT SYST APPL, V109, P12, DOI 10.1016/j.eswa.2018.05.014
   Liu CC, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P33, DOI 10.1109/SIPROCESS.2018.8600483
   Liu F., 2012, P 20 ACM INT C MULTI, P1295
   Mekruksavanich S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051636
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Nar R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2042, DOI 10.1109/ICACCI.2016.7732351
   Prabha B., 2022, Evolution in Signal Processing and Telecommunication Networks: Proceedings of Sixth International Conference on Microelectronics, Electromagnetics and Telecommunications (ICMEET 2021). Lecture Notes in Electrical Engineering (839), P39, DOI 10.1007/978-981-16-8554-5_5
   Sikandar T, 2019, MULTIMEDIA SYST, V25, P229, DOI 10.1007/s00530-018-0599-4
   Singh A, 2021, J REAL-TIME IMAGE PR, V18, P1787, DOI 10.1007/s11554-021-01169-w
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Su YT, 2019, MULTIMED TOOLS APPL, V78, P767, DOI 10.1007/s11042-018-5657-6
   Tripathi V, 2019, J REAL-TIME IMAGE PR, V16, P535, DOI 10.1007/s11554-016-0573-3
   Uddin MZ, 2013, INDOOR BUILT ENVIRON, V22, P289, DOI 10.1177/1420326X12469734
   Verma K.K., 2021, 2021 IEEE 8 UTT PRAD, P1
   Verma KK, 2021, INT J INTERACT MULTI, V7, P44, DOI 10.9781/ijimai.2021.08.008
   Verma KK, 2020, INT J INTERACT MULTI, V6, P125, DOI 10.9781/ijimai.2020.04.002
   Viraktamath S., 2021, Int. J. Eng. Res. Technol. (IJERT), V10
   Vrskova R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020931
   Wang Y, 2007, IEEE IMAGE PROC, P341
   Yin J, 2008, IEEE T KNOWL DATA EN, V20, P1082, DOI 10.1109/TKDE.2007.1042
NR 43
TC 0
Z9 0
U1 4
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103901
DI 10.1016/j.jvcir.2023.103901
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q0VH7
UT WOS:001054773900001
DA 2024-07-18
ER

PT J
AU Yang, YQ
   He, P
   Wang, SR
   Tian, Y
   Zhang, W
AF Yang, Yuqing
   He, Ping
   Wang, Shengrui
   Tian, Yu
   Zhang, Wei
TI DB-TASNet for disease diagnosis and lesion segmentation in medical
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Disease diagnosis; Lesion segmentation; Transformer; U-Net; DB-TASNet
ID TRANSFORMER; NETWORK
AB Deep learning algorithms have been successfully used in the field of medical image analysis and have greatly improved application of intelligent algorithms to medical diagnosis. However, existing deep-learning-based diagnostic methods still suffer from several drawbacks: (1) In most medical image multi-tasking methods, focus segmentation and disease classification are often performed linearly, resulting in excessive reliance on the final results of focus segmentation. (2) The computational cost of the traditional attention mechanism for performing the segmentation task is very high and the convolutional architecture cannot be used to model long-distance dependencies, which in turn affects the segmentation accuracy. To address these issues, we propose a disease diagnosis and lesion segmentation model, Dual-Branch with Transformer Axial-attention Segmentation Net (DB-TASNet). DB-TASNet is built by the DenseNet-121 classification network and U-Net segmentation network improved using an axial-attention transformer model. Moreover, DB-TASNet also includes a lesion integration module to integrate segmentation results with the classification network in order to increase its attention to lesions and improve the diagnosis results. Experimental results on the Pneumothorax dataset provided by the Society for Imaging Informatics in Medicine (SIIM) show that the average AUC of the DB-TASNet classification task reaches 0.939, and the DICE coefficient of the segmentation task reaches 0.886. Such performance suggests that the proposed model may provide an efficient and effective diagnosis tool for medical personnel.
C1 [Yang, Yuqing; He, Ping] Hebei Univ Technol, Sch Artificial Intelligence, 5340, Xiping Rd, Tianjin 300401, Peoples R China.
   [Wang, Shengrui] Univ Sherbrooke, Fac Sci, 2500 boul Univ, Sherbrooke, PQ J1K 2R1, Canada.
   [Tian, Yu] Bank Tianjin CO LTD, 18, Haitai west Rd, Tianjin 300401, Peoples R China.
   [Zhang, Wei] Hebei Univ Technol, Sch Elect & Informat Engn, 5340, Xiping Rd, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology; University of Sherbrooke; Hebei
   University of Technology
RP He, P (corresponding author), Hebei Univ Technol, Sch Artificial Intelligence, 5340, Xiping Rd, Tianjin 300401, Peoples R China.
EM yqyang3130@163.com; heping@scse.hebut.edu.cn;
   shengrui.wang@usherbrooke.ca; 1344940440@qq.com; zhangv_869@163.com
RI Yuqing, Yang/ADJ-2720-2022
FU Natural Science Foundation of Hebei Province, China [F2020202067]; China
   Scholarship Council [201975]
FX The authors thank the editor and anonymous reviewers for their helpful
   comments and valuable suggestions. This research was sup-ported by the
   Natural Science Foundation of Hebei Province, China (Grant No.
   F2020202067) and a scholarship from the China Scholarship Council (Grant
   No. 201975) .
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bhattacharjee D, 2022, PROC CVPR IEEE, P12021, DOI 10.1109/CVPR52688.2022.01172
   Chen J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76282-0
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gao K, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101836
   Gao XH, 2021, Arxiv, DOI [arXiv:2107.01682, 10.48550/ARXIV.2107.01682preprint, DOI 10.48550/ARXIV.2107.01682]
   Groza V, 2020, I S BIOMED IMAGING, DOI 10.1109/isbiworkshops50223.2020.9153444
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guan QJ, 2018, Arxiv, DOI arXiv:1801.09927
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho JAT, 2019, Arxiv, DOI [arXiv:1912.12180, DOI 10.48550/ARXIV.1912.12180]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Jin S., 2020, medRxiv
   Jing YC, 2022, LECT NOTES COMPUT SC, V13667, P111, DOI 10.1007/978-3-031-20071-7_7
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XY, 2020, Arxiv, DOI [arXiv:1911.02855, DOI 10.18653/V1/2020.ACL-MAIN.45]
   Li Z, 2019, ADV COMPUT VIS PATT, P139, DOI 10.1007/978-3-030-13969-8_7
   Liang S., 2021, arXiv
   Liu SH, 2022, LECT NOTES COMPUT SC, V13676, P72, DOI 10.1007/978-3-031-19787-1_5
   Liu Songhua, 2022, NEURIPS
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Park S, 2021, Arxiv, DOI [arXiv:2103.07055, 10.48550/arXiv.2103.07055]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruby U, 2020, INT J ADV TRENDS COM, V9
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shaw P, 2018, Arxiv, DOI arXiv:1803.02155
   Shi HS, 2020, LANCET INFECT DIS, V20, P425, DOI 10.1016/S1473-3099(20)30086-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   van Tulder G, 2021, LECT NOTES COMPUT SC, V12903, P104, DOI 10.1007/978-3-030-87199-4_10
   Vaswani A, 2017, ADV NEUR IN, V30
   Verenich E, 2021, Arxiv, DOI arXiv:2109.00573
   Vong K.-M., 2021, 2021 IEEE EMBS INT C, P1
   Xie YT, 2021, LECT NOTES COMPUT SC, V12903, P171, DOI 10.1007/978-3-030-87199-4_16
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang XY, 2022, Arxiv, DOI arXiv:2210.17409
   Zhang SH, 2019, LECT NOTES COMPUT SC, V11764, P797, DOI 10.1007/978-3-030-32239-7_88
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZZ, 2022, Arxiv, DOI arXiv:2104.14702
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 49
TC 0
Z9 0
U1 4
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103896
DI 10.1016/j.jvcir.2023.103896
EA JUL 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P1MC8
UT WOS:001048341500001
DA 2024-07-18
ER

PT J
AU Ahmad, T
   Rizvi, STH
   Kanwal, N
AF Ahmad, Tasweer
   Rizvi, Syed Tahir Hussain
   Kanwal, Neel
TI Transforming spatio-temporal self-attention using action embedding for
   skeleton-based action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Graph convolutional network; Link prediction;
   Self-attention; Computer vision
ID GRAPH; NETWORK
AB Over the past few years, skeleton-based action recognition has attracted great success because the skeleton data is immune to illumination variation, view-point variation, background clutter, scaling, and camera motion. However, effective modeling of the latent information of skeleton data is still a challenging problem. Therefore, in this paper, we propose a novel idea of action embedding with a self-attention Transformer network for skeleton-based action recognition. Our proposed technology mainly comprises of two modules as, (i) action embedding and (ii) self-attention Transformer. The action embedding encodes the relationship between corresponding body joints (e.g., joints of both hands move together for performing clapping action) and thus captures the spatial features of joints. Meanwhile, temporal features and dependencies of body joints are modeled using Transformer architecture. Our method works in a single-stream (end-to-end) fashion, where multiple-layer perceptron (MLP) is used for classification. We carry out an ablation study and evaluate the performance of our model on a small-scale SYSU-3D dataset and large-scale NTU-RGB+D and NTU-RGB+D 120 datasets where the results establish that our method performs better than other state-of-the-art architectures.
C1 [Ahmad, Tasweer] COMSATS Univ Islamabad, Sahiwal Campus, Sahiwal, Pakistan.
   [Rizvi, Syed Tahir Hussain; Kanwal, Neel] Univ Stavanger, Dept Elect Engn & Comp Sci, Stavanger, Norway.
C3 COMSATS University Islamabad (CUI); Universitetet i Stavanger
RP Ahmad, T (corresponding author), COMSATS Univ Islamabad, Sahiwal Campus, Sahiwal, Pakistan.
EM tasveerahmad@cuisahiwal.edu.pk; tahir.rizvi@uis.no; neel.kanwal@uis.no
RI Rizvi, Syed Tahir Hussain/H-4097-2016
OI Kanwal, Neel/0000-0002-8115-0558
CR Ahmad T, 2021, NEUROCOMPUTING, V423, P389, DOI 10.1016/j.neucom.2020.10.096
   Andersen R, 2006, ANN IEEE SYMP FOUND, P475
   Asif U, 2023, PATTERN RECOGN, V139, DOI 10.1016/j.patcog.2023.109484
   Baevski A., 2018, arXiv
   Barkoky A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103371
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen J, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104214
   Chen YS, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104144
   Chen YX, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107321
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Cho S, 2020, IEEE WINT CONF APPL, P624, DOI [10.1109/wacv45572.2020.9093639, 10.1109/WACV45572.2020.9093639]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Galland A., 2019, ICML 2019 WORKSHOP L
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Huang LJ, 2020, AAAI CONF ARTIF INTE, V34, P11045
   Ivanov S, 2018, Arxiv, DOI arXiv:1805.11921
   Kanwal Neel, 2023, Advances in Knowledge Discovery and Data Mining: 27th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13937), P167, DOI 10.1007/978-3-031-33380-4_13
   Kanwal N, 2022, 37TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P813, DOI 10.1145/3477314.3507256
   Ke Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P536, DOI 10.1007/978-3-030-58586-0_32
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Levy O., 2015, Transactions of the Association for Computational Linguistics, V3, P211
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li Y, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0476-x
   Li ZH, 2023, IEEE T IMAGE PROCESS, V32, P392, DOI 10.1109/TIP.2022.3226410
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu K, 2021, IEEE T MULTIMEDIA, V23, P64, DOI 10.1109/TMM.2020.2974323
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Neimark D., 2021, Video transformer network
   Newman MEJ, 2005, SOC NETWORKS, V27, P39, DOI 10.1016/j.socnet.2004.11.009
   Ou YJ, 2023, J VIS COMMUN IMAGE R, V93, DOI 10.1016/j.jvcir.2023.103804
   Parmar N, 2018, PR MACH LEARN RES, V80
   Paszke A, 2019, ADV NEUR IN, V32
   Peng W, 2021, IEEE SIGNAL PROC LET, V28, P244, DOI 10.1109/LSP.2021.3049691
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Ribeiro LFR, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P385, DOI 10.1145/3097983.3098061
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shu XB, 2022, IEEE T PATTERN ANAL, V44, P3300, DOI 10.1109/TPAMI.2021.3050918
   Shu XB, 2021, IEEE T PATTERN ANAL, V43, P1110, DOI 10.1109/TPAMI.2019.2942030
   Si CY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107511
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang MS, 2023, IEEE T PATTERN ANAL, V45, P6940, DOI 10.1109/TPAMI.2020.3032738
   Wang QY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM)
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang WX, 2019, Arxiv, DOI arXiv:1707.03993
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Zhang JP, 2022, IEEE T CIRC SYST VID, V32, P63, DOI 10.1109/TCSVT.2020.3048440
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhao R, 2019, IEEE I CONF COMP VIS, P6881, DOI 10.1109/ICCV.2019.00698
NR 70
TC 2
Z9 2
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103892
DI 10.1016/j.jvcir.2023.103892
EA JUL 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O9UG7
UT WOS:001047190000001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kim, J
   Um, GM
   Seo, J
   Kim, W
AF Kim, Jeonghwan
   Um, Gi-Mun
   Seo, Jeongil
   Kim, Wonjun
TI Part-attentive kinematic chain-based for 3D human
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D human modeling; Deep Neural Networks; Body part attentions; Kinematic
   chain-based decoder
AB As the demand for realistic representation and its applications increases rapidly, 3D human modeling via a single RGB image has become the essential technique. Owing to the great success of deep neural networks, various learning-based approaches have been introduced for this task. However, partial occlusions still give the difficulty to accurately estimate the 3D human model. In this letter, we propose the part-attentive kinematic regressor for 3D human modeling. The key idea of the proposed method is to predict body part attentions based on each body center position and estimate parameters of the 3D human model via corresponding attentive features through the kinematic chain-based decoder in a one-stage fashion. One important advantage is that the proposed method has a good ability to yield natural shapes and poses even with severe occlusions. Experimental results on benchmark datasets show that the proposed method is effective for 3D human modeling under complicated real-world environments. The code and model are publicly available at: https://github.com/DCVL-3D/PKCN_release
C1 [Kim, Jeonghwan] Konkuk Univ, Dept Artificial Intelligence, Seoul 05029, South Korea.
   [Um, Gi-Mun; Seo, Jeongil] Elect & Telecommun Res Inst, Immers Media Res Sect, Daejeon 34129, South Korea.
   [Kim, Wonjun] Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University; Electronics & Telecommunications Research Institute -
   Korea (ETRI); Konkuk University
RP Kim, W (corresponding author), Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
EM wonjkim@konkuk.ac.kr; wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
OI Kim, Jeonghwan/0000-0002-5941-8351
FU Institute of Information Communications Technology Planning amp;
   Evaluation (IITP) - Korea government (MSIT) [2018-0-00207]
FX This work was supported by Institute of Information Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2018-0-00207, Immersive Media Research
   Laboratory) .
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Biggs B, 2020, ADV NEUR IN, V33
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Choi Hongsuk, 2022, CVPR, P1475
   Choutas Vasileios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P20, DOI 10.1007/978-3-030-58607-2_2
   Gartner E, 2022, IEEECVF C COMPUTER V, P13190
   Georgakis Georgios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P768, DOI 10.1007/978-3-030-58520-4_45
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hesse N, 2018, LECT NOTES COMPUT SC, V11070, P792, DOI 10.1007/978-3-030-00928-1_89
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang W, 2020, PROC CVPR IEEE, P5578, DOI 10.1109/CVPR42600.2020.00562
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kingma D. P., 2014, arXiv
   Kocabas M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11107, DOI 10.1109/ICCV48922.2021.01094
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Li JF, 2021, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR46437.2021.00339
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Lin K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12919, DOI 10.1109/ICCV48922.2021.01270
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma QL, 2021, PROC CVPR IEEE, P16077, DOI 10.1109/CVPR46437.2021.01582
   Mehta D, 2018, INT CONF 3D VISION, P120, DOI 10.1109/3DV.2018.00024
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moon G., 2020, PROC EUR C COMPUT VI, P1
   Paszke Adam, 2017, NIPS W
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Shimada S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417877
   Sun Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11159, DOI 10.1109/ICCV48922.2021.01099
   Tang SC, 2019, IEEE I CONF COMP VIS, P7749, DOI 10.1109/ICCV.2019.00784
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wan ZN, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13013, DOI 10.1109/ICCV48922.2021.01279
   Wang, 2020, P IEEE CVF C COMP VI, P7376
   Yuan Y, 2021, PROC CVPR IEEE, P7155, DOI 10.1109/CVPR46437.2021.00708
   Zanfir A, 2018, ADV NEUR IN, V31
   Zhang HW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11426, DOI 10.1109/ICCV48922.2021.01125
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
NR 46
TC 1
Z9 1
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103881
DI 10.1016/j.jvcir.2023.103881
EA JUN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N7HZ4
UT WOS:001038691000001
DA 2024-07-18
ER

PT J
AU Savner, SS
   Kanhangad, V
AF Savner, Siddharth Singh
   Kanhangad, Vivek
TI CrowdFormer: Weakly-supervised crowd counting with improved
   generalizability
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Vision transformers; Weakly -supervised method;
   Generalizability
AB Convolutional neural networks (CNNs) have dominated the field of computer vision for nearly a decade. However, due to their limited receptive field, CNNs fail to model the global context. On the other hand, transformers, an attention-based architecture, can model the global context easily. Despite this, there are limited studies that investigate the effectiveness of transformers in crowd counting. In addition, the majority of the existing crowd-counting methods are based on the regression of density maps which requires point-level annotation of each person present in the scene. This annotation task is laborious and also error-prone. This has led to an increased focus on weakly-supervised crowd-counting methods, which require only count-level annotations. In this paper, we propose a weakly-supervised method for crowd counting using a pyramid vision transformer. We have conducted extensive evaluations to validate the effectiveness of the proposed method. Our method achieves state-of-the-art performance. More importantly, it shows remarkable generalizability.
C1 [Savner, Siddharth Singh; Kanhangad, Vivek] Indian Inst Technol Indore, Dept Elect Engn, Indore 453552, Madhya Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Savner, SS (corresponding author), Indian Inst Technol Indore, Dept Elect Engn, Indore 453552, Madhya Pradesh, India.
EM phd1901102002@iiti.ac.in
OI Savner, Siddharth Singh/0000-0002-7375-0625
CR Abousamra S, 2021, AAAI CONF ARTIF INTE, V35, P872
   Bai YT, 2021, 35 C NEURAL INFORM P, V34
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chu HP, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103319
   Chu XX, 2021, ADV NEUR IN
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Lei YJ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107616
   Leibe B, 2005, PROC CVPR IEEE, P878
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang DK, 2022, LECT NOTES COMPUT SC, V13661, P38, DOI 10.1007/978-3-031-19769-7_3
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Liang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P164, DOI 10.1007/978-3-030-58607-2_10
   Lin H., 2021, IJCAI, P837
   Lin H., 2022, P IEEECVF C COMPUTER, P19628
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu XL, 2019, IEEE T PATTERN ANAL, V41, P1862, DOI 10.1109/TPAMI.2019.2899857
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Ma ZH, 2021, AAAI CONF ARTIF INTE, V35, P2319
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Marana AN, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P354, DOI 10.1109/SIBGRA.1998.722773
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sajid U, 2020, IEEE T CIRC SYST VID, V30, P3499, DOI 10.1109/TCSVT.2020.2978717
   Sam DB, 2019, AAAI CONF ARTIF INTE, P8868
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551
   Shi MJ, 2019, PROC CVPR IEEE, P7271, DOI 10.1109/CVPR.2019.00745
   Shi ZL, 2019, IEEE I CONF COMP VIS, P4199, DOI 10.1109/ICCV.2019.00430
   Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564
   Sindagi Vishwanath A., 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P212, DOI 10.1007/978-3-030-58621-8_13
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2019, IEEE I CONF COMP VIS, P1002, DOI 10.1109/ICCV.2019.00109
   Song Q., 2021, Rethinking counting and localization in crowds: A purely point-based framework, P3365
   Song QY, 2021, AAAI CONF ARTIF INTE, V35, P2576
   Sun G., 2021, ARXIV E PRINTS ARXIV
   Tian Y, 2021, Arxiv, DOI [arXiv:2109.14483, DOI 10.48550/ARXIV.2109.14483]
   Tian YK, 2020, IEEE T IMAGE PROCESS, V29, P2714, DOI 10.1109/TIP.2019.2952083
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Vaswani A, 2017, ADV NEUR IN, V30
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   von Borstel M, 2016, LECT NOTES COMPUT SC, V9905, P365, DOI 10.1007/978-3-319-46448-0_22
   Wan J., 2020, P ADV NEUR INF PROC, P3386
   Wan J, 2021, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR46437.2021.00201
   Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416
   Wang B., 2020, Advances in Neural Information Processing Systems, V33, P1595, DOI DOI 10.48550/ARXIV.2009.13077
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Xie JY, 2022, APPL INTELL, V52, P12191, DOI 10.1007/s10489-021-03030-w
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Xiong HP, 2019, IEEE I CONF COMP VIS, P8361, DOI 10.1109/ICCV.2019.00845
   Xiyang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P241, DOI 10.1007/978-3-030-58586-0_15
   Xu CF, 2022, INT J COMPUT VISION, V130, P405, DOI 10.1007/s11263-021-01542-z
   Xu YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15550, DOI 10.1109/ICCV48922.2021.01528
   Yan Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P242, DOI 10.1007/978-3-030-58555-6_15
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Yang YF, 2020, PROC CVPR IEEE, P4373, DOI 10.1109/CVPR42600.2020.00443
   Yifan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P1, DOI 10.1007/978-3-030-58598-3_1
   Zhang SH, 2019, J VIS COMMUN IMAGE R, V62, P166, DOI 10.1016/j.jvcir.2019.05.003
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 76
TC 6
Z9 6
U1 2
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103853
DI 10.1016/j.jvcir.2023.103853
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J9GC6
UT WOS:001012626500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, RY
   Zheng, YY
   Wang, XM
   Li, D
AF Xu, Ruyu
   Zheng, Yueyang
   Wang, Xiaoming
   Li, Dong
TI Person re-identification based on improved attention mechanism and
   global pooling method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Feature representation; Attention mechanism;
   Global pooling; Spatial transform
ID NETWORK
AB Deep network has become a new favorite for person re-identification (Re-ID), whose research focus is how to effectively extract the discriminative feature representation for pedestrians. In the paper, we propose a novel Re -ID network named as improved ReIDNet (iReIDNet), which can effectively extract the local and global multi -granular feature representations of pedestrians by a well-designed spatial feature transform and coordinate attention (SFTCA) mechanism together with improved global pooling (IGP) method. SFTCA utilizes channel adaptability and spatial location to infer a 2D attention map and can help iReIDNet to focus on the salient in-formation contained in pedestrian images. IGP makes iReIDNet capture more effectively the global information of the whole human body. Besides, to boost the recognition accuracy, we develop a weighted joint loss to guide the training of iReIDNet. Comprehensive experiments demonstrate the availability and superiority of iReIDNet over other Re-ID methods. The code is available at https://github.com/XuRuyu66/ iReIDNet.
C1 [Xu, Ruyu; Wang, Xiaoming; Li, Dong] Xihua Univ, Sch Comp & Software Engineer, Chengdu 610039, Sichuan, Peoples R China.
   [Zheng, Yueyang] Kyungil Univ, Dept Convergence Contents & Media Design, Gyongsan 38428, Gyeongsangbug D, South Korea.
C3 Xihua University; Kyungil University
RP Wang, XM (corresponding author), Xihua Univ, Sch Comp & Software Engineer, Chengdu 610039, Sichuan, Peoples R China.
EM wxmwm@aliyun.com
FU Natural Science Foundation of Sichuan Province, China [2022NSFSC0533]
FX This work was supported in part by the Natural Science Foundation of
   Sichuan Province, China No. 2022NSFSC0533.
CR Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Chattopadhyay A, 2021, DET ROB PRIV ENH DEI
   Chen F, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106939
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Goyal D, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9660071
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kwasniewska A, 2017, C HUM SYST INTERACT, P41, DOI 10.1109/HSI.2017.8004993
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mathur Neha, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P129, DOI 10.1109/ICETCE48199.2020.9091747
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Park H, 2020, AAAI CONF ARTIF INTE, V34, P11839
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tan FG, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE 2017), P184, DOI 10.1109/ICSCSE.2017.53
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang T, 2022, AAAI CONF ARTIF INTE, P2540
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wei W., 2021, J VISUAL COMMUNICATI
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang J, 2022, INT CONF ACOUST SPEE, P2709, DOI 10.1109/ICASSP43922.2022.9747117
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang X, 2018, Arxiv, DOI arXiv:1711.08184
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 57
TC 3
Z9 3
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103849
DI 10.1016/j.jvcir.2023.103849
EA MAY 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I4AF0
UT WOS:001002213700001
DA 2024-07-18
ER

PT J
AU Tang, YG
   Zhang, X
   Zhang, XG
AF Tang, Yinggan
   Zhang, Xiang
   Zhang, Xuguang
TI An efficient lightweight network for single image super-resolution*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Sparse; Efficiency; Lightweight; Self-attention
ID SUPERRESOLUTION; ACCURATE
AB The outstanding performance of convolutional neural networks (CNNs) shown in single image super-resolution (SISR) strongly depends on network's depth, which hampers its application in low-power computing devices. In this paper, a lightweight and efficient network (LESR) is proposed for SISR by constructing the shallow feature extraction block (SFBlock), the cascaded sparse mask blocks (SMBlocks) and the feature fusion block (FFBlock). The SFBlock efficiently extracts global informative features from the original low resolution image using sparse self-attention, SMBlock skips the redundant computation in extracted features, and more meaningful information is distilled for the sequential reconstruction block by the FFBlock. In addition, a recently proposed activation function called ACON-C is used to replace the ReLU function to ease the training difficulty. Extensive experiments show that our proposed network performs better than most advanced lightweight SISR algorithms with comparable parameters and less FLOPs on benchmark database for x2/3/4 SISR.
C1 [Tang, Yinggan] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Tang, Yinggan; Zhang, Xiang] Yanshan Univ, Key Lab Intelligent Rehabil & Neuromodulat Hebei P, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zhang, Xuguang] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Yanshan University; Yanshan University; Hangzhou Dianzi University
RP Tang, YG (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM ygtang@ysu.edu.cn; zhangxiang726@foxmail.com; zhangxg@hdu.edu.cn
OI Yinggan, Tang/0000-0002-7440-1742
FU Hebei Innovation Capability Improve-ment Plan Project [22567619H]
FX Acknowledgment This work was supported by Hebei Innovation Capability
   Improve-ment Plan Project (22567619H) .
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Andoni A, 2015, ADV NEUR IN, V28
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen BH, 2022, LECT NOTES COMPUT SC, V13679, P254, DOI 10.1007/978-3-031-19800-7_15
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kong XT, 2021, PROC CVPR IEEE, P12011, DOI 10.1109/CVPR46437.2021.01184
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Ma NN, 2021, PROC CVPR IEEE, P8028, DOI 10.1109/CVPR46437.2021.00794
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Terasawa K, 2007, LECT NOTES COMPUT SC, V4619, P27
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wonkyung Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P465, DOI 10.1007/978-3-030-58586-0_28
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang Y., 2022, PROC INT C LEARN REP, P1
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 40
TC 5
Z9 5
U1 5
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103834
DI 10.1016/j.jvcir.2023.103834
EA MAY 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J0DH5
UT WOS:001006390300001
DA 2024-07-18
ER

PT J
AU Zago, JG
   Antonelo, EA
   Baldissera, FL
   Saad, RT
AF Zago, Joao G.
   Antonelo, Eric A.
   Baldissera, Fabio L.
   Saad, Rodrigo T.
TI Benford?s law: What does it say on adversarial images?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Benford?s law; Adversarial attacks; Convolutional neural networks;
   Adversarial detection
AB Convolutional neural networks (CNNs) are fragile to small perturbations in the input images. These networks are thus prone to malicious attacks that perturb the inputs to force a misclassification. Such slightly manipulated images aimed at deceiving the classifier are known as adversarial images. In this work, we investigate statistical differences between natural images and adversarial ones. More precisely, we show that employing a proper image transformation for a class of adversarial attacks, the distribution of the leading digit of the pixels in adversarial images deviates from Benford's law. The stronger the attack, the more distant the resulting distribution is from Benford's law. Our analysis provides a detailed investigation of this new approach that can serve as a basis for alternative adversarial example detection methods that do not need to modify the original CNN classifier neither work on the high-dimensional pixel space for features to defend against attacks.
C1 [Zago, Joao G.; Antonelo, Eric A.; Baldissera, Fabio L.; Saad, Rodrigo T.] Univ Fed Santa Catarina, Dept Automat & Syst, Florianopolis, SC, Brazil.
C3 Universidade Federal de Santa Catarina (UFSC)
RP Zago, JG (corresponding author), Univ Fed Santa Catarina, Dept Automat & Syst, Florianopolis, SC, Brazil.
EM joao.zago@posgrad.ufsc.br; eric.antonelo@ufsc.br
FU CAPES-The Brazil-ian Agency for Higher Education [001]
FX Acknowledgments This work has been partially supported by CAPES-The
   Brazil-ian Agency for Higher Education (Finance Code 001) , project
   PrInt CAPES-UFSC ?Automation 4.0?.
CR Bengio S, 2016, ARXIV
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carlini Nicholas, 2017, ACM WORKSH ART INT S, P3
   Chou E, 2020, 2020 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2020), P48, DOI 10.1109/SPW50608.2020.00025
   Deckert J, 2011, POLIT ANAL, V19, P245, DOI 10.1093/pan/mpr014
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Grosse K, 2017, Arxiv, DOI arXiv:1702.06280
   Huang XW, 2017, LECT NOTES COMPUT SC, V10426, P3, DOI 10.1007/978-3-319-63387-9_1
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jolion JM, 2001, J MATH IMAGING VIS, V14, P73, DOI 10.1023/A:1008363415314
   Katz G, 2017, LECT NOTES COMPUT SC, V10426, P97, DOI 10.1007/978-3-319-63387-9_5
   Khoury M, 2018, Arxiv, DOI arXiv:1811.00525
   Kingma D, 2014, C LEARNING REPRESENT, P12
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li YQ, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103037
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Madry A., 2018, ARXIV
   Mazumdar A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103417
   Metzen J.H., 2017, 5 INT C LEARN REPR I
   Milani S, 2016, INT CONF ACOUST SPEE, P2054, DOI 10.1109/ICASSP.2016.7472038
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Perez-Gonzalez F., 2007, 2007 IEEE INT C IM P, V1, pI
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Y, 2018, Arxiv, DOI arXiv:1710.10766
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tian Jinyu, 2021, AAAI
   Tödter KH, 2009, GER ECON REV, V10, P339
   Tramer F., 2017, INT C LEARNING REPRE
   Wang ZM, 2019, NEURAL PROCESS LETT, V50, P2731, DOI 10.1007/s11063-019-10058-0
   Yang PYD, 2020, AAAI CONF ARTIF INTE, V34, P6639
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
NR 34
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103818
DI 10.1016/j.jvcir.2023.103818
EA APR 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F1IG1
UT WOS:000979946300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xing, HQ
   Yang, JY
   Xiao, Y
AF Xing, Huiqin
   Yang, Jianyu
   Xiao, Yang
TI Learning dynamic relationship between joints for 3D hand pose estimation
   from single depth map
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand pose estimation; Dynamic anchor; Hand gesture; Depth map
AB 3D hand pose estimation from a single depth map is an essential topic in computer vision. Most existing methods are devoted to designing a model to capture more spatial information or designing loss functions based on prior knowledge to constrain the estimated pose with prior spatial information. In this work, we focus on constraining the estimation process with spatial information adaptively by learning the mutual position relationship between joint pairs. Specifically, we propose a dynamic relationship network (DRN) with dynamic anchors. The preset fixed anchors are employed to estimate the position of each joint initially. Then, each joint is considered a dynamic anchor, which plays the role of a dynamic regressor to adjust the initially estimated position of each joint. The final estimation of each joint is the weighted sum of the results from all the dynamic anchors. Extensive experiments on benchmarks demonstrate that our method provides competitive results compared with state-of-the-arts.
C1 [Xing, Huiqin; Yang, Jianyu] Soochow Univ, Sch Rail Transportat, 8 Jixue Rd, Suzhou 215131, Jiangsu, Peoples R China.
   [Xiao, Yang] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430000, Hubei, Peoples R China.
C3 Soochow University - China; Huazhong University of Science & Technology
RP Yang, JY (corresponding author), Soochow Univ, Sch Rail Transportat, 8 Jixue Rd, Suzhou 215131, Jiangsu, Peoples R China.
EM jyyang@suda.edu.cn
RI Liu, min/JXW-8493-2024; wang, yingying/JSK-6741-2023; wen,
   liang/JNR-7720-2023; Wang, Ling/KBA-9814-2024; LU, CX/KFB-9510-2024;
   Liu, Liu/JXM-8208-2024; Wang, Xiaojun/JUU-9683-2023; Zhang,
   Wenli/JXL-4317-2024; XIE, WANYING/JNR-9259-2023; Wang,
   Ling/AGR-4917-2022
OI Wang, Ling/0000-0003-0272-2974; Wang, Ling/0000-0003-0272-2974
FU National Natural Science Foun-dation of China [61773272, 62271221]; Six
   Talent Peaks Project of Jiangsu Province, China [XYDXX-053]
FX Acknowledgments This work was supported by the National Natural Science
   Foun-dation of China (NSFC No. 61773272, 62271221) , and the Six Talent
   Peaks Project of Jiangsu Province, China (No. XYDXX-053) .
CR Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen FC, 2013, J ROBOT, V2013, DOI 10.1155/2013/910961
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Cheng J, 2022, AAAI CONF ARTIF INTE, P419
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng X., 2017, ARXIV
   Deng XM, 2023, IEEE T PATTERN ANAL, V45, P932, DOI 10.1109/TPAMI.2022.3159725
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Ge LH, 2018, LECT NOTES COMPUT SC, V11217, P489, DOI 10.1007/978-3-030-01261-8_29
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Guo HK, 2017, IEEE IMAGE PROC, P4512, DOI 10.1109/ICIP.2017.8297136
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR), P103, DOI 10.1109/RCAR.2017.8311843
   Huang WT, 2020, AAAI CONF ARTIF INTE, V34, P11061
   Huang Y, 2021, PATTERN RECOGN LETT, V144, P97, DOI 10.1016/j.patrec.2020.11.011
   Kingma D. P., 2015, INT C LEARNING REPRE
   Li SL, 2019, PROC CVPR IEEE, P11919, DOI 10.1109/CVPR.2019.01220
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oberweger M., 2015, COMP VIS WINT WORKSH, P21
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Pan TH, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103461
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Ren P., 2019, BMVC, P112
   Shao ZP, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103529
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Wang GJ, 2018, J VIS COMMUN IMAGE R, V55, P404, DOI 10.1016/j.jvcir.2018.04.005
   Wang K., 2016, Proceedings of the 24th ACM international conference on Multimedia, P1227
   Wu Y, 2000, PROC CVPR IEEE, P88, DOI 10.1109/CVPR.2000.854749
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xiong F, 2019, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2019.00088
   Xu HR, 2016, IEEE IMAGE PROC, P644, DOI 10.1109/ICIP.2016.7532436
   Yang JY, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103263
   Yang JY, 2021, IEEE T MULTIMEDIA, V23, P883, DOI 10.1109/TMM.2020.2990082
   Yang JY, 2017, IEEE INT CON MULTI, P631, DOI 10.1109/ICME.2017.8019348
   Yang JY, 2016, J VIS COMMUN IMAGE R, V38, P627, DOI 10.1016/j.jvcir.2016.04.010
   Yang JY, 2016, NEUROCOMPUTING, V190, P70, DOI 10.1016/j.neucom.2016.01.032
   Yuan SX, 2018, PROC CVPR IEEE, P2636, DOI 10.1109/CVPR.2018.00279
   Yuan SX, 2017, PROC CVPR IEEE, P2605, DOI 10.1109/CVPR.2017.279
   Zhu C, 2021, IEEE-CAA J AUTOMATIC, V8, P1600, DOI 10.1109/JAS.2019.1911534
NR 47
TC 0
Z9 0
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103803
DI 10.1016/j.jvcir.2023.103803
EA MAR 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0A3EM
UT WOS:000951709200001
DA 2024-07-18
ER

PT J
AU Wei, X
   Wei, Y
   Lu, XB
AF Wei, Xuan
   Wei, Yun
   Lu, Xiaobo
TI HD-YOLO: Using radius-aware loss function for head detection in top-view
   fisheye images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fisheye images; Head detection; Radius-aware Loss Function; Deep
   learning
ID SALIENT OBJECT DETECTION
AB People detection is commonly used in computer vision systems, particularly for video surveillance and passenger flow statistics. Unlike standard cameras, fisheye cameras offer a large field of view and reduce occlusions when mounted overhead. However, due to the orientation variation of people in fisheye images, head detection models suffer from severe distortion when applied to fisheye images captured by top-view fisheye cameras. This work develops an end-to-end head detection method named HD-YOLO against complex situations in top-view fisheye images. The radius-aware loss function is designed to make HD-YOLO adapt to the impact of fisheye distortion, and the channel attention module is added to the model. We have also created new fisheye-image datasets for evaluation. Experiments showed that HD-YOLO outperforms other baseline methods on public and self-built datasets.
C1 [Wei, Xuan; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Wei, Xuan; Lu, Xiaobo] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Wei, Yun] Beijing Mass Transit Railway Operat Corp Ltd, Beijing 100044, Peoples R China.
C3 Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM xblu2013@126.com
FU National Key R&D Program of China; Major scientific research projects of
   China Railway Group;  [2020YFB1600700];  [K2019G046]
FX Acknowledgments This work is supported by National Key R&D Program of
   China under Grant 2020YFB1600700 and Major scientific research projects
   of China Railway Group under Grant K2019G046.
CR Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chiang AT, 2014, IEEE INT CON MULTI
   Chiang SH, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104069
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demiroz B. E., 2012, 2012_5th_International Symposium_on_Communications,_Control_and_Signal_Processing, P1
   Deng LY, 2020, IEEE T INTELL TRANSP, V21, P4350, DOI 10.1109/TITS.2019.2939832
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Duan ZH, 2020, IEEE COMPUT SOC CONF, P2700, DOI 10.1109/CVPRW50498.2020.00326
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krams O, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Li JY, 2020, PROCEEDINGS OF IDC 2020, P508, DOI 10.1145/3392063.3394422
   Li SY, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI [10.1109/avss.2019.8909877, 10.1109/IRCE.2019.00008]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma GX, 2021, IEEE T IMAGE PROCESS, V30, P4238, DOI 10.1109/TIP.2021.3068649
   Ma GX, 2020, IEEE T VIS COMPUT GR, V26, P3535, DOI 10.1109/TVCG.2020.3023636
   Ma GX, 2020, IEEE T MULTIMEDIA, V22, P324, DOI 10.1109/TMM.2019.2929943
   Mei YQ, 2020, Arxiv, DOI arXiv:2004.13824
   Meinel L, 2014, I SYMP CONSUM ELECTR, P398
   Qian YQ, 2020, IEEE T MULTIMEDIA, V22, P421, DOI 10.1109/TMM.2019.2929949
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Saito M., 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P435
   Seidel R, 2019, Arxiv, DOI arXiv:1805.08503
   Nguyen VT, 2016, I C INF COMM TECH CO, P840, DOI 10.1109/ICTC.2016.7763311
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang T, 2017, I S INTELL SIG PROC, P719, DOI 10.1109/ISPACS.2017.8266570
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
NR 33
TC 4
Z9 4
U1 17
U2 54
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103715
DI 10.1016/j.jvcir.2022.103715
EA DEC 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7L7EU
UT WOS:000906124900001
DA 2024-07-18
ER

PT J
AU Liang, ZM
   Huang, YP
   Liu, ZW
AF Liang, Zhenming
   Huang, Yingping
   Liu, Zhenwei
TI Efficient graph attentional network for 3D object detection from
   Frustum-based LiDAR point clouds
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D object detection; Multi -sensors fusion; Graph convolutional
   networks; Attention mechanism; Autonomous driving
AB LiDAR-based 3D object detection is important for autonomous driving scene perception, but point clouds produced by LiDAR are irregular and unstructured in nature, and cannot be adopted by the conventional Convolutional Neural Networks (CNN). Recently, Graph Convolutional Networks (GCN) has been proved as an ideal way to handle non-Euclidean structure data, as well as for point cloud processing. However, GCN involves massive computation for searching adjacent nodes, and the heavy computational cost limits its applications in processing large-scale LiDAR point cloud in autonomous driving. In this work, we adopt a frustum-based point cloud-image fusion scheme to reduce the amount of LiDAR point clouds, thus making the GCN-based large-scale LiDAR point clouds feature learning feasible. On this basis, we propose an efficient graph attentional network to accomplish the goal of 3D object detection in autonomous driving, which can learn features from raw LiDAR point cloud directly without any conversions. We evaluate the model on the public KITTI benchmark dataset, the 3D detection mAP is 63.72% on KITTI Cars, Pedestrian and Cyclists, and the inference speed achieves 7.9 fps on a single GPU, which is faster than other methods of the same type.
C1 [Liang, Zhenming; Huang, Yingping; Liu, Zhenwei] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Huang, YP (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
EM huangyingping@usst.edu.cn
FU Shanghai Nature Science Foundation of Shanghai Science and Technology
   Commission, China; National Nature Science Foundation of China; 
   [20ZR1437900];  [61374197]
FX This research was funded by Shanghai Nature Science Foundation of
   Shanghai Science and Technology Commission, China (Grant No.
   20ZR1437900) , and National Nature Science Foundation of China (Grant
   No. 61374197) .
CR Barrera Alejandro, 2020, 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC), DOI 10.1109/ITSC45102.2020.9294293
   Beltrán J, 2018, IEEE INT C INTELL TR, P3517, DOI 10.1109/ITSC.2018.8569311
   Chen C, 2021, IEEE ACCESS, V9, P51710, DOI 10.1109/ACCESS.2021.3070379
   Chen MY, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106237
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   He QD, 2021, Arxiv, DOI arXiv:2006.04043
   Jocher G., 2020, YOLOv5
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li B, 2016, Arxiv, DOI arXiv:1608.07916
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Zarzar J, 2019, Arxiv, DOI [arXiv:1911.12236, 10.48550/arXiv.1911.12236]
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 32
TC 4
Z9 4
U1 4
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103667
DI 10.1016/j.jvcir.2022.103667
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V1KD
UT WOS:000876994600002
DA 2024-07-18
ER

PT J
AU Qiao, T
   Luo, XY
   Yao, HW
   Shi, R
AF Qiao, Tong
   Luo, Xiangyang
   Yao, Hongwei
   Shi, Ran
TI Classifying between computer generated and natural images: An empirical
   study from RAW to JPEG format
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image origin forensics; Imaging procedure; Distribution model;
   Likelihood ratio test
ID INDIVIDUAL CAMERA DEVICE; STATISTICAL-MODEL; GRAPHICS; IDENTIFICATION;
   NETWORKS
AB Computer generated (CG) images have been gradually overspread on the Internet, resulting in difficult discrimination from natural images (NIs) captured by an authentic imaging device. Although some discriminators can deal with NIs in JPEG format, the classification between uncompressed NIs (that are possibly generated in any imaging procedure before compression) and CG ones still remains unknown. Thus, this paper aims to establish multiple discriminators classifying between NIs and CG images. We first describe the main imaging procedure and its intrinsic property, which characterizes the discriminative features for classification. Then, the residual noise (representing intrinsic characteristic) is extracted. Its statistical distribution indeed helps us establish multiple discriminators, consisting of the generalized likelihood ratio test (GLRT) under the framework of hypothesis testing theory. Extensive experiments empirically verify our proposed multiple discriminators outperform many prior arts. Furthermore, the robustness of discriminators is validated with considering some post-processing attacks.
C1 [Qiao, Tong; Yao, Hongwei] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
   [Luo, Xiangyang] Zhengzhou Sci & Technol Inst, State Key Lab Math Engn & Adv Comp, Zhengzhou, Henan, Peoples R China.
   [Shi, Ran] Nanjing Univ Sci & Technol Nanjing, Sch Comp Sci & Engn, Nanjing, Peoples R China.
C3 Hangzhou Dianzi University; PLA Information Engineering University;
   Nanjing University of Science & Technology
RP Luo, XY (corresponding author), Zhengzhou Sci & Technol Inst, State Key Lab Math Engn & Adv Comp, Zhengzhou, Henan, Peoples R China.
EM xiangyangluo@126.com
OI Qiao, Tong/0000-0003-4912-2132; South, Set/0000-0002-3881-3168
FU Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK219909299001-007]; National Natural Science Foundation of China
   [U1804263, 62172435]; Zhongyuan Science and Technology Innovation
   Leading Talent Project of China [214200510019]
FX Acknowledgments This work was supported by the Fundamental Research
   Funds for the Provincial Universities of Zhejiang under grant No.
   GK219909299001-007, the National Natural Science Foundation of China
   (Grant No. U1804263, 62172435) and the Zhongyuan Science and Technology
   Innovation Leading Talent Project of China (Grant No. 214200510019) .
CR [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2013, 2013 21 EUR SIGN PRO
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Barnell Mark, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1228), P1, DOI 10.1007/978-3-030-52249-0_1
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   de Rezende ERS, 2018, SIGNAL PROCESS-IMAGE, V66, P113, DOI 10.1016/j.image.2018.04.006
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Gallagher Andrew C., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562984
   Gloe T., 2010, P SAC 10 2010 ACM S, P1584
   He PS, 2018, IEEE SIGNAL PROC LET, V25, P1369, DOI 10.1109/LSP.2018.2855566
   Holmes O, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2871714
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Huang MY, 2019, J UNIVERS COMPUT SCI, V25, P1151
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Long M, 2019, MULTIMED TOOLS APPL, V78, P489, DOI 10.1007/s11042-017-5101-3
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Mader B, 2017, PERCEPTION, V46, P1062, DOI 10.1177/0301006617713633
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nataraj L., 2019, Electron. Imaging, V5, P1, DOI 10.2352/
   Ng T-T., 2005, ADVENT Technical Report, P205
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Özparlak L, 2011, IEEE T INF FOREN SEC, V6, P1418, DOI 10.1109/TIFS.2011.2162830
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qiao T, 2021, IEEE T DEPEND SECURE, V18, P2736, DOI 10.1109/TDSC.2019.2962672
   Qiao T, 2019, IEEE T MULTIMEDIA, V21, P1077, DOI 10.1109/TMM.2018.2872863
   Qiao T, 2018, IEEE ACCESS, V6, P78038, DOI 10.1109/ACCESS.2018.2884710
   Qiao T, 2018, MULTIMED TOOLS APPL, V77, P1501, DOI 10.1007/s11042-016-4314-1
   Qiao T, 2017, SIGNAL PROCESS-IMAGE, V52, P74, DOI 10.1016/j.image.2016.12.011
   Qiao T, 2015, IEEE IMAGE PROC, P3812, DOI 10.1109/ICIP.2015.7351518
   Qiao T, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0019-7
   Quan WZ, 2018, IEEE T INF FOREN SEC, V13, P2772, DOI 10.1109/TIFS.2018.2834147
   Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P1980, DOI 10.1109/TIP.2014.2310126
   Tian-Tsong Ng, 2005, 13th Annual ACM International Conference on Multimedia, P239
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Weng CC, 2005, IEEE INT SYMP CIRC S, P3801
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Yao Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041296
   Yu IJ, 2017, IEEE IMAGE PROC, P4093, DOI 10.1109/ICIP.2017.8297052
   Zhao YH, 2019, MULTIMED TOOLS APPL, V78, P8247, DOI 10.1007/s11042-018-6809-4
NR 48
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103506
DI 10.1016/j.jvcir.2022.103506
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P5AF
UT WOS:000802020500001
DA 2024-07-18
ER

PT J
AU Peng, F
   Meng, SH
   Long, M
AF Peng, Fei
   Meng, Shao-hua
   Long, Min
TI Presentation attack detection based on two-stream vision transformers
   with self-attention fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Presentation attack detection; Multi-scale retinex with color
   restoration; Vision transformer; Deep learning; Feature fusion
ID FACE; RETINEX
AB Aiming at the performance degradation of the existing presentation attack detection methods due to the illumination variation, a two-stream vision transformers framework (TSViT) based on transfer learning in two complementary spaces is proposed in this paper. The face images of RGB color space and multi-scale retinex with color restoration (MSRCR) space are fed to TSViT to learn the distinguishing features of presentation attack detection. To effectively fuse features from two sources (RGB color space images and MSRCR images), a feature fusion method based on self-attention is built, which can effectively capture the complementarity of two features. Experiments and analysis on Oulu-NPU , CASIA-MFSD , and Replay-Attack databases show that it outperforms most existing methods in intra-database testing and achieves good generalization performance in cross-database testing.
C1 [Peng, Fei; Meng, Shao-hua] Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM eepengf@gmail.com
RI Long, Min/AGW-6059-2022
FU National Natural Science Foundation of China [U1936115,62072055,
   92067104]
FX Acknowledgments This work was supported in part by projects supported by
   National Natural Science Foundation of China (Grant No.
   U1936115,62072055, 92067104) .
CR ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783
   [Anonymous], 2012, 2012 NAT C COMM
   [Anonymous], 2016, IEEE WINT CONF APPL
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chen H., 2019, IEEE Transactions on InformationForensics and Security, V15, P578
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   Dosovitskiy Alexey, 2020, ARXIV201011929
   Esser Patrick, 2020, Taming transformers for high-resolution image synthesis
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   George A., 2020, ARXIV201108019
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kim S, 2014, SENSORS-BASEL, V14, P22471, DOI 10.3390/s141222471
   Lagorio A, 2013, I W BIOMETRIC FORENS
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li H., 2016, IEEE, P1, DOI DOI 10.1109/IPTA.2016.7821027
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67
   Patel K, 2015, INT CONF BIOMETR, P98, DOI 10.1109/ICB.2015.7139082
   Peng DM, 2020, INT CONF ACOUST SPEE, P2942, DOI [10.1109/ICASSP40776.2020.9054115, 10.1109/icassp40776.2020.9054115]
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Raghavendra R, 2014, IEEE IMAGE PROC, P323, DOI 10.1109/ICIP.2014.7025064
   Simonyan K, 2014, ADV NEUR IN, V27
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wang Y., 2020, ARXIV201114503
   Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xiaokang Tu, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P686, DOI 10.1007/978-3-319-70096-0_70
   Yang S., 2020, ARXIV201214214
   Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 41
TC 5
Z9 5
U1 4
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103518
DI 10.1016/j.jvcir.2022.103518
EA APR 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L9NQ
UT WOS:000799607600004
DA 2024-07-18
ER

PT J
AU Chen, L
   Li, CQ
   Li, C
AF Chen, Lei
   Li, Chengqing
   Li, Chao
TI Security measurement of a medical communication scheme based on chaos
   and DNA coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cryptanalysis; Chaotic cryptography; Chosen-plaintext attack; DNA
   coding; DICOM image security; Privacy protection
ID IMAGE ENCRYPTION; SEQUENCE OPERATION; CRYPTANALYSIS; ALGORITHM
AB To encrypt sensitive information existing in a color DICOM images, a medical privacy protection scheme (called as MPPS) based on chaos and DNA coding was proposed by using two coupled chaotic systems to produce cryptographic primitives. Relying on some empirical analyzes and experimental results, the designers of MPPS claimed that it can withstand a chosen-plaintext attack and some other classic attacking models. However, this statement is groundless. In this paper, we investigate the essential properties of MPPS and DNA coding, and we then propose an efficient chosen-plaintext attack to disclose its equivalent secret-key. The attack only needs left ceiling log256(3 -M-& nbsp;N)] + 4 pair of chosen plain-images and the corresponding cipher-images, where M x N and "3 "are the size of the RGB color image and the number of color channels, respectively. In addition, the other claimed superiorities are questioned from the perspective of modern cryptography. Both theoretical and experimental results are presented to support the efficiency of the proposed attack and the other reported security faults. The proposed cryptanalysis results will promote the proper application of DNA encoding to protect multimedia privacy data, especially that in a DICOM image.
C1 [Chen, Lei; Li, Chengqing] Xiangtan Univ, Sch Comp Sci, Xiangtan 411105, Hunan, Peoples R China.
   [Li, Chao] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
C3 Xiangtan University; Hunan University
RP Li, CQ (corresponding author), Xiangtan Univ, Sch Comp Sci, Xiangtan 411105, Hunan, Peoples R China.
EM chengqing@xtu.edu.cn
RI Li, Chengqing/B-9388-2008
OI Li, Chengqing/0000-0002-5385-7644
FU National Natural Science Foun-dation of China [61772447]; China
   Postdoctoral Science Foundation [2019M660511]
FX Acknowledgment This work was supported by the National Natural Science
   Foun-dation of China (no. 61772447) , and the China Postdoctoral Science
   Foundation (no. 2019M660511) .
CR Acharya UR, 2001, IEEE T INF TECHNOL B, V5, P320, DOI 10.1109/4233.966107
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Braich RS, 2002, SCIENCE, V296, P499, DOI 10.1126/science.1069528
   Chen JX, 2022, IEEE T IND INFORM, V18, P2000, DOI 10.1109/TII.2021.3088465
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Gehani A, 2004, LECT NOTES COMPUT SC, V2950, P167
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2018, IEEE T IND ELECTRON, V65, P2557, DOI 10.1109/TIE.2017.2736515
   Leier A, 2000, BIOSYSTEMS, V57, P13, DOI 10.1016/S0303-2647(00)00083-6
   Li CQ, 2022, IEEE T COMPUT, V71, P364, DOI 10.1109/TC.2021.3051387
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   LIPTON RJ, 1995, SCIENCE, V268, P542, DOI 10.1126/science.7725098
   Liu S, 2022, IEEE MULTIMEDIA, V29, P74, DOI 10.1109/MMUL.2021.3114589
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Özkaynak F, 2013, SIG PROCESS COMMUN
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Panwar K, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501037
   Peng YX, 2021, AEU-INT J ELECTRON C, V129, DOI 10.1016/j.aeue.2020.153539
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Wang N, 2019, IEEE T CIRCUITS-I, V66, P4767, DOI 10.1109/TCSI.2019.2933365
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Wen HP, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030246
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Yu F, 2021, INFORM SCIENCES, V554, P145, DOI 10.1016/j.ins.2020.12.037
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zhou LL, 2020, IEEE SYST J, V14, P2508, DOI 10.1109/JSYST.2019.2927495
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 42
TC 52
Z9 52
U1 2
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103424
DI 10.1016/j.jvcir.2021.103424
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200002
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Xiao, DG
   Zhuo, L
   Li, JF
   Li, JZ
AF Xiao, Degui
   Zhuo, Lin
   Li, Jianfang
   Li, Jiazhi
TI Structure-prior deep neural network for lane detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lane marking detection; Deep neural network; Structure-prior
AB Lane detection is an important task of road environment perception for autonomous driving. Deep learning methods based on semantic segmentation have been successfully applied to lane detection, but they require considerable computational cost for high complexity. The lane detection is treated as a particular semantic segmentation task due to the prior structural information of lane markings which have long continuous shape. Most traditional CNN are designed for the representation learning of semantic information, while this prior structural information is not fully exploited. In this paper, we propose a recurrent slice convolution module (called RSCM) to exploit the prior structural information of lane markings. The proposed RSCM is a special recurrent network structure with several slice convolution units (called SCU). The RSCM could obtain stronger semantic representation through the propagation of the prior structural information in SCU. Furthermore, we design a distance loss in consideration of the prior structure of lane markings. The lane detection network can be trained more steadily via the overall loss function formed by combining segmentation loss with the distance loss. The experimental results show the effectiveness of our method. We achieve excellent computation efficiency while keeping decent detection quality on lane detection benchmarks and the computational cost of our method is much lower than the state-of-the-art methods.
C1 [Xiao, Degui; Zhuo, Lin; Li, Jianfang; Li, Jiazhi] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
C3 Hunan University
RP Zhuo, L (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
EM zhuolin@hnu.edu.cn
FU National Natural Science Foundation of China [62172150]; Science and
   Technol-ogy Project of Changsha, China [kq2004012]
FX This work was partly supported by the National Natural Science
   Foundation of China (Grant No. 62172150) and Science and Technol-ogy
   Project of Changsha, China (Grant No. kq2004012) .
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   Borkar A, 2009, IEEE IMAGE PROC, P3261, DOI 10.1109/ICIP.2009.5413980
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen ZP, 2019, IEEE INT VEH SYM, P2563, DOI [10.1109/IVS.2019.8813778, 10.1109/ivs.2019.8813778]
   Cheng HY, 2006, IEEE T INTELL TRANSP, V7, P571, DOI 10.1109/TITS.2006.883940
   Feniche M., 2019, PROC IEEE INT C COMP, DOI 10.1109/ICCSRE.2019.8807727
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2004, IEEE T INTELL TRANSP, V5, P309, DOI 10.1109/TITS.2004.838221
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Kim J, 2017, IEEE COMPUT SOC CONF, P1194, DOI 10.1109/CVPRW.2017.158
   Ko YeongMin, 2020, ABS200206604 CORR
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Liu T., 2020, LANE DETECTION LOW L, P1394, DOI [10.1109/IV47402.2020.9304613, DOI 10.1109/IV47402.2020.9304613]
   Liu Y.-B., 2020, ARXIV200715602
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma C, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P200, DOI 10.1109/WKDD.2010.118
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Neven D, 2018, IEEE INT VEH SYM, P286
   Niu JW, 2016, PATTERN RECOGN, V59, P225, DOI 10.1016/j.patcog.2015.12.010
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Philion J, 2019, PROC CVPR IEEE, P11574, DOI 10.1109/CVPR.2019.01185
   Piao J, 2017, IET IMAGE PROCESS, V11, P1210, DOI 10.1049/iet-ipr.2016.0506
   Pizzati F., 2019, P INT C COMP AID SYS, P95
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Satzoda RK, 2010, IEEE EMBED SYST LETT, V2, P23, DOI 10.1109/LES.2010.2051412
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun T.-Y., 2006, IEEE INTELL TRANSP S, P1168, DOI DOI 10.1109/ITSC.2006.1707380
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TuSimple, 2018, TUSIMPLE BENCHMARK
   Wang Y, 2019, IEEE IMAGE PROC, P1860, DOI [10.1109/icip.2019.8803154, 10.1109/ICIP.2019.8803154]
   Wang Z., 2018, Lanenet: Real-time lane detection networks for autonomous driving
   Xiao DG, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105584
   Xing Y, 2018, IEEE-CAA J AUTOMATIC, V5, P645, DOI 10.1109/JAS.2018.7511063
   Zequn Qin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P276, DOI 10.1007/978-3-030-58586-0_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zou Q, 2020, IEEE T VEH TECHNOL, V69, P41, DOI 10.1109/TVT.2019.2949603
NR 40
TC 5
Z9 5
U1 3
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103373
DI 10.1016/j.jvcir.2021.103373
EA NOV 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XK3OJ
UT WOS:000727378900001
DA 2024-07-18
ER

PT J
AU Li, YJ
   Tan, BY
   Akaho, S
   Asoh, H
   Ding, SX
AF Li, Yujie
   Tan, Benying
   Akaho, Shotaro
   Asoh, Hideki
   Ding, Shuxue
TI Gaze prediction for first-person videos based on inverse non-negative
   sparse coding with determinant sparse measure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gaze prediction; First-person video; Sparse coding; Determinant measure;
   Inverse
AB Gaze prediction is a significant approach for processing a large amount of incoming visual information of videos. Recent gaze prediction algorithms often employ sparse models with the assumption that every superpixel in the video frames can be represented as linear combinations of a few salient superpixels. However, they are not actuated enough because of the insufficient knowledge that video signals contain a non-negative request. Hence, we develop a novel gaze prediction based on an inverse sparse coding framework with a determinant sparse measure. By introducing this sparse measure, the solutions are non-negative and sparser than conventional sparse constraints. However, the proposed optimization problem becomes nonconvex, which is difficult to solve. To efficiently address the corresponding nonconvex optimization problem, we propose a novel algorithm based on the difference in convex function programming, which can yield the global solutions. Experimental results indicate the improved accuracy of the proposed approach compared with state-of-the-art algorithms.
C1 [Li, Yujie; Tan, Benying; Ding, Shuxue] Guilin Univ Elect Technol, Sch Artificial Intelligence, Guilin 541004, Peoples R China.
   [Li, Yujie; Akaho, Shotaro; Asoh, Hideki] Natl Inst Adv Ind Sci & Technol, Tsukuba, Ibaraki 3058560, Japan.
C3 Guilin University of Electronic Technology; National Institute of
   Advanced Industrial Science & Technology (AIST)
RP Tan, BY (corresponding author), Guilin Univ Elect Technol, Sch Artificial Intelligence, Guilin 541004, Peoples R China.
EM by-tan@guet.edu.cn
RI Li, YuJie/JAC-4451-2023; Tan, Benying/HTT-5225-2023; Li,
   YuJie/HGT-8657-2022; Li, yu/HHZ-5236-2022; yujie, lei/JQW-7495-2023;
   Luo, yujie/KGK-3881-2024; Akaho, Shotaro/N-3401-2016
OI Tan, Benying/0000-0002-9121-8499; Akaho, Shotaro/0000-0002-4623-2718
FU National Natural Science Foundation of China [61903090]; Guangxi
   Postdoctoral Special Foundation, China; Dean Project of Guangxi Wireless
   Broadband Communication and Signal Processing Key Laboratory; Japan
   Society for the Promotion of Science (JSPS) KAKENHI [18K18083];
   Grants-in-Aid for Scientific Research [18K18083] Funding Source: KAKEN
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61903090, the project funded by Guangxi
   Postdoctoral Special Foundation, China, the Dean Project of Guangxi
   Wireless Broadband Communication and Signal Processing Key Laboratory,
   and Japan Society for the Promotion of Science (JSPS) KAKENHI under
   Grant 18K18083.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   An LTH, 2005, ANN OPER RES, V133, P23, DOI 10.1007/s10479-004-5022-1
   [Anonymous], 2014, SIGNAL DETECTION THE, DOI DOI 10.4324/9781315806167/SIGNAL-DETECTION-THEORY-ROC-ANALYSIS-PSYCHOLOGY-DIAGNOSTICSJOHN-SWETS
   Bruckstein AM, 2008, IEEE T INFORM THEORY, V54, P4813, DOI 10.1109/TIT.2008.929920
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Cholakkal H, 2018, IEEE T IMAGE PROCESS, V27, P6064, DOI 10.1109/TIP.2018.2864891
   Cholakkal H, 2016, PROC CVPR IEEE, P5278, DOI 10.1109/CVPR.2016.570
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fischer T, 2018, LECT NOTES COMPUT SC, V11214, P339, DOI 10.1007/978-3-030-01249-6_21
   Gasso G, 2009, IEEE T SIGNAL PROCES, V57, P4686, DOI 10.1109/TSP.2009.2026004
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Huang K., 2007, P 19 INT C NEUR INF, P609, DOI DOI 10.7551/MITPRESS/7503.003.0081
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Huang YF, 2018, LECT NOTES COMPUT SC, V11208, P789, DOI 10.1007/978-3-030-01225-0_46
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kagaya H, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1085, DOI 10.1145/2647868.2654970
   Kocak A., 2014, P BRIT MACH VIS C
   Land MF, 2004, EXP BRAIN RES, V159, P151, DOI 10.1007/s00221-004-1951-9
   Le Thi HA, 2015, EUR J OPER RES, V244, P26, DOI 10.1016/j.ejor.2014.11.031
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399
   Li YJ, 2019, IEEE ACCESS, V7, P12547, DOI 10.1109/ACCESS.2019.2892945
   Li YJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1313, DOI 10.1109/ICASSP.2018.8462640
   Naqvi RA, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030587
   Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101
   Tan BY, 2018, DIGIT SIGNAL PROCESS, V83, P214, DOI 10.1016/j.dsp.2018.08.005
   Tan BY, 2018, IEEE ACCESS, V6, P67301, DOI 10.1109/ACCESS.2018.2879336
   Wang FY, 2010, IEEE T PATTERN ANAL, V32, P875, DOI 10.1109/TPAMI.2009.72
   Yang ZY, 2012, IEEE T NEUR NET LEAR, V23, P1601, DOI 10.1109/TNNLS.2012.2208476
   Zhang MM, 2017, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2017.377
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhang Xucong, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), V41, P162
NR 36
TC 4
Z9 4
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103367
DI 10.1016/j.jvcir.2021.103367
EA NOV 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD4BM
UT WOS:000722656700005
OA hybrid
DA 2024-07-18
ER

PT J
AU Gao, L
   Qi, L
   Guan, L
AF Gao, Lei
   Qi, Lin
   Guan, Ling
TI A discriminant kernel entropy-based framework for feature representation
   learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kernel entropy component analysis; Discriminant analysis; Feature
   representation learning; Iris visualization; Face recognition; Emotion
   recognition; Object recognition
ID PRINCIPAL COMPONENT ANALYSIS; DIMENSIONALITY REDUCTION; PRESERVING
   PROJECTIONS; IMAGE CLASSIFICATION; FACE; LDA; ALGORITHM; FUSION
AB The intelligent multimedia processing community has developed increasing interest in kernel entropy component analysis (KECA) due to its abilities in effective data transformation and dimensionality reduction. However, since only the unsupervised structural information of Renyi entropy from the given data set is utilized, KECA alone is incapable of generating high quality discriminant features. Aiming to develop a new and generic approach for feature representation learning, this paper proposes a discriminant kernel entropy based framework, which integrates KECA and a complete discriminant strategy (consisting of regular and irregular discriminant information), to explore discriminant feature representations from the given data set. The framework is realized and further optimized to generate a more powerful discriminant descriptor for feature representation learning, leading to improved performance. Since the joint utilization of kernel entropy estimation and the complete discriminant strategy is able to reveal the distribution and semantic information of the given data, the proposed framework opens up a new front for discriminant feature representation learning via information theoretic learning (ITL). To demonstrate the generic nature and effectiveness of the proposed framework, experiments are conducted on two different data sources; the visual data source (e.g., University of California Irvine (UCI) database, Olivetti Research Lab (ORL) database, Caltech 256 database) and the audio data source (Ryerson Multimedia Lab (RML) audio emotion database). The results show this framework yields superior performance over other methods on the data sets evaluated for feature representation learning.
C1 [Gao, Lei; Guan, Ling] Ryerson Univ, 350 Victoria St, Toronto, ON M5B 2K3, Canada.
   [Qi, Lin] Zhengzhou Univ, 100 Sci Ave, Zhengzhou 45001, Peoples R China.
C3 Toronto Metropolitan University; Zhengzhou University
RP Gao, L (corresponding author), Ryerson Univ, 350 Victoria St, Toronto, ON M5B 2K3, Canada.
EM iegaolei@gmail.com
CR Ahmed KT, 2020, IEEE ACCESS, V8, P90351, DOI 10.1109/ACCESS.2020.2993721
   Ayesha S, 2020, INFORM FUSION, V59, P44, DOI 10.1016/j.inffus.2020.01.005
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Billings SA, 2002, NEURAL NETWORKS, V15, P263, DOI 10.1016/S0893-6080(01)00142-3
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Bredin H, 2007, INT CONF ACOUST SPEE, P233
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen HR, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3332183
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chen Y., 2012, ADV INF SCI SER SCI, V4, P53
   Debruyne M, 2010, ADV DATA ANAL CLASSI, V4, P151, DOI 10.1007/s11634-010-0068-1
   Dong X, 2019, J VIS COMMUN IMAGE R, V58, P187, DOI 10.1016/j.jvcir.2018.11.030
   Elmadany NE, 2016, IEEE INT SYMP CIRC S, P590, DOI 10.1109/ISCAS.2016.7527309
   Elmadany NED, 2016, INT CONF ACOUST SPEE, P2409, DOI 10.1109/ICASSP.2016.7472109
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337
   Fan Q, 2016, KNOWL-BASED SYST, V105, P107, DOI 10.1016/j.knosys.2016.05.008
   Ficuciello F, 2018, IEEE ROBOT AUTOM LET, V3, P2608, DOI 10.1109/LRA.2018.2818933
   Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46
   Gao L., 2014, P 3 RENEWABLE POWER, P1
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jenssen R, 2010, IEEE T PATTERN ANAL, V32, P847, DOI 10.1109/TPAMI.2009.100
   Kansizoglou I., 2020, IEEE T AFFECT COMPUT
   Kim KI, 2001, IEEE SIGNAL PROC LET, V8, P39, DOI 10.1109/97.895369
   Kreyszig E., 1978, INTRO FUNCTIONAL ANA, V1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li PH, 2017, IEEE T PATTERN ANAL, V39, P803, DOI 10.1109/TPAMI.2016.2560816
   Lin C, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/421671
   Liu Chunfeng., 2013, Mathematical Problems in Engineering, V2013
   Liu QS, 2004, IEEE T CIRC SYST VID, V14, P42, DOI 10.1109/TCSVT.2003.818352
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629
   Luo W, 2018, IEEE T NEUR NET LEAR, V29, P3289, DOI 10.1109/TNNLS.2017.2712793
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Marin D, 2019, IEEE T PATTERN ANAL, V41, P136, DOI 10.1109/TPAMI.2017.2780166
   Meng M, 2020, IEEE T IMAGE PROCESS, V29, P186, DOI 10.1109/TIP.2019.2926774
   Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Shah MA, 2020, INT CONF ACOUST SPEE, P2068, DOI [10.1109/ICASSP40776.2020.9054527, 10.1109/icassp40776.2020.9054527]
   Shen XJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107023
   Shi Y, 2017, EXPERT SYST APPL, V72, P121, DOI 10.1016/j.eswa.2016.12.012
   Shirian A., 2020, ARXIV PREPRINT ARXIV
   Singha A, 2020, MULTIMED TOOLS APPL, V79, P35069, DOI 10.1007/s11042-020-08892-9
   Sohn K, 2011, IEEE I CONF COMP VIS, P2643, DOI 10.1109/ICCV.2011.6126554
   Wan MH, 2019, NEURAL PROCESS LETT, V49, P951, DOI 10.1007/s11063-018-9840-6
   Wang GQ, 2016, NEURAL PROCESS LETT, V43, P1, DOI 10.1007/s11063-014-9398-x
   Wang H, 2018, NEURAL COMPUT APPL, V29, P389, DOI 10.1007/s00521-017-2863-5
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665
   Wang YJ, 2012, IEEE T MULTIMEDIA, V14, P597, DOI 10.1109/TMM.2012.2189550
   Weidmann Joachim, 2012, Linear operators in Hilbert spaces, V68
   Xu XZ, 2019, NEUROCOMPUTING, V328, P5, DOI 10.1016/j.neucom.2018.02.100
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Yang WY, 2014, NEUROCOMPUTING, V137, P185, DOI 10.1016/j.neucom.2013.08.048
   Yang XJ, 2018, MULTIMED TOOLS APPL, V77, P3071, DOI 10.1007/s11042-017-5022-1
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Yu S, 2011, BIOINFORMATICS, V27, P118, DOI 10.1093/bioinformatics/btq569
   Zhang CJ, 2018, IEEE T NEUR NET LEAR, V29, P4479, DOI 10.1109/TNNLS.2017.2748952
   Zhang CJ, 2018, IEEE T CIRC SYST VID, V28, P1719, DOI 10.1109/TCSVT.2017.2694060
   Zhang CJ, 2017, IEEE T CIRC SYST VID, V27, P1691, DOI 10.1109/TCSVT.2016.2527380
   Zhang CJ, 2017, IEEE T NEUR NET LEAR, V28, P1550, DOI 10.1109/TNNLS.2016.2545112
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang SQ, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P281, DOI 10.1145/2911996.2912051
   Zheng Y, 2017, PATTERN RECOGN, V67, P97, DOI 10.1016/j.patcog.2017.01.029
   Zheng YJ, 2006, NEUROCOMPUTING, V69, P1806, DOI 10.1016/j.neucom.2005.08.009
NR 77
TC 2
Z9 2
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103366
DI 10.1016/j.jvcir.2021.103366
EA NOV 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700004
DA 2024-07-18
ER

PT J
AU Leng, CJ
   Ding, QC
   Wu, CD
   Chen, AG
AF Leng, Chuanjiang
   Ding, Qichuan
   Wu, Chengdong
   Chen, Ange
TI Augmented two stream network for robust action recognition adaptive to
   various action videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Two-stream network; Action recognition; Data skew
AB In video-based action recognition, using videos with different frame numbers to train a two-stream network can result in data skew problems. Moreover, extracting the key frames from a video is crucial for improving the training and recognition efficiency of action recognition systems. However, previous works suffer from problems of information loss and optical-flow interference when handling videos with different frame numbers. In this paper, an augmented two-stream network (ATSNet) is proposed to achieve robust action recognition. A frame-number-unified strategy is first incorporated into the temporal stream network to unify the frame numbers of videos. Subsequently, the grayscale statistics of the optical-flow images are extracted to filter out any invalid optical-flow images and produce the dynamic fusion weights for the two branch networks to adapt to different action videos. Experiments conducted on the UCF101 dataset demonstrate that ATSNet outperforms previously defined methods, improving the recognition accuracy by 1.13%.
C1 [Leng, Chuanjiang; Ding, Qichuan; Wu, Chengdong; Chen, Ange] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Peoples R China.
C3 Northeastern University - China
RP Ding, QC; Wu, CD (corresponding author), Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Peoples R China.
EM dingqichuan@mail.neu.edu.cn; wuchengdong@mail.neu.edu.cn
RI Wu, Chengdong/IST-5302-2023; Ding, Qichuan/AAH-8061-2019
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong WK, 2019, AAAI CONF ARTIF INTE, P8247
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Ghadiyaram D, 2019, PROC CVPR IEEE, P12038, DOI 10.1109/CVPR.2019.01232
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HE, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102925
   Jiang M, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102846
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Long X, 2018, AAAI CONF ARTIF INTE, P7202
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Oord A., 2016, ARXIV160903499
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Shou Z, 2019, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2019.00136
   Simonyan K, 2014, ADV NEUR IN, V27
   Sudhakaran S, 2020, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR42600.2020.00118
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L., 2016, P ECCV
   Wang SQ, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102929
   Wang YC, 2020, PROC CVPR IEEE, P508, DOI 10.1109/CVPR42600.2020.00059
   Wei XS, 2018, IEEE T AFFECT COMPUT, V9, P303, DOI 10.1109/TAFFC.2017.2762299
   Xiao JH, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102722
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhang HY, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102942
   Zhang XY, 2019, AAAI CONF ARTIF INTE, P9227
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 36
TC 7
Z9 7
U1 3
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103344
DI 10.1016/j.jvcir.2021.103344
EA OCT 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WP1JM
UT WOS:000712896500001
DA 2024-07-18
ER

PT J
AU Li, ZK
   Liu, XL
   Zhao, Y
   Liu, B
   Huang, Z
   Hong, RC
AF Li, Zhaokun
   Liu, Xueliang
   Zhao, Ye
   Liu, Bo
   Huang, Zhen
   Hong, Richang
TI A lightweight multi-scale aggregated model for detecting aerial images
   captured by UAVs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Aerial images; UAVs; Small-size targets; Mutil-scale aggregation;
   Attention; Model compression
AB Detecting the objects of interesting from aerial images captured by UAVs is one of the core modules in the UAVbased applications. However, it is very difficult to detection objects from aerial images. The reason is that the scale of objects in the aerial images captured by UAVs varies greatly and needs to meet certain real-time performance in detection. To deal with these challenges, we proposed a lightweight model named DSYolov3. We made the following improvements to the Yolov3 model: 1) multiple scale-aware decision discrimination network to detect objects in different scales, 2) a multi-scale fusion-based channel attention model to exploit the channelwise information complementation, 3) a sparsity-based channel pruning to compress the model. Extensive experimental evaluation has demonstrated the effectiveness and efficiency of our approach. By the proposed approach, we could not only achieve better performance than most existing detectors but also ensure the models practicable on the UAVs.
C1 [Li, Zhaokun; Liu, Xueliang; Zhao, Ye; Hong, Richang] Hefei Univ Technol, Hefei, Peoples R China.
   [Liu, Bo] Auburn Univ, Auburn, AL 36849 USA.
   [Huang, Zhen] Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
C3 Hefei University of Technology; Auburn University System; Auburn
   University; National University of Defense Technology - China
RP Huang, Z (corresponding author), Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
EM lmclizhaokun@gmail.com; liuxueliang1982@gmail.com; zhaoye@hfut.edu.cn;
   boliu@auburn.edu; huangzhen@nudt.edu.cn; hongrc.hfut@gmail.com
FU National Key R&D Program of China [2018AAA0102002]; National Natural
   Science Foundation of China (NSFC) [61976076, 61632007, 61932009,
   61806066]
FX This work was supported in part by the National Key R&D Program of China
   under grant 2018AAA0102002, and in part by the National Natural Science
   Foundation of China (NSFC) under grants 61976076, 61632007, 61932009 and
   61806066.
CR [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bazi Y, 2018, IEEE T GEOSCI REMOTE, V56, P3107, DOI 10.1109/TGRS.2018.2790926
   Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chorowski J, 2015, ADV NEUR IN, V28
   Cracknell AP, 2017, INT J REMOTE SENS, V38, P3054, DOI 10.1080/01431161.2017.1302115
   Dai JF, 2016, ADV NEUR IN, V29
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong RC, 2019, IEEE T GEOSCI REMOTE, V57, P8534, DOI 10.1109/TGRS.2019.2921396
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han S, 2015, P ADV NEUR INF PROC, V2015, P1135
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hubara I, 2018, J MACH LEARN RES, V18
   Jaderberg M., 2014, CORR
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin R, 2020, IEEE GEOSCI REMOTE S, V17, P839, DOI 10.1109/LGRS.2019.2936173
   Kellenberger B, 2019, IEEE T GEOSCI REMOTE, V57, P9524, DOI 10.1109/TGRS.2019.2927393
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li Q., 2018, AAAI, V32, DOI [https://doi.org/10.1609/aaai.v32i1.11604, DOI 10.1109/IFETC.2018.8583886]
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mnih V, 2014, ADV NEUR IN, V27
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Priya Goyal, 2017, IEEE T PATTERN ANAL, P2980
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roberge V, 2013, IEEE T IND INFORM, V9, P132, DOI 10.1109/TII.2012.2198665
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Tang ZY, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abbf9e
   Tonsen M, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P139, DOI 10.1145/2857491.2857520
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang F, 2019, IEEE I CONF COMP VIS, P8310, DOI 10.1109/ICCV.2019.00840
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yang Z, 2019, IEEE T GEOSCI REMOTE, V57, P8445, DOI 10.1109/TGRS.2019.2921111
   Ye Jianbo, 2018, P INT C LEARN REPR
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang CH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P565, DOI [10.1145/3394171.3413159, 10.1145/3394171.3413959]
   Zhang PY, 2019, IEEE INT CONF COMP V, P37, DOI 10.1109/ICCVW.2019.00011
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang XD, 2019, IEEE INT CONF COMP V, P118, DOI 10.1109/ICCVW.2019.00020
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu PF, 2019, LECT NOTES COMPUT SC, V11133, P437, DOI 10.1007/978-3-030-11021-5_27
NR 61
TC 17
Z9 19
U1 5
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103058
DI 10.1016/j.jvcir.2021.103058
EA APR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400001
DA 2024-07-18
ER

PT J
AU Zhang, MK
   Xu, L
   Xiong, J
   Zhang, XD
AF Zhang, Mingke
   Xu, Long
   Xiong, Jing
   Zhang, Xuande
TI Correlation filter via random-projection based CNNs features combination
   for visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Correlation filter; Deep features; Random-projection
ID OBJECT TRACKING
AB Object tracking based on the Convolutional Neural Networks (CNNs) with multiple feature correlation filter (CF) has become one of the best object tracking frameworks. In this paper, we propose a novel approach of CNNs based CF, which combines deep features from CNNs into low-dimensional features. To achieve the dimensionality reduction, random-projection is used due to its data-independence and superior computational efficiency over other widely used. In our proposed approach, the spectral graph theory is applied to generate a random projection matrix. This method bypasses the time-consuming Gram-Schmidt orthogonalization, where the dimension of the feature is high. The combined features have very low dimensions, less than one tenth of the dimensions of the original deep features from CNNs, offering an improvement of tracking speed and without loss of performance simultaneously. Extensive experiments are conducted on large-scale benchmark datasets. The results demonstrate that the proposed algorithm outperforms the state-of-the-art methods.
C1 [Zhang, Mingke; Xiong, Jing; Zhang, Xuande] Shaanxi Univ Sci & Technol, Sch Elect Informat & Artificial Intelligence, Xian 710021, Shaanxi, Peoples R China.
   [Xu, Long] Chinese Acad Sci, Natl Astron Observ, Key Lab Solar Act, Beijing 100101, Peoples R China.
C3 Shaanxi University of Science & Technology; Chinese Academy of Sciences;
   National Astronomical Observatory, CAS
RP Zhang, XD (corresponding author), Shaanxi Univ Sci & Technol, Sch Elect Informat & Artificial Intelligence, Xian 710021, Shaanxi, Peoples R China.
EM zhangxuande@sust.edu.cn
FU National Natural Science Foundation of China [61871260]
FX This work was supported by National Natural Science Foundation of China
   Under Grant No. 61871260. The authors also would like to thank the
   reviewers for their valuable suggestions.
CR Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Brouwer AE, 2012, UNIVERSITEXT, P1, DOI 10.1007/978-1-4614-1939-6
   Danelljan Martin, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P117, DOI 10.1007/978-3-319-19665-7_10
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Du Q, 2010, INT GEOSCI REMOTE SE, P1277, DOI 10.1109/IGARSS.2010.5653584
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, INFORM SCIENCES, V320, P395, DOI 10.1016/j.ins.2015.03.032
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu QK, 2017, LECT NOTES COMPUT SC, V10666, P316, DOI 10.1007/978-3-319-71607-7_28
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Menon V, 2016, IEEE GEOSCI REMOTE S, V13, P1275, DOI 10.1109/LGRS.2016.2581172
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Qi YW, 2020, IEEE T SYST MAN CY-S, V50, P1442, DOI 10.1109/TSMC.2018.2801284
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sui Y, 2019, INT J COMPUT VISION, V127, P1084, DOI 10.1007/s11263-019-01156-6
   Takiguchi T, 2010, INT CONF ACOUST SPEE, P2150, DOI 10.1109/ICASSP.2010.5495595
   Wang J., 2012, Geometric structure of high-dimensional data and dimensionality reduction
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang X, 2019, IEEE T CYBERNETICS, V49, P146, DOI 10.1109/TCYB.2017.2768570
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu JP, 2020, IEEE T CYBERNETICS, V50, P2536, DOI 10.1109/TCYB.2019.2901250
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
NR 40
TC 4
Z9 4
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103082
DI 10.1016/j.jvcir.2021.103082
EA MAR 2021
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400004
DA 2024-07-18
ER

PT J
AU Bum, J
   Whang, JJ
   Choo, H
AF Bum, Junghyun
   Whang, Joyce Jiyoung
   Choo, Hyunseung
TI Sentiment-based sub-event segmentation and key photo selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Personal photo collection; Event segmentation; Key photo selection;
   Summarization; Sentiment analysis
ID CLASSIFICATION
AB The number of people collecting photos has surged owing to social media and cloud services in recent years. A typical approach to summarize a photo collection is dividing it into events and selecting key photos from each event. Despite the fact that a certain event comprises several sub-events, few studies have proposed sub event segmentation. We propose the sentiment analysis-based photo summarization (SAPS) method, which automatically summarizes personal photo collections by utilizing metadata and visual sentiment features. For this purpose, we first cluster events using metadata of photos and then calculate the novelty scores to determine the sub-event boundaries. Next, we summarize the photo collections using a ranking algorithm that measures sentiment, emotion, and aesthetics. We evaluate the proposed method by applying it to the photo collections of six participants consisting of 5,480 photos in total. We observe that our sub-event segmentation based on sentiment features outperforms the existing baseline methods. Furthermore, the proposed method is also more effective in finding sub-event boundaries and key photos, because it focuses on detailed sentiment features instead of general content features.
C1 [Bum, Junghyun; Choo, Hyunseung] Sungkyunkwan Univ SKKU, Coll Comp, Suwon, South Korea.
   [Whang, Joyce Jiyoung] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
C3 Sungkyunkwan University (SKKU); Korea Advanced Institute of Science &
   Technology (KAIST)
RP Choo, H (corresponding author), Sungkyunkwan Univ SKKU, Coll Comp, Suwon, South Korea.; Whang, JJ (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
EM bumjh@skku.edu; jjwhang@kaist.ac.kr; choo@skku.edu
FU ICT Creative Consilience program [IITP-2020-2051-001]; G-ITRC
   [IITP-2019-2015-0-00742]; Basic Science Research Program
   [2019R1C1C1008956]; Engineering Research Center Program - MSIT, South
   Korea [NRF-2018R1A5A1059921]
FX This work was supported by the G-ITRC (IITP-2019-2015-0-00742), the ICT
   Creative Consilience program(IITP-2020-2051-001), the Basic Science
   Research Program (2019R1C1C1008956), and the Engineering Research Center
   Program (NRF-2018R1A5A1059921) funded by the MSIT, South Korea.
CR Aakur S.N., 2019, IEEE C COMP VIS PATT
   Ahmad K, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3306240
   [Anonymous], 2017, REAL TIME CONVOLUTIO
   Bacha S, 2016, J VIS COMMUN IMAGE R, V40, P546, DOI 10.1016/j.jvcir.2016.07.021
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Carrington D., 2020, How many photos will be taken in 2020?
   Ceron A, 2015, INT J PRESS/POLIT, V20, P339, DOI 10.1177/1940161215572634
   Ceroni A, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P187, DOI 10.1145/2671188.2749372
   Chollet F, 2015, KERAS
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   del Molino AG, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P10, DOI 10.1145/3240508.3240624
   Dimiccoli M, 2017, COMPUT VIS IMAGE UND, V155, P55, DOI 10.1016/j.cviu.2016.10.005
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   Gozali JP, 2012, IEEE INT CONF MULTI, P25, DOI 10.1109/ICMEW.2012.12
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiajie Tang, 2019, 2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS). Proceedings, P169, DOI 10.1109/ICVRIS.2019.00049
   Kalliatakis G., 2017, Keras-VGG16-Places365
   Kim J, 2016, TRANSPORT RES REC, P108, DOI 10.3141/2595-12
   Kuzovkin D, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3333612
   Li Y, 2019, LECT NOTES COMPUT SC, V11448, P128, DOI 10.1007/978-3-030-18590-9_9
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Liu X, 2019, J VIS COMMUN IMAGE R, V58, P576, DOI 10.1016/j.jvcir.2018.12.032
   Long Mai, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P91, DOI 10.1109/ISM.2011.23
   Lonn S, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.009
   Mei T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1757, DOI 10.1109/ICME.2006.262891
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Nolasco D, 2019, FUTURE GENER COMP SY, V93, P290, DOI 10.1016/j.future.2018.09.008
   Pigeau A, 2017, MULTIMED TOOLS APPL, V76, P9713, DOI 10.1007/s11042-016-3576-y
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   Shen X, 2016, MULTIMED TOOLS APPL, V75, P2527, DOI 10.1007/s11042-015-2658-6
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114
   Vonikakis V, 2017, IEEE T MULTIMEDIA, V19, P2609, DOI 10.1109/TMM.2017.2699859
   Walber T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2065, DOI 10.1145/2556288.2557025
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   Zhang LY, 2016, MULTIMED TOOLS APPL, V75, P9295, DOI 10.1007/s11042-016-3346-x
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 40
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102973
DI 10.1016/j.jvcir.2020.102973
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OM
UT WOS:000613151000002
DA 2024-07-18
ER

PT J
AU Chaitanya, BSNV
   Mukherjee, S
AF Chaitanya, B. S. N., V
   Mukherjee, Snehasis
TI Single image dehazing using improved cycleGAN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CycleGAN; Cyclic consistency loss; AOD-NET; Single image dehazing; SSIM
   loss
AB Haze is an aggregation of very fine, widely dispersed, solid and/or liquid particles suspended in the atmosphere. In this paper, we propose an end-to-end network for single image dehazing, which enhances the CycleGAN model by introducing a transformer architecture within the generator, which is specific for haze removal. The proposed model is trained in an unpaired fashion with clear and hazy images altogether and does not require pairs of hazy and corresponding ground-truth clear images. Furthermore, the proposed model does not depend on estimating the parameters of the atmospheric scattering model. Rather, it uses a K-estimation module as the generator's transformer for complete end-to-end modeling. The feature transformer introduced in the proposed generator model transforms the encoded features into desired feature space and then feeds them into the CycleGAN decoder to create a clear image. In the proposed model we further modified the cycle consistency loss to include the SSIM loss along with pixel-wise mean loss to produce a new loss function specific for the reconstruction task, which enhances the performance of the proposed model. The model performs well even on the high-resolution images provided in the NTIRE 2019 challenge dataset for single image dehazing. Further, we perform experiments on NYU-Depth and reside beta datasets. Results of our experiments show the efficacy of the proposed approach compared to the state-of-the-art in removing the haze from the input image.
C1 [Chaitanya, B. S. N., V] Indian Inst Informat Technol, Sri City, India.
   [Mukherjee, Snehasis] Shiv Nadar Univ, Greater Noida, India.
C3 Shiv Nadar University
RP Mukherjee, S (corresponding author), Shiv Nadar Univ, Greater Noida, India.
EM viswachaitanya.b16@iiits.in; snehasis.mukherjee@snu.edu.in
FU NVIDIA company, United States
FX The authors wish to thank the NVIDIA company, United States for
   providing a TITAN X GPU card as a research grant, which is used for
   conducting the experiments reported in this paper.
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   [Anonymous], 2018, P IEEE C COMP VIS PA
   Bekaert Philippe, 2010, INT C IM PROC
   Borkar K, 2020, NEUROCOMPUTING, V400, P294, DOI 10.1016/j.neucom.2020.03.027
   Borkar Kushal, 2018, ARXIVE180808610
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai Zixing, 2010, 2010 INT C INT SYST, V1
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen YY, 2019, J VIS COMMUN IMAGE R, V61, P284, DOI 10.1016/j.jvcir.2019.04.008
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hore A., 2010, 2010 20 INT C PATT R
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang Zhiying, 2018, IEEE T POWER SYST, V99, P1
   Kumar H, 2019, IET IMAGE PROCESS, V13, P1931, DOI 10.1049/iet-ipr.2018.5240
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li Boyi, 2017, IEEE I CONF COMP VIS
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu Q, 2018, IEEE T IMAGE PROCESS, V27, P5178, DOI 10.1109/TIP.2018.2849928
   Liu Z., 2018, INT C LEARN REPR
   Mei Kangfu, 2018, AS C COMP VIS
   Morales Peter, 2019, P IEEE C COMP VIS PA
   Mukhopadhyay Sudipta, 2019, ARXIV PREPRINT ARXIV
   Qu Yanyun., 2019, COMPUTER VISION PATT
   Salazar Colores S, 2019, IET IMAGE PROCESS, V13, P2877, DOI 10.1049/iet-ipr.2018.6403
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Swami K., 2018, ARXIV PREPRINT ARXIV
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Timofte Radu, 2019, ARXIV PREPRINT ARXIV
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Xiao J, 2020, NEUROCOMPUTING
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H., 2017, ARXIV PREPRINT ARXIV
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 44
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500010
DA 2024-07-18
ER

PT J
AU Zafari, S
   Murashkina, M
   Eerola, T
   Sampo, J
   Kälviäinen, H
   Haario, H
AF Zafari, Sahar
   Murashkina, Mariia
   Eerola, Tuomas
   Sampo, Jouni
   Kalviainen, Heikki
   Haario, Heikki
TI Resolving overlapping convex objects in silhouette images by concavity
   analysis and Gaussian process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Segmentation; Overlapping objects; Convex objects; Image processing;
   Computer vision; Gaussian process; Kriging; Branch and bound
ID PROCESS REGRESSION; BOLTZMANN MACHINE; CELL-NUCLEI; SEGMENTATION; MODEL;
   SHAPE; EXTRACTION; CYTOPLASM; CONTOUR; POINT
AB This paper introduces a novel method for segmentation of clustered partially overlapping convex objects in silhouette images. The proposed method involves three main steps: pre-processing, contour evidence extraction, and contour estimation. Contour evidence extraction starts by recovering contour segments from a binarized image by detecting concave points. After this the contour segments which belong to the same objects are grouped. The grouping is formulated as a combinatorial optimization problem and solved using the branch and bound algorithm. Finally, the full contours of the objects are estimated by a Gaussian process regression method. The experiments on a challenging dataset consisting of nanoparticles demonstrate that the proposed method outperforms three current state-of-art approaches in overlapping convex objects segmentation. The method relies only on edge information and can be applied to any segmentation problems where the objects are partially overlapping and have a convex shape.
C1 [Zafari, Sahar; Murashkina, Mariia; Eerola, Tuomas; Kalviainen, Heikki] Lappeenranta Lahti Univ Technol LUT, Sch Engn Sci, Comp Vis & Pattern Recognit Lab CVPRL, POB 20, Lappeenranta 53851, Finland.
   [Sampo, Jouni; Haario, Heikki] Lappeenranta Lahti Univ Technol LUT, Math Lab, Sch Engn Sci, POB 20, Lappeenranta 53851, Finland.
C3 Lappeenranta-Lahti University of Technology LUT; Lappeenranta-Lahti
   University of Technology LUT
RP Zafari, S (corresponding author), Lappeenranta Lahti Univ Technol LUT, Sch Engn Sci, Comp Vis & Pattern Recognit Lab CVPRL, POB 20, Lappeenranta 53851, Finland.
EM sahar.zafari@lut.fi
OI Eerola, Tuomas/0000-0003-1352-0999
FU Academy of Finland [313598]; Academy of Finland (AKA) [313598] Funding
   Source: Academy of Finland (AKA)
FX The research was carried out in the Automatic segmentation of
   overlapping objects for cell image analysis (CellVision) project. The
   authors would like to thank Academy of Finland for funding the
   CellVision project (Decision No. 313598).
CR Adams, 2013, INT C MACH LEARN, P1067
   Al-Kofahi Y, 2010, IEEE T BIO-MED ENG, V57, P841, DOI 10.1109/TBME.2009.2035102
   Ali S, 2012, IEEE T MED IMAGING, V31, P1448, DOI 10.1109/TMI.2012.2190089
   Arteta C, 2013, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2013.415
   Askey R., 1978, Appl. Anal., V8, P125
   Bai XZ, 2009, PATTERN RECOGN, V42, P2434, DOI 10.1016/j.patcog.2009.04.003
   Bernardis E, 2010, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2010.5540210
   Bin Samma Ali Salem, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P113, DOI 10.1109/CGIV.2010.25
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang H, 2013, IEEE T MED IMAGING, V32, P670, DOI 10.1109/TMI.2012.2231420
   Chen C, 2013, CYTOM PART A, V83A, P495, DOI 10.1002/cyto.a.22280
   Cheng JR, 2009, IEEE T BIO-MED ENG, V56, P741, DOI 10.1109/TBME.2008.2008635
   Choi S.-S., 2010, Systemics, Cybernetics and Informatic, V8, P43
   Dai JX, 2014, INT CONF SIGN PROCES, P709, DOI 10.1109/ICOSP.2014.7015095
   Danek O, 2009, LECT NOTES COMPUT SC, V5575, P410, DOI 10.1007/978-3-642-02230-2_42
   Erdil E, 2017, INT CONF ACOUST SPEE, P2357, DOI 10.1109/ICASSP.2017.7952578
   Eslami SMA, 2014, INT J COMPUT VISION, V107, P155, DOI 10.1007/s11263-013-0669-1
   Farhan M, 2013, PATTERN RECOGN, V46, P741, DOI 10.1016/j.patcog.2012.09.008
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jeulin Dominique, 2007, P 8 INT S MATH MORPH, P265
   Jung C, 2010, IEEE T BIO-MED ENG, V57, P2600, DOI 10.1109/TBME.2010.2060336
   Kothari S, 2009, I S BIOMED IMAGING, P795, DOI 10.1109/ISBI.2009.5193169
   Kumar S, 2006, PATTERN RECOGN, V39, P1088, DOI 10.1016/j.patcog.2005.11.014
   Law YN, 2011, IEEE T IMAGE PROCESS, V20, P1495, DOI 10.1109/TIP.2010.2095868
   Lou XH, 2012, PROC CVPR IEEE, P1012
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   Mao KZ, 2006, IEEE T BIO-MED ENG, V53, P1153, DOI 10.1109/TBME.2006.873538
   Martin JD, 2005, AIAA J, V43, P853, DOI 10.2514/1.8650
   MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park C, 2013, IEEE T PATTERN ANAL, V35, P669, DOI 10.1109/TPAMI.2012.163
   Prasad D., 2012, POLYGONAL REPRESENTA
   Quelhas P, 2010, IEEE T MED IMAGING, V29, P1463, DOI 10.1109/TMI.2010.2048253
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Richardson RR, 2017, J POWER SOURCES, V357, P209, DOI 10.1016/j.jpowsour.2017.05.004
   ROSENFELD A, 1985, PATTERN RECOGN LETT, V3, P71, DOI 10.1016/0167-8655(85)90045-5
   Shu J, 2013, IEEE ENG MED BIO, P5445, DOI 10.1109/EMBC.2013.6610781
   Song YY, 2017, IEEE T MED IMAGING, V36, P288, DOI 10.1109/TMI.2016.2606380
   Song YY, 2015, IEEE T BIO-MED ENG, V62, P2421, DOI 10.1109/TBME.2015.2430895
   Su H, 2015, LECT NOTES COMPUT SC, V9351, P383, DOI 10.1007/978-3-319-24574-4_46
   Wang WX, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P833
   Wen Q, 2009, I S BIOMED IMAGING, P9, DOI 10.1109/ISBI.2009.5192970
   Xie YP, 2015, LECT NOTES COMPUT SC, V9351, P374, DOI 10.1007/978-3-319-24574-4_45
   Xing FY, 2016, IEEE T MED IMAGING, V35, P550, DOI 10.1109/TMI.2015.2481436
   Xu HM, 2014, IEEE J BIOMED HEALTH, V18, P1729, DOI 10.1109/JBHI.2013.2297030
   Yan J, 2016, IEEE T SUSTAIN ENERG, V7, P87, DOI 10.1109/TSTE.2015.2472963
   Yang D, 2018, J POWER SOURCES, V384, P387, DOI 10.1016/j.jpowsour.2018.03.015
   Yang HG, 2014, PATTERN RECOGN, V47, P2266, DOI 10.1016/j.patcog.2013.11.004
   Yang JG, 2018, PROCEDIA COMPUT SCI, V129, P375, DOI 10.1016/j.procs.2018.03.093
   YEO TTE, 1994, PATTERN RECOGN LETT, V15, P1013, DOI 10.1016/0167-8655(94)90033-7
   Yu SX, 2001, PROC CVPR IEEE, P752
   Zafari S., 2018, THESIS LAPPEENRANTA
   Zafari S, 2017, LECT NOTES COMPUT SC, V10270, P245, DOI 10.1007/978-3-319-59129-2_21
   Zafari S, 2017, LECT NOTES COMPUT SC, V10118, P76, DOI 10.1007/978-3-319-54526-4_6
   Zafari S, 2015, LECT NOTES COMPUT SC, V9474, P187, DOI 10.1007/978-3-319-27857-5_17
   Zafari S, 2015, IEEE T IMAGE PROCESS, V24, P5942, DOI 10.1109/TIP.2015.2492828
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Q, 2006, IEEE IMAGE PROC, P197, DOI 10.1109/ICIP.2006.312454
   Zhang WH, 2012, PATTERN RECOGN LETT, V33, P1543, DOI 10.1016/j.patrec.2012.03.027
NR 60
TC 8
Z9 8
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102962
DI 10.1016/j.jvcir.2020.102962
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QO
UT WOS:000598558100005
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Chen, GB
   Jiang, ZY
   Kamruzzaman, MM
AF Chen, Guobin
   Jiang, Zhiyong
   Kamruzzaman, M. M.
TI Radar remote sensing image retrieval algorithm based on improved Sobel
   operator
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Radar image retrieval; Blocking histogram; Sobel operator; Gray level
   co-occurrence matrix (GLCCM)
ID COLOR; HISTOGRAM; TEXTURE; MODEL
AB Aiming at the time-consuming problem caused by large computational load of radar image retrieval, based on blocking histogram, Sobel edge detection operator and gray level co-occurrence matrix (GLCCM), new radar remote sensing image retrieval algorithm based on improved Sobel operator is proposed. Firstly, the Sobel edge detection algorithm is used to process the image, the edge image is acquired, the radar remote sensing image is analyzed from different angles, and then the different radar remote sensing images are transformed. Then, based on the above processing, Radar Remote Sensing Image Retrieval Algorithm is acquired; finally, the plurality of statistic of the matrix is recorded as a feature vector describing the radar image, and the image is retrieved according to the feature vector of the radar image. Through a large number of experiments, Radar Remote Sensing Image Retrieval algorithm can greatly reduce the retrieval time, and it also has a good retrieval effect for images with rich texture. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Guobin] Chongqing Technol & Business Univ, Chongqing Key Lab Spatial Data Min & Big Data Int, Rongzhi Coll, Chongqing 401320, Peoples R China.
   [Jiang, Zhiyong] Guilin Univ Aerosp Technol, Practice Teaching Dept, Guilin 541004, Guangxi Zhuang, Peoples R China.
   [Kamruzzaman, M. M.] Jouf Univ, Dept Comp & Informat Sci, Sakaka, Al Jouf, Saudi Arabia.
C3 Chongqing Technology & Business University; Guilin University of
   Aerospace Technology; Al Jouf University
RP Jiang, ZY (corresponding author), Guilin Univ Aerosp Technol, Practice Teaching Dept, Guilin 541004, Guangxi Zhuang, Peoples R China.
EM jiangzy@guat.edu.cn; mmkamruzzaman@ju.edu.sa
RI Kamruzzaman, M.M./F-6702-2011; Jiang, Zhiyong/CAF-5675-2022
OI Kamruzzaman, M.M./0000-0001-8464-1523; Jiang,
   Zhiyong/0000-0002-5221-6132
FU Science and Technology Research Program of Chongqing Municipal Education
   Commission [KJZD-K201902101]; Key RAMP;D plan of Guilin scientific
   research and technological development plan [20170101-3]; Guilin science
   research and technology development plan [2016012006]; Basic Competence
   Promotion Project for Young and Middle-aged Teachers in Guangxi
   Universities [2017KY0862]; Jouf University, Sakaka, Al-Jouf, KSA
   [40/168]
FX This work was supported in part by the Science and Technology Research
   Program of Chongqing Municipal Education Commission (KJZD-K201902101);
   Key R&D plan of Guilin scientific research and technological development
   plan (20170101-3), Guilin science research and technology development
   plan (2016012006) and Basic Competence Promotion Project for Young and
   Middle-aged Teachers in Guangxi Universities (2017KY0862); Jouf
   University, Sakaka, Al-Jouf, KSA (40/168).
CR Athira T.R., 2017, INT J ARTIF INTELL, V6, P8
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Han XY, 2017, REG SCI URBAN ECON, V63, P97, DOI 10.1016/j.regsciurbeco.2016.12.003
   Indahl U. G., 2015, J CHEMOMETR, V12, P261
   Pavithra LK, 2018, COMPUT ELECTR ENG, V70, P580, DOI 10.1016/j.compeleceng.2017.08.030
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P1
   Varish N, 2018, APPL INTELL, V48, P2930, DOI 10.1007/s10489-017-1125-7
   Venkateswaran K., 2017, J INDIAN SOC REMOTE, V46, P327
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, NEUROCOMPUTING, V195, P117, DOI 10.1016/j.neucom.2015.08.117
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhang R, 2018, INT J FRACTURE, V211, P125, DOI 10.1007/s10704-018-0279-6
   Zhang Y, 2018, FRONT COMPUT SCI-CHI, V12, P984, DOI 10.1007/s11704-016-5551-1
   Zhou JX, 2018, INT J MACH LEARN CYB, V9, P677, DOI 10.1007/s13042-016-0597-9
NR 17
TC 45
Z9 45
U1 4
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102720
DI 10.1016/j.jvcir.2019.102720
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900002
DA 2024-07-18
ER

PT J
AU Guo, YP
AF Guo, Yiping
TI Credit risk assessment of P2P lending platform towards big data based on
   BP neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Peer to peer; Credit risk assessment; Logistic regression; BP neural
   network; Big data
ID PREDICTION
AB Peer-to-peer (P2P) lending platform plays a significant role in modern financial systems. However, due to improper supervision, credit risk is inevitable. In this paper, we analyze the traditional financial risk and information technology risk of P2P lending platform. In order to evaluate the performance of assessment algorithms, we present a BP neural network-based algorithm for lending risk assessment. To achieve our task, we crawled large-scale lending data for 2015-2019. Logistic regression is used to compare with BP neural network method. Experimental results show that BP neural network-based algorithm outperforms traditional Logistic regression algorithm and the proposed method can effectively reduce investor risk. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Guo, Yiping] ZhengZhou ShengDa Univ Econ Business & Management, Sch Finance & Trade, Zhengzhou 451191, Peoples R China.
RP Guo, YP (corresponding author), ZhengZhou ShengDa Univ Econ Business & Management, Sch Finance & Trade, Zhengzhou 451191, Peoples R China.
EM Guo_Yipmg66@hotmail.com
CR ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933
   [Anonymous], 2007, International Review of Financial Analysis, DOI [DOI 10.1016/J.IRFA.2007.06.001.(CREDIT:ASPECTS, DOI 10.1016/J.IRFA.2007.06.001, 10.1016/j.irfa.2007.06.001]
   Atz U., 2016, PEER TO PEER LENDING
   Berger S.C., 2009, BUR BUSIN RES J, V2
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Emekter R, 2015, APPL ECON, V47, P54, DOI 10.1080/00036846.2014.962222
   Freedman S., 2008, EVIDENCE PROSPER
   Guo YH, 2016, EUR J OPER RES, V249, P417, DOI 10.1016/j.ejor.2015.05.050
   Karimi N, 2018, J VIS COMMUN IMAGE R, V55, P853, DOI 10.1016/j.jvcir.2018.04.001
   Klafft Michael, 2008, Proceedings of the 2008 International Conference on E-Learning, E-Business, Enterprise Information Systems, and E-Government, P371
   Lee E, 2012, ELECTRON COMMER R A, V11, P495, DOI 10.1016/j.elerap.2012.02.001
   Liao L., 2014, Econ. Res., V7, P125
   Luo BJ, 2013, INF SYST E-BUS MANAG, V11, P141, DOI 10.1007/s10257-011-0182-4
   Luo Chunyu., 2011, KDD, P292, DOI 10.1145/2020408.2020458.
   OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   TAM KY, 1991, OMEGA-INT J MANAGE S, V19, P429, DOI 10.1016/0305-0483(91)90060-7
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wang HX, 2009, CIBCB: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P182
   Xiangrong Y E., 2014, FINANCIAL REGULATION, V3
   Zhao HK, 2014, IEEE DATA MINING, P1109, DOI 10.1109/ICDM.2014.104
NR 21
TC 16
Z9 18
U1 2
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102730
DI 10.1016/j.jvcir.2019.102730
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA NR2WP
UT WOS:000571423900031
DA 2024-07-18
ER

PT J
AU Zhang, SP
   Yang, FZ
   Wan, S
AF Zhang, Saiping
   Yang, Fuzheng
   Wan, Shuai
TI Rate-distortion-complexity optimization for x265
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rate-distortion-complexity optimization (RDCO); X265; High Efficiency
   Video Coding (HEVC); Computational complexity allocation
AB Rate-distortion optimization (RDO) is conventionally based on the analysis of rate-distortion (R-D) curve to minimize the coding distortion under the coding bits constraint. However, it is necessary to consider the computational complexity in the RDO process. In this paper, we obtain the Confidence LEvel - Computational complexity (CLEC) curves which indicate the characteristics of coding tree units (CTUs). Based on the CLEC curves, a rate-distortion-complexity optimization (RDCO) algorithm is proposed to optimize R-D under given computational complexity and achieve the optimal coding performance for x265. Experimental results demonstrate that the proposed algorithm can achieve a wide range of encoding speed under a given quantization parameter (QP) whereas the original x265 can only achieve a few fixed encoding speeds, and the proposed algorithm can reduce the BD-rate and increase the BD-PSNR by 6.59% and 0.13 dB on average under the same requirements of encoding speeds as the original x265.
C1 [Zhang, Saiping; Yang, Fuzheng] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
   [Wan, Shuai] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
C3 Xidian University; Northwestern Polytechnical University
RP Zhang, SP (corresponding author), 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
EM spzhang@stu.xidian.edu.cn
RI Wan, Shuai/AAA-8777-2022
OI Wan, Shuai/0000-0001-8617-149X
FU National Natural Science Foundation of China [61371089, 61571337]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61371089 and Grant 61571337.
CR [Anonymous], 2013, ISOIECJCT1SC29WG11
   Bjontegaard G., 2001, Document VCEG-M33
   Corrêa G, 2016, IEEE T CIRC SYST VID, V26, P1734, DOI 10.1109/TCSVT.2015.2469533
   Correa G, 2016, J REAL-TIME IMAGE PR, V12, P107, DOI 10.1007/s11554-013-0392-8
   Correa G, 2015, IEEE INT SYMP CIRC S, P1114, DOI 10.1109/ISCAS.2015.7168833
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Fang J.-T., 2018, IEEE INT C INF COMM
   Hu Q, 2016, IEEE T MULTIMEDIA, V18, P379, DOI 10.1109/TMM.2015.2512799
   Hu Q, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P502, DOI 10.1109/VCIP.2014.7051616
   Huang YJ, 2019, IEEE T CIRC SYST VID, V29, P1038, DOI 10.1109/TCSVT.2018.2823360
   Indrale V.D., 2017, IEEE INT C COMP COMM, P1
   ITU-T, 2005, H264ISOIEC1449610 IT
   Jiménez-Moreno A, 2016, IEEE T MULTIMEDIA, V18, P563, DOI 10.1109/TMM.2016.2524995
   Li HL, 2004, IEEE T MULTIMEDIA, V6, P624, DOI [10.1109/TMM.2004.830812, 10.1109/tmm.2004.830812]
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Liu ZY, 2018, IEEE IMAGE PROC, P3623, DOI 10.1109/ICIP.2018.8451240
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Mu F., 2018, IEEE INF TECHN MECH
   SNELL JL, 1959, ECONOMETRICA, V27, P138, DOI 10.2307/1907790
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Zhang J, 2018, IEEE IMAGE PROC, P3628, DOI 10.1109/ICIP.2018.8451088
   Zhang J, 2018, IEEE T MULTIMEDIA, V20, P29, DOI 10.1109/TMM.2017.2723238
   Zhang Y, 2015, IEEE T IND INFORM, V11, P1492, DOI 10.1109/TII.2015.2491646
   Zhao TS, 2013, IEEE J-STSP, V7, P1135, DOI 10.1109/JSTSP.2013.2271421
NR 24
TC 2
Z9 2
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102870
DI 10.1016/j.jvcir.2020.102870
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000003
DA 2024-07-18
ER

PT J
AU Chen, YR
   Kuo, CCJ
AF Chen, Yueru
   Kuo, C. -C. Jay
TI PixelHop: A successive subspace learning (SSL) method for object
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Machine learning; Subspace learning; Computer vision; Pattern
   recognition
AB A new machine learning methodology, called successive subspace learning (SSL), is introduced in this work. SSL contains four key ingredients: (1) successive near-to-far neighborhood expansion; (2) unsupervised dimension reduction via subspace approximation; (3) supervised dimension reduction via label-assisted regression (LAG); and (4) feature concatenation and decision making. An image-based object classification method, called PixelHop, is proposed to illustrate the SSL design. It is shown by experimental results that the PixelHop method outperforms the classic CNN model of similar model complexity in three benchmarking datasets (MNIST, Fashion MNIST and CIFAR-10). Although SSL and deep learning (DL) have some high-level concept in common, they are fundamentally different in model formulation, the training process and training complexity. Extensive discussion on the comparison of SSL and DL is made to provide further insights into the potential of SSL. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Chen, Yueru; Kuo, C. -C. Jay] Univ Southern Calif, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Chen, YR (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.
EM yueruche@usc.edu
RI Chen, Yueru/GWC-9924-2022; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035; Chen, Yueru/0000-0003-0580-5097
FU DARPA [FA8750-16-2-0173]; Air Force Research Laboratory (AFRL)
   [FA8750-16-2-0173]; U.S. Army Research Laboratory's External
   Collaboration Initiative (ECI) of the Director's Research Initiative
   (DRIA) program
FX This research is supported in part by DARPA and Air Force Research
   Laboratory (AFRL) under agreement number FA8750-16-2-0173 and in part by
   the U.S. Army Research Laboratory's External Collaboration Initiative
   (ECI) of the Director's Research Initiative (DRIA) program. The U.S.
   Government is authorized to reproduce and distribute reprints for
   Governmental purposes notwithstanding any copyright notation hereon. The
   views and conclusions contained in this document are those of the
   authors and should not be interpreted as necessarily representing the
   official policies or endorsements, either expressed or implied, of
   DARPA, the Air Force Research Laboratory (AFRL), the U.S. Army Research
   Laboratory (ARL) or the U.S. Government.
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   [Anonymous], 2009, Technical report
   Bouwmans Thierry, 2009, Recent Patents on Computer Science, V2, P223, DOI 10.2174/1874479610902030223
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Gu Q., 22 INT JOINT C ART I
   Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578
   Kuo CCJ, 2018, J VIS COMMUN IMAGE R, V50, P237, DOI 10.1016/j.jvcir.2017.11.023
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Kuo CCJ, 2019, J VIS COMMUN IMAGE R, V60, P346, DOI 10.1016/j.jvcir.2019.03.010
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang J., ADV NEURAL INFORM PR, P1473
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Xiao H., 2017, ARXIV170807747
   Zhang Min, 2019, ARXIV190712766
NR 21
TC 39
Z9 40
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102749
DI 10.1016/j.jvcir.2019.102749
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900006
OA Bronze
DA 2024-07-18
ER

PT J
AU Wu, Y
   Liu, Z
   Zhou, XF
AF Wu, Yong
   Liu, Zhi
   Zhou, Xiaofei
TI Saliency detection using adversarial learning networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adversarial learning; Generator; discriminator; Saliency detection;
   Feedback information
ID OBJECT DETECTION; MULTILEVEL; INTEGRATION
AB This paper proposes a novel model for saliency detection using the adversarial learning networks, in which the generator is used to generate the saliency map and the discriminator is deployed to guide the training process of overall network. Concretely, the training procedure of our model consists of three steps including the training of generator, the training of discriminator, and the training throughout the overall network. The key point of training process lies in the discriminator, which is designed to provide the feedback information for the acceleration of the generator and the refinement of saliency map. Therefore, during the training stage of overall network, the output of the generator, i.e. the coarse saliency map, is fed into the discriminator, yielding the corresponding feedback information. Following this way, we can obtain the final generator with a higher performance. For testing, the obtained generator is employed to perform saliency detection. Extensive experiments on four challenging saliency detection datasets show that our model not only achieves the favorable performance against the state-of-the-art saliency models, but also possesses the faster convergence speed when training the proposed model. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wu, Yong; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wu, Yong; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Zhou, Xiaofei] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou 370018, Peoples R China.
C3 Shanghai University; Shanghai University; Hangzhou Dianzi University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI LIU, Zhi/D-4518-2012; WU, YONG/GWM-4056-2022
OI LIU, Zhi/0000-0002-8428-1131; WU, YONG/0000-0002-3256-6012
FU National Natural Science Foundation of China [61771301, 61901145]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771301 and 61901145.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], P IEEE CVPR
   [Anonymous], 2011, ADV NEURAL INF PROCE
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Huang MK, 2019, NEUROCOMPUTING, V364, P310, DOI 10.1016/j.neucom.2019.07.054
   Ji YZ, 2018, NEUROCOMPUTING, V316, P357, DOI 10.1016/j.neucom.2018.08.013
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li GY, 2019, NEUROCOMPUTING, V368, P180, DOI 10.1016/j.neucom.2019.08.051
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luc P., 2016, P NIPS
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150
   Xiao TH, 2018, LECT NOTES COMPUT SC, V11214, P172, DOI 10.1007/978-3-030-01249-6_11
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang Q, 2019, J VIS COMMUN IMAGE R, V59, P415, DOI 10.1016/j.jvcir.2019.01.034
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou XF, 2018, IEEE T MULTIMEDIA, V20, P2993, DOI 10.1109/TMM.2018.2829605
   Zhou XF, 2018, J VIS COMMUN IMAGE R, V51, P131, DOI 10.1016/j.jvcir.2018.01.014
   Zou BJ, 2015, J VIS COMMUN IMAGE R, V33, P378, DOI 10.1016/j.jvcir.2015.09.017
NR 52
TC 15
Z9 16
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102761
DI 10.1016/j.jvcir.2020.102761
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800003
DA 2024-07-18
ER

PT J
AU Mohammadzade, H
   Tabejamaat, M
AF Mohammadzade, Hoda
   Tabejamaat, Mohsen
TI Sparseness embedding in bending of space and time; a case study on
   unsupervised 3D action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised action recognition; Time series analysis; Sparseness
   embedding; Human computer interaction
ID VIDEO SURVEILLANCE; KINECT SENSOR; POSES
AB Human action recognition from skeletal data is one of the most popular topics in computer vision which has been widely studied in the literature, occasionally with some very promising results. However, being supervised, most of the existing methods suffer from two major drawbacks; (1) too much reliance on massive labeled data and (2) high sensitivity to outliers, which in turn hinder their applications in such real-world scenarios as recognizing long-term and complex movements. In this paper, we propose a novel unsupervised 3D action recognition method called Sparseness Embedding in which the spatiotemporal representation of action sequences is nonlinearly projected into an unwarped feature representation medium, where unlike the original curved space, one can easily apply the Euclidean metrics. Our strategy can simultaneously integrate the characteristics of nonlinearity, sparsity, and space curvature of sequences into a single objective function, leading to a more robust and highly compact representation of discriminative attributes without any need to label information. Moreover, we propose a joint learning strategy for dealing with the heterogeneity of the temporal and spatial characteristics of action sequences. A set of extensive experiments on six publicly available databases, including UTKinect, TST fall, UTD-MHAD, CMU, Berkeley MHAD, and NTU RGB+D demonstrates the superiority of our method compared with the state-of-the-art algorithms. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Mohammadzade, Hoda; Tabejamaat, Mohsen] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Mohammadzade, H (corresponding author), Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
EM hoda@sharif.edu; m.tabejamaat@sharif.edu
RI , Hoda/ABC-6387-2020
OI , Hoda/0000-0002-9852-5088
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Agahian S, 2019, VISUAL COMPUT, V35, P591, DOI 10.1007/s00371-018-1489-7
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934
   Anjum ML, 2017, J ROBOT, V2017, DOI 10.1155/2017/7610417
   [Anonymous], 2017, P 30 INT WORKSH QUAL
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, IEEE SIBGRAPI
   [Anonymous], ARXIV14090473
   [Anonymous], 2011, CITESEER BMVC
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI DOI 10.18653/V1/D15-1166
   [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965
   Asir M.S., 2014, SIGNAL PROCESS, V62, P4209
   Baysal Sermetcan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1727, DOI 10.1109/ICPR.2010.427
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300
   Bouachir W, 2018, PATTERN RECOGN LETT, V110, P1, DOI 10.1016/j.patrec.2018.03.018
   Chan William, 2017, U.S. Patent, Patent No. [9,799,327, 9799327]
   Chen C, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P421, DOI 10.1109/RCAR.2018.8621652
   Cherian A, 2013, IEEE T PATTERN ANAL, V35, P2161, DOI 10.1109/TPAMI.2012.259
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   Choi B., 2012, ARMA model identification
   Chrungoo A, 2014, LECT NOTES ARTIF INT, V8755, P84, DOI 10.1007/978-3-319-11973-1_9
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Dawar N, 2018, IEEE SENS J, V18, P9660, DOI 10.1109/JSEN.2018.2872862
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Einstein A, 1905, ANN PHYS-BERLIN, V17, P891
   ELMADANY NE, 2018, 2018 IEEE INT C MULT, P1
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Eweiwi A, 2015, LECT NOTES COMPUT SC, V9007, P428, DOI 10.1007/978-3-319-16814-2_28
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Farahat AK, 2013, KNOWL INF SYST, V35, P285, DOI 10.1007/s10115-012-0538-1
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gao YB, 2018, IEEE ACCESS, V6, P52277, DOI 10.1109/ACCESS.2018.2869790
   Ghodsi S, 2018, J VIS COMMUN IMAGE R, V55, P729, DOI 10.1016/j.jvcir.2018.08.001
   Ghojogh B, 2018, IEEE SENS J, V18, P1612, DOI 10.1109/JSEN.2017.2784425
   GRAVES A.B., 2019, US Patent App, Patent No. [15/043,341, 15043341]
   Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139
   Hayes Bradley, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6586, DOI 10.1109/ICRA.2017.7989778
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Pham HH, 2018, IEEE IMAGE PROC, P3483, DOI 10.1109/ICIP.2018.8451404
   Kacem A., 2012, IEEE T PATTERN ANAL
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Keselman L, 2017, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2017.167
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Lei HS, 2008, SITIS 2007: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGIES & INTERNET BASED SYSTEMS, P839, DOI 10.1109/SITIS.2007.112
   Li CL, 2018, IEEE T IMAGE PROCESS, V27, P3657, DOI 10.1109/TIP.2018.2815744
   Li CK, 2019, IEEE T HUM-MACH SYST, V49, P95, DOI 10.1109/THMS.2018.2883001
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li MQ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/4576015
   Li X, 2017, MINERAL MET MAT SER, P357, DOI 10.1007/978-3-319-51091-0_34
   Liao D., 2017, APPL COMPUT INTELL S
   Liu J., ARXIV171105941
   Liu JW, 2017, MULTIMED TOOLS APPL, V76, P6595, DOI 10.1007/s11042-016-3342-1
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Liu TW, 2018, IEEE INTERNET THINGS, V5, P3136, DOI 10.1109/JIOT.2018.2834517
   Liu ZW, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P997, DOI 10.1145/3077136.3080700
   Mazhar O, 2018, 2018 IEEE RSJ INT C, P1, DOI DOI 10.1109/IROS.2018.8594385
   Migniot C, 2013, LECT NOTES COMPUT SC, V8034, P603, DOI 10.1007/978-3-642-41939-3_59
   Moakher M, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P285, DOI 10.1007/3-540-31272-2_17
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Prati A, 2019, J AMB INTEL SMART EN, V11, P5, DOI 10.3233/AIS-180510
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Rahimi S, 2019, SIGNAL IMAGE VIDEO P, V13, P271, DOI 10.1007/s11760-018-1354-1
   Reily B, 2018, AUTON ROBOT, V42, P1281, DOI 10.1007/s10514-017-9692-3
   Ren J, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P199, DOI 10.1109/ICIVC.2018.8492894
   Salah AA, 2011, LECT NOTES COMPUT SC, V7040, P376
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Srivastava N., 2015, JMLR P, V37, P843
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tao LL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P303, DOI 10.1109/ICCVW.2015.48
   Trevarthen Colwyn., 1990, BRAIN CIRCUITS FUNCT
   Tu JH, 2018, IEEE IMAGE PROC, P3478, DOI 10.1109/ICIP.2018.8451608
   Velloso E, 2013, INT CONF AFFECT, P135, DOI 10.1109/ACII.2013.29
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Venugopalan S., ARXIV160401729
   Wang CY, 2016, PROC CVPR IEEE, P2639, DOI 10.1109/CVPR.2016.289
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L, 2018, IEEE ACCESS, V6, P50788, DOI 10.1109/ACCESS.2018.2869751
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wu Y, 2016, arXiv, P1
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P439, DOI 10.1109/TCYB.2016.2519448
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Yu H, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER AIDED EDUCATION (ICISCAE 2018), P1, DOI 10.1109/ICISCAE.2018.8666856
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang XK, 2016, PROC CVPR IEEE, P4498, DOI 10.1109/CVPR.2016.487
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zheng N., 2018, 32 AAAO C ART INT
   Zhu GM, 2016, SIGNAL PROCESS-IMAGE, V42, P19, DOI 10.1016/j.image.2016.01.003
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 117
TC 5
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102691
DI 10.1016/j.jvcir.2019.102691
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200003
DA 2024-07-18
ER

PT J
AU Qayyum, H
   Majid, M
   ul Haq, E
   Anwar, SM
AF Qayyum, Huma
   Majid, Muhammad
   ul Haq, Ehatisham
   Anwar, Syed Muhammad
TI Generation of personalized video summaries by detecting viewer's emotion
   using electroencephalography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video summarization; Emotion recognition; Electroencephalography;
   Feature extraction; Classification
ID FACIAL EXPRESSIONS; ATTENTION MODEL; RECOGNITION; FRAMEWORK; SPEECH;
   EEG; CLASSIFICATION
AB Video summaries produced by low level features are unaware of the viewer's requirements and result in a semantic gap. Video content evokes certain emotions in a viewer, which can be measured and act as a strong source of information to generate summaries meeting viewer's expectation. In this paper, we propose a personalized video summarization framework that classifies viewer's emotion based on electroen-cephalography (EEG) signals, while watching a video to extract keyframes. Features are extracted from recorded EEG signals in time, frequency and wavelet domain to classify viewer's emotions. Those frames are selected as keyframes from the video, where different emotions of viewer are evoked. Experiments are performed on 50 viewers and 50 video sequences to validate the effectiveness and efficiency of the proposed framework. It is evident from the results that the proposed method generates summaries with high precision, recall, F-measure, accuracy, and low error, hence reducing the semantic gap. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Qayyum, Huma; Majid, Muhammad; ul Haq, Ehatisham] Univ Engn & Technol Taxila, Dept Comp Engn, Taxila 47050, Pakistan.
   [Anwar, Syed Muhammad] Univ Engn & Technol Taxila, Dept Software Engn, Taxila 47050, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila
RP Majid, M (corresponding author), Univ Engn & Technol Taxila, Dept Comp Engn, Taxila 47050, Pakistan.
EM m.majid@uettaxila.edu.pk
RI anwar, syed/AGY-3965-2022; Majid, Muhammad/Z-5667-2019;
   Ehatisham-ul-Haq, Muhammad/C-5892-2018
OI anwar, syed/0000-0002-8179-3959; Majid, Muhammad/0000-0003-3662-2525;
   Ehatisham-ul-Haq, Muhammad/0000-0001-9949-6664; qayyum,
   huma/0000-0003-2049-9446
CR Abootalebi V., 2010, COMPUT METH PROG BIO, V94, P20
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], CVPR
   [Anonymous], P 2 INT C MULT HUM C
   [Anonymous], 2007, Supervised machine learning: A review of classification techniques
   ASAN E., VIDEO SHOT BOUNDARY
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Darabi K, 2017, MULTIMED TOOLS APPL, V76, P2353, DOI 10.1007/s11042-015-3210-4
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M., 2010, MULTIMED TOOLS APPL, V47, P211
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gouizi K., 2011, Journal of Medical Engineering & Technology, V35, P300, DOI 10.3109/03091902.2011.601784
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Han JW, 2014, NEUROCOMPUTING, V144, P128, DOI 10.1016/j.neucom.2013.11.052
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   Kalsum T, 2018, IET IMAGE PROCESS, V12, P1004, DOI 10.1049/iet-ipr.2017.0499
   Kannan R, 2015, INFORM PROCESS MANAG, V51, P286, DOI 10.1016/j.ipm.2014.12.001
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Lai J., 2013, INT J VISUAL COMMUN, V23, P114
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Li L., 2011, Proc. 20th Int. Conf. World Wide Web, P287
   Li L, 2006, LECT NOTES COMPUT SC, V4282, P437
   Liang NY, 2006, INT J NEURAL SYST, V16, P29, DOI 10.1142/S0129065706000482
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Liu Y., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P114
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mehmood I, 2016, NEUROCOMPUTING, V174, P393, DOI 10.1016/j.neucom.2015.05.126
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Money AG, 2009, DISPLAYS, V30, P59, DOI 10.1016/j.displa.2008.12.003
   Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320
   PAL SK, 1995, J INTELL FUZZY SYST, V3, P247
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Raheel A, 2019, MULTIMED TOOLS APPL, V78, P13971, DOI 10.1007/s11042-018-6907-3
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Taniguchi Y., 1995, MULTIMEDIA 95 P 3 AC, P25
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Truong B., ACM T MULTIMEDIA COM
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Wang F, 2012, IEEE T MULTIMEDIA, V14, P76, DOI 10.1109/TMM.2011.2165531
   Wang F, 2009, IEEE INT CON MULTI, P1326, DOI 10.1109/ICME.2009.5202747
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang Q, 2008, IEEE ICC, P5087, DOI 10.1109/ICC.2008.955
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Witten IH, 2011, MOR KAUF D, P1
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zhang Q, 2013, J HUM KINET, V39, P5, DOI 10.2478/hukin-2013-0063
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 56
TC 16
Z9 16
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102672
DI 10.1016/j.jvcir.2019.102672
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700016
DA 2024-07-18
ER

PT J
AU Fang, Y
   Zhao, J
   Hu, LZ
   Ying, XP
   Pan, YF
   Wang, XP
AF Fang, Yan
   Zhao, Jing
   Hu, Lingzhi
   Ying, Xiaoping
   Pan, Yanfang
   Wang, Xiaoping
TI Image classification toward breast cancer using deeply-learned quality
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; CNN; Quality score
ID OBJECT DETECTION
AB Image classification plays an important role in computer vision and its applications, such as scene categorization, image retrieval. Convolutional neural network based methods have shown competitive performance in image classification, which aims to exploit deep feature of training images. In this paper, based on CNN methods and image quality assessment (IQA) algorithms, we propose a novel method for medical application, that is breast cancer classification. First, we leverage CNN architecture to calculate the number of pixels in the lesions, where maximum pooling layers are used. Then, large density of pixel regions will be assigned with large quality scores, which reflect more texture and grayscale features. Finally, we construct a multi-SVM based image kernel using obtained quality scores to achieve breast cancer classification. Experimental results show our proposed method outperforms single recognition based image classification methods such as pixel grayscale or gradient. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Fang, Yan; Hu, Lingzhi; Ying, Xiaoping; Pan, Yanfang; Wang, Xiaoping] Shaanxi Univ Chinese Med, Coll Basic Med, Xianyang, Peoples R China.
   [Zhao, Jing] Shaanxi Univ Chinese Med, Affiliated Hosp, Xianyang, Peoples R China.
C3 Shaanxi University of Chinese Medicine; Shaanxi University of Chinese
   Medicine
RP Zhao, J (corresponding author), Shaanxi Univ Chinese Med, Affiliated Hosp, Xianyang, Peoples R China.
EM 3383870552@qq.com
FU General Projects in the Field of Social Development of Shaanxi Science
   and Technology Department), Shaanxi University of Traditional Chinese
   Medicine "Innovation Team of Fuzheng Guzhong Traditional Chinese
   Medicine for the Treatment of Malignant Tumors" [2017SF-306]
FX This work was supported by General Projects in the Field of Social
   Development of Shaanxi Science and Technology Department (2017SF-306),
   Shaanxi University of Traditional Chinese Medicine "Innovation Team of
   Fuzheng Guzhong Traditional Chinese Medicine for the Treatment of
   Malignant Tumors".
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Bu Jingting, 2019, IMAGE RES MED APPL, V08, P96
   Cai Cunwei, J CHINA MED U, P1
   Chang J., 2018, J VISUAL COMMUN IMAG
   Chen Yao, CHINESE J GEN CLIN M, P1
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Ding Huajie, 2019, J GUANGXI U SCI TECH, V02
   Fang Wei, 2019, NINGXIA MED J
   Gao Qiang, 2019, IMAGE RES MED APPL, V08, P26
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han Mingli, 2019, CHINESE J CT MRI, V17
   Huang Gang, CHINESE LASER, P1
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Ji Ningling, LASER OPTOELECTRON P, P1
   Li Hongmei, 2019, GEN SURROUNDING, V10, P1168
   Liao Sifan, 2019, J GUANGDONG PHARM U, V02, P1
   Liu Hong, 2019, TRANSPORT RES C-EMER, V10, P83
   Miao S, 2016, IEEE T MED IMAGING, V35, P1352, DOI 10.1109/TMI.2016.2521800
   Qi Hao, CONTROL DECISION, P1
   Qu Chunan, 2019, J PRACT MED, V06, P855
   Qu Fangfang, 2019, CHINESE J INTEGR TRA, V7, P140
   Shen Xiangxiang, J INTELL SYST, P1
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sun Wei, CHINESE GEN PRACT, P1
   Wen Min, GUANGDONG MED, P1
   Wu M D, 2019, Journal of Shandong Industrial Technology, P156
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu Bin, CHINESE ONCOL, P1
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Yang Tingting, 2019, COMPUT PROD CIRCUL, V04, P112
   Yang Wei, 2019, CHINESE J INTEGR TRA, V7, P70
   Zhang Lihua, 2019, J HUNAN U SCI TECHNO, V34, P77
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
NR 36
TC 18
Z9 18
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102609
DI 10.1016/j.jvcir.2019.102609
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600010
DA 2024-07-18
ER

PT J
AU Caetano, C
   de Melo, VHC
   Brémond, F
   dos Santos, JA
   Schwartz, WR
AF Caetano, Carlos
   de Melo, Victor H. C.
   Bremond, Francois
   dos Santos, Jefersson A.
   Schwartz, William Robson
TI Magnitude-Orientation Stream network and depth information applied to
   activity recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Activity recognition; Convolutional neural networks (CNNs); Two-stream
   convolutional networks; Spatiotemporal information; Optical flow; Depth
   information
AB The temporal component of videos provides an important clue for activity recognition, as a number of activities can be reliably recognized based on the motion information. In view of that, this work proposes a novel temporal stream for two-stream convolutional networks based on images computed from the optical flow magnitude and orientation, named Magnitude-Orientation Stream (MOS), to learn the motion in a better and richer manner. Our method applies simple non-linear transformations on the vertical and horizontal components of the optical flow to generate input images for the temporal stream. Moreover, we also employ depth information to use as a weighting scheme on the magnitude information to compensate the distance of the subjects performing the activity to the camera. Experimental results, carried on two well-known datasets (UCF101 and NTU), demonstrate that using our proposed temporal stream as input to existing neural network architectures can improve their performance for activity recognition. Results demonstrate that our temporal stream provides complementary information able to improve the classical two-stream methods, indicating the suitability of our approach to be used as a temporal video representation. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Caetano, Carlos; de Melo, Victor H. C.; dos Santos, Jefersson A.; Schwartz, William Robson] Univ Fed Minas Gerais, Dept Comp Sci, Smart Sense Lab, Belo Horizonte, MG, Brazil.
   [Bremond, Francois] INRIA, 2004 Rte Lucioles BP 93, F-06902 Sophia Antipolis, France.
C3 Universidade Federal de Minas Gerais; Inria
RP Caetano, C (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, Smart Sense Lab, Belo Horizonte, MG, Brazil.
EM carlos.caetano@dcc.ufmg.br
RI Schwartz, William Robson/E-6612-2011; dos Santos,
   Jefersson/HKW-4282-2023
OI dos Santos, Jefersson/0000-0002-8889-1586; Schwartz,
   William/0000-0003-1449-8834; Caetano, Carlos/0000-0002-1546-3740
FU Brazilian National Research Council - CNPq [311053/2016-5,
   204952/2017-4, 438629/2018-3]; Minas Gerais Research Foundation FAPEMIG
   [APQ-00567-14, PPM-00540-17]; Coordination for the Improvement of Higher
   Education Personnel - CAPES (DeepEyes Project); NVIDIA Corporation
FX The authors would like to thank the Brazilian National Research Council
   - CNPq (Grants 311053/2016-5, 204952/2017-4 and 438629/2018-3), the
   Minas Gerais Research Foundation FAPEMIG (Grants APQ-00567-14 and
   PPM-00540-17) and the Coordination for the Improvement of Higher
   Education Personnel - CAPES (DeepEyes Project). The authors gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   GeForce Titan X GPU used for this research.
CR [Anonymous], 2017 30TH SIBGRAPI C
   [Anonymous], 2013, IEEE T PATTERN ANAL
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2017 IEEE WINT C APP
   [Anonymous], 2016, ECCV
   [Anonymous], 2017, CVPR
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2007, ACCV
   [Anonymous], 2013, INT J COMPUT VISION
   [Anonymous], UCF101 DATASET 101 H
   [Anonymous], 2007, ACM MM
   [Anonymous], 2018, IJCAI
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], TECH REP
   [Anonymous], ECCV
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2016, ICPR
   [Anonymous], 2011, CVPRW
   [Anonymous], 2014, NIPS
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], CORR
   [Anonymous], 2014, VISUALIZING UNDERSTA
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2014, CVPR
   [Anonymous], 2015, ICML
   [Anonymous], 2006, ECCV
   [Anonymous], INT C DIG IM COMP TE
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, SIBGRAPI
   [Anonymous], 2015, ICCV
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], 2015, WACV
   [Anonymous], 2017 IEEE INT C COMP
   [Anonymous], 2006, HUM CTR TECHN WORKSH
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2015, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, 2017 IEEE INT C COMP
   [Anonymous], 2013, ICCV
   [Anonymous], 2008, CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], 2016, CVPR
   [Anonymous], THESIS
   [Anonymous], 2003, ICCV
   [Anonymous], 2014, CVPR
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ioffe S., 2015, arXiv: Learning
   Klaser A., 2008, BMVC 2008 19 BRIT MA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Park E., 2016, WACV
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang H., 2011, CVPR
   Wang J, 2014, SPRINGERBRIEF COMPUT, P1, DOI 10.1007/978-3-319-04561-0
   ZACH C, 2007, P 29 DAGM C PATT REC
NR 60
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102596
DI 10.1016/j.jvcir.2019.102596
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200031
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, R
   Zhao, F
   Yang, CS
   Li, Y
   Huang, TJ
AF Chen, Rui
   Zhao, Fei
   Yang, Changshui
   Li, Yuan
   Huang, Tiejun
TI Robust estimation for image noise based on eigenvalue distributions of
   large sample covariance matrices
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Noise level estimation; Eigenvalue distributions; Large sample
   covariance matrix; Random matrix theory
ID EXTREME EIGENVALUES; LEVEL ESTIMATION; VARIANCE; WISHART; APPROXIMATION;
   COMPONENTS; DOMAIN; LIMITS
AB In this paper, we propose a novel algorithm to estimate Gaussian noise levels for captured natural images by rigorously analyzing the limiting distributions of the eigenvalue spectrum of a large covariance matrix with Gaussian samples. In order to select a relatively homogeneous region that best represents the noise, the corresponding image patches are first rearranged to construct a high-dimensional noise covariance matrix. And then, an optimal criterion for classifying homogeneous regions is derived based on the statistical relationship between the largest and the second largest eigenvalues of a sample covariance matrix. Moreover, we further explore the reasons for the bias of the maximum likelihood estimator of the noise variance both in high-dimensional settings and finite samples. According to random matrix theory, we clarify the asymptotic properties of the trace of a sample covariance matrix to measure the error bounds of estimation and then propose a new bias-corrected estimator. To this end, an effective estimation method for the noise level is devised based on the boundness and asymptotic behavior of pure noise eigenvalues of the selected patches. The estimation performance of our method has been guaranteed both theoretically and empirically. Experimental results have demonstrated that our approach can reliably infer true noise variance and is superior to the competing methods in terms of both estimation accuracy and robustness. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Rui] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
   [Zhao, Fei] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
   [Yang, Changshui; Li, Yuan; Huang, Tiejun] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
C3 Tianjin University; Northwestern University; Peking University
RP Chen, R (corresponding author), Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
EM ruichen@tju.edu.cn
RI Sonka, Milan/F-6227-2017; Huang, Tiejun/D-6161-2011; Sonka,
   Milan/IZD-9792-2023; Li, Yuan/HDO-0750-2022; Chen, Rui/A-2785-2010
OI Sonka, Milan/0000-0002-9613-9968; Sonka, Milan/0000-0002-9613-9968;
   Chen, Rui/0000-0002-8003-4643; Chen, Rui/0000-0003-0705-6739
FU National Natural Science Foundation of China [61871284]; Beijing Major
   Science and Technology Project [Z171100000117008]; Equipment
   Pre-research Project of PLA Strategic Support Force, China [30503040310]
FX This work is supported by National Natural Science Foundation of China
   (No. 61871284), Beijing Major Science and Technology Project (No.
   Z171100000117008) and Equipment Pre-research Project of PLA Strategic
   Support Force, China (No. 30503040310).
CR Amer A, 2005, IEEE T CIRC SYST VID, V15, P113, DOI 10.1109/TCSVT.2004.837017
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bai ZD, 2012, J MULTIVARIATE ANAL, V106, P167, DOI 10.1016/j.jmva.2011.10.009
   Bai ZD, 2010, SPRINGER SER STAT, P91, DOI 10.1007/978-1-4419-0661-8_5
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Chen T, 2018, CLIN BREAST CANCER, V18, P1, DOI 10.1016/j.clbc.2017.06.005
   Cheng RQ, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053025
   Chiani M, 2014, J MULTIVARIATE ANAL, V129, P69, DOI 10.1016/j.jmva.2014.04.002
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   De Stefano A, 2004, EURASIP J APPL SIG P, V2004, P2400, DOI 10.1155/S1110865704401218
   Deo RS, 2016, J MULTIVARIATE ANAL, V147, P265, DOI 10.1016/j.jmva.2016.01.010
   Dong L, 2017, IEEE T IMAGE PROCESS, V26, P1017, DOI 10.1109/TIP.2016.2639447
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Franzen R, 2014, KODAK LOSSLESS TRUE
   Hashemi M, 2010, IEEE SIGNAL PROC LET, V17, P12, DOI 10.1109/LSP.2009.2030856
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544
   Kritchman S, 2008, CHEMOMETR INTELL LAB, V94, P19, DOI 10.1016/j.chemolab.2008.06.002
   Liu W, 2013, IEEE T IMAGE PROCESS, V22, P872, DOI 10.1109/TIP.2012.2219544
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Ma ZM, 2012, BERNOULLI, V18, P322, DOI 10.3150/10-BEJ334
   Marcenko V. A., 1967, MATH USSR SB, V1, P457, DOI [10.1070/SM1967v001n04ABEH001994, DOI 10.1070/SM1967V001N04ABEH001994]
   Passemier D, 2017, J R STAT SOC B, V79, P51, DOI 10.1111/rssb.12153
   Passemier D, 2012, RANDOM MATRICES-THEO, V1, DOI 10.1142/S201032631150002X
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rakhshanfar M, 2016, IEEE T IMAGE PROCESS, V25, P4172, DOI 10.1109/TIP.2016.2588320
   Rank K., 1999, IEEE P VIS IMAGE SIG, P113
   Sutour C, 2015, SIAM J IMAGING SCI, V8, P2622, DOI 10.1137/15M1012682
   Tang CW, 2015, IEEE T CIRC SYST VID, V25, P1283, DOI 10.1109/TCSVT.2014.2380196
   Ulfarsson MO, 2008, IEEE T SIGNAL PROCES, V56, P5804, DOI 10.1109/TSP.2008.2005865
   Wong WK, 2017, IEEE T IMAGE PROCESS, V26, P2905, DOI 10.1109/TIP.2017.2691543
   Yang S., 2010, J ELECTRON IMAGING, V19, P1
   Zhang S, 2015, AER ADV ENG RES, V15, P1
   Zlokolica V, 2006, IEEE SIGNAL PROC LET, V13, P337, DOI 10.1109/LSP.2006.870481
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 35
TC 1
Z9 1
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102604
DI 10.1016/j.jvcir.2019.102604
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200028
DA 2024-07-18
ER

PT J
AU Peng, ZJ
   Wang, SP
   Chen, F
   Zou, WH
   Jiang, GY
   Yu, M
AF Peng, Zongju
   Wang, Shipei
   Chen, Fen
   Zou, Wenhui
   Jiang, Gangyi
   Yu, Mei
TI Quality assessment of stereoscopic video in free viewpoint video system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Free viewpoint video system; Human visual characteristics; Video quality
   assessment; View synthesis
ID IMAGE; COMPRESSION; DISTORTION; DIBR
AB It is challenging to develop an effective quality assessment method for the stereoscopic video (SV) in the free viewpoint video (FVV) system because of asymmetric distortion and the interactively changing combinations. This paper proposes a quality assessment method that takes the characteristics of the SV in FVV systems into consideration. Specifically, considering the distortion introduced by the rendering process, the proposed method extracts a critical distortion area that can be perceivable by the human eye. The distortion degree of each critical distortion area is quantified and the overall results are pooled to obtain the initial quality score. The video pairs are classified into different combination types and the initial quality score is refined to obtain the final quality score. The experimental results show that the proposed method outperforms conventional objective methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Peng, Zongju; Wang, Shipei; Chen, Fen; Zou, Wenhui; Jiang, Gangyi; Yu, Mei] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Zou, Wenhui] China West Normal Univ, Sch Elect & Informat Engn, Nanchong 637009, Peoples R China.
C3 Ningbo University; China West Normal University
RP Peng, ZJ (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM pengzongju@126.com
RI Chen, Fen/ABG-7013-2021; jiang, gang/KII-8233-2024; Peng,
   Zongju/AAA-2914-2020
OI Peng, Zongju/0000-0001-8286-538X
FU Natural Science Foundation of China [61771269, 61620106012, 61671258,
   61871247]; Natural Science Foundation of Zhejiang Province
   [LY17F010005]; Natural Science Foundation of Ningbo [2018A610052]; K.C.
   Wong Magna Fund in Ningbo University
FX This work is supported by the Natural Science Foundation of China
   (61771269, 61620106012, 61671258, 61871247), Natural Science Foundation
   of Zhejiang Province (LY17F010005), and Natural Science Foundation of
   Ningbo (2018A610052). It is also sponsored by K.C. Wong Magna Fund in
   Ningbo University.
CR [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2012, SUBJECTIVE METHODS A
   [Anonymous], 2012, METHODOLOGY SUBJECTI
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   de Oliveira AQ, 2018, IEEE SIGNAL PROC LET, V25, P1705, DOI 10.1109/LSP.2018.2870342
   Farid MS, 2017, IEEE INT CON MULTI, P505, DOI 10.1109/ICME.2017.8019307
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Jung YJ, 2016, IEEE T CIRC SYST VID, V26, P1201, DOI 10.1109/TCSVT.2015.2430632
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Lee P. J., 2017, 2017 IEEE 6 GLOB C C, P1
   Lei JJ, 2017, MULTIMED TOOLS APPL, V76, P7661, DOI 10.1007/s11042-016-3413-3
   Li YQ, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P123, DOI 10.1109/ICMIP.2017.61
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Peng ZJ, 2015, J VIS COMMUN IMAGE R, V33, P309, DOI 10.1016/j.jvcir.2015.10.003
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Qi F, 2016, SIGNAL IMAGE VIDEO P, V10, P737, DOI 10.1007/s11760-015-0802-4
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shen LQ, 2019, IEEE TETCI, V3, P59, DOI 10.1109/TETCI.2018.2804885
   Tanimoto M., 2008, ISO IEC JTC1 SC29 WG
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tian SS, 2018, IEEE T IMAGE PROCESS, V27, P1652, DOI 10.1109/TIP.2017.2781420
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589
   Yue GH, 2018, IEEE T IND ELECTRON, V65, P2525, DOI 10.1109/TIE.2017.2739708
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao Y., 2010, P SPIE INT SOC OPT E, V7744
NR 37
TC 3
Z9 4
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102569
DI 10.1016/j.jvcir.2019.06.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200001
DA 2024-07-18
ER

PT J
AU Gao, ZS
   Dai, J
   Xie, CZ
AF Gao, Zhisheng
   Dai, Jiao
   Xie, Chunzhi
TI Dim and small target detection based on feature mapping neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dim and small target detection; Feature mapping; Deep neural network;
   Constant false alarm rate; Background suppression
ID ALGORITHM; FILTERS
AB Dim and small target detection based on passive millimeter wave or infrared imaging is of great value in both security and military fields and has been studied extensively. The problems of weak distinction between small targets and backgrounds and of less extractable features of targets have always been a technical bottleneck for accurate detection of dim and small targets. For dim and small targets with few pixel-based features on complex and diverse backgrounds, we propose a high-precision detection algorithm based on feature mapping deep neural networks with a spindle network structure. Firstly, the features of low-dimension dim and small target blocks are mapped to a higher-dimensional space. An encoded neural network is then used to extract high-discriminant features to complete the background and target recognition. Background suppression and target enhancement is realized according to the intensity (the distinguished output of the network). Finally, a detection method based on the constant false alarm rate is used to detect dim and small targets. The experimental results show that, compared with several popular algorithms for millimeter-wave and infrared image detection in different scenarios, the proposed algorithm has a lower false alarm rate, higher detection accuracy and stronger robustness. Statistics for experiments on under various false alarm rates and signal-to-noise ratios show that the detection rate of the proposed method is about 15% higher than that of the compared algorithms. In experiments on real data, the detection rate of our algorithm is more than 25% higher than that of the suboptimal algorithm. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Gao, Zhisheng; Dai, Jiao; Xie, Chunzhi] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Sichuan, Peoples R China.
C3 Xihua University
RP Gao, ZS (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Sichuan, Peoples R China.
EM gzs_xihua@mail.xhu.edu.cn
OI Dai, Jiao/0000-0003-3559-8009; jiao, dai/0000-0003-2797-2582
FU Ministry of Education Chunhui project [Z2016149]; Key Scientific
   Research Fund of Xihua University [Z17134]; Xihua University Key
   Laboratory Development Program [szjj2017-065]
FX This work has been partially supported by the Ministry of Education
   Chunhui project (Grant No: Z2016149), the Key Scientific Research Fund
   of Xihua University (Grant No: Z17134), Xihua University Key Laboratory
   Development Program (Grant No: szjj2017-065).
CR Anderson JMM, 2008, IEEE GEOSCI REMOTE S, V5, P547, DOI 10.1109/LGRS.2008.922316
   Cao Y, 2008, INT J INFRARED MILLI, V29, P188, DOI 10.1007/s10762-007-9313-x
   Chen Bing-wen, 2012, Systems Engineering and Electronics, V34, P857, DOI 10.3969/j.issn.1001-506X.2012.05.01
   Chen Y, 2011, IEEE J-STSP, V5, P629, DOI 10.1109/JSTSP.2011.2113170
   Chollet F, 2015, KERAS
   Davis James W, 2007, OTCBVS Benchmark Dataset Collection
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Feng XY, 2018, ACTA OPT SIN, V38, DOI 10.3788/AOS201838.0615004
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Gao Zhi-sheng, 2016, Optics and Precision Engineering, V24, P2601, DOI 10.3788/OPE.20162410.2601
   Geng L, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P391, DOI 10.1109/CompComm.2016.7924729
   Gong Junliang, 2013, Infrared and Laser Engineering, V42, P2566
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu T, 2010, J INFRARED MILLIM W, V29, P303
   Jin Yong-liang, 2012, Optics and Precision Engineering, V20, P171, DOI 10.3788/OPE.20122001.0171
   Li YS, 2018, ISPRS J PHOTOGRAMM, V146, P182, DOI 10.1016/j.isprsjprs.2018.09.014
   Li YS, 2018, PATTERN RECOGN, V77, P113, DOI 10.1016/j.patcog.2017.12.012
   Li ZZ, 2014, INFRARED PHYS TECHN, V67, P273, DOI 10.1016/j.infrared.2014.07.030
   Liu RM, 2010, J INFRARED MILLIM TE, V31, P1491, DOI 10.1007/s10762-010-9729-6
   Ng A., 2011, CS294A LECT NOTES, P77
   Peng NS, 2005, OPT ENG, V44, DOI 10.1117/1.1985487
   Prakash A., ARXIV181107275
   Ryu J, 2018, PROC SPIE, V10624, DOI 10.1117/12.2304677
   Wang Huigai, 2014, Infrared and Laser Engineering, V43, P2371
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang P, 2009, ELECTRON LETT, V45, P156, DOI 10.1049/el:20092206
   Wang XY, 2017, IEEE T GEOSCI REMOTE, V55, P5481, DOI 10.1109/TGRS.2017.2709250
   Wu MH, 2017, C IND ELECT APPL, P174, DOI 10.1109/ICIEA.2017.8282836
   Xie K, 2014, INFRARED PHYS TECHN, V67, P229, DOI 10.1016/j.infrared.2014.07.006
   [熊小辉 Xiong Xiaohui], 2018, [沉积学报, Acta Sedimentologica Sinica], V36, P257
   Yang H, 2012, IEEE GEOSCI REMOTE S, V9, P915, DOI 10.1109/LGRS.2012.2185776
   Zeng M, 2006, INFRARED PHYS TECHN, V48, P67, DOI 10.1016/j.infrared.2005.04.006
   Zhang P, 2007, OPT ENG, V46, DOI 10.1117/1.2759236
   Zhao JF, 2013, INFRARED PHYS TECHN, V56, P85, DOI 10.1016/j.infrared.2012.11.001
   Zhuang CQ, 2011, J PHYS-CONDENS MAT, V23, DOI 10.1088/0953-8984/23/46/465401
NR 35
TC 34
Z9 35
U1 2
U2 58
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 206
EP 216
DI 10.1016/j.jvcir.2019.05.013
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600019
DA 2024-07-18
ER

PT J
AU Yao, YY
   Liu, PZ
   Sun, XW
   Zhang, LM
AF Yao, Yiyang
   Liu, Peizhen
   Sun, Xiaowei
   Zhang, Luming
TI RETRACTED: Moving object surveillance using object proposals and
   background prior prediction (Retracted article. See vol. 69, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Video surveillance; Object; Moving target detection; Model learning
ID SALIENT; SEGMENTATION
AB In this paper, a moving object detection algorithm is combined with a background estimate and a Bing (Binary Norm Gradient) object is proposed in video surveillance. A simple background estimation method is used to detect rough images of a group of moving foreground objects. The foreground setting in the foreground will estimate another set of candidate object windows, and the target (pedestrian/vehicle) from the intersection area comes from the first two steps. In addition, the time cost is reduced by the estimated area. Experiments on outdoor datasets show that the proposed method can not only achieve high detection rate (DR), but also reduce false alarm rate (FAR) and time cost. (C) 2019 Published by Elsevier Inc.
C1 [Yao, Yiyang] State Grid Zhejiang Elect Power Co Informat & Tel, Hangzhou, Zhejiang, Peoples R China.
   [Liu, Peizhen; Sun, Xiaowei] Xian Inst Appl Opt, Xian, Shaanxi, Peoples R China.
   [Zhang, Luming] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Chinese Academy of Sciences; Zhejiang University
RP Yao, YY (corresponding author), State Grid Zhejiang Elect Power Co Informat & Tel, Hangzhou, Zhejiang, Peoples R China.
EM yiyangyao156@sohu.com
RI zhang, lu/GRO-2969-2022; Lei, Ming/JAD-1050-2023; Sun, Xiao
   Wei/U-3439-2017
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], IEEE C COMP VIS PATT
   Arifin AZ, 2006, PATTERN RECOGN LETT, V27, P1515, DOI 10.1016/j.patrec.2006.02.022
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Bathia H. V. P. K., 2015, EFFICIENT ALGORITHM, V03, P5096
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, IEEE T PATTERN ANAL, V33, P200, DOI 10.1109/TPAMI.2010.138
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding Y., 2013, Local difference pattern based local background modeling for object detection, US, Patent No. [8565482 B2, 8565482]
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Friedman N., 2013, COMPUT SCI, P175
   Gallagher A. C., 2013, Identifying unique objects in multiple image collections: US, Patent No. [US 8386505 B2[P], 8386505]
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Han X., 2015, 5 INT C INSTR MEAS C
   Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889
   Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4
   Held C, 2012, COMPUTER, V45, P83, DOI 10.1109/MC.2012.97
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P1165, DOI 10.1109/TCE.2011.6018870
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Prokhorov D. V., 2014, Method and system for object recognition based on a trainable dynamic system, Patent No. [US8705849, 8705849]
   Razlighi QR, 2011, J REAL-TIME IMAGE PR, V6, P137, DOI 10.1007/s11554-009-0144-y
   Scholkopf B., 2010, GRAPH BASED VISUAL S, P545
   Shi J., 2016, IEEE T PATTERN ANAL, V38, P1
   Shi R, 2012, IEEE SIGNAL PROC LET, V19, P215, DOI 10.1109/LSP.2012.2188388
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang S., 2015, MULTIMED TOOLS APPL, V75, P1
   Zhao D., 2015, IMPROVED BINARIZED N
   Zheng S., 2013, APPROXIMATE STRUCTUR
   2011, IEEE T IMAGE PROCESS, V20, P1709, DOI DOI 10.1109/TIP.2010.2101613
NR 45
TC 2
Z9 2
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 85
EP 92
DI 10.1016/j.jvcir.2019.03.006
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100009
DA 2024-07-18
ER

PT J
AU Chen, JZ
   Li, QQ
   Li, P
   Han, Y
   Wu, L
   Ling, HF
   Wu, WM
AF Chen, Jiazhong
   Li, Qingqing
   Li, Ping
   Han, Yu
   Wu, Lei
   Ling, Hefei
   Wu, Weimin
TI Saliency prediction by Mahalanobis distance of topological feature on
   deep color components
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency; Deep color components; Topological feature; Covariance matrix;
   Mahalanobis distance
ID MODEL
AB A new saliency prediction method via extracting topological feature and calculating Mahalanobis distance on deep color components is presented in this paper. Specifically, four selectable schemes of color components are considered and a deep convolutional network is used to learn the best scheme. Then the topological feature maps of an input image are extracted on the learned color components by the analysis of connectivity and adjacency. To achieve the final saliency map, a new fusion method is proposed by calculating the Mahalanobis distance between the feature maps and their means with their covariance matrices rather than summating the feature maps linearly. The numerical and visual evaluation shows that a competitive performance compared with fourteen state-of-the-art models is achieved by the proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Jiazhong; Li, Qingqing; Li, Ping; Han, Yu; Wu, Lei; Ling, Hefei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Wu, Weimin] Fujian Chuanzheng Commun Coll, Dept Informat Engn, Fuzhou 350000, Fujian, Peoples R China.
C3 Huazhong University of Science & Technology; Fujian Chuanzheng
   Communications College
RP Li, P (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM lpshome@hust.edu.cn
FU Natural Science Foundation of China [U1536203]; Major Scientific and
   Technological Innovation Project of Hubei Province [2015AAA013];
   National Key Research and Development program of China [2016QY01W0200]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203, in part by the Major Scientific and
   Technological Innovation Project of Hubei Province under Grant
   2015AAA013, and in part by the National Key Research and Development
   program of China under Grant 2016QY01W0200.
CR [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce NDB, 2016, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2016.62
   Cerf Moran., 2007, Advances in Neural Information and Processing Systems, P241
   Chen JZ, 2017, NEUROCOMPUTING, V251, P16, DOI 10.1016/j.neucom.2017.04.020
   CHEN L, 1982, SCIENCE, V218, P699, DOI 10.1126/science.7134969
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65
   Huang XG, 2015, 2015 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices (ASEMD), P262, DOI 10.1109/ASEMD.2015.7453564
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kootstra G., 2008, P BRIT MACH VIS C, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu S, 2018, IEEE T IMAGE PROCESS, V27, P5032, DOI 10.1109/TIP.2018.2836313
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nguyen K, 2016, IEEE IMAGE PROC, P1344, DOI 10.1109/ICIP.2016.7532577
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Rosenholtz R, 2004, J VISION, V4, P224, DOI 10.1167/4.3.9
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Shen CY, 2014, NEUROCOMPUTING, V138, P61, DOI 10.1016/j.neucom.2013.09.053
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang HY, 2007, PATTERN RECOGN LETT, V28, P2352, DOI 10.1016/j.patrec.2007.07.015
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wei Z, 2017, PROC CVPR IEEE, P3947, DOI 10.1109/CVPR.2017.420
   Wen Y, 2017, J VIS COMMUN IMAGE R, V43, P119, DOI 10.1016/j.jvcir.2016.12.005
   Xia C., 2016, IEEE T NEURAL NETWOR, V27, P153
   Yu F., 2015, ARXIV
   Yu M, 2003, PROC CVPR IEEE, P656
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang YX, 2016, IEEE T GEOSCI REMOTE, V54, P1376, DOI 10.1109/TGRS.2015.2479299
   Zhao  R., 2016, P IEEE INT C COMP VI, P1265
   Zhao T, 2016, IEEE SIGNAL PROC LET, V23, P683, DOI 10.1109/LSP.2016.2544781
NR 48
TC 4
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 149
EP 157
DI 10.1016/j.jvcir.2019.02.026
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000018
DA 2024-07-18
ER

PT J
AU Du, QY
   Tian, B
AF Du, Qiu-Yue
   Tian, Bin
TI A low-cost, accurate strain measurement using multi-view amplification
   mechanism and visual polydimethylsiloxane lens
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Strain measurement; Amplification mechanism; Visual PDMS lens;
   Smart-phone microscope
ID DIGITAL IMAGE CORRELATION; FIBER; SENSORS
AB Strain sensors are widely applied in the industry requiring specific signal amplifiers and signal readers. However, the devices are unable to read data quickly and intuitively. The present study introduces a highly accurate, repeatable, mold-free strain sensor comprising of an amplification mechanism and a smart-phone microscope. Generation of the amplification mechanism using rapid prototyping especially 3D printing is summarized and evaluated. The sensitivity of the proposed amplifier is (39.47 +/- 1.34) for nylon and (37.74 +/- 2.41) for ABS. A visual polydimethylsiloxane (PDMS) lens with a focal length of 7.23 mm is attached to the iphone6 camera, performing as a microscope for image acquisition, which provides an equivalent focal length of 6.7 mm and a resolution of 0.691 mu m. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Du, Qiu-Yue; Tian, Bin] Beijing Technol & Business Univ, Sch Mat Sci & Mech Engn, Beijing 100048, Peoples R China.
C3 Beijing Technology & Business University
RP Du, QY (corresponding author), Beijing Technol & Business Univ, Sch Mat Sci & Mech Engn, Beijing 100048, Peoples R China.
EM duqiuyue@btbu.edu.cn
FU National Natural Science Foundation of China [51805009]; Scientific
   Research Common Program of Beijing Municipal Education Commission
   [SQKM201710011002]
FX This study is financially supported by The National Natural Science
   Foundation of China (Grant No 51805009), and the Scientific Research
   Common Program of Beijing Municipal Education Commission (Grant No
   SQKM201710011002).
CR Barrera D, 2015, J LIGHTWAVE TECHNOL, V33, P2445, DOI 10.1109/JLT.2014.2366556
   Cubillas AM, 2013, CHEM SOC REV, V42, P8629, DOI 10.1039/c3cs60128e
   Drissi-Habti M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040667
   Frutiger A, 2015, ADV MATER, V27, P2440, DOI 10.1002/adma.201500072
   Joe HE, 2018, INT J PR ENG MAN-GT, V5, P173
   Kang DJ, 2014, INT J PRECIS ENG MAN, V15, P883, DOI 10.1007/s12541-014-0412-z
   Kinet D, 2014, SENSORS-BASEL, V14, P7394, DOI 10.3390/s140407394
   Lai JX, 2016, J SENSORS, V2016, DOI 10.1155/2016/8658290
   Lee C., 2013, J COMPUT CIVIL ENG, V46, P718
   Motil A, 2016, OPT LASER TECHNOL, V78, P81, DOI 10.1016/j.optlastec.2015.09.013
   Mugendiran V, 2017, J MECH SCI TECHNOL, V31, P2943, DOI 10.1007/s12206-017-0537-y
   Niu Y., 2018, IEEE T COMPON PACK T, P1
   Qureshi KK, 2013, OPT COMMUN, V309, P68, DOI 10.1016/j.optcom.2013.06.057
   Ramos T, 2015, PROCEDIA ENGINEER, V114, P232, DOI 10.1016/j.proeng.2015.08.063
   Robins P, 2001, CEMENT CONCRETE RES, V31, P719, DOI 10.1016/S0008-8846(01)00465-3
   Rutkiewicz A., 2017, BALT GEOD C, P718
   Seika M, 1997, EXP MECH, V37, P169, DOI 10.1007/BF02317855
   Sójka L, 2015, OPT COMMUN, V344, P71, DOI 10.1016/j.optcom.2015.01.005
   Sung YL, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.4.047005
   Sutradhar A, 2014, COMPUT BIOL MED, V52, P8, DOI 10.1016/j.compbiomed.2014.06.002
   Vogel D.L. J.H., 1989, J. Materials Shaping Technology, V6, P205, DOI [DOI 10.1016/J.ASR.2005.04.064, 10.1007/BF02834735]
   Webb DJ, 2015, MEAS SCI TECHNOL, V26, DOI 10.1088/0957-0233/26/9/092004
   Woyessa G, 2016, OPT EXPRESS, V24, P1206, DOI 10.1364/OE.24.001206
   Xia ML, 2016, J IND MICROBIOL BIOT, V43, P451, DOI 10.1007/s10295-015-1729-z
   Zhang CC, 2016, SCI REP-UK, V6, DOI 10.1038/srep36469
NR 25
TC 0
Z9 0
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 380
EP 386
DI 10.1016/j.jvcir.2019.01.036
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600039
DA 2024-07-18
ER

PT J
AU Xu, YF
   Wang, HG
   Liu, X
   Sun's, WT
AF Xu, Yifeng
   Wang, Huigang
   Liu, Xing
   Sun's, Weitao
TI An improved multi-branch residual network based on random multiplier and
   adaptive cosine learning rate method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; Residual network; Overfitting; Deep leaning; Batch
   size; Learning rate
AB Deep residual networks have emerged as a leading technique showing the accuracy and excellent convergence performance. However, because of overfitting and the vanishing gradient problems, we cannot achieve better results by increasing the model parameters. In this study, we propose a novel architecture that has a multi-branch residual network. The shortcut branch of residual networks can ease off the vanishing gradient. The random function and the structure of a multi-branch network improve the fitting ability. The dropout function can weaken overfitting. The proposed method also adopts the adaptive cosine learning rate method and variate batch size to improve the test accuracy. Some experimental investigations are set up to explore the impact of the following factors on the performance: the sequence of the layers, random numbers and different batch sizes, etc. We report that the results achieve 2.63% and 14.2% Top-1 error on CIFAR-10 and CIFAR-100. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xu, Yifeng; Wang, Huigang; Liu, Xing; Sun's, Weitao] Northwestern Polytech Univ, Sch Marine Sci & Technol, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Wang, HG (corresponding author), Northwestern Polytech Univ, Sch Marine Sci & Technol, Xian 710072, Shaanxi, Peoples R China.
EM xuyifeng123@mail.nwpu.edu.cn; wanghg74@nwpu.edu.cn;
   xingliu86@nwpu.edu.cn; Sunwt1223@gmail.com
FU Natural Science Foundation of China [61571369, 61471299]; Fundamental
   Research Funds for the Central Universities [3102017jc06003,
   3102017OQD053]; Nature Science Foundation of Zhejiang Province
   [LY18F010018]
FX This work was supported by the Natural Science Foundation of China under
   the grant No. 61571369 and No. 61471299. It was supported by the
   Fundamental Research Funds for the Central Universities No.
   3102017jc06003 and No. 3102017OQD053. It was supported by the Nature
   Science Foundation of Zhejiang Province under the Grant No. LY18F010018.
CR [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2017, INT C LEARN REPR WOR
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], 2017, P 30 IEEE C COMP VIS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], DATA MIN DECIS TREES
   [Anonymous], 2016, ICLR
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2015, ICLR
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], 2017, P 2017 IEEE WINT C A
   [Anonymous], 2016, ABS16080
   [Anonymous], 2016, LECT NOTES COMPUTER
   [Anonymous], COMPUT SCI
   [Anonymous], LARGE SCALE KERNEL M
   Chen CLP, 2018, IEEE T NEUR NET LEAR, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee C.Y., 2015, AISTATS
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Loshchilov I., 2017, ICLR
   Simonyan K., 2014, 14091556 ARXIV
   Srivastava R. K, 2015, ICML WORKSH
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Zagoruyko S., 2016, BMVC, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 28
TC 7
Z9 9
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 363
EP 370
DI 10.1016/j.jvcir.2019.01.030
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600037
DA 2024-07-18
ER

PT J
AU Yuan, MY
   Yin, D
   Ding, JW
   Zhou, ZP
   Zhu, CF
   Zhang, R
   Wang, A
AF Yuan, Mingyue
   Yin, Dong
   Ding, Jinwen
   Zhou, Zhipeng
   Zhu, Chengfeng
   Zhang, Rui
   Wang, An
TI A multi-image Joint Re-ranking framework with updateable Image Pool for
   person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Image pool; Multi-shot; Re-ranking
ID PEOPLE REIDENTIFICATION; CLASSIFICATION
AB Real-world video surveillance has increasing demand for person re-identification. Existing multi-shot works usually aggregate single sample features by computing the average features or using time series model. The Multi-image Joint Re-ranking framework with updateable Image Pool that we are proposing will give a different approach. First, we defined the term 'Image Pool' to store image samples for each pedestrian. Next, the updating rules of Image Pool has been defined in order to optimize the representativeness of it. Second, we compute initial ranking lists of every sample in Image Pool, and propose the 'Multiple-image Joint Re-ranking' algorithm to aggregate initial ranking lists. We calculate the rank score of partial elements of initial ranking lists. In the end, we get final ranking list by ascending the order of the rank scores. We validated our re-ranking results on Market-1501, iLIDS-VID, PR1D-2011 and our ITSD datasets, and the results outperform other methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yuan, Mingyue; Yin, Dong; Ding, Jinwen; Zhou, Zhipeng; Zhu, Chengfeng; Zhang, Rui; Wang, An] USTC, Sch Informat Sci Technol, Hefei 230027, Anhui, Peoples R China.
   [Yuan, Mingyue; Yin, Dong; Zhou, Zhipeng; Zhu, Chengfeng; Zhang, Rui] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
   [Ding, Jinwen] USTC, Dept Mat Sci & Engn, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Yin, D (corresponding author), Univ Sci & Technol China, Sch Informat Sci Technol, CAS, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
EM yindong@ustc.edu.cn
RI Ding, Jinwen/F-8136-2010
OI Zhou, Zhipeng/0000-0002-1564-5800
FU National Natural Science Foundation of China (NSFC) [61671423, 61271403]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grant No. 61671423 and Grant No. 61271403.
CR [Anonymous], P 11 INT C DISTR SMA
   [Anonymous], ARXIV170307737
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, BMVC
   [Anonymous], 2010, Human identification based on gait
   [Anonymous], SVDNET PEDESTRIAN RE
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], ARXIV170700798
   [Anonymous], ARXIV171207257
   [Anonymous], ARXIV170802286
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], ARXIV160604404
   [Anonymous], ARXIV171000478
   [Anonymous], ARXIV PREPRINT ARXIV
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen W., 2017, P CVPR, V2
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   García J, 2016, J VIS COMMUN IMAGE R, V38, P115, DOI 10.1016/j.jvcir.2016.02.009
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong DNT, 2009, LECT NOTES COMPUT SC, V5716, P179, DOI 10.1007/978-3-642-04146-4_21
   Hamdoun O., 2008, DISTRIBUTED SMART CA, P1
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Karaman S, 2012, LECT NOTES COMPUT SC, V7583, P443, DOI 10.1007/978-3-642-33863-2_44
   Karanam S, 2017, IMAGE VISION COMPUT, V60, P75, DOI 10.1016/j.imavis.2016.11.015
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W., 2018, COMPUTER VISION PATT, V1, P2
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Nakajima C, 2003, PATTERN RECOGN, V36, P1997, DOI 10.1016/S0031-3203(03)00061-X
   Quinteros MA, 2016, INT J BIOMATER, V2016, DOI 10.1155/2016/5971047
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P529, DOI 10.1109/ICME.2006.262442
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yu S, 2017, J VIS COMMUN IMAGE R, V49, P192, DOI 10.1016/j.jvcir.2017.09.007
   Zajdel W, 2005, IEEE INT CONF ROBOT, P2081
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao Haiyu, 2017, P CVPR JUL, P1077
   Zheng L., ARXIV PREPRINT ARXIV
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
NR 69
TC 5
Z9 5
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 527
EP 536
DI 10.1016/j.jvcir.2019.01.041
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600055
DA 2024-07-18
ER

PT J
AU Ji, WP
   Wu, JJ
   Shi, GM
   Wan, WF
   Xie, XM
AF Ji, Weiping
   Wu, Jinjian
   Shi, Guangming
   Wan, Wenfei
   Xie, Xuemei
TI Blind image quality assessment with semantic information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No-reference image quality assessment; Human perception; Semantic
   network; Structural semantics; Spatial semantics
ID NEURAL-NETWORKS; FRAMEWORK; EFFICIENT
AB No-reference (NR) image quality assessment (IQA) aims to evaluate the quality of an image without reference image, which is greatly desired in the automatic visual signal processing system. Distortions degrade the visual contents and affect the semantics acquisition during the process of human perception. Although the existing methods evaluate the quality of images based on the structure, texture, or statistical characteristics, and deliver high quality prediction accuracy, they do not take the spatial semantics into account. From the perspective of human perception, distortions decrease the structural semantics that represent the structural information, and disturb the spatial semantics that describe the contents of images. Therefore, we attempt to measure the image quality by its degradation of semantics in an image. To extract the semantics of an image, a semantic network is proposed. The network contains convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) that correspond to structural semantics and spatial semantics, respectively. CNN can be regarded as a coarse imitation of human visual mechanism to obtain the structural information, and LSTM can express the contents of an image. Then, by measuring the degradations of different semantics on images, a novel NR IQA is introduced. The proposed approach is evaluated on the databases of LIVE, CSIQ TID2013, and LIVE multiply distorted database as well as LIVE in the wild image quality challenge database, and the results show superior performance to other state-of-the-art NR IQA methods. Furthermore, we explore the generalization capability of the proposed approach, and the experimental results indicate the proposed approach has a high robustness. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Ji, Weiping; Wu, Jinjian; Shi, Guangming; Wan, Wenfei; Xie, Xuemei] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Wu, JJ (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
EM jinjian.wu@mail.xidian.edu.cn; gmshi@xidian.edu.cn;
   wenfei.wan@stu.xidian.edu.cn; xmxie@mail.xidian.edu.cn
RI Wu, Jinjian/GQH-0222-2022
FU Ministry of Education [6141A020336]; NSF of China [61772388, 61632019,
   61621005, 61472301]; Young Star Science and Technology Project in Shanxi
   province [2018KJXX-030]
FX This work was partially supported by the Joint fund of the Ministry of
   Education (6141A020336), the NSF of China (Nos. 61772388, 61632019,
   61621005, 61472301), the Young Star Science and Technology Project (No.
   2018KJXX-030) in Shanxi province.
CR [Anonymous], PSYCCRITIQUES
   [Anonymous], 1988, LEARNING REPRESENTAT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], COMPUT LANGU
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], CONTENT BASED IMAGE
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], INT C LEARN REPR
   [Anonymous], 2014, NEURAL EVOL COMPUT
   [Anonymous], COMPUT VISION PATTER
   [Anonymous], SIGNALS SYSTEMS COMP
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Gabarda S, 2018, J VIS COMMUN IMAGE R, V52, P101, DOI 10.1016/j.jvcir.2018.02.008
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Guan JW, 2017, IEEE T MULTIMEDIA, V19, P2505, DOI 10.1109/TMM.2017.2703148
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Johnson GM, 2002, PICS 2002: IMAGE PROCESSING, IMAGE QUALITY, IMAGE CAPTURE, SYSTEMS CONFERENCE, PROCEEDINGS, P18
   Kim J, 2017, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2017.213
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Kingma D. P, 2015, International Conference on Learning Representations
   Kriegeskorte N, 2015, ANNU REV VIS SCI, V1, P417, DOI 10.1146/annurev-vision-082114-035447
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lindsay P., 1972, HUMAN INFORM PROCESS
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2016, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2016.184
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Peng Ye, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3089, DOI 10.1109/ICIP.2011.6116318
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saad M. A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3093, DOI 10.1109/ICIP.2011.6116319
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Simonyan K, 2015, IEEE INT C ICLR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2014, ADV NEUR IN, V27
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tang LJ, 2017, J VIS COMMUN IMAGE R, V49, P204, DOI 10.1016/j.jvcir.2017.09.010
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C, 2015, J VIS COMMUN IMAGE R, V28, P53, DOI 10.1016/j.jvcir.2015.01.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wen Y, 2017, J VIS COMMUN IMAGE R, V43, P119, DOI 10.1016/j.jvcir.2016.12.005
   Wu JJ, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P663, DOI 10.1109/ChinaSIP.2015.7230487
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xu K., 2015, COMPUTER SCI, P2048
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zeiler M.D., 2014, P EUR C COMP VIS ZUR, P818
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
NR 58
TC 13
Z9 14
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 195
EP 204
DI 10.1016/j.jvcir.2018.11.038
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100021
DA 2024-07-18
ER

PT J
AU Zhang, MJ
   Zhang, HX
   Li, JZ
   Wang, L
   Fang, YX
   Sun, JD
AF Zhang, Meijia
   Zhang, Huaxiang
   Li, Junzheng
   Wang, Li
   Fang, Yixian
   Sun, Jiande
TI Supervised graph regularization based cross media retrieval with intra
   and inter-class correlation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross media retrieval; Subspace learning; Supervised graph
   regularization
ID FUSION
AB With the rapid development of internet technology, mining and retrieving the information from internet accurately is an urgent problem, among which, cross media retrieval becomes a hot spot of current research. This paper proposes a cross media retrieval approach, which learns two couples of projections based on different retrieval tasks. We first learn a common subspace to project heterogeneous media data to the isomorphic subspace, to measure the similarity of the heterogeneous media data in the isomorphic subspace. Second, we build isomorphic and heterogeneous adjacent graphs to preserve the correlations of the cross media data. Then we combine the two processes together to learn a common subspace. We also consider intra-class and inter-class similarity of images or texts in the unified framework. Third, the L-2 norm is used to perform feature selection for different media data. Experimental results on three datasets demonstrate the effectiveness of the proposed approach. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Meijia; Zhang, Huaxiang; Wang, Li; Fang, Yixian; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang; Sun, Jiande] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Li, Junzheng] Shandong Management Univ, Informatizat Off, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University; Shandong
   Management University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@163.com
FU National Natural Science Foundation of China [61572298, 61772322,
   61402268, 61401260, 61601268]; Key Research and Development Foundation
   of Shandong Province [2016G GX101009, 2017GGX10117]; Natural Science
   Foundation of Shandong China [ZR2015PF006]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61572298, 61772322, 61402268, 61401260,
   61601268), the Key Research and Development Foundation of Shandong
   Province (Nos. 2016G GX101009, 2017GGX10117), and the Natural Science
   Foundation of Shandong China (No. ZR2015PF006).
CR [Anonymous], 2012, INT J COMPUT VIS
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], CLUSTER CANONICAL CO
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Belkin M., 2009, P ADV NEUR INF PROC, V14, P585
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huang X., 2018, ARXIV180303777
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lew M. S., 2016, ACM T MULTIMEDIA COM, V2
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Shang F, 2018, J ADV COMPUT INTELL, V22, P280, DOI 10.20965/jaciii.2018.p0280
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang L, 2018, J VIS COMMUN IMAGE R, V54, P213, DOI 10.1016/j.jvcir.2018.05.006
   Wang L, 2018, IEEE ACCESS, V6, P27091, DOI 10.1109/ACCESS.2018.2831675
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Wu F, 2007, P IEEE INT C IM PROC, P1465
   Wu JL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P917, DOI 10.1145/3077136.3080678
   Yan J., 2017, IEEE T MULTIMEDIA, V6, P1, DOI DOI 10.1063/1.5006865
   Yu E., 2018, MULTIMED TOOLS APPL, P1
   Yu E, 2020, PATTERN RECOGN LETT, V130, P165, DOI 10.1016/j.patrec.2018.08.012
   Zhai X., 2013, CROSS MEDIA RETRIEVA
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang HX, 2014, NEUROCOMPUTING, V139, P289, DOI 10.1016/j.neucom.2014.02.030
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
   Zhang HX, 2009, KNOWL-BASED SYST, V22, P477, DOI 10.1016/j.knosys.2009.06.009
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhou P., 2015, P 2015 SIAM INT C DA
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 44
TC 17
Z9 17
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 1
EP 11
DI 10.1016/j.jvcir.2018.11.025
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100001
DA 2024-07-18
ER

PT J
AU Kabirirad, S
   Eslami, Z
AF Kabirirad, Saeideh
   Eslami, Ziba
TI A (<i>t</i>, <i>n</i>)-multi secret image sharing scheme based on
   Boolean operations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE (t, n)-secret image sharing scheme; Multi-secret image sharing; Boolean
   operations; Security
AB In (t, n)-multi secret image sharing (MSIS) schemes, a number of secret images are shared among n users so that participation of at least t of them is needed to recover the shared images. Due to the high volume of images and computing complexity of secret sharing schemes, recent Boolean-based approaches are highly desirable. Unfortunately, to the best of our knowledge, existing literature on Boolean-based MSIS schemes only supports two cases: (2, n) and (n, n). In (n, n)-schemes, we lose fault tolerancy such that in the absence of even one share, secret images can not be recovered. On the other hand, (2, n)-MSIS seems to be quite restrictive for the wide range of applications that might occur in practice. It is therefore a challenging problem to propose a Boolean-based (t, n)-MSIS for t not equal 2, n. The aim of this paper is to solve this problem. We further provide formal proofs of security as well as comparison with existing literature. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Kabirirad, Saeideh; Eslami, Ziba] Shahid Beheshti Univ, GC, Dept Data & Comp Sci, Tehran, Iran.
C3 Shahid Beheshti University
RP Eslami, Z (corresponding author), Shahid Beheshti Univ, GC, Dept Data & Comp Sci, Tehran, Iran.
EM s_kabirirad@sbu.ac.ir; eslami@sbu.ac.ir
RI Kabirirad, Saeideh/AAD-6386-2022
OI Kabirirad, Saeideh/0000-0003-1503-138X
CR Alvarez G, 2008, INFORM SCIENCES, V178, P4382, DOI 10.1016/j.ins.2008.07.010
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Bertoni Guido., 2011, Submission to NIST (Round 3), V6, P16
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Dworkin M. J., 2015, TECH REP
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Hua W, 2017, MULTIMED TOOLS APPL, V76, P7087, DOI 10.1007/s11042-016-3364-8
   Kanso A, 2016, MULTIMED TOOLS APPL, V76, P1
   Kelsey John., 2016, NIST Special Publication, V800, P185
   Li M, 2017, CHINESE J ELECTRON, V26, P313, DOI 10.1049/cje.2017.01.026
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Mashhadi S, 2016, SECUR COMMUN NETW, V9, P4495, DOI 10.1002/sec.1641
   Meghrajani YK, 2016, IEEE SIGNAL PROC LET, V23, P1429, DOI 10.1109/LSP.2016.2599076
   Naor M., P EUROCRYPT 94 BERL, V950
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Rukhin A., 2010, NIST Special Publication, V800, P22
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ting-Yi Chang, 2005, Operating Systems Review, V39, P48, DOI 10.1145/1044552.1044557
   Wafy M.H., 2016, INFORM SECUR J GLOB, P1
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang DS, 2011, INFORM SCIENCES, V181, P2189, DOI 10.1016/j.ins.2011.01.019
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
NR 30
TC 20
Z9 20
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 39
EP 47
DI 10.1016/j.jvcir.2018.10.014
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400006
DA 2024-07-18
ER

PT J
AU Li, XM
   Xu, GQ
   Tang, MH
AF Li, XiaoMing
   Xu, Guangquan
   Tang, Minghu
TI Community detection for multi-layer social network based on local random
   walk
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-layer social network; Local community detection; Trust;
   Multi-layer local random walk
AB With the fast development of information network, the scale of social network has become very significant, and it has become more difficult to obtain the information of entire network. In addition, because current mining method for complicated network community utilizes the information of node link or property, which cannot effectively detect the community with dense member links and highly similar properties. As a result, most current algorithms are impractical for online social network with large scale, and we propose a community detection algorithm for multi-layer social network based on local random walk (MRLCD); this algorithm determines the core node based on the repeatability of multi-layer nodes. It expands from a core node, has local random walk in multi-layer network, identifies and controls the random walk scope of node based on the intra-layer and interlayer trust. During the walk process, the clustering coefficient of nodes to be combined is comprehensively compared to further complete a local community search, and the optimal local community search is obtained through multiple iterations. Finally, the multi-layer modularity is used as the indicator for measurement and evaluation of algorithm performance, and its performance is compared with other network clustering algorithms such as GL, LART and PMM through four actual multi-layer network datasets. The MRLCD algorithm can autonomously explore the local community structure of given node, and effectively improve the stability and accuracy for local community detection in multi-layer social network. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Li, XiaoMing; Xu, Guangquan; Tang, Minghu] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
C3 Tianjin University
RP Li, XM (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
EM lxm696@tju.edu.cn
OI Li, XiaoMing/0000-0002-9956-1793
FU Major Project of Fundamental Research of Xinjiang Corps [2016AC015];
   Applied Basic Research Project of Qinghai Province [2018-ZJ-707];
   National Social Science Fund of China [14ZDB153]; National Science
   Foundation of China [61572355]
FX This word was by the Major Project of Fundamental Research of Xinjiang
   Corps [2016AC015], the Applied Basic Research Project of Qinghai
   Province [No: 2018-ZJ-707], National Social Science Fund of China
   [14ZDB153], and the National Science Foundation of China [61572355].
CR [Anonymous], DASFAA WORKSH
   Bo Yang, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P127, DOI 10.1109/WIIAT.2008.70
   Boccaletti S, 2014, PHYS REP, V544, P1, DOI 10.1016/j.physrep.2014.07.001
   Bourqui R, 2016, IEEE PAC VIS SYMP, P184, DOI 10.1109/PACIFICVIS.2016.7465267
   Buldyrev SV, 2010, NATURE, V464, P1025, DOI 10.1038/nature08932
   Cardillo A, 2013, SCI REP-UK, V3, DOI 10.1038/srep01344
   Chang E., 2006, TRUST REPUTATION SER
   D'Agostino G., 2014, SCALA NETWORKS NETWO
   De Domenico M., 2014, COMPUT SCI, V5, P1
   De Domenico M, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7868
   Delvenne JC, 2010, P NATL ACAD SCI USA, V107, P12755, DOI 10.1073/pnas.0903215107
   Dongen S., 2000, A cluster algorithm for graphs
   Evans TS, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.016105
   Flint J. E., 2015, AFR HIST STUD, V3, P149
   Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gemmetto V, 2015, SCI REP-UK, V5, DOI 10.1038/srep09120
   Guerrero M, 2017, NEUROCOMPUTING, V266, P101, DOI 10.1016/j.neucom.2017.05.029
   Interdonato R, 2017, DATA MIN KNOWL DISC, V31, P1444, DOI 10.1007/s10618-017-0525-y
   KRACKHARDT D, 1987, SOC NETWORKS, V9, P109, DOI 10.1016/0378-8733(87)90009-8
   Kuncheva Z, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1308, DOI 10.1145/2808797.2808852
   Lee Kyu Min, 2012, NEW J PHYS, V14
   Li X. M., 2017, INT C COLL COMP NETW, P416
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Magnani M., 2013, CoRR, abs/1303.4986
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Newman MEJ, 2005, SOC NETWORKS, V27, P39, DOI 10.1016/j.socnet.2004.11.009
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Nicosia V, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.042807
   Pearson K., 1893, Nature, V48, P615
   Pei J., 2000, P 2000 ACM SIGMOD IN, V4, P21
   Piccardi C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027028
   Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101
   Schaub MT, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032210
   Si A. L, 2011, STRUCTURE DYNAMICS N
   Solá Conde L, 2013, CHAOS, V23, DOI 10.1063/1.4818544
   Solé-Ribalta A, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.108701
   Tang L, 2009, IEEE DATA MINING, P503, DOI 10.1109/ICDM.2009.20
   Vijayaraghavan VS, 2015, SCI REP-UK, V5, DOI 10.1038/srep15142
   Wang WJ, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/6310827
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Whitaker M. L. A., 1970, POLITICS TRADITION C, P149
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   WOLFE AW, 1963, AM ANTHROPOL, V65, P137, DOI 10.1525/aa.1963.65.1.02a00120
   Zhou HJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.041908
   Zhou HJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.061901
NR 46
TC 18
Z9 21
U1 3
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 91
EP 98
DI 10.1016/j.jvcir.2018.10.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HD6XU
UT WOS:000452694400012
DA 2024-07-18
ER

PT J
AU Lian, S
   Luo, ZM
   Zhong, Z
   Lin, X
   Su, SZ
   Li, SZ
AF Lian, Sheng
   Luo, Zhiming
   Zhong, Zhun
   Lin, Xiang
   Su, Songzhi
   Li, Shaozi
TI Attention guided U-Net for accurate iris segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Iris segmentation; U-Net; Attention
ID RECOGNITION; FEATURES
AB Iris segmentation is a critical step for improving the accuracy of iris recognition, as well as for medical concerns. Existing methods generally use whole eye images as input for network learning, which do not consider the geometric constrain that iris only occur in a specific area in the eye. As a result, such methods can be easily affected by irrelevant noisy pixels outside iris region. In order to address this problem, we propose the ATTention U-Net (Arf-UNet) which guides the model to learn more discriminative features for separating the iris and non-iris pixels. The ATT-UNet firstly regress a bounding box of the potential iris region and generated an attention mask. Then, the mask is used as a weighted function to merge with discriminative feature maps in the model, making segmentation model pay more attention to iris region. We implement our approach on UBIRIS.v2 and CASIA.IrisV4-distance, and achieve mean error rates of 0.76% and 0.38%, respectively. Experimental results show that our method achieves consistent improvement in both visible wavelength and near-infrared iris images with challenging scenery, and surpass other representative iris segmentation approaches. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Lian, Sheng; Zhong, Zhun; Su, Songzhi; Li, Shaozi] Xiamen Univ, Dept Cognit Sci, Xiamen, Peoples R China.
   [Luo, Zhiming] Xiamen Univ, Postdoc Ctr Informat & Commun Engn, Xiamen, Peoples R China.
   [Lin, Xiang] Xiamen Univ, Fujian Prov Key Lab Ophthalmol & Visual Sci, Xiamen, Peoples R China.
   [Lin, Xiang] Xiamen Univ, Inst Eye, Xiamen, Peoples R China.
C3 Xiamen University; Xiamen University; Xiamen University; Xiamen
   University
RP Li, SZ (corresponding author), Xiamen Univ, Dept Cognit Sci, Xiamen, Peoples R China.
EM szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010; Lian, Sheng/AAX-9397-2021; Huang,
   Jingyi/KCY-2239-2024
OI Luo, Zhiming/0000-0002-3411-9582; Lian, Sheng/0000-0003-2967-3041
FU National Natural Science Foundation of China [61572409, U1705286,
   61571188]; Fujian Province 2011 Collaborative Innovation Center of TCM
   Health Management and Collaborative Innovation Center of Chinese Oolong
   Tea Industry Collaborative Innovation Center (2011) of Fujian Province;
   Fund for Integration of Cloud Computing and Big Data, Innovation of
   Science and Education
FX This work is supported by the National Natural Science Foundation of
   China (No. 61572409, No. U1705286 & No. 61571188), Fujian Province 2011
   Collaborative Innovation Center of TCM Health Management and
   Collaborative Innovation Center of Chinese Oolong Tea Industry
   Collaborative Innovation Center (2011) of Fujian Province, Fund for
   Integration of Cloud Computing and Big Data, Innovation of Science and
   Education.
CR [Anonymous], 2016, Handbook of iris recognition
   [Anonymous], 2018, DOI IEEE ACCESS, DOI [DOI 10.1109/AC, DOI 10.1109/ACCESS.2017.2784352]
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Bazrafkan S., 2017, END END DEEP NEURAL
   Chen JX, 2016, IEEE T INF FOREN SEC, V11, P1476, DOI 10.1109/TIFS.2016.2535901
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Ciresan D., 2012, NIPS, P2843
   Cireundefinedan D.C., 2011, IJCAI INT JOINT C AR, VTwo, P1237, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-210
   Daugman J.G., 1994, U.S. Patent, Patent No. 5291560
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fathi A, 2016, J VIS COMMUN IMAGE R, V38, P65, DOI 10.1016/j.jvcir.2016.02.010
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   He F, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023005
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Jain AK, 2005, LECT NOTES COMPUT SC, V3540, P1
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kirsch K., 2009, ENCY BIOMETRICS, P11, DOI [10.1007/978-0-387-73003-5{\\_}253, DOI 10.1007/978-0-387-73003-5]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta R, 2017, I S BIOMED IMAGING, P437, DOI 10.1109/ISBI.2017.7950555
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nianfeng Liu, 2016, 2016 International Conference on Biometrics (ICB), DOI 10.1109/ICB.2016.7550055
   Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Proenca H., 2007, P 2007 FIRST IEEE IN, P1, DOI [DOI 10.1109/BTAS.2007.4401910, 10.1109/BTAS.2007.4401910]
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1502, DOI 10.1109/TPAMI.2009.140
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Proença H, 2010, IMAGE VISION COMPUT, V28, P202, DOI 10.1016/j.imavis.2009.03.003
   Pundlik Shrinivas J., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563108
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shah S, 2009, IEEE T INF FOREN SEC, V4, P824, DOI 10.1109/TIFS.2009.2033225
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Tan CW, 2012, IEEE T IMAGE PROCESS, V21, P4068, DOI 10.1109/TIP.2012.2199125
   Tan TN, 2010, IMAGE VISION COMPUT, V28, P223, DOI 10.1016/j.imavis.2009.05.008
   Uhl A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P283, DOI 10.1109/ICB.2012.6199821
   Wildes RP, 1996, MACH VISION APPL, V9, P1, DOI 10.1007/BF01246633
   Yu S, 2017, J VIS COMMUN IMAGE R, V49, P192, DOI 10.1016/j.jvcir.2017.09.007
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 44
TC 97
Z9 108
U1 3
U2 89
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 296
EP 304
DI 10.1016/j.jvcir.2018.10.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500029
DA 2024-07-18
ER

PT J
AU Shi, GM
   Li, RD
   Li, F
   Niu, Y
   Yang, LL
AF Shi, Guangming
   Li, Ruodai
   Li, Fu
   Niu, Yi
   Yang, Lili
TI Depth sensing with coding-free pattern based on topological constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Coding-free; Depth sensing; Structured light; Topological constraint;
   Dynamic programming
ID STRUCTURED-LIGHT; ACQUISITION; PROFILOMETRY; MAXIMUM
AB Structured light depth sensing with a single-shot pattern is widely employed to capture depth maps for dynamic scenes. For conventional structured light techniques, the projected pattern has to be coded delicately in regards to color, shape, and intensity, in order to assign each pixel with a unique label. However, using such a complicated pattern is a double-edged sword, as although it is effective in labelling pixels, it is also sensitive to environmental noise such as: ambient illumination, textures, uneven albedos, or colors of objects in a scene. In contrast, a coding-free pattern is simply constructed and also insensitive to various environmental noise. Therefore, the coding-free pattern method is capable of robustly sensing the depth for complex scenes. The main challenge in coding-free depth sensing is the 'correspondence retrieval' between the projected and captured pattern (i.e. matching pixels between the projected and captured pattern). In this study, we focused on evaluating the correspondence retrieval in a coding-free binary grid pattern. A graph based topological labelling (GBTL) algorithm is proposed to determine the topological coordinates of the intersections of the grid. Then we retrieved the correspondence by using the topology of the grid and the epipolar constraint. We also demonstrated the upper bounds of depth variance by employing the proposed method. The proposed technique alleviates many of the limitations faced with traditional correspondence retrieval. Experimental results showed that the proposed technique performed better (i.e. in terms of precision) than the popular RGB-D cameras Kinect v1 and Kinect v2. Compared with the traditional single-shot techniques, which require complicated patterns, the proposed technique significantly improved the robustness and ease of work, while achieving comparable precision. Additionally, this proposed technique could also be used for both the binary coding-free and the traditional chromatic grid patterns.
C1 [Shi, Guangming; Li, Ruodai; Li, Fu; Niu, Yi; Yang, Lili] Xidian Univ, Sch Artificial Intelligence, Chinese Minist Educ, Key Lab Intelligent Percept & Image Understanding, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Li, F (corresponding author), Xidian Univ, Sch Artificial Intelligence, Chinese Minist Educ, Key Lab Intelligent Percept & Image Understanding, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
EM fuli@mail.xidian.edu.cn
RI Wang, Chen/JZE-6385-2024
FU NSFC [61672404, 61632019, 61751310, 61472301, 61301288, 61572387];
   Fundamental Research Funds of the Central Universities of China
   [SA-ZD160203, JBG160228, JBG160213, K5051399020, K5051202050]; Basic
   Scientific Research program [JCKY2017204B102]; Natural Science Basic
   Research Plan in Shaanxi Province of China [2016ZDJC-08]
FX We thank Dr. Mehler from University of Alberta, and anonymous reviewers
   for their useful comments and language editing which have greatly
   improved the manuscript. This work was supported in part by the NSFC
   (No. 61672404, 61632019, 61751310, 61472301, 61301288 and 61572387), the
   Fundamental Research Funds of the Central Universities of China
   (No.SA-ZD160203, JBG160228, JBG160213 K5051399020 and K5051202050),
   Basic Scientific Research program (No. JCKY2017204B102), and Natural
   Science Basic Research Plan in Shaanxi Province of China (Program No.
   2016ZDJC-08).
CR Albitar C, 2007, IEEE I CONF COMP VIS, P1207
   Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   Desjardins D, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P216, DOI 10.1109/CRV.2007.22
   Fong P., 2005, CVPR WORKSH, P101
   Furukawa R., 2009, IPSJ T COMPUTER VISI, V1, P139
   GRIFFIN PM, 1992, PATTERN RECOGN, V25, P609, DOI 10.1016/0031-3203(92)90078-W
   Gupta M, 2012, PROC CVPR IEEE, P813, DOI 10.1109/CVPR.2012.6247753
   HOSHINO H, 1994, 10TH ANNIVERSARY, IMTC/94 - ADVANCED TECHNOLOGIES IN I & M, CONFERENCE PROCEEDINGS, VOLS 1-3 AND SUPPLEMENT, P1329
   Lavoie P, 2004, IEEE T INSTRUM MEAS, V53, P437, DOI 10.1109/TIM.2004.823320
   Li F., 2017, IEEE J-STSP, V9, P384
   Li Q, 2014, APPL OPTICS, V53, P7095, DOI 10.1364/AO.53.007095
   Li RD, 2017, OPT EXPRESS, V25, P25332, DOI 10.1364/OE.25.025332
   Maurice Xavier, 2011, 2011 IEEE International Conference on Robotics and Automation, P5301
   Miyasaka T., 2000, INT ARCH PHOTOGRAMME, V33, P547
   MONKS TP, 1992, IEE CONF PUBL, V354, P327
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Pagès J, 2005, IMAGE VISION COMPUT, V23, P707, DOI 10.1016/j.imavis.2005.05.007
   Pagès J, 2006, IEEE INT CONF ROBOT, P4118, DOI 10.1109/ROBOT.2006.1642335
   Sagawa R, 2014, IEEE T PATTERN ANAL, V36, P1733, DOI 10.1109/TPAMI.2014.2300490
   Sagawa R, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P363, DOI 10.1109/3DIMPVT.2012.41
   Sagawa R, 2009, IEEE I CONF COMP VIS, P1779, DOI 10.1109/ICCV.2009.5459397
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Salvi J, 1998, PATTERN RECOGN LETT, V19, P1055, DOI 10.1016/S0167-8655(98)00085-3
   Shi GM, 2015, APPL OPTICS, V54, P3796, DOI 10.1364/AO.54.003796
   Song Z, 2010, IEEE T PATTERN ANAL, V32, P1770, DOI 10.1109/TPAMI.2009.192
   Song Z, 2010, PATTERN RECOGN, V43, P3560, DOI 10.1016/j.patcog.2010.05.008
   SRINIVASAN V, 1984, APPL OPTICS, V23, P3105, DOI 10.1364/AO.23.003105
   TAKEDA M, 1983, APPL OPTICS, V22, P3977, DOI 10.1364/AO.22.003977
   Trobina M., 1995, Error model of a coded-light range sensor
   Ulusoy Ali Osman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1786, DOI 10.1109/ICCVW.2009.5457499
   VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402
   Weiss TG, 2007, GLOB INST, P1
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
   Zhang S., 2010, HIGH RESOLUTION HIGH
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 39
TC 7
Z9 7
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 229
EP 242
DI 10.1016/j.jvcir.2018.06.009
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100020
DA 2024-07-18
ER

PT J
AU Zheng, N
   Guo, X
   Tie, Y
   Dong, N
   Qi, L
   Guan, L
AF Zheng, Ning
   Guo, Xin
   Tie, Yun
   Dong, Nan
   Qi, Lin
   Guan, Ling
TI Incremental generalized multiple maximum scatter difference with
   applications to feature extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature extraction; Generalized multiple maximum scatter difference;
   Incremental GMMSD
ID LINEAR DISCRIMINANT-ANALYSIS; EIGENFACES; CRITERION
AB In this paper, we propose a new algorithm to implement the generalized multiple maximum scatter difference (GMMSD). Due to enhanced features of this algorithm over the original GMMSD, we named it GMMSD + . By employing a different projection from both the range of the between-class scatter matrix and the null space of the within-class scatter matrix, GMMSD + can divide the centroid vector of each class into two components: intrinsic common component (ICC) and discriminant difference component (DCC), and then automatically discards ICC which contains little discriminative information, while keeping DCC which contains the true discriminative power. Next, we introduce a practical implementation of GMMSD +, which can accurately and efficiently update the discriminant vectors with new training samples incrementally, eliminating the complete re-computation of the training process. Our experiments demonstrate that incremental version of GMMSD + (IGMMSD +) eliminates the complete re-computation of the training process when new training samples are presented, leading to significantly reduced computational cost.
C1 [Zheng, Ning] Zhengzhou Univ Aeronaut, Sch Elect & Commun Engn, Zhengzhou, Henan, Peoples R China.
   [Guo, Xin; Tie, Yun; Qi, Lin] Zhengzhou Univ, Sch Informat & Engn, Zhengzhou, Henan, Peoples R China.
   [Dong, Nan; Guan, Ling] Ryerson Univ, Elect & Comp Engn, Toronto, ON, Canada.
C3 Zhengzhou University of Aeronautics; Zhengzhou University; Toronto
   Metropolitan University
RP Tie, Y (corresponding author), Zhengzhou Univ, Sch Informat & Engn, Zhengzhou, Henan, Peoples R China.
EM zhengning34@hotmail.com; guoxin19880806@163.com; ieytie@zzu.edu.cn;
   gdongnan@gmail.com; ielqi@zzu.edu.cn; lguan@ee.ryerson.ca
RI Ning, Zheng/AGZ-2040-2022; NING, ZHENG/A-5714-2013
FU Canada Research Chair Program; Key project of technology department in
   Henan Province [172102210080, 172102410067, 18A510018, 18A510019];
   Science and Technology Project of Henan Province [182102210110,
   182102210111]
FX This work is partially supported by the Canada Research Chair Program,
   Key project of technology department in Henan Province (No.
   172102210080, No. 172102410067, No.18A510018, No.18A510019), Science and
   Technology Project of Henan Province (No.182102210110, No.182102210111)
CR [Anonymous], 2012, MATRIX COMPUTATIONS
   [Anonymous], 24 CVC
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P 16 INT C PATT REC
   [Anonymous], INDEPENDENT COMPONEN
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gashler M, 2011, IEEE T SYST MAN CY B, V41, P1458, DOI 10.1109/TSMCB.2011.2151187
   Georghiades A., 2002, YALE U FACE DATABASE
   Hall P. M., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P286
   Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760
   Kim TT, 2007, INT CONF ACOUST SPEE, P1
   Liu J, 2008, PATTERN RECOGN, V41, P102, DOI 10.1016/j.patcog.2007.06.001
   Liu LP, 2009, IEEE DATA MINING, P298, DOI 10.1109/ICDM.2009.78
   Lu GF, 2012, PATTERN RECOGN, V45, P2510, DOI 10.1016/j.patcog.2012.01.018
   Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Song FX, 2007, IEEE T SYST MAN CY B, V37, P1599, DOI 10.1109/TSMCB.2007.906579
   Song F, 2007, PATTERN ANAL APPL, V10, P165, DOI 10.1007/s10044-006-0057-3
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Weng J., 2003, IEEE T PATTERN ANAL, V25
   Yan J., 2004, PROC 10 ACM SIGKDD, P725
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Ye JP, 2005, IEEE T KNOWL DATA EN, V17, P1208, DOI 10.1109/TKDE.2005.148
   Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929, DOI 10.1109/TPAMI.2005.110
   Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37
   Zhang TH, 2010, IEEE T SYST MAN CY B, V40, P253, DOI 10.1109/TSMCB.2009.2027473
   Zhao HT, 2008, IEEE T SYST MAN CY B, V38, P210, DOI 10.1109/TSMCB.2007.908870
   Zhao HT, 2004, I C CONT AUTOMAT ROB, P687
   Zheng N, 2014, J VIS COMMUN IMAGE R, V25, P1460, DOI 10.1016/j.jvcir.2014.04.009
NR 32
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 67
EP 79
DI 10.1016/j.jvcir.2018.04.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100007
DA 2024-07-18
ER

PT J
AU Iakovidou, C
   Zampoglou, M
   Papadopoulos, S
   Kompatsiaris, Y
AF Iakovidou, Chryssanthi
   Zampoglou, Markos
   Papadopoulos, Symeon
   Kompatsiaris, Yiannis
TI Content-aware detection of JPEG grid inconsistencies for intuitive image
   forensics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; JPEG artifacts; Forgery localization; Splicing
ID EXPOSING DIGITAL FORGERIES; LOCALIZATION
AB The paper proposes a novel method for detecting indicators of image forgery by locating grid alignment abnormalities in JPEG compressed image bitmaps. The method evaluates multiple grid positions with respect to a fitting function, and areas of lower contribution are identified as grid discontinuities and possibly tampered areas. An image segmentation step is introduced to differentiate between discontinuities produced by tampering and those that are attributed to image content, making the output maps easier to interpret by suppressing non-relevant activations. Our evaluations, on both synthetically produced datasets and real world tampering cases against seven methods from the literature, highlight the effectiveness of the proposed method in its ability to produce output maps that are clear and readable, and which can achieve successful detections on cases where other algorithms fail.
C1 [Iakovidou, Chryssanthi; Zampoglou, Markos; Papadopoulos, Symeon; Kompatsiaris, Yiannis] Ctr Res & Technol Hellas, Informat Technol Inst, 6km Harilaou Thermi Rd, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Iakovidou, C (corresponding author), Ctr Res & Technol Hellas, Informat Technol Inst, 6km Harilaou Thermi Rd, Thessaloniki 57001, Greece.
EM c.iakovidou@iti.gr; markzampoglou@iti.gr; papadop@iti.gr; ikom@iti.gr
RI Zampoglou, Markos/AAP-1579-2021; Papadopoulos, Symeon/AET-0683-2022;
   Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Papadopoulos,
   Symeon/0000-0002-5441-7341
FU REVEAL project; InVID project; TENSOR project; European Commission
   [FP7-610928, H2020-687786, H2020-700024]
FX This work has been supported by the REVEAL, InVID and TENSOR projects,
   partially funded by the European Commission under contract No.
   FP7-610928, H2020-687786 and H2020-700024 respectively.
CR Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2016, 2016 IEEE INT WORKSH, DOI DOI 10.1109/WIFS.2016.7823911
   [Anonymous], 2017, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-016-3855-7
   [Anonymous], 2016, 2016 IEEE INT WORKSH
   [Anonymous], TR2006579 DARTM COLL
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Fan JY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1044, DOI 10.1109/ICDSP.2015.7252037
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fontani M, 2013, IEEE T INF FOREN SEC, V8, P593, DOI 10.1109/TIFS.2013.2248727
   Gholap S., 2008, TENCON 2008 - 2008 IEEE Region 10 Conference, P1
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Su YT, 2017, J VIS COMMUN IMAGE R, V48, P480, DOI 10.1016/j.jvcir.2017.01.009
   Vonikakis V, 2006, BIOL CYBERN, V94, P192, DOI 10.1007/s00422-005-0040-x
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zampoglou M., 2016, 10 INT AAAI C WEB SO
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
NR 35
TC 35
Z9 37
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 155
EP 170
DI 10.1016/j.jvcir.2018.05.011
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU El Mezeni, DM
   Saranovac, LV
AF El Mezeni, Dragomir M.
   Saranovac, Lazar V.
TI Enhanced local tone mapping for detail preserving reproduction of high
   dynamic range images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID QUALITY ASSESSMENT; CONTRAST; RETINEX; COMPRESSION; OPERATORS
AB Enhanced Local Tone Mapping (ELTM) is a flexible tone mapping operator designed to provide a good global and local contrast simultaneously over various test scenes. Also, it has intuitive and decoupled tuning interface, providing the user with full control over final image appearance. ELTM is based on detail/base layer decomposition compressing the base plane in both linear and logarithmic domain. This provides robustness to ELTM, while modified tone compression function provides good local contrast. Results were validated using set of images with various content, brightness and resolution. In this testing ELTM performed as the best tone mapping operator, among 7 state-of-the-art global and local tone mapping operators. Even better overall results are achieved by using proposed brightness control, to handle extreme scenes. Robustness and flexibility to achieve desired appearance makes ELTM suitable for applications where user experience is the primary concern as is the case with consumer electronics products.
C1 [El Mezeni, Dragomir M.; Saranovac, Lazar V.] Univ Belgrade, Sch Elect Engn, Dept Elect, Belgrade 11000, Serbia.
C3 University of Belgrade
RP El Mezeni, DM (corresponding author), Univ Belgrade, Sch Elect Engn, Dept Elect, Belgrade 11000, Serbia.
EM elmezeni@etf.rs
RI Mezeni, Dragomir El/AAT-5893-2020; Saranovac, Lazar/Q-9482-2019
OI Mezeni, Dragomir El/0000-0001-9273-2142; Saranovac,
   Lazar/0000-0002-6823-1855
CR Ahn H, 2013, IEEE ICCE, P153, DOI 10.1109/ICCE.2013.6486837
   Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Boschetti A, 2010, IEEE INT CON MULTI, P1130, DOI 10.1109/ICME.2010.5583305
   Byung Ju Lee, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P125, DOI 10.1109/ICCE.2014.6775937
   Cadik M., 2005, EVALUATION TONE MAPP
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fairchild M.D., 2008, HDR photographic survey
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gu B, 2013, IEEE T IMAGE PROCESS, V22, P70, DOI 10.1109/TIP.2012.2214047
   Gu K., IEEE T CIRCUITS SYST, V25
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Johnson GM, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P36
   Kim K, 2011, IEEE T CONSUM ELECTR, V57, P1807, DOI 10.1109/TCE.2011.6131157
   Krasula L, 2017, IEEE J-STSP, V11, P64, DOI 10.1109/JSTSP.2016.2637168
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Kundu D, 2016, IEEE IMAGE PROC, P96, DOI 10.1109/ICIP.2016.7532326
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Larson G. W., IEEE T VISUALIZ COMP, V3
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Ma KD, 2015, IEEE T IMAGE PROCESS, V24, P3086, DOI [10.1109/TIP.2015.2436340, 10.1109/TIP.2015.2456638]
   Mantiuk R., 2006, ACM T APPL PERCEPT, V3, P3
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Monobe Y, 2005, IEEE T CONSUM ELECTR, V51, P1, DOI 10.1109/TCE.2005.1405691
   Nafchi HZ, 2015, IEEE SIGNAL PROC LET, V22, P1026, DOI 10.1109/LSP.2014.2381458
   Nasrinpour HR, 2015, IEEE IMAGE PROC, P4947, DOI 10.1109/ICIP.2015.7351748
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Pattanaik S. N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P287, DOI 10.1145/280814.280922
   Qiao MT, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013010
   Qiu TS, 2013, IEEE T IMAGE PROCESS, V22, P80, DOI 10.1109/TIP.2012.2214052
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Schlick C., 1995, Photorealistic Rendering Techniques, P7
   Shimoyama S, 2009, IEEE IMAGE PROC, P3153, DOI 10.1109/ICIP.2009.5414418
   STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782
   Tan L., 2014, ADV IMAGE GRAPHICS T, P40
   Tumblin J, 1999, COMP GRAPH, P83, DOI 10.1145/311535.311544
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yeganeh H., 2012, SUBJECT RATED IMAGE
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yoshida A, 2005, PROC SPIE, V5666, P192, DOI 10.1117/12.587782
   Zhang E., 2015, Applied Mathematics & Information Sciences, V9, P411
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
NR 51
TC 16
Z9 16
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 122
EP 133
DI 10.1016/j.jvcir.2018.03.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800012
DA 2024-07-18
ER

PT J
AU Liu, YF
   Yang, L
   Xu, M
   Wang, ZL
AF Liu, Yufan
   Yang, Li
   Xu, Mai
   Wang, Zulin
TI Rate control schemes for panoramic video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Virtual reality; Panoramic video; Rate control; Video coding
ID BIT ALLOCATION; REGION; MODEL
AB The popularity of multi-view panoramic video has been considerably increased for producing Virtual Reality (VR) content, due to its immersive visual experience. We argue in this paper that PSNR is less effective in assessing objective visual quality of compressed panoramic video than Sphere-based PSNR (S-PNSR), in which sphere-to-plain mapping of panoramic videos is considered. We also argue that S-PSNR is less effective in assessing perceptual visual quality compared with Perceptual PSNR (P-PSNR), which considers the front-center bias prior of human viewing direction. The conventional Rate Control (RC) schemes of 2-Dimensional (2D) video coding are optimized on PSNR, and thus they are not suitable for panoramic video coding. To optimize S-PSNR and P-PSNR, two novel RC schemes are proposed for panoramic video coding. In particular, we develop objective and perceptual RC formulations, corresponding to optimization on S-PSNR and P-PSNR, respectively. Then, solutions to these two formulations are provided, such that bits can be allocated to each coding block for achieving optimal S-PSNR or P-PSNR in panoramic video coding. Finally, the experiment results validate the effectiveness of the proposed RC schemes in improving S-PSNR and P-PSNR of panoramic video coding.
C1 [Liu, Yufan; Yang, Li; Xu, Mai; Wang, Zulin] Beihang Univ, Sch Elect & Informat Engn, Beijing, Peoples R China.
   [Wang, Zulin] Collaborat Innovat Ctr Geospatial Technol, Wuhan, Hubei, Peoples R China.
C3 Beihang University
RP Xu, M (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Beijing, Peoples R China.
EM maixu@buaa.edu.cn
RI Liu, Yufan/KHU-5787-2024
OI Liu, Yufan/0000-0002-8426-9335; Yang, Li/0000-0002-1889-3113
FU NSFC [61573037, 61202139, 61471022]; Fok Ying Tong Education Foundation
   [151061]
FX This work was supported by the NSFC projects under Grants 61573037,
   61202139, and 61471022, and Fok Ying Tong Education Foundation under
   Grant 151061.
CR [Anonymous], P PAN PHOT WORKSH PP
   [Anonymous], 2009, PICT COD S
   [Anonymous], VISUAL QUALITY ASSES
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Budagavi M, 2015, IEEE IMAGE PROC, P750, DOI 10.1109/ICIP.2015.7350899
   Chen Zhenzhong, 2018, SIGNAL PROCESSING
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Gaddam VR, 2016, IEEE T MULTIMEDIA, V18, P1819, DOI 10.1109/TMM.2016.2586304
   He Yuwen, 2016, AHG8 INTERDIGITES PR
   Hu SD, 2013, PICT COD SYMP, P197, DOI 10.1109/PCS.2013.6737717
   Kimata H, 2009, I SYMP CONSUM ELECTR, P899
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li JS, 2016, IEEE IMAGE PROC, P370, DOI 10.1109/ICIP.2016.7532381
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu YF, 2017, IEEE INT CON MULTI, P691, DOI 10.1109/ICME.2017.8019379
   Ng KT, 2005, IEEE T CIRC SYST VID, V15, P82, DOI 10.1109/TCSVT.2004.839989
   Ohm JR, 2013, IEEE SIGNAL PROC MAG, V30, P152, DOI 10.1109/MSP.2012.2219672
   Saxe DM, 2002, IEEE T INF TECHNOL B, V6, P310, DOI 10.1109/TITB.2002.806094
   Sun Y, 2006, IEEE T MULTIMEDIA, V8, P1, DOI 10.1109/TMM.2005.861296
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu M, 2014, IEEE J-STSP, V8, P475, DOI 10.1109/JSTSP.2014.2314864
   Youvalari Ramin Ghaznavi, 2016, 360 DEGREE PANORAMIC
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Yu Matt., 2015, P 3 INT WORKSHOP IMM, P1
   Yufan Liu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457929
   Zare A., 2016, P 24 ACM INT C MULT, P601, DOI DOI 10.1145/2964284.2967292
   Zheng JL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1319
   Zheng JL, 2007, LECT NOTES COMPUT SC, V4577, P112
NR 30
TC 18
Z9 19
U1 2
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 76
EP 85
DI 10.1016/j.jvcir.2018.03.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800008
DA 2024-07-18
ER

PT J
AU Zhang, M
   Wu, YH
   Du, Y
   Fang, L
   Pang, Y
AF Zhang, Ming
   Wu, Yunhe
   Du, Yue
   Fang, Lei
   Pang, Yu
TI Saliency detection integrating global and local information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature similarity metric; Global and local information; Locality-based
   coding method; Integration mechanism
ID VISUAL SALIENCY; ATTENTION; RANKING; MODEL
AB In this paper, we propose a novel visual saliency detection algorithm. The saliency of image region is defined as its global and local information. Firstly, we construct background-based map based on a novel multi-feature similarity metric by adjusting the weight of different features varied with image content, then integrated with center prior and Objectless measure into global saliency map. Secondly, a robust locality-based coding method is used to extract image local saliency cues by introducing effective codebooks selection rule and codebook element's reliability into reconstruction. Finally, we propose a novel integration mechanism to incorporate global and local saliency map for performance improvement. In terms of experimental results analysis on four benchmark datasets, the superiority of proposed algorithm is adequately demonstrated.
C1 [Pang, Yu] Northeast Normal Univ, Sch Informat Sci & Technol, Changchun 130117, Jilin, Peoples R China.
   Northeast Normal Univ, Key Lab Intelligent Informat Proc, Changchun 130117, Jilin, Peoples R China.
C3 Northeast Normal University - China; Northeast Normal University - China
RP Pang, Y (corresponding author), Northeast Normal Univ, Sch Informat Sci & Technol, Changchun 130117, Jilin, Peoples R China.
EM pangy654@nenu.edu.cn
RI Li, Zexi/KFA-6939-2024; Wu, Yunhe/JWA-3597-2024
OI Wu, Yunhe/0000-0001-7049-7161
FU National Natural Science Foundation of China [61672150]; Fund of Jilin
   Provincial Science and Technology Department [20160204047GX]; Fund of
   Research Contract, Jilin Provincial Education Department [571[2015]]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61672150), the Fund of Jilin Provincial Science and
   Technology Department (Grant No. 20160204047GX), the Fund of Research
   Contract, Jilin Provincial Education Department (Grant No. 571[2015]).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383017
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fang S., 2016, TNNLS, P1095
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Huo LN, 2016, PATTERN RECOGN, V49, P162, DOI 10.1016/j.patcog.2015.07.005
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Partio M., 2002, P 5 NORD SIGN PROC S
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yang YZ, 2010, LECT NOTES COMPUT SC, V6315, P631, DOI 10.1007/978-3-642-15555-0_46
   Zhang C., 2013, SIGNAL PROCESS IMAGE, V28
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 38
TC 26
Z9 26
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 215
EP 223
DI 10.1016/j.jvcir.2018.03.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800020
DA 2024-07-18
ER

PT J
AU Alphonse, AS
   Dharma, D
AF Alphonse, A. Sherly
   Dharma, Dejey
TI A novel Monogenic Directional Pattern (MDP) and pseudo-Voigt kernel for
   facilitating the identification of facial emotions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Directional pattern; ELM; Pseudo-Voigt; Monogenic
ID EXTREME LEARNING-MACHINE; EXPRESSION RECOGNITION; TEXTURE
   CLASSIFICATION; FACE; FEATURES; SCALE
AB Facial expressions are the best way of communicating human emotions. This paper proposes a novel Monogenic Directional Pattern (MDP) for extracting features from the face. To reduce the time spent on choosing the best kernel, a novel pseudo-Voigt kernel is chosen as the common kernel for dimension reduction proposed as pseudo-Voigt kernel-based Generalized Discriminant Analysis (PVK-GDA). The pseudo-Voigt kernel-based Extreme Learning Machine (PVK-ELM) is used for better recognition of facial emotions. The efficiency of the approach is proved by experimenting with the Japanese Female Facial Expression (JAFFE), Cohn Kanade (CK+), Multimedia Understanding Group (MUG), Static Facial Expressions in the Wild (SFEW) and Oulu-Chinese Academy of Science, Institute of Automation (Oulu-CASIA) datasets. This approach achieves better classification accuracy of 96.7% for JAFFE, 99.4% for CK+, 98.6% for MUG, 35.6% for SFEW and 88% for Oulu-CASIA, which is certainly higher when compared to other techniques in the literature.
C1 [Alphonse, A. Sherly; Dharma, Dejey] Anna Univ, Dept CSE, Reg Campus, Tirunelveli 627007, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Alphonse, AS (corresponding author), Anna Univ, Dept CSE, Reg Campus, Tirunelveli 627007, India.
EM sherls82@gmail.com; dejey.d@auttvl.ac.in
OI Dharma, Dejey/0000-0002-5173-4878; , sherly/0000-0002-0019-9940
CR Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Ahmed F, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P265, DOI 10.1109/ICCE.2012.6161859
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Anisetti M, 2009, STUD COMPUT INTELL, V226, P401
   [Anonymous], EMOTION RECOGNITION
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2015, PROC BRIT MACH VIS C
   Arshid S., 2017, CLUSTER COMPUT, P1
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chu B, 2014, PROC CVPR IEEE, P1907, DOI 10.1109/CVPR.2014.245
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng Y, 2017, IEEE T CYBERNETICS, V47, P1434, DOI 10.1109/TCYB.2016.2547941
   Deng Y, 2016, IEEE T IMAGE PROCESS, V25, P4209, DOI 10.1109/TIP.2016.2588330
   Deng Y, 2013, IEEE T NEUR NET LEAR, V24, P383, DOI 10.1109/TNNLS.2012.2235082
   Deng Y, 2011, IEEE T IMAGE PROCESS, V20, P2329, DOI 10.1109/TIP.2011.2109729
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Fleischmann O., 2008, 2D SIGNAL ANAL GEN H
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   He X., 2003, ADV NEURAL INFORM PR, P153
   HILL RJ, 1985, J APPL CRYSTALLOGR, V18, P173, DOI 10.1107/S0021889885010068
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang GB., 2005, Int J Inf Technol, V11, P16
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Ida T, 2000, J APPL CRYSTALLOGR, V33, P1311, DOI 10.1107/S0021889800010219
   Iosifidis A, 2015, PATTERN RECOGN LETT, V54, P11, DOI 10.1016/j.patrec.2014.12.003
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   MORISHIMA S, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P486, DOI 10.1109/VRAIS.1993.380740
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pan J., 2012, LNCS, P177
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Siddiqi MH, 2013, SENSORS-BASEL, V13, P16682, DOI 10.3390/s131216682
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Weinberger K.Q., 2006, Advances in neural information processing systems, P1473
   Wen GH, 2017, COGN COMPUT, V9, P597, DOI 10.1007/s12559-017-9472-6
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiao-li Hao, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P419, DOI 10.1007/978-981-10-5041-1_68
   Xie L., 2017, ACM T INTEL SYST TEC, V8, P28, DOI DOI 10.1145/2956556
   Xie SY, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2016.4328
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang L, 2012, IMAGE VISION COMPUT, V30, P1043, DOI 10.1016/j.imavis.2012.09.003
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhi RC, 2011, IEEE T SYST MAN CY B, V41, P38, DOI 10.1109/TSMCB.2010.2044788
   Zia MS, 2015, MULTIMED TOOLS APPL, V74, P3881, DOI 10.1007/s11042-013-1803-3
   Zong Y, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P490, DOI 10.1145/2818346.2830584
NR 70
TC 10
Z9 10
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 459
EP 470
DI 10.1016/j.jvcir.2017.10.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800039
DA 2024-07-18
ER

PT J
AU Yu, S
   Cheng, Y
   Xie, L
   Luo, ZM
   Huang, M
   Li, SZ
AF Yu, Sheng
   Cheng, Yun
   Xie, Li
   Luo, Zhiming
   Huang, Min
   Li, Shaozi
TI A novel recurrent hybrid network for feature fusion in action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Action recognition; LSTM; CNNs; IDT
ID REPRESENTATION
AB Action recognition in video is one of the most important and challenging tasks in computer vision. How to efficiently combine the spatial-temporal information to represent video plays a crucial role for action recognition. In this paper, a recurrent hybrid network architecture is designed for action recognition by fusing multi-source features: a two-stream CNNs for learning semantic features, a two-stream single-layer LSTM for learning long-term temporal feature, and an Improved Dense Trajectories (IDT) stream for learning short-term temporal motion feature. In order to mitigate the overfitting issue on small-scale dataset, a video data augmentation method is used to increase the amount of training data, as well as a two-step training strategy is adopted to train our recurrent hybrid network. Experiment results on two challenging datasets UCF-101 and HMDB-51 demonstrate that the proposed method can reach the state-of-the-art performance.
C1 [Yu, Sheng; Luo, Zhiming; Huang, Min; Li, Shaozi] Xiamen Univ, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China.
   [Yu, Sheng; Cheng, Yun; Xie, Li] Hunan Univ Humanities Sci & Technol, Sch Informat, Loudi, Hunan, Peoples R China.
   [Yu, Sheng; Luo, Zhiming; Huang, Min; Li, Shaozi] Fujian Key Lab Brain Intelligent Syst, Xiamen, Fujian, Peoples R China.
C3 Xiamen University; Hunan University Of Humanities, Science & Technology
RP Li, SZ (corresponding author), Xiamen Univ, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China.
EM szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU National Nature Science Foundation of China [61572409, 61402386,
   81230087, 61571188]; Fujian Province Collaborative Innovation Center of
   TCM Health Management; Collaborative Innovation Center of Chinese Oolong
   Tea Industry Collaborative Innovation Center of Fujian Province;
   Scientific Research Fund of Hunan Provincial Education Department
   [17C0824]; Construct Program of the Key Discipline in Hunan Province,
   China; Aid program for Science and Technology Innovative Research Team
   in Higher Educational Institute of Hunan Province,China
FX This work is supported by the National Nature Science Foundation of
   China (Nos. 61572409, 61402386, 81230087, 61571188), Fujian Province
   2011 Collaborative Innovation Center of TCM Health Management and
   Collaborative Innovation Center of Chinese Oolong Tea Industry
   Collaborative Innovation Center (2011) of Fujian Province, Scientific
   Research Fund of Hunan Provincial Education Department (No. 17C0824),
   the Construct Program of the Key Discipline in Hunan Province, China,
   the Aid program for Science and Technology Innovative Research Team in
   Higher Educational Institute of Hunan Province,China.
CR [Anonymous], ARXIVPREPRINT1212040
   [Anonymous], 2015, VERY DEEP CONVOLUTIO
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], ARXIV PREPRINT160509
   [Anonymous], JOINT PATT REC S
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], STAT
   [Anonymous], ARXIVPREPRINT1604044
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], BMVC 2009 19 BRIT MA
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIVPREPRINT1507021
   [Anonymous], ARXIVPREPRINT1701031
   [Anonymous], ARXIVPREPRINT1611060
   [Anonymous], ARXIVPREPRINT1511041
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Baccouche M, 2010, LECT NOTES COMPUT SC, V6353, P154
   Baig MM, 2017, NEUROCOMPUTING, V248, P120, DOI 10.1016/j.neucom.2017.02.077
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Cai YZ, 2016, J VIS COMMUN IMAGE R, V37, P32, DOI 10.1016/j.jvcir.2015.06.003
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duta IC, 2017, LECT NOTES COMPUT SC, V10132, P365, DOI 10.1007/978-3-319-51811-4_30
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Grushin A, 2013, IEEE IJCNN
   Hao T, 2017, J VIS COMMUN IMAGE R, V48, P453, DOI 10.1016/j.jvcir.2017.01.019
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hong RC, 2017, IEEE T IMAGE PROCESS, V26, P4128, DOI 10.1109/TIP.2017.2710635
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510
   Li WX, 2017, INT J COMPUT VISION, V122, P334, DOI 10.1007/s11263-016-0918-1
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Megrhi S, 2016, J VIS COMMUN IMAGE R, V41, P375, DOI 10.1016/j.jvcir.2016.10.016
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Richard A, 2017, COMPUT VIS IMAGE UND, V156, P79, DOI 10.1016/j.cviu.2016.10.014
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sun K, 2017, NEUROCOMPUTING, V230, P374, DOI 10.1016/j.neucom.2016.12.027
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang L., 2016, P ECCV
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Xu ZM, 2017, NEUROCOMPUTING, V236, P82, DOI 10.1016/j.neucom.2016.09.106
   Yu S, 2017, MULTIMED TOOLS APPL, V76, P13367, DOI 10.1007/s11042-016-3768-5
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
NR 63
TC 15
Z9 21
U1 2
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 192
EP 203
DI 10.1016/j.jvcir.2017.09.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800016
DA 2024-07-18
ER

PT J
AU Wei, H
   Yang, CZ
   Yu, Q
AF Wei, Hui
   Yang, Chengzhuan
   Yu, Qian
TI Contour segment grouping for object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape-based object detection; Contour grouping; Depth-first search
ID SHAPE MODEL; RECOGNITION; DESCRIPTORS; RETRIEVAL
AB In this paper, we propose a novel framework for object detection and recognition in cluttered images, given a single hand-drawn example as model. Compared with previous work, our contribution is threefold. (1) Three preprocessing procedures are proposed to reduce the number of irrelevant edge fragments that are often generated during edge detection in cluttered real images. (2) A novel shape descriptor is introduced for conducting partial matching between edge fragments and model contours. (3) An efficient search strategy is adopted to identify the location of target object hypotheses. In the hypotheses verification stage, an appearance-based (support vector machine on pyramid histogram of oriented gradients feature) method is adopted to verify the hypothesis, identify the object, and refine its location. We do extensive experiments on several benchmark datasets including ETHZ shape classes, INRIA horses, Weizmann horses, and the two classes (anchors and cups) from Caltech 101. Experimental results show that the proposed method can significantly improve the accuracy of object detection. Comparisons with other recent shape-based methods further demonstrate the effectiveness and robustness of the proposed method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Wei, Hui] Fudan Univ, Sch Comp Sci, Lab Cognit Model & Algorithm, 825 Zhangheng Rd, Shanghai 201203, Peoples R China.
   Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, 825 Zhangheng Rd, Shanghai 201203, Peoples R China.
C3 Fudan University; Fudan University
RP Wei, H (corresponding author), Fudan Univ, Sch Comp Sci, Lab Cognit Model & Algorithm, 825 Zhangheng Rd, Shanghai 201203, Peoples R China.
EM weihui@fudan.edu.cn; chengzhuanyang13@fudan.edu.cn;
   yuqian12@fudan.edu.cn
RI Yang, Chengzhuan/GXF-1310-2022; jiang, haohan/HOF-1172-2023; Wei,
   Hui/K-5819-2019
OI Wei, Hui/0000-0003-2696-0707
FU NSFC Project [61375122]; Shanghai Science and Technology Development
   Funds [13dz2260200, 13511504300]
FX This work was supported by the NSFC Project (Project No. 61375122), (in
   part) by Shanghai Science and Technology Development Funds (Project No.
   13dz2260200,13511504300).
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], J ELECT IMAGING
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], 2009 IEEE C COMP VIS
   [Anonymous], 2004, P C COMP VIS PATT RE, DOI DOI 10.1109/CVPR.2004.314
   [Anonymous], 2005, Cognitive psychology and its implications
   [Anonymous], 2014 IEEE C COMP VIS
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng G, 2015, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2015.7298721
   Chia AYS, 2012, IEEE T PATTERN ANAL, V34, P1758, DOI 10.1109/TPAMI.2011.220
   Das Bhattacharjee S, 2015, COMPUT VIS IMAGE UND, V139, P73, DOI 10.1016/j.cviu.2015.06.005
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Felzenszwalb PedroF., 2008, IEEE C COMPUTER VISI
   Fergus R, 2003, PROC CVPR IEEE, P264
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Halawani A, 2016, PATTERN RECOGN, V60, P458, DOI 10.1016/j.patcog.2016.06.003
   Hedrich J, 2013, ADV INTELL SYST, V226, P371, DOI 10.1007/978-3-319-00969-8_36
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Hong CQ, 2015, INFORM SCIENCES, V320, P395, DOI 10.1016/j.ins.2015.03.032
   Huang C, 2016, J VIS COMMUN IMAGE R, V38, P540, DOI 10.1016/j.jvcir.2016.03.028
   Ion A, 2011, COMPUT VIS IMAGE UND, V115, P817, DOI 10.1016/j.cviu.2011.02.006
   Kovesi P., 2008, Matlab and octave functions for computer vision and image processing
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lin L, 2012, PROC CVPR IEEE, P135, DOI 10.1109/CVPR.2012.6247668
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CE, 2009, IEEE I CONF COMP VIS, P2288, DOI 10.1109/ICCV.2009.5459446
   Ma TY, 2011, PROC CVPR IEEE, P1441, DOI 10.1109/CVPR.2011.5995591
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Pedrosa GV, 2013, NEUROCOMPUTING, V120, P156, DOI 10.1016/j.neucom.2012.07.055
   Ravishankar S, 2008, LECT NOTES COMPUT SC, V5302, P483, DOI 10.1007/978-3-540-88682-2_37
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Riemenschneider H, 2010, LECT NOTES COMPUT SC, V6315, P29, DOI 10.1007/978-3-642-15555-0_3
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Srinivasan P, 2010, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2010.5539834
   Teo CL, 2015, INT J ROBOT RES, V34, P627, DOI 10.1177/0278364914558493
   Toshev A, 2010, PROC CVPR IEEE, P950, DOI 10.1109/CVPR.2010.5540114
   Wang XG, 2012, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.2012.6247670
   Wei H, 2017, INFORM SCIENCES, V385, P395, DOI 10.1016/j.ins.2016.12.039
   Wei H, 2016, PATTERN RECOGN LETT, V77, P42, DOI 10.1016/j.patrec.2016.03.022
   Wei Zheng, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2703, DOI 10.1109/CVPRW.2009.5206642
   Yang C, 2014, IEEE IMAGE PROC, P2202, DOI 10.1109/ICIP.2014.7025446
   Yang XW, 2012, PATTERN RECOGN, V45, P1927, DOI 10.1016/j.patcog.2011.11.010
   Yang XW, 2010, LECT NOTES COMPUT SC, V6315, P757, DOI 10.1007/978-3-642-15555-0_55
   Yarlagadda P, 2012, LECT NOTES COMPUT SC, V7572, P766, DOI 10.1007/978-3-642-33718-5_55
   Yu Q, 2017, PATTERN RECOGN, V65, P82, DOI 10.1016/j.patcog.2016.11.020
   Zheng W., 2012, P AS C COMP VIS DAEJ, P289
   Zhu L, 2010, IEEE T PATTERN ANAL, V32, P1029, DOI 10.1109/TPAMI.2009.65
   Zhu QH, 2008, LECT NOTES COMPUT SC, V5303, P774
NR 67
TC 19
Z9 22
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 292
EP 309
DI 10.1016/j.jvcir.2017.07.003
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700023
DA 2024-07-18
ER

PT J
AU Liu, SJ
   Cao, JX
   Liu, HQ
   Shen, XD
   Zhang, K
   Wang, P
AF Liu, Shujun
   Cao, Jianxin
   Liu, Hongqing
   Shen, Xiaodong
   Zhang, Kui
   Wang, Pin
TI MRI reconstruction using a joint constraint in patch-based total
   variational framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CS-MRI; Total variation; Joint constraint; LMMSE
ID RESONANCE IMAGE-RECONSTRUCTION; LOW-RANK; RESTORATION; ALGORITHM
AB Compressed sensing (CS) as an efficient means has been widely applied in magnetic resonance imaging (MRI). As a regularization term to enforce the sparsity in the finite difference domain, the conventional total variation (TV) has been introduced in this field, where the staircase effect is presented. To overcome this issue, a new framework in the difference domain called joint constraint patch-based total variation (JCTV) is proposed. First, the image patch is utilized as the unit for TV norm to improve the adaptativity. Second, JCTV introduces a new nonlocal constraint term that exploits the estimated coefficients of the fully sampled image via linear minimum mean square error (LMMSE) criterion to improve the reconstruction performance. Finally, an alternative minimization algorithm is developed to seek the solution. Extensive experiments on a set of in vivo MR images demonstrate that the proposed algorithm outperforms the state-of-the-art approaches in terms of peak signal-to-noise ratio and visual quality. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Shujun; Cao, Jianxin; Shen, Xiaodong; Zhang, Kui; Wang, Pin] Chongqing Univ, Coll Commun Engn, Chongqing 400044, Peoples R China.
   [Liu, Hongqing] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Mobile Commun Technol, Chongqing 400065, Peoples R China.
C3 Chongqing University; Chongqing University of Posts & Telecommunications
RP Liu, SJ (corresponding author), Chongqing Univ, Coll Commun Engn, Chongqing 400044, Peoples R China.
EM liusj@cqu.edu.cn
OI Liu, Shu jun/0000-0002-6608-2286
FU Basic and Advanced Research Project in Chongqing China
   [cstc2016jcyjA0134, cstc2016jcyjA0043]; National Natural Science
   Foundation of China [61501072, 61471073, 61675036, 41404027]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments that have greatly helped to improve the quality of
   the work. This research is partly supported by the Basic and Advanced
   Research Project in Chongqing China (Grant no. cstc2016jcyjA0134,
   cstc2016jcyjA0043) and the National Natural Science Foundation of China
   (Grant nos. 61501072, 61471073, 61675036, 41404027).
CR Adluru G, 2010, J MAGN RESON IMAGING, V32, P1217, DOI 10.1002/jmri.22358
   [Anonymous], IEEE T, DOI DOI 10.1109/TCDS.2021.3131253
   Baraniuk R., 2009, RICE WAVELET TOOLBOX
   Bilgin A., 2010, Proceeding of International Society for Magnetic Resonance in Medicine, V18, P4887
   Block K., MAGN RESON MED, V57
   Block KT, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/184123
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candes E., 2005, l1-magic: Recovery of sparse signals via convex programming, P1
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen C, 2014, MED IMAGE ANAL, V18, P834, DOI 10.1016/j.media.2013.12.004
   Chen YM, 2010, INVERSE PROBL IMAG, V4, P223, DOI 10.3934/ipi.2010.4.223
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Finn JP, 2006, RADIOLOGY, V241, P338, DOI 10.1148/radiol.2412041866
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Gill PR, 2011, IEEE T SIGNAL PROCES, V59, P4595, DOI 10.1109/TSP.2011.2161292
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guerquin-Kern M, 2011, IEEE T MED IMAGING, V30, P1649, DOI 10.1109/TMI.2011.2140121
   Huang JZ, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P968, DOI 10.1109/ISBI.2012.6235718
   Huang JZ, 2010, LECT NOTES COMPUT SC, V6361, P135
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Lai ZY, 2016, MED IMAGE ANAL, V27, P93, DOI 10.1016/j.media.2015.05.012
   Liang D, 2011, MAGN RESON MED, V65, P1384, DOI 10.1002/mrm.22736
   Liu J, 2015, INFORM SCIENCES, V295, P232, DOI 10.1016/j.ins.2014.10.041
   Louchet C, 2011, SIAM J IMAGING SCI, V4, P651, DOI 10.1137/100785855
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Majumdar A, 2011, MAGN RESON IMAGING, V29, P408, DOI 10.1016/j.mri.2010.09.001
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Ning BD, 2013, MAGN RESON IMAGING, V31, P1611, DOI 10.1016/j.mri.2013.07.010
   Qu X, 2010, ELECTRON LETT, V46, P121, DOI 10.1049/el.2010.1845
   Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007
   Qu XB, 2012, MAGN RESON IMAGING, V30, P964, DOI 10.1016/j.mri.2012.02.019
   Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538
   Shi F, 2015, IEEE T MED IMAGING, V34, P2459, DOI 10.1109/TMI.2015.2437894
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Trzasko J., IEEE T MED IMAGING, V28
   Wang YH, 2017, AAAI CONF ARTIF INTE, P2761
   Xu C, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1275, DOI 10.1145/2939672.2939798
   Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
   Yang RK, 2010, RADIOGRAPHICS, V30, P185, DOI 10.1148/rg.301095076
   Zhan ZF, 2016, IEEE T BIO-MED ENG, V63, P1850, DOI 10.1109/TBME.2015.2503756
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
NR 49
TC 8
Z9 10
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 150
EP 164
DI 10.1016/j.jvcir.2017.03.017
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500014
DA 2024-07-18
ER

PT J
AU Yang, LL
   Li, F
   Xiong, ZW
   Shi, GM
   Niu, Y
   Li, RD
AF Yang, Lili
   Li, Fu
   Xiong, Zhiwei
   Shi, Guangming
   Niu, Yi
   Li, Ruodai
TI Single-shot dense depth sensing with frequency-division multiplexing
   fringe projection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Range finding; Three-dimensional sensing; Three-dimensional image
   acquisition; Depth sensing; Structured light
ID PHASE-UNWRAPPING ALGORITHM; WINDOWED FOURIER-TRANSFORM;
   PATTERN-ANALYSIS; PROFILOMETRY; ACQUISITION; OBJECTS
AB In structured light illumination (SLI) systems, multi-shot fringe patterns can reach higher precision than a single-shot fringe pattern. However, multi-shot methods are not suitable for dynamic scenes while single-shot ones are limited in the measurement accuracy. In this paper, a novel single-shot depth sensing method with frequency-division multiplexing (FDM) framework is proposed. To achieve a simultaneous casting, two fringe patterns with coprime periods are modulated into a single pattern. The method of fringe pattern extraction is similar to the demodulation in communication systems. The Gabor filter is adopted to get the phase information in the pattern, and the coprime theorem is used to solve the phase ambiguity. Quantitative and qualitative evaluations have proved that our method achieves higher accuracy in depth sensing compared with the Kinect vi and ToF camera. In addition, benefiting from the single-shot pattern, our method is suitable for dynamic scenes. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yang, Lili; Li, Fu; Shi, Guangming; Niu, Yi; Li, Ruodai] Xidian Univ, Sch Elect Engn, Chinese Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Xiong, Zhiwei] Univ Sci & Technol China, Hefei 230026, Peoples R China.
C3 Xidian University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Li, F (corresponding author), Xidian Univ, Sch Elect Engn, Chinese Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM fuli@mail.xidian.edu.cn
FU China Scholarship Council (CSC); NSFC [61672404, 61100155, 61472301,
   61572387, 61301288]; Fundamental Research Funds of the Central
   Universities of China [JBG160228, K5051399020, K5051202050, SA-ZD160203,
   JB140207]; Natural Science Basic Research Plan in Shaanxi Province of
   China [2016ZDJC-08]
FX Lili Yang's contribution was made when she was a visiting PhD student at
   the Australian National University, sponsored by the China Scholarship
   Council (CSC). This work was supported in part by the NSFC (No.
   61672404, 61100155, 61472301, 61572387 and 61301288), the Fundamental
   Research Funds of the Central Universities of China (Nos. JBG160228,
   K5051399020, K5051202050, SA-ZD160203 and JB140207), and Natural Science
   Basic Research Plan in Shaanxi Province of China (Program No.
   2016ZDJC-08).
CR Abid AZ, 2007, APPL OPTICS, V46, P6120, DOI 10.1364/AO.46.006120
   Albitar C, 2007, IEEE I CONF COMP VIS, P1207
   Asundi A, 1998, APPL OPTICS, V37, P5416, DOI 10.1364/AO.37.005416
   Baldi A, 2003, APPL OPTICS, V42, P2498, DOI 10.1364/AO.42.002498
   Budianto B, 2014, APPL OPTICS, V53, P7442, DOI 10.1364/AO.53.007442
   Casey C., OPT ENG, P53
   Chen CW, 2000, J OPT SOC AM A, V17, P401, DOI 10.1364/JOSAA.17.000401
   Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755
   Creath K., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V556, P337, DOI 10.1117/12.949561
   Dursun A, 2004, MEAS SCI TECHNOL, V15, P1768, DOI 10.1088/0957-0233/15/9/013
   Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128
   Gorthi SS, 2010, OPT LASER ENG, V48, P133, DOI 10.1016/j.optlaseng.2009.09.001
   Guan C, 2005, PROC SPIE, V5798, P15, DOI 10.1117/12.603808
   Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406
   Gupta P., GRAY CODE COMPOSITE
   Gutmann B, 2000, APPL OPTICS, V39, P4802, DOI 10.1364/AO.39.004802
   Hassebrook LG, 1997, P SOC PHOTO-OPT INS, V3204, P102, DOI 10.1117/12.294447
   Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806
   Kemao Q, 2008, APPL OPTICS, V47, P5408, DOI 10.1364/AO.47.005408
   Kemao Q, 2007, OPT LASER ENG, V45, P304, DOI 10.1016/j.optlaseng.2005.10.012
   Li F., IEEE J SELECTED TOPI, P9
   Morita H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P468, DOI 10.1109/CCV.1988.590025
   Nico G, 2000, IEEE T SIGNAL PROCES, V48, P2545, DOI 10.1109/78.863057
   POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X
   Pribanic T, 2010, IMAGE VISION COMPUT, V28, P1255, DOI 10.1016/j.imavis.2010.01.003
   Sagawa R, 2009, IEEE I CONF COMP VIS, P1779, DOI 10.1109/ICCV.2009.5459397
   Sansoni G, 2005, MEAS SCI TECHNOL, V16, P1109, DOI 10.1088/0957-0233/16/5/009
   Shi GM, 2015, APPL OPTICS, V54, P3796, DOI 10.1364/AO.54.003796
   SRINIVASAN V, 1984, APPL OPTICS, V23, P3105, DOI 10.1364/AO.23.003105
   Su XY, 2004, OPT LASER ENG, V42, P245, DOI 10.1016/j.optlaseng.2003.11.002
   TAKEDA M, 1983, APPL OPTICS, V22, P3977, DOI 10.1364/AO.22.003977
   Takeda M, 1997, APPL OPTICS, V36, P5347, DOI 10.1364/AO.36.005347
   TAKEDA M, 1994, APPL OPTICS, V33, P7829, DOI 10.1364/AO.33.007829
   VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402
   Wang M., 2014, SPIE DEFENSE SECURIT
   Yang F, 2015, PROC SPIE, V9302, DOI 10.1117/12.2081130
   Yang Z, 2013, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2013.11
   Zhang S, 2007, APPL OPTICS, V46, P50, DOI 10.1364/AO.46.000050
   Zhang S, 2010, OPT LASER ENG, V48, P149, DOI 10.1016/j.optlaseng.2009.03.008
   Zhang YY, 2014, IEEE T IMAGE PROCESS, V23, P97, DOI 10.1109/TIP.2013.2286901
   Zheng SZ, 2006, OPT ENG, V45, DOI 10.1117/1.2213986
   Zhong JG, 2005, OPT LETT, V30, P2560, DOI 10.1364/OL.30.002560
   Zhong JG, 2004, OPT ENG, V43, P895, DOI 10.1117/1.1666870
NR 43
TC 10
Z9 10
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 139
EP 149
DI 10.1016/j.jvcir.2017.03.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500013
DA 2024-07-18
ER

PT J
AU Tariq, J
   Kwong, S
   Yuan, H
AF Tariq, Junaid
   Kwong, Sam
   Yuan, Hui
TI Spatial/temporal motion consistency based MERGE mode early decision for
   HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fast MERGE mode prediction; High Efficiency Video Coding (HEVC); Image
   coding; Video coding; Inter mode decision; Fast mode decision; Merge
   candidates; Sum of absolute difference; SAD
ID PREDICTION; INTRA
AB A framework for the early decision of MERGE mode (EDM) is proposed to overcome the brute force inter mode decision for the coding unit (CU) in High Efficiency Video Coding (HEVC). Firstly, the prediction results of merge candidates (MrgCands) in previous and current frame are modeled to identify smooth/single-motion regions for EDM. Secondly, the RD-cost based statistical model is proposed for EDM since MERGE is selected 98.20% on average when 2N x 2N and MERGE produce similar RD-cost. Finally, a model is proposed that obtains the SAD values for the prediction units (PU) of modes using the motion-estimation of 2N x 2N and performs EDM based on the comparison of these SAD values. Experimental results demonstrate that an average 46.75% coding time can be saved, while the Bjontegaard delta bit rate (BDBR) increase is only 1.79%. In addition, an average of 68.54% complexity reduction is achieved with 1.79% BDBR increase for conference video sequences. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Tariq, Junaid; Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Tariq, Junaid] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
   [Yuan, Hui] Shandong Univ, Sch Informat Sci & Engn, Shandong, Peoples R China.
C3 City University of Hong Kong; NITEC University; Shandong University
RP Kwong, S (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM junaid.tariq@hitecuni.edu.pk; cssamk@cityu.edu.hk; yuanhui0325@gmail.com
RI Yuan, Hui/HDO-3699-2022; Kwong, Sam/C-9319-2012
OI Yuan, Hui/0000-0001-5212-3393; Kwong, Sam/0000-0001-7484-7261
FU RGC General Research Fund (GRF) [9042322, CityU 11200116]; National
   Natural Science Foundation of China [61571274]; Shandong Natural Science
   Funds for Distinguished Young Scholar [JQ201614]; Young Scholars Program
   of Shandong University (YSPSDU) [2015WLJH39]
FX This work was supported in part by RGC General Research Fund (GRF)
   9042322 (CityU 11200116); in part by the National Natural Science
   Foundation of China under Grants 61571274; in part by Shandong Natural
   Science Funds for Distinguished Young Scholar under Grant JQ201614; in
   part by the Young Scholars Program of Shandong University (YSPSDU) under
   Grant 2015WLJH39.
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Bjontegaard G., 2001, P ITU T SB16 Q 6 VCE
   Bossen F., 2012, TECH REP
   Coi S.P.K., 2011, TECH REP
   Gweon Y.-L.L.R.H., 2011, TECH REP
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Kim J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P449, DOI 10.1109/PCS.2012.6213251
   Kim K.S.B.B. Il-Koo, 2013, TECH REP, P1423
   Lee H, 2015, IEEE T BROADCAST, V61, P388, DOI 10.1109/TBC.2015.2419172
   McCann W.-J.H.K., 2010, TECH REP
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Qiang Hu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457828
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan J., 2010, P SOC PHOTO-OPT INS, V7798, P7798
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/SMC.2015.311
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1782, DOI 10.1109/SMC.2015.312
   Tourapis AM, 2005, IEEE T CIRC SYST VID, V15, P119, DOI 10.1109/TCSVT.2004.837021
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Won K., 2011, TECH REP
   Zeng HQ, 2014, IEEE T CIRC SYST VID, V24, P1566, DOI 10.1109/TCSVT.2014.2310143
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P4511, DOI 10.1109/TIP.2014.2352036
   Zheng K.C., 2008, PARALLAX PHOTOGRAPHY
NR 27
TC 18
Z9 19
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 198
EP 213
DI 10.1016/j.jvcir.2017.01.029
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600017
DA 2024-07-18
ER

PT J
AU Wang, Y
   Yang, YT
   Chen, T
AF Wang, Yi
   Yang, Yetao
   Chen, Tao
TI Spectral-spatial adaptive and well-balanced flow-based anisotropic
   diffusion for multispectral image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multispectral images; Anisotropic diffusion; Spectral-spatial adaptive;
   Image denoising; Partial differential equation
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; EDGE-DETECTION; NOISE
   REMOVAL; BACKWARD DIFFUSION; MULTIVALUED IMAGES; RESTORATION;
   ENHANCEMENT; EFFICIENT; EQUATION
AB Anisotropic diffusion can provide better compromise between noise reduction and edge preservation. In multispectral images, there exist different spatial local structures in the same band. Therefore, the levels of smoothing of anisotropic diffusion process should conform to both of image spectral and spatial features. In this paper, we present an effective denoising algorithm by integrating the spectral-spatial adaptive mechanism into a well-balanced flow (WBF) based anisotropic diffusion model, in which an adjustable weighted function is introduced to perform the appropriate levels of smoothing and enhancing according to different feature scales. Moreover, we make the fidelity term in the model to be adaptive by replacing the original noisy signal with the last evolution of the smoothed image. Consequently, the proposed algorithm can better control the diffusion behavior than traditional multispectral diffusion-based algorithms. The experimental results verify that our algorithm can improve visual quality of the image and obtain better quality indices. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Wang, Yi; Yang, Yetao; Chen, Tao] China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
C3 China University of Geosciences
RP Wang, Y (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
EM cug.yi.wang@gmail.com
RI Wang, Yi/J-2321-2019; , 陈涛/H-5740-2019
OI Wang, Yi/0000-0002-1347-7030; , 陈涛/0000-0001-6965-1256
FU National Natural Science Foundation of China (NSFC) [61271408, 61601418]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grant 61271408 and 61601418. The authors would like
   to thank the handling editor and anonymous reviewers for their valuable
   comments and suggestions which significantly improved the quality of
   this paper.
CR Acton ST, 1998, IEEE T IMAGE PROCESS, V7, P280, DOI 10.1109/83.661178
   Acton ST, 1997, INT J REMOTE SENS, V18, P2877, DOI 10.1080/014311697217404
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   Aubert G., 2002, MATH PROBLEMS IMAGE
   Barcelos CAZ, 2003, IEEE T IMAGE PROCESS, V12, P751, DOI 10.1109/TIP.2003.814242
   Barcelos CAZ, 2005, COMPUT APPL MATH, V24, P131, DOI 10.1590/S1807-03022005000100008
   Benazza-Benyahia A, 2005, IEEE T IMAGE PROCESS, V14, P1814, DOI 10.1109/TIP.2005.857247
   Bettahar S, 2012, IEEE T IMAGE PROCESS, V21, P2500, DOI 10.1109/TIP.2011.2177844
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Boccignone G, 2002, IEEE T PATTERN ANAL, V24, P1298, DOI 10.1109/TPAMI.2002.1039202
   Bresson X, 2008, INVERSE PROBL IMAG, V2, P455, DOI 10.3934/ipi.2008.2.455
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Cha YJ, 2006, IEEE T IMAGE PROCESS, V15, P2315, DOI 10.1109/TIP.2006.875182
   Chaux C, 2008, IEEE T SIGNAL PROCES, V56, P3855, DOI 10.1109/TSP.2008.921757
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Duijster A, 2009, IEEE T GEOSCI REMOTE, V47, P3892, DOI 10.1109/TGRS.2009.2031103
   GALATSANOS NP, 1989, IEEE T ACOUST SPEECH, V37, P415, DOI 10.1109/29.21708
   GALATSANOS NP, 1991, IEEE T SIGNAL PROCES, V39, P2222, DOI 10.1109/78.91180
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   HUNT BR, 1984, IEEE T ACOUST SPEECH, V32, P592, DOI 10.1109/TASSP.1984.1164363
   NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H
   Peng HH, 2014, IEEE T IMAGE PROCESS, V23, P264, DOI 10.1109/TIP.2013.2287612
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Pope K, 1998, 1998 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P154, DOI 10.1109/IAI.1998.666877
   Prasath VBS, 2014, NONLINEAR ANAL-REAL, V17, P33, DOI 10.1016/j.nonrwa.2013.10.004
   Prasath VBS, 2010, INT J REMOTE SENS, V31, P2091, DOI 10.1080/01431160903260965
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Smolka B, 2008, INT CONF SIGN PROCES, P777, DOI 10.1109/ICOSP.2008.4697245
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperlé D, 2002, IEEE SIGNAL PROC MAG, V19, P16, DOI 10.1109/MSP.2002.1028349
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   Wang Y, 2007, IEEE T IMAGE PROCESS, V16, P1854, DOI 10.1109/TIP.2007.899002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   Weickert Joachim, 2001, Acta Math. Univ. Comenian NS., V70, P33
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054
   Zehtabian A, 2015, EUR J REMOTE SENS, V48, P183, DOI 10.5721/EuJRS20154811
NR 53
TC 8
Z9 8
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 185
EP 197
DI 10.1016/j.jvcir.2017.01.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400018
DA 2024-07-18
ER

PT J
AU Su, PC
   Kuo, TY
   Li, MH
AF Su, Po-Chyi
   Kuo, Tien-Ying
   Li, Meng-Huan
TI A practical design of digital watermarking for video streaming services
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital watermark; Videos streaming; Digital rights management;
   Copyright protection; Tracking
ID COMPRESSED-DOMAIN; SYSTEM
AB A practical design of digital watermarking for video streaming services is proposed in this research. The information of a legitimate recipient is represented as a watermark, which is embedded in the video stream to serve as a cue to trace the recipient in case a clone of the video is illegally distributed. The watermark signals are designed to embed in some areas of video frames to benefit the video stream server, as the result of only partial actions required, including decoding, processing and re-encoding. The invariance of feature points and the self-similarity of hidden signals are further exploited to enable watermark detection without involving the original video. The watermark can decently survive transcoding processes and geometrical modifications of frames. The experimental results demonstrate the advantages of the proposed scheme in terms of watermark visibility, capacity and detection methodology. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Su, Po-Chyi; Li, Meng-Huan] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
   [Kuo, Tien-Ying] Natl Taipei Univ Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Central University; National Taipei University of Technology
RP Kuo, TY (corresponding author), Natl Taipei Univ Technol, Dept Elect Engn, Taipei, Taiwan.
EM tykuo@ntut.edu.tw
RI Kuo, Tien-Ying/B-6702-2013; SU, PO-CHYI/GWC-9682-2022
OI Kuo, Tien-Ying/0000-0001-9831-5622
FU Ministry of Science and Technology in Taiwan, R.O.C. [MOST
   104-2221-E-008-075, MOST 105-2221-E-027-038]
FX This research is supported by the Ministry of Science and Technology in
   Taiwan, R.O.C., under Grants MOST 104-2221-E-008-075 and MOST
   105-2221-E-027-038.
CR Ahumada A. J.  Jr., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1666, P365, DOI 10.1117/12.135982
   Barni M, 2005, IEEE T MULTIMEDIA, V7, P23, DOI 10.1109/TMM.2004.840594
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chug TY, 1998, IEEE T CONSUM ELECTR, V44, P895, DOI 10.1109/30.713211
   Cox IJ., 2007, DIGITAL WATERMARKING
   Darmstaedter V, 1998, LECT NOTES COMPUT SC, V1425, P190
   Dittmann J., 1998, Proceedings ACM Multimedia 98, P71, DOI 10.1145/290747.290757
   Gersho A., 2003, Vector Quantization and Signal Compression
   Gigaud G, 2010, IEEE IMAGE PROC, P3669, DOI 10.1109/ICIP.2010.5652507
   Hartung F, 1996, P SOC PHOTO-OPT INS, V2952, P205, DOI 10.1117/12.251278
   Hartung F., 1997, P MULT COMP NETW MMC
   Kalker T, 1999, PROC SPIE, V3657, P103, DOI 10.1117/12.344661
   Kang LW, 2010, IEEE INT CON MULTI, P1248, DOI 10.1109/ICME.2010.5582615
   Kuo TY, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P204, DOI 10.1109/IIH-MSP.2008.231
   Kutter M, 1999, P SOC PHOTO-OPT INS, V3528, P423, DOI 10.1117/12.337432
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Lee MJ, 2012, DIGIT SIGNAL PROCESS, V22, P190, DOI 10.1016/j.dsp.2011.08.001
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Liu K.J. R., 2005, MULTIMEDIA FINGERPRI
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Simitopoulos D, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P569, DOI 10.1109/ICME.2002.1035845
   Su P.-C., 2001, P SOC PHOTO-OPT INS, P423
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Voloshynovskiy S, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P999, DOI 10.1109/ICIP.2001.958294
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Wu GZ, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1877525
   Zeng W., 2006, MULTIMEDIA SECURITY
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
NR 34
TC 8
Z9 9
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 161
EP 172
DI 10.1016/j.jvcir.2016.11.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200013
DA 2024-07-18
ER

PT J
AU Sha, CS
   Hou, J
   Cui, HX
AF Sha, Chunshi
   Hou, Jian
   Cui, Hongxia
TI A robust 2D Otsu's thresholding method in image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Otsu's method; Thresholding; Image segmentation
ID C-MEANS ALGORITHM
AB Otsu's method is a classic thresholding approach in image segmentation. While the two-dimensional (2D) Otsu's method performs better than the original one in segmenting images corrupted by noise, it is sensitive to Salt&Pepper noise. In order to solve this problem, we present a robust 2D Otsu's thresholding method in this paper. Our method builds the 2D histogram based on the image smoothed by both median and average filters, in contrast to the traditional method using averaged image only. Then the optimal threshold vector is determined with two one-dimensional searches on the two dimensions of the 2D histogram. In addition, we introduce a region post-processing step to deal with the pixels of noise and edges. Compared with the traditional 2D Otsu's method, our method improves the robustness to Salt&Pepper noise and Gaussian noise significantly. Experimental results on both synthetic and real images validate the effectiveness of the proposed MAOTSU_2D method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Sha, Chunshi; Hou, Jian] Bohai Univ, Coll Engn, Jinzhou 121013, Peoples R China.
   [Cui, Hongxia] Bohai Univ, Coll Informat Sci & Technol, Jinzhou 121013, Peoples R China.
C3 Bohai University; Bohai University
RP Hou, J (corresponding author), Bohai Univ, Coll Engn, Jinzhou 121013, Peoples R China.
EM dr.houjian@gmail.com
RI CUI, XU/JYO-8134-2024
FU National Natural Science Foundation of China [61473045, 41371425];
   Program for Liaoning Innovative Research Team in University [LT2013023]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant Nos. 61473045 and 41371425, and by the
   Program for Liaoning Innovative Research Team in University (LT2013023).
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], INT C INF TECHN E SE, DOI 10.1109/ICITeS.2012.6216680
   Cai HM, 2014, IEEE T IMAGE PROCESS, V23, P1038, DOI 10.1109/TIP.2014.2298981
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chen Q, 2012, IET IMAGE PROCESS, V6, P426, DOI 10.1049/iet-ipr.2010.0078
   Chen Y, 2010, INT ASIA CONF INFORM, P282, DOI 10.1109/CAR.2010.5456687
   Cheriet M, 1998, IEEE T IMAGE PROCESS, V7, P918, DOI 10.1109/83.679444
   Fan Jiu-lun, 2007, Acta Electronica Sinica, V35, P751
   Fan Jiu-lun, 2007, Acta Electronica Sinica, V35, P1398
   Gong JA, 1998, PATTERN RECOGN, V31, P295, DOI 10.1016/S0031-3203(97)00043-5
   Guo WY, 2014, OPTIK, V125, P5234, DOI 10.1016/j.ijleo.2014.05.003
   Hao Y., 2005, J IMAGE GRAPH, V4
   Hou J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2559803
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jing Xiao-jun, 2003, Acta Electronica Sinica, V31, P1281
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lai YK, 2014, IEEE T IMAGE PROCESS, V23, P992, DOI 10.1109/TIP.2013.2297014
   Lang XP, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P677, DOI 10.1109/CISP.2008.179
   Liu Jianzhuang, 1991, China 1991 International Conference on Circuits and Systems. Conference Proceedings (Cat. No.91TH0387-1), P325, DOI 10.1109/CICCAS.1991.184351
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Masulli F, 1999, ARTIF INTELL MED, V16, P129, DOI 10.1016/S0933-3657(98)00069-4
   Moghaddam RF, 2012, PATTERN RECOGN, V45, P2419, DOI 10.1016/j.patcog.2011.12.013
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1989, IEE PROC-E, V136, P284, DOI 10.1049/ip-e.1989.0039
   Qiwei Wang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P238, DOI 10.1109/ICIG.2011.151
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sirisha P., 2013, J SOFTW ENG, V7
   Sthitpattanapongsa P., 2012, ADV IMAGE VIDEO TECH, P358
   [汪海洋 WANG HaiYang], 2007, [自动化学报, Acta Automatica Sinica], V33, P968
   Wang L, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE AND EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P136, DOI 10.1109/ITME.2008.4743838
   Wang N, 2010, PATTERN RECOGN LETT, V31, P1809, DOI 10.1016/j.patrec.2010.06.002
   Wei KP, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 5, PROCEEDINGS, P591
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Xu XY, 2011, PATTERN RECOGN LETT, V32, P956, DOI 10.1016/j.patrec.2011.01.021
   Xue J., 2011, IEEE T IMAGE PROCESS, P20
   YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1
   [岳峰 YUE Feng], 2009, [自动化学报, Acta Automatica Sinica], V35, P1022
   Zhang DQ, 2004, ARTIF INTELL MED, V32, P37, DOI [10.1016/j.artmed.2004.01.012, 10.1016/j.artmed. 2004.01.012]
NR 40
TC 71
Z9 86
U1 3
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 339
EP 351
DI 10.1016/j.jvcir.2016.10.013
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000030
DA 2024-07-18
ER

PT J
AU Kim, S
   Kang, SJ
   Kim, YH
AF Kim, Sanghun
   Kang, Suk-Ju
   Kim, Young Hwan
TI Anisotropic diffusion noise filtering using region adaptive smoothing
   strength
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Anisotropic diffusion; Adaptive smoothing strength
ID IMAGE; ALGORITHM
AB This paper presents an improved anisotropic diffusion method using region adaptive smoothing strength. Unlike existing methods, the proposed method uses an adaptive classifier to find a good estimate of the optimal smoothing strength for each iteration to consider the varying noise characteristics. Further, when. training the classifiers, the usefulness of the training data is verified and less useful data are excluded to avoid degraded training results, thereby generating robust and improved denoising performance. For reduction of the computational complexity, this paper also proposes a simple region analysis technique. Consequently, the proposed method is appropriate for the devices that have relatively small computing power. Experimental results confirm that the proposed method outperforms AD-based benchmark methods by increased peak signal-to-noise ratio up to 2.37 dB and structural similarity up to 0.0557 for 10% noise level. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kim, Sanghun; Kim, Young Hwan] Pohang Univ Sci & Technol POSTECH, Dept Elect Engn, Pohang 37673, South Korea.
   [Kang, Suk-Ju] Sogang Univ, Dept Elect Engn, Seoul 04107, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Sogang University
RP Kim, YH (corresponding author), Pohang Univ Sci & Technol POSTECH, Dept Elect Engn, Pohang 37673, South Korea.
EM youngk@postech.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [20100023428]; MSIP (Ministry of Science, ICT and Future Planning),
   Korea, under the "ICT Consilience Creative Program"
   [IITP-2015-R0346-15-1007]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology 20100023428 and the MSIP (Ministry
   of Science, ICT and Future Planning), Korea, under the "ICT Consilience
   Creative Program" (IITP-2015-R0346-15-1007) supervised by the
   IITP(Institute for Information & communications Technology Promotion).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Cho SI, 2014, PATTERN RECOGN LETT, V46, P36, DOI 10.1016/j.patrec.2014.05.003
   Criminisi A., 2013, DECISION FORESTCOM, DOI DOI 10.1007/978-1-4471-4929-3
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Li HC, 2012, ELECTRON LETT, V48, P827, DOI 10.1049/el.2011.3994
   Mohri M., 2012, Foundations of Machine Learning
   Nguyen TA, 2010, IEEE T CONSUM ELECTR, V56, P1610, DOI 10.1109/TCE.2010.5606304
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Talebi H, 2014, IEEE T IMAGE PROCESS, V23, P755, DOI 10.1109/TIP.2013.2293425
   Thaipanich T, 2010, IEEE T CONSUM ELECTR, V56, P2623, DOI 10.1109/TCE.2010.5681149
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
NR 14
TC 3
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 384
EP 391
DI 10.1016/j.jvcir.2016.07.005
PN A
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500034
DA 2024-07-18
ER

PT J
AU Xie, YR
   Li, HL
   Huang, C
   Wu, B
   Xu, LF
AF Xie, Yurui
   Li, Hongliang
   Huang, Chao
   Wu, Bo
   Xu, Linfeng
TI Feature discovering for image classification via wavelet-like pattern
   decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dictionary learning; Image classification; Sparse representation;
   Hierarchical architecture
ID K-SVD; DICTIONARY
AB In this paper, we propose a feature discovering method incorporated with a wavelet-like pattern decomposition strategy to address the image classification problem. In each level, we design a discriminative feature discovering dictionary learning (DFDDL) model to exploit the representative visual samples from each class and further decompose the commonality and individuality visual patterns simultaneously. The representative samples reflect the discriminative visual cues per class, which are beneficial for the classification task. Furthermore, the commonality visual elements capture the communal visual patterns across all classes. Meanwhile, the class-specific discriminative information can be collected by the learned individuality visual elements. To further discover the more discriminative feature information from each class, we then integrate the DFDDL into a wavelet-like hierarchical architecture. Due to the designed hierarchical strategy, the discriminative power of feature representation can be promoted. In the experiment, the effectiveness of proposed method is verified on the challenging public datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xie, Yurui; Li, Hongliang; Huang, Chao; Wu, Bo; Xu, Linfeng] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Xie, YR (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Sichuan, Peoples R China.
EM gloriousxyr@163.com
RI Xu, Linfeng/HME-1913-2023; Huang, Chao/L-1445-2019; Huang,
   Chao/JJD-0553-2023
OI Xu, Linfeng/0000-0002-9934-0958; Huang, Chao/0000-0001-8775-3192
FU National Natural Science Foundation of China [61525102, 61271289];
   program for Science and Technology Innovative Research Team for Young
   Scholars in Sichuan Province, China [2014TD0006]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61525102, 61271289), and by The program for Science and
   Technology Innovative Research Team for Young Scholars in Sichuan
   Province, China (No. 2014TD0006).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], 2007, NIPS
   [Anonymous], CVPR
   [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], 2014, ECCV
   [Anonymous], 2010, CVPR
   [Anonymous], 2007, ICCV
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], 2010, CVPR
   [Anonymous], NIPS
   [Anonymous], 2013, P 5 INT C INTERNET M
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], 2014, P INT C LEARN REPR B
   [Anonymous], CVPR
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], CVPR
   Boureau Y., 2011, ICCV
   Cai S., 2014, ECCV
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Daubechies I., 1992, 10 LECT WAVELETS
   Gemert J.C., 2008, ECCV
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Jiang QP, 2015, J VIS COMMUN IMAGE R, V33, P123, DOI 10.1016/j.jvcir.2015.09.009
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kong S., 2012, ECCV
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu HX, 2013, J VIS COMMUN IMAGE R, V24, P1232, DOI 10.1016/j.jvcir.2013.08.007
   Liu J., 2013, SLEP: Sparse Learning with Efficient Projections
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J., 2008, CVPR
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Mairal Julien., 2008, ECCV
   Pham D.-S., 2008, CVPR
   Sajjad M, 2015, J VIS COMMUN IMAGE R, V26, P50, DOI 10.1016/j.jvcir.2014.10.012
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu C., 2014, P INT C MACH LEARN, p865~873
   Yang L., 2008, CVPR
   Yang M., 2011, ICCV
   Yang SY, 2013, J VIS COMMUN IMAGE R, V24, P181, DOI 10.1016/j.jvcir.2012.07.011
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang H., 2006, CVPR
   Zhu JY, 2015, J VIS COMMUN IMAGE R, V31, P225, DOI 10.1016/j.jvcir.2015.07.002
NR 51
TC 1
Z9 1
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 627
EP 637
DI 10.1016/j.jvcir.2016.08.002
PN B
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600019
DA 2024-07-18
ER

PT J
AU Lin, CS
   Yang, WJ
   Su, CW
AF Lin, Chow-Sing
   Yang, Wei-jong
   Su, Chieh-Wei
TI FITD: Fast Intra Transcoding from H.264/AVC to high efficiency video
   coding based on DCT coefficients and prediction modes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Transcoding; Depth limitation; Early termination; Intra prediction
ID DECISION ALGORITHM; STANDARD; MPEG-2; ARCHITECTURES; OPTIMIZATION
AB In the literatures, the designs of H.264 to High Efficiency Video Coding (HEVC) transcoders mostly focus on inter transcoding. In this paper, a fast intra transcoding system from H.264 to HEVC based on discrete cosine transform (DCT) coefficients and intra prediction modes, called FITD, is proposed by using the intra information retrieved from an H.264 decoder for transcoding. To design effective transcoding strategies, FITD not only refers block size of intra prediction and intra prediction modes, but also effectively uses the DCT coefficients to help a transcoder to predict the complexity of the blocks. We successfully use DCT coefficients as well as intra prediction information embedded in H.264 bitstreams to predict the coding depth map for depth limitation and early termination to simplify HEVC re-encoding process. After a HEVC encoder gets the prediction of a certain CU size from depth map, if it reaches the predicted depth, the HEVC encoder will stop the next CU branch. As a result, the numbers of CU branches and predictions in HEVC re-encoder will be substantially reduced to achieve fast and precise intra transcoding. The experimental results show that the FITD is 1.7-2.5 times faster than the original HEVC in encoding intra frames, while the bitrate is only increased to 3% or less and the PSNR degradation is also controlled within 0.1 dB. Compared to the previous H.264 to HEVC transcoding approaches, FITD clearly maintains the better trade-off between re-encoding speed and video quality. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lin, Chow-Sing; Yang, Wei-jong; Su, Chieh-Wei] Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Shu Lin St, Tainan 70005, Taiwan.
C3 National University Tainan
RP Lin, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Shu Lin St, Tainan 70005, Taiwan.
EM mikelin@mail.nutn.edu.tw; weijongx@hotmail.com; chiehwei.su@gmail.com
RI Lin, Chow-Sing/JPX-6621-2023
FU Ministry of Science and Technology in Taiwan (ROC) [MOST
   103-2221-E-024-007]
FX This work was partially supported by Ministry of Science and Technology
   in Taiwan (ROC) under contract MOST 103-2221-E-024-007.
CR Bjork N, 1998, IEEE T CONSUM ELECTR, V44, P88, DOI 10.1109/30.663734
   Dong Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P651, DOI 10.1109/ICME.2012.112
   Fernández-Escribano G, 2008, IEEE T CIRC SYST VID, V18, P172, DOI 10.1109/TCSVT.2008.918115
   Fernandez-Escribano G, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P440
   Li B., 2011, JCTVCG399, P298
   Lu X, 2005, IEEE INT SYMP CIRC S, P1246
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   PEIXOTO E, 2012, 19 IEEE INT C IM PRO, P737
   Shen HF, 2008, IEEE T CIRC SYST VID, V18, P746, DOI 10.1109/TCSVT.2008.918783
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen T, 2013, IEEE DATA COMPR CONF, P241, DOI 10.1109/DCC.2013.32
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   Su YP, 2005, IEEE INT SYMP CIRC S, P1234
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang HL, 2007, IEEE T MULTIMEDIA, V9, P882, DOI 10.1109/TMM.2007.893345
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Youn J, 2000, J VIS COMMUN IMAGE R, V11, P385, DOI 10.1006/jvci.2000.0449
   Youn JN, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P243, DOI 10.1145/319463.319616
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhou Z, 2005, IEEE INT SYMP CIRC S, P1230
NR 22
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 130
EP 140
DI 10.1016/j.jvcir.2016.03.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100012
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Lin, TL
   Chou, CC
AF Liu, Zhaoyi
   Lin, Ting-Lan
   Chou, Chi-Chan
TI Efficient prediction of CU depth and PU mode for fast HEVC encoding
   using statistical analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC (High Efficiency Video Coding); CU (Coding Unit) size decision; PU
   (Prediction Unit) mode decision; Statistical analysis; k-means
   clustering algorithm
ID DECISION; VIDEO; ALGORITHM
AB High Efficiency Video Coding (HEVC) adopts complex quadtree-structured CU (coding unit) and PU (prediction unit) modes. Thus, the search process for optimal modes causes high computational complexity in HEVC. To solve this problem, a fast coding algorithm is proposed. Thirteen neighboring CTUs (Coding Tree Unit) are divided into three classes with the k-means method, and are selectively used as the reference CTUs to calculate the predicted CU depth levels for the current CTU. Additionally, for every CU depth, we skip some rarely used PU modes to reduce the complexity of the PU selection algorithm. Experimental results show that compared with the HEVC reference software, our algorithm can achieve 56.71% time saving with Low Delay Configuration profile and 59.76% with Random Access Configuration profile, whereas values of BDBR (Bjontegaard Delta Bit Rate) are only 1.0517% and 0.9918%, respectively. Compared with five state-of-the-art algorithms, the proposed algorithm has significant encoding time reduction with good bitrate performances. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Zhaoyi] Beijing Inst Technol, Sch Informat & Elect, 5 South Zhongguancun St, Beijing 100081, Peoples R China.
   [Lin, Ting-Lan; Chou, Chi-Chan] Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
C3 Beijing Institute of Technology; Chung Yuan Christian University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
EM 20091305@bit.edu.cn; tinglan@cycu.edu.tw; g10276011@cycu.edu.tw
FU National Science Council Taiwan [NSC 101-2221-E-033-036, NSC
   102-2221-E-033-018]; Ministry of Science and Technology, Taiwan [MOST
   103-2221-E-033-020, MOST 104-2221-E-033-041, MOST 104-2218-E-033-010]
FX This research is supported by the National Science Council Taiwan, under
   Grants NSC 101-2221-E-033-036 and NSC 102-2221-E-033-018, and by the
   Ministry of Science and Technology, Taiwan, under Grant MOST
   103-2221-E-033-020, MOST 104-2221-E-033-041 and MOST 104-2218-E-033-010.
CR Ahn S, 2013, PICT COD SYMP, P113, DOI 10.1109/PCS.2013.6737696
   [Anonymous], ITUTSG16Q6
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], IEEE INT S CONS EL
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], NAT C COMM NCC
   [Anonymous], 2012, ITUTSG16 WP3
   Bjontegard G., 2001, VCEGM33 ITUT
   da Silva TL, 2013, IEEE I C ELECT CIRC, P165, DOI 10.1109/ICECS.2013.6815380
   Lee JH, 2013, IEEE IMAGE PROC, P1982, DOI 10.1109/ICIP.2013.6738408
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   Panayides A, 2012, IEEE ENG MED BIO, P2170, DOI 10.1109/EMBC.2012.6346391
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun K., 2013, DISCRIMINATION TOMAT, P1
   Tan HL, 2012, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2012.6288011
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yang S, 2014, I SYMP CONSUM ELECTR, P17
   Yang S, 2013, 2013 IEEE 11TH IVMSP WORKSHOP: 3D IMAGE/VIDEO TECHNOLOGIES AND APPLICATIONS (IVMSP 2013)
   Zhang YF, 2013, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2013.13
NR 27
TC 13
Z9 13
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 474
EP 486
DI 10.1016/j.jvcir.2016.03.025
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100041
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Liu, AA
   Su, YT
AF Nie, Wei-Zhi
   Liu, An-An
   Su, Yu-Ting
TI 3D object retrieval based on sparse coding in weak supervision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D model retrieval; Sparse representation; Dictionary learning; Fisher
   discrimination; Weak supervision; Characteristic view extraction;
   Similarity measure; View-based model
ID MODEL; SHAPE; RECOGNITION; SEARCH; COLOR
AB With the rapid development of computer vision and digital capture equipment, we can easily record the 3D information of objects. In the recent years, more and more 3D data are generated, which makes it desirable to develop effective 3D retrieval algorithms. In this paper, we apply the sparse coding method in a weakly supervision manner to address 3D model retrieval. First, each 3D object, which is represented by a set of 2D images, is used to learn dictionary. Then, sparse coding is used to compute the reconstruction residual for each query object. Finally, the residual between the query model and the candidate model is used for 3D model retrieval. In the experiment, ETH, NTU and ALOL dataset are used to evaluate the performance of the proposed method. The results demonstrate the superiority of the proposed method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Nie, Wei-Zhi; Liu, An-An; Su, Yu-Ting] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM anan0422@gmail.com
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61472275, 61303208];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [15JCYBJC16200]; Elite Scholar Program of Tianjin University
   [2014XRG-0046]; Specialized Research Fund for the Doctoral Program of
   Higher Education [20120032120023]
FX This work was supported in part by the National Natural Science
   Foundation of China (61472275, 61303208), the Tianjin Research Program
   of Application Foundation and Advanced Technology (15JCYBJC16200), the
   grant of Elite Scholar Program of Tianjin University (2014XRG-0046),
   Specialized Research Fund for the Doctoral Program of Higher Education
   (20120032120023)
CR Alizadeh F., 2013, P EUROGRAPHICS WORKS, P97
   [Anonymous], 2013, P EUR WORKSH 3D OBJ, DOI DOI 10.2312/3DOR/3DOR13/049-056
   [Anonymous], 2003, INT J IMAGE GRAPH
   [Anonymous], P ACM ICMR
   [Anonymous], 2009, P 17 ACM INT C MULT
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Assfalg J, 2007, IEEE T MULTIMEDIA, V9, P589, DOI 10.1109/TMM.2006.886271
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P374, DOI 10.1109/TMM.2011.2176111
   Furuya T, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P274, DOI 10.1109/CW.2013.60
   Gao Y, 2010, P ACM INT C MULT FIR, P955
   Gao Y., 2015, 3D OBJECT RETRIEVAL
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gao Yue, 2011, SIG P IMAGE COMMUN, V26
   Jarvelin K., 2000, SIGIR Forum, V34, P41
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Lee R. C. T., 1976, IEEE Transactions on Software Engineering, VSE-2, P185, DOI 10.1109/TSE.1976.225946
   Leng B, 2015, IEEE T IMAGE PROCESS, V24, P94, DOI 10.1109/TIP.2014.2372618
   Li B, 2014, MULTIMED TOOLS APPL, V72, P1531, DOI 10.1007/s11042-013-1464-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu K, 2014, IEEE T IMAGE PROCESS, V23, P4553, DOI 10.1109/TIP.2014.2343460
   Mangai MA, 2013, COMPUT ELECTR ENG, V39, P809, DOI 10.1016/j.compeleceng.2013.01.004
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Müller S, 2001, INT J PATTERN RECOGN, V15, P223, DOI 10.1142/S0218001401000800
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   OQUAB MAXIME., 2014, Weakly Supervised Object Recognition with Convolutional Neural Networks
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Pajarola R, 2004, IEEE T VIS COMPUT GR, V10, P598, DOI 10.1109/TVCG.2004.19
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Paquet E, 2007, IEEE T INSTRUM MEAS, V56, P1924, DOI 10.1109/TIM.2007.903605
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Wang Xiangyu, 2014, NEURCOMPTING
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang Luming, 2014, LEARNING PROBABILIST
   Zhong B, 2014, PATTERN RECOGN, V47, P1395, DOI 10.1016/j.patcog.2013.10.002
NR 44
TC 27
Z9 31
U1 3
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 40
EP 45
DI 10.1016/j.jvcir.2015.06.011
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700006
DA 2024-07-18
ER

PT J
AU Nangtin, P
   Kumhom, P
   Chamnongthai, K
AF Nangtin, Prasit
   Kumhom, Pinit
   Chamnongthai, Kosin
TI Gait identification with partial occlusion using six modules and
   consideration of occluded module exclusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait identification; Partial occlusion; Excluding part; Gait Energy
   Image; Visual surveillance system; Silhouette resizing; TDPCA; TDLDA
ID DISCRIMINANT-ANALYSIS; RECOGNITION
AB In gait identification, partial occlusion sometimes occurs and leads to missed identification. This paper proposes a gait identification method for partial occlusion case by using six modules and consideration of occluded module exclusion. In this method, a Gait Energy Image (GEI) is separated into four individual modules, and three of neighboring modules are coupled into other two coupling modules. When partial occlusion of a module occurs, the occluded module is detected and excluded from consideration for gait identification. In addition, the combined TDPCA and TDLDA are employed to extract gait features comparing with trained features in the database, and the candidate with the highest score in matching with the database is selected as identified person. To evaluate performance of proposed method, experiments carried out with CASIA dataset with 123 classes and our own EEPIT dataset with 135 classes indicate effectiveness of module separation and significance of exclusion of occluded modules. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Nangtin, Prasit; Kumhom, Pinit; Chamnongthai, Kosin] King Mongkuts Univ Technol Thonburi, Elect & Telecommun Engn Dept, Fac Engn, 126 Pracha Uthid Rd, Bangkok 10140, Thailand.
C3 King Mongkuts University of Technology Thonburi
RP Chamnongthai, K (corresponding author), King Mongkuts Univ Technol Thonburi, Elect & Telecommun Engn Dept, Fac Engn, 126 Pracha Uthid Rd, Bangkok 10140, Thailand.
EM prasit@pit.ac.th; pinit.kum@kmutt.ac.th; kosin.cha@kmutt.ac.th
RI Chamnongthai, Kosin/AEX-9479-2022
OI Chamnongthai, Kosin/0000-0003-1509-5754
CR Ali Hayder., 2011, International Journal of Signal Processing, Image Processing and Pattern (IJSIP), V4, P141
   Boulgouris NV, 2007, PATTERN RECOGN, V40, P1763, DOI 10.1016/j.patcog.2006.11.012
   Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191
   DEMPSTER WT, 1967, AM J ANAT, V120, P33, DOI 10.1002/aja.1001200104
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Lu JW, 2007, PATTERN RECOGN LETT, V28, P2401, DOI 10.1016/j.patrec.2007.08.004
   Makihara Yasushi, 2003, ECCV 06 P 9 EUR C 3, P151
   Nangtin Prasit, 2011, 2011 INT WORKSH SMAR, P13
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Sanguansat P, 2006, IEICE T INF SYST, VE89D, P2164, DOI 10.1093/ietisy/e89-d.7.2164
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang Liang, 2004, IEEE T CIRCUITS SYST, V14, P1
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yu Jun, 2013, IEEE T IND ELECTRON, V62, P3742
NR 21
TC 4
Z9 5
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 107
EP 121
DI 10.1016/j.jvcir.2016.01.008
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200009
DA 2024-07-18
ER

PT J
AU Lézoray, O
AF Lezoray, Olivier
TI Complete lattice learning for multivariate mathematical morphology
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mathematical morphology; Complete lattice; Rank transform; Manifold
   learning; Multivariate; Quantization; Out of sample extension; Patch
ID OPERATORS; MATRIX
AB The generalization of mathematical morphology to multivariate vector spaces is addressed in this paper. The proposed approach is fully unsupervised and consists in learning a complete lattice from an image as a nonlinear bijective mapping, interpreted in the form of a learned rank transformation together with an ordering of vectors. This unsupervised ordering of vectors relies on three steps: dictionary learning, manifold learning and out of sample extension. In addition to providing an efficient way to construct a vectorial ordering, the proposed approach can become a supervised ordering by the integration of pairwise constraints. The performance of the approach is illustrated with color image processing examples. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lezoray, Olivier] Normandie Univ, UNICAEN, ENSICAEN, GREYC UMR CNRS 6072, Caen, France.
C3 Universite de Caen Normandie; Centre National de la Recherche
   Scientifique (CNRS)
RP Lézoray, O (corresponding author), Normandie Univ, UNICAEN, ENSICAEN, GREYC UMR CNRS 6072, Caen, France.
EM olivier.lezoray@unicaen.fr
RI Lézoray, Olivier/K-7326-2014
OI Lézoray, Olivier/0000-0003-0540-543X
FU Agence Nationale de la Recherche [ANR-14-CE27-0001]; Agence Nationale de
   la Recherche (ANR) [ANR-14-CE27-0001] Funding Source: Agence Nationale
   de la Recherche (ANR)
FX This work received funding from the Agence Nationale de la Recherche,
   ANR-14-CE27-0001 GRAPHSIP.
CR Angulo J, 2005, COMPUT IMAGING VIS, V30, P387
   Angulo J, 2007, COMPUT VIS IMAGE UND, V107, P56, DOI 10.1016/j.cviu.2006.11.008
   Angulo J, 2014, PATTERN RECOGN LETT, V47, P93, DOI 10.1016/j.patrec.2014.05.015
   Angulo J, 2010, J VIS COMMUN IMAGE R, V21, P33, DOI 10.1016/j.jvcir.2009.10.002
   Angulo JS, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P69, DOI 10.1109/ISSPA.2003.1224642
   [Anonymous], 1967, LATTICE THEORY
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], 2012, VECTOR QUANTIZATION
   Aptoula E, 2008, J VIS COMMUN IMAGE R, V19, P165, DOI 10.1016/j.jvcir.2007.10.001
   Aptoula E, 2008, PATTERN RECOGN LETT, V29, P109, DOI 10.1016/j.patrec.2007.09.011
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Burgeth B, 2007, IMAGE VISION COMPUT, V25, P496, DOI 10.1016/j.imavis.2006.06.002
   Burgeth B, 2014, PATTERN RECOGN LETT, V47, P29, DOI 10.1016/j.patrec.2014.01.018
   Cevikalp H, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P489
   Chanussot J., 1997, Sixth International Conference on Image Processing and its Applications (Conf. Publ. No.443), P804, DOI 10.1049/cp:19971007
   Chen C, 2010, NEUROCOMPUTING, V73, P951, DOI 10.1016/j.neucom.2009.08.021
   Drineas P, 2005, J MACH LEARN RES, V6, P2153
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Garcia A, 2008, PROC SPIE, V6812, DOI 10.1117/12.767521
   GOUTSIAS J, 1995, COMPUT VIS IMAGE UND, V62, P326, DOI 10.1006/cviu.1995.1058
   Heijmans H., 1994, Advances in Electronics and Electron Physics
   Keshet R., 2000, Fundamenta Informaticae, V41, P33
   Ledda A, 2005, LECT NOTES COMPUT SC, V3708, P356
   Lee JA, 2007, INFORM SCI STAT, P1
   Lezoray O, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P183, DOI 10.1109/ICIAPW.2007.33
   Lezoray Olivier, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P35
   Lézoray O, 2012, IEEE IMAGE PROC, P129, DOI 10.1109/ICIP.2012.6466812
   Lezoray O, 2002, IEEE T IMAGE PROCESS, V11, P783, DOI 10.1109/TIP.2002.800889
   RONSE C, 1990, SIGNAL PROCESS, V21, P129, DOI 10.1016/0165-1684(90)90046-2
   SALEMBIER P, 2009, ICIP, P2269
   Talbot H., 1998, MATH M ORPHOLOGY ITS, P27
   Talebi H, 2014, IEEE T IMAGE PROCESS, V23, P755, DOI 10.1109/TIP.2013.2293425
   Talwalkar A, 2013, J MACH LEARN RES, V14, P3129
   Velasco-Forero Santiago, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P219, DOI 10.1007/978-3-642-38294-9_19
   Velasco-Forero S, 2014, Advances in low level color image processing, P223
   Velasco-Forero S, 2012, IEEE J-STSP, V6, P753, DOI 10.1109/JSTSP.2012.2211336
   Velasco-Forero S, 2011, LECT NOTES COMPUT SC, V6671, P355, DOI 10.1007/978-3-642-21569-8_31
   Velasco-Forero S, 2011, IEEE T IMAGE PROCESS, V20, P3301, DOI 10.1109/TIP.2011.2144611
   Velasco-Forero S, 2010, IEEE IMAGE PROC, P1409, DOI 10.1109/ICIP.2010.5651305
   Ta VT, 2011, IEEE T IMAGE PROCESS, V20, P1504, DOI 10.1109/TIP.2010.2101610
   [No title captured]
NR 45
TC 17
Z9 18
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 220
EP 235
DI 10.1016/j.jvcir.2015.12.017
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600020
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, TG
   Miao, QG
   Tian, K
   Song, JF
   Yang, Y
   Qi, YT
AF Liu, Tiange
   Miao, Qiguang
   Tian, Kuan
   Song, Jianfeng
   Yang, Yun
   Qi, Yutao
TI SCTMS: Superpixel based color topographic map segmentation method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Scanned topographic map; Superpixel; Multiple
   features combination; Boundary detection; Watershed transform; Region
   merging; Support vector machine
ID IMAGE SEGMENTATION; EXTRACTION; OPTIMIZATION; FEATURES
AB Different from natural image, topographic map is a complex manually generated image which has amount of interlaced lines and area features. Because of the frequent intersection and the overlap between geographic elements, the misalignment in scanner and other disturbances like inappropriate preserving, false color, mixed color and color aliasing problems occur in the raster color maps. These problems could cause serious challenges in segmentation process. In this work, we present a color topographic map segmentation method based on superpixel to overcome these problems. Firstly, the finest partition is obtained based on double color-opponent boundary detection method and watershed approach. Then, a strict region merging method is introduced to prevent mis-merging while superpixels generated. This merging method could make the superpixel partition accurately adherent the boundary between different geographic elements. Finally, luminosity, color and texture information are combinative applied to classify the superpixel into different layers based on support vector machine. The experimental results show that the proposed method outperforms other state-of-art topographic map segmentation approaches. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liu, Tiange; Miao, Qiguang; Tian, Kuan; Song, Jianfeng; Qi, Yutao] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Yang, Yun] Xian Res Inst Surveying & Mapping, Xian 710054, Shaanxi, Peoples R China.
   [Yang, Yun] State Key Lab Geoinformat Engn, Xian 710054, Shaanxi, Peoples R China.
C3 Xidian University
RP Miao, QG (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM qgmiao@126.com
OI Miao, Qiguang/0000-0002-2872-388X; tian, kuan/0000-0002-9409-5842
FU National Natural Science Foundations of China [61472302, 61272280,
   U1404620, 41271447, 61272195]; Program for New Century Excellent Talents
   in University - China [NCET-12-0919]; Fundamental Research Funds for the
   Central Universities [K5051203020, K5051303018, BDY081422, JB150313];
   Natural Science Foundation of Shaanxi Province [2014JM8310, 2010JM8027];
   State Key Laboratory of Geoinformation Engineering [SKLGIE2014-M-4-4]
FX The work was jointly supported by the National Natural Science
   Foundations of China under Grant Nos. 61472302, 61272280, U1404620,
   41271447 and 61272195, the Program for New Century Excellent Talents in
   University - China (NCET-12-0919), the Fundamental Research Funds for
   the Central Universities under Grant Nos. K5051203020, K5051303018,
   BDY081422, and JB150313, Natural Science Foundation of Shaanxi Province,
   under grant Nos. 2014JM8310 and 2010JM8027, The State Key Laboratory of
   Geoinformation Engineering under grant No. SKLGIE2014-M-4-4.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, REMOTE SENSING PIXEL
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], J WSCG
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822
   BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879
   Brox T, 2010, IMAGE VISION COMPUT, V28, P376, DOI 10.1016/j.imavis.2009.06.009
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y, 2006, IEEE T GEOSCI REMOTE, V44, P1048, DOI 10.1109/TGRS.2005.861478
   Chiang Y.Y., 2011, GRAPHICS RECOGNITION, V7423, P25, DOI [DOI 10.1007/978-3-642-36824-0, DOI 10.1007/978-3-642-36824-0_3]
   Chiang YY, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2557423
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   den Hartog J., 1996, Graphics Recognition, Methods and Applications. First International Workshop. Selected Papers, P159
   Dhar DB, 2006, INT J DOC ANAL RECOG, V8, P232, DOI 10.1007/s10032-005-0010-9
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Khotanzad A, 1996, PROCEEDINGS OF THE IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P190, DOI 10.1109/IAI.1996.493751
   Khotanzad A, 2003, IEEE T PATTERN ANAL, V25, P18, DOI 10.1109/TPAMI.2003.1159943
   Knerr S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P41
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Leyk S, 2010, LECT NOTES COMPUT SC, V6020, P231
   Leyk S, 2010, GEOINFORMATICA, V14, P1, DOI 10.1007/s10707-008-0074-z
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mayoraz E, 1999, LECT NOTES COMPUT SC, V1607, P833
   Mello CAB, 2012, IEEE SYS MAN CYBERN, P132, DOI 10.1109/ICSMC.2012.6377689
   Moore A. P., 2008, IEEE C COMPUTER VISI, P1
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   San LM, 2004, I C COMP GRAPH IM VI, P187
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sridhar B., 2013, ACEEE International Journal on Signal and Image Processing, V4, P56
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   [王可 Wang Ke], 2004, [西北工业大学学报, Journal of Northwestern Polytechnical University], V22, P695
   WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Wu YW, 2013, COMPUT VIS IMAGE UND, V117, P1421, DOI 10.1016/j.cviu.2013.05.003
   Xin D., 2006, J INFORM COMPUTING S, V1, P275
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
NR 43
TC 8
Z9 10
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 78
EP 90
DI 10.1016/j.jvcir.2015.12.004
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600007
DA 2024-07-18
ER

PT J
AU Zhu, SY
   Zeng, B
   Gabbouj, M
AF Zhu, Shuyuan
   Zeng, Bing
   Gabbouj, Moncef
TI Adaptive sampling for compressed sensing based image compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparsity; Compressed sensing (CS); Block-based compressed sensing (BCS);
   Image compression; Image coding; Adaptive sampling; Sampling efficiency;
   Measurement allocation
ID DECOMPOSITION; SPARSITY
AB The compressed sensing (CS) theory has been successfully applied to image compression in the past few years as most image signals are sparse in a certain domain. In this paper, we focus on how to improve the sampling efficiency for CS-based image compression by using our proposed adaptive sampling mechanism on the block-based CS (BCS), especially the reweighted one. To achieve this goal, two solutions are developed at the sampling side and reconstruction side, respectively. The proposed sampling mechanism allocates the CS-measurements to image blocks according to the statistical information of each block so as to sample the image more efficiently. A generic allocation algorithm is developed to help assign CS-measurements and several allocation factors derived in the transform domain are used to control the overall allocation in both solutions. Experimental results demonstrate that our adaptive sampling scheme offers a very significant quality improvement as compared with traditional non-adaptive ones. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhu, Shuyuan; Zeng, Bing] Univ Elect Sci & Technol China, Inst Image Proc, Chengdu 610054, Peoples R China.
   [Zeng, Bing] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
   [Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
C3 University of Electronic Science & Technology of China; Hong Kong
   University of Science & Technology; Tampere University
RP Zeng, B (corresponding author), Univ Elect Sci & Technol China, Inst Image Proc, Chengdu 610054, Peoples R China.
EM eezeng@uestc.edu.cn
RI Gabbouj, Moncef/G-4293-2014
OI Gabbouj, Moncef/0000-0002-9788-2323
FU National Key Basic Research Program of China [2015CB351804]; National
   Natural Science Foundation of China [61300091, 61370148]; Sichuan
   Province's Science and Technology Innovative Research Team Program for
   Young Scholars [2014TD0006]; Fundamental Research Funds for the Central
   Universities of China [ZYGX2013J023]
FX This work has been supported by the National Key Basic Research Program
   of China (2015CB351804), National Natural Science Foundation of China
   (61300091 and 61370148), Sichuan Province's Science and Technology
   Innovative Research Team Program for Young Scholars (2014TD0006), and
   Fundamental Research Funds for the Central Universities of China
   (ZYGX2013J023).
CR Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   DeVore RA, 2007, J COMPLEXITY, V23, P918, DOI 10.1016/j.jco.2007.04.002
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Mansour H, 2012, INT CONF ACOUST SPEE, P3465, DOI 10.1109/ICASSP.2012.6288662
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Wipf D, 2010, IEEE J-STSP, V4, P317, DOI 10.1109/JSTSP.2010.2042413
   Wu XL, 2008, IEEE DATA COMPR CONF, P123, DOI 10.1109/DCC.2009.69
   Yang Y, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P373, DOI 10.1109/PCS.2009.5167354
   Zhu SY, 2014, IEEE INT CON MULTI
NR 18
TC 24
Z9 27
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 94
EP 105
DI 10.1016/j.jvcir.2015.03.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900009
DA 2024-07-18
ER

PT J
AU Wang, C
   Shen, MM
   Yao, C
AF Wang, Ci
   Shen, Minmin
   Yao, Chen
TI No-reference quality assessment for DCT-based compressed image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compression distortion; Probability model; No-reference estimate;
   Objective quality assessment; Image quality assessment; Gaussian
   distribution; Uniform distribution; Noise variance
ID STRUCTURAL SIMILARITY; DISTRIBUTIONS; INFORMATION; TRANSFORM; DOMAIN;
   NOISE
AB A blind/no-reference (NR) method is proposed in this paper for image quality assessment (IQA) of the images compressed in discrete cosine transform (DCT) domain. When an image is measured by structural similarity (SSIM), two variances, i.e. mean intensity and variance of the image, are used as features. However, the parameters of original copies are actually unavailable in NR applications; hence SSIM is not widely applicable. To extend SSIM in general cases, we apply Gaussian model to fit quantization noise in spatial domain, and directly estimate noise distribution from the compressed version. Benefit from this rearrangement, the revised SSIM does not require original image as the reference. Heavy compression always results in some zero-value DCT coefficients, which need to be compensated for more accurate parameter estimate. By studying the quantization process, a machine-learning based algorithm is proposed to estimate quantization noise taking image content into consideration. Compared with state-of-the-art algorithms, the proposed IQA is more heuristic and efficient. With some experimental results, we verify that the proposed algorithm (provided no reference image) achieves comparable efficacy to some full reference (FR) methods (provided the reference image), such as SSIM. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Ci] E China Normal Univ, Dept Comp Sci & Technol, Shanghai, Peoples R China.
   [Shen, Minmin] Univ Konstanz, INCIDE Ctr, Constance, Germany.
   [Shen, Minmin] S China Univ Technol, Sch Software Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Yao, Chen] Minist Publ Secur, Res Inst 3, Beijing, Peoples R China.
   [Yao, Chen] Shanghai Key Lab Digital Media Proc & Transmiss, Shanghai, Peoples R China.
C3 East China Normal University; University of Konstanz; South China
   University of Technology; Ministry of Public Security (China)
RP Yao, C (corresponding author), Minist Publ Secur, Res Inst 3, Beijing, Peoples R China.
EM yaochensing@126.com
RI Sun, Yuchen/JZD-1692-2024
FU National Nature Science Foundation of China [60902072, 61302121,
   61201446]; Opening Project of Shanghai Key Laboratory of Digital Media
   Processing and Transmission
FX This work is supported by National Nature Science Foundation of China,
   Nos. 60902072, 61302121, 61201446 as well as the Opening Project of
   Shanghai Key Laboratory of Digital Media Processing and Transmission.
CR Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Hero AO, 1996, IEEE T SIGNAL PROCES, V44, P2026, DOI 10.1109/78.533723
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Narwaria M, 2012, IEEE T IMAGE PROCESS, V21, P3364, DOI 10.1109/TIP.2012.2197010
   Pao IM, 1998, IEEE T CIRC SYST VID, V8, P264, DOI 10.1109/76.678620
   Pappas T.N., 2000, HDB IMAGE VIDEO P
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N., 2007, P 3 INT WORKSH VID P, P1
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   REININGER RC, 1983, IEEE T COMMUN, V31, P835, DOI 10.1109/TCOM.1983.1095893
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Segall CA, 2004, IEEE T IMAGE PROCESS, V13, P898, DOI 10.1109/TIP.2004.827230
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 26
TC 7
Z9 8
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 53
EP 59
DI 10.1016/j.jvcir.2015.01.006
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000007
DA 2024-07-18
ER

PT J
AU Lin, YB
   Young, CP
   Lin, CH
AF Lin, Yen-Bor
   Young, Chung-Ping
   Lin, Chih-Hung
TI Non-iterative and spatial domain focus map estimation based on
   intentional re-blur from a single image (NasBirSi)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Focus map; 3D representation; Algorithm; Visualization; Image processing
ID DEPTH ESTIMATION; ALGORITHM
AB Transforming conventional pre-existing 2D content is still a necessary technique for utilizing pre-existing content for stereo vision. In this paper, a spatial domain focus map estimation algorithm based of an intentional re-blur on a single image, which is the only input data, is presented. The proposed intentional re-blur amplifies the blur in the original input image, and the value of our proposed ratio map is the ratio of the gradient magnitude of the intentional re-blurred image to the gradient magnitude of the original image. The edges of the original input image were re-blurred such that the widths of the edges on the ratio map differ. According to the theoretically derived results and the observations of the example used, the widths of the edges on the introduced ratio map were found to be related to the distance of each object from the camera focus. The pixels close to the focal point of the camera are on a thinner edge. In contrast, the edges are wider when the pixels are farther from the focal point. We utilized this discovery to derive the final focus map, whose enhanced effectiveness, quality, and precision were demonstrated experimentally. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lin, Yen-Bor; Young, Chung-Ping] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
   [Lin, Chih-Hung] Natl Chiayi Univ, Grad Inst Math & Sci Educ, Chiayi 600, Taiwan.
C3 National Cheng Kung University; National Chiayi University
RP Lin, YB (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Tainan 701, Taiwan.
EM yen_bor@yahoo.com.tw
CR [Anonymous], C COMP VIS PATT REC
   [Anonymous], DEPTH ESTIMATION INT
   [Anonymous], 3DTV C TRUE VIS CAPT
   [Anonymous], DEPTH IMAGE BASED RE
   Bando Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409087
   Bing-Zhong Jing, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1205, DOI 10.1109/ICMLC.2012.6359527
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cantoni V, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P90, DOI 10.1109/ICIAP.2001.956990
   Chang YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1958
   Chen WM, 2013, J SYST SOFTWARE, V86, P198, DOI 10.1016/j.jss.2012.07.044
   Cheng CC, 2010, IEEE T CONSUM ELECTR, V56, P1739, DOI 10.1109/TCE.2010.5606320
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Francois E, 1997, IEEE T CIRC SYST VID, V7, P237, DOI 10.1109/76.554436
   Gonzalez R., 2002, WOODS DIGITAL IMAGE
   Guo G, 2008, INT CONF ACOUST SPEE, P2181
   Jung SW, 2012, IEEE SIGNAL PROC LET, V19, P303, DOI 10.1109/LSP.2012.2191616
   Kuo TY, 2011, IEEE T CONSUM ELECTR, V57, P817, DOI 10.1109/TCE.2011.5955227
   LAI SH, 1992, IEEE T PATTERN ANAL, V14, P405, DOI 10.1109/34.126803
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077
   Raskar R, 2004, ACM T GRAPHIC, V23, P679, DOI 10.1145/1015706.1015779
   Ray S., 2002, Applied Photographic Optics
   Sajjad M, 2012, MULTIMEDIA TOOLS APP, P1
   Sajjad M, 2014, SENSORS-BASEL, V14, P3652, DOI 10.3390/s140203652
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   SCHNEIDER G, 1994, IEEE IMAGE PROC, P116, DOI 10.1109/ICIP.1994.413542
   SHAO M, 1991, CVGIP-IMAG UNDERSTAN, V53, P219, DOI 10.1016/1049-9660(91)90029-O
   Wang DL, 2011, J VIS COMMUN IMAGE R, V22, P325, DOI 10.1016/j.jvcir.2011.02.001
   Yang NE, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P311, DOI 10.1109/ICCE.2012.6161883
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P873, DOI 10.1109/TIP.2011.2162739
NR 34
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 80
EP 93
DI 10.1016/j.jvcir.2014.11.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000008
DA 2024-07-18
ER

PT J
AU Zhang, SQ
   Zhao, XM
AF Zhang, Shiqing
   Zhao, Xiaoming
TI Locality-sensitive kernel sparse representation classification for face
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Kernal; Sparsity; Data locality; Face
   recognition; Discriminating; l(1)-norm; Classification
ID ILLUMINATION
AB In this paper a new classification method called locality-sensitive kernel sparse representation classification (LS-KSRC) is proposed for face recognition. LS-KSRC integrates both sparsity and data locality in the kernel feature space rather than in the original feature space. LS-KSRC can learn more discriminating sparse representation coefficients for face recognition. The closed form solution of the l(1)-norm minimization problem for LS-KSRC is also presented. LS-KSRC is compared with kernel sparse representation classification (KSRC), sparse representation classification (SRC), locality-constrained linear coding (LLC), support vector machines (SVM), the nearest neighbor (NN), and the nearest subspace (NS). Experimental results on three benchmarking face databases, i.e., the ORL database, the Extended Yale B database, and the CMU PIE database, demonstrate the promising performance of the proposed method for face recognition, outperforming the other used methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Shiqing; Zhao, Xiaoming] Taizhou Univ, Inst Image Proc & Pattern Recognit, Taizhou 318000, Peoples R China.
C3 Taizhou University
RP Zhao, XM (corresponding author), Taizhou Univ, Inst Image Proc & Pattern Recognit, Taizhou 318000, Peoples R China.
EM tzxyzxm@163.com
FU National Natural Science Foundation of China [61203257, 61272261]
FX This work is supported by National Natural Science Foundation of China
   under Grant Nos. 61203257 and 61272261.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2009, P ADV NEUR INF PROC
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Candes E.J., 2005, l1-MAGIC: Recovery of sparse signals via convex programming
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Cevher V, 2010, IEEE SIGNAL PROC MAG, V27, P92, DOI 10.1109/MSP.2010.938029
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Han B, 2010, J VIS COMMUN IMAGE R, V21, P325, DOI 10.1016/j.jvcir.2010.02.007
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Schmidt M.W., 2008, COMPUTER VISION PATT, P1
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang SQ, 2009, PATTERN RECOGN LETT, V30, P1208, DOI 10.1016/j.patrec.2009.05.011
   Zhou Y., 2012, 8365 SPIE
NR 38
TC 8
Z9 10
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1878
EP 1885
DI 10.1016/j.jvcir.2014.09.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300007
DA 2024-07-18
ER

PT J
AU Tran, TT
   Pham, VT
   Shyu, KK
AF Thi-Thao Tran
   Van-Truong Pham
   Shyu, Kuo-Kai
TI Image segmentation using fuzzy energy-based active contour with shape
   prior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Shape prior; Shape normalization; Level set method;
   Fuzzy energy; Moment-based alignment; Active contour models; PCA
ID LEVEL-SET; KERNEL SPACE; MODEL; NORMALIZATION; FRAMEWORK; MUMFORD;
   DRIVEN
AB This paper presents a fuzzy energy-based active contour model with shape prior for image segmentation. The paper proposes a fuzzy energy functional including a data term and a shape prior term. The data term, inspired from the region-based active contour approach proposed by Chan and Vese, evolves the contour relied on image information. The shape term inspired from Chan and Zhu's work, defined as the distance between the evolving shape and a reference one, constrains the evolving contour with respect to the reference shape. To align the shapes, we exploit the shape normalization procedure which takes into account the affine transformation. In addition, to minimize the energy functional, we utilize a direct method to calculate the energy alterations. The proposed model therefore can deal with images with background clutter and object occlusion, improves the computational speed, and avoids difficulties associated with time step selection issue in gradient descent-based approaches. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Thi-Thao Tran; Van-Truong Pham; Shyu, Kuo-Kai] Natl Cent Univ, Dept Elect Engn, Chungli 320, Taiwan.
   [Van-Truong Pham] Hanoi Univ Sci & Technol, Hanoi, Vietnam.
C3 National Central University; Hanoi University of Science & Technology
   (HUST)
RP Shyu, KK (corresponding author), Natl Cent Univ, Dept Elect Engn, Chungli 320, Taiwan.
EM kkshyu@ee.ncu.edu.tw
RI Pham, Van-Truong/KRP-5967-2024
OI Tran, Thi-Thao/0009-0008-0862-1262; Pham, Van-Truong/0000-0003-3489-0569
FU National Science Council of Taiwan [NSC 102-2221-E-008-087-MY3]
FX The authors would like to thank the National Science Council of Taiwan
   for supporting this research under the Grant No. NSC
   102-2221-E-008-087-MY3.
CR Andreopoulos A, 2008, MED IMAGE ANAL, V12, P335, DOI 10.1016/j.media.2007.12.003
   [Anonymous], 2002, SURFACES
   [Anonymous], P IEEE C COMP VIS PA
   Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343
   Bresson X, 2006, INT J COMPUT VISION, V68, P145, DOI 10.1007/s11263-006-6658-x
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan T., 2005, P COMP VIS PATT REC
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985
   Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   Dambreville S., 2006, P 3 INT C IM AN REC
   Dambreville S, 2008, IEEE T PATTERN ANAL, V30, P1385, DOI 10.1109/TPAMI.2007.70774
   Gibou F., 2005, P 4 ANN HAW INT C ST
   Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439
   Grimson E., 2000, P COMP VIS PATT REC
   Hansson M., 2011, P IEEE S BIOM IM
   He L, 2010, J VIS COMMUN IMAGE R, V21, P343, DOI 10.1016/j.jvcir.2010.02.009
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Krinidis S, 2009, IEEE T IMAGE PROCESS, V18, P2747, DOI 10.1109/TIP.2009.2030468
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   LEU JG, 1989, PATTERN RECOGN LETT, V10, P243, DOI 10.1016/0167-8655(89)90095-0
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   PEI SC, 1995, IMAGE VISION COMPUT, V13, P711, DOI 10.1016/0262-8856(95)98753-G
   Piovano J., 2008, P EUR C COMP VIS ECC
   Riklin-Raviv T, 2007, INT J COMPUT VISION, V72, P309, DOI 10.1007/s11263-006-9042-y
   Rousson M., 2002, P IEEE WORKSH MOT VI
   Sethian J., 1999, LEVEL SET METHODS FA
   Shyu KK, 2012, NONLINEAR DYNAM, V69, P295, DOI 10.1007/s11071-011-0265-2
   SONG B, 2002, 0268 UCLA CAM
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Vu N., 2008, P COMP VIS PATT REC
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xu N., 2003, IEEE INT C COMP VIS
   Xu N, 2007, COMPUT VIS IMAGE UND, V107, P210, DOI 10.1016/j.cviu.2006.11.004
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
NR 42
TC 26
Z9 28
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1732
EP 1745
DI 10.1016/j.jvcir.2014.06.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100022
DA 2024-07-18
ER

PT J
AU Wu, YD
   Sun, Y
   Feng, ZD
   Zhang, HY
AF Wu, Yadong
   Sun, Yu
   Feng, Zhidan
   Zhang, Hongying
TI A novel total variation based frame layer rate control algorithm for
   H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Rate control; Total variation; Incomplete derivative PID
   controller; Quantization parameter; Video coding; Rate distortion model;
   Buffer control
ID ADAPTIVE RATE CONTROL
AB Rate control (RC) plays a crucial role in controlling compression bitrates and encoding qualities for networked video applications. In this research, we propose a new total variation (TV) based frame layer rate control algorithm for H.264/AVC. One of its novelties is that a total variation measure, used in image processing field, is proposed to describe encoding distortion in video compression. For intraframes, we present a TV distortion-quantization (D-TV-Q(step)) model to obtain accurate QP step size (Q(step)). Using TV measure to represent frame complexity, we also present an analytic model to calculate Q(step) for the initial frame, and develop an effective scene change detection method. In addition, an incomplete derivative proportional integral derivative (IDPID) buffer controller is proposed to reduce the deviation between the current buffer fullness and the target buffer fullness, and minimizes the buffer overflow or underflow. Extensive experimental results show that, compared with JVT-W042, the proposed algorithm successfully achieves more accurate target bit rates, reduces frame skipping, decreases quality fluctuation and improves the overall coding quality. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wu, Yadong] Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang 621010, Peoples R China.
   [Wu, Yadong; Sun, Yu] Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72035 USA.
   [Feng, Zhidan] Univ Arkansas Med Sci, IT Res & Dev Grp, Little Rock, AR 72205 USA.
   [Zhang, Hongying] Southwest Univ Sci & Technol, Sch Informat & Engn, Mianyang 621010, Peoples R China.
C3 Southwest University of Science & Technology - China; University of
   Central Arkansas; University of Arkansas System; University of Arkansas
   Medical Sciences; Southwest University of Science & Technology - China
RP Sun, Y (corresponding author), Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72035 USA.
EM yusun@uca.edu
FU University of Central Arkansas; National Natural Science Foundation of
   China [61303127]
FX This work is partially founded by China Scholarship Council (CSC),
   faculty sabbatical leave fund of University of Central Arkansas, and
   National Natural Science Foundation of China (Grant No. 61303127). We
   sincerely thank the editor and the reviewers for their detailed,
   valuable, and insightful comments.
CR Bennett S., 1993, A history of control engineering, 1930-1955, P48
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chan T, 2005, HDB MATH MODELS COMP
   Goto T, 2011, IEEE T CONSUM ELECTR, V57, P253, DOI 10.1109/TCE.2011.5735510
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   ISO/IECJTC1/SC29/WG11, 1993, ISOIECJTC1SC29WG11 T
   ITU-T/SG15, 1997, ITUTSG15 TMN8
   Jing X, 2008, IEEE SIGNAL PROC LET, V15, P373, DOI 10.1109/LSP.2008.920010
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   LEONTARIS A, 2007, JVT W042 23 M SAN JO
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shen LQ, 2007, OPT ENG, V46, DOI 10.1117/1.2754303
   Suhring K., 2011, H 264 AVC REFERENCE
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   Sun Y, 2009, IET IMAGE PROCESS, V3, P286, DOI 10.1049/iet-ipr.2009.0037
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P140, DOI 10.1109/TCSVT.2007.913757
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu PH, 2007, IEEE T CIRC SYST VID, V17, P857, DOI 10.1109/TCSVT.2007.899605
   Yan B, 2009, IEEE SIGNAL PROC LET, V16, P145, DOI 10.1109/LSP.2008.2010813
   Zhou YM, 2011, IEEE T CIRCUITS-II, V58, P184, DOI 10.1109/TCSII.2011.2106350
NR 24
TC 3
Z9 4
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 879
EP 890
DI 10.1016/j.jvcir.2014.02.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200017
DA 2024-07-18
ER

PT J
AU Kayhan, SK
AF Kayhan, Sema Koc
TI An effective 2-stage method for removing impulse noise in images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Impulse noise removal; Weighted mean filter; Robust estimation;
   Geman-McClure function; Impulse noise detector; Neuro-fuzzy; Image
   denoising; Adaptive filter
ID SWITCHING MEDIAN FILTER; ROBUST ESTIMATION; CORRUPTED IMAGES; DETECTOR;
   ALGORITHM
AB In this paper, a robust 2-stage impulse noise removal system is proposed to remove impulse noise from extremely corrupted images. The contributions are in two-fold. First, a neuro-fuzzy based impulse noise detector (NFIDET) is introduced to identify the noisy pixels. NFIDET is a powerful noise detector that can handle image corruption even up to 90% with zero miss and false detection rate with a simple neuro-fuzzy structure. This is the best result among the other impulse noise detectors in the literature. Second, this paper presents a new approach for weight calculation of adaptive weighted mean filter by using robust statistical model. An adaptive robust weighted mean (ARWM) filter removes a detected noisy pixel by adaptively determining filtering window size and replacing a noisy pixel with the weighted mean of the noise-free pixels in its window. A Geman-McClure robust estimation function is used to estimate the weights of the pixels. Simulation results also show that the proposed robust filter substantially outperforms many other existing algorithms in terms of image restoration. (C) 2013 Elsevier Inc. All rights reserved.
C1 Gaziantep Univ, Dept Elect & Elect, TR-27310 Gaziantep, Turkey.
C3 Gaziantep University
RP Kayhan, SK (corresponding author), Gaziantep Univ, Dept Elect & Elect, TR-27310 Gaziantep, Turkey.
EM skoc@gantep.edu.tr
RI kayhan, sema/AAE-1157-2020
CR Alajlan N, 2004, SIGNAL PROCESS-IMAGE, V19, P993, DOI 10.1016/j.image.2004.08.003
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Deng ZF, 2007, IEEE SIGNAL PROC LET, V14, P31, DOI 10.1109/LSP.2006.881524
   Dong Yiqiu, 2006, Acta Scientiarum Naturalium Universitatis Pekinensis, V42, P604
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Duan F, 2010, IEEE SIGNAL PROC LET, V17, P647, DOI 10.1109/LSP.2010.2049515
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   GEMAN S, 1987, P 46 SESS INT STAT I, V52
   Hampel FR, 1986, Robust statistics. The approach based on influence functions
   Hampel F, 2011, COMPUT STAT DATA AN, V55, P324, DOI 10.1016/j.csda.2010.05.001
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Noha A., 2008, P SPIE VISUAL COMMUN, V6822
   Peter DJ, 2010, J COMPUT SCI TECH-CH, V25, P623, DOI 10.1007/s11390-010-9351-z
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Rabie T, 2005, IEEE T IMAGE PROCESS, V14, P1755, DOI 10.1109/TIP.2005.857276
   Shademan A., 2010, IEEE INT C ROB AUT A
   SUGENO M, 1988, FUZZY SET SYST, V28, P15, DOI 10.1016/0165-0114(88)90113-3
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Xu HX, 2004, PATTERN RECOGN LETT, V25, P1657, DOI 10.1016/j.patrec.2004.05.025
   Yen J, 1998, IEEE T FUZZY SYST, V6, P530, DOI 10.1109/91.728447
   Yüksel ME, 2004, IEEE T FUZZY SYST, V12, P854, DOI 10.1109/TFUZZ.2004.836075
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
NR 33
TC 9
Z9 10
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 478
EP 486
DI 10.1016/j.jvcir.2013.12.016
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300023
DA 2024-07-18
ER

PT J
AU Zhang, XB
   Feng, XC
AF Zhang, Xiaobo
   Feng, Xiangchu
TI Multiple-step local Wiener filter with proper stopping in wavelet.
   domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Wavelet transform; The heat diffusion equation; Wiener
   filter; Proper stopping; Denoising amount; Noise variance; Iterative
   implementation
ID IMAGE DENOISING ALGORITHM; WINDOWS
AB In this paper, we propose an adaptive multiple steps local Wiener filter image denoising algorithm in the wavelet domain. This algorithm can be considered as a discretized implementation of adaptive heat diffusion equation, and is carried out by multiple successive steps. The denoised output from one iteration is taken as the input to the next. The proper iteration number is determined by total denoising amount which is measured by noise variance. The selected local window sizes are also relatively stable. The experimental results show the effectiveness of the proposed method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Xiaobo; Feng, Xiangchu] Xidian Univ, Dept Math, Xian 710071, Peoples R China.
   [Zhang, Xiaobo] Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
C3 Xidian University; Xianyang Normal University
RP Zhang, XB (corresponding author), Xidian Univ, Dept Math, Xian 710071, Peoples R China.
EM zhangxiaobo419@126.com
OI Zhang, Xiaobo/0000-0001-6018-4655
FU National Nature Science Foundation of China [61102018, 61271294];
   Natural Science Foundation of Xianyang Normal University [11XSYK304]
FX This work is partially supported by the National Nature Science
   Foundation of China (Grant Nos. 61102018 and 61271294) and Natural
   Science Foundation of Xianyang Normal University (No. 11XSYK304).
CR Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Eom IK, 2004, IEEE SIGNAL PROC LET, V11, P937, DOI 10.1109/LSP.2004.836940
   Ghael SP, 1997, P SOC PHOTO-OPT INS, V3169, P389, DOI 10.1117/12.292799
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Mandava AK, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3628671
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Rahman SMM, 2008, IEEE T CIRCUITS-I, V55, P2013, DOI 10.1109/TCSI.2008.918198
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Shui PL, 2007, SIGNAL PROCESS, V87, P1721, DOI 10.1016/j.sigpro.2007.01.021
   Shui PL, 2005, IEEE SIGNAL PROC LET, V12, P681, DOI 10.1109/LSP.2005.855555
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Zhang XB, 2013, COMPUT ELECTR ENG, V39, P934, DOI 10.1016/j.compeleceng.2012.07.013
   Zhong JM, 2008, IEEE T CIRCUITS-I, V55, P2716, DOI 10.1109/TCSI.2008.920061
NR 18
TC 14
Z9 18
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 254
EP 262
DI 10.1016/j.jvcir.2013.11.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300002
DA 2024-07-18
ER

PT J
AU Rodtook, A
   Makhanov, SS
AF Rodtook, Annupan
   Makhanov, Stanislav S.
TI Multi-feature gradient vector flow snakes for adaptive segmentation of
   the ultrasound images of breast cancer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active contours; Breast cancer; Ultra sound images; Direction score;
   Convergence; Numerical experiments; Ground truth; Ultrasound images of
   breast cancer
ID ACTIVE CONTOUR MODEL; EXTERNAL FORCE; T-SNAKES; SHAPE; BOUNDARY; FIELD;
   ALGORITHMS; MUMFORD; TUMOR
AB Segmentation of ultrasound (US) images of breast cancer is one of the most challenging problems of the modern medical image processing. A number of popular codes for US segmentation are based on a generalized gradient vector flow (GGVF) method proposed by Xu and Prince. The GGVF equations include a smoothing term (diffusion) applied to regions of small gradients of the edge map and a stopping term to fix and extend large gradients appearing at the boundary of the object.
   The paper proposes two new directions. The first component is diffusion as a polynomial function of the intensity of the edge map. The second component is the orientation score of the vector field. The new features are integrated into the GGVF equations in the smoothing and the stopping term.
   The algorithms, having been tested by a set of ground truth images, show that the proposed techniques lead to a better convergence and better segmentation accuracy with the reference to conventional GGVF snakes. The adaptive multi-feature snake does not require any hand-tuning. However, it is as efficient as the standard GGVF with the parameters selected by the "brutal force approach". Finally, proposed approach has been tested against recent modifications of GGVF, i.e. the Poisson gradient vector flow, the mixed noise vector flow and the convolution vector flow. The numerical tests employing 195 synthetic and 48 real ultrasound images show a tangible improvement in the accuracy of segmentation. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Rodtook, Annupan] Ramkhamhang Univ, Dept Comp Sci, Bangkok 10240, Thailand.
   [Makhanov, Stanislav S.] Thammasat Univ, Sirindhorn Int Inst Technol, Sch Informat & Comp Technol, Pathum Thani 12000, Thailand.
C3 Ramkhamhaeng University; Thammasat University
RP Makhanov, SS (corresponding author), Thammasat Univ, Sirindhorn Int Inst Technol, Sch Informat & Comp Technol, Pathum Thani 12000, Thailand.
EM makhanov@siit.tu.ac.th
RI Rodtook, Annupan/GOV-7658-2022; Makhanov, Stanislav/AAT-6430-2020;
   S.Makhanov/ABA-3316-2020
OI S.Makhanov/0000-0002-1906-0359; Rodtook, Annupan/0000-0001-5433-1305
FU Thailand Research Fund [BRG5380016]; Center of Excellency in Biomedical
   Engineering, Thammasat University of Thailand
FX We acknowledge the codes to compute the convolution vector flows (CVF)
   generously provided by Dr. B. Li. We wish to thank Dr. Vongsaisuwon, Dr.
   Chulakadabba and Dr. Manasnayakorn with the Queen Sirikit Center for
   Breast Cancer of Bangkok for the ground truth images. This research is
   sponsored by Thailand Research Fund grant BRG5380016 and the Center of
   Excellency in Biomedical Engineering, Thammasat University of Thailand.
CR Akgul YS, 1998, PROC CVPR IEEE, P298, DOI 10.1109/CVPR.1998.698623
   Alemán-Flores M, 2005, INT CONGR SER, V1281, P1063, DOI 10.1016/j.ics.2005.03.157
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Castelmen K.R., 1996, DIGITAL IMAGE PROCES
   Chan-Feil L., 2008, ACTA AUTOMATICA SINI, V34, P660
   Chang RF, 2003, ULTRASOUND MED BIOL, V29, P1571, DOI 10.1016/S0301-5629(03)00992-X
   Charmi MA, 2008, PATTERN RECOGN LETT, V29, P897, DOI 10.1016/j.patrec.2008.01.011
   Chen CM, 2000, ULTRASOUND MED BIOL, V26, P273, DOI 10.1016/S0301-5629(99)00140-4
   Chen DR, 2003, ULTRASOUND MED BIOL, V29, P1017, DOI 10.1016/S0301-5629(03)00059-0
   Cheng HD, 2010, PATTERN RECOGN, V43, P299, DOI 10.1016/j.patcog.2009.05.012
   Cheng JR, 2006, IEEE T IMAGE PROCESS, V15, P1563, DOI 10.1109/TIP.2006.871140
   Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108
   Chipman H, 2006, BIOSTATISTICS, V7, P286, DOI 10.1093/biostatistics/kxj007
   Chucherd S, 2010, IEICE T INF SYST, VE93D, P2822, DOI 10.1587/transinf.E93.D.2822
   Chung R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P849, DOI 10.1109/ICPR.1996.546144
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Cvancarova M, 2005, INT CONGR SER, V1281, P218, DOI 10.1016/j.ics.2005.03.190
   Czerwinski RN, 1999, IEEE T MED IMAGING, V18, P126, DOI 10.1109/42.759114
   Dagher I, 2008, IMAGE VISION COMPUT, V26, P905, DOI 10.1016/j.imavis.2007.10.010
   Delingette H, 2001, COMPUT VIS IMAGE UND, V83, P140, DOI 10.1006/cviu.2001.0920
   Delingnette H., 2000, 6 EUR C COMP VIS ECC, V2, P381
   Diop ES, 2013, MED IMAGE ANAL, V17, P165, DOI 10.1016/j.media.2012.09.006
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Fenster A, 1998, IEEE T INSTRUM MEAS, V47, P1439, DOI 10.1109/19.746709
   Fenster SD, 2001, IEEE T PATTERN ANAL, V23, P1028, DOI 10.1109/34.955115
   FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Ghita O, 2010, PATTERN RECOGN, V43, P2646, DOI 10.1016/j.patcog.2010.02.023
   Giraldi G, 2003, PATTERN RECOGN LETT, V24, P993, DOI 10.1016/S0167-8655(02)00223-4
   Gupta S, 2007, DIGIT SIGNAL PROCESS, V17, P542, DOI 10.1016/j.dsp.2006.12.001
   Hamarneh G, 2000, COMPUT CARDIOL, V27, P115, DOI 10.1109/CIC.2000.898469
   He L, 2008, IMAGE VISION COMPUT, V26, P141, DOI 10.1016/j.imavis.2007.07.010
   Hsu C.Y., 2003, P C CVGIP 2003 TAIW, P477
   Hsu CY, 2008, COMPUT MED IMAG GRAP, V32, P601, DOI 10.1016/j.compmedimag.2008.07.001
   Hsu CY, 2012, FUTURE GENER COMP SY, V28, P322, DOI 10.1016/j.future.2010.11.008
   Huang YL, 2007, J DIGIT IMAGING, V20, P238, DOI 10.1007/s10278-006-1041-6
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   Jumaat AK, 2010, PROCD SOC BEHV, V8, P640, DOI 10.1016/j.sbspro.2010.12.089
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KUAN DT, 1987, IEEE T ACOUST SPEECH, V35, P373, DOI 10.1109/TASSP.1987.1165131
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lefebvre F, 1998, IEEE T MED IMAGING, V17, P45, DOI 10.1109/42.668693
   Levienaise-Obadia B, 1999, IMAGE VISION COMPUT, V17, P583, DOI 10.1016/S0262-8856(98)00177-2
   Li B, 2007, IEEE T IMAGE PROCESS, V16, P2096, DOI 10.1109/TIP.2007.899601
   Li CM, 2005, PATTERN RECOGN, V38, P1947, DOI 10.1016/j.patcog.2004.12.015
   Liu B, 2010, PATTERN RECOGN, V43, P2028, DOI 10.1016/j.patcog.2010.01.002
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   McInerney T, 2008, COMPUT MED IMAG GRAP, V32, P331, DOI 10.1016/j.compmedimag.2007.11.004
   McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6
   Mignotte M, 2001, COMPUT MED IMAG GRAP, V25, P265, DOI 10.1016/S0895-6111(00)00075-6
   Mille J, 2009, COMPUT VIS IMAGE UND, V113, P946, DOI 10.1016/j.cviu.2009.05.002
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Naldi G., 2002, Surveys on Mathematics for Industry, V10, P315
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Park H, 2001, IEEE T CIRC SYST VID, V11, P252, DOI 10.1109/76.905991
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pujol O, 2005, IMAGE VISION COMPUT, V23, P681, DOI 10.1016/j.imavis.2005.03.007
   Ray N, 2001, PATTERN RECOGN, V34, P1483, DOI 10.1016/S0031-3203(00)00077-7
   Rochery M, 2006, INT J COMPUT VISION, V69, P27, DOI 10.1007/s11263-006-6851-y
   Rodtook A, 2010, PATTERN RECOGN, V43, P3522, DOI 10.1016/j.patcog.2010.04.003
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Shang YF, 2008, COMPUT MED IMAG GRAP, V32, P109, DOI 10.1016/j.compmedimag.2007.10.004
   Shih FY, 2007, COMPUT VIS IMAGE UND, V105, P93, DOI 10.1016/j.cviu.2006.08.007
   Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193
   Strintzis MG, 1997, IEEE SIGNAL PROC LET, V4, P156, DOI 10.1109/97.586034
   Tang JS, 2009, PATTERN RECOGN, V42, P1172, DOI 10.1016/j.patcog.2008.09.007
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Vitti A, 2012, ISPRS J PHOTOGRAMM, V69, P50, DOI 10.1016/j.isprsjprs.2012.02.005
   Wang X, 2004, INT J COMPUT VISION, V59, P87, DOI 10.1023/B:VISI.0000020672.14006.ad
   Wei M, 2004, COMPUT MED IMAG GRAP, V28, P109, DOI 10.1016/j.compmedimag.2003.12.002
   Xu C., 2000, HDB MEDICAL IMAGING, P129
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yu JH, 2009, COMPUT METH PROG BIO, V96, P193, DOI 10.1016/j.cmpb.2009.04.013
   Yuan Y, 2012, MATH COMPUT MODEL, V55, P1705, DOI 10.1016/j.mcm.2011.11.014
   Zhang Y, 2007, COMPUT BIOL MED, V37, P1591, DOI 10.1016/j.compbiomed.2007.02.008
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zhu XJ, 2011, ULTRASONICS, V51, P181, DOI 10.1016/j.ultras.2010.08.001
NR 82
TC 40
Z9 45
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1414
EP 1430
DI 10.1016/j.jvcir.2013.09.009
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700016
DA 2024-07-18
ER

PT J
AU Chen, DY
   Chiu, YM
AF Chen, Duan-Yu
   Chiu, Yu-Ming
TI Visual attention guided video copy detection based on feature points
   matching with geometric-constraint measurement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention; Video copy detection; Feature point; Geometric
   constraint; Spatiotemporal analysis; Delaunay triangulation; Video copy
   attacks; Similarity measurement
ID MODEL
AB In this paper, to efficiently detect video copies, focus of interests in videos is first localized based on 3D spatiotemporal visual attention modeling. Salient feature points are then detected in visual attention regions. Prior to evaluate similarity between source and target video sequences using feature points, geometric constraint measurement is employed for conducting bi-directional point matching in order to remove noisy feature points and simultaneously maintain robust feature point pairs. Consequently, video matching is transformed to frame-based time-series linear search problem. Our proposed approach achieves promising high detection rate under distinct video copy attacks and thus shows its feasibility in real-world applications. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Duan-Yu; Chiu, Yu-Ming] Yuan Ze Univ, Dept Elect Engn, Chungli, Taiwan.
C3 Yuan Ze University
RP Chen, DY (corresponding author), Yuan Ze Univ, Dept Elect Engn, Chungli, Taiwan.
EM s994622@mail.yzu.edu.tw
CR Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chiu CY, 2010, IEEE T CIRC SYST VID, V20, P1603, DOI 10.1109/TCSVT.2010.2087471
   Chum O., 2007, P ACM INT C IM VID R
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hoad TC, 2006, ACM T INFORM SYST, V24, P1, DOI 10.1145/1125857.1125858
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   James W., 1980, PRINCIPLES PSYCHOL
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Li S, 2007, IEEE T CIRC SYST VID, V17, P1383, DOI 10.1109/TCSVT.2007.903798
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   PAL NR, 1991, IEEE T SYST MAN CYB, V21, P1260, DOI 10.1109/21.120079
   Xiaojie Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1393, DOI 10.1109/ICPR.2010.344
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
NR 18
TC 4
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 544
EP 551
DI 10.1016/j.jvcir.2013.04.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900004
DA 2024-07-18
ER

PT J
AU Choi, IH
   Nam, YO
   Song, BC
AF Choi, Ik Hyun
   Nam, Yeon-Oh
   Song, Byung Cheol
TI A content-adaptive sharpness enhancement algorithm using 2D FIR filters
   trained by pre-emphasis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pre-emphasis; Sharpening; Learning; FIR; Dictionary; Content-adaptive;
   Synthesis; Patch
ID IMAGE-ENHANCEMENT
AB This paper proposes a content-adaptive sharpening algorithm using two-dimensional (2D) FIR filters trained by pre-emphasis for various image pairs. In the learning stage, all low-quality (LQ) and high-quality (HQ) image pairs are first pre-emphasized, i.e., properly sharpened. Then selective 2D FIR filter coefficients for high-frequency synthesis are trained using the pre-emphasized LQ-HQ image pairs, and then are stored in a dictionary that resembles an LUT (look-up table). In the inference stage, each input image is pre-emphasized in the same manner as in the learning stage. The best-matched 2D filter for each LQ patch is then found in the dictionary, and an HQ patch corresponding to the input LQ patch is synthesized using the resultant 2D FIR filter. The experiment results show that the proposed algorithm visually outperforms existing ones and that the mean of absolute errors (MAEs) and MSSSIM (multi-scale structure similarity) of the proposed algorithm are about 10% to 60% lower and about 0.002-0.053 higher, respectively than those of the existing algorithms. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Choi, Ik Hyun; Nam, Yeon-Oh; Song, Byung Cheol] Inha Univ, Inchon 302751, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Sch Elect Engn, 253 Yonghyun 4Dong, Inchon 402751, South Korea.
EM bcsong@inha.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2012000446]; LG Electronics
FX This research was financially supported by Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education, Science and Technology (2012000446), and
   by LG Electronics.
CR [Anonymous], 2010, EUR C COMP VIS
   Bellers EB, 2003, PROC SPIE, V5022, P594, DOI 10.1117/12.476707
   Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185
   Cvetkovic S, 2008, IEEE T CONSUM ELECTR, V54, P1, DOI 10.1109/TCE.2008.4470016
   Cvetkovic SD, 2011, IEEE J-STSP, V5, P217, DOI 10.1109/JSTSP.2010.2055831
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Kim C, 2010, IEEE IMAGE PROC, P2017, DOI 10.1109/ICIP.2010.5651057
   Lee S, 2007, IEEE T CIRC SYST VID, V17, P199, DOI 10.1109/TCSVT.2006.887078
   Liu B, 2011, IEEE T CONSUM ELECTR, V57, P583, DOI 10.1109/TCE.2011.5955195
   Ojo OA, 2000, IEEE T CONSUM ELECTR, V46, P474, DOI 10.1109/30.883396
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Rieder P, 2001, IEEE T CONSUM ELECTR, V47, P666, DOI 10.1109/30.964161
   Shao L, 2008, IEEE T IMAGE PROCESS, V17, P1772, DOI 10.1109/TIP.2008.2002162
   Shao L, 2008, SIGNAL PROCESS-IMAGE, V23, P463, DOI 10.1016/j.image.2008.04.011
   Shao L, 2011, SIGNAL IMAGE VIDEO P, V5, P307, DOI 10.1007/s11760-010-0202-8
   Tegenbosch A.P., 2004, P SPIE VCIP, P1181
   Toh KKV, 2011, IEEE T CONSUM ELECTR, V57, P1227, DOI 10.1109/TCE.2011.6018878
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Xu BL, 2010, IEEE T CONSUM ELECTR, V56, P1746, DOI 10.1109/TCE.2010.5606321
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
NR 24
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 579
EP 591
DI 10.1016/j.jvcir.2013.04.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900007
DA 2024-07-18
ER

PT J
AU Lu, CY
   Min, H
   Gui, J
   Zhu, L
   Lei, YK
AF Lu, Can-Yi
   Min, Hai
   Gui, Jie
   Zhu, Lin
   Lei, Ying-Ke
TI Face recognition via Weighted Sparse Representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Weighted Sparse Representation; Nearest Feature
   Classifiers; Locality; Linearity; Sparse Representation; Classification;
   Local representation
AB Face recognition using Sparse Representation based Classification (SRC) is a new hot technique in recent years. SRC can be regarded as a generalization of Nearest Neighbor and Nearest Feature Subspace. This paper first reviews the Nearest Feature Classifiers (NFCs), including Nearest Neighbor (NN), Nearest Feature Line (NFL), Nearest Feature Plane (NFP) and Nearest Feature Subspace (NFS), and formulates them as general optimization problems, which provides a new perspective for understanding NFCs and SRC. Then a locality Weighted Sparse Representation based Classification (WSRC) method is proposed. WSRC utilizes both data locality and linearity; it can be regarded as extensions of SRC, but the coding is local. Experimental results on the Extended Yale B, AR databases and several data sets from the UCI repository show that WSRC is more effective than SRC. Crown Copyright (C) 2012 Published by Elsevier Inc. All rights reserved.
C1 [Lu, Can-Yi; Min, Hai; Gui, Jie; Zhu, Lin] Chinese Acad Sci, Hefei Inst Intelligent Machines, Hefei, Peoples R China.
   [Lu, Can-Yi; Min, Hai; Zhu, Lin] Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China.
   [Lei, Ying-Ke] Inst Elect Engn, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Lu, CY (corresponding author), Chinese Acad Sci, Hefei Inst Intelligent Machines, Hefei, Peoples R China.
EM canyilu@gmail.com
FU National Science Foundation of China [60975005, 61005010, 60873012,
   60805021, 60905023, 31071168, 61133010]; Knowledge Innovation Program of
   the Chinese Academy of Sciences [Y023A61121]
FX This work was supported by the grants of the National Science Foundation
   of China, Nos. 60975005, 61005010, 60873012, 60805021, 60905023,
   31071168, 61133010, and the Knowledge Innovation Program of the Chinese
   Academy of Sciences, Y023A61121.
CR Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   [Anonymous], 2009, P ADV NEUR INF PROC
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Frank A., 2010, UCI MACHINE LEARNING
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Liu XM, 2003, PATTERN RECOGN, V36, P313, DOI 10.1016/S0031-3203(02)00033-X
   Lu C.-Y., 2012, ADV INTELLIGENT COMP, P83
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Martinez A.M., 1998, 24 CVC TECHN
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shan SG, 2002, INT CONF ACOUST SPEE, P2125
   Shan SG, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P1522, DOI 10.1109/ICOSP.2000.893388
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yu Kai, 2010, ICML, P1215
NR 29
TC 185
Z9 210
U1 1
U2 76
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 111
EP 116
DI 10.1016/j.jvcir.2012.05.003
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000004
DA 2024-07-18
ER

PT J
AU Liao, HB
   Chen, QH
   Zhou, QJ
   Guo, L
AF Liao, Hai-bin
   Chen, Qing-hu
   Zhou, Qian-jin
   Guo, Lin
TI Rapid 3D face reconstruction by fusion of SFS and Local Morphable Model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reconstruction; Feature extraction; Image representation; Dense
   correspondence; Linear combination; 3D face modeling;
   Shape-From-Shading; 3D Morphable Model; Radial basis function
ID RECOVERING FACIAL SHAPE; STATISTICAL-MODEL; SINGLE IMAGE; ALBEDO
AB Various modeling methodologies have been proposed to model the human face realistically. However, despite the fact that these methods can give high-quality results, the time, cost, and labor required to generate such models by these methods are often high. In this paper, we propose an integrated modeling approach combining Shape-From-Shading (SFS) and Local Morphable Model (LMM), which can rapidly create a realistic 3D face model on the basis of a single 2D image rapidly. This method obtains 3D contour face quickly by SFS firstly; then, recovers local accurate 3D data by LMM; lastly, reconstructs a 3D face model of high-accuracy by carrying out interpolation smoothing on the 3D contour face with local 3D accurate data. Experimental results show that this method has the advantages of modeling with higher accuracy and lower complexity, and can reconstruct personalized 3D face model from a single real-world photo in a short time. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Liao, Hai-bin; Chen, Qing-hu; Zhou, Qian-jin; Guo, Lin] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Liao, HB (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
EM liao_haibing@163.com
RI Liao, Haibin/AAB-6485-2020
OI Liao, Haibin/0000-0002-7984-2811
FU Fundamental Research Funds for the Central Universities
   [20102120103000004]; Scientific and Technological Project of Henan
   Province [092102210398]
FX We are grateful to the Beijing University of Multimedia Technology and
   Graphics Lab which provided the BJUT-3D Face Database, and sincerely
   thank the students of School of Electronic Information at Wuhan
   University for the photos herein. This work is supported by the
   Fundamental Research Funds for the Central Universities (No:
   20102120103000004) and the Scientific and Technological Project of Henan
   Province (No: 092102210398).
CR [Anonymous], 2005, MISKLTR05FMFR001 BJU
   Baek Seung-Yeob, 2009, P 8 INT C VIRT REAL, P94
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Blanz V., 2002, IT+TI Informationstechnik und Technische Informatik, V44, P295, DOI 10.1524/itit.2002.44.6.295
   Brooks M.J., 1985, P IJCAI 9 ANGELES CA, P932
   Castelan M, 2007, IEEE T IMAGE PROCESS, V16, P1139, DOI 10.1109/TIP.2006.891351
   Castelán M, 2006, COMPUT VIS IMAGE UND, V103, P64, DOI 10.1016/j.cviu.2006.03.001
   Chen WC, 2010, J VIS COMMUN IMAGE R, V21, P427, DOI 10.1016/j.jvcir.2010.03.004
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   DeCarlo D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P67, DOI 10.1145/280814.280823
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gong X, 2007, LECT NOTES COMPUT SC, V4841, P488
   Gong X, 2010, LECT NOTES ARTIF INT, V6401, P419, DOI 10.1007/978-3-642-16248-0_59
   Hu YX, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P843
   Jiang DL, 2005, PATTERN RECOGN, V38, P787, DOI 10.1016/j.patcog.2004.11.004
   Jingu Heo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P20, DOI 10.1109/CVPR.2009.5204300
   Kemelmacher I, 2006, LECT NOTES COMPUT SC, V3951, P277
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Knothe R, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P637
   Lee WS, 2000, IMAGE VISION COMPUT, V18, P355, DOI 10.1016/S0262-8856(99)00057-8
   LIU Z, 2000, MSRTR200011 MICR COR
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Peng X., 2006, J COMPUTER AIDED DES, V18, P743
   PIGHIN F, 1999, THESIS U WASHINGTON
   Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3
   Romdhani S., 2005, THESIS U BASEL BRUSS
   Samaras D, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.855858
   Smith WAP, 2005, IEEE I CONF COMP VIS, P588
   Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251
   Wallraven C., 1999, DAGM S, P405
   ZHA HB, 2003, P 8 INT C COMP AID D, P217
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658
   Zhou SK, 2004, LECT NOTES COMPUT SC, V3021, P588
NR 37
TC 13
Z9 16
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 924
EP 931
DI 10.1016/j.jvcir.2012.06.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900009
DA 2024-07-18
ER

PT J
AU Zhang, PZ
   Wang, SZ
   Wang, RT
AF Zhang, Peizhen
   Wang, Shuozhong
   Wang, Runtian
TI Reducing frequency-domain artifacts of binary image due to coarse
   sampling by repeated interpolation and smoothing of Radon projections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discrete Radon transform; Radon projection; Fourier slice theorem; Polar
   coordinate interpolation; Low-pass filtering; Fourier diffraction
   theorem; Acoustic tomography; Interpolation-smoothing-decimation
ID TRANSFORM
AB We develop a method to calculate 2D spectrum of a binary image with better quality than that obtained via direct 2D-FFT. With FFT, jagged edges of objects due to coarse sampling introduce artifacts into the frequency domain, especially in the high-frequency area. With the proposed method, Radon projections of the binary image along lines at different viewing angles are calculated. Each projection is extended by interpolation, then smoothed and decimated. The interpolation-smoothing-decimation operation is repeated several times to reduce ruggedness and improve quality of the Radon projections considerably. One-dimensional FFT of each refined Radon projection is calculated, resulting in a set of frequency-domain samples distributed on a polar coordinate system. These samples are interpolated onto a Cartesian grid to give the required 2D spectrum of the sampled binary image. Numerical computations on several objects show that the method can provide significant improvement to the spectrum as compared with direct 2D-FFT. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zhang, Peizhen; Wang, Shuozhong] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Zhang, Peizhen] Guangdong Ocean Univ, Sch Informat, Zhanjiang 524088, Peoples R China.
   [Wang, Runtian] Chinese Acad Sci, Shanghai Acoust Lab, Shanghai 200032, Peoples R China.
C3 Shanghai University; Guangdong Ocean University; Chinese Academy of
   Sciences
RP Wang, SZ (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
EM zpzhen7242@163.com; shuowang@shu.edu.cn; wangrunt@126.com
RI Zhang, Peizhen/AAG-4343-2021
FU Natural Science Foundation of China [61071187]
FX This work was supported by the Natural Science Foundation of China under
   the Grant No. 61071187.
CR Averbuch A, 2008, SIAM J SCI COMPUT, V30, P785, DOI 10.1137/060650301
   Averbuch A, 2006, APPL COMPUT HARMON A, V21, P145, DOI 10.1016/j.acha.2005.11.003
   DING Kang, 1996, J DYNAMIC ANAL MEASU, V14, P10
   KAK AC, 1999, PRINCIPLES COMPUTERI, P56
   Kak AvinashC., 2001, CLASSICS APPL MATH, V33
   Ledda A., 2008, 16 EUR SIGN PROC C E, P25
   Mbachu C. B., 2011, INT J ENG SCI TECHNO, V3, P6775
   Mueller N, 2008, IEEE IMAGE PROC, P901, DOI 10.1109/ICIP.2008.4711901
   Wang S., 2010, 17 INT C SOUND VIBR
   Wang SZ, 1996, J ACOUST SOC AM, V99, P1924, DOI 10.1121/1.415375
   Yang L., 1996, Appl. Math., V11, P419, DOI DOI 10.1007/BF02662881
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhao X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P63, DOI 10.1109/CISP.2008.632
   Zhu LM, 2003, MECH SYST SIGNAL PR, V17, P551, DOI 10.1006/mssp.2001.1397
NR 14
TC 2
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 697
EP 704
DI 10.1016/j.jvcir.2012.04.001
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400002
DA 2024-07-18
ER

PT J
AU Cabido, R
   Montemayor, AS
   Pantrigo, JJ
   Martínez-Zarzuela, M
   Payne, BR
AF Cabido, R.
   Montemayor, A. S.
   Pantrigo, J. J.
   Martinez-Zarzuela, M.
   Payne, B. R.
TI High-performance template tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Template tracking; Multiview tracking; Face tracking;
   Real time; Particle filters; GPGPU; High-performance
ID MEAN SHIFT
AB Tracking systems are important in computer vision, with applications in video surveillance, human computer interfaces (HCI), etc. Consumer graphics processing units (GPUs) have experienced an extraordinary evolution in both computing performance and programmability, leading to a greater use of the GPU for non-rendering applications, such as image processing and computer vision tasks. In this work we show an effective particle filtering implementation for real-time template tracking based on the use of a graphics card as a streaming architecture in a translation-rotation-scale model. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Cabido, R.; Montemayor, A. S.; Pantrigo, J. J.] Univ Rey Juan Carlos, Dept Ciencias Comp, Mostoles 28933, Spain.
   [Martinez-Zarzuela, M.] Univ Valladolid, Dept Teoria Senal Comunicac & Ingn Telemat, E-47011 Valladolid, Spain.
   [Payne, B. R.] N Georgia Coll & State Univ, Dept Math & Comp Sci, Dahlonega, GA 30597 USA.
C3 Universidad Rey Juan Carlos; Universidad de Valladolid; University
   System of Georgia; North Georgia College & State University
RP Pantrigo, JJ (corresponding author), Univ Rey Juan Carlos, Dept Ciencias Comp, C Tulipan S-N, Mostoles 28933, Spain.
EM raul.cabido@urjc.es; antonio.sanz@urjc.es; juanjose.pantrigo@urjc.es;
   marmar@tel.uva.es; bpayne@northgeorgia.edu
RI Payne, Bryson/JVN-5887-2024; Pantrigo, Juan José/AAA-2290-2019;
   Anton-Rodriguez, Miriam/G-9474-2013; González-Ortega, David/G-6199-2017;
   Montemayor, Antonio S./Y-5409-2019; Martinez-Zarzuela, Mario/G-1752-2013
OI Payne, Bryson/0000-0003-4539-0308; Pantrigo, Juan
   José/0000-0002-7175-3371; Anton-Rodriguez, Miriam/0000-0002-3328-5183;
   Montemayor, Antonio S./0000-0002-8980-8799; Cabido,
   Raul/0000-0002-9178-9224; Martinez-Zarzuela, Mario/0000-0002-6866-3316
FU Spanish Ministry of Education and Science [CICYT TIN2008-06890-C02-02];
   URJC; CAM [URJC-CM-2008-CET-3625]; Nvidia Professor Partnership Program
FX We would like to thank the Spanish Ministry of Education and Science
   that has been supported this research by CICYT TIN2008-06890-C02-02,
   URJC and CAM by URJC-CM-2008-CET-3625, and the Nvidia Professor
   Partnership Program.
CR Alefs Bram, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P405, DOI 10.1109/ITSC.2007.4357689
   [Anonymous], 2001, EC FUND CAVIAR PROJ
   [Anonymous], NVID CUDA PROGR GUID
   [Anonymous], IB AM S COMP GRAPH S
   [Anonymous], P 8 INT WORKSH INT S
   [Anonymous], 2009, PAR STUD FAQ
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bradski G.R., 1998, Intel Technology Journal, pQ2
   Cabido R, 2009, MACH VISION APPL, V21, P43, DOI 10.1007/s00138-008-0140-4
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEUTSCH B, 2005, DAGM S, P269
   Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Fung J., 2008, P IEEE INT C MULT EX
   *KHRON OPENCL WORK, 2008, OPENCL SPEC 1 0
   Klein G., 2006, P BRIT MACH VIS C
   LANVIN P, 2005, P INT C MULT EXP ICM
   Lim Jongwoo., 2005, Advances in Neural Information Processing Systems, P793
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma J., 2007, P IEEE IMTC WARS POL, P1
   Mateo O, 2009, J SIGNAL PROCESS SYS, V57, P285, DOI DOI 10.1007/S11265-008-0250-2
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Montemayor A.S., 2004, P ACM SIGGRAPH, P94
   Montemayor A. S., 2006, P ACM SIGGRAPH BOST
   Nguyen C. T., 2007, IEEE C COMP VIS PATT, P1
   Nguyen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P678, DOI 10.1109/ICCV.2001.937587
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   PAPAKIPOS M, 2007, P WIND HARDW ENG C W
   Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Ross D, 2004, LNCS, P707
   Schreiber D, 2007, PATTERN RECOGN LETT, V28, P1483, DOI 10.1016/j.patrec.2007.03.007
   Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z
   Song L., 2007, LNCS
   Suzuki N., 2006, P BRIT MACH VIS C BM, P37
   VENKATASUBRAMAN.S, 2003, SIGMOD DIMACS WORKSH
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   YANG R., 2002, J GRAPHICS TOOLS, V7, P91
   Yao ZR, 2006, IMAGE VISION COMPUT, V24, P573, DOI 10.1016/j.imavis.2005.09.007
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 44
TC 3
Z9 5
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 271
EP 286
DI 10.1016/j.jvcir.2011.10.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900005
DA 2024-07-18
ER

PT J
AU Strachota, P
   Benes, M
   Tintera, J
AF Strachota, Pavel
   Benes, Michal
   Tintera, Jaroslav
TI Towards clinical applicability of the diffusion-based DT-MRI
   visualization algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Biomedical magnetic resonance imaging; Diffusion equations;
   Computational study; Parallel processing; Scientific visualization;
   Diffusion tensor; Numerical solution; Total variation
ID PRINCIPLES
AB For the purpose of DT-MRI data visualization, an algorithm based on a numerical model of texture diffusion is proposed. As a prerequisite of entering clinical use, its parameters need to be adjusted properly so that the procedure gives satisfactory results with limited computational resources and time available. This contribution introduces the principles of the method and reports on the results of extensive computational studies aimed at finding optimal settings of the numerical scheme and model parameters with respect to visualization purposes. Total variation is used as a measure of visual quality of the produced images. Further, we provide evidence that using the algorithm is fully feasible on state of the art hardware. Finally, high resolution visualizations based on real data are demonstrated. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Strachota, Pavel; Benes, Michal] Czech Tech Univ, Fac Nucl Sci & Phys Engn, Dept Math, Prague 12000 2, Czech Republic.
   [Tintera, Jaroslav] Inst Clin & Expt Med IKEM, Prague 14021 4, Czech Republic.
C3 Czech Technical University Prague; Institute for Clinical & Experimental
   Medicine (IKEM)
RP Strachota, P (corresponding author), Czech Tech Univ, Fac Nucl Sci & Phys Engn, Dept Math, Trojanova 13, Prague 12000 2, Czech Republic.
EM pavel.strachota@fjfi.cvut.cz; michal.benes@fjfi.cvut.cz; jati@medicon.cz
RI Strachota, Pavel/KCZ-1132-2024; Benes, Michal/M-8351-2014
OI Strachota, Pavel/0000-0003-1527-8606; Benes, Michal/0000-0002-7171-978X
FU HPC-EUROPA++ [211437]; European Community - Research Infrastructure
   Action; Grant Agency of the Czech Technical University in Prague
   [SGS10/086/OHK4/1T/14]; Ministry of Education of the Czech Republic
   [MSM6840770010]; Jindrich Necas Center for Mathematical Modeling
   [LC06052]; Institute for Clinical and Experimental Medicine (IKEM) in
   Prague
FX This work was carried out under the HPC-EUROPA++ project (project
   number: 211437), with the support of the European Community - Research
   Infrastructure Action of the FP7 "Coordination and support action"
   Program. This work was supported by the Grant Agency of the Czech
   Technical University in Prague, Grant No. SGS10/086/OHK4/1T/14 and the
   project of the Ministry of Education of the Czech Republic MSM6840770010
   "Applied Mathematics in Technical and Physical Sciences". Partial
   support of the project "Jindrich Necas Center for Mathematical
   Modeling", No. LC06052. Special thanks to the colleagues at the
   Institute for Clinical and Experimental Medicine (IKEM) in Prague for
   providing input datasets, consultations, and support.
CR [Anonymous], P INT SOC MAG RES ME
   [Anonymous], COMPLETE MPI REFEREN
   [Anonymous], 9 IEEE INT C COMP VI
   [Anonymous], P 5 DISTR MEM COMP C
   [Anonymous], TENSOR FIELD VISUALI
   [Anonymous], MED IMAGING IMAGE PR
   [Anonymous], COLOR ATLAS TXB HUMA
   BASSER PJ, 1994, BIOPHYS J, V66, P259, DOI 10.1016/S0006-3495(94)80775-1
   Basser PJ, 1996, J MAGN RESON SER B, V111, P209, DOI [10.1006/jmrb.1996.0086, 10.1016/j.jmr.2011.09.022]
   Bene3 M., 2003, APPL MATH, V48, P437
   Benes M, 2004, APPL NUMER MATH, V51, P187, DOI 10.1016/j.apnum.2004.05.001
   Benes M., 2001, INTERFACE FREE BOUND, V3, P201, DOI DOI 10.4171/IFB/38
   Butcher J. C., 2016, NUMERICAL METHODS OR, DOI DOI 10.1002/9780470753767
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Eymard R, 2000, HDBK NUM AN, V7, P713
   Fillard P, 2003, LECT NOTES COMPUT SC, V2879, P967
   Le Bihan D, 2001, J MAGN RESON IMAGING, V13, P534, DOI 10.1002/jmri.1076
   Lomax H., 2001, SCIENTIF COMPUT
   Mori S, 2002, NMR BIOMED, V15, P468, DOI 10.1002/nbm.781
   Mori S, 2006, NEURON, V51, P527, DOI 10.1016/j.neuron.2006.08.012
   Schiesser W. E., 1991, NUMERICAL METHOD LIN
   Strachota P, 2010, NUMERICAL MATHEMATICS AND ADVANCED APPLICATIONS 2009, P839, DOI 10.1007/978-3-642-11795-4_90
   Strachota P, 2009, ALGORITMY 2009: 18TH CONFERENCE ON SCIENTIFIC COMPUTING, P134
   Tuch DS, 2002, MAGNET RESON MED, V48, P577, DOI 10.1002/mrm.10268
   Tuch DS, 2004, MAGN RESON MED, V52, P1358, DOI 10.1002/mrm.20279
   Westin CF, 2002, MED IMAGE ANAL, V6, P93, DOI 10.1016/S1361-8415(02)00053-1
   Zheng Xiaoqiang., 2003, P IEEE VISUALIZATION, P33
NR 27
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 387
EP 396
DI 10.1016/j.jvcir.2011.11.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900015
DA 2024-07-18
ER

PT J
AU Xu, J
   Yang, L
   Wu, DP
AF Xu, Jun
   Yang, Lei
   Wu, Dapeng
TI Ripplet: A new transform for image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Harmonic analysis; Fourier transform; Wavelet transform; Curvelet
   transform; Image representation; Image compression; Transform coding;
   Image denoising
ID CONTINUOUS CURVELET TRANSFORM; REPRESENTATION; COMPRESSION; FRAMES
AB Efficient representation of images usually leads to improvements in storage efficiency, computational complexity and performance of image processing algorithms. Efficient representation of images can be achieved by transforms. However, conventional transforms such as Fourier transform and wavelet transform suffer from discontinuities such as edges in images. To address this problem, we propose a new transform called ripplet transform. The ripplet transform is a higher dimensional generalization of the curvelet transform, designed to represent images or two-dimensional signals at different scales and different directions. Specifically, the ripplet transform allows arbitrary support c and degree d while the curvelet transform is just a special case of the ripplet transform (Type I) with c = 1 and d = 2. Our experimental results demonstrate that the ripplet transform can provide efficient representation of edges in images. The ripplet transform holds great potential for image processing such as image restoration, image denoising and image compression. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Xu, Jun; Yang, Lei; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Xu, J (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM junxu9@ufl.edu
RI Xu, Jun/F-5929-2012
OI Wu, Dapeng/0000-0003-1755-0183
CR [Anonymous], 1983, The Radon Transform and Some of Its Applications
   [Anonymous], 1992, LECT WAVELETS
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P162, DOI 10.1016/j.acha.2005.02.003
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P198, DOI 10.1016/j.acha.2005.02.004
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   CANDS DLD, 2005, MULTISCALE MODEL SIM, V5, P861
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cohle A., 1992, Communications on Pure and Applied Mathematics, V4, P45
   Do M.N., 2003, BEYOND WAVELETS
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Donoho DL, 1998, IEEE T INFORM THEORY, V44, P2435, DOI 10.1109/18.720544
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4056, P12, DOI 10.1117/12.381679
   Hormander L, 2003, ANAL LINEAR PARTIAL
   LE PENNEC E, 2005, IEEE T IMAGE PROCESS, V14, P423
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Manikandan M., 2007, INT C SIGN PROC COMM, P274
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   TAUBMAN D, 2000, P 2000 INT C IM PROC, V2
   VETTERLI M, 1992, IEEE T SIGNAL PROCES, V40, P2207, DOI 10.1109/78.157221
NR 22
TC 68
Z9 69
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 627
EP 639
DI 10.1016/j.jvcir.2010.04.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hiew, BY
   Teoh, ABJ
   Yin, OS
AF Hiew, Bee Yan
   Teoh, Andrew Beng Jin
   Yin, Ooi Shih
TI A secure digital camera based fingerprint verification system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Touch-less based fingerprint system; Template protection; Support Vector
   Machine; Fingerprint verification; Cancellable biometrics; Random
   projection; Gabor filters; Principle component analysis
ID PRIVACY
AB Contemporary fingerprint system uses solid flat sensor which requires contact of the finger on a platen surface. This often results in several problems such as image deformation, durability weakening in the sensor, latent fingerprint issues which can lead to forgery and hygienic problems. On the other hand, biometric characteristics cannot be changed; therefore, the loss of privacy is permanent if they are ever compromised. Coupled with template protection mechanism, a touch-less fingerprint verification system is further provoked. In this issue, a secure end-to-end touch-less fingerprint verification system is presented. The fingerprint image captured with a digital camera is first pre-processed via the proposed pre-processing algorithm to reduce the problems appear in the image. Then, Multiple Random Projections-Support Vector Machine (MRP-SVM) is proposed to secure fingerprint template while improving system performance. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Hiew, Bee Yan; Yin, Ooi Shih] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Multimedia University; Yonsei University
RP Teoh, ABJ (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
EM byhiew@mmu.edu.my; andrew_tbj@yahoo.com; syooi@mmu.edu.my
RI Teoh, Andrew Beng Jin/F-4422-2010
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484
FU Korea Science and Engineering Foundation (KOSEF) through the Biometrics
   Engineering Research Center (BERC) at Yonsei University
   [R112002105080020[2009]]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) through the Biometrics Engineering Research Center (BERC) at
   Yonsei University. (Grant Number: R112002105080020[2009]).
CR ANDREW BJ, 2007, IEEE T SYST MAN CY B, V37, P1096
   ANDREW BJ, 2004, COMPUT SECUR J, V23, P606
   ANDREW BJ, 2003, AI 2003 ADV ART INT
   Ang R, 2005, LECT NOTES COMPUT SC, V3574, P242
   [Anonymous], P 2004 INT S INT SIG
   [Anonymous], 2002, LOC NORM
   [Anonymous], 2003, Handbook of fingerprint recognition
   [Anonymous], P 3 INT C IM GRAPH C
   BOULT T, 2006, 7 INT C AUT FAC GEST
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen, 2006, P BIOM S BIOM CONS C
   Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036
   Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45
   *DIG DESCR SYST IN, 2000, AM REG SEC SMALL BUS
   HIEW BY, 2006, 9 INT C CONTR AUT RO
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Kargupta H, 2005, KNOWL INF SYST, V7, P387, DOI 10.1007/s10115-004-0173-6
   LEE C, P INT C BIOM 2006, P348
   Lee C, 2006, LECT NOTES COMPUT SC, V4109, P358
   Lee CJ, 1999, ELECTRON LETT, V35, P288, DOI 10.1049/el:19990213
   MAINGUET JF, FINGERPRINT SENSING
   Nakamura T, 2004, INT C PATT RECOG, P536, DOI 10.1109/ICPR.2004.1334192
   Parziale G, 2006, LECT NOTES COMPUT SC, V3832, P244
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   SANO E, P 2006 C COMP VIS PA, P27
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Schneier B, 1999, COMMUN ACM, V42, P136, DOI 10.1145/310930.310988
   *TST, BIOM TOUCHL SENS TEC
   WATSON CI, 1994, NATL I STANDARDS TEC
   2009, MOTION BLUR
   2009, DEPTH FIELD
NR 31
TC 25
Z9 30
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 219
EP 231
DI 10.1016/j.jvcir.2009.12.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400004
DA 2024-07-18
ER

PT J
AU Pishdad, L
   Rabiee, HR
   Mirarmandehi, N
AF Pishdad, Leila
   Rabiee, Hamid R.
   Mirarmandehi, Nasim
TI A fair optimization scheduling scheme for IEEE 802.16 networks in
   multimedia applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Broadband Wireless Access; Scheduling; Knapsack Problem; Quality of
   Service; Multimedia Networking; IEEE 802.16
ID SERVICE; MANAGEMENT; QUALITY; SUPPORT; QOS
AB IEEE 802.16 networks are designed based on differentiated services concept to provide better Quality of Service (QoS) support for a wide range of applications, from multimedia to typical web services, and therefore they require a fair and efficient scheduling scheme. However, this issue is not addressed in the standard. In this paper we present a new fair scheduling scheme which fulfills the negotiated QoS parameters of different connections while providing fairness among the connections of each class of service. This scheme models scheduling as a knapsack problem, where a fairness parameter reflecting the specific requirements of the connections is defined to be used in the optimization criterion. The proposed scheduler is evaluated through simulation in terms of delay, throughput and fairness index. The results show fairness of the scheduling scheme to all connections while the network guarantees for those connections are fulfilled. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Pishdad, Leila; Rabiee, Hamid R.; Mirarmandehi, Nasim] Sharif Univ Technol, Digital Media Lab, Adv Informat & Commun Technol Res Ctr, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Rabiee, HR (corresponding author), Sharif Univ Technol, Digital Media Lab, Adv Informat & Commun Technol Res Ctr, Dept Comp Engn, Tehran, Iran.
EM pishdad@ce.sharif.edu; rabiee@sharif.edu; armandeh@ce.sharif.edu
RI Pishdad, Leila/AAB-4621-2020; Rabiee, Hamid R./L-7866-2017
OI Pishdad, Leila/0000-0001-7825-5757; Rabiee, Hamid R./0000-0002-9835-4493
FU Iran Telecommunication Research Center (ITRC)
FX This work has been supported by Iran Telecommunication Research Center
   (ITRC).
CR [Anonymous], 2004, IEEE Guide for Application of Composite Line Post Insulators, P1
   [Anonymous], 1984, ACM Transaction on Computer Systems
   [Anonymous], NETWORK SIMULATOR NS
   Barford P., 1999, World Wide Web, V2, P15, DOI 10.1023/A:1019236319752
   Chan LF, 2006, I C WIREL COMM NETW, P1352
   CHEN J, 2006, WORKSH NS 2 IP NETW, P1
   Chen JF, 2005, IEEE ICC, P3422
   Chu GS, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P435, DOI 10.1109/ICCCAS.2002.1180654
   Cicconetti C, 2006, IEEE NETWORK, V20, P50, DOI 10.1109/MNET.2006.1607896
   IBARRA OH, 1975, J ACM, V22, P463, DOI 10.1145/321906.321909
   Lera A, 2007, IEEE NETWORK, V21, P34, DOI 10.1109/MNET.2007.4305171
   Niyato D, 2005, GLOB TELECOMM CONF, P3702
   Niyato D, 2006, IEEE T MOBILE COMPUT, V5, P668, DOI 10.1109/TMC.2006.85
   Niyato D, 2006, IEEE T COMPUT, V55, P1473, DOI 10.1109/TC.2006.172
   Seeling P, 2004, IEEE COMMUN SURV TUT, V6, P58, DOI 10.1109/COMST.2004.5342293
   Singh V, 2006, IEEE WCNC, P984
   Vazirani V.V., 2001, Approximation algorithms, V1
   Wongthavarawat K, 2003, INT J COMMUN SYST, V16, P81, DOI 10.1002/dac.581
NR 18
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 167
EP 174
DI 10.1016/j.jvcir.2009.05.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800010
DA 2024-07-18
ER

PT J
AU Li, X
   Hutter, A
   Kaup, A
AF Li, Xiang
   Hutter, Andreas
   Kaup, Andre
TI Efficient one-pass frame level rate control for H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hybrid video coding; One-pass video coding; Rate control;
   Rate-distortion optimization; Budget allocation; Quantization parameter
   determination; Inter-frame dependency; H.264/AVC
ID RATE CONTROL SCHEME; BIT ALLOCATION; VIDEO; QUANTIZATION; ALGORITHM;
   MODEL
AB In this paper, an efficient one-pass frame level rate control algorithm is proposed for H.264/AVC, where the two essential problems in rate control, i.e., the budget allocation (BA) and the quantization parameter determination (QPD) are both considered. First, an efficient BA scheme is designed with special consideration of the inter-frame dependency. Accordingly, the error propagation caused by improper QP assignment in the motion compensation process is reduced and the total distortion is kept at a low level. Second, a better QPD method is developed based on an accurate rate model and a second feedback mechanism so that a high rate accuracy is guaranteed. Simulations verified the performance of the proposed algorithm. Compared with the fixed QP coding and the two recommended rate control algorithms (G012-MB and G012-Frame) in H.264/AVC reference software, up to 1.50, 1.12, and 0.94dB were achieved with a higher rate accuracy in the coding efficiency test defined by ITU-T VCEG. Particularly, a more significant improvement was observed in slow movement scenarios: compared with G012-MB, a gain of 0.80 dB on average and 1.43 dB at maximum was obtained with 66.0% reduction of average rate mismatch. Compared with G012-Frame, the average and maximum gains are 0.34 and 1.06 dB, respectively. While at the same time, the average rate mismatch was reduced by 90.4%. Considering the low computational cost, the proposed algorithm is quite appealing to real-time video applications. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Li, Xiang; Kaup, Andre] Univ Erlangen Nurnberg, Chair Multimedia Commun & Signal Proc, Erlangen, Germany.
   [Li, Xiang; Hutter, Andreas] Siemens Corp Technol, Informat & Commun, Munich, Germany.
C3 University of Erlangen Nuremberg; Siemens AG; Siemens Germany
RP Li, X (corresponding author), Univ Erlangen Nurnberg, Chair Multimedia Commun & Signal Proc, Erlangen, Germany.
EM xiang@lnt.de
OI Kaup, Andre/0000-0002-0929-5074
FU European Community [INFSO-ICT-214625]
FX This work was achieved with help of the European Community's Seventh
   Framework Program through grant agreement ICT OPTIMIX No.
   INFSO-ICT-214625. The authors would like to thank Mr. Peter Amon for
   many insightful discussions and suggestions.
CR [Anonymous], 1997, ITUTSG15
   Beermann M, 2002, IEEE IMAGE PROC, P93
   BJONTEGAARD G, 2001, VCEG M AUST TEX
   Cai JF, 2006, J VIS COMMUN IMAGE R, V17, P783, DOI 10.1016/j.jvcir.2004.11.005
   Chen ZZ, 2007, IEEE T CIRC SYST VID, V17, P158, DOI 10.1109/TCSVT.2006.888022
   Cherniavsky N, 2007, IEEE T CIRC SYST VID, V17, P59, DOI 10.1109/TCSVT.2006.887135
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Dong JP, 2007, IEEE INT SYMP CIRC S, P289, DOI 10.1109/ISCAS.2007.378392
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P970, DOI 10.1109/TCSVT.2002.805511
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   Huang CM, 2007, IEEE T MULTIMEDIA, V9, P1113, DOI 10.1109/TMM.2007.902840
   *ISO IEC JTC1 SC29, 1997, WG11 ISOIECJTC1SC29
   *ISO IEC JTC1 SC29, 1993, MPEG931457 ISOIECJTC
   *ISO TEC JTC1 SC29, 1996, N1469 ISOTECJTC1SC29
   *ITU T, 2000, ITUTRECH263
   *ITU T, 2004, 1449610 ISOIEC ITUT
   Jiang MQ, 2006, IEEE T MULTIMEDIA, V8, P467, DOI 10.1109/TMM.2006.870713
   *JVT, 2007, H264AVC JVT
   Kamaci N, 2005, IEEE T CIRC SYST VID, V15, P994, DOI 10.1109/TCSVT.2005.852400
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   LI X, 2008, EUR SIGN PROC C EUSI
   LI X, 2009, CALCULATION LAPLACE
   Li X, 2009, IEEE T CIRC SYST VID, V19, P193, DOI 10.1109/TCSVT.2008.2009255
   LI Z, 2003, JVT M JOINT VID TEAM
   Liu S, 2005, IEEE T CIRC SYST VID, V15, P15, DOI 10.1109/TCSVT.2004.839996
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P533, DOI 10.1109/83.334987
   Ribas-Corbera J, 2000, IEEE T CIRC SYST VID, V10, P1154, DOI 10.1109/76.875518
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Schuster GM, 1999, IEEE T MULTIMEDIA, V1, P3, DOI 10.1109/6046.748167
   Sermadevi Y, 2004, IEEE DATA COMPR CONF, P232
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   TAN T, 2007, ITUTVCEGSG16
   Wiegand T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958171
   Yu Y, 2001, IEEE T CIRC SYST VID, V11, P345, DOI 10.1109/76.911160
   Zhou SM, 2007, IEEE T CIRC SYST VID, V17, P996, DOI 10.1109/TCSVT.2007.903123
NR 37
TC 5
Z9 6
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 585
EP 594
DI 10.1016/j.jvcir.2009.09.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400008
DA 2024-07-18
ER

PT J
AU Chen, HT
   Tien, MC
   Chen, YW
   Tsai, WJ
   Lee, SY
AF Chen, Hua-Tsung
   Tien, Ming-Chun
   Chen, Yi-Wen
   Tsai, Wen-Jiin
   Lee, Suh-Yin
TI Physics-based ball tracking and 3D trajectory reconstruction with
   applications to shooting location estimation in basketball video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shot classification; Object tracking; Sports video analysis; Camera
   calibration; Semantic analysis; Multimedia system; 3D trajectory
   reconstruction
ID SOCCER VIDEO; FRAMEWORK
AB The demand for computer-assisted game study in sports is growing dramatically. This paper presents a practical video analysis system to facilitate semantic content understanding. A physics-based algorithm is designed for ball tracking and 3D trajectory reconstruction in basketball videos and shooting location statistics can be obtained. The 2D-to-3D inference is intrinsically a challenging problem due to the loss of 3D information in projection to 2D frames. One significant contribution of the proposed system lies in the integrated scheme incorporating domain knowledge and physical characteristics of ball motion into object tracking to overcome the problem of 2D-to-3D inference. With the 2D trajectory extracted and the camera parameters calibrated, physical characteristics of ball motion are involved to reconstruct the 3D trajectories and estimate the shooting locations. Our experiments on broadcast basketball videos show promising results. We believe the proposed system will greatly assist intelligence collection and statistics analysis in basketball games. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Chen, Hua-Tsung; Chen, Yi-Wen; Tsai, Wen-Jiin; Lee, Suh-Yin] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu 300, Taiwan.
   [Tien, Ming-Chun] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
C3 National Yang Ming Chiao Tung University; National Taiwan University
RP Chen, HT (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM huatsung@cs.nctu.edu.tw; sylee@csie.nctu.edu.tw
FU National Science Council of Taiwan, R.O.C [NSC 95-2221-E-009-076-MY3];
   Lee and MTI center for Networking Research at National Chiao Tung
   University, Taiwan
FX The research is partially supported by the National Science Council of
   Taiwan, R.O.C, under the grant No. NSC 95-2221-E-009-076-MY3 and
   partially supported by Lee and MTI center for Networking Research at
   National Chiao Tung University, Taiwan.
CR [Anonymous], 2005, P 2005 INT C IM PROC
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen DY, 2006, J INF SCI ENG, V22, P1145
   Chen DY, 2005, J VIS COMMUN IMAGE R, V16, P212, DOI 10.1016/j.jvcir.2004.08.003
   Chen HC, 2007, LECT NOTES COMPUT SC, V4430, P1
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   DUAN LY, 2004, P IEEE INT C AC SPEE
   Ekin A, 2003, IEEE IMAGE PROC, P21
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Farin D, 2004, PROC SPIE, V5307, P80
   Farin D., 2005, P IEEE INT C MULT EX
   Ferman A. M., 2001, Journal of Electronic Imaging, V10, P917, DOI 10.1117/1.1406946
   Gong YH, 2004, COMPUT VIS IMAGE UND, V96, P181, DOI 10.1016/j.cviu.2004.02.002
   Guéziec A, 2002, COMPUTER, V35, P38, DOI 10.1109/2.989928
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Heng WJ, 2002, IEEE T MULTIMEDIA, V4, P434, DOI 10.1109/TMM.2002.806532
   Jahne B., 2002, DIGITAL IMAGE PROCES
   LEE SY, 2001, P INT C INF COMM SIG
   Lu H, 2003, PATTERN RECOGN LETT, V24, P2651, DOI 10.1016/S0167-8655(03)00108-9
   Millerson G., 1990, TECHNIQUE TELEVISION, V12th
   Pingali G, 2000, INT C PATT RECOG, P152, DOI 10.1109/ICPR.2000.902885
   WANG JR, 2004, IEEE 6 INT S MULT SO, P186
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Yu X., 2003, PROC 11 ACM INT C MU, P11
NR 27
TC 54
Z9 65
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2009
VL 20
IS 3
BP 204
EP 216
DI 10.1016/j.jvcir.2008.11.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 424VD
UT WOS:000264595500004
DA 2024-07-18
ER

PT J
AU Shen, XJ
   Ju, SG
   Cho, SY
   Li, F
AF Shen, Xiangjun
   Ju, Shiguang
   Cho, Siu-Yeung
   Li, Feng
TI Mining user hidden semantics from image content for image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE content-based image retrieval; dynamical feature selection; dynamical
   weight adjusting; similar region pair matching; object semantics;
   object-relation semantics
ID UNSUPERVISED SEGMENTATION; RELEVANCE FEEDBACK; COLOR
AB The problem confronted in the content-based image retrieval research is the semantic gap between the low-level feature representing and high-level semantics in the images. This paper describes a way to bridge such gap: by learning the similar images given from the user, the system extracts the similar region pairs and classifies those similar region pairs either as object or non-object semantics, and either as object-relation or non-object-relation semantics automatically, which are obtained from comparing the distances and spatial relationships in the similar region pairs by themselves. The system also extracts interesting parts of the features from the similar region pair and then adjusts each interesting feature and region pair weight dynamically. Using those objects and object-relation semantics as well as the dynamic weights adjustment from the similar images, the semantics of those similar images can be mined and used for searching the similar images. The experiments show that the proposed system can retrieve the similar images well and efficient. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Shen, Xiangjun; Ju, Shiguang; Li, Feng] Jiangsu Univ, Sch Comp Sci & Commun Engn, Jiangsu 212013, Peoples R China.
   [Cho, Siu-Yeung] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
C3 Jiangsu University; Nanyang Technological University
RP Shen, XJ (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Jiangsu 212013, Peoples R China.
EM xiangjun.shen@gmail.com
RI Cho, Siu-Yeung/A-3665-2011
CR BRADSHAW B, 2000, ACM MULTIMEDIA 2000, P167
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Corridoni JM, 1999, MULTIMEDIA SYST, V7, P175, DOI 10.1007/s005300050120
   DENG Y, 1999, P IEEE INT C AC SPEE, V6, P3017
   Deng Y., 1999, P IEEE INT S CIRC SY, V4, P21, DOI DOI 10.1109/ISCAS.1999.779933
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Fauqueur J, 2004, J VISUAL LANG COMPUT, V15, P69, DOI 10.1016/j.jvlc.2003.08.002
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gevers T, 2002, IEEE T MULTIMEDIA, V4, P509, DOI 10.1109/TMM.2002.802023
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Hsieh JW, 2003, IEEE T IMAGE PROCESS, V12, P1404, DOI 10.1109/TIP.2003.816013
   Jing F, 2004, IEEE T CIRC SYST VID, V14, P672, DOI 10.1109/TCSVT.2004.826775
   Kang LW, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1866148
   Khotanzad A, 2003, PATTERN RECOGN, V36, P1679, DOI 10.1016/S0031-3203(02)00292-3
   Kim BG, 2003, PATTERN RECOGN LETT, V24, P2995, DOI 10.1016/S0167-8655(03)00160-0
   LI B, 2002, P IEEE INT C IM PROC, V2, P22
   Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214
   Lu Y, 2003, IEEE T MULTIMEDIA, V5, P339, DOI 10.1109/TMM.2003.813280
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   MEDIN DL, 1993, PSYCHOL REV, V100, P254, DOI 10.1037/0033-295X.100.2.254
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   MORI G, 2001, P IEEE C COMPUT VIS, V1, P8
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Pei SC, 1999, IEEE T CIRC SYST VID, V9, P501, DOI 10.1109/76.754779
   Pun CM, 2003, COMPUT VIS IMAGE UND, V89, P24, DOI 10.1016/S1077-3142(03)00012-2
   Shafarenko L, 1997, IEEE T IMAGE PROCESS, V6, P1530, DOI 10.1109/83.641413
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771
   SMITH JR, 1994, IEEE IMAGE PROC, P407, DOI 10.1109/ICIP.1994.413817
   Wang J.Z, 2001, IEEE T PATTERN ANAL, V23, P1
   Zhao R, 2002, PATTERN RECOGN, V35, P593, DOI 10.1016/S0031-3203(01)00062-0
NR 33
TC 5
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2008
VL 19
IS 3
BP 145
EP 164
DI 10.1016/j.jvcir.2007.04.009
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 290FT
UT WOS:000255109400001
DA 2024-07-18
ER

PT J
AU Yin, WT
   Goldfarb, D
   Osher, S
AF Yin, Wotao
   Goldfarb, Donald
   Osher, Stanley
TI A comparison of three total variation based texture extraction models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image decomposition; texture extraction; feature selection; total
   variation; variational imaging; second-order cone programming;
   interior-point method
ID TOTAL VARIATION MINIMIZATION; IMAGE DECOMPOSITION; FILTERS; SIGNALS
AB This paper qualitatively compares three recently proposed models for signal/image texture extraction based on total variation minimization: the Meyer [27], Vese-Osher (VO) [35], and TV-L-1 [12,38,2-4,29-31] models. We formulate discrete versions of these models as second-order cone programs (SOCPs) which can be solved efficiently by interior-point methods. Our experiments with these models on ID oscillating signals and 2D images reveal their differences: the Meyer model tends to extract oscillation patterns in the input, the TV-L-1 model performs a strict multiscale decomposition, and the Vese-Osher model has properties falling in between the other two models. (c) 2007 Elsevier Inc. All rights reserved.
C1 Rice Univ, Dept Computat & Appl Math, Houston, TX 77005 USA.
   Columbia Univ, Dept Ind Engn & Operat Res, New York, NY 10027 USA.
   Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA.
C3 Rice University; Columbia University; University of California System;
   University of California Los Angeles
RP Yin, WT (corresponding author), Rice Univ, Dept Computat & Appl Math, 6100 Main St,MS-134, Houston, TX 77005 USA.
EM wotao.yin@rice.edu; goldfarb@columbia.edu; sjo@math.ucla.edu
RI Yin, Wotao/A-5472-2011
OI Yin, Wotao/0000-0001-6697-9731
CR Alizadeh F, 2003, MATH PROGRAM, V95, P3, DOI 10.1007/s10107-002-0339-5
   ALLINEY S, 1992, IEEE T SIGNAL PROCES, V40, P1548, DOI 10.1109/78.139258
   Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179
   Alliney S, 1996, IEEE T SIGNAL PROCES, V44, P1346, DOI 10.1109/78.506602
   [Anonymous], 1989, GRADUATE TEXTS MATH
   Aubert G, 2005, APPL MATH OPT, V51, P163, DOI 10.1007/s00245-004-0812-z
   Aujol J.F., 2003, Lecture Notes in Computer Science, V2695
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chen T, 2005, PROC CVPR IEEE, P532
   Chen T, 2005, LECT NOTES COMPUT SC, V3765, P114
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chung G, 2006, PROC SPIE, V6065, DOI 10.1117/12.659849
   Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0
   GARNETT J, 2005, 0557 CAM UCLA
   Goldfarb D, 2005, SIAM J SCI COMPUT, V27, P622, DOI 10.1137/040608982
   HADDAD A, 2004, 0452 CAM UCLA
   KINDERMANN S, 2005, 0542 CAM UCLA
   Kindermann S, 2006, J SCI COMPUT, V28, P411, DOI 10.1007/s10915-006-9074-z
   LE T, 2005, 0513 CAM UCLA
   Le TM, 2005, MULTISCALE MODEL SIM, V4, P390, DOI 10.1137/040610052
   Lieu L., 2005, 0533 CAM UCLA
   LIEU L, 2006, THESIS UCLA
   Meyer Y., 2002, University Lecture Series, V22
   *MOSEK APS INC, 2006, MOS OPT TOOLS VER 4
   Nikolova M, 2004, J MATH IMAGING VIS, V21, P155, DOI 10.1023/B:JMIV.0000035180.40477.bd
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   YIN W, 2007, MULTISCALE DECOMPOSI
   Yin WT, 2005, LECT NOTES COMPUT SC, V3752, P73
   Yin WT, 2005, BIOINFORMATICS, V21, P2410, DOI 10.1093/bioinformatics/bti341
NR 39
TC 52
Z9 65
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 240
EP 252
DI 10.1016/j.jvcir.2007.01.004
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300004
DA 2024-07-18
ER

PT J
AU Chung, SC
   Kuo, CM
   Shih, PY
AF Chung, Shu-Chiang
   Kuo, Chung-Ming
   Shih, Po-Yi
TI Rate-constrained motion estimation using Kalman filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE R-D motion estimation; motion model; Kalman filter
ID COMPENSATION; ALGORITHM; STANDARD
AB The rate-constrained (R-D) motion estimation techniques have been presented to improve the conventional block-matching algorithm by using a joint rate and distortion criterion. This paper presents a new motion estimation algorithm using Kalman filter to improve the performance of the conventional R-D motion estimation at a relatively low computational cost. The Kalman filter exploits the correlation of block motion to achieve higher precision of motion estimation and compensation. In the proposed algorithm, the Kalman filter is embedded into the optimization process of R-D motion estimation by defining a new R-D criterion. Simulation results show that the new algorithm improves the rate-distortion performance significantly. (C) 2005 Elsevier Inc. All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
CR Chen MC, 1998, IEEE T CIRC SYST VID, V8, P147, DOI 10.1109/76.664100
   CHUI CK, 1987, SPRINGER SERIES INFO, V17
   Coban MZ, 1998, IEEE T IMAGE PROCESS, V7, P769, DOI 10.1109/83.668031
   GIROD B, 1994, P SOC PHOTO-OPT INS, V2308, P1026, DOI 10.1117/12.185863
   GREWAL M, 1993, KALMAN FILTERING THE
   Hoang DT, 1998, IEEE T CIRC SYST VID, V8, P488, DOI 10.1109/76.709413
   *ISO IEC, 1998, 144962 ISOIEC
   *ISO IEC, 2001, JTC1SC29WG11 ISOIEC
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Ju JCH, 1999, IEEE T CIRC SYST VID, V9, P994, DOI 10.1109/76.795051
   KOGA T, 1981, P NTC81 NEW ORL LA
   Kossentini F, 1997, IEEE J SEL AREA COMM, V15, P1752, DOI 10.1109/49.650048
   Kuo CM, 2004, OPT ENG, V43, P2707, DOI 10.1117/1.1799151
   Kuo CM, 1996, IEEE T BROADCAST, V42, P110, DOI 10.1109/11.506827
   KUO CM, 1994, IEE ELECT LETT, V30, P1204
   LI HB, 1994, IEEE T IMAGE PROCESS, V3, P589, DOI 10.1109/83.334983
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   SHEILA YY, 2000, IEEE T CIRCUITS SYST, V10, P942
   SRINIVASAN R, 1985, IEEE T COMMUN, V33, P888, DOI 10.1109/TCOM.1985.1096398
   Su JK, 2000, IEEE T IMAGE PROCESS, V9, P1509, DOI 10.1109/83.862628
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 1996, IEEE T CIRC SYST VID, V6, P182, DOI 10.1109/76.488825
NR 22
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 929
EP 946
DI 10.1016/j.jvcir.2005.06.004
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500015
DA 2024-07-18
ER

PT J
AU Ji, XP
   Wei, ZQ
   Feng, YW
AF Ji, Xiaopeng
   Wei, Zhiqiang
   Feng, Yewei
TI Effective vehicle detection technique for traffic surveillance systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE moving object detection; optical flow; image segmentation; background
   updating; shadow elimination
ID MOTION SEGMENTATION; TRACKING; MODEL
AB Moving object detection is one of the key technologies for intelligent video monitoring systems. For real-time detection of moving object in the surveillance scene, the general and simple method is based on background image difference. However, it requires the accurate current background image and the approach for automatic background updating along with the illumination variance is difficult to design and implement. This limits its applications. To solve the above problem, a new self-adaptive background approximating and updating algorithm based on optical flow theory is presented for the traffic surveillance scene in this paper. To detect the moving regions of interest in the scene, the difference image between the current frame and the updating background is first obtained by using a color image difference model, and then a self-adaptive thresholding segmentation method for moving object detection based on the Gaussian model is developed and implemented. Moreover, an effective shadow-eliminating algorithm based on contour information and color features is developed. Experimental results demonstrate that the proposed background updating method can update the background exactly and rapidly along with the variance of illumination, the self-adaptive thresholding segmentation method based on the Gaussian model can extract the moving object regions accurately and completely, and the shadow can be eliminated accurately. This is the foundation for further objects recognition and understanding. (C) 2005 Elsevier Inc. All rights reserved.
C1 Ocean Univ China, Dept Comp Sci, Qingdao 266071, Peoples R China.
C3 Ocean University of China
RP Ji, XP (corresponding author), Ocean Univ China, Dept Comp Sci, 23 XiangGang Dong Rd, Qingdao 266071, Peoples R China.
EM jxiaopeng@ouc.edu.cn
CR BERTHOLD KP, 1980, 572 MIT
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   Cucchiara R., 2001, P IEEE INT C IM AN P
   DENG G, 1995, IEEE T IMAGE PROCESS, V4, P506, DOI 10.1109/83.370681
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Galic S, 2000, IWISPA 2000: PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P63, DOI 10.1109/ISPA.2000.914892
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   GONZSLEZ RC, 2002, DIGITAL IMAGE PROCES
   JOURLIN M, 1988, J MICROSC-OXFORD, V149, P21, DOI 10.1111/j.1365-2818.1988.tb04559.x
   Kim JB, 2003, PATTERN RECOGN LETT, V24, P113, DOI 10.1016/S0167-8655(02)00194-0
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Li XB, 2002, PATTERN RECOGN, V35, P967, DOI 10.1016/S0031-3203(01)00079-6
   MA J, 1987, PATTERN RECOGN LETT, V5, P203, DOI 10.1016/0167-8655(87)90064-X
   MIKIC I, 2000, P INT C PATT REC, P9
   MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452
   NARIMAN H, 2000, P SOC PHOTO-OPT INS, V4067, P133
   NAYAR SK, 1993, PATTERN RECOGN, V26, P1529, DOI 10.1016/0031-3203(93)90158-S
   Needham C.J., 2001, PROC BMVA BRIT MACHI, V1, P93, DOI DOI 10.5244/C.15.11
   Pitas I., 1990, NONLINEAR DIGITAL FI
   SMITH SM, 1995, IEEE T PATTERN ANAL, V17, P814, DOI 10.1109/34.400573
   THOMPSON WB, 1990, INT J COMPUT VISION, V4, P39, DOI 10.1007/BF00137442
   YONEYAMA A, P IEEE C ADV VID SIG
   Youshan Q., 2003, Acta Photonica Sinica, V32, P182
   Zhang Ze-xu, 2003, Acta Electronica Sinica, V31, P1299
NR 24
TC 47
Z9 59
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 647
EP 658
DI 10.1016/j.jvcir.2005.07.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300010
DA 2024-07-18
ER

PT J
AU Thomas, G
   Govindan, VK
AF Thomas, Gylson
   Govindan, V. K.
TI Computationally efficient filtered-backprojection algorithm for
   tomographic image reconstruction using Walsh transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE tomography; Walsh transform; fast algorithm; filtered-backprojection
   algorithm
AB In this paper, we discuss the implementation of the filtered-backprojection (FBP) algorithm for tomographic image reconstruction using Walsh transform to exploit its fast computational ability. Walsh transform is the fastest unitary transform known so far. The major advantage of Walsh transform is that it involves only real additions and subtractions whereas Fourier transform involves complex multiplications and additions. Implementation of the proposed algorithm necessitates the design of an appropriate filter in Walsh domain. In this research, the known Fourier filter coefficients have been transformed into Walsh domain, thereby the 1 x N Fourier filter coefficients were converted into an N x N sparse matrix with nonzero elements in a special pattern. The proposed algorithm has been implemented by taken into account of the special nature of the Walsh domain filter coefficients and tested for its performance using the well-known 'Shepp-Logan head phantom' test image. The results demonstrate that the reconstruction strategy has comparable performance with a significant reduction of computing time. For example, with a 128 x 128-pixel image and 180 views, the speedup achieved is fourfold, with reconstructions qualitatively and visually the same as that of FBP algorithm in the Fourier domain. (C) 2006 Elsevier Inc. All rights reserved.
C1 Natl Inst Technol, Dept Comp Engn, Calicut 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Thomas, G (corresponding author), Natl Inst Technol, Dept Comp Engn, Calicut 673601, Kerala, India.
EM y3dp34@nitc.ac.in
RI Thomas, Gylson/AAQ-2854-2021
CR [Anonymous], 1975, ORTHOGONAL TRANSFORM
   CHRISTOPHER JZ, 1985, IEEE T ACOUSTIC SPEE, V33, P1246
   GILBERT BK, 1981, IEEE T BIO-MED ENG, V28, P98, DOI 10.1109/TBME.1981.324783
   HALL EL, 1974, IEEE T COMPUT, V23, P976
   Herman G. T., 1995, Real-Time Imaging, V1, P3, DOI 10.1006/rtim.1995.1002
   HERMAN GT, 1980, IMAGE RECONSTRUCTIO
   HORN BKP, 1979, P IEEE, V67, P1616, DOI 10.1109/PROC.1979.11542
   Kak A.C. Slaney M., 1999, PRINCIPLES COMPUTERI
   Matej S, 2004, IEEE T MED IMAGING, V23, P401, DOI 10.1109/TMI.2004.824233
   PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869
   RADON J, 1986, IEEE T MED IMAGING, V5, P170, DOI 10.1109/TMI.1986.4307775
   ROBERT M, 1983, P IEEE, V71, P390
   SAMIT B, 2000, IEEE T IMAGE PROCESS, V9, P1760
   SCUDDER HJ, 1978, P IEEE, V66, P628, DOI 10.1109/PROC.1978.10990
   SHEPP LA, 1974, IEEE T NUCL SCI, VNS21, P21, DOI 10.1109/TNS.1974.6499235
NR 15
TC 2
Z9 5
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 581
EP 588
DI 10.1016/j.jvcir.2006.02.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300005
DA 2024-07-18
ER

PT J
AU Chen, YK
   Li, EQ
   Zhou, XS
   Ge, S
AF Chen, Yen-Kuang
   Li, Eric Q.
   Zhou, Xiaosong
   Ge, Steven
TI Implementation of H.264 encoder and decoder on personal computers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; video codec; multimedia; MMX/SSE technologies; SIMD;
   Hyper-Threading Technology; multi-threading
AB H.264 is an emerging video coding standard, which aims at compressing high-quality video contents at low-bit rates. While the new encoding and decoding processes are similar to many previous standards, the new standard includes a number of new features and thus requires much more computation than most existing standards do. The complexity of H.264 standard poses a large amount of challenges to implementing the encoder/decoder in real-time via software on personal computers. This work analyzes software implementation of H.264 encoder and decoder on general-purpose processors with media instructions and multi-threading capabilities. Specifically, we discuss how to optimize the algorithms of H.264 encoders and decoders on Intel Pentium 4 processors. We first analyze the reference implementation to identify the time-consuming modules, and present optimization methods using media instructions to improve the speed of these modules. After appropriate optimizations, the speed of the codec improves by more than 3x. Nonetheless, the H.264 encoder is still too complicated to be implemented in real-time on a single processor. Thus, we also study how to partition the H.264 encoder into multiple threads, which then can be run on systems with multiple processors or multi-threading capabilities. We analyze different multi-threading schemes that have different quality/performance, and propose a scheme with good scalability (i.e., speed) and good quality. Our encoder can obtain another 3.8x speedup on a four-processor system or 4.6x speedup on a four-processor system with Hyper-Threading Technology. This work demonstrates that hardware-specific algorithm modifications can speed up the H.264 decoder and encoder substantially. The performance improvement techniques on modern microprocessors demonstrated in this work can be applied not only to H.264, but also to other video or multimedia processing applications. (c) 2005 Elsevier Inc. All rights reserved.
C1 Intel Corp, Corp Technol Grp, Santa Clara, CA 95052 USA.
C3 Intel Corporation
RP Chen, YK (corresponding author), Intel Corp, Corp Technol Grp, 2200 Mission Coll Blvd, Santa Clara, CA 95052 USA.
EM yen-kuang.chen@intel.com
RI Chen, Yen-Kuang/ABE-6483-2021; Ge, Steven/ABF-1186-2021
OI Chen, Yen-Kuang/0000-0003-4546-9497; Ge, Steven/0000-0001-7406-3782
CR [Anonymous], 144962 ISOIEC
   BARBOSA DM, 1999, INT C PAR COMP SYST
   Casalino F, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P363, DOI 10.1109/MMCS.1999.779231
   Chen Y, 2002, IEE CONF PUBL, P47, DOI 10.1049/cp:20020359
   Ge S, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P469
   Gibbs WW, 2004, SCI AM, V291, P96, DOI 10.1038/scientificamerican1104-96
   HOLLIMAN M, 2003, WORKSH COMP ARCH EV, P23
   *INT CORP, IA 32 INT ARCH SOFTW, V2
   *INT CORP, 2004, NEXT GEN INT PROC SO
   *INT CORP, 2003, MOT EST ALG US STREA
   *INT CORP, INT PENT 4 OPT REF M
   *ISO IEC, 1449610 ISOIEC
   IVERSON V, 2004, INT C IM PROC, P1541
   Lappalainen V, 2003, J VLSI SIG PROC SYST, V34, P239, DOI 10.1023/A:1023248302658
   Lappalainen V, 2003, IEEE T CIRC SYST VID, V13, P717, DOI 10.1109/TCSVT.2003.814968
   Lappalainen V., 1998, Proceedings ACM Multimedia 98, P309, DOI 10.1145/290747.290787
   Li EQ, 2004, PROC SPIE, V5308, P384, DOI 10.1117/12.525581
   LI X, 2004, IEEE INT C AC SPEECH, V3, P369
   Malvar H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P489
   Marr D. T., 2002, Intel Technology Journal
   Meng B., 2003, IEEE INT C AC SPEECH, V3, P389
   SHEN K, 1995, SPIE C DIG VID COMPR
   Taylor H. H., 1993, DCC '93. Data Compression Conference (Cat. No.93TH0536-3), P420, DOI 10.1109/DCC.1993.253107
   van der Tol EB, 2003, PROC SPIE, V5022, P707, DOI 10.1117/12.476234
   Zhou XS, 2003, PROC SPIE, V5022, P224, DOI 10.1117/12.484746
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 26
TC 52
Z9 65
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 509
EP 532
DI 10.1016/j.jvcir.2005.05.004
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000017
DA 2024-07-18
ER

PT J
AU Naphade, MR
AF Naphade, MR
TI On supervision and statistical learning for semantic multimedia analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE factor graphs; sum product algorithm; active learning; hidden Markov
   models; dynamic Bayesian networks; support vector machines
ID HIDDEN MARKOV-MODELS; IMAGE CLASSIFICATION; SEGMENTATION; SPEECH; AUDIO
AB Media analysis for video indexing is witnessing an increasing influence of statistical techniques. Examples of these techniques include the use of generative models as well as discriminant techniques for video structuring, classification, summarization, indexing, and retrieval. There is increasing emphasis on reducing the amount of supervision and user interaction needed to construct and utilize the semantic models. This paper highlights the statistical learning techniques in semantic multimedia indexing and retrieval. In particular the gamut of techniques from supervised to unsupervised systems will be demonstrated. (C) 2004 Elsevier Inc. All rights reserved.
C1 IBM Corp, Thomas J Watson Res Ctr, Pervas Media Management Grp, Hawthorne, NY 10532 USA.
C3 International Business Machines (IBM)
RP IBM Corp, Thomas J Watson Res Ctr, Pervas Media Management Grp, 19 Skyline Dr, Hawthorne, NY 10532 USA.
EM naphade@us.ibm.com
CR ADAMS WH, 2002, P TEXT RETR C TREC
   [Anonymous], P 3 ACM INT C MULT S
   Barnard K., 2001, INT C COMPUTER VISIO
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Chen T, 1998, P IEEE, V86, P837, DOI 10.1109/5.664274
   CLARKSON B, 1999, P IEEE INT C ACC SPE
   Courtney JD, 1997, PATTERN RECOGN, V30, P607, DOI 10.1016/S0031-3203(96)00107-0
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ellis D. P. W., 1996, THESIS MIT CAMBRIDGE
   FERMAN AM, 1999, P IEEE INT C IM PROC
   Foote J, 1999, INT CONF ACOUST SPEE, P3029, DOI 10.1109/ICASSP.1999.757479
   Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087
   *ISO IEC, 2001, JTC1SC29WG11N3966 IS
   IYENGAR G, 1998, SPIE C STOR RETR STI, P216
   IYENGAR V, 2000, ACM SIGKDD, P91
   Jang PJ, 1999, IEEE INTELL SYST APP, V14, P51, DOI 10.1109/5254.796090
   JOACHIMS T, 1999, SUPPROT VECTOR LEARN
   KENDER JR, 1998, CVPR 98, P367
   Kobla V, 2000, PROC SPIE, V3972, P332
   Kozintsev MR, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P35, DOI 10.1109/IVL.2000.853836
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   LEVINSON S, 1989, P DARPA SPEECH NAT L, P75
   LIU L, 2000, P WORKSH CONT BAS AC
   Liu Z, 1998, J VLSI SIG PROC SYST, V20, P61, DOI 10.1023/A:1008066223044
   LIU Z, 1998, MULTIMEDIA SIGNAL PR
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Minami K, 1998, IEEE MULTIMEDIA, V5, P17, DOI 10.1109/93.713301
   NAKAMURA Y, 1997, P ACM INT MULT C
   Nam JH, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P550, DOI 10.1109/ICIP.1997.638830
   NAPHADE M, 2002, IEEE INT C IM PROC R
   NAPHADE M, 2003, SPIE STORAGE RETRIEV, V5021
   NAPHADE M, 2002, SPIE C STORAGE RETRI
   Naphade M.R., 2001, IEEE INT C MULTIMEDI
   Naphade MR, 2002, IEEE IMAGE PROC, P145
   Naphade MR, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P46, DOI 10.1109/ICIP.2001.958047
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   Naphade MR, 2000, PROC SPIE, V4210, P13, DOI 10.1117/12.403809
   Naphade MR, 2000, PROC SPIE, V3972, P168
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   NAPHADE MR, 2001, ACM MULTIMEDIA, P411
   NAPHADE MR, 2000, P NEUR INF PROC SYST, V13, P967
   Poritz A., 1982, ICASSP 1982, P1291
   Qian R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P200, DOI 10.1109/CVPR.1999.786939
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RATAN A, 1999, P COMP VIS PATT REC, V1, P423
   REHG J, 1999, P COMP VIS PATT REC, V2, P110
   SRINIVASAN S, 2000, P IEEE INT C MULT EX, P388
   SUNDARAM H, 2000, P IEEE INT C MULT EX, V1
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   *TRC, 2001, VID RETR
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Vapnik V, 1995, NATURE STAT LEARING
   Wactlar HD, 1996, COMPUTER, V29, P46, DOI 10.1109/2.493456
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   WOLF W, 1997, P INT C ACOUSTICS SI
   Zhang T, 2000, PROC SPIE, V3972, P506
   Zhang T., 2000, P 17 INT C MACH LEAR, P1191
NR 58
TC 11
Z9 11
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 348
EP 369
DI 10.1016/j.jvcir.2004.04.010
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100006
DA 2024-07-18
ER

PT J
AU Zhong, D
   Chang, SF
AF Zhong, D
   Chang, SF
TI Real-time view recognition and event detection for sports video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video indexing; content-based video retrieval; sports video analysis;
   MPEG-7
AB In this paper, we present a general framework and new effective algorithms to detect the syntactic structures that are at a level higher than shots. In sports video, such high-level structures are often characterized by the specific views (e.g., pitching or serve) and the subsequent temporal transition patterns within each temporal structural segment. We have developed robust statistical models for detecting the domain-specific views with real-time performance and high accuracy. The models combine domain-independent global color filtering method and domain-specific constraints on the spatio-temporal properties of the segmented regions (e.g., locations, shapes, and motion of the objects). The real-time performance was accomplished by using efficient compressed-domain processing at the front end and computational expensive object-level processing on filtered candidates only. High-level events (e.g., strokes, net plays, and baseline plays) are also detected after the view recognition. Results of such structure and event detection allow for efficient browsing and summarization of long sports video programs. (C) 2004 Elsevier Inc. All rights reserved.
C1 Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
C3 Columbia University
RP Chang, SF (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
EM dzhong@ee.columbia.edu
CR [Anonymous], **NON-TRADITIONAL**
   Bierling M., 1988, VISUAL COMMUNICATION, V1001
   CHANG SF, 2001, IEEE CVPR WORKSH CON
   CHANG SF, 1997, ACM 5 MULT C SEATT N
   GONG Y, 1995, P ICMCS95 WASH MAY
   HANJALIC A, 1999, IEEE T CIRCUITS SYST, V9
   JAIMES A, 2000, 4 AS C COMP VIS ACCV
   LIENHART R, 1997, P IEEE INT C MUTL CO
   RUI Y, 2000, 8 ACM INT C MULT OCT
   SATO T, 1998, P 1998 INT WORKSH CO
   SAUR DD, 1997, P SPIE EL IM C STOR
   SUDHIR G, 1998, P 1998 INT WORKSH CO
   SUNDARAM H, 2000, ACM MULTIMEDIA 2000
   ZHANG D, 2002, ACM MULTIMEDIA 2002
   ZHONG D, 1997, IEEE INT S CIRC SYST
   ZHONG D, 2001, IEEE C MULTIMEDIA EX
   ZHONG D, 2001, IEEE INT C IM PROC T
NR 17
TC 35
Z9 39
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 330
EP 347
DI 10.1016/j.jvcir.2004.04.009
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100005
DA 2024-07-18
ER

PT J
AU Liapis, S
   Sifakis, E
   Tziritas, G
AF Liapis, S
   Sifakis, E
   Tziritas, G
TI Colour and texture segmentation using wavelet frame analysis,
   deterministic relaxation, and fast marching algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID STATISTICAL-ANALYSIS; CLASSIFICATION; FILTERS; IMAGES; MODELS
AB Luminance, colour, and/or texture features may be used, either alone or in combination, for segmentation. In this paper luminance and colour classes are described using the corresponding empirical probability distributions. For texture analysis and characterisation a multichannel scale/orientation decomposition is performed using wavelet frame analysis. Knowing only the number of the different classes of the image, regions of homogeneous patterns are identified. On these regions the features characterising and describing the different classes are estimated. Two labelling algorithms are proposed. The first, a deterministic relaxation algorithm using a quadratic distance measure, yields the labelling of pixels to the different colour-texture classes. The second is a new Multi-label Fast Marching algorithm utilising a level set boundary determination. (C) 2003 Elsevier Inc. All rights reserved.
C1 Univ Crete, Dept Comp Sci, Iraklion, Greece.
C3 University of Crete
RP Tziritas, G (corresponding author), Univ Crete, Dept Comp Sci, POB 2208, Iraklion, Greece.
EM liapis@csd.uoc.gr; sifakis@csd.uoc.gr; tziritas@csd.uoc.gr
RI Tziritas, Georgios/AAO-5855-2021
CR BELONGIE S, 1998, INT C COMP VIS
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BESAG J, 1986, J R STAT SOC B, V48, P259
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   BRODATZ P, 1966, PHOTOGRAPHIC ALBUM A
   CHEN PC, 1983, IEEE T PATTERN ANAL, V5, P64, DOI 10.1109/TPAMI.1983.4767346
   CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995
   Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kashyap RL, 1982, PATTERN RECOGN LETT, V1, P43, DOI 10.1016/0167-8655(82)90050-2
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   Laine A, 1996, IEEE T IMAGE PROCESS, V5, P771, DOI 10.1109/83.499915
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Paragios N., 1999, INT C COMP VIS
   PORAT M, 1989, IEEE T BIO-MED ENG, V36, P115, DOI 10.1109/10.16457
   Raghu PP, 1996, IEEE T IMAGE PROCESS, V5, P1625, DOI 10.1109/83.544570
   Raghu PP, 1997, IEEE T IMAGE PROCESS, V6, P1376, DOI 10.1109/83.624953
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Randen T, 1999, IEEE T IMAGE PROCESS, V8, P571, DOI 10.1109/83.753744
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   SETHIAN JA, 1996, ACTA NUMER, P309
   Sifakis E, 2002, J VIS COMMUN IMAGE R, V13, P44, DOI 10.1006/jvci.2001.0474
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Young T.Y., 1986, HDB PATTERN RECOGNIT
NR 29
TC 27
Z9 29
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2004
VL 15
IS 1
BP 1
EP 26
DI 10.1016/S1047-3203(03)00025-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 772PV
UT WOS:000188851200001
DA 2024-07-18
ER

PT J
AU Goldberg, N
   Feuer, A
   Goodwin, GC
AF Goldberg, N
   Feuer, A
   Goodwin, GC
TI Super-resolution reconstruction using spatio-temporal filtering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE super-resolution; aliasing
ID HIGH-RESOLUTION IMAGE; RESTORATION; SEQUENCE; NOISY; TIME
AB It has been known for some time that temporal dependence (motion) plays a key role in the super-resolution (SR) reconstruction of a single frame (or sequence of frames). While the impact of global time-invariant translations is relatively well known, the general motion case has not been studied in detail. In this paper, we discuss SR reconstruction for both motion models from a frequency-domain point of view. A noniterative algorithm for SR reconstruction is presented using spatio-temporal filtering. The concepts of motion-compensated windows and sinc interpolation kernels are utilized, resulting in a finite impulse response (FIR) filter realization. In the simulations, we assume a priori knowledge of the motion (optical flow), which is commonly done throughout much of the SR reconstruction literature. The proposed process is localized in nature, and this enables the selective reconstruction of desired parts of a particular frame or sequence of frames. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Technion Israel Inst Technol, Dept EE, IL-32000 Haifa, Israel.
   Univ Newcastle, CIDAC, Dept EE, Newcastle, NSW 2308, Australia.
C3 Technion Israel Institute of Technology; University of Newcastle
RP Technion Israel Inst Technol, Dept EE, IL-32000 Haifa, Israel.
OI Goodwin, Graham/0000-0003-2408-212X
CR Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bose N.K., 1993, Proc. IEEE International Conf. Acoustics, V. V, P269
   CHRIJVER A, 1986, THEORY LINEAR INTEGE
   DUBOIS E, 1985, P IEEE, V73, P502, DOI 10.1109/PROC.1985.13182
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893
   Elad M, 1999, IEEE T PATTERN ANAL, V21, P817, DOI 10.1109/34.790425
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   HUANG TS, 1984, ADV COMPUTER VISION, pCH7
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   PATTI AJ, 1994, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.1994.413332
   PATTI AJ, 1995, IEEE INT C AC SPEECH, V2, P2197
   PELEG S, 1987, PATTERN RECOGN LETT, V5, P223, DOI 10.1016/0167-8655(87)90067-5
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Tekalp A., 1992, PROC IEEE INT CONF A, V3, P169
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
NR 18
TC 9
Z9 10
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 508
EP 525
DI 10.1016/S1047-3203(03)00042-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800008
DA 2024-07-18
ER

PT J
AU Zhang, H
   Wang, YF
   Yang, YJ
AF Zhang, Han
   Wang, Yongfang
   Yang, Yingjie
TI LL-WSOD: Weakly supervised object detection in low-light
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised learning; Object detection; Low light; Salient priors
ID ENHANCEMENT
AB Weakly supervised detection performs significantly lower than the fully supervised methods due to the lack of detailed and precise annotations. Especially, its performance deteriorates more severely in low-light conditions with the lack of low-light datasets. To overcome these issues, we propose a new Low-Light Weakly Supervised Object Detection (LL-WSOD) framework. First, we propose a Progressive Low-light NoiseModule (PLNM) to train the model progressively with low light using the common datasets with normal light, greatly reducing the training difficulty. Next, a Residual Self-refinement Low-light Rebuild Module (ResSLRM) is proposed to allow convolutional neural networks to learn sharper features by rebuilding low-light features into normal-light images. Finally, a Pseudo Boundingbox Assisted Learning Module (PBALM) is designed to perform better low-light training using salient priors. The results show that the proposed LL-WSOD algorithm effectively detects objects under low-light conditions and achieves great results on the real low-light dataset ExDark.
C1 [Wang, Yongfang] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Wang, YF (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM yfw@shu.edu.cn
RI Chen, Jin/KBQ-0163-2024; Zhang, Xiaoxi/KBP-8753-2024; WANG,
   YUHAO/KBB-0213-2024
OI Chen, Jin/0009-0005-5844-635X; 
FU Natural Science Foundation of China [61671283, U2033218]
FX This work was supported by Natural Science Foundation of China under
   Grant Nos. 61671283, U2033218.
CR Al Sobbahi R, 2022, SIGNAL PROCESS-IMAGE, V109, DOI 10.1016/j.image.2022.116848
   Al Sobbahi R, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116527
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Brooks T, 2019, PROC CVPR IEEE, P11028, DOI 10.1109/CVPR.2019.01129
   Chen WJ, 2021, VISUAL COMPUT, V37, P805, DOI 10.1007/s00371-020-01831-7
   Cui Z., 2021, arXiv, DOI [10.48550/arXiv.2205.03346, DOI 10.48550/ARXIV.2205.03346]
   Cui Z., 2022, P BRIT MACH VIS C, P21
   Du PL, 2019, IEEE IMAGE PROC, P3367, DOI [10.1109/icip.2019.8803672, 10.1109/ICIP.2019.8803672]
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Hai J, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103712
   Hong Y., 2021, BRIT MACH VIS C, V1, P3
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Ke Yang, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P8371, DOI 10.1109/ICCV.2019.00846
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Liang JX, 2022, IEEE T MULTIMEDIA, V24, P1609, DOI 10.1109/TMM.2021.3068840
   Liu HM, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3274926
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WY, 2022, AAAI CONF ARTIF INTE, P1792
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Qiu YS, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031347
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sasagawa Yukihiro, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P345, DOI 10.1007/978-3-030-58589-1_21
   Shao FF, 2022, NEUROCOMPUTING, V496, P192, DOI 10.1016/j.neucom.2022.01.095
   Shen L, 2017, Arxiv, DOI arXiv:1711.02488
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Van Nhan Nguyen, 2019, IEEE Power and Energy Technology Systems Journal, V6, P11, DOI 10.1109/JPETS.2018.2881429
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei KX, 2020, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR42600.2020.00283
   Wu YR, 2023, IEEE T NETW SCI ENG, V10, P3086, DOI 10.1109/TNSE.2022.3151502
   Xu X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414839
   Yang J, 2016, INT C PATT RECOG, P751, DOI 10.1109/ICPR.2016.7899725
   Yang SL, 2023, IEEE T COMPUT IMAG, V9, P29, DOI 10.1109/TCI.2023.3240087
   Yang WH, 2020, IEEE T IMAGE PROCESS, V29, P5737, DOI 10.1109/TIP.2020.2981922
   Zhao XM, 2020, IEEE SENS J, V20, P4901, DOI 10.1109/JSEN.2020.2966034
   Zheng YQ, 2020, PROC CVPR IEEE, P6748, DOI 10.1109/CVPR42600.2020.00678
   Zhongzheng Ren, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10595, DOI 10.1109/CVPR42600.2020.01061
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
   Ziqiang Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P155, DOI 10.1007/978-3-030-58580-8_10
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 54
TC 0
Z9 0
U1 24
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104010
DI 10.1016/j.jvcir.2023.104010
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DO4B8
UT WOS:001132968600001
DA 2024-07-18
ER

PT J
AU Wang, M
   Yang, WZ
   Wang, LJ
   Chen, DY
   Wei, FY
   KeZiErBieKe, H
   Liao, YY
AF Wang, Min
   Yang, Wenzhong
   Wang, Liejun
   Chen, Danny
   Wei, Fuyuan
   KeZiErBieKe, HaiLaTi
   Liao, Yuanyuan
TI FE-YOLOv5: Feature enhancement network based on YOLOv5 for small object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Small object detection; Feature enhancement; Spatial-aware
AB Due to their inherent characteristics, small objects have weaker feature representation after multiple downsampling and are even annihilated in the background. FPN's simple feature concatenation does not fully utilize multi-scale information and introduces irrelevant context into the information transfer, further reducing the detection performance of the small object. To address the above issues, we propose the simple but effective FE-YOLOv5. (1) We designed the feature enhancement module (FEM) to capture more discriminative features of the small object. Global attention and high-level global contextual information are used to guide shallow, high-resolution features. Global attention interacts with cross-dimensional feature interaction and reduces information loss. High-level context complements more detailed semantic information by modeling global relationships through non-local networks. (2) We design the spatially aware module (SAM) to filter spatial information and enhance the robustness of features. Deformable convolution performs sparse sampling and adaptive spatial learning to better focus on foreground objects. According to the experimental results, our proposed FE-YOLOv5 outperforms the other architectures in the VisDrone2019 dataset and Tsinghua-Tencent100K dataset. Compared to YOLOv5, the APS was improved by 2.8% and 2.9%, respectively.
C1 [Wang, Min; Yang, Wenzhong; Wang, Liejun; Chen, Danny; Wei, Fuyuan; KeZiErBieKe, HaiLaTi; Liao, Yuanyuan] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi, Xinjiang, Peoples R China.
   [Wang, Min; Yang, Wenzhong; Chen, Danny; Wei, Fuyuan] Xinjiang Univ, Xinjiang Key Lab Multilingual Informat Technol, Urumqi, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Yang, WZ (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Urumqi, Xinjiang, Peoples R China.
EM wangmin@stu.xju.edu.cn; yangwenzhong@xju.edu.cn; wljxju@xju.edu.cn;
   kabuoxygen@163.com; 641868693@qq.com; hayrat805@163.com;
   liaoyuan@xju.edu.cn
FU National Natural Science Foundation of China [U1603115]; Science and
   Technology Project of Autonomous Region [2020A02001- 1]; Jiangxi Natural
   Science Foundation Project [2021D01C080]; Research on short-term and
   impending precipitation prediction model and accuracy evaluation in
   Northern Xinjiang Based on deep learning;  [20202BAB202023]
FX This research was funded by [the National Natural Science Foundation of
   China] grant number [No. U1603115], [Science and Technology Project of
   Autonomous Region] grant number [No. 2020A02001-1], [Research on
   short-term and impending precipitation prediction model and accuracy
   evaluation in Northern Xinjiang Based on deep learning] grant number
   [2021D01C080] and [Jiangxi Natural Science Foundation Project] grant
   number [No. 20202BAB202023].
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cao Y., 2019, CORR, P1, DOI [DOI 10.1109/ICCVW.2019.00246, 10.1109/ICCVW.2019.00246]
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YQ, 2021, IEEE WINT CONF APPL, P1159, DOI 10.1109/WACV48630.2021.00120
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kisantal M, 2019, Arxiv, DOI arXiv:1902.07296
   Li HC, 2018, Arxiv, DOI [arXiv:1805.10180, DOI 10.48550/ARXIV.1805.10180]
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., 2021, arXiv, DOI DOI 10.48550/ARXIV.2112.05561
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sun W, 2022, APPL INTELL, V52, P8448, DOI 10.1007/s10489-021-02893-3
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang CHY, 2022, PROC CVPR IEEE, P13658, DOI 10.1109/CVPR52688.2022.01330
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhu PF, 2022, IEEE T PATTERN ANAL, V44, P7380, DOI 10.1109/TPAMI.2021.3119563
   Zhu X., 2020, arXiv
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 33
TC 24
Z9 25
U1 41
U2 97
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103752
DI 10.1016/j.jvcir.2023.103752
EA NOV 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9GY0
UT WOS:000971749700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Xing, HQ
   Zhou, YC
   Yang, JY
   Xiao, Y
AF Xing, Huiqin
   Zhou, Yicong
   Yang, Jianyu
   Xiao, Yang
TI Learning full context feature for human motion prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human motion prediction; Context feature; Motion constraint; Dictionary
AB Human motion prediction aims to predict the target poses given the previous poses. Most existing methods are devoted to extracting richer motion features from only the given previous poses to predict the target poses. However, we consider that the post poses after the target poses are helpful in acquiring the context feature and constraint between neighbor motions, which is also important for motion prediction. In this paper, we explore to make use of the post motion information for a powerful human motion prediction method. Specifically, we propose a human motion prediction model which learns the motion constraint from both the previous and post poses, in order to fully utilize the context features of the target poses. During training, the proposed memory dictionary module is used to learn the mapping from previous features to post features. In testing, the proposed memory dictionary module fully exploits the learned mapping to calculate the future motion feature according to the input previous feature. Thus, the context feature of human motion is enriched in our method. We evaluate the proposed method on two large-scale datasets, Human3.6M and CMU-Mocap. The experimental results demonstrate that our method improves the motion prediction performance, especially for long-term human motion.
C1 [Xing, Huiqin; Zhou, Yicong; Yang, Jianyu] Soochow Univ, Sch Rail Transportat, 8 Jixue Rd, Suzhou 215131, Jiangsu, Peoples R China.
   [Xiao, Yang] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Hubei, Peoples R China.
C3 Soochow University - China; Huazhong University of Science & Technology
RP Yang, JY (corresponding author), Soochow Univ, Sch Rail Transportat, 8 Jixue Rd, Suzhou 215131, Jiangsu, Peoples R China.
EM jyyang@suda.edu.cn
FU National Natural Science Foun-dation of China [62271221, 61773272]; Six
   Talent Peaks Project of Jiangsu Province, China [XYDXX-053]
FX <B>Acknowledgments</B> This work was supported by the National Natural
   Science Foun-dation of China (NSFC No. 62271221, 61773272) , and the Six
   Talent Peaks Project of Jiangsu Province, China (No. XYDXX-053) .
CR Akhter I., 2008, NIPS
   Aksan E, 2021, INT CONF 3D VISION, P565, DOI 10.1109/3DV53792.2021.00066
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   [Anonymous], 2003, CMU mocap database
   Barsoum E, 2018, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2018.00191
   Cao WM, 2022, NEUROCOMPUTING, V493, P106, DOI 10.1016/j.neucom.2022.04.047
   Chao X., 2020, P ASIAN C COMPUTER V
   Cui Qiongjie, 2021, P IEEE CVF C COMP VI, P4801
   Dahiya A, 2023, ROBOT AUTON SYST, V161, DOI 10.1016/j.robot.2022.104335
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Gopalakrishnan A, 2019, PROC CVPR IEEE, P12108, DOI 10.1109/CVPR.2019.01239
   Gui LY, 2018, LECT NOTES COMPUT SC, V11208, P823, DOI 10.1007/978-3-030-01225-0_48
   He YW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR), P103, DOI 10.1109/RCAR.2017.8311843
   Huang Y, 2021, PATTERN RECOGN LETT, V144, P97, DOI 10.1016/j.patrec.2020.11.011
   Huynh DQ, 2009, J MATH IMAGING VIS, V35, P155, DOI 10.1007/s10851-009-0161-2
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jain DK, 2020, NEURAL COMPUT APPL, V32, P14579, DOI 10.1007/s00521-020-04941-4
   Kundu JN, 2019, AAAI CONF ARTIF INTE, P8553
   Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171
   Li C, 2018, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2018.00548
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Liu ZG, 2023, IEEE T PATTERN ANAL, V45, P681, DOI 10.1109/TPAMI.2021.3139918
   Mao W, 2019, IEEE I CONF COMP VIS, P9488, DOI 10.1109/ICCV.2019.00958
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Ruiz AH, 2019, IEEE I CONF COMP VIS, P7133, DOI 10.1109/ICCV.2019.00723
   Shao ZP, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103529
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song CY, 2023, DISPLAYS, V76, DOI 10.1016/j.displa.2022.102360
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Tang YY, 2018, Arxiv, DOI arXiv:1805.02513
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang Jack, 2005, Advances in Neural Information Processing Systems, V18
   Wang L, 2023, LECT NOTES COMPUT SC, V13844, P307, DOI 10.1007/978-3-031-26316-3_19
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wei Mao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P474, DOI 10.1007/978-3-030-58568-6_28
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu HR, 2016, IEEE IMAGE PROC, P644, DOI 10.1109/ICIP.2016.7532436
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang JY, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103263
   Yang JY, 2021, IEEE T MULTIMEDIA, V23, P883, DOI 10.1109/TMM.2020.2990082
   Yang JY, 2017, IEEE INT CON MULTI, P631, DOI 10.1109/ICME.2017.8019348
   Yang JY, 2016, J VIS COMMUN IMAGE R, V38, P627, DOI 10.1016/j.jvcir.2016.04.010
   Yang JY, 2016, NEUROCOMPUTING, V190, P70, DOI 10.1016/j.neucom.2016.01.032
   Yujun Cai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P226, DOI 10.1007/978-3-030-58571-6_14
   Zhang YH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3229, DOI 10.1145/3474085.3475473
   Zhong JQ, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109427
   Zhu C, 2021, IEEE-CAA J AUTOMATIC, V8, P1600, DOI 10.1109/JAS.2019.1911534
NR 51
TC 0
Z9 0
U1 7
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103955
DI 10.1016/j.jvcir.2023.103955
EA OCT 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y2IZ1
UT WOS:001103567800001
DA 2024-07-18
ER

PT J
AU Li, J
   Liu, Z
   Li, L
   Lin, JQ
   Yao, J
   Tu, JM
AF Li, Jie
   Liu, Zhao
   Li, Li
   Lin, Junqin
   Yao, Jian
   Tu, Jingmin
TI Multi-view convolutional vision transformer for 3D object recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view; 3D object recognition; Feature fusion; Convolutional neural
   networks
ID FUSION
AB With the rapid development of three-dimensional (3D) vision technology and the increasing application of 3D objects, there is an urgent need for 3D object recognition in the fields of computer vision, virtual reality, and artificial intelligence robots. The view-based method projects 3D objects into two-dimensional (2D) images from different viewpoints and applies convolutional neural networks (CNN) to model the projected views. Although these methods have achieved excellent recognition performance, there is not sufficient information interaction between the features of different views in these methods. Inspired by the recent success achieved by vision transformer (ViT) in image recognition, we propose a hybrid network by taking advantage of CNN to extract multi-scale local information of each view, and of transformer to capture the relevance of multi -scale information between different views. To verify the effectiveness of our multi-view convolutional vision transformer (MVCVT), we conduct experiments on two public benchmarks, ModelNet40 and ModelNet10, and compare with those of some state-of-the-art methods. The final results show that MVCVT has competitive performance in 3D object recognition.
C1 [Li, Jie; Liu, Zhao; Tu, Jingmin] Hubei Univ Technol, Hubei Key Lab High Efficiency Utilizat Solar Energ, Wuhan 430068, Peoples R China.
   [Li, Li; Yao, Jian] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Lin, Junqin] Beijing Inst Precis Mechatron & Controls, Beijing 100076, Peoples R China.
   [Lin, Junqin] Lab Aerosp Servo Actuat & Transmiss, Beijing 100076, Peoples R China.
   [Yao, Jian] Wuhan Univ, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
C3 Hubei University of Technology; Wuhan University; Wuhan University
RP Tu, JM (corresponding author), Hubei Univ Technol, Hubei Key Lab High Efficiency Utilizat Solar Energ, Wuhan 430068, Peoples R China.
EM jielonline@hbut.edu.cn; ja102@hbut.edu.cn; jingmin.tu@hbut.edu.cn
FU National Natural Sci-ence Foundation of China [42271445, U22A2009,
   2022PGE008]; Foundation of Anhui Province Key Laboratory of Phys-ical
   Geographic Environment [JCYJ20220530140618040]; Shenzhen Science and
   Technology Program [2021Szvup100]; Shen-zhen Central Guiding the Local
   Science and Technology Development Program;  [42101440]
FX <B>Acknowledgments</B> This work was partially supported by the National
   Natural Sci-ence Foundation of China (No. 42101440, No. 42271445 and No.
   U22A2009) , the Foundation of Anhui Province Key Laboratory of Phys-ical
   Geographic Environment (2022PGE008) , the Shenzhen Science and
   Technology Program (No. JCYJ20220530140618040) , the Shen-zhen Central
   Guiding the Local Science and Technology Development Program (No.
   2021Szvup100) .
CR Ben-Shabat Y, 2018, IEEE ROBOT AUTOM LET, V3, P3145, DOI 10.1109/LRA.2018.2850061
   Chen S., 2022, arXiv
   Chen S, 2021, Arxiv, DOI [arXiv:2110.13083, DOI 10.48550/ARXIV.2110.13083]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elizar E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197384
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Hagbi N, 2011, IEEE T VIS COMPUT GR, V17, P1369, DOI 10.1109/TVCG.2010.241
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426
   He XW, 2023, Arxiv, DOI arXiv:2109.01291
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZY, 2019, AAAI CONF ARTIF INTE, P8505
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Jing WP, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14041036
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Lei Ba J., 2016, arXiv
   Liang Q, 2021, PATTERN RECOGN LETT, V150, P214, DOI 10.1016/j.patrec.2021.07.010
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu DN, 2022, IEEE T INTELL TRANSP, V23, P24854, DOI 10.1109/TITS.2022.3198836
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Meng HY, 2019, IEEE I CONF COMP VIS, P8499, DOI 10.1109/ICCV.2019.00859
   Pylvanainen T., 2010, S 3D DAT PROC VIS TR, P738
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qi SH, 2022, IET COMPUT VIS, DOI 10.1049/cvi2.12107
   Qiu S, 2021, IEEE WINT CONF APPL, P3812, DOI 10.1109/WACV48630.2021.00386
   Ren MW, 2017, Arxiv, DOI [arXiv:1711.10108, DOI arXiv:1711.10108.null]
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tang Y., 2016, P 24 ACM INT C MULT, P397
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang C, 2019, Arxiv, DOI arXiv:1906.01592
   Wang WJ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14091996
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie JW, 2021, PROC CVPR IEEE, P14971, DOI 10.1109/CVPR46437.2021.01473
   Xu Y, 2021, IEEE T IMAGE PROCESS, V30, P5299, DOI 10.1109/TIP.2021.3082310
   Yang MM, 2023, IEEE WINT CONF APPL, P653, DOI 10.1109/WACV56688.2023.00072
   Yang Z, 2019, IEEE I CONF COMP VIS, P7504, DOI 10.1109/ICCV.2019.00760
   You HX, 2019, AAAI CONF ARTIF INTE, P9119
   Yu T, 2021, IEEE T IMAGE PROCESS, V30, P2168, DOI 10.1109/TIP.2021.3049968
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
NR 45
TC 2
Z9 2
U1 9
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103906
DI 10.1016/j.jvcir.2023.103906
EA AUG 2023
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P8ZJ3
UT WOS:001053498700001
DA 2024-07-18
ER

PT J
AU Ding, GC
   Lin, XJ
   Wang, JJ
   Ding, DD
AF Ding, Gongchun
   Lin, Xiujun
   Wang, Junjie
   Ding, Dandan
TI Accelerating QTMT-based CU partition and intra mode decision for
   versatile video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile Video Coding; CU partition; Intra prediction; Intra mode;
   Complexity
ID DEPTH DECISION; ALGORITHM
AB The H.266/VVC achieves about 50% bitrate saving compared to its predecessor H.265/HEVC at the expense of exponentially increased computational complexity. The most efficient but complex technique for H.266/VVC intra frame coding is the QuadTree with a nested Multi-type Tree encoding structure (QTMT), which usually requires traversing the Rate-Distortion (R-D) cost of each partition and each mode for the best option. To alleviate such computational burden while preserving the coding efficiency as much as possible, this paper develops a multi-feature guided Fast CU Partition (FCP) and Laplacian guided Fast Mode Selection (FMS) to accelerate the intra QTMT decision together. For FCP, we regard the CU partition as a classification problem and adopt the Support Vector Machine (SVM) for its low-complexity implementation; after evaluating the contribution of a set of features, three representative features of video textures are selected and used to train the SVM model. Additionally, an advanced technique is applied by adopting a soft decision in SVM for a more flexible trade-off between the complexity and R-D performance. For FMS, we utilize the Laplace operator to determine the most probable directions of the current CU and skip half of the candidate modes for runtime saving. Experimental results demonstrate that the proposed FCP reduces the encoding time of H.266/VVC by 51.03% with 1.65% Bjontegaard Delta Bit-Rate (BDBR) increase; the proposed FMS reduces the encoding time by 12.68% with 0.09% BDBR loss. Their direct combination and advanced combination finally lead to 54.84% encoding time reduction with 1.74% BDBR increase and 40.39% encoding time reduction with 1.33% BDBR increase, respectively, outperforming state-of-the-art approaches significantly.
C1 [Ding, Gongchun; Lin, Xiujun; Wang, Junjie; Ding, Dandan] Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou 311121, Zhejiang, Peoples R China.
C3 Hangzhou Normal University
RP Ding, DD (corresponding author), Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou 311121, Zhejiang, Peoples R China.
EM DandanDing@hznu.edu.cn
RI WANG, Junjie/IAR-6122-2023
OI WANG, Junjie/0000-0002-9347-6475
FU National Natural Science Foundation of China [62171174]
FX We would like to thank Zongju Peng of the School of Electrical and
   Electronic Engineering, Chongqing University of Technology, for helpful
   discussions on topics related to this work. This research was supported
   by National Natural Science Foundation of China under Grant 62171174.
CR Abdallah B., 2022, P 2022 IEEE INT C DE, P1
   Amna M, 2021, 2020 10TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), DOI 10.1109/ISIVC49222.2021.9487529
   Bossen F, 2021, IEEE T CIRC SYST VID, V31, P3765, DOI 10.1109/TCSVT.2021.3072204
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Cao J, 2020, LECT NOTES COMPUT SC, V11961, P739, DOI 10.1007/978-3-030-37731-1_60
   Cen YF, 2015, INFORM PROCESS LETT, V115, P719, DOI 10.1016/j.ipl.2015.04.001
   Chen F, 2020, MULTIMED TOOLS APPL, V79, P27923, DOI 10.1007/s11042-020-09401-8
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Ding DD, 2021, P IEEE, V109, P1494, DOI 10.1109/JPROC.2021.3059994
   Ding DD, 2022, IEEE T CYBERNETICS, V52, P1207, DOI 10.1109/TCYB.2020.2998481
   Dong XC, 2022, IEEE T MULTIMEDIA, V24, P400, DOI 10.1109/TMM.2021.3052348
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Gou AR, 2022, IEEE INT SYMP CIRC S, P3028, DOI 10.1109/ISCAS48785.2022.9937635
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Huang YY, 2020, MULTIMED TOOLS APPL, V79, P33957, DOI 10.1007/s11042-020-08882-x
   Imen W, 2022, SIGNAL IMAGE VIDEO P, V16, P1811, DOI 10.1007/s11760-022-02139-w
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim K, 2019, IEEE T CIRC SYST VID, V29, P1462, DOI 10.1109/TCSVT.2018.2839113
   Kuang W, 2020, IEEE T CIRC SYST VID, V30, P1481, DOI 10.1109/TCSVT.2019.2903547
   Kuang W, 2020, IEEE T IMAGE PROCESS, V29, P170, DOI 10.1109/TIP.2019.2924810
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Li YC, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414838
   Liao WH, 2018, SIGNAL PROCESS-IMAGE, V67, P140, DOI 10.1016/j.image.2018.06.003
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Saldanha M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103202
   Shen LQ, 2015, SIGNAL PROCESS-IMAGE, V32, P121, DOI 10.1016/j.image.2015.01.008
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Tech G, 2021, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP42928.2021.9506360
   Wang YJ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11193090
   Wang ZM, 2022, 2022 11TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS (ICCCAS 2022), P237, DOI 10.1109/ICCCAS55266.2022.9825469
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu GQ, 2021, IEEE INT SYMP CIRC S
   Wu SL, 2022, IEEE T CIRC SYST VID, V32, P5638, DOI 10.1109/TCSVT.2022.3146061
   Xu J, 2022, IEEE IMAGE PROC, P2706, DOI 10.1109/ICIP46576.2022.9897378
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yao YB, 2022, MULTIMED TOOLS APPL, V81, P17205, DOI 10.1007/s11042-022-12582-z
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang QW, 2022, DIGIT SIGNAL PROCESS, V127, DOI 10.1016/j.dsp.2022.103539
   Zhang QW, 2021, MULTIMEDIA SYST, V27, P1, DOI 10.1007/s00530-020-00688-z
   Zhang SP, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103621
   Zhang YM, 2019, ACM T STORAGE, V15, DOI 10.1145/3289604
   Zhu L., 2022, ARXIV
NR 52
TC 4
Z9 4
U1 3
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103832
DI 10.1016/j.jvcir.2023.103832
EA MAY 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H7VY2
UT WOS:000998006700001
DA 2024-07-18
ER

PT J
AU Wu, YQ
   Zhang, BH
   Lu, XQ
   Gu, Y
   Wang, YM
   Liu, X
   Ren, Y
   Li, JJ
AF Wu, Yongqiang
   Zhang, Baohua
   Lu, Xiaoqi
   Gu, Yu
   Wang, Yueming
   Liu, Xin
   Ren, Yan
   Li, Jianjun
TI A novel Siamese network object tracking algorithm based on tensor space
   mapping and memory-learning mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Siamese network; Tensor space; Memory -learning
ID VISUAL TRACKING
AB The tracker is a core component of the tracking algorithm, but it is difficult to identify the object, which is a challenge to improve the tracking accuracy. This paper proposes a Siamese network-based tracking algorithm based on tensor space mapping and memory-learning mechanisms. Firstly, the source image is mapped to the tensor space to serialize the feature distributions. Then the gating mechanism is used to extract the association information about the adjacent state, which guides the update of the subsequent state, and the interactive in-formation on the objects is used to locate the object. On this basis, a memory-learning module is built to traverse and extract the fine-grained features, which can filter the semantic information of the object learned by the tracker. As a result, the tracking accuracy is enhanced. The experiments show that the proposed algorithm has better performance than that of the comparison methods in the OTB100 data set and the VOT data set.
C1 [Wu, Yongqiang; Zhang, Baohua; Gu, Yu; Wang, Yueming; Liu, Xin; Ren, Yan; Li, Jianjun] Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Inner Mongolia, Peoples R China.
   [Lu, Xiaoqi] Mongolia Ind Univ, Sch Informat Engn, Hohhot 010051, Inner Mongolia, Peoples R China.
   [Zhang, Baohua; Lu, Xiaoqi; Gu, Yu; Wang, Yueming; Liu, Xin; Li, Jianjun] Inner Mongolia Key Lab Pattern Recognit & Intellig, Baotou 014010, Inner Mongolia, Peoples R China.
C3 Inner Mongolia University of Science & Technology
RP Zhang, BH (corresponding author), Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Inner Mongolia, Peoples R China.; Zhang, BH (corresponding author), Inner Mongolia Key Lab Pattern Recognit & Intellig, Baotou 014010, Inner Mongolia, Peoples R China.
EM zbh_wj2004@imust.edu.cn
RI Wang, Yueming/AAO-3016-2020; lu, xiaoqi/G-3472-2013
OI Wang, Yueming/0000-0002-2059-4315; 
FU National Natural Science Foundation of China [61962046, 62262048,
   62001255, 62066036, 61841204]; Inner Mongolia Outstanding Youth
   Cultivation Fund [2018JQ02]; Inner Mongolia Science and Technology Plan
   Project [2020GG0315, 2021GG0082]; Inner Mongolia Natural Science
   Foundation [2022MS06017, 2019MS06003, 2018MS06018]; Fundamental Research
   Funds for Inner Mongolia University of Science Technology [019, 042];
   Central Government Guides Local Science and Technology Development Fund
   Project of China [2021ZY0004]; Inner Mongolia College Science and
   Technology Research Project [NJZY145]; Chunhui Program of the Ministry
   of Education of the People's Republic of China [1383]
FX The authors thank the anonymous reviewers and editors for the very
   constructive comments. This work was supported by the National Natural
   Science Foundation of China (61962046, 62262048, 62001255, 62066036,
   61841204) . Inner Mongolia Outstanding Youth Cultivation Fund (2018JQ02)
   . Inner Mongolia Science and Technology Plan Project (2020GG0315,
   2021GG0082) . Inner Mongolia Natural Science Foundation (2022MS06017,
   2019MS06003, 2018MS06018) ; Fundamental Research Funds for Inner
   Mongolia University of Science & Technology (019, 042) ; The Central
   Government Guides Local Science and Technology Development Fund Project
   of China (grant number: 2021ZY0004) ; Inner Mongolia College Science and
   Technology Research Project (grant numbers: NJZY145) ; Chunhui Program
   of the Ministry of Education of the People's Republic of China (1383) .
CR [Anonymous], 2014, BMVC, DOI DOI 10.5244/C.28.56
   [Anonymous], 2017, P IEEE INT C COMP VI
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bian Z., 2021, IEEE T CYBERNETICS P, P1
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chang S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081858
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Fan Heng, 2019, CVPR, P5374
   Feng W, 2019, IEEE T IMAGE PROCESS, V28, P3232, DOI 10.1109/TIP.2019.2895411
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Guo Cheng, 2009, Computer Engineering and Applications, V45, P10, DOI 10.3778/j.issn.1002-8331.2009.06.003
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu XH, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422500033
   Huang L., 2019, IEEE T PATTERN ANAL, V2, P5
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Javed S., 2021, arXiv
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kart U, 2018, INT C PATT RECOG, P2112, DOI 10.1109/ICPR.2018.8546179
   Kristan M., 2018, ECCV WORKSHOPS, P0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Maksai A, 2016, Arxiv, DOI arXiv:1612.00604
   [孟琭 Meng Lu], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P1011
   Rahman MM, 2020, IEEE ACCESS, V8, P100857, DOI 10.1109/ACCESS.2020.2997917
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao F, 2021, IEEE T NEUR NET LEAR, V32, P4475, DOI 10.1109/TNNLS.2020.3018025
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
NR 55
TC 3
Z9 3
U1 3
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103742
DI 10.1016/j.jvcir.2022.103742
EA JAN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8O4SD
UT WOS:000925824600001
DA 2024-07-18
ER

PT J
AU Weng, SW
   Hou, TS
   Zhang, TC
   Pan, JS
AF Weng, Shaowei
   Hou, Tanshuai
   Zhang, Tiancong
   Pan, Jeng-Shyang
TI Adaptive smoothness evaluation and multiple asymmetric histogram
   modification for reversible data hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding (RDH); FCM; Multiple features; Asymmetric
   predictor; IDPSO
ID WATERMARKING METHOD; IMAGE; ALGORITHM; EXPANSION; VIDEO
AB In this paper, an adaptive reversible data hiding (RDH) algorithm based on multiple asymmetric histograms is proposed by making full use of the image content. Different from existing multiple prediction error histogram (PEHs) modification methods that directly cluster all the pixels of a cover image into multiple categories, we firstly utilize a smoothness threshold to exclude as many pixels in complex regions as possible for reducing unnecessary pixel shifting, and then exploit fuzzy C-means with multiple deliberately-designed features to construct multiple sharply-distributed categories, which helps in increasing the subsequent embedding performance. Two asymmetric PEHs for each class are generated using a pair of asymmetric predictors, and the short part of each asymmetric PEH is modified to reduce the number of invalid modifications. The improved discrete particle swarm optimization is used to adaptively select the best bin while reducing computational complexity. The experimental results show that the proposed method outperforms several state-of-the-art RDH methods.
C1 [Weng, Shaowei; Hou, Tanshuai; Zhang, Tiancong] Fujian Univ Technol, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350108, Peoples R China.
   [Weng, Shaowei; Hou, Tanshuai; Zhang, Tiancong] Fujian Univ Technol, Sch Elect Elect Engn & Phys, Fuzhou 350108, Peoples R China.
   [Pan, Jeng-Shyang] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
C3 Fujian University of Technology; Fujian University of Technology;
   Shandong University of Science & Technology
RP Zhang, TC (corresponding author), Fujian Univ Technol, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350108, Peoples R China.
EM kushentian@163.com
RI Pan, Jeng-Shyang/AEO-3450-2022; tian'cong, zhang/IQU-9892-2023
OI Pan, Jeng-Shyang/0000-0002-3128-9025; tian'cong,
   zhang/0000-0002-5343-6233
FU National NSF of China; Fujian Science Fund for Distinguished Young
   Scholars, China;  [62262062];  [61872095];  [61571139];  [61872128]; 
   [2020J06043]
FX Acknowledgments This work was supported in part by the National NSF of
   China under Grant 62262062, 61872095, Grant 61571139, Grant 61872128, in
   part by Fujian Science Fund for Distinguished Young Scholars, China
   under Grant 2020J06043.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 1999, KODAK IMAGE DATABASE
   [Anonymous], 1977, USC SIPI IMAGE DATAB
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Boggs P.T., 1995, ACTA NUMER, V4, P1, DOI 10.1017/s0962492900002518
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hou JC, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116118
   Kouhi A, 2022, INFORM SCIENCES, V589, P46, DOI 10.1016/j.ins.2021.12.092
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mao NX, 2022, SIGNAL PROCESS, V198, DOI 10.1016/j.sigpro.2022.108577
   Mustafa A, 2016, Arxiv, DOI arXiv:1606.07378
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qi WF, 2020, IEEE T CIRC SYST VID, V30, P2300, DOI 10.1109/TCSVT.2019.2942489
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weng SW, 2021, INFORM SCIENCES, V549, P13, DOI 10.1016/j.ins.2020.10.063
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Xiong XG, 2022, SIGNAL PROCESS, V194, DOI 10.1016/j.sigpro.2022.108458
   Yang WJ, 2013, J SYST SOFTWARE, V86, P567, DOI 10.1016/j.jss.2012.09.041
   Yu CQ, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108527
   Zhao L, 1999, PATTERN RECOGN, V32, P547, DOI 10.1016/S0031-3203(98)00119-8
NR 44
TC 3
Z9 3
U1 5
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103732
DI 10.1016/j.jvcir.2022.103732
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7S5GP
UT WOS:000910781800001
DA 2024-07-18
ER

PT J
AU Xu, J
   Fu, ZZ
AF Xu, Jin
   Fu, Zhizhong
TI Image compressive sensing via hybrid regularization combining
   centralized group sparse representation and deep denoiser prior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compressive sensing; Hybrid regularization; Centralized group
   sparse representation; Deep denoiser prior
ID RESTORATION; ALGORITHM; NETWORK
AB To effectively solve the ill-posed image compressive sensing (CS) reconstruction problem, it is essential to properly exploit image prior knowledge. In this paper, we propose an efficient hybrid regularization approach for image CS reconstruction, which can simultaneously exploit both internal and external image priors in a unified framework. Specifically, a novel centralized group sparse representation (CGSR) model is designed to more effectively exploit internal image sparsity prior by suppressing the group sparse coding noise (GSCN), i.e., the difference between the group sparse coding coefficients of the observed image and those of the original image. Meanwhile, by taking advantage of the plug-and-play (PnP) image restoration framework, a state-of-the-art deep image denoiser is plugged into the optimization model of image CS reconstruction to implicitly exploit external deep denoiser prior. To make our hybrid internal and external image priors regularized image CS method (named as CGSR-D-CS) tractable and robust, an efficient algorithm based on the split Bregman iteration is developed to solve the optimization problem of CGSR-D-CS. Experimental results demonstrate that our CGSR-D-CS method outperforms some state-of-the-art image CS reconstruction methods (either model-based or deep learning-based methods) in terms of both objective quality and visual perception.
C1 [Xu, Jin; Fu, Zhizhong] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Xu, J (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.
EM jinxu@uestc.edu.cn
OI Xu, Jin/0000-0002-6021-5551
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chang K, 2016, IEEE SIGNAL PROC LET, V23, P449, DOI 10.1109/LSP.2016.2527680
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen G, 2016, J VIS COMMUN IMAGE R, V38, P407, DOI 10.1016/j.jvcir.2016.03.018
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Du J, 2019, NEUROCOMPUTING, V328, P105, DOI 10.1016/j.neucom.2018.04.084
   Eslahi N, 2016, IEEE T IMAGE PROCESS, V25, P3126, DOI 10.1109/TIP.2016.2562563
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Franzen R, 1999, Kodak lossless true color image suite
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Kulkarni K, 2016, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2016.55
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Shi WZ, 2020, IEEE T IMAGE PROCESS, V29, P375, DOI 10.1109/TIP.2019.2928136
   Chien TV, 2017, SIGNAL PROCESS-IMAGE, V54, P93, DOI 10.1016/j.image.2017.02.012
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao HT, 2019, NEUROCOMPUTING, V359, P483, DOI 10.1016/j.neucom.2019.05.006
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zha ZY, 2021, IEEE T IMAGE PROCESS, V30, P5819, DOI 10.1109/TIP.2021.3086049
   Zha ZY, 2021, IEEE T IMAGE PROCESS, V30, P5223, DOI 10.1109/TIP.2021.3078329
   Zha ZY, 2022, IEEE T NEUR NET LEAR, V33, P4451, DOI 10.1109/TNNLS.2021.3057439
   Zha ZY, 2020, IEEE T IMAGE PROCESS, V29, P8960, DOI 10.1109/TIP.2020.3021291
   Zha ZY, 2020, IEEE T IMAGE PROCESS, V29, P5094, DOI 10.1109/TIP.2020.2972109
   Zhang J, 2020, IEEE J-STSP, V14, P765, DOI 10.1109/JSTSP.2020.2977507
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang ZH, 2021, IEEE T IMAGE PROCESS, V30, P1487, DOI 10.1109/TIP.2020.3044472
NR 37
TC 0
Z9 0
U1 3
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103723
DI 10.1016/j.jvcir.2022.103723
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M7DR
UT WOS:000906814200001
DA 2024-07-18
ER

PT J
AU Pehlivan, S
   Laaksonen, J
AF Pehlivan, Selen
   Laaksonen, Jorma
TI Improved action proposals using fine-grained proposal features with
   recurrent attention models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Temporal action proposal generation; Untrimmed video understanding;
   Temporal convolution; Recurrent models; Attention
ID ACTION RECOGNITION
AB Recent models for the temporal action proposal task show that local properties can be an alternative to the region proposal network (RPN) for generating good proposal candidates on untrimmed videos. In this study, we devise an RPN model with a new two-stage pipeline and a new joint scoring function for temporal proposals. The evaluation of local properties is integrated into our RPN model to search for the best proposal candidates that can be distinguished mainly in fine details of proposal regions. Our network models proposals in multiple scales using two recurrent neural network layers with attention mechanisms. We observe that joint training of the RPN with local clues and multi-scale modeling of proposals with recurrent attention mechanisms improve the performance of the proposal generation task. Our model yields state-of-the-art results on the THUMOS-14 and comparable results on the ActivityNet-1.3 datasets.
C1 [Pehlivan, Selen; Laaksonen, Jorma] Aalto Univ, Dept Comp Sci, Espoo, Finland.
C3 Aalto University
RP Pehlivan, S (corresponding author), Aalto Univ, Dept Comp Sci, Espoo, Finland.
EM selen.pehlivantort@aalto.fi
FU Academy of Finland; Aalto University's Aalto Science IT project; CSC-IT
   Center for Science;  [329268];  [345791]
FX This work has been funded by the Academy of Finland through the projects
   "Movie Making Finland: Finnish fiction films as audiovisual big data
   (MoMaF)"(project number 329268) and "Understanding speech and scene with
   ears and eyes (USSEE)"(project number 345791). We also acknowledge the
   computational resources provided by the Aalto University's Aalto Science
   IT project and CSC-IT Center for Science.
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2018, CURR CONTENTS
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eun Hyunjun., 2019, IEEE Transactions on Circuits and Systems for Video Technology
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Girdhar R, 2017, ADV NEUR IN, V30
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He JW, 2018, IEEE WINT CONF APPL, P343, DOI 10.1109/WACV.2018.00044
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Huang JJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P993, DOI 10.1145/3240508.3240659
   Islam A, 2021, AAAI CONF ARTIF INTE, V35, P1637
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li YX, 2020, AAAI CONF ARTIF INTE, V34, P11466
   Lin CRN, 2020, AAAI CONF ARTIF INTE, V34, P11499
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin WY, 2021, Arxiv, DOI arXiv:2005.04490
   Lin Z., 2017, ICLR
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Pramono RRA, 2019, IEEE I CONF COMP VIS, P61, DOI 10.1109/ICCV.2019.00015
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Tan J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13506, DOI 10.1109/ICCV48922.2021.01327
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu M., 2020, PROC IEEE C COMPUTER
   Yueran Bai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P121, DOI 10.1007/978-3-030-58604-1_8
   Yuxi Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P510, DOI 10.1007/978-3-030-58517-4_30
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
NR 64
TC 0
Z9 0
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103709
DI 10.1016/j.jvcir.2022.103709
EA DEC 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5GZ8
UT WOS:000975836500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, ZL
   Lao, LJ
   Zhang, XY
   Li, Y
   Zhang, T
   Cui, Z
AF Wang, Zili
   Lao, Lingjie
   Zhang, Xiaoya
   Li, Yong
   Zhang, Tong
   Cui, Zhen
TI Context-dependent emotion recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Context-based Emotion Recognition; Tubal Transformer; Hierarchical
   Fusion; Affective Computing
AB Most previous methods for emotion recognition focus on facial emotion and ignore the rich context information that implies important emotion states. To make full use of the contextual information to make up for the facial information, we propose the Context-Dependent Net (CD-Net) for robust context-aware human emotion recognition. Inspired by the long-range dependency of the transformer, we introduce the tubal transformer which forms the shared feature representation space to facilitate the interactions among the face, body, and context features. Besides, we introduce the hierarchical feature fusion to recombine the enhanced multi-scale face, body, and context features for emotion classification. Experimentally, we verify the effectiveness of the proposed CD-Net on the two large emotion datasets, CAER-S and EMOTIC. On the one hand, the quantitative evaluation results demonstrate the superiority of the proposed CD-Net over other state-of-the-art methods. On the other hand, the visualization results show CD-Net can capture the dependencies among the face, body, and context components and focus on the important features related to the emotion.
C1 [Wang, Zili; Lao, Lingjie; Zhang, Xiaoya; Li, Yong; Zhang, Tong; Cui, Zhen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
C3 Nanjing University of Science & Technology
RP Li, Y (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
EM yong.li@njust.edu.cn
RI Zhang, tong/IAP-2587-2023; ZHANG, TAO/ITV-6162-2023; zhang,
   tong/JAO-3571-2023
FU National Natural Science Founda-tion of China; Natural Science
   Foundation of Jiangsu Province, China; Shuangchuang Program of Jiangsu
   Province, China;  [62102180];  [BK20210329];  [JSSCBS20210210]
FX Acknowledgment This work was supported by the National Natural Science
   Founda-tion of China (62102180) , the Natural Science Foundation of
   Jiangsu Province, China (BK20210329) , Shuangchuang Program of Jiangsu
   Province, China (JSSCBS20210210) .
CR Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Girard JM, 2017, IEEE INT CONF AUTOMA, P581, DOI 10.1109/FG.2017.144
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Han K, 2022, Arxiv, DOI arXiv:2012.12556
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   Huang JS, 2022, NEUROCOMPUTING, V469, P119, DOI 10.1016/j.neucom.2021.10.049
   Kosti R, 2017, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2017.212
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li YH, 2023, IEEE T PATTERN ANAL, V45, P1489, DOI 10.1109/TPAMI.2022.3164083
   Li Y, 2021, Arxiv, DOI arXiv:2108.04983
   Li Y, 2018, INT C PATT RECOG, P2209, DOI 10.1109/ICPR.2018.8545853
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mehrabian A., 1971, IMPLICIT COMMUNICATI, P43
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Patterson G, 2016, LECT NOTES COMPUT SC, V9910, P85, DOI 10.1007/978-3-319-46466-4_6
   Schindler K, 2008, NEURAL NETWORKS, V21, P1238, DOI 10.1016/j.neunet.2008.05.003
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Thuseethan S, 2022, NEUROCOMPUTING, V492, P174, DOI 10.1016/j.neucom.2022.04.019
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang WH, 2021, Arxiv, DOI arXiv:2102.12122
   Xiao Y, 2022, NEUROCOMPUTING, V470, P29, DOI 10.1016/j.neucom.2021.10.037
   Yan JW, 2018, NEUROCOMPUTING, V309, P27, DOI 10.1016/j.neucom.2018.03.068
   Yang JL, 2017, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2017.554
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yuan K, 2021, Arxiv, DOI [arXiv:2103.11816, DOI 10.48550/ARXIV.2103.11816]
   Zhang MH, 2019, IEEE INT CON MULTI, P151, DOI 10.1109/ICME.2019.00034
   Zhang S., 2019, IEEE Transactions on Affective Computing
   [张醒 Zhang Xing], 2013, [火工品, Initiators & Pyrotechnics], P1
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
NR 43
TC 3
Z9 3
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103679
DI 10.1016/j.jvcir.2022.103679
EA NOV 2022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600009
DA 2024-07-18
ER

PT J
AU Wei, JW
   Sun, HT
   Yang, Y
   Xu, X
   Li, JJ
   Shen, HT
AF Wei, Jiwei
   Sun, Haotian
   Yang, Yang
   Xu, Xing
   Li, Jingjing
   Shen, Heng Tao
TI Semantic guided knowledge graph for large-scale zero-shot learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Large-scale zero-shot learning; Semantic guided knowledge graph;
   Multi-granularity fusion network
AB Zero-shot learning has received growing attention, which aims to improve generalization to unseen concepts. The key challenge in zero-shot tasks is to precisely model the relationship between seen and unseen classes. Most existing zero-shot learning methods capture inter-class relationships via a shared embedding space, leading to inadequate use of relationships and poor performance. Recently, knowledge graph-based methods have emerged as a new trend of zero-shot learning. These methods use a knowledge graph to accurately model the inter-class relationships. However, the currently dominant method for zero-shot learning directly extracts the fixed connection from off-the-shelf WordNet, which will inherit the inherent noise in WordNet. In this paper, we propose a novel method that adopts class-level semantic information as a guidance to construct a new semantic guided knowledge graph (SG-KG), which can correct the errors in the existing knowledge graph and accurately model the inter-class relationships. Specifically, our method includes two main steps: noise suppression and semantic enhancement. Noise suppression is used to eliminate noise edges in the knowledge graph, and semantic enhancement is used to connect two classes with strong relations. To promote high efficient information propagation among classes, we develop a novel multi-granularity fusion network (MGFN) that integrates discriminative information from multiple GCN branches. Extensive experiments on the large-scale ImageNet-21K dataset and AWA2 dataset demonstrate that our method consistently surpasses existing methods and achieves a new state-of-the-art result.
C1 [Yang, Yang] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Peoples R China.
   Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Yang, Y (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Peoples R China.
EM dlyyang@gmail.com
RI Shen, Heng Tao/ABD-5331-2021; Li, Jingjing/T-6522-2019
FU National Natural Science Foundation of China [U20B2063]; Sichuan Science
   and Technology Program, China [2022YFG0032]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China under grant U20B2063, the Sichuan Science
   and Technology Program, China under grant 2022YFG0032.
CR Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   [Anonymous], 2009, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2009.5206848
   Changpinyo S, 2017, IEEE I CONF COMP VIS, P3496, DOI 10.1109/ICCV.2017.376
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen X., 2020, IEEE T MULTIMED
   Huynh D, 2020, PROC CVPR IEEE, P4482, DOI 10.1109/CVPR42600.2020.00454
   Ebisu T, 2020, IEEE T KNOWL DATA EN, V32, P941, DOI 10.1109/TKDE.2019.2893920
   Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gao J., 2020, IEEE T MULTIMED
   Gao JY, 2019, AAAI CONF ARTIF INTE, P8303
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo QY, 2022, IEEE T KNOWL DATA EN, V34, P3549, DOI 10.1109/TKDE.2020.3028705
   Guo YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1774
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jia Z, 2020, IEEE T IMAGE PROCESS, V29, P1958, DOI 10.1109/TIP.2019.2947780
   Jia Z, 2017, IEEE IMAGE PROC, P1287, DOI 10.1109/ICIP.2017.8296489
   Kampffmeyer M, 2019, PROC CVPR IEEE, P11479, DOI 10.1109/CVPR.2019.01175
   Kim J.-H., 2017, INT C LEARNING REPRE
   Kingma D. P., 2014, arXiv
   Kipf TN, 2016, ARXIV
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Le Cacheux Y, 2019, IEEE I CONF COMP VIS, P10332, DOI 10.1109/ICCV.2019.01043
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Li X, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102981
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Li Y., 2021, IEEE T MULTIMED
   Li Y, 2018, AAAI CONF ARTIF INTE, P7049
   Li Y, 2018, PROC CVPR IEEE, P7463, DOI 10.1109/CVPR.2018.00779
   Liu Shaoteng, 2020, P IEEE CVF C COMP VI, P9273
   Long Y, 2017, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2017.653
   Long Y, 2017, IEEE WINT CONF APPL, P944, DOI 10.1109/WACV.2017.110
   Mishra A, 2018, IEEE COMPUT SOC CONF, P2269, DOI 10.1109/CVPRW.2018.00294
   Ni J, 2019, ADV NEUR IN, V32
   Niu L, 2019, IEEE T IMAGE PROCESS, V28, P965, DOI 10.1109/TIP.2018.2872916
   Norouzi M., 2014, P INT C LEARN REPR
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Pitner G, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371899
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Shah H, 2019, AAAI CONF ARTIF INTE, P3044
   Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044
   Shermin T, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108246
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Sohn K, 2015, ADV NEUR IN, V28
   Song Q, 2018, IEEE T KNOWL DATA EN, V30, P1887, DOI 10.1109/TKDE.2018.2807442
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verma VK, 2020, AAAI CONF ARTIF INTE, V34, P6062
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wah Catherine, 2011, Technical report
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Wei J., 2019, P INT DESIGN ENG TEC, P1
   Wei Jiwei, 2020, P IEEE C COMP VIS PA, P13005
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xie GS, 2022, IEEE T NEUR NET LEAR, V33, P2903, DOI 10.1109/TNNLS.2020.3046924
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie YR, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103010
   Zhang CR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1641, DOI 10.1145/3343031.3351000
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111
   Zhu YZ, 2019, IEEE I CONF COMP VIS, P9843, DOI 10.1109/ICCV.2019.00994
NR 68
TC 5
Z9 5
U1 3
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103629
DI 10.1016/j.jvcir.2022.103629
EA SEP 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800002
DA 2024-07-18
ER

PT J
AU Shao, T
   Liu, TQ
   Wu, DP
   Tsai, CY
   Lei, ZJ
   Katsavounidis, I
AF Shao, Tong
   Liu, Tianqi
   Wu, Dapeng
   Tsai, Chia-Yang
   Lei, Zhijun
   Katsavounidis, Ioannis
TI PTR-CNN for in-loop filtering in video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Blocking artifact; In-loop filter; Convolutional neural
   network; Image quality assessment
AB A deep learning method called PTR-CNN (Predicted frame with Transform unit partition and prediction Residual aided CNN) is proposed for in-loop filtering in video compression. To reduce the computational complexity of an end-to-end CNN in-loop filter, a non-learning method of reference frame selection is designed to select the highest quality frame based on the frame's blurriness and smoothiness scores. The transform unit (TU) partition and the prediction residual (PR) of the current frame are used as extra inputs to the neural network as the filtering guidance. The selected similar and high quality reference frame (RF) and the current unfiltered frame (CUF) are input to a CNN based motion compensation module to generate a predicted frame (PF). Finally input the PF, the CUF, the CUF's TU partition and the CUF's PR into the main CNN to reconstruct the filtered frame. The model is implemented in Tensorflow and tested in HEVC and AV1. Experimental results show that the complexity of proposed PTR-CNN is less than SOTA CNN-based reference aided in-loop filtering methods and slightly outperforms their RD performance. The scheme introduces a complexity overhead of 7% on the encoder. In particular, for random access, the proposed model achieves 11.78% coding gain over HEVC with DBF/SAO off, while has a gain of 4.76% over HEVC with DBF/SAO on. Ablation study demonstrates that the RF contributes about 10% of the total gain, and the TU and PR contribute over 4% of the total one, proving the effectiveness of each module. Moreover, it is observed that the proposed method can restore detailed structures and textures and hence improve the subjective quality.
C1 [Shao, Tong; Liu, Tianqi] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
   [Wu, Dapeng] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Tsai, Chia-Yang; Lei, Zhijun; Katsavounidis, Ioannis] Meta, 1101 Dexter Ave N, Seattle, WA 98109 USA.
C3 State University System of Florida; University of Florida; City
   University of Hong Kong
RP Liu, TQ (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM tianqi.liu1@utl.edu
OI Wu, Dapeng/0000-0003-1755-0183; Liu, Tianqi/0000-0002-8617-5236
CR [Anonymous], 2001, Q6SG16 ITUT
   [Anonymous], 2014, HIGH EFFICIENCY VIDE
   Chen JD, 2006, IEEE T AUDIO SPEECH, V14, P1218, DOI 10.1109/TSA.2005.860851
   Chen Y, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.2
   Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Fang RG, 2017, IEEE T CIRC SYST VID, V27, P1381, DOI 10.1109/TCSVT.2016.2539658
   Fu C.-M., 2011, PROC IEEE 13 INT WOR, P1
   Han JN, 2021, Arxiv, DOI arXiv:2008.06091
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang ZJ, 2021, IEEE T IMAGE PROCESS, V30, P5439, DOI 10.1109/TIP.2021.3084345
   Jain V, 2007, IEEE I CONF COMP VIS, P636
   Jia CM, 2019, IEEE T IMAGE PROCESS, V28, P3343, DOI 10.1109/TIP.2019.2896489
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Li TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2921877
   Lu G, 2018, LECT NOTES COMPUT SC, V11218, P591, DOI 10.1007/978-3-030-01264-9_35
   Mukherjee D, 2017, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2017.8296284
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Orfanidis S. J., 1995, Introduction to signal processing
   Pan ZQ, 2020, IEEE T IMAGE PROCESS, V29, P5352, DOI 10.1109/TIP.2020.2982534
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Nguyen T, 2013, IEEE J-STSP, V7, P978, DOI 10.1109/JSTSP.2013.2278071
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Welch G., 1995, INTRO KALMAN FILTER
   Xu XY, 2020, IEEE DATA COMPR CONF, P402, DOI 10.1109/DCC47342.2020.00066
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang R, 2019, IEEE T CIRC SYST VID, V29, P2039, DOI 10.1109/TCSVT.2018.2867568
   Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697
   Yu Y., 2019, IEEE ICC, P1, DOI [DOI 10.1145/3313991.3314015, 10.1109/ICC.2019.8761403, DOI 10.1109/icc.2019.8761403]
   Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3827, DOI 10.1109/TIP.2018.2815841
NR 34
TC 4
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103615
DI 10.1016/j.jvcir.2022.103615
EA SEP 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800004
DA 2024-07-18
ER

PT J
AU Yang, CN
   Wu, XT
   Chung, MJ
   Zhang, XL
AF Yang, Ching-Nung
   Wu, Xiaotian
   Chung, Min-Jung
   Zhang, Xuliang
TI AMBTC-based secret image sharing by simple modular arithmetic
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Secret sharing; Simple modular arithmetic; AMBTC;
   Distortion-free
ID STEGANOGRAPHY; AUTHENTICATION; SCHEME; QUALITY
AB A distortionless secret image sharing scheme using finite field GF(P-G) (P-G is the largest prime less than a given number) is investigated for sharing the absolute moment block truncation coding (AMBTC) images. Two adjusting operations are devised to modify the AMBTC trios (i.e., quantization pixels and bit maps) suitable for GF(P-G) sharing. Polynomials under GF(P-G) are constructed for encrypting the quantization pixels and bit maps. When sharing the trios under GF(P-G), the AMBTC image is perfectly recovered. Moreover, the bit map sharing under GF(P-G) can be extended to GF(P-S) (P-S is the smallest prime larger than a given number). Another scheme using GF(P-S) is constituted by combining quantization pixel sharing under GF(P-G) and bit map sharing under GF(P-S). But the scheme using GF(P-S) is not always lossless. Experimental results show that the proposed schemes are effective. Since GF(P-G) and GF(PS) are simple modular arithmetic, improved computational efficiency is obtained.
C1 [Wu, Xiaotian; Zhang, Xuliang] Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
   [Yang, Ching-Nung; Chung, Min-Jung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Shoufeng Township, Taiwan.
C3 Jinan University; National Dong Hwa University
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
EM wxiaotian@jnu.edu.cn
RI Yang, Ching-Nung/HKV-1639-2023
FU National Natural Science Foundation of China [61972179]; Guangdong Basic
   and Ap-plied Basic Research Foundation, China [2020A1515011476];
   Fundamental Research Funds for the Central Universities, China [MOST
   110-2221-E-259-005-MY2]; Ministry of Science and Technology, Taiwan
FX Acknowledgment This work was partially supported by National Natural
   Science Foundation of China (Grant No. 61972179) , Guangdong Basic and
   Ap-plied Basic Research Foundation, China (Grant No. 2020A1515011476)
   ,Fundamental Research Funds for the Central Universities, China, and
   Ministry of Science and Technology, Taiwan, under Grant MOST
   110-2221-E-259-005-MY2.
CR Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen CC, 2016, J VIS COMMUN IMAGE R, V38, P595, DOI 10.1016/j.jvcir.2016.04.004
   Chen JX, 2021, IEEE T EMERG TOP COM, V9, P2170, DOI 10.1109/TETC.2020.2974183
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P18653, DOI 10.1007/s11042-019-7205-4
   Liu YX, 2021, IEEE T INTELL TRANSP, V22, P3952, DOI 10.1109/TITS.2020.2994386
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Liu YN, 2013, IEEE T COMPUT, V62, P2335, DOI 10.1109/TC.2012.216
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Wu XT, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2020.102452
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Wu XT, 2018, SIGNAL PROCESS-IMAGE, V66, P42, DOI 10.1016/j.image.2018.05.001
   Wu Z, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8030448
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yan XH, 2018, DIGIT SIGNAL PROCESS, V82, P80, DOI 10.1016/j.dsp.2018.07.015
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
NR 31
TC 6
Z9 6
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103482
DI 10.1016/j.jvcir.2022.103482
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PF
UT WOS:000783924700001
DA 2024-07-18
ER

PT J
AU Sharma, S
   Gupta, V
   Juneja, M
AF Sharma, Saurabh
   Gupta, Vishal
   Juneja, Mamta
TI A novel unsupervised multiple feature hashing for image retrieval and
   indexing (MFHIRI)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Image indexing; Multi-view hashing; Approximate nearest
   neighbor search; Feature fusion; Graph theory
AB Recently, techniques that can automatically figure out the incisive information from gigantic visual databases are urging popularity. The existing multi-feature hashing method has achieved good results by fusing multiple features, but in processing these multi-features, fusing multi-features into one feature will cause the feature dimension to be very high, increasing the amount of calculation. On the one hand, it is not easy to discover the internal ties between different features. This paper proposes a novel unsupervised multiple feature hashing for image retrieval and indexing (MFHIRI) method to learn multiple views in a composite manner. The proposed scheme learns the binary codes of various information sources in a composite manner, and our scheme relies on weighted multiple information sources and improved KNN concept. In particular, here we adopt an adaptive weighing scheme to preserve the similarity and consistency among binary codes. Precisely, we follow the graph modeling theory to construct improved KNN concept, which further helps preserve different statistical properties of individual sources. The important aspect of improved KNN scheme is that we can find the neighbors of a data point by searching its neighbors' neighbors. During optimization, the sub-problems are solved in parallel which efficiently lowers down the computation cost. The proposed approach shows consistent performance over state-of-the-art (three single-view and eight multi-view approaches) on three broadly followed datasets viz. CIFAR-10, NUS-WIDE and Caltech-256.
C1 [Sharma, Saurabh] Thapar Inst Engn & Technol, Patiala, Punjab, India.
   [Sharma, Saurabh; Gupta, Vishal; Juneja, Mamta] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Thapar Institute of Engineering & Technology; Panjab University
RP Gupta, V (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM vishal@pu.ac.in
RI Sharma, Saurabh/JFK-3974-2023
FU Ministry of Electronics and IT, Govern-ment of INDIA [PhD-MLA/4 (61)
   /2015-16]
FX The authors thank the reviewers for their helpful comments. First author
   would like to thank Ministry of Electronics and IT, Govern-ment of
   INDIA, for providing fellowship under Grant number: PhD-MLA/4 (61)
   /2015-16 (Visvesvaraya PhD Scheme for Electronics and IT) to pursue his
   Ph.D. work.
CR [Anonymous], 2015, P 27 INT C SCI STAT
   [Anonymous], 2009, NEURIPS
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chen ZX, 2018, PATTERN RECOGN, V75, P149, DOI 10.1016/j.patcog.2017.02.026
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475
   Guttman Antonin., 1984, P 1984 ACM SIGMOD C, P47
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Kim S, 2012, LECT NOTES COMPUT SC, V7576, P538, DOI 10.1007/978-3-642-33715-4_39
   Kim S, 2013, INT CONF ACOUST SPEE, P3123, DOI 10.1109/ICASSP.2013.6638233
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Liu L, 2020, NAT SUSTAIN, V3, P548, DOI 10.1038/s41893-020-0518-5
   Liu W., 2016, P AAAI C ART INT, V30
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu XL, 2014, PATTERN RECOGN, V47, P748, DOI 10.1016/j.patcog.2013.08.022
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Ou MD, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P895, DOI 10.1145/2783258.2783283
   Ravela S, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P278, DOI 10.1145/278459.258589
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sharma S, 2019, ARTIF INTELL REV, V52, P1189, DOI 10.1007/s10462-018-9673-8
   Shen FM, 2019, IEEE T IMAGE PROCESS, V28, P3662, DOI 10.1109/TIP.2019.2899987
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen XB, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178119
   Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342
   Shi XS, 2016, LECT NOTES COMPUT SC, V9911, P419, DOI 10.1007/978-3-319-46478-7_26
   Shrivastava A, 2014, PR MACH LEARN RES, V32
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Wang GA, 2018, LECT NOTES COMPUT SC, V11219, P491, DOI 10.1007/978-3-030-01267-0_29
   Wang J., 2014, CoRR
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   WEISS Y, 2008, ADV NEURAL INFORM PR, V21, P1753
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiang LY, 2019, NEURAL PROCESS LETT, V49, P1055, DOI 10.1007/s11063-018-9892-7
   Xu Y, 2017, NEUROCOMPUTING, V229, P45, DOI 10.1016/j.neucom.2016.05.109
   Yang R, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P180, DOI 10.1145/3078971.3078981
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang X, 2012, PROC CVPR IEEE, P2058, DOI 10.1109/CVPR.2012.6247910
   Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335
   Zhang Z, 2019, IEEE T IMAGE PROCESS, V28, P4803, DOI 10.1109/TIP.2019.2912290
   Zhu L, 2020, IEEE T IMAGE PROCESS, V29, P4643, DOI 10.1109/TIP.2020.2974065
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu XF, 2021, IEEE T KNOWL DATA EN, V33, P2425, DOI 10.1109/TKDE.2019.2956530
   Zhu XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107175
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
NR 55
TC 2
Z9 2
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103467
DI 10.1016/j.jvcir.2022.103467
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PF
UT WOS:000783924700004
DA 2024-07-18
ER

PT J
AU Liang, SL
   Meng, XZ
   Su, Z
   Zhou, F
AF Liang, Songliang
   Meng, Xiaozhe
   Su, Zhuo
   Zhou, Fan
TI Multi-receptive Field Aggregation Network for single image deraining
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deraining; Dilated convolution; Attention mechanism
ID RAIN STREAKS; MODEL
AB Image deraining is a significant problem that ensures the visual quality of images to prompt computer vision systems. However, due to the insufficiency of captured rain streaks features and global information, current image deraining methods often face the issues of rain streaks remaining and image blurring. In this paper, we propose a Multi-receptive Field Aggregation Network (MRFAN) to restore a cleaner rain-free image. Specifically, we construct a Multi-receptive Field Feature Extraction Block (MFEB) to capture rain features with different receptive fields. In MFEB, we design a Self-supervised Block (SSB) and an Aggregation Block (AGB). SSB can make the network adaptively focus on the critical rain features and rain-covered areas. AGB effectively aggregates and redistributes the multi-scale features to help the network simulate rain streaks better. Experiments show that our method achieves better results on both synthetic datasets and real-world rainy images.
C1 [Liang, Songliang; Meng, Xiaozhe; Su, Zhuo; Zhou, Fan] Sun Yat Sen Univ, Sch Comp Sci & Engn, Res Inst, Yat Sen Univ Shenzhen, Guangzhou, Peoples R China.
C3 Sun Yat Sen University
RP Su, Z (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Res Inst, Yat Sen Univ Shenzhen, Guangzhou, Peoples R China.
EM suzhuo3@mail.sysu.edu.cn
RI Meng, Xiaozhe/GPX-2128-2022; Su, Zhuo/AAO-4506-2020; Zhou,
   fan/KIL-4066-2024
OI Su, Zhuo/0000-0002-6090-0110; 
FU Shenzhen Science and Technology Program [JCYJ20200109142612234];
   Guangdong Basic and Applied Basic Research Foundation [2021A1515012313]
FX Acknowledgement This research is supported by the Shenzhen Science and
   Technology Program (No. JCYJ20200109142612234) , and the Guangdong Basic
   and Applied Basic Research Foundation (No. 2021A1515012313) .
CR Chang Y, 2017, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2017.191
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Du SL, 2018, PATTERN RECOGN, V79, P303, DOI 10.1016/j.patcog.2018.02.016
   Fu XY, 2021, AAAI CONF ARTIF INTE, V35, P1352
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Guo BY, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102851
   Hu XW, 2019, PROC CVPR IEEE, P8014, DOI 10.1109/CVPR.2019.00821
   Jin X, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107143
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Li RT, 2019, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2019.00173
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li YW, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103149
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liang X, 2019, COMPUT GRAPH FORUM, V38, P159, DOI 10.1111/cgf.13825
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Sharma PK, 2019, IEEE IMAGE PROC, P2796, DOI [10.1109/icip.2019.8803353, 10.1109/ICIP.2019.8803353]
   Sun, 2017, ARXIV PREPRINT ARXIV
   Tang QF, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103039
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1643, DOI 10.1145/3394171.3413820
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2517, DOI 10.1145/3394171.3413559
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wang Z., 2020, ARXIV200712061
   Wei W, 2019, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2019.00400
   Wei Y., 2021, P IEEE INT C MULT EX, P1, DOI DOI 10.1109/ICME51207.2021.9428285
   Wei YY, 2021, IEEE T IMAGE PROCESS, V30, P4788, DOI 10.1109/TIP.2021.3074804
   Wei YY, 2019, IEEE DATA MINING, P628, DOI 10.1109/ICDM.2019.00073
   Xu W, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103133
   Yang WH, 2021, IEEE T PATTERN ANAL, V43, P4059, DOI 10.1109/TPAMI.2020.2995190
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yang YZ, 2019, IEEE INT CON MULTI, P1378, DOI 10.1109/ICME.2019.00239
   Yasarla R, 2020, PROC CVPR IEEE, P2723, DOI 10.1109/CVPR42600.2020.00280
   Yinglong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P367, DOI 10.1007/978-3-030-58520-4_22
   Zamir S.W., 2021, PROC CVPR IEEE, DOI DOI 10.1109/CVPR46437.2021.01458
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang Y., 2021, IEEE T CLOUD COMPUT, V99, P1, DOI [10.1109/TCC.2019.2923222, DOI 10.1109/TCC.2019.2923222]
   Zhang Z., 2021, PREPRINTS
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 42
TC 3
Z9 3
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103469
DI 10.1016/j.jvcir.2022.103469
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7YP
UT WOS:000779631900004
DA 2024-07-18
ER

PT J
AU Yuan, D
   Shu, X
   Fan, NN
   Chang, XJ
   Liu, Q
   He, ZY
AF Yuan, Di
   Shu, Xiu
   Fan, Nana
   Chang, Xiaojun
   Liu, Qiao
   He, Zhenyu
TI Accurate bounding-box regression with distance-IoU loss for visual
   tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Bounding-box regression; Distance-IoU loss
ID OBJECT; SIMILARITY; NETWORK; FLOWS
AB Most existing trackers are based on using a classifier and multi-scale estimation to estimate the target state. Consequently, and as expected, trackers have become more stable while tracking accuracy has stagnated. While trackers adopt a maximum overlap method based on an intersection-over-union (IoU) loss to mitigate this problem, there are defects in the IoU loss itself, that make it impossible to continue to optimize the objective function when a given bounding box is completely contained within/without another bounding box; this makes it very challenging to accurately estimate the target state. Accordingly, in this paper, we address the above-mentioned problem by proposing a novel tracking method based on a distance-IoU (DIoU) loss, such that the proposed tracker consists of target estimation and target classification. The target estimation part is trained to predict the DIoU score between the target ground-truth bounding-box and the estimated bounding-box. The DIoU loss can maintain the advantage provided by the IoU loss while minimizing the distance between the center points of two bounding boxes, thereby making the target estimation more accurate. Moreover, we introduce a classification part that is trained online and optimized with a Conjugate-Gradient based strategy to guarantee real-time tracking speed. Comprehensive experimental results demonstrate that the proposed method achieves competitive tracking accuracy when compared to state-of-the-art trackers while with a real-time tracking speed.
C1 [Yuan, Di] Xidian Univ, Guangzhou Inst Technol, Guangzhou 510555, Peoples R China.
   [Shu, Xiu] Harbin Inst Technol, Sch Sci, Shenzhen 518055, Peoples R China.
   [Yuan, Di; Fan, Nana; Liu, Qiao; He, Zhenyu] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen 518055, Peoples R China.
   [Chang, Xiaojun] RMIT Univ, Sch Comp Technol, Melbourne, Vic 3046, Australia.
   [Liu, Qiao] Chongqing Normal Univ, Natl Ctr Appl Math, Chongqing 401331, Peoples R China.
C3 Xidian University; Harbin Institute of Technology; Harbin Institute of
   Technology; Royal Melbourne Institute of Technology (RMIT); Chongqing
   Normal University
RP Yuan, D (corresponding author), Xidian Univ, Guangzhou Inst Technol, Guangzhou 510555, Peoples R China.
EM dyuanhit@gmail.com
RI Shu, Xiu/HNP-8892-2023; Chang, Xiaojun/A-2055-2015; Yuan, Di/Q-6521-2019
OI Chang, Xiaojun/0000-0002-7778-8807; Yuan, Di/0000-0001-9403-1112
FU National Natural Science Foun-dation of China [62172126]; Special
   Research project on COVID-19 Prevention and Control of Guangdong
   Province, China [2020KZDZDX1227]; Shenzhen Research Council, China
   [JCYJ20210324120202006]; China Scholarship Council [DE190100626];
   Australian Research Council (ARC) Discovery Early Career Researcher
   Award (DECRA)
FX Acknowledgment This research was supported by the National Natural
   Science Foun-dation of China (Grant No. 62172126) , by the Special
   Research project on COVID-19 Prevention and Control of Guangdong
   Province, China (Grant No. 2020KZDZDX1227) , by the Shenzhen Research
   Council, China (Grant No. JCYJ20210324120202006) . Dr Di Yuan was
   sup-ported by a scholarship from China Scholarship Council. Dr Xiaojun
   Chang was partially supported by Australian Research Council (ARC)
   Discovery Early Career Researcher Award (DECRA) under grant no.
   DE190100626.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   CHEN Z, 2020, IEEECVF C COMPUT VIS, P6668
   Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Dong X., 2020, ECCV
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jung I., 2018, P ECCV, P83
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M., 2019, ICCV WORKSH
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Lan L, 2020, INT J COMPUT VISION, V128, P1937, DOI 10.1007/s11263-020-01314-1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li CY, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102737
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li Y, 2019, AAAI CONF ARTIF INTE, P8666
   Li ZY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103107
   Liao JW, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102896
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Q, 2021, IEEE T MULTIMEDIA, V23, P2114, DOI 10.1109/TMM.2020.3008028
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Park E, 2018, LECT NOTES COMPUT SC, V11207, P587, DOI 10.1007/978-3-030-01219-9_35
   Pu S., 2018, ADV NEURAL INFORM PR, V31, P1931, DOI DOI 10.1016/J.PATCOG.2018.10.005
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shu X, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108293
   Shu X, 2021, NEUROCOMPUTING, V453, P438, DOI 10.1016/j.neucom.2021.01.081
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Yuan D., 2021, ACM T MULTIM COMPUT
   Yuan D., 2021, ARXIV PREPRINT ARXIV
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Yuan D, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102882
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105554
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P14277, DOI 10.1007/s11042-018-6800-0
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang MK, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103082
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P455, DOI 10.1007/978-3-030-58610-2_27
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 74
TC 18
Z9 18
U1 9
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103428
DI 10.1016/j.jvcir.2021.103428
EA JAN 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, LP
   Wei, H
AF Wang, Luping
   Wei, Hui
TI Indoor scene understanding based on manhattan and non-manhattan
   projection of spatial right-angles
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-manhattan; Ceiling; Indoor scene; Spatial right-angle; Monocular
   vision
ID MOTION
AB Understanding of indoor scenes has considerable value in computer vision. Most previous methods infer indoor scenes via manhattan assumption. However, attic ceilings do not satisfy manhattan assumption and understanding them remains a big challenge. Non-manhattan ceilings can be seen as compositions of spatial right-angles projections. In this paper, we presented a method to understand indoor scenes including both manhattan structures and non-manhattan attic ceilings from a single image. First, angle projections are detected and assigned to different clusters. Then vanishing points of attic ceilings can be estimated. Third, it is possible to determine the attic ceilings of non-manhattan surfaces. The proposed approach requires no prior training. We compared the estimated attic layout against the ground truth and measured the percentage of pixels that were incorrectly classified. Experimental results showed that the method can understand indoor scenes including both manhattan and non-manhattan attic ceilings, meeting the requirements of robot navigation.
C1 [Wang, Luping] Univ Shanghai Sci & Technol, Sch Mech Engn, Lab 3D Scene Understanding & Visual Nav, Shanghai 200093, Peoples R China.
   [Wei, Hui] Fudan Univ, Sch Comp Sci, Lab Algorithms Cognit Models, Shanghai 201203, Peoples R China.
C3 University of Shanghai for Science & Technology; Fudan University
RP Wang, LP (corresponding author), Univ Shanghai Sci & Technol, Sch Mech Engn, Lab 3D Scene Understanding & Visual Nav, Shanghai 200093, Peoples R China.
EM 15110240007@fudan.edu.cn
RI Wei, Hui/K-5819-2019; Wang, Luping/AAZ-4035-2021
OI Wang, Luping/0000-0002-2417-4561; Wei, Hui/0000-0003-2696-0707
FU NSFC Project [62003212, 61771146, 61375122]
FX This work was supported by the NSFC Project (Project Nos. 62003212,
   61771146 and 61375122) .
CR [Anonymous], 2018, PROC ASIAN C COMPUT
   [Anonymous], 2010, NIPS
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Atapour-Abarghouei Atapour-Abarghouei A. A., 2019, P IEEE CVF C COMP VI, P3373
   Choi W, 2015, INT J COMPUT VISION, V112, P204, DOI 10.1007/s11263-014-0779-4
   Dasgupta S, 2016, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2016.73
   Del Pero L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2009, DOI 10.1109/CVPR.2011.5995737
   Del Pero L, 2013, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2013.27
   Del Pero L, 2012, PROC CVPR IEEE, P2719, DOI 10.1109/CVPR.2012.6247994
   Delage Erick, 2006, 2006 IEEE COMP SOC C, P2418
   GIBSON EJ, 1960, SCI AM, V202, P64, DOI 10.1038/scientificamerican0460-64
   HE ZJ, 1995, P NATL ACAD SCI USA, V92, P11155, DOI 10.1073/pnas.92.24.11155
   Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Jia ZY, 2013, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2013.8
   Koenderink JJ, 1996, PERCEPT PSYCHOPHYS, V58, P163, DOI 10.3758/BF03211873
   Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872
   Lee JK, 2019, INT J COMPUT VISION, V127, P1426, DOI 10.1007/s11263-019-01196-y
   Li J, 2019, COMPUT VIS IMAGE UND, V186, P25, DOI 10.1016/j.cviu.2019.06.002
   Li RH, 2018, COGN COMPUT, V10, P875, DOI 10.1007/s12559-018-9591-8
   Li SP, 2019, ROBOT AUTON SYST, V112, P201, DOI 10.1016/j.robot.2018.11.009
   Li XT, 2019, PROC CVPR IEEE, P12360, DOI 10.1109/CVPR.2019.01265
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Magerand L, 2020, IEEE T PATTERN ANAL, V42, P430, DOI 10.1109/TPAMI.2018.2849973
   Mallya A, 2015, IEEE I CONF COMP VIS, P936, DOI 10.1109/ICCV.2015.113
   Miraldo P, 2018, PROC CVPR IEEE, P2012, DOI 10.1109/CVPR.2018.00215
   Mohamed H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010127
   Ren YZ, 2017, LECT NOTES COMPUT SC, V10115, P36, DOI 10.1007/978-3-319-54193-8_3
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853
   Saxena A, 2008, P 23 NAT C ART INT, V3, P1571
   Straub J, 2018, IEEE T PATTERN ANAL, V40, P235, DOI 10.1109/TPAMI.2017.2662686
   Sun K, 2019, INFORM SCIENCES, V479, P101, DOI 10.1016/j.ins.2018.11.055
   Wang C, 2018, INT CONF 3D VISION, P533, DOI 10.1109/3DV.2018.00067
   Wang L., IEEE T ARTIF INTELL, V1
   Wang LP, 2022, IEEE T INTELL TRANSP, V23, P8544, DOI 10.1109/TITS.2021.3083572
   Wang LP, 2020, IEEE T IMAGE PROCESS, V29, P9345, DOI 10.1109/TIP.2020.3026628
   Wang LP, 2020, IEEE-CAA J AUTOMATIC, V7, P1190, DOI 10.1109/JAS.2020.1003117
   Wang LP, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103569
   Wei H, 2018, PATTERN RECOGN, V81, P497, DOI 10.1016/j.patcog.2018.04.017
   Wei H, 2018, IEEE T IMAGE PROCESS, V27, P3164, DOI 10.1109/TIP.2018.2818931
   Wei Y, 2019, NEURAL PROCESS LETT, V49, P1007, DOI 10.1007/s11063-018-9861-1
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yu F., 2016, ARXIV150603365
   Zhai MH, 2016, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2016.610
   Zhang PB, 2019, IET COMPUT VIS, V13, P267, DOI 10.1049/iet-cvi.2018.5365
   Zhao YB, 2013, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2013.401
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zou CH, 2018, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2018.00219
NR 49
TC 3
Z9 3
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103307
DI 10.1016/j.jvcir.2021.103307
EA SEP 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900014
DA 2024-07-18
ER

PT J
AU Zhong, X
   Nie, GZ
   Huang, WX
   Liu, WX
   Ma, B
   Lin, CW
AF Zhong, Xian
   Nie, Guozhang
   Huang, Wenxin
   Liu, Wenxuan
   Ma, Bo
   Lin, Chia-Wen
TI Attention-guided image captioning with adaptive global and local feature
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image captioning; Encoder-decoder; Spatial information; Adaptive
   attention
AB Although attention mechanisms are exploited widely in encoder-decoder neural network-based image captioning framework, the relation between the selection of salient image regions and the supervision of spatial information on local and global representation learning was overlooked, thereby degrading captioning performance. Consequently, we propose an image captioning scheme based on adaptive spatial information attention (ASIA), extracting a sequence of spatial information of salient objects in a local image region or an entire image. Specifically, in the encoding stage, we extract the object-level visual features of salient objects and their spatial bounding-box. We obtain the global feature maps of an entire image, which are fused with local features and the fused features are fed into the LSTM-based language decoder. In the decoding stage, our adaptive attention mechanism dynamically selects the corresponding image regions specified by an image description. Extensive experiments conducted on two datasets demonstrate the effectiveness of the proposed method.
C1 [Zhong, Xian; Nie, Guozhang; Liu, Wenxuan] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Huang, Wenxin] Hubei Univ, Sch Comp Sci & Informat Engn, Wuhan, Hubei, Peoples R China.
   [Ma, Bo] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
   [Lin, Chia-Wen] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu, Taiwan.
   [Lin, Chia-Wen] Natl Tsing Hua Univ, Inst Commun Engn, Hsinchu, Taiwan.
C3 Wuhan University of Technology; Hubei University; State University
   System of Florida; University of Florida; National Tsing Hua University;
   National Tsing Hua University
RP Huang, WX (corresponding author), Hubei Univ, Sch Comp Sci & Informat Engn, Wuhan, Hubei, Peoples R China.
EM wenxin.huang@whu.edu.cn
RI Lin, Chia-Wen/ABH-6075-2020; Huang, Wenxin/AFN-5558-2022; Lin,
   Chia-Wen/M-4571-2013
OI Zhong, Xian/0000-0002-5242-0467
FU Fundamental Research Funds for the Central Universities of China
   [191010001]; Hubei Key Laboratory of Transportation Internet of Things
   [2018IOT003, 2020III026GX]; Ministry of Science and Technology, Taiwan
   [MOST 109-2634-F-007-013]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities of China under Grant 191010001, in part by the
   Hubei Key Laboratory of Transportation Internet of Things under Grant
   2018IOT003 and Grant 2020III026GX, and in part by the Ministry of
   Science and Technology, Taiwan, under Grant MOST 109-2634-F-007-013.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], N AM CHAPTER ASS COM
   Chen H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P606
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Dong J., 2020, P IEEE INT C MULT EX, P1
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang WH, 2018, AAAI CONF ARTIF INTE, P6959
   Jiansheng Dong, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P548, DOI 10.1145/3372278.3390714
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lavie A., 2007, P 2 WORKSH STAT MACH, P228
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z., 2012, P ACM INT C MULTIMED, P199
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mun J, 2017, AAAI CONF ARTIF INTE, P4233
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, P2506, DOI 10.1109/ICCV.2017.272
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang Y, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P433, DOI 10.1145/3126686.3126714
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415
   Zhong X, 2019, PROC INT C TOOLS ART, P1245, DOI 10.1109/ICTAI.2019.00-94
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
NR 46
TC 9
Z9 11
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103138
DI 10.1016/j.jvcir.2021.103138
EA JUN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1MD
UT WOS:000674618200002
DA 2024-07-18
ER

PT J
AU Khan, R
   Yang, Y
   Liu, Q
   Qaisar, ZH
AF Khan, Rizwan
   Yang, You
   Liu, Qiong
   Qaisar, Zahid Hussain
TI A ghostfree contrast enhancement method for multiview images without
   depth information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view low-light images; Feature matching; Exposure fusion
ID FUSION
AB High dynamic range (HDR) images greatly improve visual content quality, but pose challenges in processing, acquisition, and display. Images captured in real-world scenarios with multiple nonlinear cameras, extremely short unknown exposure time, and a shared light source present the additional challenges of incremental baseline and angle deviation amongst the cameras. The disparity maps in such conditions are not reliable; therefore, we propose a method that relies on the accurate detection and matching of feature points across adjacent viewpoints. We determine the exposure gain among the matched feature points in the involved views and design an image restoration method to restore multiview low dynamic range (MVLDR) images for each viewpoint. Finally, the fusion of these restored MVLDR images produces high-quality images for each viewpoint without capturing a series of bracketed exposure. Extensive experiments are conducted in controlled and uncontrolled conditions, and results prove that the proposed method competes for the state-of-the-arts.
C1 [Khan, Rizwan; Yang, You; Liu, Qiong] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 4370074, Peoples R China.
   [Khan, Rizwan; Yang, You; Liu, Qiong] Wuhan Natl Lab Optoelect, Wuhan 4370074, Peoples R China.
   [Qaisar, Zahid Hussain] NFC Inst Engn & Technol, Dept Comp Sci, Multan, Pakistan.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Liu, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 4370074, Peoples R China.
EM rizvankhan@hust.edu.cn; q.liu@hust.edu.cn
RI Khan, Rizwan Hasan/F-8276-2014; Khan, Dr Rizwan/JQW-7885-2023
OI Khan, Rizwan Hasan/0000-0002-9965-8982; 
FU National Key Research and Development Program of China [2020YFB2103501];
   National Natural Science Foundation of China [61971203]; Wuhan Science
   and Technology Bureau [2020020601012222]; Fundamental Research Funds for
   the Central Universities, China [HUST 2020JYCXJJ062]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFB2103501, in part by the
   National Natural Science Foundation of China under Grant 61971203, in
   part by the Wuhan Science and Technology Bureau under Grant
   2020020601012222, and in part by the Fundamental Research Funds for the
   Central Universities, China under Grant HUST 2020JYCXJJ062.
CR [Anonymous], 2018, BRIT MACH VIS C
   Ashikhmin M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P145
   Bilcu Radu Ciprian, 2008, 2008 15th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2008), P1312, DOI 10.1109/ICECS.2008.4675101
   Bonnard J, 2012, PROC SPIE, V8436, DOI 10.1117/12.922789
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chiang JC, 2017, CIRC SYST SIGNAL PR, V36, P2786, DOI 10.1007/s00034-016-0437-x
   Debevec P.E., 2008, Recovering High Dynamic Range Radiance Maps from Photographs, P31
   Eilertsen G., 2016, High Dynamic Range Video, P185
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Guo HQ, 2017, J OPT SOC AM A, V34, P1961, DOI 10.1364/JOSAA.34.001961
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kou F, 2017, IEEE INT CON MULTI, P1105, DOI 10.1109/ICME.2017.8019529
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Li ZH, 2018, IEEE T IMAGE PROCESS, V27, P976, DOI 10.1109/TIP.2017.2771142
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Muijs R.T.J., 2015, US Patent, Patent No. [9,098,906, 9098906]
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   OMalley S.M., 2006, 4 IEEE INT C COMP CO P 4 IEEE INT C COMP, P15
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Reinhard E, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366220
   Ren X., 2018, P IEEE INT S CIRC SY, P1, DOI [10.1109/IS CAS.2018.8351427., DOI 10.1109/ISCAS.2018.8351427]
   Troccoli A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P861
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu S., EUR C COMP VIS ECCV EUR C COMP VIS ECCV
   Wu XL, 2011, IEEE T IMAGE PROCESS, V20, P1262, DOI 10.1109/TIP.2010.2092438
   Yan J., 2019, ARXIV PREPRINT ARXIV
   Zhang XY, 2017, J OPT SOC AM A, V34, P1400, DOI 10.1364/JOSAA.34.001400
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
NR 38
TC 5
Z9 6
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103175
DI 10.1016/j.jvcir.2021.103175
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500003
DA 2024-07-18
ER

PT J
AU Suneetha, M
   Prasad, MVD
   Kishore, PVV
AF Suneetha, M.
   Prasad, M. V. D.
   Kishore, P. V. V.
TI Multi-view motion modelled deep attention networks (M2DA-Net) for video
   based sign language recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi view; Sign language recognition; Deep learning; Attention models;
   Motion modelled
ID FEATURES; ALGORITHMS; CNN
AB Currently, video-based Sign language recognition (SLR) has been extensively studied using deep learning models such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs). In addition, using multi view attention mechanism along with CNNs could be an appealing solution that can be considered in order to make the machine interpretation process immune to finger self-occlusions. The proposed multi stream CNN mixes spatial and motion modelled video sequences to create a low dimensional feature vector at multiple stages in the CNN pipeline. Hence, we solve the view invariance problem into a video classification problem using attention model CNNs. For superior network performance during training, the signs are learned through a motion attention network thus focusing on the parts that play a major role in generating a view based paired pooling using a trainable view pair pooling network (VPPN). The VPPN, pairs views to produce a maximally distributed discriminating features from all the views for an improved sign recognition. The results showed an increase in recognition accuracies on 2D video sign language datasets. Similar results were obtained on benchmark action datasets such as NTU RGB D, MuHAVi, WEIZMANN and NUMA as there is no multi view sign language dataset except ours.
C1 [Suneetha, M.; Prasad, M. V. D.; Kishore, P. V. V.] Koneru Lakshmaiah Educ Fdn, Dept ECE, Biomech & Vis Comp Res Ctr, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kishore, PVV (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept ECE, Biomech & Vis Comp Res Ctr, Vaddeswaram, Andhra Pradesh, India.
EM pvvkishore@kluniversity.in
RI , MVD Prasad/U-6732-2018; Kishore, P.V.V./R-3293-2017
OI , MVD Prasad/0000-0003-2410-1175; Kishore, P.V.V./0000-0002-3247-3043
CR Achmed I., 2014, THESIS U WESTER CAPE THESIS U WESTER CAPE
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahmad T, 2020, IEEE ACCESS, V8, P305, DOI 10.1109/ACCESS.2019.2961770
   Ahmed MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072208
   AL-Rousan M, 2009, APPL SOFT COMPUT, V9, P990, DOI 10.1016/j.asoc.2009.01.002
   Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Dabre K, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P317, DOI 10.1109/CSCITA.2014.6839279
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Efthymiou N, 2018, IEEE IMAGE PROC, P455, DOI 10.1109/ICIP.2018.8451146
   Elons AS, 2013, APPL SOFT COMPUT, V13, P1646, DOI 10.1016/j.asoc.2012.11.036
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Fathi A., 2008, 2008 IEEE C COMPUTER, P1
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gao Z, 2017, MULTIMED TOOLS APPL, V76, P20125, DOI 10.1007/s11042-017-4384-8
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Iosifidis A, 2013, SIGNAL PROCESS, V93, P1445, DOI 10.1016/j.sigpro.2012.08.015
   Ji XF, 2016, MULTIMED TOOLS APPL, V75, P11847, DOI 10.1007/s11042-015-2661-y
   Ji YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P574, DOI 10.1145/3343031.3350959
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kishore P., 2019, INT J INNOV TECHNOL, V8, P765
   Kishore PVV, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P34, DOI 10.1109/SPACES.2015.7058288
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364
   Koller Oscar., 2016, P BMVC, P1, DOI 10.5244/C.30.136
   Kumar DA, 2019, IEEE SIGNAL PROC LET, V26, P169, DOI 10.1109/LSP.2018.2883864
   Kumar EK, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2018.2817179
   Kumar EK, 2018, IEEE SIGNAL PROC LET, V25, P1860, DOI 10.1109/LSP.2018.2877891
   Kwon B, 2017, IEEE ACCESS, V5, P12496, DOI 10.1109/ACCESS.2017.2723039
   Li Y, 2010, IEEE IFIP NETW OPER, P17, DOI 10.1109/NOMS.2010.5488428
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Plyer A, 2016, J REAL-TIME IMAGE PR, V11, P713, DOI 10.1007/s11554-014-0423-0
   Rao G. A., 2017, Far East Journal of Electronics and Communications, V17, P49, DOI [10.17654/EC017010049, DOI 10.17654/EC017010049]
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rao GA, 2018, J ENG SCI TECHNOL, V13, P2352
   Rao GA, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P194, DOI 10.1109/SPACES.2018.8316344
   Ravi S, 2019, J COMPUT LANG, V52, P88, DOI 10.1016/j.cola.2019.04.002
   Ravi S, 2018, TURK J ELECTR ENG CO, V26, P2871, DOI 10.3906/elk-1711-139
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shivashankara S, 2017, INT CONF COMM SYST, P293, DOI [10.1109/CSNT.2017.8418554, 10.1109/CSNT.2017.58]
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Suharjito, 2017, PROCEDIA COMPUT SCI, V116, P441, DOI 10.1016/j.procs.2017.10.028
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Wang DG, 2018, LECT NOTES COMPUT SC, V11213, P457, DOI 10.1007/978-3-030-01240-3_28
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang Q, 2007, COMPUT VIS IMAGE UND, V108, P87, DOI 10.1016/j.cviu.2006.11.009
   Wei W., 2019, PATTERN RECOGN LETT, V119, P131, DOI DOI 10.1016/j.patrec.2017.12.005
   Wei WT, 2019, IEEE T BIO-MED ENG, V66, P2964, DOI 10.1109/TBME.2019.2899222
   Xue F, 2019, IET COMPUT VIS, V13, P708, DOI 10.1049/iet-cvi.2018.5830
   Yan Y, 2013, IEEE IMAGE PROC, P2837
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Zare A, 2020, PATTERN ANAL APPL, V23, P265, DOI 10.1007/s10044-019-00788-1
   Zhang Liang-Guo., 2004, Proceedings of the 6th international conference on Multimodal interfaces, ICMI '04, P198, DOI DOI 10.1145/1027933.1027967
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhu F, 2013, PATTERN RECOGN LETT, V34, P20, DOI 10.1016/j.patrec.2012.04.016
   Zhu JG, 2019, IEEE SIGNAL PROC LET, V26, P1633, DOI 10.1109/LSP.2019.2942739
   Zhu K., 2019, IEEE T MULTIMED
   Zhu SG, 2019, J VIS COMMUN IMAGE R, V60, P38, DOI 10.1016/j.jvcir.2018.12.026
   Zhu Y., 2019, VISUAL COMPUT, V36, P1
NR 67
TC 9
Z9 9
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103161
DI 10.1016/j.jvcir.2021.103161
EA MAY 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200007
DA 2024-07-18
ER

PT J
AU Li, J
   Huang, L
   Wei, ZQ
   Zhang, WF
   Qin, QB
AF Li, Jie
   Huang, Lei
   Wei, Zhiqiang
   Zhang, Wenfeng
   Qin, Qibing
TI Multi-task learning with deformable convolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-task learning; Deformable convolution; Recognition
AB Multi-task learning aims to tackle various tasks with branched feature sharing architectures. Considering its diversity and complexity, discriminative feature representations need to be extracted for each individual task. Fixed geometric structures as a limitation of convolutional neural networks (CNNs) in building models, is also exists and poses a severe challenge in multi-task learning since the geometric variations will augment when we deal with multiple tasks. In this paper, we go beyond these limitations and propose a novel multi-task network by introducing the deformable convolution. Our design, the Deformable Multi-Task Network (DMTN), starts with a single shared network for constructing a shared feature pool. Then, we present task-specific deformable modules to extract discriminative features to be tailored for each task from the shared feature pool. The task-specific deformable modules utilize two new parts, deformable part and alignment part, to extract more discriminative task-specific features while greatly enhancing the transformation modeling capability. Experiments conducted on various multi-task learning types demonstrate the effectiveness of the proposed method. On multiple classification tasks, semantic segmentation and depth estimation tasks, our DMTN exceeds state-of-the-art approaches against strong baselines.
C1 [Li, Jie; Huang, Lei; Wei, Zhiqiang; Zhang, Wenfeng; Qin, Qibing] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266000, Peoples R China.
   [Huang, Lei; Wei, Zhiqiang] Pilot Natl Lab Marine Sci & Technol Qingdao, Qingdao 266000, Peoples R China.
C3 Ocean University of China; Laoshan Laboratory
RP Huang, L (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266000, Peoples R China.
EM huangl@ouc.edu.cn
RI wei, zhiqiang/M-8868-2013
FU National Natural Science Foundation of China [61872326, 61672475];
   Shandong Provincial Natural Science Foundation [ZR2019MF044]; Qingdao
   Independent Innovation Major Project [20322hy, 203212xx]
FX This work is supported by the National Natural Science Foundation of
   China (No.61872326, No.61672475) ; Shandong Provincial Natural Science
   Foundation (ZR2019MF044) ; Qingdao Independent Innovation Major Project
   (20322hy, 203212xx) . This work got the GPU computation support from
   Center for High Performance Computing and System Simulation, Pilot
   National Laboratory for Marine Science and Technology (Qingdao) .
CR Ager S, 2008, OMNIGLOT WRITING SYS, V27, P2008
   Aguilar E, 2019, J VIS COMMUN IMAGE R, V60, P360, DOI 10.1016/j.jvcir.2019.03.011
   [Anonymous], ABS13065151 CORR
   [Anonymous], 2020, IEEE T NEUR NET LEAR, DOI [DOI 10.1109/TKDE.2019.2903810, DOI 10.1109/TNNLS.2019.2912082]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bragman FJS, 2019, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2019.00147
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen Z, 2018, PR MACH LEARN RES, V80
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Deng LJ, 2021, INT J ENVIRON HEAL R, V31, P202, DOI 10.1080/09603123.2019.1640355
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Gao ZS, 2019, J VIS COMMUN IMAGE R, V62, P206, DOI 10.1016/j.jvcir.2019.05.013
   HasanPour S.H., 2018, ABS180206205 CORR
   Hassani K, 2019, IEEE I CONF COMP VIS, P8159, DOI 10.1109/ICCV.2019.00825
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu JN, 2019, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2019.00152
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin X, 2019, ADV NEUR IN, V32
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Liu SK, 2019, PROC CVPR IEEE, P1871, DOI 10.1109/CVPR.2019.00197
   Liu W, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1618, DOI 10.1145/3123266.3123422
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long M., 2017, ADV NEUR IN, V30, P1
   Lu YX, 2017, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2017.126
   Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Nokland A., 2019, P 36 INT C MACHINE L, V97, P4839
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruder S., 2017, CoRR abs/1705.08142
   Sener O, 2018, ADV NEUR IN, V31
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Strezoski G, 2019, IEEE I CONF COMP VIS, P1375, DOI 10.1109/ICCV.2019.00146
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Vandenhende Simon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P527, DOI 10.1007/978-3-030-58548-8_31
   Vandenhende S., 2019, ABS190402920 CORR
   Wang XH, 2019, J VIS COMMUN IMAGE R, V62, P217, DOI 10.1016/j.jvcir.2019.05.009
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Zagoruyko S., 2016, BMVC, P1
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao JJ, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107469
   Zhu J, 2018, IEEE GEOSCI REMOTE S, V15, P1254, DOI 10.1109/LGRS.2018.2830403
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 58
TC 12
Z9 12
U1 7
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103109
DI 10.1016/j.jvcir.2021.103109
EA APR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700011
DA 2024-07-18
ER

PT J
AU Kharghanian, R
   Peiravi, A
   Moradi, F
   Iosifidis, A
AF Kharghanian, Reza
   Peiravi, Ali
   Moradi, Farshad
   Iosifidis, Alexandros
TI Pain detection using batch normalized discriminant restricted Boltzmann
   machine layers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pain detection; Convolutional deep belief network; Discriminant Feature
   Learning; Representation learning; Batch Normalization
ID FACIAL EXPRESSION
AB A system for automatic pain detection whereby pain-related features are extracted from facial images using a four-layer Convolutional Deep Belief Network (CDBN) is proposed in this study. The CDBN is trained by greedy layer-wise procedure whereby each added layer is trained as a Convolutional Restricted Boltzmann Machine (CRBM) by contrastive divergence. Since conventional CRBM is trained in a purely unsupervised manner, there is no guarantee that learned features are appropriate for the supervised task at hand. A discriminative objective based on between-class and within-class distances is proposed to adapt CRBM to learn task-related features. When discriminative and generative objectives are appropriately combined, a competitive classification performance can be achieved. Moreover, we introduced batch normalization (BN) units in the structure of the CRBM model to smooth optimization landscape and speed up the learning process. BN units come right before sigmoid units. Extracted features are then used to train a linear SVM to classify each frame into pain or no-pain classes. Extensive experiments on UNBC-McMaster Shoulder Pain database demonstrate the effectiveness of the proposed method for automatic pain detection.
C1 [Kharghanian, Reza; Peiravi, Ali] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
   [Moradi, Farshad] Aarhus Univ, Dept Engn, Integrated Circuits & Elect Lab, Aarhus, Denmark.
   [Iosifidis, Alexandros] Aarhus Univ, Dept Engn Elect & Comp Engn, Aarhus, Denmark.
C3 Ferdowsi University Mashhad; Aarhus University; Aarhus University
RP Peiravi, A (corresponding author), Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
EM peiravi@um.ac.ir
RI Peiravi, A./B-8729-2015; Iosifidis, Alexandros/G-2433-2013
OI Kharghanian, Reza/0000-0002-4033-7156; Iosifidis,
   Alexandros/0000-0003-4807-1345
CR Alharbi S, 2017, IEEE IPCCC, DOI 10.1109/TCYB.2017.2662199
   Ashraf A., 2019, 2019 14 IEEE INT C A
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Bargshady G, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P52, DOI [10.1109/CCOMS.2019.8821779, 10.1109/ccoms.2019.8821779]
   Berthouze N., 2020, ARXIV PREPR ARXIV200
   Craig K.D., 2003, SOCIAL INFLUENCES CO
   Das S., IEEE INT SYMP CIRC S
   Friesen E., 1978, Environmental Psychology & Nonverbal Behavior, V3, P5, DOI 10.1037/t27734-000
   Gawande A., 2010, The checklist manifesto: how to get things right
   Ghasemi A, 2014, 2014 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING (SSP), P61, DOI 10.1109/SSP.2014.6884575
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Hinton Geoffrey E., 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P599, DOI 10.1007/978-3-642-35289-8_32
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kingma D. P., 2014, arXiv
   Larochelle H., 2012, LEARNING ALGORITHMS, V13, P1
   Larochelle H., 2008, P 25 INT C MACH LEAR, P536
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Lesage FX, 2012, OCCUP MED-OXFORD, V62, P600, DOI 10.1093/occmed/kqs140
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey Patrick, 2009, Int Conf Affect Comput Intell Interact Workshops, V2009, P1
   Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   Melzack D., 2001, HDB PAIN ASSESSMENT
   Neftci E, 2014, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00272
   Neshov N, 2015, INT WORKSH INT DATA, P251, DOI 10.1109/IDAACS.2015.7340738
   O'Connor P, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00178
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pedersen H, 2015, LECT NOTES COMPUT SC, V9163, P128, DOI 10.1007/978-3-319-20904-3_12
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rathee N, 2015, J VIS COMMUN IMAGE R, V33, P247, DOI 10.1016/j.jvcir.2015.09.007
   Santurkar S, 2018, ADV NEUR IN, V31
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Simonyan K., 2014, 14091556 ARXIV
   Tavakolian M, 2019, INT J COMPUT VISION, V127, P1413, DOI 10.1007/s11263-019-01191-3
   van Tulder G, 2016, IEEE T MED IMAGING, V35, P1262, DOI 10.1109/TMI.2016.2526687
   Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080
   Zafar Z, 2014, INT C PATT RECOG, P4696, DOI 10.1109/ICPR.2014.803
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191
NR 49
TC 8
Z9 10
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103062
DI 10.1016/j.jvcir.2021.103062
EA MAR 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700009
DA 2024-07-18
ER

PT J
AU Padmanabhan, S
   Radhika, KR
AF Padmanabhan, Suresh
   Radhika, K. R.
TI Optimal feature selection-based biometric key management for identity
   management system: Emotion oriented facial biometric system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Identity management system; Facial emotions; Metaheuristic optimization
ID AGREEMENT SCHEME; GENERATION; SECURITY
AB Identity management systems with biometric key binding make digital transactions secure and reliable. A novel methodology is proposed to develop an intelligent key management system using facial emotions. Key binding with facial emotions makes use of an intrinsic user specific trait facilitating a more natural computer to human interaction. The proposed system utilizes metaheuristic swarm intelligence based optimization techniques to extract optimal features. The work demonstrates key binding by encrypting an image with a secret key bound to optimal features extracted from facial emotions. Efficiency and correctness of proposed key management is validated by successful decryption at receiving end with any one of the enrolled emotions given as input. Deer Hunting Optimization Algorithm and Chicken Swarm Optimization are merged to select optimal features from facial emotions. The derived algorithm is called Fitness Sorted Deer Hunting Optimization Algorithm with Rooster Update. Seven facial emotions - anger, disgust, fear, happiness, sadness, surprise and neutral are used to extract optimal features from Japanese Female Facial Expressions and Yale Facial datasets to train the neural network. Proposed work achieved better performance results over state-of-art optimization algorithms such as whale optimization algorithm, grey wolf optimization, chicken swarm optimization and deer hunting optimization algorithm. Accuracy of proposed model is 2.2% better than deer hunting optimization algorithm and 12.3% better than chicken swarm optimization for a key length 80.
C1 [Padmanabhan, Suresh; Radhika, K. R.] Visveswariah Technol Univ, Dept Informat Sci & Engn, BMS Coll Engn, Bengaluru, India.
C3 BMS College of Engineering; Visvesvaraya Technological University
RP Padmanabhan, S (corresponding author), Visveswariah Technol Univ, Dept Informat Sci & Engn, BMS Coll Engn, Bengaluru, India.
EM sureshpadmanb5@gmail.com
RI K R, Radhika/N-9614-2017
OI K R, Radhika/0000-0003-2535-9717; padmanabhan,
   suresh/0000-0003-3536-4640
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   [Anonymous], 2013, 2013 INT C INFORMATI
   Boussaïd I, 2013, INFORM SCIENCES, V237, P82, DOI 10.1016/j.ins.2013.02.041
   Brammya G., COMPUT J, DOI [10.1093/comjnl/bxy133., DOI 10.1093/COMJNL/BXY133.]
   Dokeroglu T, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106040
   Eastwood SC, 2016, IEEE T HUM-MACH SYST, V46, P231, DOI 10.1109/THMS.2015.2412944
   Feng Q, 2018, FUTURE GENER COMP SY, V84, P239, DOI 10.1016/j.future.2017.07.040
   Fernández-Navarro F, 2017, IEEE T NEUR NET LEAR, V28, P2592, DOI 10.1109/TNNLS.2016.2598657
   Jain AK, 2012, COMPUTER, V45, P87, DOI 10.1109/MC.2012.364
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Kuzu RS, 2020, IEEE T INF FOREN SEC, V15, P2641, DOI 10.1109/TIFS.2020.2971144
   Li C, 2016, IEEE T INF FOREN SEC, V11, P543, DOI 10.1109/TIFS.2015.2505630
   Li C, 2015, IEEE T INF FOREN SEC, V10, P1193, DOI 10.1109/TIFS.2015.2402593
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2013, IEEE T INF FOREN SEC, V8, P350, DOI 10.1109/TIFS.2012.2234740
   Luan G, 2019, IEEE PHOTON J, V11, P1
   Maiorana E, 2019, EUR W VIS INF PROCES, P181, DOI [10.1109/euvip47703.2019.8946206, 10.1109/EUVIP47703.2019.8946206]
   Meng X., 2014, LECT NOTES COMPUTER, V8794, DOI [10.1007/978-3-319-11857-4_10., DOI 10.1007/978-3-319-11857-4_10.]
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   Nguyen NT, 2018, MULTIMED TOOLS APPL, V77, P23909, DOI 10.1007/s11042-018-5708-z
   Panchal G, 2018, COMPUT ELECTR ENG, V69, P461, DOI 10.1016/j.compeleceng.2018.01.028
   Pandurangi Bhagyashree, 2020, IMAGE ENCRYPTION BAS
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Revina I.M., 2018, J KING SAUD U COMPTE, DOI [10. 1016/j.jksuci2018.09.002., DOI 10.1016/J.JKSUCI2018.09.002.]
   Ríos-Sánchez B, 2020, IET BIOMETRICS, V9, P109, DOI 10.1049/iet-bmt.2019.0093
   Saini N, 2013, OPT LASER ENG, V51, P1014, DOI 10.1016/j.optlaseng.2013.03.006
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sarkar A, 2019, INT J SYST ASSUR ENG, V10, P1023, DOI 10.1007/s13198-019-00832-7
   Sheng WG, 2015, IEEE T SYST MAN CY-S, V45, P1205, DOI 10.1109/TSMC.2015.2389768
   Shi BY, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P486, DOI 10.1145/3350546.3360738
   Smeets D, 2012, IEEE T SYST MAN CY C, V42, P710, DOI 10.1109/TSMCC.2011.2174221
   Song YJ, 2019, IEEE ACCESS, V7, P84386, DOI 10.1109/ACCESS.2019.2923018
   Nguyen TH, 2015, IET BIOMETRICS, V4, P29, DOI 10.1049/iet-bmt.2014.0026
   Torres J, 2013, IEEE COMMUN SURV TUT, V15, P787, DOI 10.1109/SURV.2012.072412.00129
   Wu ZD, 2018, INFORM SCIENCES, V433, P431, DOI 10.1016/j.ins.2016.12.048
   Yuvaraju M., INT J RES ELECT ELEC, V3, P1
   Zhang L, 2019, ADV MECH ENG, V11, DOI 10.1177/1687814019846998
   Zhang LP, 2017, WIREL NETW, V23, P1901, DOI 10.1007/s11276-016-1267-2
   Zhao ZC, 2019, IEEE ACCESS, V7, P31305, DOI 10.1109/ACCESS.2019.2900925
NR 42
TC 1
Z9 1
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103002
DI 10.1016/j.jvcir.2020.103002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900008
DA 2024-07-18
ER

PT J
AU Liu, XM
   Zhou, XB
   Qian, XH
AF Liu, Xiaoming
   Zhou, Xiaobo
   Qian, Xiaohua
TI Transparency-guided ensemble convolutional neural network for the
   stratification between pseudoprogression and true progression of
   glioblastoma multiform in MRI
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pseudo progression; Glioblastoma multiforme; Diffusion tensor imaging
   (DTI); Convolutional networks understanding; Ensemble CNN
ID FEATURES
AB For patients with glioblastoma multiform (GBM), differentiating pseudoprogression (PsP) from true tumor progression (TTP) is a challenging and time-consuming task for radiologists. Although deep neural networks can automatically diagnose PsP and TTP, lacking of interpretability has always been its major drawback. To overcome these shortcomings and produce more reliable outcomes, we propose a transparency-guided ensemble convolutional neural network (CNN) to automatically discriminate PsP and TTP in magnetic resonance imaging (MRI). A total of 84 patients with GBM were enrolled in the study. First, three typical convolutional neutral networks, namely VGG, ResNet and DenseNet, were trained to distinguish PsP and TTP. Subsequently, we used class-specific gradient information from convolutional layers to highlight the important regions in MRI scans. And radiologists selected the most lesion-relevant layer for each CNN. Finally, the selected layers are utilized to guide the construction of a multi-scale ensemble CNN whose classification accuracy reached 90.20%, and whose specificity is promoted 20% than that of a single CNN. The results demonstrate the presented network can enhance the reliability and accuracy of CNNs.
C1 [Liu, Xiaoming; Qian, Xiaohua] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200030, Peoples R China.
   [Liu, Xiaoming] Jilin Univ, Coll Elect Sci & Engn, Changchun 130012, Peoples R China.
   [Qian, Xiaohua] Wake Forest Sch Med, Dept Radiol, Winston Salem, NC 27157 USA.
   [Zhou, Xiaobo; Qian, Xiaohua] Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, Houston, TX 77030 USA.
C3 Shanghai Jiao Tong University; Jilin University; Wake Forest University;
   University of Texas System; University of Texas Health Science Center
   Houston
RP Qian, XH (corresponding author), Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200030, Peoples R China.
EM xiaohua.qian@sjtu.edu.cn
CR Agarwal A, 2013, J NEURO-ONCOL, V112, P413, DOI 10.1007/s11060-013-1070-1
   Asl EH, 2018, FRONT BIOSCI-LANDMRK, V23, P584, DOI 10.2741/4606
   Chu HH, 2013, RADIOLOGY, V269, P831, DOI 10.1148/radiol.13122024
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Hosny A, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002711
   Huang GL, 2017, IEEE ICC
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Jiao B, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P212, DOI 10.1109/IS3C.2016.64
   Kawahara J, 2017, NEUROIMAGE, V146, P1038, DOI 10.1016/j.neuroimage.2016.09.046
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li L, 2019, PROC CVPR IEEE, P10563, DOI 10.1109/CVPR.2019.01082
   Li MY, 2020, MED PHYS, V47, P1139, DOI 10.1002/mp.14003
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Molle Pieter, 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P115, DOI 10.1007/978-3-030-02628-8_13
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Paquette B, 2016, CANCER MED-US, V5, P1753, DOI 10.1002/cam4.734
   Qian XH, 2016, MED PHYS, V43, P5889, DOI 10.1118/1.4963812
   Radford A., 2015, ARXIV
   Reimer C, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174620
   Sahiner B, 2012, MED PHYS, V39, P28, DOI 10.1118/1.3662072
   Sarraf S.Tofighi., 2016, Classification of alzheimer's disease using fmri data and deep learning convolutional neural networks
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RupeshKumar., 2015, CoRR
   Tan H, 2012, BIOINFORMATICS, V28, P2948, DOI 10.1093/bioinformatics/bts558
   Thomas AA, 2015, J NEURO-ONCOL, V125, P183, DOI 10.1007/s11060-015-1893-z
   Tsien C, 2010, J CLIN ONCOL, V28, P2293, DOI 10.1200/JCO.2009.25.3971
   Ulmer S, 2006, NEUROLOGY, V67, P1668, DOI 10.1212/01.wnl.0000242894.21705.3c
   Wang DF, 2015, MED BIOL ENG COMPUT, V53, P1247, DOI 10.1007/s11517-015-1347-y
   Wang S, 2016, AM J NEURORADIOL, V37, P28, DOI 10.3174/ajnr.A4474
   Woolrich MW, 2009, NEUROIMAGE, V45, pS173, DOI 10.1016/j.neuroimage.2008.10.055
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang J, 2016, COMPUT BIOL MED, V73, P94, DOI 10.1016/j.compbiomed.2016.03.027
   Zhang ZH, 2014, SCIENTOMETRICS, V101, P1679, DOI 10.1007/s11192-014-1294-7
NR 40
TC 5
Z9 5
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102880
DI 10.1016/j.jvcir.2020.102880
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400008
DA 2024-07-18
ER

PT J
AU Jiang, M
   Pan, N
   Kong, J
AF Jiang, Min
   Pan, Na
   Kong, Jun
TI Spatial-temporal saliency action mask attention network for action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Two-stream; Saliency attention; Key-frame
ID REPRESENTATION; MODEL
AB Recently, video action recognition about two-stream network is still a popular research topic in computer vision. However, most of current two-stream-based methods have two redundancy issues, including: inter-frame redundancy and intra-frame redundancy. To solve the above problems, a Spatial-Temporal Saliency Action Mask Attention network (STSAMANet) is built for action recognition. First, this paper introduces a key-frame mechanism to eliminate inter-frame redundancy. This mechanism can compute key frames on each video sequence to get the greatest difference between frames. Then, Mask R-CNN detection technology is introduced to build a saliency attention layer to eliminate intra-frame redun-dancy. This layer is to focus on the saliency human body and objects for each action class. We experiment on two public video action datasets, i.e., the UCF101 dataset and Penn Action dataset to verify the effec-tiveness of our method in action recognition. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Jiang, Min; Pan, Na; Kong, Jun] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Jiang, M (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
EM minjiang@jiangnan.edu.cn
RI ZHU, BIN/IYJ-3847-2023
FU National Natural Science Foundation of China [61362030, 61201429]; China
   Postdoctoral Science Foundation [2015M581720, 2016M600360]; Jiangsu
   Postdoctoral Science Foundation [1601216C]; Scientific and Technological
   Aid Program of Xinjiang [2017E0279]
FX This work was partially supported by the National Natural Science
   Foundation of China (61362030, 61201429), China Postdoctoral Science
   Foundation (2015M581720, 2016M600360), Jiangsu Postdoctoral Science
   Foundation (1601216C), Scientific and Technological Aid Program of
   Xinjiang (2017E0279).
CR [Anonymous], 2015, ABS151104119 CORR
   [Anonymous], 2016, P INT C LEARN REPR
   [Anonymous], 2015, ABS150702159 CORR
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Black M.J, 2018, GCPR
   Cai Y, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15040702
   Cao C., 2016, IJCAI, V1, P3
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gharbi H, 2017, INT CONF ACOUST SPEE, P1502, DOI 10.1109/ICASSP.2017.7952407
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   King DB, 2015, ACS SYM SER, V1214, P1
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P2856, DOI 10.1109/TIP.2016.2556940
   Kulhare S, 2016, INT C PATT RECOG, P835, DOI 10.1109/ICPR.2016.7899739
   Kuncheva LI, 2018, J VIS COMMUN IMAGE R, V52, P118, DOI 10.1016/j.jvcir.2018.02.010
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Lin WY, 2018, AAAI CONF ARTIF INTE, P7130
   Lin YW, 2017, IEEE T CIRC SYST VID, V27, P1208, DOI 10.1109/TCSVT.2016.2527258
   Liu JY, 2019, IEEE T MULTIMEDIA, V21, P887, DOI 10.1109/TMM.2018.2871418
   Liu ZY, 2018, IFIP ADV INF COMM TE, V519, P109, DOI 10.1007/978-3-319-92007-8_10
   Nasreen A., 2013, INT J COMPUT SCI COM, V3, P194
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pazhoumand-Dar H, 2015, J VIS COMMUN IMAGE R, V30, P10, DOI 10.1016/j.jvcir.2015.03.002
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Sikka K, 2018, IEEE T PATTERN ANAL, V40, P1829, DOI 10.1109/TPAMI.2017.2741482
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sudhakaran S., 2018, ABS180711794 CORR
   Sudhakaran S., 2017, 2017 14 IEEE INT C A, P1, DOI DOI 10.1109/AVSS.2017.8078468
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang Y, 2017, IEEE INT CONF COMP V, P2129, DOI 10.1109/ICCVW.2017.249
   Xie GS, 2017, IEEE T CIRC SYST VID, V27, P1263, DOI 10.1109/TCSVT.2015.2511543
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu QC, 2019, IEEE INT CON MULTI, P568, DOI 10.1109/ICME.2019.00104
   Yifan W., 2016, 2 STREAM SR CNNS ACT, DOI [10.5244/C.30.108., DOI 10.5244/C.30.108]
   Zhang Q, 2014, SYMMETRY-BASEL, V6, P926, DOI 10.3390/sym6040926
   Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280
   Zhu JG, 2018, INT C PATT RECOG, P645, DOI 10.1109/ICPR.2018.8545710
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
   Zhu Y, 2019, LECT NOTES COMPUT SC, V11363, P363, DOI 10.1007/978-3-030-20893-6_23
NR 61
TC 16
Z9 18
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102846
DI 10.1016/j.jvcir.2020.102846
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400008
DA 2024-07-18
ER

PT J
AU Zhou, JJ
   Zhu, GW
   Zhang, QC
   Yang, ZQ
   Sun, PF
   Liu, JH
AF Zhou, Junjie
   Zhu, Guowei
   Zhang, Qingchao
   Yang, Zhenqiang
   Sun, Pengfei
   Liu, Jiahao
TI Analysis of active faults based on natural earthquakes in Central north
   China
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active fault zone; Earthquake distribution; Taihang mountain front
   fault; Velocity inversion
ID OBJECT DETECTION
AB As an important part of the integration of Beijing-Tianjin-Hebei, it is very important to analyze the seismic activity of active structures in Central north China. There are two sets of active faults belt in the lot, and there have been devastating earthquakes, which need to grasp the level of seismic activity. Located at the boundary of the third-order tectonic unit, there are a series of faults in the area, such as the north to the east Taihang mountain front fault, the north to the east Xinhe fault and the north to the west Cixian-darning fault, which intersect and cut each other to form fault depression basin. There are different scales of NE, NNE, and NW faults, which are considered to be the birthplace of the earthquake. At the same time, more than 6 magnitude earthquake magnitude have happened in the Cixian and Xingtai. The seismogenic structure of the research shows that these earthquakes associated with deep fault activities, the source location in the deep crust velocity structure mutation. In order to determine and analyze the P-wave velocity structure characteristics and the hypocenter distribution, and the activity characteristics of the deep space of active fault belt, the natural seismic data monitored by seismic network are collected and organized, which are used to analyze the relationship between seismic wave velocity and hypocenter position. Due to the deep migration of the crustal material and the horizontal principal compressive the NEE direction stress in North China, the crustal thickness on the west side of the Taihang mountain front fault is greater than that of the east side, from 1 km to 7 km. Along the trend, the epicenter of the small earthquake is mainly distributed in the crustal thickening area on the west side of this active fault, and the epicenter of the eastern plain is less distributed. The depth of the small earthquake is concentrated in the range of 8-20 Km. Comprehensive analysis shows that the seismic p-wave velocity structure characteristics can be divided into the sedimentary cover, upper crust, the earth's crust and the lower crust structure, thickness of different location have change, the thickness of the sedimentary cover Taihang uplift zone thickness 0.1-3 km, to 5-7 km in Handan fault depression: The thickness of the crystalline basement in the Taihang mountain uplift is 3-5 km, and the Handan fault depression basin is thickened to 7-10 km. The thickness of the crust on the west side of Taihang mountain front fault is significantly greater, than that on the east side. The thickness of the crust on the west side is decreased from 36-40 km on the west side to 30-35 km on the east side and about 7-10 km on the east side. Due to the near east-west tension, the zone has disengaging movement, forming the characteristics of shovel-type normal fault combination. In the earth's crust with high-speed and low-speed layer between configuration characteristics, seismic horizon of earthquake preparation 12-18 km deep in the earth's crust, characterized by low speed and high speed layer mutation position, concentrated distribution of small earthquakes, the seismogenic layer a concentration distribution in the crust velocity structure conversion section. Seismic activity is concentrated in the west end of the Cixian-daming fault and the west side of the Xinhe fault, with an average depth of 12-18 km. (C) 2019 Published by Elsevier Inc.
C1 [Zhou, Junjie; Zhu, Guowei; Zhang, Qingchao; Yang, Zhenqiang; Liu, Jiahao] China Univ Min & Technol, Beijing 100083, Peoples R China.
   [Zhou, Junjie; Sun, Pengfei] Hebei Univ Engn, Handan 056038, Hebei, Peoples R China.
C3 China University of Mining & Technology; Hebei University of Engineering
RP Zhou, JJ (corresponding author), China Univ Min & Technol, Beijing 100083, Peoples R China.
EM ansanzhou7684@163.com
FU National Key R&D Program of China [2018YFC0807801]; China Geological
   Survey Bureau [DD20160267]; National Science Foundation of China
   [41604069]
FX This research was partially supported by the National Key R&D Program of
   China (Grant No. 2018YFC0807801), the China Geological Survey Bureau
   (Grant No. DD20160267), the National Science Foundation of China (Grant
   No. 41604069). Thanks to peer review experts valuable advice and
   suggestions!
CR Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang JL, 2005, CHINESE SCI BULL, V50, P544, DOI 10.1360/04wd0206
   LIU FT, 1984, ACTA GEOPHYS SINICA, V27, P167
   Xu J., 2000, Seismol. Geol., V22, P111
   Xu Jie, 1988, Seismology and Geology, V10, P51
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200491
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu Xi-wei, 2002, LATEST CRUSTAL DEFOR, P150
   Yang XP, 2016, CHINESE J GEOPHYS-CH, V59, P528, DOI 10.6038/cjg20160212
   Zhang XM, 2006, CHINESE J GEOPHYS-CH, V49, P1709
   Zhao Yan-lai, 1993, EARTHQUAKE CHINA, V3, P129
   Zhou LQ, 2006, CHINESE J GEOPHYS-CH, V49, P1062
   Zhou Long-quan, PROG GEOPHYS, V20, P503
   Zhu ZHi-ping, 2006, ACTA SEISMOL SIN, V17, P328
   Zou Y, 2008, CHINESE J ORG CHEM, V28, P111
NR 20
TC 0
Z9 0
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102612
DI 10.1016/j.jvcir.2019.102612
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700003
DA 2024-07-18
ER

PT J
AU Liu, M
   Rong, XL
   Jiang, TC
AF Liu, Miao
   Rong, Xiaoli
   Jiang, Tiechao
TI Representative discovery of structure cues for coronary heart disease
   recognition based on quality assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image recognition; Image quality assessment; Iterative reconstruction
   algorithm; Image match
ID FILTERED BACK-PROJECTION; ITERATIVE RECONSTRUCTION; ABDOMINAL CT;
   CONTRAST; ARTERY; ANGIOGRAPHY; BMI
AB Image recognition is an indispensable technique in computer vision, such as face recognition, vehicle recognition. It can be also widely used in medical research. Coronary heart disease recognition is still a big challenge due to artifacts or noise. In addition, recognizing coronary heart disease manually is a huge workload. So in this paper, we exploit representative structure cues for coronary heart disease recognition. More specifically, we first leverage Iterative Reconstruction (IR) algorithm to reduce the radiation dose during CT angiography acquisition. For structure cues discovery, we propose grid-based image segmentation algorithm, where each grid is represented by an according image quality score. High probability grid of disease cues corresponds to high quality score. Then, each training image is represented using quality score matrix. Afterward, we incorporate low-level features (grayscale and texture) with quality score matrix. Finally, image matching algorithm is proposed for structure cues discovery from test images. Experimental results demonstrate the effectiveness of our proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Miao; Jiang, Tiechao] Jilin Univ, Dept Cardiol, China Japan Union Hosp, Changchun, Jilin, Peoples R China.
   [Liu, Miao; Jiang, Tiechao] Jilin Prov Key Lab Genet Diag Cardiovasc Dis, Changchun, Jilin, Peoples R China.
   [Liu, Miao; Jiang, Tiechao] Jilin Prov Mol Biol Res Ctr Precis Med Major Card, Changchun, Jilin, Peoples R China.
   [Rong, Xiaoli] Jilin Univ, Dept Clin Lab, China Japan Union Hosp, Changchun, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Jiang, TC (corresponding author), Jilin Univ, Dept Cardiol, China Japan Union Hosp, Changchun, Jilin, Peoples R China.
EM liumiao1983@jlu.edu.cn; rongxl16@mails.jlu.edu.cn; jiangtc@jlu.edu.cn
OI Rong, Xiaoli/0000-0002-1030-509X
FU Natural Science Foundation of China [81570360]; Health Commission of
   Jilin Province [2017Q013]
FX This work was supported by Natural Science Foundation of China (No.
   81570360), Health Commission of Jilin Province (No. 2017Q013).
CR Boulanger CM, 2017, NAT REV CARDIOL, V14, P259, DOI 10.1038/nrcardio.2017.7
   Cohen JG, 2017, EUR RADIOL, V27, P3266, DOI 10.1007/s00330-016-4716-5
   Cui YJ, 2013, FIXED POINT THEORY A, DOI 10.1186/1687-1812-2013-345
   Eckel N, 2018, LANCET DIABETES ENDO, V6, P714, DOI 10.1016/S2213-8587(18)30137-2
   Euler A, 2017, EUR RADIOL, V27, P5252, DOI 10.1007/s00330-017-4825-9
   Gatti M, 2018, J COMPUT ASSIST TOMO, V42, P191, DOI 10.1097/RCT.0000000000000677
   Goitein O, 2017, INT J CARDIOVAS IMAG, V33, P739, DOI 10.1007/s10554-016-1050-6
   Hansen PC, 2018, NUMER ALGORITHMS, V79, P107, DOI 10.1007/s11075-017-0430-x
   Khera AV, 2017, NAT REV GENET, V18, DOI 10.1038/nrg.2016.160
   Lee M, 2017, OPT EXPRESS, V25, P27415, DOI 10.1364/OE.25.027415
   Liu XF, 2012, NEUROCOMPUTING, V79, P132, DOI 10.1016/j.neucom.2011.10.016
   Lv PJ, 2017, EUR RADIOL, V27, P374, DOI 10.1007/s00330-016-4349-8
   Maeda E, 2017, J CARDIOVASC COMPUT, V11, P40, DOI 10.1016/j.jcct.2016.11.002
   Masuda T, 2018, ACAD RADIOL, V25, P1298, DOI 10.1016/j.acra.2018.01.019
   Sandler V, 2017, DIABETOLOGIA, V60, P518, DOI 10.1007/s00125-016-4182-2
   Shinbane JS, 2018, WORLD J PEDIATR CONG, V9, P347, DOI 10.1177/2150135118757992
   Simmonds M, 2017, OBES REV, V18, P382, DOI 10.1111/obr.12510
   Solomon J, 2017, RADIOLOGY, V284, P777, DOI 10.1148/radiol.2017161736
   Tang YC, 2018, ACAD RADIOL, V25, P1010, DOI 10.1016/j.acra.2017.12.018
   Tepe J, 2017, INVERSE PROBL SCI EN, V25, P1448, DOI 10.1080/17415977.2016.1267168
   Valgimigli M, 2018, EUR J CARDIO-THORAC, V53, P34, DOI 10.1093/ejcts/ezx334
   Yu S, 2017, CLIN RADIOL, V72, DOI 10.1016/j.crad.2016.08.004
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
NR 23
TC 1
Z9 1
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102607
DI 10.1016/j.jvcir.2019.102607
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600009
DA 2024-07-18
ER

PT J
AU Yin, JP
   Han, YY
   Wang, XF
   Chang, BH
   Dong, FD
   Xu, YJ
AF Yin, J. P.
   Han, Y. Y.
   Wang, X. F.
   Chang, B. H.
   Dong, F. D.
   Xu, Y. J.
TI A new charge structure based on computer modeling and simulation
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Charge structure; Computer modeling and simulation technology; PELE;
   Liner
ID OBJECT DETECTION
AB This paper proposes a new charge structure, which can form a penetrator with enhanced lateral effect (PELE) or explosively formed projectile (EFP) by different initiation modes. The purpose of this paper is to study the dynamic response and aftereffect of the charge liner under explosive load in PELE mode. To this end, the computer modeling and simulation analysis method was used to simulate the forming and penetrating target progress of the PELE formed by charge liner. The results indicated that the ANSYS/LS-DYNA finite element software could accurately simulate the formation of PELE and the damage process to the target, and we could obtain exact forming and damage data by this method. The PELE damage element could be formed by the new charge structure liner under explosive load, its velocity was 2050 m/s, the head-to-tail velocity gradient was only 20 m/s, the length of damage element was 63.62 mm, and the length-diameter ratio was 1.79. And PELE damage element could effectively damage 15 mm target, the inlet opening hole diameter of the target was measured to be 68 mm, the outlet diameter was 72 mm. This finding could serve a technical basis for computer modeling and simulation technology of charge structure. (C) 2019 Published by Elsevier Inc.
C1 [Yin, J. P.; Han, Y. Y.; Wang, X. F.; Chang, B. H.; Xu, Y. J.] North Univ China, Sch Mechatron Engn, Taiyuan 030051, Shanxi, Peoples R China.
   [Dong, F. D.] Sci & Technol Transient Impact Lab, Beijing 102202, Peoples R China.
C3 North University of China
RP Yin, JP (corresponding author), North Univ China, Sch Mechatron Engn, Taiyuan 030051, Shanxi, Peoples R China.
EM yjp123@nuc.edu.cn
FU National Natural Science Foundation of China [11572291]; Key Laboratory
   Foundation of Science and Technology on Transient Impact [61426060101]
FX This work is financially supported by the National Natural Science
   Foundation of China Grant No. 11572291 and the Key Laboratory Foundation
   of Science and Technology on Transient Impact under Grant No.
   61426060101. The financial contributions are gratefully acknowledged
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   [Anonymous], 1991, UCRL-MA-106439
   Arnold W, 2014, 28TH INTERNATIONAL SYMPOSIUM ON BALLISTICS, VOLS 1 AND 2, P289
   Arnold W, 2011, BALLISTICS 2011: 26TH INTERNATIONAL SYMPOSIUM ON BALLISTICS, VOL 1 AND VOL 2, P305
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Bender D., 2001, P 19 INT S BALL CAS, P679
   [陈刚 CHEN Gang], 2007, [爆炸与冲击, Explosion and Shock Waves], V27, P131
   Fong R., 1991, 41 ANN BOMB WARH TEC, P172
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hu C.M., 2003, Explos. Shock Waves, P188
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Jiang Jian-wei, 2008, Transactions of Beijing Institute of Technology, V28, P756
   Jin B., 2016, THESIS
   Lei M., 2016, J ORDNANCE EQUIPMENT, V8, P43
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Wang YL, 2016, THESIS
   Wei Gao, 2018, CHIN J TACTIC MISSIL, V3, P116
   Xu ML, 2017, J COMPUT SCI TECH-CH, V32, P1162, DOI 10.1007/s11390-017-1791-2
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Yin JP, 2017, STRENGTH MATER+, V49, P20, DOI 10.1007/s11223-017-9837-9
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang X.H., 2014, 23 NAT C STRUCT ENG, VIll, P258
   Zhang Yang-yi, 2010, Journal of PLA University of Science and Technology (Natural Science Edition), V11, P468
   [张洋溢 ZHANG Yang-yi], 2009, [弹道学报, Journal of Ballistics], V21, P90
NR 30
TC 5
Z9 5
U1 2
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102613
DI 10.1016/j.jvcir.2019.102613
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600013
DA 2024-07-18
ER

PT J
AU Jiao, QH
   Liu, Z
   Ye, LW
   Wang, Y
AF Jiao, Qihan
   Liu, Zhi
   Ye, Linwei
   Wang, Yang
TI Weakly labeled fine-grained classification with hierarchy relationship
   of fine and coarse labels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained classification; Weakly labeled images; Convolutional block
   attention; Feature fusion
ID IMAGE CLASSIFICATION; LOW-RANK; MODEL
AB The current work of fine-grained classification generally depends on a large number of fine labels of images. However, these fine labels are much more difficult to annotate than the coarse labels, which generalize fine labels based on the hierarchy of categories. In this paper, we propose to make fine labels prediction under a weakly supervised setting where a subset of training data is labeled with fine labels and the others only have coarse labels. We aim to explore the hierarchy relationship between coarse classes and fine classes to achieve a better performance on fine-grained classification and meanwhile reduce the heavy dependence on fine labels. To this end, we use convolutional block attention module and multi-scale convolution kernel based feature fusion to generate more effective features from multi-scale convolution kernels and multi-level features. Besides, an adaptive classification module exploits the hierarchy relationship of categories to learn the fine-grained classifier automatically according to the available labels of the training data. Comprehensive experiments on the CIFAR100 dataset, a subset of ImageNet and CUB-200-2011 dataset demonstrate the better fine-grained classification performance of our model. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Jiao, Qihan; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Jiao, Qihan; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Ye, Linwei; Wang, Yang] Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
C3 Shanghai University; Shanghai University; University of Manitoba
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI Zhang, Han/JMR-0670-2023; LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61771301]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61771301.
CR Ahmed K, 2016, LECT NOTES COMPUT SC, V9911, P516, DOI 10.1007/978-3-319-46478-7_32
   [Anonymous], ICLR
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], 2016, P BRIT MACHINE VISIO
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2009, Technical report
   [Anonymous], 2017, Dual path networks
   [Anonymous], 2015, P INT C LEARNING REP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2007, P 13 AM C INF SYST A
   [Anonymous], 2014, MULTIPLE OBJECT RECO
   [Anonymous], P INT C MACH LEARN
   Branson S., 2014, BIRD SPECIES CATEGOR, V1, P7
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Goo W, 2016, LECT NOTES COMPUT SC, V9906, P86, DOI 10.1007/978-3-319-46475-6_6
   Gregersdotter K, 2015, ANIMAL HORROR CINEMA: GENRE, HISTORY AND CRITICISM, P1
   Hagawa R, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P36, DOI 10.1109/ACPR.2015.7486461
   He XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P627, DOI 10.1145/3123266.3123319
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Huang XJ, 2018, PERSISTENT TOXIC SUBSTANCE MONITORING: NANOELECTROCHEMICAL METHODS, P1, DOI 10.1002/9783527344109
   Jaderberg M., 2015, ICLR, DOI DOI 10.48550/ARXIV.1506.02025
   Komodakis N, 2017, P ICLR
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Lefort R, 2009, I S INTELL SIG PR, P143, DOI 10.1109/WISP.2009.5286569
   Lei J, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P240, DOI 10.1109/CRV.2017.21
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Ristin M, 2015, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2015.7298619
   Ristin M, 2014, PROC CVPR IEEE, P3654, DOI 10.1109/CVPR.2014.467
   Shen ZQ, 2017, IEEE INT CON MULTI, P1470, DOI 10.1109/ICME.2017.8019332
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wah Catherine, 2011, Technical report
   Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu Z, 2018, IEEE T PATTERN ANAL, V40, P1100, DOI 10.1109/TPAMI.2016.2637331
   Xu Z, 2017, IEEE T IMAGE PROCESS, V26, P135, DOI 10.1109/TIP.2016.2621661
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
   Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng ZN, 2013, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2013.97
   Zhang CJ, 2018, IEEE T MULTIMEDIA, V20, P903, DOI 10.1109/TMM.2017.2759500
   Zhang CJ, 2018, IEEE T CIRC SYST VID, V28, P428, DOI 10.1109/TCSVT.2016.2613125
   Zhang CJ, 2017, IEEE T NEUR NET LEAR, V28, P1550, DOI 10.1109/TNNLS.2016.2545112
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang GL, 2017, CHIN CONT DECIS CONF, P2151
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhang XP, 2016, IEEE T IMAGE PROCESS, V25, P878, DOI 10.1109/TIP.2015.2509425
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
NR 65
TC 6
Z9 6
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102584
DI 10.1016/j.jvcir.2019.102584
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200010
DA 2024-07-18
ER

PT J
AU Ma, J
   Yuan, YY
AF Ma, Ji
   Yuan, Yuyu
TI Dimension reduction of image deep feature using PCA
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Feature extraction; Dimension reduction; PCA algorithm
ID CONVOLUTIONAL NEURAL-NETWORK; MODEL
AB Convolution neural networks based methods can derive deep features from training images. However, one challenge is that the dimension of the extracted image features increases dramatically with more network layers. To solve this problem, this paper focuses on the study of dimension reduction. After using deep learning to extract image features, the PCA algorithm is used to achieve dimension reduction. Specifically, we first leverage deep convolutional neural network to extract image features. Then, we introduce and leverage PCA algorithm to achieve dimension reduction. Aiming at the problem that it is difficult to process high-dimensional sparse big data based on PCA algorithm. This paper optimizes the PCA algorithm. After image preprocessing, the feasibility of PCA algorithm for dimension reduction of image feature extraction by deep learning is verified by simulation experiments. The efficiency of the proposed algorithm is proved by comparing the performance of PCA algorithm before and after optimization. (C) 2019 Published by Elsevier Inc.
C1 [Ma, Ji] Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing, Peoples R China.
   [Yuan, Yuyu] Beijing Univ Posts & Telecommun, Sch Software, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Ma, J (corresponding author), Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing, Peoples R China.
EM maji@bupt.edu.cn; yuanyuyu@bupt.edu.cn
FU National Natural Science Foundation of China [91118002]
FX This work was supported by the National Natural Science Foundation of
   China (No. 91118002)
CR Braga NRF, 2018, PHYS LETT B, V776, P78, DOI 10.1016/j.physletb.2017.11.034
   Capozziello S., 2018, INT J MOD PHYS D, V27, P1753
   Chen HX, 2013, MECH SYST SIGNAL PR, V40, P469, DOI 10.1016/j.ymssp.2013.06.023
   Cui YJ, 2016, APPL MATH LETT, V51, P48, DOI 10.1016/j.aml.2015.07.002
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Gao M, 2015, APPL MATH COMPUT, V266, P429, DOI 10.1016/j.amc.2015.05.090
   Ghamisi P, 2017, IEEE J-STARS, V10, P3011, DOI 10.1109/JSTARS.2016.2634863
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Han X, 2017, MED PHYS, V44, P1408, DOI 10.1002/mp.12155
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Hu PJ, 2017, INT J COMPUT ASS RAD, V12, P399, DOI 10.1007/s11548-016-1501-5
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Lee MJ, 2017, ADV SCI LETT, V23, P1623, DOI 10.1166/asl.2017.8643
   Li C, 2016, IEEE GEOSCI REMOTE S, V13, P641, DOI 10.1109/LGRS.2016.2532380
   Li SQ, 2015, VASCULAR, V23, P558, DOI 10.1177/1708538115598070
   Liu F, 2016, ACTA MATH SIN, V32, P507, DOI 10.1007/s10114-016-5200-5
   Meng XZ, 2016, J MATH ANAL APPL, V433, P227, DOI 10.1016/j.jmaa.2015.07.056
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Rahmani M, 2017, IEEE T SIGNAL PROCES, V65, P6260, DOI 10.1109/TSP.2017.2749215
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Robinson AE, 2007, VISION RES, V47, P1631, DOI 10.1016/j.visres.2007.02.017
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Tabuchi A, 1982, Nippon Ganka Gakkai Zasshi, V86, P2024
   [唐利明 Tang Liming], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P108
   [童水光 Tong Shuiguang], 2017, [振动与冲击, Journal of Vibration and Shock], V36, P34
   Ueda T, 1997, J OPER RES SOC JPN, V40, P466, DOI 10.15807/jorsj.40.466
   Wan S, 2010, INT J GEOGR INF SCI, V24, P623, DOI 10.1080/13658810802587709
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zhang D, 2018, WATER RESOUR MANAG, V32, P2079, DOI 10.1007/s11269-018-1919-3
   ZHANG Hui, 2017, INVERSE PROBL IMAG, V6, P357
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 37
TC 82
Z9 86
U1 6
U2 76
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102578
DI 10.1016/j.jvcir.2019.102578
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200012
DA 2024-07-18
ER

PT J
AU Zakharov, N
   Su, H
   Zhu, J
   Gläscher, J
AF Zakharov, Nikolai
   Su, Hang
   Zhu, Jun
   Glaescher, Jan
TI Towards controllable image descriptions with semi-supervised VAE
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE VAE; Image caption; Generative models; Semi-supervised
AB Image captioning models successfully describe the visual contents of images using natural language. To generate more natural and diverse descriptions, a model must learn style-specific patterns and requires collecting style-specific datasets, which is time-consuming. To address this issue, we propose a semi-supervised deep generative model, Semi-supervised Conditional Variational Auto-Encoder (SCVAE). Our model is capable of leveraging more labelled and unlabelled data in the generative model schema. Extensive empirical results demonstrate that compared with the start-of-art models, our proposed method is able to generate more accurate image captions with more extensive styles. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zakharov, Nikolai; Su, Hang; Zhu, Jun] Tsinghua Univ, Inst Al THBI Lab, State Key Lab Intell Tech & Sys, Dept Comp Sci & Tech,BNRist Ctr, Beijing 100084, Peoples R China.
   [Glaescher, Jan] Univ Med Ctr Hamburg Eppendorf, Inst Syst Neurosci, Hamburg, Germany.
C3 Tsinghua University; University of Hamburg; University Medical Center
   Hamburg-Eppendorf
RP Zhu, J (corresponding author), Tsinghua Univ, Inst Al THBI Lab, State Key Lab Intell Tech & Sys, Dept Comp Sci & Tech,BNRist Ctr, Beijing 100084, Peoples R China.; Gläscher, J (corresponding author), Univ Med Ctr Hamburg Eppendorf, Inst Syst Neurosci, Hamburg, Germany.
EM dcszj@mail.tsinghua.edu.cn; glaescher@uke.de
OI Glascher, Jan/0000-0002-1020-7115
FU National NSF of China [61621136008, 61620106010, 61571261]; Beijing
   Natural Science Foundation [L172037]; DITD Program [JCKY2017204B064];
   Tsinghua Tiangong Institute for Intelligent Computing; NVIDIA NVAIL
   program
FX The work is supported by the National NSF of China (Nos. 61621136008,
   61620106010 and 61571261), Beijing Natural Science Foundation (No.
   L172037), DITD ProgramJCKY2017204B064, Tsinghua Tiangong Institute for
   Intelligent Computing and the NVIDIA NVAIL program. J.Z. and J.G. are
   corresponding authors.
CR [Anonymous], 2018, ARXIV180507112
   [Anonymous], 2017, ARXIV170306029
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bowman S. R., 2015, GENERATING SENTENCES
   Chen T., 2018, ARXIV180703871
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Dong YP, 2017, PROC CVPR IEEE, P975, DOI 10.1109/CVPR.2017.110
   Foumani SNM, 2019, J VIS COMMUN IMAGE R, V59, P195, DOI 10.1016/j.jvcir.2019.01.009
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Kingma D. P., 2013, ARXIV13126114
   Lin C.-Y., 2004, TEXT SUMMAR BRANCH O
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Mao JH, 2015, IEEE I CONF COMP VIS, P2533, DOI 10.1109/ICCV.2015.291
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Rezende Danilo Jimenez, 2014, ARXIV14014082
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang LW, 2017, ADV NEUR IN, V30
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Xu WD, 2017, AAAI CONF ARTIF INTE, P3358
   Yang Z., 2017, PR MACH LEARN RES, P3881, DOI DOI 10.5555/3305890.3306082
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You Quanzeng, 2018, ARXIV180110121
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
NR 39
TC 3
Z9 4
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102574
DI 10.1016/j.jvcir.2019.102574
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200006
DA 2024-07-18
ER

PT J
AU Shishido, H
   Harazaki, A
   Kameda, Y
   Kitahara, I
AF Shishido, Hidehiko
   Harazaki, Aoi
   Kameda, Yoshinari
   Kitahara, Itaru
TI Smooth switching method for asynchronous multiple viewpoint videos using
   frame interpolation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Free-viewpoint video; Bullet-time; Frame interpolation; Morphing;
   Asynchronous multi-view videos
AB This research proposes a method that generates viewpoint smooth switching by reducing the flickering artefacts that are observed at bullet-times generated from asynchronous multi-view videos using frame interpolation processing. When we asynchronously capture multi-view videos of an object moving at a high velocity, deviations occur in the observed position at the bullet-times. We apply a frame interpolation technique to smooth this problem. By selecting suitable interpolated images that produce the smallest movement of the subject's observed position, we smoothly generate a viewpoint-switched bullet-time video.
   In this paper, we examine the subjective evaluation of the video generated by the proposed method. And we also examine objective evaluation. Therefore, the effectiveness of the proposed method is shown. Furthermore, reproducibility was improved by considering the application conditions of the proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Shishido, Hidehiko; Harazaki, Aoi; Kameda, Yoshinari; Kitahara, Itaru] Univ Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki, Japan.
C3 University of Tsukuba
RP Shishido, H (corresponding author), Univ Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki, Japan.
EM shishido@ccs.tsukuba.ac.jp; s1520814@u.tsukuba.ac.jp;
   kameda@iit.tsukuba.ac.jp; kitahara@ccs.tsukuba.ac.jp
FU JSPS KAKENHI [17H01772, 17K13180]; CREST, JST; Grants-in-Aid for
   Scientific Research [17K13180] Funding Source: KAKEN
FX This work was supported by JSPS KAKENHI Grant Nos. 17H01772 and
   171(13180 and CREST, JST.
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], SIGGRAPH ASIA2014
   [Anonymous], 2015, ITE T MEDIA TECHNOL
   [Anonymous], 3DTV C 2017 RES APPL
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Choi K, 2005, LECT NOTES COMPUT SC, V3617, P661, DOI 10.1007/11553595_81
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Guillemaut JY, 2009, IEEE I CONF COMP VIS, P809, DOI 10.1109/ICCV.2009.5459299
   Hilton A, 2010, GEOM COMPUT, V5, P77, DOI 10.1007/978-3-642-12392-4_4
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   Kellis E, 2007, J SPORT SCI MED, V6, P154
   Kilner J, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P177
   Koyama T, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P178, DOI 10.1109/ISMAR.2003.1240701
   Lee SY, 1996, J VISUAL COMP ANIMAT, V7, P3, DOI 10.1002/(SICI)1099-1778(199601)7:1<3::AID-VIS131>3.0.CO;2-U
   Li MY, 2009, J IRON STEEL RES INT, V16, P407
   O'Dwyer N, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P262, DOI 10.1109/ISMAR-Adjunct.2017.87
   Shechtman E, 2010, PROC CVPR IEEE, P615, DOI 10.1109/CVPR.2010.5540159
   Silva JR, 2011, COMPUT GRAPH-UK, V35, P412, DOI 10.1016/j.cag.2011.01.012
   Simakov D, 2008, PROC CVPR IEEE, P3887
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Straka M, 2011, LECT NOTES COMPUT SC, V6688, P635, DOI 10.1007/978-3-642-21227-7_59
   Tanimoto M, 2011, IEEE SIGNAL PROC MAG, V28, P67, DOI 10.1109/MSP.2010.939077
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 25
TC 3
Z9 3
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 68
EP 76
DI 10.1016/j.jvcir.2019.04.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600006
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Silva, RRV
   Araujo, FHD
   Ushizima, DM
   Bianchi, AGC
   Carneiro, CM
   Medeiros, FNS
AF Silva, Romuere R. V.
   Araujo, Flavio H. D.
   Ushizima, Daniela M.
   Bianchi, Andrea G. C.
   Carneiro, Claudia M.
   Medeiros, Fatima N. S.
TI Radial feature descriptors for cell classification and recommendation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Radial feature descriptors; Cell classification; Image retrieval;
   Convolutional neural networks
ID TEXTURAL FEATURES; MR-IMAGES; SEGMENTATION; RETRIEVAL; CYTOPLASM;
   DIAGNOSIS; NUCLEUS; COLOR
AB This paper introduces computational tools for cell classification into normal and abnormal, as well as content-based-image-retrieval (CBIR) for cell recommendation. It also proposes the radial feature descriptors (RFD), which define evenly interspaced segments around the nucleus, and proportional to the convexity of the nuclear boundary. Experiments consider Herlev and CRIC image databases as input to classification via Random Forest and bootstrap: we compare 14 different feature sets by means of False Negative Rate (FNR) and Kappa (kappa), obtaining FNR = 0.02 and kappa = 0.89 for Herlev, and FNR = 0.14 and kappa = 0.78 for CRIC. Next, we sort and rank cell images using convolutional neural networks and evaluate performance with the Mean Average Precision (MAP), achieving MAP = 0.84 and MAP = 0.82 for Herlev and CRIC, respectively. Cell classification show encouraging results regarding RFD, including its sensitivity to intensity variation around the nuclear membrane as it bypasses cytoplasm segmentation. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Silva, Romuere R. V.; Araujo, Flavio H. D.; Medeiros, Fatima N. S.] Univ Fed Ceara, Fortaleza, CE, Brazil.
   [Silva, Romuere R. V.; Araujo, Flavio H. D.] Univ Fed Piaui, Pico, PI, Brazil.
   [Ushizima, Daniela M.] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Ushizima, Daniela M.] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
   [Bianchi, Andrea G. C.; Carneiro, Claudia M.] Univ Fed Ouro Preto, Ouro Preto, MG, Brazil.
C3 Universidade Federal do Ceara; Universidade Federal do Piaui; University
   of California System; University of California Berkeley; United States
   Department of Energy (DOE); Lawrence Berkeley National Laboratory;
   Universidade Federal de Ouro Preto
RP Ushizima, DM (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM romuere@ufpi.edu.br; fiavio86@ufpi.edu.br; dani.lbnl@berkeley.edu;
   andrea@iceb.ufop.br; fsombra@ufc.br
RI de Medeiros, Fátima Nelsizeuma Sombra/E-1168-2011; Bianchi, Andrea G.
   Campos/AAN-4193-2021; de Araújo, Flávio H Duarte/C-9541-2015; carneiro,
   claudia m/B-6205-2013; Silva, Romuere/AFW-0349-2022; Ushizima,
   Daniela/AAN-4215-2021; carneiro, Claudia Martins/AAP-4455-2020
OI de Medeiros, Fátima Nelsizeuma Sombra/0000-0003-3075-8771; Bianchi,
   Andrea G. Campos/0000-0001-7949-1188; Silva,
   Romuere/0000-0002-7163-7469; Ushizima, Daniela/0000-0002-7363-9468;
   carneiro, Claudia Martins/0000-0002-6002-857X; Araujo,
   Flavio/0000-0003-2824-2645
FU CNPq [304673/2011-0, 472565/2011-7, 401120/2013-9, 306600/2016-1];
   Fapemig; Gordon and Betty Moore Foundation [GBMF3834]; Alfred P. Sloan
   Foundation [2013-10-27]; Office of Science of the US Department of
   Energy (DOE) under Advanced Scientific Computing Research (ASCR) Early
   Career Award [DE-AC02-05CH11231]; CAPES/CNPq-PVE [401442/2014-4,
   207307/2015-6, 207306/2015-0]
FX This work was supported by CNPq (304673/2011-0, 472565/2011-7,
   401120/2013-9, 306600/2016-1), CAPES/CNPq-PVE (401442/2014-4,
   207307/2015-6, 207306/2015-0) and Fapemig. This research is also funded
   in part by the Gordon and Betty Moore Foundation through Grant GBMF3834
   and by the Alfred P. Sloan Foundation through Grant 2013-10-27 to the
   University of California, Berkeley. Algorithmic work is partially
   supported by the Office of Science of the US Department of Energy (DOE)
   under Contract No. DE-ACO2-05CH11231, Advanced Scientific Computing
   Research (ASCR) Early Career Award. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the authors and they do not necessarily reflect the views of DOE or the
   University of California. We are grateful to the cytopathologists,
   Alessandra Tobias and Mariana Trevisan, who classified the cervical
   cells manually for the CRIC database, and to the BIDS data scientists
   and staff for encouraging the exploration of Python packages in
   deploying open -source
CR Ajdadi FR, 2016, SOIL TILL RES, V162, P8, DOI 10.1016/j.still.2016.04.012
   [Anonymous], 2016, 2016 IEEE/OES China Ocean Acoustics (COA)
   [Anonymous], 2015, COMPUTATIONAL MATH M
   Araujo FHD, 2018, EXPERT SYST APPL, V109, P35, DOI 10.1016/j.eswa.2018.05.015
   Bejnordi BE, 2013, PROC SPIE, V8676, DOI 10.1117/12.2007185
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CASTLEMAN KR, 1980, IEEE T PATTERN ANAL, V2, P451, DOI 10.1109/TPAMI.1980.6592366
   Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012
   Chen YF, 2014, IEEE J BIOMED HEALTH, V18, P94, DOI 10.1109/JBHI.2013.2250984
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Sa JJD, 2014, IEEE IMAGE PROC, P2280, DOI 10.1109/ICIP.2014.7025462
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636
   Freeman W. T., 1994, P INT WORKSH AUT FAC, P296
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Gao JQ, 2013, APPL MATH COMPUT, V219, P6410, DOI 10.1016/j.amc.2013.01.005
   Gençtav A, 2012, PATTERN RECOGN, V45, P4151, DOI 10.1016/j.patcog.2012.05.006
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu P, 2016, OPTIK, V127, P11599, DOI 10.1016/j.ijleo.2016.09.040
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Jantzen J., 2005, Nature inspired Smart Information Systems (NiSIS 2005), P1
   Kale A., 2010, 20 INT C PATT REC IC, P2399, DOI [10.1109/ICPR.2010.587, DOI 10.1109/ICPR.2010.587]
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li K, 2012, PATTERN RECOGN, V45, P1255, DOI 10.1016/j.patcog.2011.09.018
   Li L, 2016, OPTIK, V127, P7408, DOI 10.1016/j.ijleo.2016.05.105
   Li L, 2016, AEU-INT J ELECTRON C, V70, P920, DOI 10.1016/j.aeue.2016.04.007
   Lu Z, 2015, IEEE T IMAGE PROCESS, V24, P1261, DOI 10.1109/TIP.2015.2389619
   Marinakis Y, 2009, COMPUT BIOL MED, V39, P69, DOI 10.1016/j.compbiomed.2008.11.006
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Nikou C, 2012, CERVICAL CELL CLASSI, P483
   Noroozi N, 2016, J VIS COMMUN IMAGE R, V40, P128, DOI 10.1016/j.jvcir.2016.06.014
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Phoulady HA, 2017, COMPUT MED IMAG GRAP, V59, P38, DOI 10.1016/j.compmedimag.2017.06.007
   Ramalho G., 2015, P IEEE ISBI 2 OV CER, P1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabino DMU, 2004, REAL-TIME IMAGING, V10, P205, DOI 10.1016/j.rti.2004.02.007
   Sarwar A., 2015, PERSONALIZED MED UNI, V4, P54, DOI [10.1016/j.pmu.2014.10.001, DOI 10.1016/J.PMU.2014.10.001]
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Szegedy C., ABS160207261 COMP RE
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Tareef A., 2018, IEEE T MED IMAGING, P1
   Ushizima D., 2014, OV CERV CYT IM SEGM, P1
   Ushizima D., 2016, P PYDATA, V1, P1
   Wang B, 2015, INFORM SCIENCES, V302, P132, DOI 10.1016/j.ins.2014.07.028
   Wang XW, 2010, TECHNOL CANCER RES T, V9, P231, DOI 10.1177/153303461000900302
   Watanabe S, 2004, ACTA CYTOL, V48, P505, DOI 10.1159/000326412
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 51
TC 5
Z9 5
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 105
EP 116
DI 10.1016/j.jvcir.2019.04.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600010
OA Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Sriman, B
   Schomaker, L
AF Sriman, Bowornrat
   Schomaker, Lambert
TI Multi-script text versus non-text classification of regions in scene
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Text detection in scene images; Text/non-text classification; Color
   features; Color histogram autocorrelation
ID SCALE; RECOGNITION
AB Text versus non-text region classification is an essential but difficult step in scene-image analysis due to the considerable shape complexity of text and background patterns. There exists a high probability of confusion between background elements and letter parts. This paper proposes a feature-based classification of image blocks using the color autocorrelation histogram (CAH) and the scale-invariant feature transform (SIFT) algorithm, yielding a combined scale and color-invariant feature suitable for scene-text classification. For the evaluation, features were extracted from different color spaces, applying color-histogram autocorrelation. The color features are adjoined with a SIFT descriptor. Parameter tuning is performed and evaluated. For the classification, a standard nearest-neighbor (INN) and a support vector machine (SVM) were compared. The proposed method appears to perform robustly and is especially suitable for Asian scripts such as Kannada and Thai, where urban scene-text fonts are characterized by a high curvature and salient color variations. (C) 2019 Published by Elsevier Inc.
C1 [Sriman, Bowornrat; Schomaker, Lambert] Univ Groningen, Artificial Intelligence, Nijenborgh 9, NL-9747 AG Groningen, Netherlands.
C3 University of Groningen
RP Sriman, B (corresponding author), Univ Groningen, Artificial Intelligence, Nijenborgh 9, NL-9747 AG Groningen, Netherlands.
EM B.Sriman@rug.nl; l.r.b.schomaker@rug.nl
RI Schomaker, Lambert/GYU-5840-2022; Schomaker, Lambert/A-9489-2008
OI Schomaker, Lambert/0000-0003-2351-930X
FU Netherlands Fellowship Programmes (NFP) [CF8777/2013]
FX We sincerely thank the anonymous reviewers for their highly constructive
   feedback to improve this work. This research was supported by
   Netherlands Fellowship Programmes (NFP) Grant No. CF8777/2013. This
   support is gratefully acknowledged.
CR Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Azad P, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4275, DOI 10.1109/IROS.2009.5354611
   Beaudoin N, 2002, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2002.1048189
   Buck JR, 2002, COMPUTER EXPLORATION
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Drews P., 2011, Proceedings of the 2011 9th IEEE International Conference on Industrial Informatics (INDIN 2011), P305, DOI 10.1109/INDIN.2011.6034893
   Farag A. A., 2014, BIOMEDICAL IMAGE ANA
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Goodfellow I.J., 2013, MULTIDIGIT NUMBER RE
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   Jiang RJ, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P819
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0
   Koenderink J. J., 2010, Color for the sciences
   Kwok N. M., 2009, 2009 2nd International Congress on Image and Signal Processing, P1, DOI DOI 10.1109/CISP.2009.5304250
   Lejun G., 2016, CORNER DETECTION BAS, P1069
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucchese L, 2001, IEE P-VIS IMAGE SIGN, V148, P141, DOI 10.1049/ip-vis:20010229
   Alves WAL, 2010, WSCG 2010: FULL PAPERS PROCEEDINGS, P165
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Minetto R, 2014, COMPUT VIS IMAGE UND, V122, P92, DOI 10.1016/j.cviu.2013.10.004
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Salton G, 1986, Introduction to Modern Information Retrieval
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Sriman B., 2015, OBJECT ATTENTION PAT, V1, P304
   Sriman B, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P755, DOI 10.1109/ACPR.2015.7486604
   Tetsu M., 2010, IMAGE CLASSIFICATION, P384, DOI [10.1007/978-3-642-12297-2_37, DOI 10.1007/978-3-642-12297-2_37]
   TORP H, 1994, IEEE T ULTRASON FERR, V41, P604, DOI 10.1109/58.308495
   TROOST JM, 1991, PERCEPT PSYCHOPHYS, V50, P591, DOI 10.3758/BF03207545
   von Goethe JohannWolfgang., 1982, Theory of Colours
   Wang WX, 2015, J INDIAN SOC REMOTE, V43, P501, DOI 10.1007/s12524-014-0432-2
   Wang WX, 2009, J APPL REMOTE SENS, V3, DOI 10.1117/1.3256135
   Wu JC, 2008, MACH VISION APPL, V19, P195, DOI 10.1007/s00138-007-0092-0
   Xu JM, 2014, INT C PATT RECOG, P4714, DOI 10.1109/ICPR.2014.806
   Zhang JunFu Zhang JunFu, 2009, Transactions of the Chinese Society of Agricultural Engineering, V25, P1
   Zhang W., 2016, SENSORS, V16
   Zhu AN, 2015, PATTERN RECOGN LETT, V67, P153, DOI 10.1016/j.patrec.2015.06.009
   Zhu SY, 2016, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2016.74
NR 44
TC 9
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 23
EP 42
DI 10.1016/j.jvcir.2019.04.007
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600003
OA Green Published
DA 2024-07-18
ER

PT J
AU Dai, B
   Wang, YB
   Yao, YY
   Ye, WJ
   Chen, T
AF Dai, Bo
   Wang, Yanbo
   Yao, Yiyang
   Ye, Weijing
   Chen, Ting
TI RETRACTED: Efficient object analysis by leveraging deeply-trained object
   proposals prediction model (Retracted article. See vol. 69, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Video surveillance; Deep model; Object; Moving target detection; Model
   learning
ID SALIENT; SEGMENTATION
AB In this paper, a learned motion target detection algorithm combining background estimation and Bing (binary specification gradient) objects is proposed in video surveillance. A simple background estimation method for detecting rough images of a set of moving foreground objects. The foreground setting in the foreground will estimate another set of candidate window, and the target (pedestrian/vehicle) coming from the cross region comes from the first two steps. In addition, the time cost is reduced by the estimated area. Experiments on outdoor datasets show that this method can not only achieve higher detection rate, but also reduce false positive rate and time overhead. (C) 2019 Published by Elsevier Inc.
C1 [Dai, Bo; Wang, Yanbo; Yao, Yiyang; Ye, Weijing] State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Ting] State Grid Zhejiang Xianju Power Supply Co, Taizhou, Peoples R China.
C3 State Grid Corporation of China
RP Dai, B (corresponding author), State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
RI wangwangwang, yuanyaunyuan/HHN-6432-2022; Wang, Yanbo/HFZ-8018-2022;
   Wang, Ying/HJI-2509-2023; Wang, Yin/HCI-9352-2022; wang,
   yiran/IAP-0414-2023; wang, yan/GSE-6489-2022; Wang, Yuan/HHC-1520-2022;
   wang, yan/JBJ-7462-2023
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2016, ARXIV161001708
   [Anonymous], IEEE C COMP VIS PATT
   Arifin AZ, 2006, PATTERN RECOGN LETT, V27, P1515, DOI 10.1016/j.patrec.2006.02.022
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Bathia H. V. P. K., 2015, EFFICIENT ALGORITHM, V03, P5096
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, IEEE T PATTERN ANAL, V33, P200, DOI 10.1109/TPAMI.2010.138
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding Y., 2013, Local difference pattern based local background modeling for object detection, US, Patent No. [8565482 B2, 8565482]
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Friedman N., 2013, COMPUT SCI, P175
   Gallagher A. C., 2013, US, Patent No. [8386505 B2[P], 8386525]
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Han X., 2015, 5 INT C INSTR MEAS C
   Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889
   Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4
   Held C, 2012, COMPUTER, V45, P83, DOI 10.1109/MC.2012.97
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P1165, DOI 10.1109/TCE.2011.6018870
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Prokhorov D. V., 2014, Method and system for object recognition based on a trainable dynamic system, Patent No. [US8705849, 8705849]
   Razlighi QR, 2011, J REAL-TIME IMAGE PR, V6, P137, DOI 10.1007/s11554-009-0144-y
   Scholkopf B., 2010, GRAPH BASED VISUAL S, P545
   Shi J., 2016, IEEE T PATTERN ANAL, V38, P1
   Shi R, 2012, IEEE SIGNAL PROC LET, V19, P215, DOI 10.1109/LSP.2012.2188388
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang S., 2015, MULTIMED TOOLS APPL, V75, P1
   Zhao D., 2015, IMPROVED BINARIZED N
   Zheng S., 2013, APPROXIMATE STRUCTUR
   2011, IEEE T IMAGE PROCESS, V20, P1709, DOI DOI 10.1109/TIP.2010.2101613
NR 45
TC 3
Z9 3
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 218
EP 224
DI 10.1016/j.jvcir.2019.02.024
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100023
DA 2024-07-18
ER

PT J
AU Zighem, MEN
   Ouafi, A
   Zitouni, A
   Ruichek, Y
   Taleb-Ahmed, A
AF Zighem, Mohammed-En-nadhir
   Ouafi, Abdelkrim
   Zitouni, Athmane
   Ruichek, Yassine
   Taleb-Ahmed, Abdelmalik
TI Two-stages based facial demographic attributes combination for age
   estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Age estimation; Demographic classification; Feature extraction; SVR; SVM
ID GENDER ESTIMATION; CLASSIFICATION; DESCRIPTOR; FEATURES
AB Automatic age estimation from face images is a topic of growing interest nowadays, because of its great value in various applications. The main challenge in automatic facial age estimation task comes from the large intra-class facial appearance variations due to both gender and race attributes. To this end, in this paper we propose a complete approach for age estimation based on demographic classification. The proposed approach consists of three main parts: (1) Automatic face detection and alignment to extract only the regions of interest. (2) Feature extraction from facial region images using Multi-level face representation. (3) Two-Stages age Estimation (TSE). The main idea of TSE is to classify the input face image into one of demographic classes, then estimate age within the identified demographic class. The experimental results demonstrate that our proposed approach can offer better performance for age estimation when compared to the state-of-the-art methods on MORPH-II, PAL and a subset of LFW databases. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zighem, Mohammed-En-nadhir; Ouafi, Abdelkrim; Zitouni, Athmane] Univ Mohamed Khider, Dept Elect Engn, Lab LESIA, POB 145 RP, Biskra, Algeria.
   [Ruichek, Yassine] Univ Bourgogne Franche Comte, Le2i EA7508, UTBM, F-90010 Belfort, France.
   [Taleb-Ahmed, Abdelmalik] UVHC, CNRS, UMR 8520, IEMN,Dept OAE, Valenciennes, France.
C3 Universite Mohamed Khider Biskra; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Universite de Bourgogne; Universite de
   Franche-Comte; Centre National de la Recherche Scientifique (CNRS);
   Universite Polytechnique Hauts-de-France; Universite de Lille; CNRS -
   Institute for Engineering & Systems Sciences (INSIS)
RP Zighem, MEN (corresponding author), Univ Mohamed Khider, Dept Elect Engn, Lab LESIA, POB 145 RP, Biskra, Algeria.
EM zighem25@gmail.com; ou_karim@yahoo.fr; zitou_a@yahoo.fr;
   yassine.ruichek@utbm.fr; Abdelmalik.Taleb-Ahmed@univ-valenciennes.fr
RI Ruichek, Yassine/GRX-3627-2022
OI RUICHEK, Yassine/0000-0003-4795-8569
CR Agrawal SC, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P5, DOI 10.1109/MSPCT.2017.8363882
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, MSUCSE145
   [Anonymous], ACOUSTICS SPEECH AND
   [Anonymous], PATTERN RECOGN
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2009, 2009 IEEE 3 INT C BI, DOI DOI 10.1109/BTAS.2009.5339053
   [Anonymous], APPLICATIONS OF COMP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, COMPUTER VISION PATT
   [Anonymous], SCI WORLD J
   [Anonymous], 2010, Proc. MPVA
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   [Anonymous], 2006, P 14 ANN ACM INT C M
   Bekhouche SE, 2017, EXPERT SYST APPL, V80, P297, DOI 10.1016/j.eswa.2017.03.030
   Bekhouche SE, 2015, 3RD INTERNATIONAL CONFERENCE ON CONTROL, ENGINEERING & INFORMATION TECHNOLOGY (CEIT 2015)
   Carcagnì P, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0089-y
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Choi SE, 2017, EXPERT SYST APPL, V80, P107, DOI 10.1016/j.eswa.2017.03.008
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Dibeklioglu H, 2015, IEEE T IMAGE PROCESS, V24, P1928, DOI 10.1109/TIP.2015.2412377
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fernández C, 2015, LECT NOTES COMPUT SC, V8912, P133, DOI 10.1007/978-3-319-13737-7_12
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Gunay A., 2008, COMPUTER INFORM SCI, P1
   Günay A, 2016, LECT NOTES ELECTR EN, V363, P295, DOI 10.1007/978-3-319-22635-4_27
   Guo G., 2010, IEEE COMP SOC C COMP, P71, DOI DOI 10.1109/CVPRW.2010.5543609
   Guo GH, 2013, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2013-164
   Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Gysel P., 2016, P ICLR
   Hadid A, 2013, NEUROCOMPUTING, V100, P197, DOI 10.1016/j.neucom.2011.10.040
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868
   Huerta I, 2015, PATTERN RECOGN LETT, V68, P239, DOI 10.1016/j.patrec.2015.06.006
   Kang JS, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040108
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liao HB, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1712686
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P1666, DOI 10.1109/TIP.2017.2657118
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Luu K., 2011, P INT JOINT C BIOM, P1
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Mokadem A., 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P88, DOI 10.1109/PSIVT.2010.22
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rodríguez P, 2017, PATTERN RECOGN, V72, P563, DOI 10.1016/j.patcog.2017.06.028
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suo J., 2008, Automatic Face and Gesture Recognition, P1
   Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77
   Weng RL, 2016, IEEE T MULTIMEDIA, V18, P2066, DOI 10.1109/TMM.2016.2591508
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P267, DOI 10.1109/ICCVW.2015.43
NR 72
TC 18
Z9 18
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 236
EP 249
DI 10.1016/j.jvcir.2019.03.025
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100025
DA 2024-07-18
ER

PT J
AU Cai, W
   Wen, XD
   Wang, SS
   Wang, LJ
AF Cai, Wei
   Wen, Xiaodong
   Wang, Saisai
   Wang, Lijuan
TI A real-time detection method of building energy efficiency based on
   image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Building energy efficiency; Image processing; Air tightness; Heat
   transfer coefficient
ID IN-SITU CALIBRATION; OBJECT DETECTION; DEEP
AB In recent years, with the rapid development of economy and the acceleration of urbanization process, building energy consumption has become an urgent problem to be solved. Its total energy consumption shows a trend of sustained growth, and the growth rate is faster and faster, so the requirements of building energy efficiency detection technology are higher and higher. Aiming at the problems of time-consuming and difficult detection of traditional detection methods, this paper introduces infrared image processing technology and proposes an energy-saving detection method for buildings based on image processing. The air tightness and heat transfer coefficient are studied respectively. Firstly, the feasibility of infrared method to detect air tightness is theoretically analyzed, and the corresponding technical scheme and detection process are given. Secondly, the infrared image is grayed and filtered to eliminate the influence of thermal defect area on the calculation of heat transfer coefficient after eliminating interference noise. Finally, based on the one-dimensional steady heat transfer theory, the principle of quantitative detection of heat transfer coefficient in infrared image is given by studying the heat transfer process of the wall, and the related correction method is designed. The feasibility and superiority of this method are illustrated by an example. Therefore, this method has good application prospects in building energy-saving detection. (C) 2019 Published by Elsevier Inc.
C1 [Cai, Wei; Wang, Lijuan] Ningbo Univ Technol, Sch Civil & Transportat Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Wen, Xiaodong; Wang, Saisai] Ningbo Univ Technol, Inst Durabil Concrete Struct, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University of Technology; Ningbo University of Technology
RP Cai, W (corresponding author), Ningbo Univ Technol, Sch Civil & Transportat Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM caiwei@nbut.edu.cn; wenxiaodong@nbut.cn; wss@nbut.edu.cn
RI Yin, Jing/KDO-6274-2024
FU Zhejiang Provincial Natural Science Foundation of China [LY15E080016,
   Y16E080033]; Beijing Key Lab of Heating, Gas Supply, Ventilating and Air
   Conditioning Engineering [NR2015K07]; Ningbo Natural Science Foundation
   [2016A610113]
FX This research was supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant Nos. LY15E080016 and Y16E080033, and
   funded by Beijing Key Lab of Heating, Gas Supply, Ventilating and Air
   Conditioning Engineering (No. NR2015K07). Programs supported by Ningbo
   Natural Science Foundation (No. 2016A610113). We are appreciative of the
   anonymous reviewers' constructive comments, which have resulted in great
   improvements in this manuscript.
CR Aditya L, 2017, RENEW SUST ENERG REV, V73, P1352, DOI 10.1016/j.rser.2017.02.034
   Bushinsky SM, 2013, MAR CHEM, V155, P22, DOI 10.1016/j.marchem.2013.05.001
   Calmels  L., 2018, PHYS REV B, V76, P3009
   Chaston CC, 2014, GEOPHYS RES LETT, V41, P8185, DOI 10.1002/2014GL062116
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dennenwaldt  T., 2017, MICROSC MICROANAL, V23, P2154
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hossain S, 2016, CAN J ELECT COMPUT E, V39, P219, DOI 10.1109/CJECE.2016.2541661
   KLAUSNER JF, 1993, INT J HEAT MASS TRAN, V36, P651, DOI 10.1016/0017-9310(93)80041-R
   LAWSON RD, 1957, PHYS REV, V108, P1300, DOI 10.1103/PhysRev.108.1300
   [李孟 Li Meng], 2013, [红外技术, Infrared Technology], V35, P567
   Lingyan Han, 2015, Advanced Materials Research, V1092-1093, P545, DOI 10.4028/www.scientific.net/AMR.1092-1093.545
   Makhmalbaf MHM, 2012, HEAT MASS TRANSFER, V48, P1023, DOI 10.1007/s00231-011-0951-0
   Malusek A, 2014, PHYS MED BIOL, V59, P7195, DOI 10.1088/0031-9155/59/23/7195
   Moschet C, 2015, WATER RES, V71, P306, DOI 10.1016/j.watres.2014.12.043
   Ram ST, 2016, J GEOPHYS RES-SPACE, V121, P538, DOI 10.1002/2015JA021932
   Rathsman B. G., 1954, POWER APPARATUS SY 3, V73, P1037
   Raviv G, 2017, SAFETY SCI, V91, P298, DOI 10.1016/j.ssci.2016.08.027
   RIAZ T, 1987, ENERG ECON, V9, P195, DOI 10.1016/0140-9883(87)90027-2
   Sengul  T., 2017, COMMUN PUR APPL ANAL, V13, P2609
   Siriwitpreecha A, 2013, INT J HEAT MASS TRAN, V65, P423, DOI 10.1016/j.ijheatmasstransfer.2013.06.015
   Wang FJ, 2017, IEEE T VLSI SYST, V25, P1164, DOI 10.1109/TVLSI.2016.2620460
   [杨勇 YANG Yong], 2011, [电子学报, Acta Electronica Sinica], V39, P1894
   Ye J., 2015, CHIN REFRACT, V24, P12
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   [章雪挺 Zhang Xueting], 2014, [仪器仪表学报, Chinese Journal of Scientific Instrument], V35, P1497
   Zhang Yining, 2016, Journal of Applied Optics, V37, P288, DOI 10.5768/JAO201637.0206001
NR 36
TC 9
Z9 9
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 295
EP 304
DI 10.1016/j.jvcir.2019.02.032
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000032
DA 2024-07-18
ER

PT J
AU Liu, MF
   Guan, WL
   Yan, J
   Hu, HJ
AF Liu, Maofu
   Guan, Weili
   Yan, Jie
   Hu, Huijun
TI Correlation identification in multimodal weibo via back propagation
   neural network with genetic algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimodal weibo; Correlation classification model; Back propagation;
   Genetic algorithm; GA-BP
AB The rapid development of social media services has spawned abundant user generated contents (UGC), such as Sina Weibo, which is one of the biggest Chinese microblogging platforms. In order to enhance the quality and popularity of the posted weibo (the microblog), Weibo users usually embed some social information and images or micro-videos, namely the multimodal weibo, and we assume that there is a close correlation among the multimodal weibo data, especially between the visual data (image/microvideo) and its corresponding text, for a multimodal weibo of high quality. Hence, we try to evaluate the quality of multimodal weibo via analyzing the correlation in the multimodal weibo. This paper constructs the classification model based on back propagation (BP) neural network with genetic algorithm (GA), to automatically identify the correlation within the multimodal weibo, and investigates three kinds of features from multimodal weibo to uncover their contributions to the correlation. The experimental results verify the superiority of the GA-BP based classification model over the traditional BP neural network. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Maofu; Yan, Jie; Hu, Huijun] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
   [Guan, Weili] Hewlett Packard Enterprise Singapore, Singapore 117417, Singapore.
C3 Wuhan University of Science & Technology
RP Hu, HJ (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
EM liumaofu@wust.edu.cn; huhuijun@wust.edu.cn
CR [Anonymous], 2016, ACM MULTIMEDIA
   [Anonymous], 2010, P 2010 43 HAWAII INT, DOI [DOI 10.1353/JSM.2016.0009, DOI 10.1109/HICSS.2010.412]
   [Anonymous], 2013, INT C LEARN REPR ICL
   Asur S., 2011, COMPUT SCI
   Bazzi Tony, 2016, International Journal of Computer and Information Technology, V5, P359
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cha  M., 2010, ICWSM, P10
   Chen T., 2013, P 21 ACM INT C MULT, P781, DOI [DOI 10.1145/2502081.2502203, 10.1145/2502081, DOI 10.1145/2502081]
   Chen T, 2015, AAAI CONF ARTIF INTE, P30
   Fagerland MW, 2016, J STAT COMPUT SIM, V86, P3398, DOI 10.1080/00949655.2016.1156682
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Honeycutt C., 2009, Beyond microblogging: Conversation and collaboration via twitter, P1, DOI [DOI 10.1109/HICSS.2009.89, 10.1109/HICSS.2009.602, DOI 10.1109/HICSS.2009.602]
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Liu MF, 2017, COMPUT VIS IMAGE UND, V163, P58, DOI 10.1016/j.cviu.2017.04.012
   Liu M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P970, DOI 10.1145/3123266.3123341
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Mohammadi-Nejad AR, 2016, I S BIOMED IMAGING, P820, DOI 10.1109/ISBI.2016.7493392
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Sriram B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/1835449.1835643
   Suh Bongwon, 2010, 2010 IEEE 2 INT C SO, P177, DOI DOI 10.1109/SOCIALCOM.2010.33
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Yang L., 2016, INT J DATABASE THEOR, V9, P167
   Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331
   Zhao Xun., 2013, SEMANTIC WEB WEB SCI, P55, DOI [10.1007/978-1-4614-6880-6_5, DOI 10.1007/978-1-4614-6880-6_5]
NR 30
TC 15
Z9 16
U1 1
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 312
EP 318
DI 10.1016/j.jvcir.2019.02.015
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000034
DA 2024-07-18
ER

PT J
AU Tu, B
   Kuang, WL
   Shang, YH
   He, DB
   Zhao, L
AF Tu, Bing
   Kuang, Wenlan
   Shang, Yongheng
   He, Danbing
   Zhao, Lin
TI A multi-view object tracking using triplet model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; BING feature; Triplet model
AB Object tracking is very important in intelligent systems, such as video surveillance, automatic drive and traffic security. Background subtraction algorithm is a mature method for foreground object extraction, but it may be affected by complicated background or the change of object shape. So in this paper, a novel object tracking method is proposed using a triplet model. First, BING feature is used to find some potential object proposals. Then, we construct a triplet model for each potential object. The triplet of the same object between two consecutive frames is considered similar. Finally, object tracking can be achieved by computing feature difference of triplets. Experimental results show that our method can achieve object tracking effectively and in real time. (C) 2019 Published by Elsevier Inc.
C1 [Tu, Bing; Kuang, Wenlan; He, Danbing; Zhao, Lin] Hunan Inst Sci & Technol, Coll Informat & Commun Engn, Yueyang 414006, Peoples R China.
   [Shang, Yongheng] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou, Zhejiang, Peoples R China.
C3 Hunan Institute of Science & Technology; Zhejiang University
RP Tu, B (corresponding author), Hunan Inst Sci & Technol, Coll Informat & Commun Engn, Yueyang 414006, Peoples R China.
FU National Natural Science Foundation of China [51704115]; Key Laboratory
   Open Fund Project of Hunan Province University [17K040, 15K051]; Science
   and Technology Program of Hunan Province [2016TP1021]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 51704115, by the Key Laboratory Open Fund Project of
   Hunan Province University under Grant 17K040 and 15K051, by the Science
   and Technology Program of Hunan Province under Grant 2016TP1021.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2016, ARXIV161001708
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
NR 19
TC 5
Z9 5
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 64
EP 68
DI 10.1016/j.jvcir.2019.01.032
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000009
DA 2024-07-18
ER

PT J
AU Zhang, Y
AF Zhang, Ya
TI Research on key technologies of remote design of mechanical products
   based on artificial intelligence
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Artificial intelligence; Machinery; Remote design; Image processing
ID OBJECT DETECTION; DEEP
AB With the development of information technology, mechanical product design has become an important part of the enterprise and design community. In the traditional mechanical design process, the product not only has performance requirements, but also has many economic requirements such as manufacturing cost and sales profit. Many conditions also have great uncertainty. In addition, in design and evaluation, in addition to the existing theoretical analysis, in most cases, it is mainly judged based on the designer's experience. In view of the deficiencies in mechanical design, this paper proposes a key technology research of remote design of mechanical products based on artificial intelligence. The wireless communication technology is used to build a client/server wireless communication platform, which is convenient for designers to transmit remote information. The application of image processing and pattern recognition technology to target the components involved in mechanical products helps designers grasp many parameters of mechanical products. The research on the key technology of remote design of mechanical products based on artificial intelligence in this paper has certain reference value for the application of artificial intelligence technology in the field of mechanical product design with insufficient knowledge. (C) 2019 Published by Elsevier Inc.
C1 [Zhang, Ya] Zhejiang Univ Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Science & Technology
RP Zhang, Y (corresponding author), Zhejiang Univ Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM 116015@zust.edu.cn
RI Azonnoudo, Seyido/ISU-7505-2023
FU Startup Foundation of Zhejiang University of Science and Technology
   [F701102H02]
FX This work was financially supported by Startup Foundation of Zhejiang
   University of Science and Technology (F701102H02).
CR [Anonymous], 2004, RES REM DES SYST BRI
   Chen Xiaofang, 2014, ELECT TECHNOL SOFTW, V4, P89
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Ganzhou Y. E., 2010, SCI TECHNOL INFORM, V15, P138
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huo Weiying, 2013, DISCUSSION REMOTE ME, V32, P314
   Kang Peng, 2006, SHANXI COMMUN SCI TE, V5, P78
   Li Xiating, 2012, WIREL INTERCONN TECH, V3, P64
   Lin Lili, 2016, SCI TECHNOL OUTL, P26
   Liu Junxia, 2016, COMPUTER FAN
   Liu Yazhen, 2008, SCI TECHNOL INFORM S, V14, P290
   Luo H., 2017, ELECTR WORLD, V21, P21
   Ma Hongzhong, 2007, MOTOR CONDITION MONI, P214
   Qi Kelun, 2009, FIELD EQUIPMENT FAUL, P35
   Su Peihua, 2012, ELECTR WORLD, V14, P76
   Wang Li, 2017, Science & Technology Review, V35, P15, DOI 10.3981/j.issn.1000-7857.2017.15.001
   Wang Wenzhong, 2005, MECH DES MANUF, V12, P75
   Wang Xingwang, 2017, J PRACT DERMATOL, V3, P141, DOI DOI 10.1007/s10584-016-1843-6
   Wei Zhe, 2017, CHIN MED EQUIPM, V14, P142
   Xu C. S., 1995, INSTR MEAS TECHN C
   Xu Zhiwei, 2014, LAB TECHNOL MANAGE, V1, P201
   Yan Lei, 2013, BIG SCI SCI MYST, V21, P309
   Yu Jiguang, 2012, DESIGN IMPLEMENTATIO
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang Haixia, 2000, J TSINGHUA U NAT SCI, V40, P100
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang Xiaoli, 2005, LIFTING TRANSPORT MA
   Zhong Ming, 1999, RES APPL ARTIFICIAL
   Zhu Minhui, 2017, AUTOMOB ACCESS, V17, P4
   Zong Mingcheng, 1998, NONDESTR TEST, V20, P71
NR 38
TC 8
Z9 9
U1 5
U2 44
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 250
EP 257
DI 10.1016/j.jvcir.2019.02.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000027
DA 2024-07-18
ER

PT J
AU Du, L
   Zhang, W
   Fu, HZ
   Ren, WQ
   Zhang, XP
AF Du, Ling
   Zhang, Wei
   Fu, Huazhu
   Ren, Wenqi
   Zhang, Xinpeng
TI An efficient privacy protection scheme for data security in video
   surveillance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Privacy protection; Data security; Video surveillance
ID AUTOMATIC FACE SEGMENTATION
AB The advancement in video surveillance has raised significant concerns about privacy protection. The existing methods focus on identifying the sensitive region and preserving the behavior of the target, however, they ignore the recoverability of private content. In this paper, we propose a novel and efficient privacy protection scheme for data security in video surveillance, which jointly addresses several key challenges, including de-identification, behavior preservation, recoverability, and compressibility in one unified system. Our method constructs a public stream and a private residual error stream by blurring the private sensitive region. With our scheme, ordinary users could recognize the behaviors in the public identity-protected video stream for surveillance purpose, while authorized users are able to access the recovered private content (e.g., for law investigations). Moreover, the compressed privacy protected region and residual error could be able to save the costs associated with transmission and storage. The extensive experiments on two standard surveillance datasets and a user study demonstrate the effectiveness of our privacy protection system. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Du, Ling] Tianjin Polytech Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
   [Zhang, Wei] JD AI Res, Beijing, Peoples R China.
   [Fu, Huazhu] ASTAR, Singapore, Singapore.
   [Ren, Wenqi] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Zhang, Xinpeng] Fudan Univ, Sch Comp Sci & Technol, Shanghai 200433, Peoples R China.
C3 Tiangong University; Agency for Science Technology & Research (A*STAR);
   Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Fudan University
RP Du, L (corresponding author), Tianjin Polytech Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
EM duling@tjpu.edu.cn
RI Wang, Meng/ITR-8699-2023; Ren, Wenqi/L-8724-2019; Zhang,
   Wayne/AAF-3407-2019; Fu, Huazhu/A-1411-2014
OI Fu, Huazhu/0000-0002-9702-5524
FU Science&Technology Development Fund of Tianjin Education Commission for
   Higher Education, China [2017KJ091]
FX This research was supported by the Science&Technology Development Fund
   of Tianjin Education Commission for Higher Education, China (Grant No.
   2017KJ091).
CR Agarwal P, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671954.1671956
   Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551
   [Anonymous], 2013, 18 INT C DIG SIGN PR
   [Anonymous], P INT C AUT FAC GEST
   [Anonymous], 6 INT WORKSH QUAL MU
   BENALOH JC, 1987, LECT NOTES COMPUT SC, V263, P251
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cao  X., 2014, IEEE CHIN SUMM INT C
   Chan AB, 2009, IEEE T PATTERN ANAL, V31, P1862, DOI 10.1109/TPAMI.2009.110
   Chen DT, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/75427
   Cheng XG, 2011, IEEE T MULTIMEDIA, V13, P1333, DOI 10.1109/TMM.2011.2167222
   Dong Li, 2016, 2016 12th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN). Proceedings, P365, DOI 10.1109/MSN.2016.066
   Du L, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P80, DOI 10.1109/SPAC.2014.6982661
   Dufaux F., 2006, SPIE MOBILE MULTIMED, V6250, P1
   Erdelyi  A., 2014, P MEDIAEVAL 2014 WOR
   Erdélyi A, 2018, MULTIMED TOOLS APPL, V77, P2285, DOI 10.1007/s11042-016-4337-7
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gharat  A., 2013, INT J ADV RES COMPUT, V2, P180
   Hong SX, 2017, IEEE ACCESS, V5, P6515, DOI 10.1109/ACCESS.2017.2695561
   Jaha ES, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Korshunov  P., SPIE APPL DIGITAL IM, V8856
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XJ, 2017, IEEE T CLOUD COMPUT, V5, P510, DOI 10.1109/TCC.2015.2469651
   Ma XJ, 2016, IEEE T EMERG TOP COM, V4, P349, DOI 10.1109/TETC.2015.2460462
   Martin K, 2008, IEEE T CIRC SYST VID, V18, P1152, DOI 10.1109/TCSVT.2008.927110
   Martinez-Ponte I., 2005, INT WORKSH IM AN MUL
   Naor  M., ADV CRYPTOLOGY EUROC
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Peng F, 2013, IEEE T INF FOREN SEC, V8, P1688, DOI 10.1109/TIFS.2013.2259819
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Ruchaud N, 2016, IEEE INT CONF MULTI
   Samuel A, 2015, IEEE T MULTIMEDIA, V17, P1484, DOI 10.1109/TMM.2015.2458299
   Schaffer M, 2005, LECT NOTES COMPUT SC, V3677, P140
   Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84
   Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sznitman R, 2010, IEEE T PATTERN ANAL, V32, P1914, DOI 10.1109/TPAMI.2010.106
   Tansuriyavong S., 2001, PROC WORKSHOP PERCEP, V4, P1
   Thorpe C, 2013, IEEE T PATTERN ANAL, V35, P3066, DOI 10.1109/TPAMI.2013.161
   Upmanyu M, 2009, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2009.5459370
   Wang HZ, 2006, LECT NOTES COMPUT SC, V3851, P328
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler T., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P593, DOI 10.1109/AVSS.2010.38
   Winkler T, 2012, MULTIMEDIA SYST, V18, P99, DOI 10.1007/s00530-011-0241-1
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang  W., 2005, INT C IM PROC
   Zhang X, 2018, IEEE ACCESS, V6, P18074, DOI 10.1109/ACCESS.2018.2820724
   Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 57
TC 23
Z9 25
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 347
EP 362
DI 10.1016/j.jvcir.2019.01.027
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600036
DA 2024-07-18
ER

PT J
AU Li, JT
   Jia, BS
   Zhang, CH
   Wang, W
AF Li, Jiangtao
   Jia, Baoshan
   Zhang, Chunhua
   Wang, Wei
TI Seepage mechanism technical practice of hydraulic fracturing of coal
   seam and auxiliary image simulation technology
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gas extraction; Coal seam permeability enhancement; Sublevel hydraulic
   fracturing; Fracturing equipment; Auxiliary image technology
ID OBJECT DETECTION
AB A new method of fracturing hydraulic fracturing is proposed for the characteristics of poor coal permeability and soft coal in coal mine area in China. This method can make the hydraulic pressure concentrated on the coal at one point, and the water pressure is reduced, Effective water pressure increases, the smaller the flow that can get a better fracture effect. Through the numerical simulation, the law of fracture distribution and permeability evolution during segmental hydraulic fracturing is analyzed. Complete sets of anti-reflection equipment for segmented hydraulic fracturing have been developed, which is mainly composed of mobile high-pressure pump station, high-pressure rubber hose, water injector, putters and corresponding connecting parts. It solves the problem of tightness of hydraulic fracturing device, and breaks through the problem of miniaturization of high pressure pumping station, so that the high pressure pumping station can achieve larger working pressure at smaller flow rate. The whole process is simulated and validated by assistant image simulation technology, and applied to Pansidong Coal Mine of Huainan Mining Group. The industrial test of hydraulic directional fracturing of Pan coal mine in Huainan mining group shows that the loose influence range of coal can reach 10 m, and the pressure of underground movable high pressure hydraulic pumping station reaches 25 MPa, and the flow rate is 180 L/min. Compared with non fracturing drilling, drilling, the average gas concentration after fracturing, the average daily average flow rate of mixed gas drainage quantity is improved significantly, the application effect is good, and the equipment is simple, easy to use, can be repeatedly used, and has better economic benefit and application prospect. (C) 2019 Published by Elsevier Inc.
C1 [Li, Jiangtao] Northeastern Univ, Sch Resources & Civil Engn, Shenyang 110004, Liaoning, Peoples R China.
   [Jia, Baoshan; Zhang, Chunhua; Wang, Wei] Liaoning Tech Univ, Sch Safety Sci & Engn, Fuxin 723000, Peoples R China.
   [Li, Jiangtao] CCTEG Shenyang Res Inst, Shenyang 110016, Liaoning, Peoples R China.
C3 Northeastern University - China; Liaoning Technical University
RP Jia, BS (corresponding author), Liaoning Tech Univ, Sch Safety Sci & Engn, Fuxin 723000, Peoples R China.
EM jbs1972@126.com
RI jiangtao, li/HTL-7510-2023; zhang, cl/JDW-6549-2023; zhang,
   chunmei/IUQ-7038-2023; Zhang, Chun/GRE-8915-2022
FU National Science and Technology Key Program of large oil and gas field
   and CBM development in 13th Five-year Period Plan [2016ZX05045-004-001]
FX Project supported by National Science and Technology Key Program of
   large oil and gas field and CBM development in 13th Five-year Period
   Plan (Grant No. 2016ZX05045-004-001)
CR Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   [段康廉 Duan Kanglian], 2002, [煤炭学报, Journal of China Coal Society], V27, P50
   [富向 FU Xiang], 2011, [煤炭学报, Journal of China Coal Society], V36, P1317
   Guo BH, 2010, ROCK SOIL MECH, V31, P1965
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang BX, 2011, J MIN SAFE ENG, V28, P167
   Jiang Wenzhong, 2009, J LIAONING TU NATURA, V28, P93
   [李晓红 LI Xiao-hong], 2008, [煤炭学报, Journal of China Coal Society], V33, P1386
   Li Xuechen, 2006, J HENAN POLYTECH U, V25, P270
   Lin B.Q., 2011, J MIN SAFE ENG, V28, P452
   Lin Tong, 1997, NATURAL GAS IND, V17, P53
   Lu P, 2015, INT J COAL SCI TECHN, V2, P84, DOI DOI 10.1007/S40789-015-0061-6
   Martynyuk PA, 2008, J MIN SCI+, V44, P544, DOI 10.1007/s10913-008-0061-7
   Mu CM, 2013, ROCK SOIL MECH, V34, P2496
   [唐书恒 Tang Shuheng], 2011, [煤炭学报, Journal of China Coal Society], V36, P65
   Wang Kuijun, 2012, Patent No. [CN102704905A, 102704905]
   Yan S., 2000, Journal of China Coal Society, V25, P32
   [杨宏伟 Yang Hongwei], 2012, [北京科技大学学报, Journal of University Science and Technology Beijing], V34, P1235
   Yang Tianhong, 2004, THEORY MODEL APPL
   [袁亮 Yuan Liang], 2016, [煤炭学报, Journal of China Coal Society], V41, P1
   [袁亮 YUAN Liang], 2008, [岩石力学与工程学报, Chinese Journal of Rock Mechanics and Engineering], V27, P1370
   [翟成 Zhai Cheng], 2011, [煤炭学报, Journal of China Coal Society], V36, P1996
   Zhang C.H., 2009, Coal Sci. Technol., V37, P49, DOI [10.13199/j.cst.2009.08.54.zhangchh.027, DOI 10.13199/J.CST.2009.08.54.ZHANGCHH.027]
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang Guohua, 2004, STUDY FRACTURE MECH
   Zhang L., P IEEE C COMP VIS PA, P1908
   Zhang Lin, 2008, J COAL SCI, V33, P323
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   [张明杰 Zhang Mingjie], 2015, [安全与环境学报, Journal of Safety and Environment], V15, P39
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zou Zhongyou, 2000, COAL MINE SAFETY, P34
NR 36
TC 7
Z9 7
U1 3
U2 49
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 244
EP 252
DI 10.1016/j.jvcir.2019.01.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600025
DA 2024-07-18
ER

PT J
AU Wu, XT
   Chen, D
   Yang, CN
   Yang, YY
AF Wu, Xiaotian
   Chen, Dong
   Yang, Ching-Nung
   Yang, Yi-Yun
TI A (<i>k</i>, <i>n</i>) threshold partial reversible AMBTC-based visual
   cryptography using one reference image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Block truncation coding; Partial reversible;
   Meaningful share; Contrast; Reference image
ID SECRET SHARING SCHEMES; GENERAL ACCESS STRUCTURES; EXTENDED
   CAPABILITIES; ABILITIES; QUALITY
AB Recently, Yang et al. introduced a (k; n) approach called Reversible Absolute moment block truncation coding Visual Cryptography Scheme (RAVCS) (Yang et al., 2017) to conceal a secret image into n AMBTC shares. However, a large number of reference images is used in their method. To reduce the number of reference images, a (k; n) PRAVCS using one AMBTC reference image is introduced. In encoding phase, a binary secret image is shared into n AMBTC shadow images according to the base matrices generated by two proposed constructions. In decoding phase, the secret image is recovered by stacking sufficient bitmaps, and the AMBTC reference image is partially recovered as well. When n AMBTC shares are used, losslessly reconstruction for the reference image is obtained. Theoretical analysis and experiments by the proposed method are demonstrated to show the effectiveness. Moreover, Construction 1 has larger contrast, while Construction 2 achieves higher reversibility for more thresholds. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wu, Xiaotian; Chen, Dong] Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Wu, Xiaotian] Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Wu, Xiaotian] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Yang, Ching-Nung; Yang, Yi-Yun] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Shoufeng Township, Taiwan.
C3 Jinan University; Nanjing University of Information Science &
   Technology; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS; National Dong Hwa University
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.; Wu, XT (corresponding author), Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.; Wu, XT (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
EM wxt.sysu@gmail.com
RI Yang, Ching-Nung/HKV-1639-2023
OI Wu, Xiaotian/0000-0002-1484-2247
FU National Natural Science Foundation of China [61602211]; Science and
   Technology Program of Guangzhou, China [201707010259]; Fundamental
   Research Funds for the Central Universities; Ministry of Science and
   Technology [107-2221-E-259-007]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant No. 61602211), Science and Technology Program of
   Guangzhou, China (Grant No. 201707010259), Fundamental Research Funds
   for the Central Universities and Ministry of Science and Technology,
   under Grant 107-2221-E-259-007.
CR Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blaldey G. R., 1979, P NAT COMP C, V88, P317
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2006, THEOR COMPUT SCI, V369, P169, DOI 10.1016/j.tcs.2006.08.008
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ou DH, 2014, J VIS COMMUN IMAGE R, V25, P1222, DOI 10.1016/j.jvcir.2013.12.018
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
   Yang CN, 2008, COMPUT J, V51, P710, DOI 10.1093/comjnl/bxm118
   Yang CN, 2017, J VIS COMMUN IMAGE R, V48, P182, DOI 10.1016/j.jvcir.2017.06.012
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2005, PATTERN RECOGN LETT, V26, P193, DOI 10.1016/j.patrec.2004.08.025
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 32
TC 7
Z9 7
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 550
EP 562
DI 10.1016/j.jvcir.2019.02.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600057
DA 2024-07-18
ER

PT J
AU Chen, XM
   Chen, ZB
   Li, Y
   He, TY
   Hou, JH
   Liu, S
   He, Y
AF Chen, Xiaoming
   Chen, Zhibo
   Li, Ye
   He, Tianyu
   Hou, Junhui
   Liu, Sen
   He, Ying
TI ImmerTai: Immersive Motion Learning in VR Environments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Immersive education; Motion training; VR education
ID VIRTUAL ENVIRONMENTS; SYSTEM
AB Immersive learning in Virtual Reality (VR) environments is the developing trend for future education systems including remote physical training. This paper presents "ImmerTai", a system that is designed for effective remote motion training, particularly for Chinese Taichi, in an immersive way. With ImmerTai, the Taichi expert's motion is captured and delivered to remote students in CAVE, HMD and PC environments for learning. The students' motions are also captured for motion quality assessment and a group of students can form a virtual collaborative learning scenario. We built up a Taichi motion dataset with ground truth of motion quality, and based on this, we developed and evaluated several motion quality assessment methods. Then, user tests were designed and carried out to measure and compare the learning outcomes (learning time, quality and overall efficiency) of students in Cave Automatic Virtual Environment (CAVE), Head Mounted Display (HMD) and Personal Computer (PC) environments. Meanwhile, the connections between students' learning outcomes and their VR experience were investigated and discussed too. Our results show that ImmerTai can accelerate the learning process of students noticeably (up to 17%) compared to non-immersive learning with the conventional PC setup. However, we observed a substantial difference in the quality of the learnt motion between CAVE (26% gain) and HMD (23% drop) compared to PC (baseline). While strong VR presence can enhance the learning experience of students, their learning outcomes are not fully consistent to their experience. Overall, ImmerTai with CAVE demonstrated a significantly higher learning efficiency than other tested environments. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chen, Xiaoming; Chen, Zhibo; Li, Ye; He, Tianyu; Liu, Sen] Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
   [Hou, Junhui] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Chen, Xiaoming] Univ Sci & Technol China, Inst Adv Technol, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; City University of Hong Kong; Nanyang Technological
   University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Chen, ZB (corresponding author), Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
EM chenzhibo@ustc.edu.cn; hetianyu@mail.ustc.edu.cn; elsen@iat.ustc.edu.cn
RI He, Ying/A-3708-2011; Chen, Zhibo/T-5349-2019
OI He, Ying/0000-0002-6749-4485; Chen, Zhibo/0000-0002-8525-5066; Chen,
   Xiaoming/0000-0002-7503-3021; He, Tianyu/0000-0002-4828-3228; Hou,
   Junhui/0000-0003-3431-2021
FU National Key Research and Development Program of China [2016YFC0801001];
   National Program on Key Basic Research Projects (973 Program)
   [2015CB351803]; NSFC [61571413, 61632001, 61390514]; Scientific and
   Technological Project Grant by the Ministry of Human Resources and
   Social Security of China; Department of Human Resources and Social
   Security of Anhui Province, China
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant No. 2016YFC0801001, the
   National Program on Key Basic Research Projects (973 Program) under
   Grant 2015CB351803, NSFC under Grant 61571413, 61632001, 61390514, and
   Scientific and Technological Project Grant offered by the Ministry of
   Human Resources and Social Security of China and the Department of Human
   Resources and Social Security of Anhui Province, China.
CR Alexiadis DS, 2014, IEEE T MULTIMEDIA, V16, P1391, DOI 10.1109/TMM.2014.2317311
   [Anonymous], 2006, 3 INT FORUM APPL WEA
   Bian YL, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P433, DOI 10.1145/2858036.2858351
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Chew BS, 2011, IEEE T MULTIMEDIA, V13, P40, DOI 10.1109/TMM.2010.2082512
   Chua PT, 2003, P IEEE VIRT REAL ANN, P87
   Paiva PVD, 2015, SYMP VIRTUAL AUGMENT, P176, DOI 10.1109/SVR.2015.33
   Girden E.R., 1992, ANOVA: Repeated Measures, V84
   Günther T, 2015, P IEEE VIRT REAL ANN, P327
   Hachimura K, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P217, DOI 10.1109/ROMAN.2004.1374759
   He TY, 2017, P IEEE VIRT REAL ANN, P307, DOI 10.1109/VR.2017.7892299
   Horváth I, 2016, INT CONF COGN INFO, P359, DOI 10.1109/CogInfoCom.2016.7804576
   Hou JH, 2013, IEEE IMAGE PROC, P709, DOI 10.1109/ICIP.2013.6738146
   Hou Junhui., 2014, 2014 IEEE International Conference on Multimedia and Expo (ICME), P1
   Hu F, 2017, IEEE T SYST MAN CY-S, V47, P347, DOI 10.1109/TSMC.2016.2560127
   Hu XQ, 2016, 2016 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET), P53, DOI 10.1109/ISET.2016.15
   Jung Sang-Hack, 2006, 4 IEEE INT C COMP VI, P5
   Kadu H, 2014, IEEE T MULTIMEDIA, V16, P2191, DOI 10.1109/TMM.2014.2360793
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Kurillo G, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P269
   Li M, 2016, IEEE T MULTIMEDIA, V18, P2293, DOI 10.1109/TMM.2016.2614228
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Patel Kayur u. a., 2006, P PRESENCE 2006 9 AN
   Pei W, 2016, INT CONF UBIQ ROBOT, P353, DOI 10.1109/URAI.2016.7734059
   Pham MT, 2010, IEEE ENG MED BIO, P6345, DOI 10.1109/IEMBS.2010.5627632
   Rammer JR, 2014, IEEE ENG MED BIO, P2525, DOI 10.1109/EMBC.2014.6944136
   Serikali Mfundishi Obuabasa, 2006, AFRIASIAN RESOURCE H
   Sun C, 2011, COMPUT GRAPH FORUM, V30, P1953, DOI 10.1111/j.1467-8659.2011.02048.x
   Tan CH, 2015, VISUAL COMPUT, V31, P1521, DOI 10.1007/s00371-014-1031-5
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang UY, 2002, PRESENCE-VIRTUAL AUG, V11, P304, DOI 10.1162/105474602317473240
   Yang ZY, 2006, IEEE INT SYM MULTIM, P177
   Yougui Lin, 2010, 2010 IEEE 11th International Conference on Computer-Aided Industrial Design & Conceptual Design (CAIDCD 2010), P1149, DOI 10.1109/CAIDCD.2010.5681865
   Zhang S, 2011, C IND ELECT APPL, P1993, DOI 10.1109/ICIEA.2011.5975919
   Zhu HM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1082, DOI 10.1109/ICInfA.2013.6720456
NR 36
TC 32
Z9 35
U1 2
U2 57
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 416
EP 427
DI 10.1016/j.jvcir.2018.11.039
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100041
DA 2024-07-18
ER

PT J
AU Chiang, PY
   Chen, CC
   Hsia, CH
AF Chiang, Pei-Ying
   Chen, Chun-Chi
   Hsia, Chih-Hsien
TI A touchless interaction interface for observing medical imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Touch less; Volume rendering; Focus and context; Visualization; Medical
   imaging
AB Using volume rendering to generate 3D models is associated with the problem of missing features on areas of interest, which are possibly concealed by other information. This article presents a novel focus-and-context medical imaging observation system using gesture-based technique to build a touchless interactive environment. The system offers two types of medical imaging observation tool, namely, 3D section cutting tool and 3-axes cross-section synchronization tool, enabling users to quickly and easily observe tissue sections. Feature classification was achieved using region growing and size-based transfer approaches. Combined with view penetration function (cylinder and cone view penetration functions), the system allows for direct observation of hidden features. The analytical experimental results verified that the proposed system is easy to operate in a touchless environment and creates positive user experience regarding observation and interaction. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chiang, Pei-Ying; Chen, Chun-Chi] Natl Taipei Univ Technol, Taipei, Taiwan.
   [Hsia, Chih-Hsien] Natl Ilan Univ, Yilan, Taiwan.
C3 National Taipei University of Technology; National Ilan University
RP Chiang, PY (corresponding author), Natl Taipei Univ Technol, Taipei, Taiwan.
EM peiyingc@csie.ntut.edu.tw
OI Hsia, Chih-Hsien/0000-0003-2665-0821
FU Taiwan Ministry of Science and Technology [MOST 105-2221-E-027-088, MOST
   106-2221-E-027-133-MY2, MOST 107-2218-E-002-056, MOST
   104-2221-E-027-057]
FX This research was supported by Taiwan Ministry of Science and Technology
   under Grant Nos. MOST 105-2221-E-027-088, MOST 106-2221-E-027-133-MY2,
   MOST 107-2218-E-002-056 and MOST 104-2221-E-027-057. Data sets are
   courtesy of the University of Utah, Viatronix Inc., Tiani Medgraph,
   Philips Research and The Institute for Neuroradiology, Frankfurt.
CR Asmund Birkeland., 2009, Proceedings of the 25th Spring Conference on Computer Graphics, P121, DOI DOI 10.1145/1980462.1980487
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1077, DOI 10.1109/TVCG.2006.140
   Chen CK, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 1, PROCEEDINGS, P368, DOI 10.1109/ISDA.2008.232
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Dehmeshi J, 2008, IEEE T MED IMAGING, V27, P467, DOI 10.1109/TMI.2007.907555
   Deng Y., 2016, FRAMEWORK INSPECTION, DOI [10.1007/978-981-10-2666-9_70, DOI 10.1007/978-981-10-2666-9_70]
   Gallo L., 2013, SIGGRAPH Asia Technical Briefs, DOI [10.1145/2542355.2542390, DOI 10.1145/2542355.2542390]
   Gallo L, 2014, J AMB INTEL SMART EN, V6, P93, DOI 10.3233/AIS-130239
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Huang RZ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P355
   Igarashi T, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P403, DOI 10.1145/2984511.2984537
   Jung Y., 2016, P 33 COMP GRAPH INT, P109, DOI 10.1145/2949035.2949063
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Luo YL, 2012, COMPUT SCI ENG, V14, P63, DOI 10.1109/MCSE.2011.114
   Molchanov P., 2016, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, P4207, DOI DOI 10.1109/CVPR.2016.456
   Qian C., 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145
   Rautek P, 2008, COMPUT GRAPH FORUM, V27, P847, DOI 10.1111/j.1467-8659.2008.01216.x
   Shen JC, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P85, DOI 10.1109/CW.2014.20
   Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450
   Ruppert GCS, 2012, WORLD J UROL, V30, P687, DOI 10.1007/s00345-012-0879-0
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Viola I, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P139, DOI 10.1109/VISUAL.2004.48
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Westover L., 1990, Computer Graphics, V24, P367, DOI 10.1145/97880.97919
NR 28
TC 7
Z9 8
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 363
EP 373
DI 10.1016/j.jvcir.2018.12.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100036
DA 2024-07-18
ER

PT J
AU Zheng, Y
   Cao, X
   Xiao, Y
   Zhu, XY
   Yuan, J
AF Zheng, Yan
   Cao, Xiang
   Xiao, Yi
   Zhu, Xianyi
   Yuan, Jin
TI Joint residual pyramid for joint image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Neural convolutional pyramid; Joint super-resolution;
   Residual block
AB Joint image super-resolution refers to methods to enhance the resolution of an image with the guidance of a higher resolution image. It is similar to image completion, which is shown to benefit from larger receptive fields in recent deep neural network based methods. However, larger receptive fields increase the depths and parameters of the network, which may cause degradation and large memory consumption. To this end, we propose a joint residual pyramid model by introducing residual blocks and linear interpolation layers into the convolutional neural pyramid (CNP), and adopting the CNP in the joint super-resolution framework. Our model consists of three sub-networks, two for feature extraction concatenated by another for image reconstruction. Experimental results show that our model outperforms existing state-of-the-art algorithms not only on data pairs of RGB/depth images, but also on data pairs like color/saliency and color-scribbles/colorized images, without significantly sacrificing computation efficiency and memory space. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zheng, Yan] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
   [Cao, Xiang; Xiao, Yi; Zhu, Xianyi; Yuan, Jin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Yuan, J (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
RI Cao, Xiang/ACT-7733-2022; Wang, Zejun/KBB-8454-2024
OI Cao, Xiang/0000-0002-8813-9669; 
FU National Key R&D Program of China [2018YFB0203904]; NSFC from PRC
   [61872137, 61502158, 61502157]; Hunan NSF [2017JJ3042, 2018113067];
   China Post-doctoral Foundation [2016M590740]
FX The work is supported by the National Key R&D Program of China
   (2018YFB0203904), NSFC from PRC (61872137, 61502158, 61502157), Hunan
   NSF (2017JJ3042, 2018113067), and China Post-doctoral Foundation (Grant
   Num.: 2016M590740).
CR [Anonymous], CORR
   [Anonymous], ECCV
   [Anonymous], ACCELERATING SUPER R
   [Anonymous], CVPR
   [Anonymous], ACM MULTIMEDIA
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Diebel J., 2005, P 18 INT C NEUR INF, V18, P291
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   He K., 2010, Eccv, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei JJ, 2017, IEEE T IMAGE PROCESS, V26, P1732, DOI 10.1109/TIP.2017.2656463
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10
   Lu JJ, 2015, PROC CVPR IEEE, P2245, DOI 10.1109/CVPR.2015.7298837
   Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433
   Mathieu Michael, 2016, ICLR, DOI DOI 10.48550/ARXIV.1511.05440
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Ren HY, 2017, IEEE COMPUT SOC CONF, P1050, DOI 10.1109/CVPRW.2017.142
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Wu Hsien-Huang P., 2007, ICM2007 4th IEEE International Conference on Mechatronics, ICM2007, P1
   Xiao Y, 2018, LECT NOTES ARTIF INT, V11012, P797, DOI 10.1007/978-3-319-97304-3_61
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
NR 38
TC 6
Z9 6
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 53
EP 62
DI 10.1016/j.jvcir.2018.11.028
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100006
DA 2024-07-18
ER

PT J
AU Chen, JL
   Lu, W
   Fang, YM
   Liu, XJ
   Yeung, Y
   Xue, YJ
AF Chen, Jialiang
   Lu, Wei
   Fang, Yanmei
   Liu, Xianjin
   Yeung, Yuileong
   Xue, Yingjie
TI Binary image steganalysis based on local texture pattern
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binary image steganalysis; Local texture pattern; Manhattan distance;
   Ensemble classifier
ID SPLICING DETECTION; AUTHENTICATION; DCT
AB In this paper, we propose a novel steganalytic scheme based on local texture pattern (LTP) to detect binary image steganography. We first assess how the expanded LTPs capture embedding distortions exactly. Considering curse of dimensionality when expanding LTPs, we employ Manhattan distance to measure the pixels correlation in a 5 x 5 sized block and select the pixels with closely correlation to remove some LTPs that are not interested. Although the stego image can maintain good visual quality, steganography scheme changes the inter-pixels correlation of binary image. Therefore we utilize totally 8192 LTPs histogram to define a 8192-dimensional steganalytic feature set. Original images and stego images are classified by ensemble classifier. Experimental results show that the proposed steganalytic method can more effectively detect state-of-the-art binary image steganography schemes compared with other steganalytic schemes.
C1 [Chen, Jialiang; Lu, Wei; Fang, Yanmei; Liu, Xianjin; Yeung, Yuileong; Xue, Yingjie] Sun Yat Sen Univ, Sch Data & Comp Sci, Gumgdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W; Fang, YM (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Gumgdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM luwei3@mail.sysu.edu.cn; fangym@mail.sysu.edu.cn
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; Natural Science
   Foundation of Guangdong [2016A030313350]; Special Funds for Science and
   Technology Development of Guangdong [2016KZ010103]; Key Project of
   Scientific Research Plan of Guangzhou [201804020068]; Fundamental
   Research Funds for the Central Universities [16lgjc83, 17lgjc45];
   Science and Technology Planning Project of Guangdong Province
   [2017A040405051]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45), the Science and Technology Planning Project of
   Guangdong Province (Grant No. 2017A040405051).
CR [Anonymous], 2011, P SPIE INT SOC OPT E
   [Anonymous], 2011, INT J COMPUT SCI ENG
   Cao H., 2012, SIGN INF PROC ASS AN, P1
   Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P653, DOI 10.1109/ARES.2010.66
   Feng B., 2013, INT WORKSH DIG WAT, P514
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Feng BW, 2015, MULTIMED TOOLS APPL, V74, P9623, DOI 10.1007/s11042-014-2140-x
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Filler T., 2010, P SPIE INT SOC OPT E, P175
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lin X., 2014, INT WORKSH DIG WAT, P389
   Meng Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1441, DOI 10.1109/ICPR.2010.356
   Nguyen TS, 2016, MULTIMED TOOLS APPL, V75, P8513, DOI 10.1007/s11042-015-2768-1
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Rimoldi B., COMMUNICATIONS HDB, V133
   TUCERYAN M, 1990, IEEE T PATTERN ANAL, V12, P211, DOI 10.1109/34.44407
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Yang HJ, 2008, IEEE T MULTIMEDIA, V10, P339, DOI 10.1109/TMM.2008.917404
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
   Yuan YF, 2017, LECT NOTES COMPUT SC, V10602, DOI 10.1007/978-3-319-68505-2_10
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
NR 29
TC 23
Z9 24
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 149
EP 156
DI 10.1016/j.jvcir.2018.06.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100014
DA 2024-07-18
ER

PT J
AU Singh, SP
   Bhatnagar, G
AF Singh, Satendra Pal
   Bhatnagar, Gaurav
TI A new robust watermarking system in integer DCT domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital watermarking; Integer discrete cosine transform; Chaotic map;
   Stochastic resonance
ID DYNAMIC-STOCHASTIC RESONANCE; DIGITAL WATERMARKING; IMAGE
   AUTHENTICATION; LOGO EXTRACTION; SCHEME; ALGORITHMS; TRANSFORM; NOISE
AB In this paper, a robust watermarking technique is proposed using integer discrete cosine transform, non-linear chaotic map and dynamic stochastic resonance (DSR). Firstly, the host image is transformed into integer DCT domain where the coefficients are partitioned into non-over-lapping blocks. A circulant matrix is then constructed from the selected blocks. Block selection is done using a non-linear chaotic map. This circulant matrix is used for embedding the watermark by computing the singular values. The extraction of the watermark is done by producing the dynamic stochastic resonance (DSR) phenomena and casting a verification step. This verification step essentially solves the false positive detection problem that arises in SVD based watermarking. The experimental results demonstrate that the proposed scheme is imperceptible and robust against a variety of intentional or unintentional attacks.
C1 [Singh, Satendra Pal; Bhatnagar, Gaurav] Indian Inst Technol Jodhpur, Dept Math, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Bhatnagar, G (corresponding author), Indian Inst Technol Jodhpur, Dept Math, Jodhpur, Rajasthan, India.
EM pg201383504@iitj.ac.in; goravb@iitj.ac.in
RI Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372
FU Science and Engineering Research Board, DST, India
FX This work was supported by the Science and Engineering Research Board,
   DST, India.
CR Ababneh S, 2009, J VIS COMMUN IMAGE R, V20, P303, DOI 10.1016/j.jvcir.2009.03.010
   Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], INT C COMPUT VISION
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Choi KC, 2016, MULTIMED TOOLS APPL, V75, P6621, DOI 10.1007/s11042-015-2596-3
   Chouhan R., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2745, DOI 10.1109/ICIP.2011.6116238
   Cox I. J., 2002, Digital Watermarking
   Gard T. C, 1998, Introduction to Stochastic Differential Equations
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Histace A, 2006, ELECTRON LETT, V42, P393, DOI 10.1049/el:20060180
   Hongler MO, 2003, IEEE T PATTERN ANAL, V25, P1051, DOI 10.1109/TPAMI.2003.1227982
   Jha RK, 2014, COMPUT ELECTR ENG, V40, P1917, DOI 10.1016/j.compeleceng.2013.07.024
   Jha RK, 2013, SIGNAL IMAGE VIDEO P, V7, P119, DOI 10.1007/s11760-011-0236-6
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lang FN, 2012, EXPERT SYST APPL, V39, P12046, DOI 10.1016/j.eswa.2012.03.070
   Lu HT, 2003, ELECTRON LETT, V39, P898, DOI 10.1049/el:20030589
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Oraintara S, 2002, IEEE T SIGNAL PROCES, V50, P607, DOI 10.1109/78.984749
   Pei SC, 2000, IEEE T SIGNAL PROCES, V48, P3345, DOI 10.1109/78.886998
   Plonka G, 2003, APPL COMPUT HARMON A, V15, P70, DOI 10.1016/S1063-5203(03)00032-0
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Sang T, 2001, IEEE T COMMUN, V49, P620, DOI 10.1109/26.917768
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Suhail MA, 2003, INFORM SCIENCES, V151, P93, DOI 10.1016/S0020-0255(02)00291-8
   Sun SF, 2008, SIGNAL PROCESS, V88, P2085, DOI 10.1016/j.sigpro.2008.02.010
   Suzuki T, 2010, IEEE T IMAGE PROCESS, V19, P2958, DOI 10.1109/TIP.2010.2051867
   Wang XY, 2014, MULTIMED TOOLS APPL, V72, P1933, DOI 10.1007/s11042-013-1483-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu G, 2006, P IEEE 8 INT C SIGN, V2, P1
   Wu WC, 2016, J VIS COMMUN IMAGE R, V38, P18, DOI 10.1016/j.jvcir.2016.02.005
   Wu YD, 2005, IEEE T MULTIMEDIA, V7, P624, DOI 10.1109/TMM.2005.846774
   Ye Q, 2003, P IEEE INT C IM PROC, V5, P1849
   Ye QH, 2004, IEEE IMAGE PROC, P263
   Zeng YH, 2001, IEEE T SIGNAL PROCES, V49, P2774, DOI 10.1109/78.960425
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 36
TC 78
Z9 81
U1 3
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 86
EP 101
DI 10.1016/j.jvcir.2018.03.006
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800009
DA 2024-07-18
ER

PT J
AU Bolaños, M
   Peris, A
   Casacuberta, F
   Soler, S
   Radeva, P
AF Bolanos, Marc
   Peris, Alvaro
   Casacuberta, Francisco
   Soler, Sergi
   Radeva, Petia
TI Egocentric video description based on temporally-linked sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Egocentric vision; Video description; Deep learning; Multi-modal
   learning
AB Egocentric vision consists in acquiring images along the day from a first person point-of-view using wearable cameras. The automatic analysis of this information allows to discover daily patterns for improving the quality of life of the user. A natural topic that arises in egocentric vision is storytelling, that is, how to understand and tell the story relying behind the pictures.
   In this paper, we tackle storytelling as an egocentric sequences description problem. We propose a novel methodology that exploits information from temporally neighboring events, matching precisely the nature of egocentric sequences. Furthermore, we present a new method for multimodal data fusion consisting on a multi input attention recurrent network. We also release the EDUB-SegDesc dataset. This is the first dataset for egocentric image sequences description, consisting of 1339 events with 3991 descriptions, from 55 days acquired by 11 people. Finally, we prove that our proposal outperforms classical attentional encoder-decoder methods for video description.
C1 [Bolanos, Marc; Soler, Sergi; Radeva, Petia] Univ Barcelona, Barcelona, Spain.
   [Bolanos, Marc; Radeva, Petia] Comp Vis Ctr, Bellaterra, Spain.
   [Peris, Alvaro; Casacuberta, Francisco] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
C3 University of Barcelona; Centre de Visio per Computador (CVC);
   Universitat Politecnica de Valencia
RP Bolaños, M (corresponding author), Univ Barcelona, Barcelona, Spain.
EM marc.bolanos@ub.edu; lvapeab@prhlt.upv.es; fcn@prhlt.upv.es;
   ssolerso8@alumnes.ub.ed; petia.ivanova@ub.edu
FU CERCA [TIN2015-66951-C2, SGR 1219]; Marato TV3 [20141510]; R-MIPRCV
   network [TIN2014-54728-REDC]; FPU fellowship; NVIDIA Corporation; 
   [PrometeoII/2014/030]
FX This work was partially founded by TIN2015-66951-C2, SGR 1219, CERCA,
   Grant 20141510 (Marato TV3), PrometeoII/2014/030 and R-MIPRCV network
   (TIN2014-54728-REDC). Petia Radeva is partially founded by ICREA
   Academia'2014. Marc Bolanos is partially founded by an FPU fellowship.
   We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of a Titan X GPU used for this research. The funders had no
   role in the study design, data collection, analysis, and preparation of
   the manuscript.
CR [Anonymous], 2016, Theano: A Python framework for fast computation of mathematical ex
   [Anonymous], HIERARCHICAL LSTM AD
   [Anonymous], 2014, CORR
   [Anonymous], BATCH BASED ACTIVITY
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], IMPROVING LSTM BASED
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, 12 C ASS MACHINE TRA
   [Anonymous], VIBIKNET VISUAL BIDI
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], DEEPSEEK VIDEO CAPTI
   [Anonymous], SEMANTIC SUMMARIZATI
   [Anonymous], ATTENTION BASED MULT
   [Anonymous], 2013, One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling
   [Anonymous], 2014, INT C LEARNING REPRE
   [Anonymous], 2014, WORKSHOP SYNTAX SEMA
   [Anonymous], 2017, LEARNING REMEMBER RA
   [Anonymous], 2017, Dense-captioning events in videos. Paper presented at: International Conference on Computer Vision (ICCV)
   [Anonymous], 2016 IEEE Winter Conf. Appl. Comput. Vision, DOI [DOI 10.1109/WACV.2016.7477708, 10.1109/WACV.2016.7477708]
   [Anonymous], 2017, IEEE T HUM-MACH SYST, DOI DOI 10.1109/THMS.2016.2616296
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REP IC
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Castro D, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P75, DOI 10.1145/2802083.2808398
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen X., 2015, MICROSOFT COCO CAPTI
   Chenyou Fan, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P459, DOI 10.1007/978-3-319-46604-0_33
   Dimiccoli M, 2017, COMPUT VIS IMAGE UND, V155, P55, DOI 10.1016/j.cviu.2016.10.005
   Doherty AR, 2013, AM J PREV MED, V44, P320, DOI 10.1016/j.amepre.2012.11.008
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Iwashita Y, 2014, INT C PATT RECOG, P4310, DOI 10.1109/ICPR.2014.739
   Lavie A, 2009, MACH TRANSL, V23, P105, DOI 10.1007/s10590-009-9059-4
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Peris A, 2017, COMPUT SPEECH LANG, V45, P201, DOI 10.1016/j.csl.2016.12.003
   Peris A, 2016, LECT NOTES COMPUT SC, V9887, P3, DOI 10.1007/978-3-319-44781-0_1
   Reunanen J., 2003, Journal of Machine Learning Research, V3, P1371, DOI 10.1162/153244303322753715
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sellen A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P81
   Spector A, 2003, BRIT J PSYCHIAT, V183, P248, DOI 10.1192/bjp.183.3.248
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Toselli AH, 2011, MULTIMODAL INTERACTIVE PATTERN RECOGNITON AND APPLICATIONS, P1, DOI 10.1007/978-0-85729-479-1
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Xu K., 2015, COMPUTER SCI, P2048
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zeiler Matthew D., 2012, ADADELTA ADAPTIVE LE
NR 56
TC 13
Z9 13
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 205
EP 216
DI 10.1016/j.jvcir.2017.11.022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700021
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Xiang, GQ
   Jia, HZ
   Yang, MY
   Zhang, XF
   Huang, XF
   Liu, J
   Xie, XD
AF Xiang, Guoqing
   Jia, Huizhu
   Yang, Mingyuan
   Zhang, Xinfeng
   Huang, Xiaofeng
   Liu, Jie
   Xie, Xiaodong
TI A perceptually temporal adaptive quantization algorithm for HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inter-frame dependency; AQ; QP offset; JND; SSIM; Subjective quality
ID RATE-DISTORTION OPTIMIZATION; QUALITY
AB Adaptive quantization (AQ) proves to be an effective coding tool to improve the performance of video coding. This paper presents a perceptually temporal AQ method to improve the subjective coding performance for High Efficiency Video Coding (HEVC). We first put forward a perceptual quality oriented motion estimation algorithm, which is conducted with a spatial-temporal just noticeable distortion (JND) model. Then one perceptual feature in temporal domain is proposed to develop our AQ method, which can generate different quantization parameter (QP) offsets for each coding unit (CU). The proposed method fully utilizes the temporal and perceptual characteristics of each CU, which can produce more visual-friendly QP offsets distribution. Experiments are conducted on HM16.0 (HEVC reference software), and with SSIM (Structure Similarity Index Metric) as the distortion metric, more than 8.08% and 7.95% rate savings can be obtained for Low-Delay-P (LDP) and Low-Delay-B (LDB) configurations on average, respectively. The subjective quality evaluation demonstrates that the proposed AQ method can achieve comparable visual quality as the HM16.0 while the proposed method can yield remarkable bitrate reductions.
C1 [Xiang, Guoqing; Jia, Huizhu; Liu, Jie; Xie, Xiaodong] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
   [Yang, Mingyuan] Beijing BOYA HUALU Technol Inc, Beijing 100080, Peoples R China.
   [Zhang, Xinfeng] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Huang, Xiaofeng] Nvidia Co, Shanghai, Peoples R China.
   [Jia, Huizhu] Cooperat Medianet Innovat Ctr, Tianjin, Peoples R China.
   [Jia, Huizhu] Beida Binhai Informat Res, Tianjin, Peoples R China.
C3 Peking University; University of Southern California; Nvidia Corporation
RP Jia, HZ (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
EM gqxiang@jdl.ac.cn; hzjia@jdl.ac.cn; mingyuan.yang@boyahualu.com;
   xinfengz@usc.edu; hehuang@nvidia.com; liuzimin@jdl.ac.cn;
   xdxie@jdl.ac.cn
RI Zhang, Xinfeng/X-8148-2019
FU National Science Foundation of China [61502013]; National Key Research
   and Development Program of China [2016YFB0401904, 2016YFB0402001]; Major
   National Scientific Instrument and Equipment Development Project of
   China [2013YQ030967]
FX This work is partially supported by the National Science Foundation of
   China under contract No. 61502013, National Key Research and Development
   Program of China under contract No. 2016YFB0401904 and No.
   2016YFB0402001 and the Major National Scientific Instrument and
   Equipment Development Project of China under contract No. 2013YQ030967.
CR [Anonymous], 2013, Technical Report JCTVC-L1100
   [Anonymous], 1993, JTC1SC29WG11 ISO IEC
   [Anonymous], 2011, JCTVC-E051
   [Anonymous], 2001, SC16Q6 ITUT
   Brooks AC, 2008, IEEE T IMAGE PROCESS, V17, P1261, DOI 10.1109/TIP.2008.926161
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Guoqing Xiang, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P362, DOI 10.1109/ICCE.2017.7889356
   Li S, 2016, IEEE T CIRC SYST VID, V26, P117, DOI 10.1109/TCSVT.2015.2450131
   Prangnell L, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P35, DOI 10.1109/PCS.2015.7170042
   Rohaly A.M., 2000, ITU T STANDARDS CONT, P9
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tourapis AM, 2001, P SOC PHOTO-OPT INS, V4310, P883
   Wang Yubing., Survey of Objective Video Quality Measurements
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu JJ, 2016, INT CONF ACOUST SPEE, P1581, DOI 10.1109/ICASSP.2016.7471943
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yeo CH, 2013, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2013.6637940
NR 18
TC 10
Z9 10
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 280
EP 289
DI 10.1016/j.jvcir.2017.11.011
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700028
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, G
   Zhang, YD
   Li, JT
AF Wang, Gang
   Zhang, Yongdong
   Li, Jintao
TI High-level background prior based salient object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Background prior; Superpixel; Objectness
ID REGION DETECTION; COLOR
AB Salient object detection is a fundamental problem in computer vision. Existing methods using only lowlevel features failed to uniformly highlight the salient object regions. In order to combine high-level saliency priors and low-level appearance cues, we propose a novel Background Prior based Salient detection method (BPS) for high-quality salient object detection.
   Different from other background prior based methods, a background estimation is added before performing saliency detection. We utilize the distribution of bounding boxes generated by a generic object proposal method to obtain background information. Three background priors are mainly considered to model the saliency, namely background connectivity prior, background contrast prior and spatial distribution prior, allowing the proposed method to highlight the salient object as a whole and suppress background clutters.
   Experiments conducted on two benchmark datasets validate that our method outperforms 11 state-ofthe-art methods, while being more efficient than most leading methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Wang, Gang; Zhang, Yongdong; Li, Jintao] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Zhang, YD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM wanggang01@ict.ac.cn; zhyd@ict.ac.cn; jtli@ict.ac.cn
RI wang, gang/ITT-0670-2023
FU National Nature Science Foundation of China [61525206, 61271428,
   61273247, 61672495]; Beijing Advanced Innovation Center for Imaging
   Technology [BAICIT-2016009]
FX This work was supported by National Nature Science Foundation of China
   under Grant (61525206, 61271428, 61273247, 61672495); the Beijing
   Advanced Innovation Center for Imaging Technology under Grant
   BAICIT-2016009.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], ARXIV160403227
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], ARXIV14115878
   [Anonymous], INT C MULT RETR
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Strand R, 2013, COMPUT VIS IMAGE UND, V117, P429, DOI 10.1016/j.cviu.2012.10.011
   Toivanen PJ, 1996, PATTERN RECOGN LETT, V17, P437, DOI 10.1016/0167-8655(96)00010-4
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 39
TC 12
Z9 12
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 432
EP 441
DI 10.1016/j.jvcir.2017.02.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700037
DA 2024-07-18
ER

PT J
AU Pan, XQ
   Chen, YR
   Kuo, CCJ
AF Pan, Xiaqing
   Chen, Yueru
   Kuo, C. -C. Jay
TI Design, analysis and application of a volumetric convolutional neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; 3D shape classification; ModelNet40 shape
   dataset; Unsupervised learning; Anchor vector
AB The design, analysis and application of a volumetric convolutional neural network (VCNN) are studied in this work. Although many CNNs have been proposed in the literature, their design is empirical. In the design of the VCNN, we propose a feed-forward K-means clustering algorithm to determine the filter number and size at each convolutional layer systematically. For the analysis of the VCNN, the cause of confusing classes in the output of the VCNN is explained by analyzing the relationship between the filter weights (also known as anchor vectors) from the last fully-connected layer to the output. Furthermore, a hierarchical clustering method followed by a random forest classification method is proposed to boost the classification performance among confusing classes. For the application of the VCNN, we examine the 3D shape classification problem and conduct experiments on a popular ModelNet40 dataset. The proposed VCNN offers the state-of-the-art performance among all volume-based CNN methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Pan, Xiaqing; Chen, Yueru; Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Pan, XQ (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM xiaqingp@usc.edu
RI Chen, Yueru/GWC-9924-2022; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU University of Southern California's Center for High Performance
   Computing (hpc.usc.edu)
FX Computation for the work described in this paper was supported by the
   University of Southern California's Center for High Performance
   Computing (hpc.usc.edu).
CR [Anonymous], 2000, Icml, DOI DOI 10.1007/3-540-44491-2_3
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Bai S., GIFT REALTIME SCALAB
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Chang A.X., INFORM RICH 3D MODEL
   Chaouch M., 2007, 2007 IEEE INT C IM P, V6, pVI
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Dong J., IEEE T CIRC SYST VID, V25
   Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hegde V, FUSIONNET 3D OBJECT
   johns E., PAIRWISE DECOMPOSITI
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo C.C. J., 2016, UNDERSTANDING CONVOL
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Li Bo., 2012, Proceedings of EuroGraphics 3DOR, P119, DOI 10.2312/3DOR/3DOR12/119-126
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Ruizhongtai Qi C., 2016, Volumetric and Multi-View CNNs for Object Classification on 3D Data
   Sawa M., SHREC16 TRACK LARGE
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Simonyan K., 2014, 14091556 ARXIV
   Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002
   Spaeth S., 2016, The Decentralized and Networked Future of Value Creation: 3D Printing and Its Implications for Society, Industry, and Sustainable Development, P59
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Wu J., LEARNING PROBABILIST
   Xie J, 2015, PROC CVPR IEEE, P1275, DOI 10.1109/CVPR.2015.7298732
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
NR 37
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 128
EP 138
DI 10.1016/j.jvcir.2017.03.016
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lee, WY
   Kuo, YH
   Hsu, WH
   Aizawa, K
AF Lee, Wen-Yu
   Kuo, Yin-Hsi
   Hsu, Winston H.
   Aizawa, Kiyoharu
TI City-view image location identification by multiple geo-social media and
   graph-based image cluster refinement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Check-in data; Geo-tagged image; Image location identification; Social
   media; Sparse coding
AB "What is this" and "where am I" are two common questions that arise when people travel abroad. Recently, landmark image identification has shown great promise for the addressed problems, where most previous approaches are either visual-based or location-based. However, regarding city-view image location identification, there could be a number of buildings in a close proximity. Moreover, it is common that photos were taken indoors. The conditions may degrade the performance of previous approaches. To remedy the deficiencies, this paper unifies visual features, geo-tags, and check-in data, based on cross domain social media, for city-view image location identification. Besides, this paper shows an effective and memory-efficient implementation based on sparse coding, where a new dictionary selection approach is presented. Further, this paper proposes a location-aware graph-based regrouping approach, leveraging spanning graph construction, on clusters of photos to refine clustering results. Experimental results show the improvement over the baselines (location-based, visual-based, etc.). (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lee, Wen-Yu; Kuo, Yin-Hsi; Hsu, Winston H.] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
   [Hsu, Winston H.] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
   [Aizawa, Kiyoharu] Univ Tokyo, Dept Informat & Commun Engn, Tokyo 1138656, Japan.
C3 National Taiwan University; National Taiwan University; University of
   Tokyo
RP Lee, WY (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
EM majorrei@cmlab.csie.ntu.edu.tw; kuonini@cmlab.csie.ntu.edu.tw;
   winston@csie.ntu.edu.tw; aizawa@hal.t.u-tokyo.ac.jp
FU summer program of Interchange Association, Japan
FX This paper was partially supported by the summer program of Interchange
   Association, Japan.
CR [Anonymous], APPROXIMATION ALGORI
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], P ACM MM
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], P ACM INT C MULT
   [Anonymous], P GI BTW
   [Anonymous], P ACM GEOMM
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], P INT C MULT MM 2010
   Cao LL, 2010, INT CONF ACOUST SPEE, P2274, DOI 10.1109/ICASSP.2010.5495905
   Cao LL, 2009, IEEE T MULTIMEDIA, V11, P208, DOI 10.1109/TMM.2008.2009693
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Coates A., 2011, P 28 INT C MACH LEAR, V28, P921
   de Silva GamhewageC., 2009, Proc. of 2009 ACM Multimedia Int. Conf. (ACM-Multimedia'09), P785
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Feng L, 2015, J VIS COMMUN IMAGE R, V33, P104, DOI 10.1016/j.jvcir.2015.09.002
   Hays J, 2008, PROC CVPR IEEE, P3436
   Jin C, 2016, J VIS COMMUN IMAGE R, V34, P167, DOI 10.1016/j.jvcir.2015.10.017
   Joshi D, 2012, MULTIMED TOOLS APPL, V56, P131, DOI 10.1007/s11042-010-0553-8
   Karakostas G, 2009, ACM T ALGORITHMS, V5, DOI 10.1145/1597036.1597045
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kherfi ML, 2007, IEEE T MULTIMEDIA, V9, P893, DOI 10.1109/TMM.2007.893349
   Kuo YH, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P201, DOI 10.1145/2647868.2656406
   Lee WY, 2013, J VIS COMMUN IMAGE R, V24, P295, DOI 10.1016/j.jvcir.2012.12.002
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICCV.2009.5459432
   Liu H., 2012, Proceedings_of_the_20th_ACM_ International_Conference_on_Multimedia, MM'12, P9
   Liu Q, 2014, IEEE T KNOWL DATA EN, V26, P278, DOI 10.1109/TKDE.2012.233
   Liu W., 2010, PROC ICML, P679
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Nister David, 2006, CVPR
   Quanz B, 2012, IEEE T KNOWL DATA EN, V24, P1789, DOI 10.1109/TKDE.2012.75
   Sang Jitao., 2012, SIGSPATIALGIS, P402
   Schindler G., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Shao-Lun Huang, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P382, DOI 10.1109/ASPDAC.2011.5722218
   Shaw B., 2013, ACM DIGITAL LIB, P717, DOI DOI 10.1145/2433396.2433485
   Simon I., 2007, PROC IEEE ICCV, P1
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P627, DOI 10.1016/B978-1-59749-272-0.50014-1
   YAO ACC, 1982, SIAM J COMPUT, V11, P721, DOI 10.1137/0211059
   Zandbergen PA, 2011, J NAVIGATION, V64, P381, DOI 10.1017/S0373463311000051
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
   Zhou H, 2002, INFORM PROCESS LETT, V81, P271, DOI 10.1016/S0020-0190(01)00232-0
NR 42
TC 1
Z9 1
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 200
EP 211
DI 10.1016/j.jvcir.2016.09.017
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000018
DA 2024-07-18
ER

PT J
AU Pun, CM
   Huang, GH
AF Pun, Chi-Man
   Huang, Guoheng
TI On-line video object segmentation using illumination-invariant
   color-texture feature extraction and marker prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video object segmentation; Illumination invariance; Region merging;
   Marker prediction; Superpixel
ID VISUAL TRACKING; IMAGE; MOTION; SHIFT
AB A novel on-line video object segmentation scheme based on illumination-invariant color-texture feature extraction and marker prediction is proposed in this paper. First, the location of the object of interest is initialized based on user-specified markers. Superpixels are generated in the next available frame of the input video to extract the illumination-invariant color-texture features of the object of interest. The proposed object marker prediction scheme consists of estimating the user-specified markers and locating the object of interest in the next available frame via superpixel motion prediction using illumination invariant optical flow, marker superpixel candidate generation using short-term superpixel affinity, and maximum likelihood computation using long-term superpixel affinity. The experimental results obtained when the proposed method is applied to several challenging video clips demonstrate that the proposed approach is competitive with several other state-of-the-art methods, especially when the illumination and object motion change dramatically. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pun, Chi-Man; Huang, Guoheng] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo; yb27405@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX This research was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (008/2013/A1,
   093-2014-A2).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], P 12 EUR C COMP VI 7
   [Anonymous], P 2013 IEEE INT C CO
   [Anonymous], MULTIMED TOOLS APPL
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Golland P, 1997, COMPUT VIS IMAGE UND, V68, P346, DOI 10.1006/cviu.1997.0553
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   Hariharakrishnan K, 2005, IEEE T MULTIMEDIA, V7, P853, DOI 10.1109/TMM.2005.854437
   He SF, 2017, IEEE T CIRC SYST VID, V27, P1006, DOI 10.1109/TCSVT.2016.2527300
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Huang GH, 2016, MULTIMED TOOLS APPL, V75, P5473, DOI 10.1007/s11042-015-2516-6
   Jacobs DW, 1998, PROC CVPR IEEE, P610, DOI 10.1109/CVPR.1998.698668
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Lee HY, 2003, IEEE T MULTIMEDIA, V5, P358, DOI 10.1109/TMM.2003.814792
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Lempitsky V., 2008, Proceedings of the 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'08), P1
   Liu Y, 2005, IEEE T CIRC SYST VID, V15, P885, DOI 10.1109/TCSVT.2005.848346
   Malik J., 2007, Computer Vision and Pattern Recognition, P1
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   Singh V. K., 2008, PROC 2008 IEEE WORKS, P1
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Sun SJ, 2003, IEEE T CIRC SYST VID, V13, P75, DOI 10.1109/TCSVT.2002.808089
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Varas D, 2014, PROC CVPR IEEE, P3470, DOI 10.1109/CVPR.2014.444
   Vazquez-Reina A, 2010, LECT NOTES COMPUT SC, V6315, P268, DOI 10.1007/978-3-642-15555-0_20
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang C, 2014, IEEE T MULTIMEDIA, V16, P903, DOI 10.1109/TMM.2014.2306393
   Wang TH, 2014, COMPUT VIS IMAGE UND, V120, P14, DOI 10.1016/j.cviu.2013.10.013
   Wang TH, 2012, IEEE T MULTIMEDIA, V14, P389, DOI 10.1109/TMM.2011.2177078
   Willert V, 2005, LECT NOTES COMPUT SC, V3663, P9
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhong F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366194
NR 46
TC 7
Z9 7
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 391
EP 405
DI 10.1016/j.jvcir.2016.10.017
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000034
DA 2024-07-18
ER

PT J
AU Vakili, N
   Rezghi, M
   Hosseini, SM
AF Vakili, Nima
   Rezghi, Mansoor
   Hosseini, S. Mohammad
TI Improving image segmentation by using energy function based on mixture
   of Gaussian pre-processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active contour; Image segmentation; Level set; Gaussian mixture
   distribution; EM-algorithm; Pre-processing
ID ACTIVE CONTOURS; TEXTURE SEGMENTATION; LEVEL-SETS; PROPAGATION;
   SURFACES; MODEL
AB In this paper, by proposing a two-stage segmentation method based on active contour model, we improve the procedure of former image segmentation methods. The first stage of our method is computing weights, means and variances of image by utilizing Mixture of Gaussian distribution which parameters are obtained from EM-algorithm. Once they are obtained, in the second stage, by incorporating level set method for minimizing energy function, the segmentation is achieved. We use an adaptive direction function to make the curve evolution robust against the curves initial position and a nonlinear adaptive velocity to speed up the process of curve evolution and also a probability-weighted edge and region indicator function to implement a robust segmentation for objects with weak boundaries. The paper consists of minimizing a functional containing a penalty term in an attempt to maintain the signed distance property in the entire domain and an external energy term such that it achieves a minimum when the zero level set of the function is located at desired position. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Vakili, Nima; Hosseini, S. Mohammad] Univ Tarbiat Modares, Dept Appl Math, POB 14115-175, Tehran, Iran.
   [Rezghi, Mansoor] Univ Tarbiat Modares, Dept Comp Sci, POB 14115-175, Tehran, Iran.
C3 Tarbiat Modares University; Tarbiat Modares University
RP Vakili, N (corresponding author), Univ Tarbiat Modares, Dept Appl Math, POB 14115-175, Tehran, Iran.
EM nima.vakili@modares.ac.ir; rezghi@modares.ac.ir; hossei_m@modares.ac.ir
RI Hosseini, S. Mohammad/Y-7031-2019
OI Rezghi, Mansoor/0000-0003-4214-5008
CR [Anonymous], 2009, Biometrics, DOI [10.1007/978-0-387-73003-5_196, DOI 10.1007/978-0-387-73003-5_196]
   Ben Ayed I, 2005, IEEE T PATTERN ANAL, V27, P793, DOI 10.1109/TPAMI.2005.106
   Ben Ayed I, 2006, IEEE T PATTERN ANAL, V28, P1493, DOI 10.1109/TPAMI.2006.191
   Bilmes J., GENTLE TUTORIAL EM A
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chabrier S., 2008, J IMAGE VIDEO PROCES
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng YC, 2007, ACM SIGCOMM COMP COM, V37, P25, DOI 10.1145/1282427.1282384
   CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Li CM, 2005, PROC CVPR IEEE, P430
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mansouri AR, 2006, COMPUT VIS IMAGE UND, V101, P137, DOI 10.1016/j.cviu.2005.07.008
   Mitiche A, 2010, SPRINGER TOP SIGN PR, V5, P1
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Rousson M, 2003, PROC CVPR IEEE, P699
   Vemuri B, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P251, DOI 10.1007/0-387-21810-6_14
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang B, 2014, IEEE T CYBERNETICS, V44, P418, DOI 10.1109/TCYB.2013.2256891
   Xue JR, 2011, IEEE T IMAGE PROCESS, V20, P1177, DOI 10.1109/TIP.2010.2077643
NR 25
TC 2
Z9 2
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 239
EP 246
DI 10.1016/j.jvcir.2016.10.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000021
DA 2024-07-18
ER

PT J
AU Hou, DD
   Zhang, WM
   Yu, NH
AF Hou, Dongdong
   Zhang, Weiming
   Yu, Nenghai
TI Image camouflage by reversible image transformation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image camouflage; Image transformation; Image encryption; Reversible
   data hiding
ID HISTOGRAM-MODIFICATION; PARALLEL FRAMEWORK; WATERMARKING
AB A new reversible image transformation technique is proposed, which not only improves the visual quality of the camouflage image created by transforming a secret image to a freely-selected target image, but also can restore the secret image without any loss. Effective clustering algorithm is utilized to reduce the information for recording block indexes that is vital for restoring the secret image. Therefore, the transformation can be made between the blocks with relatively small size, thus greatly improving the visual quality of the camouflage image. The root mean square error of camouflage image was reduced by 6 in most cases compared with the previous method. Since the proposed technique is reversible, we can further realize two-round transformation by transforming the camouflage image to another target image and thus hide two images into only one. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hou, Dongdong; Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
EM houdd@mail.ustc.edu.cn; zhangwm@ustc.edu.cn; ynh@ustc.edu.cn
FU Natural Science Foundation of China [61170234, 60803155]; Strategic and
   Piloted Project of CAS [XDA06030601]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61170234 and Grant 60803155, and by the Strategic and
   Piloted Project of CAS under Grant XDA06030601.
CR Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J., 2010, P SPIE ELECT IMAGING
   Lai IJ, 2011, IEEE T INF FOREN SEC, V6, P936, DOI 10.1109/TIFS.2011.2135853
   Lee YL, 2014, IEEE T CIRC SYST VID, V24, P695, DOI 10.1109/TCSVT.2013.2283431
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
NR 20
TC 27
Z9 27
U1 2
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 225
EP 236
DI 10.1016/j.jvcir.2016.06.018
PN A
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500021
DA 2024-07-18
ER

PT J
AU Liu, RY
   Miao, QG
   Huang, B
   Song, JF
   Debayle, J
AF Liu, Ruyi
   Miao, Qiguang
   Huang, Bormin
   Song, Jianfeng
   Debayle, Johan
TI Improved road centerlines extraction in high-resolution remote sensing
   images using shear transform, directional morphological filtering and
   enhanced broken lines connection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Road centerlines extraction; Shear transform; Multivariate adaptive
   regression splines; (MARS); Directional segmentation; Tensor voting
ID MANY-CORE PROCESSORS; SATELLITE IMAGES; PARALLEL FRAMEWORK; FEATURES;
   TREE
AB Road information plays an important role in many civilian and military applications. Road centerlines extraction from high-resolution remote sensing images can be used to update a transportation database. However, it is difficult to extract a complete road network from high-resolution images, especially when the color of road is close to that of background. This paper proposes an improved method for road centerlines extraction, which is based on shear transform, directional segmentation, shape features filtering, directional morphological filtering, tensor voting, multivariate adaptive regression splines (MARS) and enhanced broken lines connection. The proposed method consists of five steps. Firstly, directional segmentation based on spectral information and shear transform is used to segment the images for obtaining the initial road map. Shear transform is introduced to overcome the disadvantage of the loss of the road segment information. Secondly, we perform hole filling to remove the holes due to noise in some road regions. Thirdly, reliable road segments are extracted by road shape features and directional morphological filtering. Directional morphological filtering can separate road from the neighboring non-road objects to ensure the independence of each road target candidate. Fourthly, tensor voting and MARS are exploited to extract smooth road centerlines, which overcome the shortcoming that the road centerlines extracted by the thinning algorithm have many spurs. Finally, we propose an enhanced broken lines connection algorithm to generate a complete road network, in which a new measure function is constructed and spectral similarity is introduced. We evaluate the performance on the high-resolution aerial and QuickBird satellite images. The results demonstrate that the proposed method is promising. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Ruyi; Miao, Qiguang; Song, Jianfeng] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Huang, Bormin] Univ Wisconsin, Space Sci & Engn Ctr, Madison, WI 53706 USA.
   [Debayle, Johan] Ecole Natl Super Mines, Ctr Ingn & Sant, F-42023 St Etienne, France.
C3 Xidian University; University of Wisconsin System; University of
   Wisconsin Madison; IMT - Institut Mines-Telecom; Mines Saint-Etienne
RP Miao, QG (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM qgmiao@126.com
RI Debayle, Johan/V-8438-2019
OI Debayle, Johan/0000-0002-9593-0467; Miao, Qiguang/0000-0002-2872-388X;
   Liu, Ruyi/0000-0001-9231-1081
FU National Natural Science Foundations of China [61472302, 61272280,
   U1404620, 41271447]; Open Projects Program of National Laboratory of
   Pattern Recognition [201600031]; Program for New Century Excellent
   Talents in University [NCET-12-0919]; Fundamental Research Funds for the
   Central Universities [K5051203020, K5051303018, JB150313, JB150317,
   BDY081422]; Special Program for Applied Research on Super Computation of
   the NSFC-Guangdong Joint Fund (the second phase); Natural Science
   Foundation of Shaanxi Province [2010JM8027]; Creative Project of the
   Science and Technology State of Xi'an [CXY1441(1)]; State Key Laboratory
   of Geo-information Engineering [SKLG1E2014-M-4-4]
FX The work was jointly supported by the National Natural Science
   Foundations of China under Grant Nos. 61472302, 61272280, U1404620 and
   41271447; The Open Projects Program of National Laboratory of Pattern
   Recognition (201600031); The Program for New Century Excellent Talents
   in University under Grant No. NCET-12-0919; The Fundamental Research
   Funds for the Central Universities under Grant Nos. K5051203020,
   K5051303018, JB150313, JB150317 and BDY081422; Special Program for
   Applied Research on Super Computation of the NSFC-Guangdong Joint Fund
   (the second phase); Natural Science Foundation of Shaanxi Province,
   under Grant No. 2010JM8027; The Creative Project of the Science and
   Technology State of Xi'an under Grant No. CXY1441(1); The State Key
   Laboratory of Geo-information Engineering under Grant No.
   SKLG1E2014-M-4-4.
CR [Anonymous], 1991, Computer and Robot Vision
   [Anonymous], 1998, P EMPIRICAL EVAL TEC
   Cao CQ, 2014, REMOTE SENS-BASEL, V6, P9014, DOI 10.3390/rs6099014
   Chaudhuri D, 2012, IEEE J-STARS, V5, P1538, DOI 10.1109/JSTARS.2012.2199085
   Das S, 2011, IEEE T GEOSCI REMOTE, V49, P3906, DOI 10.1109/TGRS.2011.2136381
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Gamba P, 2006, IEEE GEOSCI REMOTE S, V3, P387, DOI 10.1109/LGRS.2006.873875
   Grote A, 2012, PHOTOGRAMM REC, V26, P8, DOI 10.1111/j.1477-9730.2011.00670.x
   Hastie T., 2009, The Elements of Statistical Learning
   Hu J, 2007, IEEE T GEOSCI REMOTE, V45, P4144, DOI 10.1109/TGRS.2007.906107
   Hu XY, 2007, PHOTOGRAMM ENG REM S, V73, P1049
   Huang X, 2009, INT J REMOTE SENS, V30, P1977, DOI 10.1080/01431160802546837
   Jiao L., 2008, Image Multiscale Geometric Analysis: Theory andApplications-Beyond Wavelets
   Li MM, 2016, INT J APPL EARTH OBS, V44, P217, DOI 10.1016/j.jag.2015.09.005
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Medioni G., 2000, COMPUTATIONAL FRAMEW
   Mena JB, 2003, PATTERN RECOGN LETT, V24, P3037, DOI 10.1016/S0167-8655(03)00164-8
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   Miao ZL, 2013, IEEE GEOSCI REMOTE S, V10, P583, DOI 10.1109/LGRS.2012.2214761
   Mokhtarzade M, 2007, INT J APPL EARTH OBS, V9, P32, DOI 10.1016/j.jag.2006.05.001
   Mordohai P., 2006, SYNTHESIS LECT IMAGE, V2, P1, DOI DOI 10.2200/S00049ED1V01Y200609IVM008
   Mukundan Ramakrishnan., 1998, MOMENT FUNCTIONS IMA, V100
   Poullis C, 2010, ISPRS J PHOTOGRAMM, V65, P165, DOI 10.1016/j.isprsjprs.2009.10.004
   Shi WZ, 2014, IEEE T GEOSCI REMOTE, V52, P3359, DOI 10.1109/TGRS.2013.2272593
   Ünsalan C, 2012, IEEE T GEOSCI REMOTE, V50, P4441, DOI 10.1109/TGRS.2012.2190078
   Wang LZ, 2015, IEEE GEOSCI REMOTE S, V12, P736, DOI 10.1109/LGRS.2014.2360457
   Xu PF, 2012, J VIS COMMUN IMAGE R, V23, P827, DOI 10.1016/j.jvcir.2012.04.008
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang J, 2007, INT J REMOTE SENS, V28, P4653, DOI 10.1080/01431160701250382
   Yin DD, 2015, IEEE J-STARS, V8, P4785, DOI 10.1109/JSTARS.2015.2477097
   Yuan JY, 2011, IEEE T GEOSCI REMOTE, V49, P4528, DOI 10.1109/TGRS.2011.2146785
   Zhang C., 1999, ROAD NETWORK DETECTI, V8093
NR 35
TC 10
Z9 10
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 300
EP 311
DI 10.1016/j.jvcir.2016.06.024
PN A
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500026
DA 2024-07-18
ER

PT J
AU Xu, PF
   Zheng, X
   Chang, XJ
   Miao, QG
   Tang, ZY
   Chen, XJ
   Fang, DY
AF Xu, Pengfei
   Zheng, Xia
   Chang, Xiaojun
   Miao, Qiguang
   Tang, Zhanyong
   Chen, Xiaojiang
   Fang, Dingyi
TI Artistic information extraction from Chinese calligraphy works via
   Shear-Guided filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Artistic information extraction; Spirit information; Shear-Guided
   filter; Evaluation parameters; Chinese calligraphy works
ID IMAGE; RECOGNITION
AB Chinese calligraphy is a unique visual art, and is still emitting fascinating artistic brilliance and charm. The artistic beauty of Chinese calligraphy is constituted by two elements, i.e., form and spirit, which attract continual attentions by calligraphy artists. In this paper, we present Shear-Guided filter to extract the artistic information. Shear-Guided filter is designed by combining the shear transformation and the guided filter. It has both the edge-preserving smoothing property from the guided filter and the linear multidirectional property from the shear transformation. Shear-Guided filter can extract more spirit information from the calligraphy images, especially in the half-dry strokes. Furthermore, the previous evaluation parameters consider all pixels equally, which is against the truth. Here we put forward three new parameters to solve this issue. Finally, experiments show that Shear-Guided filter can extract the information of form and spirit more accurately, and the new evaluation parameters have better performances in evaluation. (C) 2016 Published by Elsevier Inc.
C1 [Xu, Pengfei; Tang, Zhanyong; Chen, Xiaojiang; Fang, Dingyi] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
   [Zheng, Xia] Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
   [Chang, Xiaojun] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia.
   [Miao, Qiguang] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Northwest University Xi'an; Zhejiang University; University of
   Technology Sydney; Xidian University
RP Zheng, X (corresponding author), Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
EM 455291381@qq.com
RI ; Chang, Xiaojun/A-2055-2015
OI Miao, Qiguang/0000-0002-2872-388X; Chang, Xiaojun/0000-0002-7778-8807;
   Fang, Dingyi/0000-0002-5816-6922
FU National Natural Science Foundations of China [61373177, 61502387,
   61202198, 61272195]; Natural Science Foundation of Shaanxi Province,
   China [2016JQ6029, 2014JM8310, 2010JM8027]; Science Research Project of
   the Education Department of Shanxi Province [15JK1748, 15JK1734];
   Science Foundations of Northwest University [14NW25, 14NW27, 14NW28]
FX The work was jointly supported by the National Natural Science
   Foundations of China under Grant Nos. 61373177, 61502387, 61202198 and
   61272195; Natural Science Foundation of Shaanxi Province, China, under
   Grant Nos. 2016JQ6029, 2014JM8310 and 2010JM8027; The Science Research
   Project of the Education Department of Shanxi Province under Grant Nos.
   15JK1748 and 15JK1734; The Science Foundations of Northwest University
   under Grant Nos. 14NW25, 14NW27, 14NW28.
CR Alameda-Pineda X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P5, DOI 10.1145/2733373.2806238
   [Anonymous], BIOMETRICS BIOINFORM
   [Anonymous], P 5 ACM INT C MULT R
   [Anonymous], P IS T SPIE EL IM BU
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Han YH, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P251, DOI 10.1145/2671188.2749290
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1665, DOI 10.1109/TMM.2014.2321530
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Liu XQ, 2012, IEEE T MULTIMEDIA, V14, P482, DOI 10.1109/TMM.2011.2177646
   Lu SJ, 2010, INT J DOC ANAL RECOG, V13, P303, DOI 10.1007/s10032-010-0130-8
   Lu WM, 2011, J ZHEJIANG U-SCI C, V12, P873, DOI 10.1631/jzus.C1100005
   Lu XQ, 2013, PROC INT CONF DOC, P240, DOI 10.1109/ICDAR.2013.55
   Miao QG, 2015, NEUROCOMPUTING, V168, P808, DOI 10.1016/j.neucom.2015.05.043
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   Nagy G, 2011, PROC INT CONF DOC, P977, DOI 10.1109/ICDAR.2011.198
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Wang W, 2016, 2016 IEEE INNOVATIVE SMART GRID TECHNOLOGIES - ASIA (ISGT-ASIA), P1, DOI [10.1109/ISGT-Asia.2016.7796352, 10.1109/CPEM.2016.7540636]
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Xia Y, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12207
   Xu SH, 2012, IEEE INTELL SYST, V27, P63, DOI 10.1109/MIS.2012.46
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Yi CC, 2014, IEEE T IMAGE PROCESS, V23, P2972, DOI 10.1109/TIP.2014.2317980
   Zhang Jun-song, 2006, Journal of Zhejiang University (Science), V7, P1178, DOI 10.1631/jzus.2006.A1178
   Zhang LM, 2016, IEEE T AUTOM SCI ENG, V13, P894, DOI 10.1109/TASE.2015.2418223
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P1538, DOI 10.1109/TMM.2015.2451954
   Zhang X., 2011, P 2011 WORKSHOP HIST, P37
   Zhang Y, 2013, ADV MECH ENG, V2013, P1, DOI DOI 10.4225/08/58B5BAAD4FCC2
   Zheng X., 2015, MULTIMED TOOLS APPL, P1
NR 35
TC 5
Z9 5
U1 2
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 791
EP 807
DI 10.1016/j.jvcir.2016.07.012
PN B
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600033
DA 2024-07-18
ER

PT J
AU Wang, XH
   Wan, Y
   Li, R
   Wang, JL
   Fang, LL
AF Wang, Xianghai
   Wan, Yu
   Li, Rui
   Wang, Jinling
   Fang, Lingling
TI A multi-object image segmentation C-V model based on region division and
   gradient guide
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-object image segmentation; C-V model; Gradient guide; Region
   division
ID ACTIVE CONTOURS; LEVEL
AB The Chan-Vese (C-V) model is an ineffective method for processing images in which the intensity is inhomogeneous. This is especially true for multi-object segmentation, in which the target may be missed or excessively segmented. In addition, for images with rich texture information, the processing speed of the C-V is slow. To overcome these problems, this paper proposes an effective multi-object C-V segmentation model based on region division and gradient guide. First, a rapid initial contour search is conducted using Otsu's method. This contour line becomes the initial contour for our multi-object segmentation C-V model based on a gradient guide. To achieve the multi-object segmentation the image is then converted to a single level set whose evolution is controlled using an adaptive gradient. The feasibility of the proposed model is analyzed theoretically, and a number of simulation experiments are conducted to validate its effectiveness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Xianghai; Wang, Jinling; Fang, Lingling] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Liaoning Provin, Peoples R China.
   [Wang, Xianghai; Wan, Yu; Li, Rui] Liaoning Normal Univ, Sch Math, Dalian 116029, Liaoning Provin, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University
RP Wang, XH (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Liaoning Provin, Peoples R China.
EM xhwang@lnnu.edu.cn; wanxiaoyu121@163.com; 754668577@qq.com;
   893651260@qq.com; fanglingling1985@163.com
RI wang, dan/JEF-0836-2023; Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939
FU Natural Science Foundation of China [41271422, 61402214]; Specialized
   Research Fund for the Doctoral Program of Higher Education of China
   [20132136110002]
FX This work is sponsored in part by Natural Science Foundation of China
   (41271422 and 61402214), Specialized Research Fund for the Doctoral
   Program of Higher Education of China (20132136110002).
CR [Anonymous], IEEE INT C COMP VIS
   Cao G, 2008, PATTERN RECOGN LETT, V29, P457, DOI 10.1016/j.patrec.2007.10.024
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   [陈波 CHEN Bo], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P11
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dai LZ, 2015, PATTERN RECOGN, V48, P2513, DOI 10.1016/j.patcog.2015.03.001
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang Dakai., 2008, Partial differential equation method on digital image processing, V1
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang X.H., 2014, J IMAGE GRAPH, V19, P207
   [王相海 Wang Xianghai], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P751
NR 12
TC 6
Z9 8
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 100
EP 106
DI 10.1016/j.jvcir.2016.05.011
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900010
DA 2024-07-18
ER

PT J
AU Zahedi, M
   Rahimi, M
AF Zahedi, Morteza
   Rahimi, Marziea
TI 3-D color histogram equalization by principal component analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color images; Image enhancement; Histogram equalization; Principal
   component analysis
ID IMAGE-ENHANCEMENT
AB Color histogram equalization is a method for improving visual appearance of images by enhancing image contrast. Color histogram equalization methods are mostly faced with problems like over-enhancement and brightening. In this paper a new color histogram equalization method is proposed which defines a new three dimensional cumulative distribution function based on a one-dimensional histogram. This one-dimensional histogram is calculated by taking into account the correlation between color channels using PCA. Over-enhancement and brightening are solved by this method because of applying the equalization on a transformed image instead of image itself. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zahedi, Morteza; Rahimi, Marziea] Shahrood Univ Technol, Sch Comp & IT Engn, Shahrood, Iran.
C3 Shahrood University of Technology
RP Rahimi, M (corresponding author), Shahrood Univ Technol, Sch Comp & IT Engn, Shahrood, Iran.
EM zahedi@shahroodut.ac.ir; marziea.rahimi@shahroodut.ac.ir
OI Zahedi, Morteza/0000-0002-8648-4514
CR Bassiou N, 2007, COMPUT VIS IMAGE UND, V107, P108, DOI 10.1016/j.cviu.2006.11.012
   BOCKSTEIN IM, 1986, J OPT SOC AM A, V3, P735, DOI 10.1364/JOSAA.3.000735
   Chen H.O., 2009, IEEE T CONSUM ELECTR, V55, P2072
   Du Q, 2008, INT J HIGH PERFORM C, V22, P438, DOI 10.1177/1094342007088380
   Forrest AK, 2005, IEE P-VIS IMAGE SIGN, V152, P677, DOI 10.1049/ip-vis:20045045
   Gonzalez R, 2009, DIGITAL IMAGE PROCES
   Han JH, 2011, IEEE T IMAGE PROCESS, V20, P506, DOI 10.1109/TIP.2010.2068555
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kim T, 2006, ELECTRON LETT, V42, P452, DOI 10.1049/el:20064207
   Lucchese L, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1077, DOI 10.1109/ICIP.2001.958684
   Menotti D., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P414, DOI 10.1109/IWSSIP.2007.4381129
   Mlsna PA, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1015, DOI 10.1109/ICIP.1996.561000
   MLSNA PA, 1995, IEEE T GEOSCI REMOTE, V33, P212, DOI 10.1109/36.368207
   Naik SK, 2003, IEEE T IMAGE PROCESS, V12, P1591, DOI 10.1109/TIP.2003.819231
   Pichon E, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P117
   Pitas I, 1996, IEEE T IMAGE PROCESS, V5, P168, DOI 10.1109/83.481684
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   Shlens J., 2005, ARXIV
   STRICKLAND RN, 1987, OPT ENG, V26, P609, DOI 10.1117/12.7974125
   TRAHANIAS PE, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P545, DOI 10.1109/ICPR.1992.202045
   Wang C, 2008, IET IMAGE PROCESS, V2, P249, DOI 10.1049/iet-ipr:20070198
   WEEKS AR, 1995, J ELECTRON IMAGING, V4, P15, DOI 10.1117/12.191335
   Zhang Q, 1996, PROCEEDINGS OF THE IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218, DOI 10.1109/IAI.1996.493756
NR 24
TC 4
Z9 5
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 58
EP 64
DI 10.1016/j.jvcir.2016.05.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900006
DA 2024-07-18
ER

PT J
AU Gbèhounou, S
   Lecellier, F
   Fernandez-Maloigne, C
AF Gbehounou, Syntyche
   Lecellier, Francois
   Fernandez-Maloigne, Christine
TI Evaluation of local and global descriptors for emotional impact
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Images; Local descriptors; Subjective evaluations; Emotions;
   Classification
ID COLOR PREFERENCE; REPRESENTATION; CLASSIFICATION; FEATURES
AB In order to model the concept of emotion and to extract the emotional impact from images, one may search suitable image processing features. However, in the literature, there is no consensus on the ones to consider since they are often linked to the application. Obviously, the perception of emotion is not only influenced by the content of the images, it is also modified by some personal experiences like cultural aspects and semantic associated to some colours or objects. In this paper, we choose low level features frequently used in CBIR especially those based on SIFT descriptors. To take into account the complex process of emotion perception, we also consider colour and texture features and one global scene descriptor: GIST. We supposed the chosen features could implicitly encode high-level information about emotions due to their accuracy in the different CBIR applications of the literature.
   We test our methodology on two databases: SENSE and IAPS. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Gbehounou, Syntyche; Lecellier, Francois; Fernandez-Maloigne, Christine] Univ Poitiers, XLIM Lab, UMR CNRS 7252, Poitiers, France.
C3 Universite de Poitiers
RP Lecellier, F (corresponding author), Univ Poitiers, XLIM Lab, UMR CNRS 7252, Poitiers, France.
EM syntyche.gbehounou@univ-poitiers.fr;
   fran-cois.lecellier@univ-poitiers.fr;
   christine.fernandez@univ-poitiers.fr
CR [Anonymous], 2007, P IEEE COMP SOC C CO
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], THESIS
   Beke L, 2008, COLOR RES APPL, V33, P381, DOI 10.1002/col.20434
   Boyatziz C., 1993, J GENET PSYCHOL, V155, P77
   Bradley MM, 2007, PSYCHOPHYSIOLOGY, V44, P364, DOI 10.1111/j.1469-8986.2007.00520.x
   Bradley MM, 2006, PSYCHOPHYSIOLOGY, V43, P486, DOI 10.1111/j.1469-8986.2006.00412.x
   Bradley MM, 2001, EMOTION, V1, P300, DOI 10.1037//1528-3542.1.3.300
   Demanet L, 2009, NUMER MATH, V113, P1, DOI 10.1007/s00211-009-0226-6
   Denis P., 2016, IMPROVEMENT NATURAL
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Fernandez-Maloigne C., 2012, Advanced color image processing and analysis
   Gbèhounou S, 2013, LECT NOTES COMPUT SC, V8047, P515, DOI 10.1007/978-3-642-40261-6_62
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kaya N., 2004, P AIC COL PAINTS INT
   Ke Y, 2004, PROC CVPR IEEE, P506
   Keil A, 2002, PSYCHOPHYSIOLOGY, V39, P641, DOI 10.1017/S0048577202394162
   Lang P. J., 2005, A6 U FLOR CTR RES PS
   Liu E., 2011, INT C COMP VIS THEOR
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucassen M. P., 2010, P CGIV
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Nister David, 2006, CVPR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ou LC, 2004, COLOR RES APPL, V29, P381, DOI 10.1002/col.20047
   Ou LC, 2004, COLOR RES APPL, V29, P292, DOI 10.1002/col.20024
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Paleari Marco, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P425, DOI 10.1109/CBMI.2008.4564978
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Solli M., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P398
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang WN, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4571
   Wei KP, 2008, LECT NOTES ARTIF INT, V5139, P485
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 39
TC 7
Z9 7
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 276
EP 283
DI 10.1016/j.jvcir.2016.03.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA DN5ZB
UT WOS:000377149100023
OA Green Submitted
DA 2024-07-18
ER

PT J
AU López-Fernández, D
   Madrid-Cuevas, FJ
   Carmona-Poyato, A
   Muñoz-Salinas, R
   Medina-Carnicer, R
AF Lopez-Fernandez, D.
   Madrid-Cuevas, F. J.
   Carmona-Poyato, A.
   Munoz-Salinas, R.
   Medina-Carnicer, R.
TI A new approach for multi-view gait recognition on unconstrained paths
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; Unconstrained paths; Rotation-invariant; Angular
   analysis; Curved trajectories; 3D reconstruction
ID IDENTIFICATION; IMAGE; MOTION
AB Direction changes cause difficulties for most of the gait recognition systems, due to appearance changes. We propose a new approach for multi-view gait recognition, which focuses on recognizing people walking on unconstrained (curved and straight) paths. To this effect, we present a new rotation invariant gait descriptor which is based on 3D angular analysis of the movement of the subject. Our method does not require the sequence to be split into gait cycles, and is able to provide a response before processing the whole sequence. A Support Vector Machine is used for classifying, and a sliding temporal window with majority vote policy is used to reinforce the classification results. The proposed approach has been experimentally validated on "AVA Multi-View Dataset" and "Kyushu University 4D Gait Database" and compared with related state-of-art work. Experimental results demonstrate the effectiveness of this approach in the problem of gait recognition on unconstrained paths. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lopez-Fernandez, D.; Madrid-Cuevas, F. J.; Carmona-Poyato, A.; Munoz-Salinas, R.; Medina-Carnicer, R.] Univ Cordoba, Dept Comp & Numer Anal, Maimonides Inst Biomed Res IMIBIC, Cordoba, Spain.
C3 Universidad de Cordoba
RP López-Fernández, D (corresponding author), Univ Cordoba, Comp & Numer Anal Dept, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
EM i52lofed@uco.es; fjmadrid@uco.es; ma1capoa@uco.es; rmsalinas@uco.es;
   rmedina@uco.es
RI Carmona-Poyato, Angel/G-1593-2015; Cuevas, Francisco José
   Madrid/H-1396-2015; Medina-Carnicer, Rafael/G-3401-2015; Munoz-Salinas,
   Rafael/K-5999-2014
OI Medina-Carnicer, Rafael/0000-0003-4481-0614; Lopez-Fernandez,
   David/0000-0003-2582-4260; Munoz-Salinas, Rafael/0000-0002-8773-8571
FU Science and Technology Ministry of Spain [TIN2012-32952]; FEDER
FX This work has been developed with the support of the Research Projects
   called TIN2012-32952 and BROCA both financed by Science and Technology
   Ministry of Spain and FEDER.
CR [Anonymous], P 21 BRIT MACH VIS C
   [Anonymous], 2012, 2012 INT C DIGITAL I
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Castro FM, 2014, INT C PATT RECOG, P1692, DOI 10.1109/ICPR.2014.298
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Cheng MH, 2008, PATTERN RECOGN, V41, P2541, DOI 10.1016/j.patcog.2007.11.021
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   Diaz-Más L, 2010, PATTERN RECOGN, V43, P2119, DOI 10.1016/j.patcog.2010.01.001
   Drinkwater DT., 1980, Kinanthropometry II, P177
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Gross J., 2001, Tech. Rep. CMU-RI-TR-01-18, V45, P1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Han J., 2005, IEEE INT C IM PROC 2, V3, P297
   Haro G, 2012, PATTERN RECOGN, V45, P3231, DOI 10.1016/j.patcog.2012.02.029
   Hofmann M., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P399, DOI 10.1109/BTAS.2012.6374606
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang PS, 1999, ARTIF INTELL ENG, V13, P359, DOI 10.1016/S0954-1810(99)00008-4
   Iwashita Y, 2014, PATTERN RECOGN LETT, V48, P60, DOI 10.1016/j.patrec.2014.04.004
   Jean F, 2009, PATTERN RECOGN, V42, P2936, DOI 10.1016/j.patcog.2009.05.006
   Jeong S, 2013, J SUPERCOMPUT, V65, P122, DOI 10.1007/s11227-013-0897-8
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P822, DOI 10.1016/j.jvcir.2014.01.012
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Liu NN, 2010, INT CONF ACOUST SPEE, P1410, DOI 10.1109/ICASSP.2010.5495466
   López-Fernández D, 2014, LECT NOTES COMPUT SC, V8703, P26, DOI 10.1007/978-3-319-13323-2_3
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Rougier C, 2011, IEEE ENG MED BIO, P5136, DOI 10.1109/IEMBS.2011.6091272
   Seely RD, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P135
   Shakhnarovich G., 2001, IEEE COMP SOC C COMP, V1
   Singh S, 2009, LECT NOTES COMPUT SC, V5909, P446, DOI 10.1007/978-3-642-11164-8_72
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Takahashi T, 2006, INT C PATT RECOG, P603
   Tsuji A, 2010, PROC CVPR IEEE, P717, DOI 10.1109/CVPR.2010.5540144
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Yous S, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P71
   Yu SQ, 2006, LECT NOTES COMPUT SC, V3851, P807
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 47
TC 23
Z9 25
U1 2
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 396
EP 406
DI 10.1016/j.jvcir.2016.03.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100034
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pan, XQ
   Chachada, S
   Kuo, CCJ
AF Pan, Xiaqing
   Chachada, Sachin
   Kuo, C-C. Jay
TI A two-stage shape retrieval (TSR) method with global and local features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 2D shape retrieval; Shape representation; MPEG-7 shape dataset; Kimia99
   dataset; Tari1000 dataset
ID IMAGE RETRIEVAL; RECOGNITION
AB A robust two-stage shape retrieval (TSR) method is proposed to address the 2D shape retrieval problem. Most state-of-the-art shape retrieval methods are based on local features matching and ranking. Their retrieval performance is not robust since they may retrieve globally dissimilar shapes in high ranks. To overcome this challenge, we decompose the decision process into two stages. In the first irrelevant cluster filtering (ICF) stage, we consider both global and local features and use them to predict the relevance of gallery shapes with respect to the query. Irrelevant shapes are removed from the candidate shape set. After that, a local-features-based matching and ranking (LMR) method follows in the second stage. We apply the proposed TSR system to MPEG-7, Kimia99 and Taril 000 three datasets and show that it outperforms all other existing methods. The robust retrieval performance of the TSR system is demonstrated. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pan, Xiaqing; Chachada, Sachin; Kuo, C-C. Jay] Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Pan, XQ (corresponding author), Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
EM xiaqingp@usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU University of Southern California's Center for High-Performance
   Computing
FX Computation for the work described in this paper was supported by the
   University of Southern California's Center for High-Performance
   Computing (hpc.usc.edu).
CR Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   [Anonymous], SURVEY MULTIVIEW LEA
   Aslan C, 2008, IEEE T PATTERN ANAL, V30, P2188, DOI 10.1109/TPAMI.2007.70842
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bai X, 2012, IEEE T IMAGE PROCESS, V21, P2747, DOI 10.1109/TIP.2011.2170082
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Dogan G, 2015, PROC CVPR IEEE, P4222, DOI 10.1109/CVPR.2015.7299050
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Felzenszwalb PF, 2007, PROC CVPR IEEE, P367
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Mokhtarian F, 1998, SER SOFTW ENGN KNOWL, V8, P51
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Pratt W.K., 2007, DIGITAL IMAGE PROCES, V4th ed., DOI DOI 10.1002/0470097434
   Premachandran V, 2013, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2013.209
   Qadeer N., 2015, ADV MULTIMEDIA, V2015, P3
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Xu C, 2014, PR MACH LEARN RES, V32, P865
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 40
TC 5
Z9 6
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 753
EP 762
DI 10.1016/j.jvcir.2016.04.021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100063
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, P
   Peng, Z
   Li, DL
   Yang, LJ
AF Chen, Peng
   Peng, Zhang
   Li, Dalong
   Yang, Lijuan
TI An improved augmented reality system based on AndAR
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE AndAR; Mobile augmented reality; Android platform; Registration; Inliers
   tracking; Feature extraction and matching; Low-level visual features;
   Architecture
AB AndAR is a project applied to develop Mobile Augmented Reality (MAR) applications on the android platform. The existing registration technologies of AndAR are still base on markers assume that all frames from all videos contain the target objects. With the need of practical application, the registration based on natural features is more popular, but the major limitation of the registration is that many of them are based on low-level visual features. This paper improves AndAR by introducing the planar natural features. The key of registration based on planar natural features is to get the homography matrix which can be calculated with more than 4 pairs of matching feature points, so a 3D registration method based on ORB and optical flow is proposed in this paper. ORB is used for feature point matching and RANSAC is used to choose good matches, called inliers, from all the matches. When the ratio of inliers is more than 50% in some video frame, inliers tracking based on optical flow is used to calculate the homography matrix in the latter frames and when the number of inliers successfully tracked is less than 4, then it goes back to ORB feature point matching again. The result shows that the improved AndAR can augment not only reality based on markers but also reality based on planar natural features in near real time and the hybrid approach can not only improve speed but also extend the usable tracking range. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Peng; Peng, Zhang; Li, Dalong; Yang, Lijuan] China Three Gorges Univ, Coll Comp & Informat Technol, Yichang, Peoples R China.
C3 China Three Gorges University
RP Chen, P (corresponding author), China Three Gorges Univ, Coll Comp & Informat Technol, Yichang, Peoples R China.
EM chenpeng@ctgu.edu.cn
RI chen, peng/HMD-1278-2023
FU National Natural Science Foundation of China [61272236]
FX The research work was supported by National Natural Science Foundation
   of China under Grant No. 61272236.
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Guan T, 2014, IEEE MULTIMEDIA, V21, P32, DOI 10.1109/MMUL.2013.31
   Guan T, 2013, IEEE T MULTIMEDIA, V15, P1688, DOI 10.1109/TMM.2013.2265674
   Huang B.B., 2012, PROC ANTICOUNTERFEIT, P1
   Ji R., 2011, ACM T MULTIM COMPUT, V7, P1, DOI DOI 10.1145/2037676.2037688
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo Ya-wei, 2013, Application Research of Computers, V30, P591, DOI 10.3969/j.issn.1001-3695.2013.02.076
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ufkes A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P226, DOI 10.1109/CRV.2013.51
   Vincent L, 2009, INT J COMPUT VISION, V81, P155
   Wei BC, 2014, IEEE MULTIMEDIA, V21, P41, DOI 10.1109/MMUL.2013.65
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
NR 19
TC 24
Z9 26
U1 3
U2 66
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 63
EP 69
DI 10.1016/j.jvcir.2015.06.016
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700009
DA 2024-07-18
ER

PT J
AU Li, P
   Bu, JJ
   Yu, J
   Chen, C
AF Li, Ping
   Bu, Jiajun
   Yu, Jun
   Chen, Chun
TI Towards robust subspace recovery via sparsity-constrained latent
   low-rank representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Latent low-rank representation; Sparse learning; Subspace clustering;
   Robust recovery; Visual analysis; Augmented Lagrangian Multiplier
   method; Feature extraction; Outlier detection
AB Robust recovery of subspace structures from noisy data has received much attention in visual analysis recently. To achieve this goal, previous works have developed a number of low-rank based methods, among of which Low-Rank Representation (LRR) is a typical one. As a refined variant, Latent LRR constructs the dictionary using both observed and hidden data to relieve the insufficient sampling problem. However, they fail to consider the observation that each data point can be represented by only a small subset of atoms in a dictionary. Motivated by this, we present the Sparse Latent Low-rank representation (SLL) method, which explicitly imposes the sparsity constraint on Latent LRR to encourage a sparse representation. In this way, each data point can be represented by only selecting a few points from the same subspace. Its objective function is solved by the linearized Augmented Lagrangian Multiplier method. Favorable experimental results on subspace clustering, salient feature extraction and outlier detection have verified promising performances of our method. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Li, Ping; Yu, Jun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
   [Bu, Jiajun; Chen, Chun] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University
RP Li, P (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
EM patriclouis.lee@gmail.com
OI Li, Ping/0000-0002-8515-7773
FU Zhejiang Provincial Natural Science Foundation of China [LQ15F020012];
   National Key Technology Support Program of China [2012BAI34B03]
FX This work was supported in part by Zhejiang Provincial Natural Science
   Foundation of China under Grant LQ15F020012 and the National Key
   Technology Support Program of China under Grant 2012BAI34B03.
CR [Anonymous], 2012, P INT C ART INT STAT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2011, ADV NEURAL INFORM PR
   Avron H, 2012, P 29 INT C MACH LEAR
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Deng Y, 2013, IEEE T NEUR NET LEAR, V24, P383, DOI 10.1109/TNNLS.2012.2235082
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365
   Fazel M., THESIS
   Haldar Justin P, 2009, IEEE Signal Process Lett, V16, P584, DOI 10.1109/LSP.2009.2018223
   He BS, 2000, J OPTIMIZ THEORY APP, V106, P337, DOI 10.1023/A:1004603514434
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Jaggi M., 2012, P 29 INT C MACH LEAR
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li P, 2015, SIGNAL PROCESS, V110, P222, DOI 10.1016/j.sigpro.2014.08.026
   Li P, 2013, NEUROCOMPUTING, V119, P243, DOI 10.1016/j.neucom.2013.03.034
   Liansheng Zhuang, 2012, P IEEE C COMP VIS PA
   Lin Z., 2009, The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu J, 2010, IEEE T NEURAL NETWOR, V21, P621, DOI 10.1109/TNN.2010.2040290
   Liu R. S., 2012, P IEEE C COMP VIS PA
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MARCHUK G. I., 1990, Handb. Numer. Anal., V1, P197, DOI DOI 10.1016/S1570-8659(05)80035-3
   Shen Y., 2012, OPTIMIZ METHODS SOFT
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894
   Wei S., CORR
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia Y., 2015, INFORM SCI IN PRESS
   Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   Yang HQ, 2011, IEEE T NEURAL NETWOR, V22, P433, DOI 10.1109/TNN.2010.2103571
   Yang JF, 2013, MATH COMPUT, V82, P301
   Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang Q., 2012, P 18 ACM SIGKDD INT
NR 50
TC 8
Z9 9
U1 0
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 46
EP 52
DI 10.1016/j.jvcir.2015.06.012
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700007
DA 2024-07-18
ER

PT J
AU Fernández-García, NL
   Martínez, LD
   Carmona-Poyato, A
   Madrid-Cuevas, FJ
   Medina-Carnicer, R
AF Fernandez-Garcia, N. L.
   Del-Moral Martinez, L.
   Carmona-Poyato, A.
   Madrid-Cuevas, F. J.
   Medina-Carnicer, R.
TI A new thresholding approach for automatic generation of polygonal
   approximations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital planar curves; Polygonal approximation; Dominant points;
   Significance of contour points; Thresholding techniques; Object
   recognition; Assessment of polygonal approximations; Corner points;
   Automatic algorithm
ID DOMINANT POINT DETECTION; DIGITAL PLANAR CURVES; SHAPE REPRESENTATION;
   ALGORITHM; POLYGONIZATION
AB The present paper proposes a new algorithm for automatic generation of polygonal approximations of 2D closed contours based on a new thresholding method. The new proposal computes the significance level of the contour points using a new symmetric version of the well-known Ramer, Douglas-Peucker method, and then a new Adaptive method is applied to threshold the normalized significance level of the contour points to generate the polygonal approximation. The experiments have shown that the new algorithm has good performance for generating polygonal approximations of 2D closed contours. Furthermore, the new algorithm does not require any parameter to be tuned. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Fernandez-Garcia, N. L.; Del-Moral Martinez, L.; Carmona-Poyato, A.; Madrid-Cuevas, F. J.; Medina-Carnicer, R.] Univ Cordoba, Dept Comp & Numer Anal, Maimonides Inst Biomed Res IMIBIC, Cordoba, Spain.
C3 Universidad de Cordoba
RP Fernández-García, NL (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, Maimonides Inst Biomed Res IMIBIC, Cordoba, Spain.
EM ma1fegan@uco.es; i52momal@uco.es; ma1capoa@uco.es; ma1macuf@uco.es;
   rmedina@uco.es
RI Carmona-Poyato, Angel/G-1593-2015; Fernández García, Nicolás
   Luis/AAP-9118-2021; Cuevas, Francisco José Madrid/H-1396-2015;
   Medina-Carnicer, Rafael/G-3401-2015
OI Fernández García, Nicolás Luis/0000-0002-1267-6986; Medina-Carnicer,
   Rafael/0000-0003-4481-0614
FU Economy and Competitiveness Ministry of Spain [TIN2012-32952]; BROCA -
   Economy and Competitiveness Ministry of Spain; FEDER
FX This work has been developed with the support of the Research Projects
   called TIN2012-32952 and BROCA both financed by Economy and
   Competitiveness Ministry of Spain and FEDER.
CR Aguilera-Aguilera EJ, 2015, J VIS COMMUN IMAGE R, V30, P106, DOI 10.1016/j.jvcir.2015.03.007
   Ataer-Cansizoglu E, 2013, PATTERN RECOGN, V46, P1140, DOI 10.1016/j.patcog.2012.10.014
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   CARMONAPOYATO A, 2011, PATTERN RECOGN, V4, P44
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Ebisch K, 2002, COMPUT GEOSCI-UK, V28, P995, DOI 10.1016/S0098-3004(02)00009-2
   HERSHBERGER J, 1992, PROCEEDINGS : 5TH INTERNATIONAL SYMPOSIUM ON SPATIAL DATA HANDLING, VOLS 1 AND 2, P134
   Horng JH, 2002, PATTERN RECOGN LETT, V23, P171, DOI 10.1016/S0167-8655(01)00098-8
   Inesta JM, 1998, PATTERN RECOGN, V31, P685, DOI 10.1016/S0031-3203(97)00081-2
   Jeannin S., 1999, ISOIECJTC1SC29WG11MP
   Kolesnikov A, 2007, PATTERN RECOGN, V40, P1282, DOI 10.1016/j.patcog.2006.09.002
   Kolesnikov A, 2014, PATTERN RECOGN, V47, P623, DOI 10.1016/j.patcog.2013.09.002
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   Masood A, 2007, J VIS COMMUN IMAGE R, V18, P264, DOI 10.1016/j.jvcir.2006.12.002
   Melkman A., 1998, COMPUTATIONAL MORPHO, P87
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   Parvez MT, 2015, IMAGE VISION COMPUT, V34, P1, DOI 10.1016/j.imavis.2014.10.012
   Parvez MT, 2010, PATTERN RECOGN LETT, V31, P1997, DOI 10.1016/j.patrec.2010.06.007
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PIKAZ A, 1995, PATTERN RECOGN, V28, P373, DOI 10.1016/0031-3203(94)00108-X
   Prasad DK, 2012, IMAGE VISION COMPUT, V30, P843, DOI 10.1016/j.imavis.2012.06.010
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Salotti M, 2002, PATTERN RECOGN, V35, P435, DOI 10.1016/S0031-3203(01)00051-6
   Salotti M, 2001, PATTERN RECOGN LETT, V22, P215, DOI 10.1016/S0167-8655(00)00088-X
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   Urdiales C, 2002, PATTERN RECOGN, V35, P43, DOI 10.1016/S0031-3203(01)00041-3
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 39
TC 9
Z9 9
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 155
EP 168
DI 10.1016/j.jvcir.2015.12.013
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qi, M
   Li, BZ
   Sun, HF
AF Qi, Min
   Li, Bing-Zhao
   Sun, Huafei
TI Image representation by harmonic transforms with parameters in
   <i>SL</i>(<i>2</i>, <i>R</i>)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; Orthogonal moments and transforms; 2-D linear
   canonical transform; Polar harmonic linear canonical transform; 2-D
   linear canonical transform series; Kernel; Transform coefficients;
   Parameter sensitivity
ID LINEAR CANONICAL TRANSFORM; FOURIER-MELLIN MOMENTS; PATTERN-RECOGNITION;
   ZERNIKE MOMENTS; COMPUTATION; INVARIANTS
AB In this paper, a kind of invariant harmonic transforms with parameters in SL(2,R) are proposed, which include the polar linear canonical transform (PLCT) and the two-dimensional linear canonical transform series (2-D LCTS). The capabilities of the PLCT and the 2-D LCTS on image representation are analyzed. The experimental results show that the 2-D LCTS has much stronger capability on the image representation with respect to characters, and has better invariance of scale and noise than the other transforms. Moreover, due to the varieties of parameters, the performance of the image representation is going bad when parameters used in the reconstructing process are inconsistent with those in the decomposing process. In other words, the proposed transforms can be used for the protection of the image safety because they have free parameters than the traditional methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Qi, Min; Li, Bing-Zhao; Sun, Huafei] Beijing Inst Technol, Sch Math & Stat, Beijing 100081, Peoples R China.
   [Li, Bing-Zhao; Sun, Huafei] Beijing Inst Technol, Beijing Key Lab MCAACI, Beijing 100081, Peoples R China.
   [Qi, Min] Beijing Coll Finance & Commerce, Beijing 110000, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology;
   Beijing College of Finance & Commerce
RP Li, BZ (corresponding author), Beijing Inst Technol, Sch Math & Stat, Beijing 100081, Peoples R China.
EM li_bingzhao@bit.edu.cn
RI Li, Bing-Zhao/B-5165-2009
FU National Natural Science Foundation of China [61179031, 61171195,
   10932002]; Program for New Century Excellent Talents in University
   [NCET-12-0042]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61179031, 61171195 and 10932002), and is also supported by
   Program for New Century Excellent Talents in University (No.
   NCET-12-0042).
CR ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617
   ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   Campos RG, 2011, SIGNAL PROCESS, V91, P1444, DOI 10.1016/j.sigpro.2010.07.007
   Coatrieux JL, 2008, IEEE ENG MED BIOL, V27, P81, DOI [10.1109/MEMB.2007.911462, 10.1109/MEMB.20O7.911462]
   COLLINS SA, 1970, J OPT SOC AM, V60, P1168, DOI 10.1364/JOSA.60.001168
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Foon NH, 2004, I C COMP GRAPH IM VI, P65
   GHOSAL S, 1994, IEEE T IMAGE PROCESS, V3, P14, DOI 10.1109/83.265977
   Healy JJ, 2009, SIGNAL PROCESS, V89, P641, DOI 10.1016/j.sigpro.2008.10.011
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Koç A, 2008, IEEE T SIGNAL PROCES, V56, P2383, DOI 10.1109/TSP.2007.912890
   Li BZ, 2007, SIGNAL PROCESS, V87, P983, DOI 10.1016/j.sigpro.2006.09.008
   Li CP, 2012, SIGNAL PROCESS, V92, P1658, DOI 10.1016/j.sigpro.2011.12.024
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Liu YL, 2010, SIGNAL PROCESS, V90, P933, DOI 10.1016/j.sigpro.2009.09.030
   MOSHINSKY M, 1971, J MATH PHYS, V12, P1772, DOI 10.1063/1.1665805
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Ren HP, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P307, DOI 10.1109/FSKD.2007.213
   SHENG Y, 1986, J OPT SOC AM A, V3, P885, DOI 10.1364/JOSAA.3.000885
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Shu HZ, 2008, IEEE ENG MED BIOL, V27, P89, DOI 10.1109/MEMB.2008.918690
   Shu HZ, 2007, IEEE ENG MED BIOL, V26, P70, DOI 10.1109/EMB.2007.906026
   Singh C, 2012, IET IMAGE PROCESS, V6, P617, DOI 10.1049/iet-ipr.2011.0510
   Singh C, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013034
   Singh C, 2013, INFORM SCIENCES, V233, P255, DOI 10.1016/j.ins.2013.01.012
   Stern Adrian, 2007, Signal, Image and Video Processing, V1, P359, DOI 10.1007/s11760-007-0029-0
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wei DY, 2009, IEEE SIGNAL PROC LET, V16, P853, DOI 10.1109/LSP.2009.2026107
   Wolf K.B., 1979, INTEGRAL TRANSFORMS, V11
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
   Xu GL, 2009, IET SIGNAL PROCESS, V3, P392, DOI 10.1049/iet-spr.2008.0102
   Xu TZ., 2013, LINEAR CANONICAL TRA
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zhao J, 2013, SIGNAL PROCESS, V93, P695, DOI 10.1016/j.sigpro.2012.09.008
NR 40
TC 8
Z9 8
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 184
EP 192
DI 10.1016/j.jvcir.2015.12.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600016
DA 2024-07-18
ER

PT J
AU Jung, CK
   Chen, XF
   Cai, JJ
   Lei, HZ
   Yun, I
   Kim, J
AF Jung, Cheolkon
   Chen, Xufeng
   Cai, Jiji
   Lei, Haozhen
   Yun, Inyong
   Kim, Joongkyu
TI Boundary-preserving stereo matching with certain region detection and
   adaptive disparity adjustment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Disparity estimation; Image segmentation; Stereo matching; Disparity
   adjustment; Disparity classification; Boundary-preserving; Certain
   region detection; Stereoscopic 3D
ID PARALLEL FRAMEWORK; MOTION ESTIMATION; ALGORITHM; WINDOW
AB In this paper, we propose boundary-preserving stereo matching using certain region detection and adaptive disparity adjustment. The main contribution of the proposed method lies in the detection and adjustment of incorrect disparities. In the detection process, we detect certain regions in initial disparity maps to distinguish errors in disparity caused by the disparity discontinuity. In the adjustment process, we adjust the disparity map to reduce the adverse effect of errors in disparity using the certain region detection results. Based on the color similarity, spatial distance, and the reliability of the certain and uncertain regions, we set an adaptive support-weight to each pixel for adjusting the accuracy. Experimental results demonstrate that the proposed method produces high-quality disparity maps by successfully preserving disparity discontinuities along the object boundaries. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jung, Cheolkon; Chen, Xufeng; Cai, Jiji; Lei, Haozhen] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Yun, Inyong; Kim, Joongkyu] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
C3 Xidian University; Sungkyunkwan University (SKKU)
RP Jung, CK (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM zhengzk@xidian.edu.cn
FU National Natural Science Foundation of China [61271298]; International
   S&T Cooperation Program of China [2014DFG12780]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments that have led to improvements in the quality and
   presentation of the paper. This work was supported by the National
   Natural Science Foundation of China (No. 61271298) and the International
   S&T Cooperation Program of China (No. 2014DFG12780).
CR [Anonymous], P 3 CAN C COMP ROB V
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2007, P IEEE COMP SOC C CO
   Birchfield S.T., 2007, IMAGE VISION COMPUT
   Bleyer M, 2005, ISPRS J PHOTOGRAMM, V59, P128, DOI 10.1016/j.isprsjprs.2005.02.008
   Chan SC, 2007, IEEE SIGNAL PROC MAG, V24, P22, DOI 10.1109/MSP.2007.905702
   Deng Y, 2007, IEEE T PATTERN ANAL, V29, P1068, DOI 10.1109/TPAMI.2007.1043
   Gonzalez V., 2009, C MULT
   Gu Z, 2008, PATTERN RECOGN LETT, V29, P1230, DOI 10.1016/j.patrec.2008.01.032
   Hawi F, 2012, PR IEEE COMP DESIGN, P256, DOI 10.1109/ICCD.2012.6378649
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmuller H., 2007, P IEEE COMP SOC C CO
   Hong L, 2004, PROC CVPR IEEE, P74
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Karim HA, 2010, IEEE T CONSUM ELECTR, V56, P1705, DOI 10.1109/TCE.2010.5606316
   Klaus A, 2006, INT C PATT RECOG, P15
   Li WF, 2009, IEEE T CIRC SYST VID, V19, P533, DOI 10.1109/TCSVT.2009.2014021
   Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54
   Manap N.A., 2012, J TELECOMMUN ELECT C, V4, P51
   Michael M, 2013, IEEE INT VEH SYM, P1197, DOI 10.1109/IVS.2013.6629629
   Prazdny K., 1985, BIOL CYBERN
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Shen LQ, 2010, IEEE T CIRC SYST VID, V20, P925, DOI 10.1109/TCSVT.2010.2045910
   Sun J, 2005, PROC CVPR IEEE, P399
   Veksler O, 2003, PROC CVPR IEEE, P556
   Wang LH, 2010, IEEE T BROADCAST, V56, P425, DOI 10.1109/TBC.2010.2053971
   Xu Y., 2002, P INT C PATT REC
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yoon SU, 2007, IEEE T CIRC SYST VID, V17, P1450, DOI 10.1109/TCSVT.2007.905363
NR 32
TC 10
Z9 11
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 1
EP 9
DI 10.1016/j.jvcir.2015.08.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700001
DA 2024-07-18
ER

PT J
AU Qu, XC
   Kim, S
   Cui, R
   Kim, HJ
AF Qu, Xiaochao
   Kim, Suah
   Cui, Run
   Kim, Hyoung Joong
TI Linear collaborative discriminant regression classification for face
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Feature extraction; Dimensionality reduction;
   Collaborative representation; Sparse representation; Linear regression
   classification; Linear collaborative discriminant regression
   classification; Linear discriminant regression classification
ID REPRESENTATION
AB This paper proposes a novel face recognition method that improves Huang's linear discriminant regression classification (LDRC) algorithm. The original work finds a discriminant subspace by maximizing the between-class reconstruction error and minimizing the within-class reconstruction error simultaneously, where the reconstruction error is obtained using Linear Regression Classification (LRC). However, the maximization of the overall between-class reconstruction error is easily dominated by some large class-specific between-class reconstruction errors, which makes the following LRC erroneous. This paper adopts a better between-class reconstruction error measurement which is obtained using the collaborative representation instead of class-specific representation and can be regarded as the lower bound of all the class-specific between-class reconstruction errors. Therefore, the maximization of the collaborative between-class reconstruction error maximizes each class-specific between-class reconstruction and emphasizes the small class-specific between-class reconstruction errors, which is beneficial for the following LRC. Extensive experiments are conducted and the effectiveness of the proposed method is verified. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Qu, Xiaochao; Kim, Suah; Cui, Run; Kim, Hyoung Joong] Korea Univ, Grad Sch Informat Secur & Management, Seoul 136713, South Korea.
C3 Korea University
RP Kim, HJ (corresponding author), Korea Univ, Grad Sch Informat Secur & Management, Anam Dong 5ga, Seoul 136713, South Korea.
EM quxiaochao@gmail.com; suahnkim@gmail.com; cuirun@korea.ac.kr;
   khj-@korea.ac.kr
OI Kim, Suah/0000-0003-1692-2790
FU Technology Innovation Program - Ministry of Trade, Industry & Energy
   (MI, Korea) [10050653]; Korea University; National Nature Science
   Foundation of China [61170207]
FX This work was supported by the Technology Innovation Program (No.
   10050653, Research-standardization project for multimedia Integrity
   verification via reversible data hiding technique), funded by the
   Ministry of Trade, Industry & Energy (MI, Korea). This research was
   supported by Korea University. This research is partially supported by
   the National Nature Science Foundation of China (No. 61170207).
CR [Anonymous], 2007, PROC IEEE INT C COMP
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen HT, 2005, PROC CVPR IEEE, P846
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P91, DOI 10.1109/LSP.2012.2230257
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lu YW, 2014, NEURAL COMPUT APPL, V24, P1843, DOI 10.1007/s00521-013-1435-6
   Martinez A., 1998, AR FACE DATABASE
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Niyogi X., NEURAL INFORM PROCES, V16, P153
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Tang X, 2014, NEUROCOMPUTING, V145, P402, DOI 10.1016/j.neucom.2014.05.012
   Timofte R, 2014, PATTERN RECOGN LETT, V43, P127, DOI 10.1016/j.patrec.2013.08.010
   TURK M, P IEEE C COMP VIS PA, P586
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 27
TC 11
Z9 11
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 312
EP 319
DI 10.1016/j.jvcir.2015.07.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600028
DA 2024-07-18
ER

PT J
AU Schwartz, S
   Wong, A
   Clausi, DA
AF Schwartz, Shimon
   Wong, Alexander
   Clausi, David A.
TI Optimized sampling distribution based on nonparametric learning for
   improved compressive sensing performance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed sampling; Compressive sensing; Sparse measurements; Data
   acquisition; Learned sampling distribution; Fluorescence microscopy;
   Laser range measurement; Markov chain Monte Carlo (MCMC)
ID SPARSE RECONSTRUCTION
AB In this work, an optimized nonparametric learning approach for obtaining the data-guided sampling distribution is proposed, where a probability density function (pdf) is learned in a nonparametric manner based on past measurements from similar types of signals. This learned sampling distribution is then used to better optimize the sampling process based on the underlying signal characteristics. A realization of this stochastic learning approach for compressive sensing of imaging data is introduced via a stochastic Monte Carlo optimization strategy to learn a nonparametric sampling distribution based on visual saliency. Experiments were performed using different types of signals such as fluorescence microscopy images and laser range measurements. Results show that the proposed optimized sampling method which is based on nonparametric stochastic learning outperforms significantly the previously proposed approach. The proposed method is achieves higher reconstruction signal to noise ratios at the same compression rates across all tested types of signals. Crown Copyright (C) 2015 Published by Elsevier Inc. All rights reserved.
C1 [Schwartz, Shimon; Wong, Alexander; Clausi, David A.] Univ Waterloo, Dept Syst Design Engn, Res Grp, Vis & Image Proc Lab, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Schwartz, S (corresponding author), Univ Waterloo, Dept Syst Design Engn, Res Grp, Vis & Image Proc Lab, Waterloo, ON N2L 3G1, Canada.
EM tsschwar@uwaterloo.ca; a28wong@uwaterloo.ca; dclausi@uwaterloo.ca
RI Clausi, David A/J-4613-2013; Wong, Alexander/GZM-2929-2022
OI Wong, Alexander/0000-0002-5295-2797
FU Natural Sciences and Engineering Research Council of Canada; Canada
   Research Chairs Program; Ontario Ministry of Research and Innovation
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada, the Canada Research Chairs Program, and the Ontario
   Ministry of Research and Innovation. The authors would also like to
   thank National Research Council Canada (NRC) and The Brown University
   pattern theory group for the test laser range data as well as Yeast
   Resource Center - University of Washington in Seattle for the test
   fluorescence microscopy data.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Andrieu C, 2008, STAT COMPUT, V18, P343, DOI 10.1007/s11222-008-9110-y
   Arias-Castro E., FUNDAMENTAL LIMITS A
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bruckstein AM, 2008, IEEE T INFORM THEORY, V54, P4813, DOI 10.1109/TIT.2008.929920
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Castro R., ADAPTIVE SENSING PER
   Chen JW, 2014, DIGIT SIGNAL PROCESS, V29, P54, DOI 10.1016/j.dsp.2014.02.011
   Chib S, 2005, STAT NEERL, V59, P30, DOI 10.1111/j.1467-9574.2005.00277.x
   CHIB S, 1995, AM STAT, V49, P327, DOI 10.2307/2684568
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Duarte MF, 2011, IEEE T SIGNAL PROCES, V59, P4053, DOI 10.1109/TSP.2011.2161982
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Elad M., 2007, P SPIE WAV 12 SAN DI
   Gamerman Dani., 1997, Stochastic simulation for Bayesian inference
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Haupt J., SEQUENTIALLY DESIGNE
   Hou X., COMPUTER VISION PATT
   Liu CY, 2012, OPT EXPRESS, V20, DOI 10.1364/OE.20.010200
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Puy G, 2011, IEEE SIGNAL PROC LET, V18, P595, DOI 10.1109/LSP.2011.2163712
   Riffle M, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-263
   Rioux M., 29077 CNRC
   Robucci R, 2008, INT CONF ACOUST SPEE, P5125, DOI 10.1109/ICASSP.2008.4518812
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   Schwartz S., 2012, 2012 Canadian Conference on Computer and Robot Vision, P1, DOI 10.1109/CRV.2012.8
   Schwartz S, 2013, J VIS COMMUN IMAGE R, V24, P160, DOI 10.1016/j.jvcir.2012.02.002
   Schwartz S, 2013, OPT EXPRESS, V21, P329, DOI 10.1364/OE.21.000329
   Schwartz S, 2012, IEEE ENG MED BIO, P4365, DOI 10.1109/EMBC.2012.6346933
   Schwartz S, 2012, OPT EXPRESS, V20, P17281, DOI 10.1364/OE.20.017281
   Stankovic I., RECOVERY IMAGES MISS
   Stankovic L, 2014, IET SIGNAL PROCESS, V8, P246, DOI 10.1049/iet-spr.2013.0385
   The Brown University Pattern Theory Group, 2000, BROWN RANG IM DAT
   Wang ZM, 2010, IEEE T IMAGE PROCESS, V19, P264, DOI 10.1109/TIP.2009.2032889
   Wong A. M., 2010, IEEE T BIOMED ENG, P1
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Zhang X., 2012, OPTICAL ENG, V51
NR 38
TC 1
Z9 1
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 26
EP 40
DI 10.1016/j.jvcir.2015.05.010
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600003
DA 2024-07-18
ER

PT J
AU Qian, ZX
   Zhang, XP
   Ren, YL
AF Qian, Zhenxing
   Zhang, Xinpeng
   Ren, Yanli
TI JPEG encryption for image rescaling in the encrypted domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Signal processing; Encrypted domain; Image rescaling; Privacy
   preserving; Compression; JPEG; Discrete cosine transfrom; Cloud storage
AB This work proposes a novel protocol of encrypting the JPEG image suitable for image rescaling in the encrypted domain. To protect the privacy of original content, the image owner perturbs the texture and randomizes the structure of the JPEG image by enciphering the quantized Discrete Cosine Transform (DCT) coefficients. After receiving the encrypted JPEG image, the service provider generates a rescaled JPEG image by down-sampling the encrypted DCT coefficients. On the recipient side, the encrypted JPEG image rescaled by the service provider can be decrypted to a plaintext image with a lower resolution with the aid of encryption keys. Experimental results show that the proposed method has a good capability of rescaling the privacy-protected JPEG file. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Qian, Zhenxing; Zhang, Xinpeng; Ren, Yanli] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Qian, ZX (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM zxqian@shu.edu.cn; xzhang@shu.edu.cn; renyanli@shu.edu.cn
RI Qian, Zhenxing/AHC-9176-2022
FU Shanghai Rising-Star Program [14QA1401900]; Natural Science Foundation
   of China [61103181, 61202367, 61472235]; Natural Science Foundation of
   Shanghai [12ZR1443700, 14ZR1415100]; Innovation Program of Shanghai
   Municipal Education Commission [14YZ020]
FX This work was supported by Shanghai Rising-Star Program under Grant
   14QA1401900, the Natural Science Foundation of China under Grant
   61103181, Grant 61202367 and Grant 61472235, the Natural Science
   Foundation of Shanghai under Grant 12ZR1443700 and Grant 14ZR1415100,
   and the Innovation Program of Shanghai Municipal Education Commission
   under Grant 14YZ020.
CR Barni M., IEEE T SIGNAL PROCES, V30
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Deng MN, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P9
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Erkin Z., 2008, EURASIP J INFORM SEC, V2007
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Ghosh A, 2012, SIAM J COMPUT, V41, P1673, DOI 10.1137/09076828X
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Merhav N, 1997, IEEE T CIRC SYST VID, V7, P468, DOI 10.1109/76.585926
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Sankar L, 2013, IEEE SIGNAL PROC MAG, V30, P95, DOI 10.1109/MSP.2013.2264541
   Schaefer G., 2004, P SPIE STORAGE RETRI, V5307
   Zhang XP, 2012, IEEE T IMAGE PROCESS, V21, P3108, DOI 10.1109/TIP.2012.2187671
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
NR 21
TC 6
Z9 6
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 9
EP 13
DI 10.1016/j.jvcir.2014.10.008
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000002
DA 2024-07-18
ER

PT J
AU Sajjad, M
   Mehmood, I
   Baik, SW
AF Sajjad, Muhammad
   Mehmood, Irfan
   Baik, Sung Wook
TI Image super-resolution using sparse coding over redundant dictionary
   based on effective image representations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Reconstruction; Denoising;
   Representation-coefficients; Sparse-coding; vercomplete-dictionary;
   Visual-saliency; Pursuit algorithm
ID SIMPLE CELLS; REGRESSION
AB Recent years have shown a growing research interest in the sparse-representation of signals. Signals are described through sparse linear combinations of signal-atoms over a redundant-dictionary. Therefore, we propose a novel super-resolution framework using an overcomplete-dictionary based on effective imagerepresentations such as edges, contours and high-order structures. This scheme recovers the vector of common sparse-representations between low-resolution and corresponding high-resolution imagepatches by solving the l(1)-regularized least-squared problem; subsequently, it reconstructs the HR output by multiplying it with the learned dictionary. The dictionary used in the proposed-technique contains more effective image-representations than those in previous approaches because it contains featuredescriptors such as edges, contours and motion-selective features. Therefore, the proposed-technique is more robust to various types of distortion. A saliency-map quickens this technique by confining the optimization-process to visually salient regions. Experimental analyses confirm the effectiveness of the proposed-scheme, and its quantitative and qualitative performance as compared with other state-of-the-art super-resolution algorithms. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Sajjad, Muhammad; Mehmood, Irfan; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM sajjad@sju.ac.kr; irfanmehmood@sju.ac.kr; sbaik@sejong.ac.kr
RI Sajjad, Muhammad/L-5269-2016; Sajjad, Muhammad/GZL-4962-2022; Baik, Sung
   Wook/AAR-8236-2020
OI Sajjad, Muhammad/0000-0001-5646-0338; Sajjad,
   Muhammad/0000-0003-0006-1156; Baik, Sung Wook/0000-0002-6678-7788;
   Mehmood, Irfan/0000-0001-7864-957X
FU MSIP (Ministry of Science, ICT & Future Planning), South Korea in the
   ICT RD Program [R0112-14-1014]
FX This research is supported by MSIP (Ministry of Science, ICT & Future
   Planning), South Korea in the ICT R&D Program 2014 (R0112-14-1014).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   ALBRECHT DG, 1991, VISUAL NEUROSCI, V7, P531, DOI 10.1017/S0952523800010336
   [Anonymous], ANAL VISUAL BEHAV
   [Anonymous], REDW CTR THEOR NEUT
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], J MACH LEARN RES
   [Anonymous], P SPIE C HUMAN VISIO
   [Anonymous], J VIS
   [Anonymous], P EUR SIGN PROC C LA
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1007/978-3-642-14267-3_2
   [Anonymous], P EUR SIGN PROC C EU
   [Anonymous], P SPIE
   [Anonymous], MATH TECHNIQUE UNPUB
   [Anonymous], ABOUT SPARSELAB
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Cadieu C., 2009, Advances in Neural Information Processing Systems 21 (NIPS'08), P209
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Dong WS, 2013, J VIS COMMUN IMAGE R, V24, P1055, DOI 10.1016/j.jvcir.2013.06.019
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   HUBEL DH, 1959, J PHYSIOL-LONDON, V147, P226, DOI 10.1113/jphysiol.1959.sp006238
   Jurio A, 2011, IEEE T IMAGE PROCESS, V20, P3112, DOI 10.1109/TIP.2011.2158227
   Kulkarni N, 2012, IEEE T CIRC SYST VID, V22, P778, DOI 10.1109/TCSVT.2011.2180773
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Lou YF, 2011, J MATH IMAGING VIS, V39, P1, DOI 10.1007/s10851-010-0220-8
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Sajjad M., 2012, MULTIMED TOOLS APPL, P1
   Sajjad M, 2015, MULTIMED TOOLS APPL, V74, P8961, DOI 10.1007/s11042-013-1570-1
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sheikh H. R., 2003, Image and video quality assessment research at live
   Simoncelli EP, 1998, VISION RES, V38, P743, DOI 10.1016/S0042-6989(97)00183-1
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tipping M.E., 2002, ADV NEURAL INFORM PR, P1279
   Touryan J, 2005, NEURON, V45, P781, DOI 10.1016/j.neuron.2005.01.029
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Wang JJ, 2010, PATTERN RECOGN LETT, V31, P1, DOI 10.1016/j.patrec.2009.09.004
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weisberg S, 2014, APPL LINEAR REGRESSI
   Xiong HK, 2013, IEEE T CIRC SYST VID, V23, P710, DOI 10.1109/TCSVT.2012.2221271
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2012, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2012.6247948
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2010, LECT NOTES COMPUT SC, V6313, P566
NR 65
TC 26
Z9 28
U1 0
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 50
EP 65
DI 10.1016/j.jvcir.2014.10.012
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000006
DA 2024-07-18
ER

PT J
AU Yan, XH
   Wang, S
   Niu, XM
   Yang, CN
AF Yan, Xuehu
   Wang, Shen
   Niu, Xiamu
   Yang, Ching-Nung
TI Random grid-based visual secret sharing with multiple decryptions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptographic scheme; Visual secretsharing; Progressive visual
   secret sharing; Random grids; Loss less recovery; Pixel expansion;
   Threshold; Multiple decryptions
ID IMAGE ENCRYPTION; CRYPTOGRAPHY
AB Visual cryptographic scheme (VCS) with multiple decryptions has the features of both OR-based VCS (OVCS) and XOR-based VCS (XVCS), which can be applied in wider applications. In this paper, a threshold VCS with the abilities of OR and XOR decryptions is proposed based on random grids CRC). If a copy machine is not available, the secret could be reconstructed by stacking. On the other hand, if a device having XOR operation is available, the visual quality of the recovered secret image is improved as well as the secret can be reconstructed losslessly for (k, n) threshold (case) when n shares are collected. Experiments are conducted to evaluate the security and efficiency of the proposed scheme. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yan, Xuehu; Wang, Shen; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept CSIE, Hualien 974, Taiwan.
C3 Harbin Institute of Technology; National Dong Hwa University
RP Yan, XH (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM shen.wang@hit.edu.cn
RI Yang, Ching-Nung/HKV-1639-2023; Yan, Xuehu/AFK-3139-2022; Yan,
   Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720; Yang,
   Ching-Nung/0000-0002-3881-7329
FU National Natural Science Foundation of China [61100187, 61301099,
   61361166006]
FX The authors wish to thank the anonymous reviewers for their suggestions
   to improve this paper. This work is supported by the National Natural
   Science Foundation of China (Grant Nos.: 61100187, 61301099,
   61361166006). The authors wish to thank Prof. Daoshun Wang for his
   discussions and Dr. Mahmoud Emam for his suggestions to improve this
   paper.
CR Chen T.H., 2008, P 18 INF SEC C
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yi Feng, 2008, Journal of Tsinghua University (Science and Technology), V48, P121
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 23
TC 21
Z9 21
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 94
EP 104
DI 10.1016/j.jvcir.2014.11.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000009
DA 2024-07-18
ER

PT J
AU Fan, Q
   Qi, C
AF Fan, Qiang
   Qi, Chun
TI Two-stage salient region detection by exploiting multiple priors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Superpixel isolation; Superpxiel distribution; Location prior; Multiple
   priors; Salient region; Two-stage; Image-feature-based; Precision/recall
   rate
ID VISUAL-ATTENTION; COLOR
AB Saliency detection has become a valuable tool for many image processing tasks, like image retargeting, object recognition, and adaptive compression. With the rapid development of the saliency detection methods, people have approved the hypothesis that "the appearance contrast between the salient object and the background is high", and build their saliency methods on some priors that explain this hypothesis. However, these methods are not satisfactory enough. We propose a two-stage salient region detection method. The input image is first segmented into superpixels. In the first stage, two measures which measure the isolation and distribution of each superpixel are proposed, we consider that both of these two measures are important for finding the salient regions, thus the image-feature-based saliency map is obtained by combining the two measures. Then, in the second stage, we incorporate into the image-feature-based saliency map a location prior map to emphasize the foci of attention. In this algorithm, six priors that explain what is the salient region are exploited. The proposed method is compared with the state-of-the-art saliency detection methods using one of the largest publicly available standard databases, the experimental result indicates that the proposed method has better performance. We also demonstrate how the saliency map of the proposed method can be used to create high quality of initial segmentation masks for subsequent image processing, like Grabcut based salient object segmentation. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Fan, Qiang; Qi, Chun] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Qi, C (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qichun@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61133008, 60972124];
   Specialized Research Fund for the Doctoral Program of Higher Education
   [20110201110012]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61133008), in part by the National Natural
   Science Foundation of China (No. 60972124) and in part by the
   Specialized Research Fund for the Doctoral Program of Higher Education
   (Grant No. 20110201110012).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 1955, PRINCIPLES GESTALT P
   [Anonymous], 2010, Technical Report
   [Anonymous], 2007, P IEEE C COMP VIS PA
   Avidan S, 2007, ACM T GRAPHIC, P26
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Gorisse D, 2012, IEEE T PATTERN ANAL, V34, P402, DOI 10.1109/TPAMI.2011.193
   Guo C., 2008, P IEEE C COMP VIS PA
   Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034
   Harel J., 2007, P ADV NEUR INF PROC
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Liu Tie, 2007, P IEEE C COMP VIS PA
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rother C., 2006, ACM T GRAPHIC, V25, P291
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 33
TC 11
Z9 12
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1823
EP 1834
DI 10.1016/j.jvcir.2014.09.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300002
DA 2024-07-18
ER

PT J
AU Wu, MS
AF Wu, Ming-Sheng
TI Genetic algorithm based on discrete wavelet transformation for fractal
   image compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fractal image compression; Partitioned iterated function system;
   Discrete wavelet transformation; Dihedral transformation; FIC using DWT;
   Evolutionary algorithm; Genetic algorithm; GA based on DWT
ID SPATIAL CORRELATION; CODING METHOD; SEARCH
AB In this paper, a genetic algorithm (GA) based on discrete wavelet transformation (DWT) is proposed to overcome the drawback of the time-consuming for the fractal encoder. First, for each range block, two wavelet coefficients are used to find the fittest Dihedral block of the domain block. The similar match is done only with the fittest block to save seven eighths redundant MSE computations. Second, embedding the DWT into the GA, a GA based on DWT is built to fast evolutionary speed further and maintain good retrieved quality. Experiments show that, under the same number of MSE computations, the PSNR of the proposed GA method is reduced 0.29 to 0.47 dB in comparison with the SGA method. Moreover, at the encoding time, the proposed GA method is 100 times faster than the full search method, while the penalty of retrieved image quality is relatively acceptable. (C) 2014 Elsevier Inc. All rights reserved.
C1 Cheng Shiu Univ, Dept Elect Engn, Kaohsiung 83347, Taiwan.
C3 Cheng Shiu University
RP Wu, MS (corresponding author), Cheng Shiu Univ, Dept Elect Engn, 840 Chengcing Rd, Kaohsiung 83347, Taiwan.
EM sheng@csu.edu.tw
CR [Anonymous], 1991, FRACTALS FUNDAMENTAL
   [Anonymous], FRACTALS CHAOS
   BARNSLEY MF, 1985, P ROY SOC LOND A MAT, V399, P243, DOI 10.1098/rspa.1985.0057
   Chung KL, 2006, CHAOS SOLITON FRACT, V29, P215, DOI 10.1016/j.chaos.2005.08.023
   Duh DJ, 2008, IMAGING SCI J, V56, P79, DOI 10.1179/174313107X214259
   Duh DJ, 2005, IMAGE VISION COMPUT, V23, P1115, DOI 10.1016/j.imavis.2005.05.013
   Fisher Y., 1994, Fractal Image Compression
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kovács T, 2008, IMAGE VISION COMPUT, V26, P1129, DOI 10.1016/j.imavis.2007.12.008
   Muruganandham A, 2010, PROCEDIA COMPUT SCI, V2, P338, DOI 10.1016/j.procs.2010.11.044
   Shen FR, 2004, SIGNAL PROCESS-IMAGE, V19, P393, DOI 10.1016/j.image.2004.02.002
   Truong TK, 2004, CHAOS SOLITON FRACT, V22, P1071, DOI 10.1016/j.chaos.2004.03.015
   Tseng CC, 2008, IMAGE VISION COMPUT, V26, P1154, DOI 10.1016/j.imavis.2008.01.003
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wang XY, 2011, CHINESE PHYS B, V20, DOI 10.1088/1674-1056/20/10/104202
   Wang XY, 2010, IMAGE VISION COMPUT, V28, P1303, DOI 10.1016/j.imavis.2010.01.008
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang XY, 2009, FRACTALS, V17, P459, DOI 10.1142/S0218348X09004491
   Wang XY, 2009, FRACTALS, V17, P451, DOI 10.1142/S0218348X09004545
   Wang Z, 2000, SIGNAL PROCESS-IMAGE, V15, P767, DOI 10.1016/S0923-5965(99)00018-1
   Wu MS, 2007, ENG APPL ARTIF INTEL, V20, P531, DOI 10.1016/j.engappai.2006.08.005
   Wu MS, 2010, DIGIT SIGNAL PROCESS, V20, P1150, DOI 10.1016/j.dsp.2009.12.009
   Wu MS, 2006, CHAOS SOLITON FRACT, V28, P497, DOI 10.1016/j.chaos.2005.07.004
   Zhang Y, 2012, NONLINEAR ANAL-REAL, V13, P106, DOI 10.1016/j.nonrwa.2011.07.017
NR 24
TC 22
Z9 23
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1835
EP 1841
DI 10.1016/j.jvcir.2014.09.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300003
DA 2024-07-18
ER

PT J
AU Hsieh, JW
   Cheng, JC
   Chen, LC
   Chuang, CH
   Chen, DY
AF Hsieh, Jun-Wei
   Cheng, Jiun-Chen
   Chen, Li-Chih
   Chuang, Chi-Hung
   Chen, Duan-Yu
TI Handheld object detection and its related event analysis using ratio
   histogram and mixture of HMMs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Behavior analysis; Interaction event; Ratio histogram; HMMs; Hand-held
   object detection; Smoking event detection; Event multiplicity; Code book
ID MOTION; SURVEILLANCE; RECOGNITION
AB This paper proposes a novel system to analyze human-object interaction events happening between hands and faces in real time. Two challenging problems in this event analysis must be addressed, i.e., there is no prior knowledge (like shape, color, size, and texture) about the handheld objects, and there are large spatial-temporal variations in event representation. For the first challenge, a novel ratio histogram is proposed to find important color bins to locate handheld objects and their trajectories via a code book technique. This scheme is different from other boosted methods which require very time-consuming estimations to search reliable body configurations. For the second challenge, a mixture of HMMs is proposed to describe an event not only from its dynamic context but also its multiplicity context. It can be performed in real time because an exhaustive search process is avoided to find possible interaction pairs between objects and body parts. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Hsieh, Jun-Wei] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
   [Cheng, Jiun-Chen; Chen, Li-Chih; Chen, Duan-Yu] Yuan Ze Univ, Dept Elect Engn, Chungli 320, Taiwan.
   [Chuang, Chi-Hung] Fo Guang Univ, Dept Learning & Digital Technol, Jiaosi 26247, Yilan, Taiwan.
   [Chen, Li-Chih] Lee Ming Inst Technol, Dept Elect Engn, New Taipei City 243, Taiwan.
C3 National Taiwan Ocean University; Yuan Ze University; Fo Guang
   University
RP Hsieh, JW (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Beining Rd, Keelung 202, Taiwan.
EM shieh@ntou.edu.tw
FU National Science Council of Taiwan, Taiwan, R.O.C
   [NSC98-2221-E-019-070-MY2]; Ministry of Economic Affairs of Taiwan,
   R.O.C [97-EC-17-A-02-S1-032]
FX This work was supported in part by National Science Council of Taiwan
   under Grant NSC98-2221-E-019-070-MY2, Taiwan, R.O.C and the Ministry of
   Economic Affairs of Taiwan, R.O.C under contract no.
   97-EC-17-A-02-S1-032.
CR [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], INT C COMP VIS OCT
   [Anonymous], INT C COMP VIS OCT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], INT C GRAPH IM PROC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2 INT WORKSH SEM LEA
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], INT C COMP VIS ICCV
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Comaniciu D., 2000, IEEE Proc. on Computer Vision and Pattern Recognition on, P673
   Delaitre Vincent., 2011, ADV NEURAL INFORM PR
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fathi A., 2008, IEEE COMPUTER SOC C, P1
   Feng Lu, 2007, IEEE Internatonal Conference on Mobile Adhoc and Sensor Systems, 2007. MASS 2007, P1
   Filipovych R., 2008, IEEE C COMPUTER VISI, P1
   Gaidon A, 2011, PROC CVPR IEEE
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I., 2007, INT C COMP VIS OCT
   Maji S., 2011, IEEE C COMP VIS PATT
   Marszalek M., 2009, IEEE C COMP VIS PATT
   Nguyen NT, 2003, PROC CVPR IEEE, P620
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   Park S, 2003, LECT NOTES COMPUT SC, V2728, P394
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rosales R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P117, DOI 10.1109/CVPR.1999.784618
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Shi YF, 2004, PROC CVPR IEEE, P862
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu JX, 2007, IEEE I CONF COMP VIS, P290, DOI 10.1109/ICCV.2007.4408865
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
NR 44
TC 3
Z9 5
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1399
EP 1415
DI 10.1016/j.jvcir.2014.05.009
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100010
DA 2024-07-18
ER

PT J
AU Ou, DH
   Sun, W
AF Ou, Duanhao
   Sun, Wei
TI Reversible AMBTC-based secret sharing scheme with abilities of two
   decryptions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; Meaningful shadows; Stacking decryption; Complete
   decryption; Reversibility; Absolute moment block truncation coding; No
   extra process; No codebook required
ID VISUAL CRYPTOGRAPHY; AUTHENTICATION; STEGANOGRAPHY; IMAGES
AB This paper presents a secret sharing scheme to encode a secret binary image in images which are compressed by absolute moment block truncation coding (AMBTC) method. The generated shadows by the proposed scheme are in AMBTC-compressed format and meaningful, the visual quality of which is the same as that of its original AMBTC version. In the proposed scheme, the secret image can be reconstructed in two situations: (1) if some light-weight computational devices are available, the secret image can be completely decrypted without any distortion, and (2) otherwise, the secret image can also be revealed by human visual system. Furthermore, the proposed scheme provides the reversibility for protecting the valuable cover images. In addition, underlying the proposed (2,2) scheme, this paper gives a construction for the (2, n) scheme where one participant may require more than one shadow. Theoretical analysis and simulation results demonstrate the superiority of the proposed scheme. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Ou, Duanhao] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Sun, W (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM ouduanh@mail2.sysu.edu.cn; sunwei@mail.sysu.edu.cn
FU 973 Program [2011CB302400]; Natural Science Foundation of Guangdong
   Province, China [S2013010013728]
FX This work was in part supported by 973 Program (Grant No. 2011CB302400)
   and Natural Science Foundation of Guangdong Province, China (Grant No.
   S2013010013728).
CR [Anonymous], 1979, P AFIPS NAT COMP C N
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blundo C, 1998, COMPUT GRAPH, V22, P449, DOI 10.1016/S0097-8493(98)00034-X
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL II, P253, DOI 10.1109/CINC.2009.249
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2012, DIGIT SIGNAL PROCESS, V22, P776, DOI 10.1016/j.dsp.2012.04.004
   Guo JM, 2010, IEEE T IMAGE PROCESS, V19, P2056, DOI 10.1109/TIP.2010.2045709
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Naor M., 1997, Security Protocols. International Workshop Proceedings, P197
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wu C., 2009, INT INF HID MULT SIG, P1014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 30
TC 12
Z9 12
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1222
EP 1239
DI 10.1016/j.jvcir.2013.12.018
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200047
DA 2024-07-18
ER

PT J
AU Atzori, L
   Floris, A
   Ginesu, G
   Giusto, DD
AF Atzori, Luigi
   Floris, Alessandro
   Ginesu, Giaime
   Giusto, Daniele D.
TI Quality perception when streaming video on tablet devices
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality of Experience; Video streaming; Subjective quality assessment;
   Video on tablet devices; Multimedia services; Quality models; Objective
   quality metrics; Mean opinion score
AB The proposed work aims at analyzing the quality perceived by the user when streaming video on tablet devices. The contributions of this paper are: (i) to analyze the results of subjective quality assessments to determine which Quality of Service (QoS) parameters mainly affect-the users' Quality of Experience (QoE) in video streaming over tablet devices; (ii) to define a parametric quality model useful in system control and optimization for the considered scenarios; (iii) to compare the performance of the proposed model with subjective quality results obtained in alternative state-of-the-art studies and investigate whether other models could be applied to our case and vice versa. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Atzori, Luigi; Floris, Alessandro; Ginesu, Giaime; Giusto, Daniele D.] Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy.
C3 University of Cagliari
RP Atzori, L (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy.
EM l.atzori@diee.unica.it; alessandro.floris@diee.unica.it;
   g.ginesu@diee.unica.it; ddgiusto@unica.it
RI Floris, Alessandro/L-6707-2018; Giusto, Daniele D./AAP-6211-2020
OI Floris, Alessandro/0000-0002-8745-1327; 
CR Ascenso J., 2012, INT C TEL MULT TEMU
   Atzori L, 2012, SIGNAL PROCESS-IMAGE, V27, P1049, DOI 10.1016/j.image.2012.09.005
   De Simone F, 2009, INT WORKSH QUAL MULT
   Khan Asiya, 2009, Journal of Multimedia, V4, P228, DOI 10.4304/jmm.4.4.228-239
   Lin XY, 2012, IEEE T CONSUM ELECTR, V58, P505, DOI 10.1109/TCE.2012.6227454
   Romaniak P, 2012, CONSUM COMM NETWORK, P597, DOI 10.1109/CCNC.2012.6181021
   Shi Z., 2012, INT C ANT COUNT SEC
   Staelens N, 2013, IEEE T CIRC SYST VID, V23, P1322, DOI 10.1109/TCSVT.2013.2243052
   Venkataraman M, 2011, IEEE NETWORK, V25, P4, DOI 10.1109/MNET.2011.5687947
   WENGER S, 1999, PROPOSED ERROR PATTE
   Yamada T., 2012, IEEE INT C AC SPEECH
   YAMAGISHI K, 2008, IEEE INT C COMM ICC
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
NR 13
TC 11
Z9 11
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 586
EP 595
DI 10.1016/j.jvcir.2013.08.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100008
DA 2024-07-18
ER

PT J
AU Chang, PC
   Chung, KL
   Chen, JJ
   Lin, CH
   Lin, TJ
AF Chang, Po-Chun
   Chung, Kuo-Liang
   Chen, Jiann-Jone
   Lin, Chien-Hsiung
   Lin, Tseng-Jung
TI A DCT/DST-based error propagation-free data hiding algorithm for HEVC
   intra-coded frames
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; DCT/DST; H.264/AVC; HEVC; Intra-coded frames; Intra-frame
   error propagation
ID WATERMARKING SCHEME; ROBUST WATERMARKING; VIDEO
AB Currently, two error propagation-free discrete cosine transform (DCT)-based data hiding algorithms, one by Ma et al. and the other by Lin et al., were presented for H.264/AVC intra-coded frames. However, the state-of-the-art video codec, high efficiency video coding (HEVC), adopts both integer DCT and discrete sine transform (DST) such that the previous DCT-based algorithms cannot fully utilize available capacity for data hiding in HEVC. This paper presents the first DCT/DST-based data hiding algorithm for HEVC intra-coded frames where the block DCT and DST coefficient characteristics are investigated to locate the transformed coefficients that can be perturbed without propagating errors to neighboring blocks. Experimental results confirm the merits of the proposed algorithm in providing the intra-frame error propagation-free advantage, the quality improvement for marked images, the compression power inherited from HEVC, and the superiority of embedding capacity for low bitrate coding when compared with the previous two algorithms for H.264/AVC. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chang, Po-Chun; Chung, Kuo-Liang; Lin, Chien-Hsiung; Lin, Tseng-Jung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Chen, Jiann-Jone] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM d9409301@mail.ntust.edu.tw
RI Chen, Jiann-Jone/IVU-6945-2023
FU National Science Council of ROC [NSC99-2221-E-011-078-MY3,
   NSC101-2221-E-011-139-MY3, NSC102-2221-E-011-055-MY3,
   NSC101-2221-E-011-137]
FX The work of K.L. Chung and C.H. Lin was supported by the National
   Science Council of ROC under the contracts NSC99-2221-E-011-078-MY3,
   NSC101-2221-E-011-139-MY3, and NSC102-2221-E-011-055-MY3. The work of
   J.J. Chen was supported by the National Science Council of ROC under the
   contract NSC101-2221-E-011-137.
CR [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2013, P 11 JCT VC M
   [Anonymous], 2003, ITU T REC F IN PRESS
   [Anonymous], 2004, Data hiding fundamentals and applications: content security in digital multimedia
   Bossen F., 2013, ICTVCL1100
   Chang HT, 2009, OPT ENG, V48, DOI 10.1117/1.3127192
   Gong X, 2008, IEEE INT SYM MULTIM, P649, DOI 10.1109/ISM.2008.16
   Huo WJ, 2011, IEEE SIGNAL PROC LET, V18, P535, DOI 10.1109/LSP.2011.2162061
   Kim I., IEEE T CIRCUITS SYST, V22
   Li Y, 2010, INT CONF SIGN PROCES, P1833, DOI 10.1109/ICOSP.2010.5656918
   Lin TJ, 2013, J SYST SOFTWARE, V86, P604, DOI 10.1016/j.jss.2012.10.922
   Liu TY, 2010, IEEE T INF FOREN SEC, V5, P945, DOI 10.1109/TIFS.2010.2072501
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Noorkami M., 2006, SPIE Security, Steganography, and Watermarking of Multimedia Contents, V6072, P489
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qiu G, 2004, INT C PATT RECOG, P865
   Samira B, 2012, INT CONF SIGN PROCES, P1682, DOI 10.1109/ICoSP.2012.6491904
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian GF, 2012, 2012 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P547, DOI 10.1109/APCCAS.2012.6419093
   Wong K, 2006, LECT NOTES COMPUT SC, V4105, P57
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang LW, 2010, INT CONF ACOUST SPEE, P1758, DOI 10.1109/ICASSP.2010.5495443
NR 23
TC 93
Z9 113
U1 1
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 239
EP 253
DI 10.1016/j.jvcir.2013.10.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300001
DA 2024-07-18
ER

PT J
AU Gallego, J
   Pardàs, M
AF Gallego, Jaime
   Pardas, Montse
TI Region based foreground segmentation combining color and depth sensors
   via logarithmic opinion pool decision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Foreground segmentation; Space-color models; Space-depth models; Kinect
   camera; GMM; Color and depth combination; Logarithmic Opinion Pool;
   Hellinger distance
AB In this paper we present a novel foreground segmentation system that combines color and depth sensors information to perform a more complete Bayesian segmentation between foreground and background classes. The system shows a combination of spatial-color and spatial-depth region-based models for the foreground as well as color and depth pixel-wise models for the background in a Logarithmic Opinion Pool decision framework used to correctly combine the likelihoods of each model. A posterior enhancement step based on a trimap analysis is also proposed in order to correct the precision errors that the depth sensor introduces. The results presented in this paper show that our system is robust in front of color and depth camouflage problems between the foreground object and the background, and also improves the segmentation in the area of the objects' contours by reducing the false positive detections that appear due to the lack of precision of the depth sensors. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Gallego, Jaime; Pardas, Montse] Univ Politecn Cataluna, Dept Signal Theory & Commun, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Gallego, J (corresponding author), Univ Politecn Cataluna, Dept Signal Theory & Commun, Barcelona, Spain.
EM jgallego@upc.edu; montse.pardas@upc.edu
RI Gallego, Jaime/AAC-3603-2021; Pardas, Montse/G-3967-2014
OI Gallego, Jaime/0000-0003-3332-619X; Pardas, Montse/0000-0002-5861-6356
CR [Anonymous], 1999, IEEE COMP SOC C COMP
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], P 3DPVT
   BERAN R, 1977, ANN STAT, V5, P445, DOI 10.1214/aos/1176343842
   Bleiweiss A, 2009, LECT NOTES COMPUT SC, V5742, P58, DOI 10.1007/978-3-642-03778-8_5
   Crabb Ryan, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563170
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Frick Anatol, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P296, DOI 10.1007/978-3-642-23123-0_30
   Gallego J, 2009, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2009.5414380
   Guomundsson Sigurjon Arni, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563154
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   KULLBACK S, 1987, AM STAT, V41, P340
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Pinheiro P., BAYESIAN SENSOR FUSI
   Schiller I, 2011, LECT NOTES COMPUT SC, V6688, P59, DOI 10.1007/978-3-642-21227-7_6
   Shah S., 1999, Proceedings of the Second International Conference on Information Fusion. FUSION '99, P722
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Stone E. E., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P71, DOI 10.4108/icst.pervasivehealth.2011.246034
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu Q, 2008, PROCEEDINGS OF THE FIFTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P87, DOI 10.1109/CRV.2008.7
   Xia Lu, 2011, WORKSH HUM ACT UND 3
   YU T, 2007, P IEEE WORKSH MOT VI, P5
NR 22
TC 10
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 184
EP 194
DI 10.1016/j.jvcir.2013.03.019
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900016
DA 2024-07-18
ER

PT J
AU Ofli, F
   Chaudhry, R
   Kurillo, G
   Vidal, R
   Bajcsy, R
AF Ofli, Ferda
   Chaudhry, Rizwan
   Kurillo, Gregorij
   Vidal, Rene
   Bajcsy, Ruzena
TI Sequence of the most informative joints (SMIJ): A new representation for
   human skeletal action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action representation; Human action recognition; Informative
   joints; Bag-of-words; Linear dynamical systems; Normalized edit
   distance; Cross-database generalization; Berkeley MHAD; HDM05; MSR
   Action3D
ID BINET-CAUCHY KERNELS; DYNAMICAL-SYSTEMS; MOTION CAPTURE; CLASSIFICATION
AB Much of the existing work on action recognition combines simple features with complex classifiers or models to represent an action. Parameters of such models usually do not have any physical meaning nor do they provide any qualitative insight relating the action to the actual motion of the body or its parts. In this paper, we propose a new representation of human actions called sequence of the most informative joints (SMIJ), which is extremely easy to interpret. At each time instant, we automatically select a few skeletal joints that are deemed to be the most informative for performing the current action based on highly interpretable measures such as the mean or variance of joint angle trajectories. We then represent the action as a sequence of these most informative joints. Experiments on multiple databases show that the SMIJ representation is discriminative for human action recognition and performs better than several state-of-the-art algorithms. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Ofli, Ferda; Kurillo, Gregorij; Bajcsy, Ruzena] Univ Calif Berkeley, Tele Immers Lab, Berkeley, CA 94720 USA.
   [Chaudhry, Rizwan; Vidal, Rene] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD USA.
C3 University of California System; University of California Berkeley;
   Johns Hopkins University
RP Ofli, F (corresponding author), Univ Calif Berkeley, Tele Immers Lab, Berkeley, CA 94720 USA.
EM fofli@eecs.berkeley.edu; rizwanch@cis.jhu.edu;
   gregorij@eecs.berkeley.edu; rvidal@cis.jhu.edu; bajcsy@eecs.berkeley.edu
RI Ofli, Ferda/G-2027-2017; Vidal, Rene/A-3367-2010
OI Ofli, Ferda/0000-0003-3918-3230; 
FU European Research Council grant VideoWorld [NSF 0941362, NSF 0941463,
   NSF 0941382, ONR N000141310116]
FX This work is supported in part by the European Research Council grant
   VideoWorld as well as the grants NSF 0941362, NSF 0941463, NSF 0941382
   and ONR N000141310116.
CR Afsari B., 2012, P IEEE C COMP VIS PA
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2006, Elements of Information Theory
   [Anonymous], P IEEE INT WORKSH VI
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2012, 2012 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2012.6239231
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P NEUR INF PROC SYST
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   [Anonymous], 2013, P IEEE WORKSH APPL C
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Beaudoin P., 2008, P 2008 ACM SIGGRAPHE, P117
   Bissacco A, 2001, PROC CVPR IEEE, P52
   Bissacco A, 2007, IEEE T PATTERN ANAL, V29, P1958, DOI 10.1109/TPAMI.2007.1101
   Cetingul H.E., 2007, P INT WORKSH DYN VIS
   Chan AB, 2005, PROC CVPR IEEE, P846
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   De Cock K, 2002, SYST CONTROL LETT, V46, P265, DOI 10.1016/S0167-6911(02)00135-4
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   López-Méndez A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.49
   LOWRANCE R, 1975, J ACM, V22, P177, DOI 10.1145/321879.321880
   MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Shannon C.E., 1949, Illini books, V1
   Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x
   Taylor G.W., 2009, P INT C MACH LEARN I
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5
   Vidal R., 2007, Proceedings of the European Control Conference, P27
   Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou F., 2012, IEEE T PATTERN ANAL, V99, P1
NR 43
TC 225
Z9 251
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 24
EP 38
DI 10.1016/j.jvcir.2013.04.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Stückler, J
   Behnke, S
AF Stueckler, Jeorg
   Behnke, Sven
TI Multi-resolution surfel maps for efficient dense 3D modeling and
   tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D multi-resolution RGB-D image representation; Real-time RGB-D image
   registration; Visual odometry; Dense object modeling; Dense indoor scene
   mapping; Real-time simultaneous localization and mapping; On-line
   loop-closure detection; Real-time pose tracking
ID SCAN REGISTRATION
AB Building consistent models of objects and scenes from moving sensors is an important prerequisite for many recognition, manipulation, and navigation tasks. Our approach integrates color and depth measurements seamlessly in a multi-resolution map representation. We process image sequences from RGB-D cameras and consider their typical noise properties. In order to align the images, we register view-based maps efficiently on a CPU using multi-resolution strategies. For simultaneous localization and mapping (SLAM), we determine the motion of the camera by registering maps of key views and optimize the trajectory in a probabilistic framework. We create object models and map indoor scenes using our SLAM approach which includes randomized loop closing to avoid drift. Camera motion relative to the acquired models is then tracked in real-time based on our registration method. We benchmark our method on publicly available RGB-D datasets, demonstrate accuracy, efficiency, and robustness of our method, and compare it with state-of-the-art approaches. We also report on several successful public demonstrations where it was used in mobile manipulation tasks. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Stueckler, Jeorg; Behnke, Sven] Univ Bonn, Comp Sci Inst 6, D-53113 Bonn, Germany.
C3 University of Bonn
RP Stückler, J (corresponding author), Univ Bonn, Comp Sci Inst 6, Friedrich Ebert Allee 144, D-53113 Bonn, Germany.
EM stueckler@ais.uni-bonn.de; behnke@ais.uni-bonn.de
RI Stückler, Jörg/AAK-9145-2021; Behnke, Sven/B-5509-2013
OI Stückler, Jörg/0000-0002-2328-4363; Behnke, Sven/0000-0002-5040-7525
CR [Anonymous], 2012, P IEEE INT C ROB AUT
   [Anonymous], 1979, UPDATING FORMULAE PA
   [Anonymous], 2009, P ROB SCI SYST RSS
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Censi A, 2007, IEEE INT CONF ROBOT, P3167, DOI 10.1109/ROBOT.2007.363961
   CHAN TF, 1979, COMMUN ACM, V22, P526, DOI 10.1145/359146.359152
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Droeschel D., 2009, ROBUST EGOMOTION EST
   Endres F., 6D VISUAL SLAM RGB D
   Engelhard N., 2011, P RGB D WORKSH 3D PE
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Huang AlbertS., 2011, INT S ROBOTICS RES I, P1
   Klein George, 2007, P1
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376
   Krainin M., 2011, INT J ROBOTICS RES, V30
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Magnusson M, 2007, J FIELD ROBOT, V24, P803, DOI 10.1002/rob.20204
   May S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1673, DOI 10.1109/IROS.2009.5354684
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nistér D, 2004, PROC CVPR IEEE, P652
   Nüchter A, 2005, 2005 12TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, P242
   Roth H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.112
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Se S, 2001, IEEE INT CONF ROBOT, P2051, DOI 10.1109/ROBOT.2001.932909
   Steinbrucker F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P719, DOI 10.1109/ICCVW.2011.6130321
   Stoyanov T, 2012, INT J ROBOT RES, V31, P1377, DOI 10.1177/0278364912460895
   Stuckler Jorg, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P218, DOI 10.1109/Humanoids.2011.6100917
   Stühmer J, 2010, LECT NOTES COMPUT SC, V6376, P11
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Weise T, 2011, COMPUT VIS IMAGE UND, V115, P635, DOI 10.1016/j.cviu.2010.11.023
   Whelan T., 2012, MITCSAILTR2012031
   Zhou K, 2011, IEEE T VIS COMPUT GR, V17, P669, DOI 10.1109/TVCG.2010.75
NR 35
TC 132
Z9 150
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 137
EP 147
DI 10.1016/j.jvcir.2013.02.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900013
DA 2024-07-18
ER

PT J
AU Chen, Y
   Thing, VLL
AF Chen, Yu
   Thing, Vrizlynn L. L.
TI Image content analysis for sector-wise JPEG fragment classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DCT coefficient analysis; JPEG directional analysis; Image content
   analysis; Horizontal versus vertical; Erroneous fragment classification;
   JPEG carving; Digital image forensics; Image processing
AB In this paper, we propose a sector-wise JPEG fragment classification approach to classify normal and erroneous JPEG data fragments with the minimum size of 512 bytes per fragment. Our method is based on processing each read-in sector of 512 bytes with using the DCT coefficient analysis methods for extracting the features of visual inconsistencies. The classification is conducted before the inverse DO and can be performed simultaneously with JPEG decoding. The contributions of this work are two-folds: (1) a sector-wise JPEG erroneous fragment classification approach is proposed (2) new DCT coefficient analysis methods are introduced for image content analysis. Testing results on a variety of erroneous fragmented and normal JPEG files prove the strength of this operator for the purpose of forensics analysis, data recovery and abnormal fragment inconsistencies classification and detection. Furthermore, the results also show that the proposed DCT coefficient analysis methods are efficient and practical in terms of classification accuracy. In our experiment, the proposed approach yields a false positive rate of 0.32% and a true positive rate of 96.1% in terms of erroneous JPEG fragment classification. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Yu; Thing, Vrizlynn L. L.] Inst Infocomm Res, CSI Dept, Singapore 138632, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Chen, Y (corresponding author), Inst Infocomm Res, CSI Dept, 1 Fusionopolis Way, Singapore 138632, Singapore.
EM ychen@i2r.a-star.edu.sg; vriz@i2r.a-star.edu.sg
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y., 2012, INT C IM PROC COMP V
   Chen YW., 2005, Combining SVMs with Various Feature Selection Strategies
   Cohen M.I., P 1 INT C FOR APPL T
   Douceur JR, 1999, PERFORMANCE EVALUATION REVIEW, SPECIAL ISSUE, VOL 27 NO 1, JUNE 1999, P59, DOI 10.1145/301464.301480
   Garnkel S.L., 2006, RES ADV DIGITAL FORE
   Li QM, 2011, IEEE INT CON MULTI
   Memon N, 2006, IEEE T IMAGE PROCESS, V15, P385, DOI 10.1109/TIP.2005.863054
   Pal A., 2008, DIGITAL INVESTIGATIO
   Pal A, 2008, DIGIT INVEST, V5, pS2, DOI 10.1016/j.diin.2008.05.015
   Pal A, 2009, IEEE SIGNAL PROC MAG, V26, P59, DOI 10.1109/MSP.2008.931081
   Svetnik V, 2004, LECT NOTES COMPUT SC, V3077, P334
   Thing V.L.L., 2011, INT C COMP INT SEC
   Thing VLL, 2010, CHINA COMMUN, V7, P1
   Ying H.-M., 2010, S AFR INF SEC MULT S
   Ying H.-M., 2010, INT ICST C FOR APPL
NR 16
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 857
EP 866
DI 10.1016/j.jvcir.2013.06.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700012
DA 2024-07-18
ER

PT J
AU Gouiffès, M
   Planes, B
   Jacquemin, C
AF Gouiffes, Michele
   Planes, Bertrand
   Jacquemin, Christian
TI HTRI: High time range imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color saliency; Temporal saliency; Image fusion; Photometric changes;
   Motion detection; Image sequences; Art-Science; Photography
ID SALIENCY; FUSION
AB HDRI (High Dynamic Range Imaging) techniques are used to produce dynamic and well-contrasted images of real-world luminance, by capturing several images of the same scene through exposure bracketing. In the same vein, we have developed a new approach to image fusion from a series of photographs of the same scene taken at different timestamps. When compared with HDRI, exposure bracketing at a single timestamp is replaced by timestamp variation disregarding exposure times. Because of the parallel between these two approaches, this technique is called HTRI (High Time Range Imaging), it aims at capturing ephemeral events occurring over a long time period during which a sequence of images is shot.
   For each pixel location, the most salient colors are privileged in the series of photographs. The choice of the saliency criterion is based on an analysis of the existing admitted definitions of visual attention. In a second stage, a higher priority is assigned to the pixels with high temporal saliency, i.e., which appear very briefly in the sequence, jointly producing spatial and temporal changes of contrast between two successive frames. The proposed algorithm captures all these salient objects in the final image, without introducing a significant amount of noise, and despite the large illumination changes that may occur in the acquisition conditions from one frame to the next. Experiments evaluate the impact of the method parameters, and confirm benefits of HTRI compared to other fusion techniques. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Gouiffes, Michele; Jacquemin, Christian] Univ Paris Sud, CNRS, LIMSI, F-91405 Orsay, France.
C3 Universite Paris Saclay; Universite Paris Cite; Centre National de la
   Recherche Scientifique (CNRS)
RP Gouiffès, M (corresponding author), Univ Paris Sud, CNRS, LIMSI, F-91405 Orsay, France.
EM michele.gouiffes@u-psud.fr; planesbertrand@gmail.com;
   christian.jacquemin@limsi.fr
CR Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365
   BARTELSO.CJ, 1967, J OPT SOC AM, V57, P953, DOI 10.1364/JOSA.57.000953
   Buser P., 1992, Vision
   Chiranjeevi P, 2012, J VIS COMMUN IMAGE R, V23, P948, DOI 10.1016/j.jvcir.2012.06.004
   De Decker Bert, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2536, DOI 10.1109/CVPRW.2009.5206752
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Ebner M, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P642
   El Baf F, 2008, LECT NOTES COMPUT SC, V5358, P772, DOI 10.1007/978-3-540-89639-5_74
   Freeman B., 2003, IEEE C COMP VIS PATT, V2, P264
   Gouiffès M, 2011, J VIS COMMUN IMAGE R, V22, P48, DOI 10.1016/j.jvcir.2010.10.002
   Granados M., 2010, IEEE C COMP VIS PATT
   Gu B, 2012, J VIS COMMUN IMAGE R, V23, P604, DOI 10.1016/j.jvcir.2012.02.009
   Guo C., 2008, INT C COMP VIS PATT
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jacobs K., 2008, IEEE COMPUTER GRAPHI
   Ladson J, 2007, COLOR RES APPL, V32, P160, DOI 10.1002/col.20301
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Matkovic K., 1997, THESIS
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   MITTAL A., 2012, IEEE SIGNAL PROCESS, VPP, P99
   Moerland T, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P820, DOI 10.1109/ICME.2005.1521549
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Obdrzalek S., 2003, IEEE WORKSH COL PHOT
   Peli E, 2001, J OPT SOC AM A, V18, P283, DOI 10.1364/JOSAA.18.000283
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871
   Raskar R., 2005, ACM SIGGRAPH 2005 IN
   Reinhard E., 2006, The Morgan Kaufmann Series in Computer Graphics
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vizireanu N, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3134142
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P1158, DOI 10.1016/j.jvcir.2012.07.010
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 39
TC 7
Z9 7
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 361
EP 372
DI 10.1016/j.jvcir.2013.01.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200013
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Tseng, WY
   Chou, BY
AF Yeh, Chia-Hung
   Tseng, Wen-Yu
   Chou, Bo-Yi
TI Mode decision acceleration for scalable video coding through coded block
   pattern
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable video coding; Fast mode decision; Coded block pattern;
   Coarse-gain; Inter-layer prediction; Highest temporal level analysis;
   Quality scalability; Spatial scalability
ID H.264/AVC STANDARD; INTRA-PREDICTION; ALGORITHM; SELECTION; SCALABILITY;
   EXTENSION
AB This paper presents a fast mode decision to accelerate the encoding process of scalable video coding (SVC) through coded block pattern (CBP) analysis. CBP contains residual information of each macroblock (MB) and provide cues for mode prediction in encoding process. The proposed algorithm makes use of the existing mode information in base layer (BL), enhancement layer (EL) and CBP to remove invalid modes for the mode prediction of the current MB in EL coding. Also, the EL's modes in the highest temporal level of a group of picture are determined by high correlation exists in adjacent frames. Experimental results show that the proposed algorithm saves an average of 68% of EL motion estimation time with minor degradation in PSNR and with few bitrate increase of SVC quality and spatial scalabilities when compared to JSVM 9.19.14. Our algorithm outperforms the best-known method by 17% EL motion estimation time saving in average. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Yeh, Chia-Hung; Tseng, Wen-Yu; Chou, Bo-Yi] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.
C3 National Sun Yat Sen University
RP Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.
EM yeh@mail.ee.nsysu.edu.tw
CR [Anonymous], 2001, SC16Q6 ITUT
   Chen BY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P721, DOI 10.1109/ICME.2008.4607536
   Choi I, 2006, IEEE T CIRC SYST VID, V16, P1557, DOI 10.1109/TCSVT.2006.883506
   Chou B.-Y., 2009, P APSIPA ASC 2009 OC, P79
   Hong Z., 1919, P 19 INT C ADV INF N, V1, P775
   ISO, 2004, 1449610 ISOIEC
   JCT-VC, 2010, JCTVCC405R1
   JCT-VC, 2010, JCTVCA119
   Kim BG, 2008, IEEE T CIRC SYST VID, V18, P273, DOI 10.1109/TCSVT.2008.918121
   Kim C, 2007, IEEE T CIRC SYST VID, V17, P441, DOI 10.1109/TCSVT.2006.888829
   LEE J, 2004, P IEEE INT C MULT EX, V2, P1131, DOI DOI 10.1109/ICME.2004.1394416
   Li H, 2006, IEEE T CIRC SYST VID, V16, P889, DOI 10.1109/TCSVT.2006.877404
   Lin HC, 2010, IEEE T CIRC SYST VID, V20, P732, DOI 10.1109/TCSVT.2010.2045832
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Ri SH, 2009, IEEE T CIRC SYST VID, V19, P302, DOI 10.1109/TCSVT.2008.2009257
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P975, DOI 10.1109/TCSVT.2008.920742
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Vieron J., 2007, JTC1SC29WG11 ISOIEC
   WIEGAND T, 2007, JTC1SC29WG11 ISOIEC
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Yeh CH, 2010, IEEE T CIRC SYST VID, V20, P563, DOI 10.1109/TCSVT.2010.2041825
   Yu ACW, 2008, IEEE T CIRC SYST VID, V18, P186, DOI 10.1109/TCSVT.2007.913970
   Zeng H., 2009, IEEE T CIRCUITS SYST, V19, P1
NR 25
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1167
EP 1178
DI 10.1016/j.jvcir.2012.08.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300001
DA 2024-07-18
ER

PT J
AU Yang, L
   Wu, DP
AF Yang, Lei
   Wu, Dapeng
TI Adaptive quantization using piecewise companding and scaling for
   Gaussian mixture
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalar quantization; Companding; Scaling; Lloyd-Max quantizer; Gaussian
   mixture model (GMM); Analog-to-digital converter (ADC); High dynamic
   range (HDR) image; Tone mapping
ID DYNAMIC-RANGE IMAGES; TONE REPRODUCTION; SCENES; CONVERTER; OPERATOR;
   DISPLAY; MODEL; CMOS
AB Quantization is fundamental to analog-to-digital converter (ADC) and signal compression. In this paper, we propose an adaptive quantizer with piecewise companding and scaling for signals of Gaussian mixture model (GMM). Our adaptive quantizer operates under three modes, each of which corresponds to different types of GMM. Moreover, we propose a reconfigurable architecture to implement our adaptive quantizer in an ADC. We also use it to quantize images and design the tone mapping algorithm for high dynamic range (HDR) image compression. Our experimental results show that (I) the proposed quantizer is able to achieve performance close to the optimal quantizer (i.e., Lloyd-Max quantizer for GMM) in the sense of mean squared error (MSE), at much lower computational cost than it; (2) the proposed quantizer is able to achieve much better MSE performance than a uniform quantizer, at a cost similar to the uniform quantizer. The proposed adaptive quantizer holds great potential in the appilcations of the existing ADC and HDR image compression. Published by Elsevier Inc.
C1 [Yang, Lei; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Yang, L (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM leiyang@ufl.edu; wu@ece.ufl.edu
OI Wu, Dapeng/0000-0003-1755-0183
FU Directorate For Engineering; Div Of Electrical, Commun & Cyber Sys
   [1002214] Funding Source: National Science Foundation
CR [Anonymous], EUR 2002 SEP
   [Anonymous], 2000, LECT NOTES MATH
   [Anonymous], 2006, PATTERN RECOGN
   BENNETT WR, 1948, AT&T TECH J, V27, P446, DOI 10.1002/j.1538-7305.1948.tb01340.x
   Boschetti A, 2010, IEEE INT CON MULTI, P1130, DOI 10.1109/ICME.2010.5583305
   CHIU K, 1993, GRAPH INTER, P245
   Choi M, 2001, IEEE J SOLID-ST CIRC, V36, P1847, DOI 10.1109/4.972135
   Debevec P, 2002, IEEE COMPUT GRAPH, V22, P24, DOI 10.1109/MCG.2002.988743
   Debevec P.E., 2008, P 24 ANN C COM GRAPH, P1
   DiCarlo JM, 2000, PROC SPIE, V3965, P392, DOI 10.1117/12.385456
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Duan J, 2010, PATTERN RECOGN, V43, P1847, DOI 10.1016/j.patcog.2009.12.006
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fartal R., 2002, ACM T GRAPHIC, V21, P249
   Gersho A., 1993, VECTOR QUANTIZATION
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   Gulati K, 2001, IEEE J SOLID-ST CIRC, V36, P1900, DOI 10.1109/4.972140
   Hossack D, 1998, IEEE J SOLID-ST CIRC, V33, P1059, DOI 10.1109/4.701259
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Johns D.A., 2008, ANALOG INTEGRATED CI
   Kazakos D., 2006, P 12 BIENN IEEE C EL, P462
   Khan IA, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL WORKSHOP ON MATRIX ANALYSIS AND APPPLICATIONS, VOL 1, P1, DOI 10.1145/1838002.1838049
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Ma JW, 2000, NEURAL COMPUT, V12, P2881, DOI 10.1162/089976600300014764
   Pattanaik S.N., 1998, P SIGGRAPH 98, P287
   Peric ZH, 2008, INFORM SCIENCES, V178, P4375, DOI 10.1016/j.ins.2008.05.029
   Pohlmann K.C., 2005, PRINCIPLES DIGITAL A, V5th
   Qiu GP, 2005, IEEE INT SYMP CIRC S, P6276
   Qiu GP, 2006, INT C PATT RECOG, P996
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xuan GR, 2001, IEEE IMAGE PROC, P145, DOI 10.1109/ICIP.2001.958974
NR 35
TC 8
Z9 8
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 959
EP 971
DI 10.1016/j.jvcir.2012.06.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900001
DA 2024-07-18
ER

PT J
AU Lee, C
   Kim, CS
AF Lee, Chul
   Kim, Chang-Su
TI Rate-distortion optimized layered coding of high dynamic range videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range video; Video coding; Rate-distortion optimization;
   Layered coding; H.264/AVC; Tone mapping; Backward compatibility; Human
   visual system
ID BIT ALLOCATION; CODER
AB An efficient algorithm to compress high dynamic range (HDR) videos into layered bitstreams is proposed in this work. First, we separate an HDR video sequence into a tone-mapped low dynamic range (LDR) sequence and a ratio sequence, which represents ratios between HDR and LDR pixel values. Then, we encode the LDR and ratio sequences to maximize the rate-distortion (R-D) performance by extending the standard H.264/AVC codec. Specifically, we estimate the distortion of the HDR sequence from those of the LDR sequence and the ratio sequence, and then allocate a limited bit budget to the LDR sequence and the ratio sequence efficiently to maximize the qualities of both LDR and HDR sequences. Conventional LDR devices use only the LDR stream, whereas HDR devices reconstruct the HDR video from the LDR and ratio streams. Simulation results show that the proposed algorithm provides significantly better R-D performance than conventional HDR video coding techniques. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Lee, Chul; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM kayne@korea.ac.kr; changsukim@korea.ac.kr
RI Lee, Chul/W-3762-2019
OI Lee, Chul/0000-0001-9329-7365; Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2012-011031, NRF-M1AXA003-2011-0031648]; Global Frontier R&D Program on
   Human-centered Interaction for Coexistence; National Research Foundation
   of Korea
FX We thank Dr. Grzegorz Krawczyk for making the HDR sequences "Tunnel" and
   "Sun" available for our experiments and Dr. Rafal Mantiuk for providing
   us valuable comments and their experimental data on the "Tunnel"
   sequence for comparison. This work was supported partly by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MEST) (No. 2012-011031), and partly by the Global Frontier R&D Program
   on Human-centered Interaction for Coexistence, funded by the National
   Research Foundation of Korea grant funded by the Korean Government
   (MEST) (NRF-M1AXA003-2011-0031648).
CR [Anonymous], 2006, Elements of Information Theory
   [Anonymous], 2009, 291992 ISOIEC
   [Anonymous], 2005, 1449610 ISOIEC AVC
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 2005, MAX PLANK INSTITUT I
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   [Anonymous], P ACM SIGGRAPH 2008
   [Anonymous], 2004, 144962 ISOIEC
   Bahn S, 2007, IN C IND ENG ENG MAN, P492, DOI 10.1109/IEEM.2007.4419238
   Bross B., 2011, JCTVCG1103
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Debevec P.E., 2006, ACM SIGGRAPH COURSE
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Dufaux F, 2009, IEEE SIGNAL PROC MAG, V26, P195, DOI 10.1109/MSP.2009.934187
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gao YY, 2009, IEEE T CIRC SYST VID, V19, P500, DOI 10.1109/TCSVT.2009.2014018
   Garbas JU, 2011, INT CONF ACOUST SPEE, P829
   Gersho A., 2003, Vector Quantization and Signal Compression
   Irawan P., 2005, Rendering Techniques, P231
   Kains F., 2003, ACM SIGGRAPH SKETCHE
   Kamaci N, 2005, IEEE T CIRC SYST VID, V15, P994, DOI 10.1109/TCSVT.2005.852400
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Larson G.W., 1998, Rendering with radiance: the art and science of lighting visualization
   Lee C., 2008, P 16 EUR SIGN PROC C
   Li ZG, 2006, IEEE T CIRC SYST VID, V16, P1449, DOI 10.1109/TCSVT.2006.885176
   Liu S, 2008, PROC SPIE, V6822, DOI 10.1117/12.766601
   Mai ZC, 2011, IEEE T IMAGE PROCESS, V20, P1558, DOI 10.1109/TIP.2010.2095866
   Mantiuk R, 2004, ACM T GRAPHIC, V23, P733, DOI 10.1145/1015706.1015794
   Mantiuk R., 2006, MPII20064001
   Mantiuk R., 2006, P SPIE HUMAN VISION, V6057
   Mantiuk R, 2006, ACM T GRAPHIC, V25, P713, DOI 10.1145/1141911.1141946
   Okuda M, 2007, J VIS COMMUN IMAGE R, V18, P377, DOI 10.1016/j.jvcir.2007.06.004
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Segall A, 2007, IEEE IMAGE PROC, P1
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tchou C., 2001, ACM SIGGRAPH SKETCHE
   Van Hateren JH, 2006, ACM T GRAPHIC, V25, P1380, DOI 10.1145/1183287.1183293
   Wang HM, 2005, FIBER POLYM, V6, P6, DOI 10.1007/BF02875567
   Ward G, 2005, THIRTEENTH COLOR IMAGING CONFERENCE, FINAL PROGRAM AND PROCEEDINGS, P283
   Ward Greg., 2004, Proceedings of the 1st Symposium on Applied Perception in Graphics and Visualization, APGV '04, P83
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu RF, 2005, IEEE COMPUT GRAPH, V25, P57, DOI 10.1109/MCG.2005.133
NR 43
TC 11
Z9 13
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 908
EP 923
DI 10.1016/j.jvcir.2012.05.009
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900008
DA 2024-07-18
ER

PT J
AU Muhit, AA
   Pickering, MR
   Frater, MR
   Arnold, JF
AF Muhit, Abdullah A.
   Pickering, Mark R.
   Frater, Michael R.
   Arnold, John F.
TI Video coding using fast geometry-adaptive partitioning and an elastic
   motion model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Elastic motion model; Geometry-adaptive partition; Motion
   estimation; Motion compensation; H.264; H.265; Sliced blocks
ID COMPENSATION
AB Effective motion-compensated prediction is the key to high-performance video coding. To ensure continuous improvement of video coders, emerging motion-compensation technologies will need to be successfully integrated into future standards. Higher order elastic motion models and geometry-adaptive block partitioning are such advanced techniques that are good candidates for integration into future generations of video coders. However, it is vital that these techniques are additive in performance, non-interfering and maintain justifiable complexity. In this paper, we propose an efficient block-partitioning scheme that incorporates both geometry-adaptive partitioning and an elastic motion model as extensions to the standard motion estimation procedure. Our experiments suggest that geometric partitioning in combination with the use of an elastic motion model can provide enhanced performance, although the increased complexity is of some concern for real-time applications. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Muhit, Abdullah A.; Pickering, Mark R.; Frater, Michael R.; Arnold, John F.] Univ New S Wales, Australian Def Force Acad, Sch Engn & Informat Technol, Canberra, ACT, Australia.
C3 University of New South Wales Sydney; Australian Defense Force Academy
RP Muhit, AA (corresponding author), Univ New S Wales, Australian Def Force Acad, Sch Engn & Informat Technol, Canberra, ACT, Australia.
EM muhit@ieee.org
CR [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 1995, H263 ITUT
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   CHAN MH, 1990, IEE P, V137
   DUFAUX F, 1995, P IEEE, V83, P858, DOI 10.1109/5.387089
   Escoda OD, 2007, INT CONF ACOUST SPEE, P657
   FERREIRA RU, 2009, P 16 IEEE INT C IM P
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HUNG EM, P ICIP 2006, P1697
   *ITU T, 1994, H261 ITUT
   Karczewicz M, 1997, SIGNAL PROCESS-IMAGE, V10, P63, DOI 10.1016/S0923-5965(97)00019-2
   KONDO S, P ICIP 2005 IT
   Kordasiewicz RC, 2007, IEEE T CIRC SYST VID, V17, P1388, DOI 10.1109/TCSVT.2007.903777
   Kybic J, 2003, IEEE T IMAGE PROCESS, V12, P1427, DOI 10.1109/TIP.2003.813139
   LI HB, 1995, IEEE T COMMUN, V43, P1673, DOI 10.1109/26.380216
   MA S, P SPIE, V6508
   MUHIT AA, 2008, CIRCUITS SYSTEMS SIG, V27, P657
   Muhit AA, 2009, IEEE IMAGE PROC, P621, DOI 10.1109/ICIP.2009.5413849
   Muhit AA, 2010, IEEE T CIRC SYST VID, V20, P661, DOI 10.1109/TCSVT.2010.2045804
   Muhit AA, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P413
   NAKAYA Y, 1994, IEEE T CIRC SYST VID, V4, P339, DOI 10.1109/76.305878
   Paul M, 2010, IEEE T IMAGE PROCESS, V19, P691, DOI 10.1109/TIP.2009.2033406
   SEFERIDIS V, 1993, OPT ENG, V32, P1464, DOI 10.1117/12.138613
   SULLIVAN GJ, 1991, P GLOBECOM 91 PHOEN, P85
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang K, 1997, IEEE J SEL AREA COMM, V15, P1704, DOI 10.1109/49.650044
NR 26
TC 15
Z9 23
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 31
EP 41
DI 10.1016/j.jvcir.2011.07.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100004
DA 2024-07-18
ER

PT J
AU Algin, GB
   Tunali, ET
AF Algin, Gul Boztok
   Tunali, E. Turban
TI Scalable video encryption of H.264 SVC Codec
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264 SVC; Layered security; Multimedia encryption; Scalable video
   encryption; Video Coding; Perceptual encryption; Synchronized secure
   video transmission; Selective encryption
ID DESIGN
AB A new algorithm for encrypting H.264 SVC (Scalable Video Codec) video data is developed. Security requirements of encoded video are examined together with constraints arising from structural properties of the SVC software. Performance analysis of the new algorithm is reported and its strength against cryptanalysis attacks is discussed. It has been demonstrated that the new algorithm has almost no overhead with low level encryption and acceptable overhead for high level encryption that leads to totally unperceivable video. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Algin, Gul Boztok] Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
   [Tunali, E. Turban] Izmir Univ Econ, Dept Comp Engn, TR-35330 Izmir, Turkey.
C3 Ege University; Izmir Ekonomi Universitesi
RP Algin, GB (corresponding author), Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
EM gul.boztok@ege.edu.tr; turhan.tunali@ieu.edu.tr
RI Algın, Gül Boztok/B-1106-2016
OI Algın, Gül Boztok/0000-0003-3989-1616
CR Agi I., 1996, Proceedings of the Symposium on Network and Distributed System Security, P137, DOI 10.1109/NDSS.1996.492420
   ALATTAR AM, 1999, P IEEE INT S CIRC SY
   ALATTAR AM, 1999, P INT C IM PROC ICIP
   [Anonymous], 1996, P ACM INT MULT C BOS
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Kim H, 2007, IEEE T SIGNAL PROCES, V55, P2263, DOI 10.1109/TSP.2007.892710
   KUNKELMANN T, 1997, P 4 IEEE INT C MULT
   LI S, 2004, APPENDIX MULTIMEDIA, V24, P57
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Maples T., 1995, P 4 INT C COMP COMM
   MEYER J, 1995, SEC MECH MULT DAT EX
   QIAO L, 1998, INT J COMPUTERS GRAP
   REICHEL J, 2006, JVT 19 M GEN SWITZ A
   Richardson I.E. G., 2002, VIDEO CODEC DESIGN
   SAID A, 2005, P IEEE INT C IM PROC, V2
   Shi C., 1999, P INT C PAR DISTR PR
   Thomas N, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P157
   Uehara T, 2006, IEEE T IMAGE PROCESS, V15, P3592, DOI 10.1109/TIP.2006.881939
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Wen JT, 2002, IEEE T CIRC SYST VID, V12, P545, DOI 10.1109/TCSVT.2002.800321
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   XIE D, 2005, INT S CIRC SYST KOB
   Yuan C, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P620
   ZHOU J, 2007, IEEE SIGNAL PROCESSI, V14
   SVM SOFTWARE MANUAL
NR 27
TC 17
Z9 19
U1 7
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2011
VL 22
IS 4
BP 353
EP 364
DI 10.1016/j.jvcir.2011.02.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 751AG
UT WOS:000289589100006
DA 2024-07-18
ER

PT J
AU Liu, J
   Huan, ZD
   Huang, HY
AF Liu, Jun
   Huan, Zhongdan
   Huang, Haiyang
TI Image restoration under mixed noise using globally convex segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total variation; Globally convex segmentation; Split Bregman iteration;
   Mixed noise; Impulsive noise; Image denoising; Image deblurring;
   Variational PDE method
ID MINIMIZATION; REMOVAL; IMPULSE; RECONSTRUCTION; ALGORITHMS
AB The total variation based regularization method has been proven to be quite efficient for image restoration. However, the noise in the image is assumed to be Gaussian in the overwhelming majority of researches. In this paper an extended ROF model is presented to restore image with non-Gaussian noise, in which the locations of the blurred pixels with high level noise are detected by a function and two estimated parameters of noise, while the fidelity and smoothness terms can be adaptively adjusted by updating these parameters. In contrast to the previous method, our model can give a much better restoration in some particular cases, such as the blurred image corrupted by impulsive noise and mixed noise. Moreover, the proposed minimization problem is solved by the split Bregman iteration, which makes our algorithm very fast. We provide some experiments and comparisons with other methods to illustrate the high efficiency of our method. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Liu, Jun; Huan, Zhongdan; Huang, Haiyang] Beijing Normal Univ, Minist Educ, Lab Math & Complex Syst, Sch Math Sci, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Huang, HY (corresponding author), Beijing Normal Univ, Minist Educ, Lab Math & Complex Syst, Sch Math Sci, Beijing 100875, Peoples R China.
EM hyhuangbnu@gmail.com
RI cai, bo/G-1491-2010
FU National Science Foundation of China (NSFC) [11071023]
FX We thank authors of [9,20-23] for their kind offer the Matlab source
   codes to make comparisons, we also thank the anonymous reviewers for
   their valuable comments. The research has been supported by National
   Science Foundation of China (NSFC, No. 11071023).
CR [Anonymous], 0906 UCLA CAM
   Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Dabov K., 2008, P SPIE EL IM JAN
   FOI A, 2006, P SPIE EL IM ALG SYS, V5
   GOLDSTEIN T, 2008, 0829 UCLA CAM
   Huang YM, 2009, IEEE SIGNAL PROC LET, V16, P457, DOI 10.1109/LSP.2009.2016835
   Liu J, 2009, INT J COMPUT VISION, V85, P182, DOI 10.1007/s11263-009-0254-9
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   RUDIN L, 1994, INT C IM PROC NOV, V1, P31
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tai X., 2009, 0905 UCLA CAM
   Vogel CR, 1998, IEEE T IMAGE PROCESS, V7, P813, DOI 10.1109/83.679423
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
NR 23
TC 6
Z9 7
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 263
EP 270
DI 10.1016/j.jvcir.2010.12.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300006
DA 2024-07-18
ER

PT J
AU Lee, S
   Yun, ID
   Lee, SU
AF Lee, Soochahn
   Yun, Il Dong
   Lee, Sang Uk
TI Robust bilayer video segmentation by adaptive propagation of global
   shape and local appearance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video segmentation; Shape prior; Local appearance; Adaptive local
   refinement; Incremental shape set; Adaptive frame propagation;
   Branch-and-mincut; MRF energy minimization
AB Segmenting semantic objects of interest from video has long been an active research topic, with a wide range of potential applications. In this paper, we present a bilayer video segmentation method robust to abrupt motion and change in appearance for both the foreground and background. Specifically, based on a few manually segmented keyframes, the proposed method propagates the global shape of the foreground as priors to adjacent frames by applying branch-and-mincut [1], which jointly estimates what is optimal among a set of shapes along with its pose and the corresponding segmentation in the current image. Based on this preliminary segmentation we determine two types of local regions likely to have erroneous results, and apply a probabilistic framework where shape and appearance cues are adaptively emphasized for local refinement. With each successive frame segmentation, the set of shapes applied as priors are incrementally updated. Experimental results support the robustness of the proposed method for obstacles such as background clutter, motion, and appearance changes, from only a small number of user segmented keyframes. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lee, Soochahn] Seoul Natl Univ, Automat & Syst Res Inst, Seoul, South Korea.
   [Yun, Il Dong] Hankuk Univ Foreign Studies, Dept Digital Informat Engn, Yongin, South Korea.
   [Lee, Sang Uk] Seoul Natl Univ, Dept Elect Engn, Seoul, South Korea.
C3 Seoul National University (SNU); Hankuk University Foreign Studies;
   Seoul National University (SNU)
RP Lee, S (corresponding author), Seoul Natl Univ, Automat & Syst Res Inst, Seoul, South Korea.
EM redhouse@cvl.snu.ac.kr; yun@hufs.ac.kr; sanguk@ipl.snu.ac.kr
RI Lee, Soochahn/AAE-8471-2020
OI Lee, Soochahn/0000-0002-2975-2519
FU Ministry of Education, Science and Technology [20090053539]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (20090053539).
CR [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   BAI X, 2007, IEEE ICCV
   Blake A., 1998, ACTIVE CONTOURS
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Choi JG, 1997, IEEE T CIRC SYST VID, V7, P279, DOI 10.1109/76.564107
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cremers D., 2006, IEEE T PAMI
   Freedman Daniel., 2005, CVPR
   Gastaud M., 2004, IEEE T CIRCUITS SYST
   Kohli P., 2008, IJCV
   KOHLI P, 2007, PAMI
   KOLMOGOROV V, 2008, IJCV, V76
   Kumar M.P., 2005, CVPR
   Lempitsky Victor., 2008, ECCV
   LEVENTON M, 2000, IEEE CVPR
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   LU L, 2007, CVPR07
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P1190, DOI 10.1109/76.809155
   PROTIERE A, 2007, IEEE T IMAGE PROCESS
   REN X, 2007, CVPR07
   REN X, 2005, NIPS05
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   SUN J, 2006, ECCV, V2, P628
   Wang YL, 2005, POLYHEDRON, V24, P585, DOI 10.1016/j.poly.2004.12.019
   YIN P, 2007, CVPR07
   YU T, 2007, WMVC07
NR 27
TC 8
Z9 9
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 665
EP 676
DI 10.1016/j.jvcir.2010.04.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400006
DA 2024-07-18
ER

PT J
AU Wang, RZ
   Chien, YF
   Lin, YY
AF Wang, Ran-Zan
   Chien, Yin-Fang
   Lin, Yung-Yi
TI Scalable user-friendly image sharing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image sharing; Secret sharing; Secret image sharing; User-friendly
   shadow image; Progressive reconstruction; Scalable sharing; Visual
   cryptography; Visual secret sharing
ID SECRET; STEGANOGRAPHY
AB Image sharing addresses a fault-tolerant protection mechanism for important images. In a typical image sharing scheme, the generated shadow images usually have a noise-like appearance that conceals the secret image completely, but this makes them difficult to identify and manage. This paper proposes a scalable user-friendly image sharing scheme in which each generated shadow image looks like a shrunken replica of the original image. The scheme provides an easy-to-identify interface for managing the shadow images. Compared with previous user-friendly image sharing schemes, the proposed method can reconstruct the original image without any loss and still has the small-size shadow images. A notable feature is that the qualities of generated shadow images are scalable in the proposed scheme, which allows the quality of the shadow images to be adjusted according to the requirements of diverse applications. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Wang, Ran-Zan; Chien, Yin-Fang; Lin, Yung-Yi] Yuan Ze Univ, Dept Comp Sci & Engn, Tao Yuan 320, Taiwan.
C3 Yuan Ze University
RP Wang, RZ (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, 135 Far E Rd, Tao Yuan 320, Taiwan.
EM rzwang@saturn.yzu.edu.tw
RI cai, bo/G-1491-2010
CR Chang CC, 2002, PROCEEDINGS OF THE 6TH JOINT CONFERENCE ON INFORMATION SCIENCES, P964
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chao KY, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3206950
   Chen JYC, 2009, PRESENCE-TELEOP VIRT, V18, P1, DOI 10.1162/pres.18.1.1
   Chen SK, 2005, PATTERN RECOGN, V38, P2466, DOI 10.1016/j.patcog.2005.04.002
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Huang CP, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/63281
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CC, 2003, OPT ENG, V42, P2340, DOI 10.1117/1.1588661
   Lin SJ, 2009, OPT ENG, V48, DOI 10.1117/1.3168644
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2009, J INTERNET TECHNOL, V10, P155
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Yang CN, 2007, INT J IMAG SYST TECH, V17, P40, DOI 10.1002/ima.20096
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
NR 20
TC 10
Z9 10
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 751
EP 761
DI 10.1016/j.jvcir.2010.06.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400014
DA 2024-07-18
ER

PT J
AU Tsai, MJ
AF Tsai, Min-Jen
TI A visible watermarking algorithm based on the content and contrast aware
   (COCOA) technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CSF; Human Vision System; NVF; Visible watermarking; Wavelet transform;
   Copyright protection; Image inpainting; Image recovery
AB A novel visible watermarking algorithm based on the content and contrast aware (COCOA) technique with the consideration of Human Visual System (HVS) model is presented in this study. In order to determine the optimal watermark locations and strength at the watermark embedding stage, the COCOA visible watermarking utilizes the global and local characteristics of the host and watermark images in the discrete wavelet transform (DWT) domain. To achieve the best tradeoff between the embedding energy of watermark and the perceptual translucence, the utilization of contrast-sensitive function, noise visible function of perceptual model, and the basis function amplitudes of DWT coefficients are fine tuned, for the best quality of perceptual translucence and noise reduction of the COCOA algorithm. The experimental results demonstrate that COCOA technique not only provides high PSNR values for the watermarked images, but also preserves the watermark visibility under various signal processing operations, especially the watermark removal attack. (C) 2009 Elsevier Inc. All rights reserved.
C1 Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
FU National Science Council in Taiwan, Republic of China
   [NSC95-2416-H009-027, NSC96-2416-H009-015, NSC97-2410-H009-034]
FX This work is supported by the National Science Council in Taiwan,
   Republic of China, under Grant NSC95-2416-H009-027, NSC96-2416-H009-015
   and NSC97-2410-H009-034.
CR [Anonymous], USC SIPI IM DAT
   [Anonymous], Stirmark
   Beegan AP, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P88, DOI 10.1109/DSPWS.2002.1231082
   Bekkat N, 2004, J ELECTRON IMAGING, V13, P341, DOI 10.1117/1.1666872
   BERTALMIO M, 2000, IMAGE INPAINTING SIG
   Braudaway GW, 1996, P SOC PHOTO-OPT INS, V2659, P126, DOI 10.1117/12.235469
   Brooks AC, 2008, IEEE T IMAGE PROCESS, V17, P1261, DOI 10.1109/TIP.2008.926161
   Chantada GL, 2005, J PEDIAT HEMATOL ONC, V27, P39, DOI 10.1097/01.mph.0000149251.68562.8e
   Chen PM, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P910, DOI 10.1109/ICOSP.2000.891668
   Chu YP, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 1, P726, DOI 10.1109/IMSCCS.2006.112
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   DING K, 2005, IEICE T FUND ELECTR, V88, P87
   Fei CH, 2006, IEEE T INF FOREN SEC, V1, P43, DOI 10.1109/TIFS.2005.863505
   Hu YJ, 2001, ELECTRON LETT, V37, P1219, DOI 10.1049/el:20010838
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Huang CH, 2004, IEEE T MULTIMEDIA, V6, P16, DOI 10.1109/TMM.2003.819579
   Kankanhalli MS, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P568, DOI 10.1109/MMCS.1999.779263
   Kundur D, 2004, P IEEE, V92, P879, DOI 10.1109/JPROC.2004.827336
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Levicky D, 2004, RADIOENGINEERING, V13, P38
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Meng JH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P474, DOI 10.1109/ICIP.1998.723534
   Min-Jen Tsai, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P273
   Mohan J, 1999, INDIAN J HETEROCY CH, V9, P51
   MOHANTY SP, 2000, P IEEE INT C MULT EX, V20, P1029
   Pei SC, 2006, IEEE T INF FOREN SEC, V1, P543, DOI 10.1109/TIFS.2006.885031
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   TEO PC, 1994, P SOC PHOTO-OPT INS, V2179, P127, DOI 10.1117/12.172664
   VILLASENOR JD, 1995, IEEE T IMAGE PROCESS, V4, P1053, DOI 10.1109/83.403412
   Voloshynovskiy Sviatoslav., 1999, Third International Workshop on Information Hiding, P211
   Wang HZ, 2005, IEEE IMAGE PROC, P1609
   Wang Y, 2003, SYM REL DIST SYST, P25
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Watson AB, 1998, P SOC PHOTO-OPT INS, V3299, P139, DOI 10.1117/12.320105
   YONG L, 2004, CHINESE J COMPUT, V27, P533
   Yu D, 2002, EURASIP J APPL SIG P, V2002, P92, DOI 10.1155/S111086570200046X
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
   AIS WATERMARK PICTUR
NR 42
TC 28
Z9 29
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2009
VL 20
IS 5
BP 323
EP 338
DI 10.1016/j.jvcir.2009.03.011
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 547LX
UT WOS:000273891500003
DA 2024-07-18
ER

PT J
AU Mochizuki, Y
   Torii, A
   Imiya, A
AF Mochizuki, Yoshihiko
   Torii, Akihiko
   Imiya, Atsushi
TI <i>N</i>-Point Hough transform for line detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hough transform; Three-point Hough transform; Random sampling; Geometric
   duality; Randomized hough transform; Projective geometry; Spherical
   geometry; Discrete voting space; Continuous voting space
ID ELLIPSE DETECTION
AB In this paper, we introduce the N-point Hough transform for the detection of a large number of planar lines in a noisy image. The N-point Hough transform yields the randomized Hough transform and the three-point Hough transform if we set N = 2 and N = 3, respectively. From the viewpoint of the number of sample points required for the computation of lines, the N-point Hough transform is a generalization of the usual randomized Hough transform. The three-point Hough transform is introduced to increase the speed of the randomized Hough transform; the third point is used to avoid the selection of meaningless first and second sample points, which are used for the computation of the parameters of a line. This additional sample point guarantees the accuracy and robustness of a line detected using the first and second sample points. The N-point Hough transform evaluates the accuracy and robustness of a computed line using additional (N - 2) points for each line. The evaluation in the N-point Hough transform is achieved by counting the cardinality of sample points in the neighborhood of this line as the support of the sample points for the acceptance of this line. First, to define the neighborhood of a line mathematically, in this paper we clarify the relationship between a line and a set of parameters in the voting space using geometric duality. This relationship allows us to define a metric in the voting space. The metric is used for the clustering of bins in the spherical voting space to guarantee the accurate and robust computation of lines. Finally, we evaluate the performance of the N-point Hough transform by comparing it with the randomized Hough transform, which is the two-point Hough transform in our framework of the voting method. This comparative study shows the geometric and computational advantages of the N-point Hough transform. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Mochizuki, Yoshihiko] Chiba Univ, Grad Sch Sci & Technol, Inage Ku, Chiba 2638522, Japan.
   [Torii, Akihiko] Czech Tech Univ, Ctr Machine Percept, Prague 12135 2, Czech Republic.
   [Imiya, Atsushi] Chiba Univ, Inst Media & Informat, Inage Ku, Chiba 2638522, Japan.
C3 Chiba University; Czech Technical University Prague; Chiba University
RP Mochizuki, Y (corresponding author), Chiba Univ, Grad Sch Sci & Technol, Inage Ku, 1-33 Yayoi Cho, Chiba 2638522, Japan.
EM motchy@graduate.chiba-u.jp; torii@cmp.felk.cvut.cz;
   imiya@faculty.chiba-u.jp
RI Mochizuki, Yoshihiko/C-5719-2011; Torii, Akihiko/B-9270-2015
OI Mochizuki, Yoshihiko/0000-0002-1290-7828; 
CR Aguado AS, 2000, P ROY SOC A-MATH PHY, V456, P503, DOI 10.1098/rspa.2000.0528
   [Anonymous], 1986, IEEE T PATTERN ANAL
   Ballard D.H., 1982, Computer Vision
   Becker JM, 2000, P SOC PHOTO-OPT INS, V4117, P243, DOI 10.1117/12.404826
   BENTZVI D, 1990, PATTERN RECOGN LETT, V11, P167, DOI 10.1016/0167-8655(90)90002-J
   Bhattacharya P, 2002, PATTERN RECOGN LETT, V23, P1705, DOI 10.1016/S0167-8655(02)00133-2
   Bhattacharya P, 2003, PATTERN RECOGN, V36, P483, DOI 10.1016/S0031-3203(02)00079-1
   Chen TC, 2001, REAL-TIME IMAGING, V7, P473, DOI 10.1006/rtim.2001.0233
   DEANS SR, 1981, IEEE T PATTERN ANAL, V3, P185, DOI 10.1109/TPAMI.1981.4767076
   Goldenshluger A, 2004, ANN STAT, V32, P1908, DOI 10.1214/009053604000000760
   HSU CC, 1990, PATTERN RECOGN, V23, P275, DOI 10.1016/0031-3203(90)90015-D
   Immerkær J, 1998, PATTERN RECOGN LETT, V19, P1133, DOI 10.1016/S0167-8655(98)00095-6
   Intel Corporation, OP SOURC COMP VIS LI
   KALVIAINEN H, 1995, IMAGE VISION COMPUT, V13, P239, DOI 10.1016/0262-8856(95)99713-B
   KENZIE DS, 1990, PATTERN RECOGN, V23, P283
   Kesidis AL, 1999, IEEE T PATTERN ANAL, V21, P1329, DOI 10.1109/34.817411
   KIRYATI N, 1991, CVGIP-GRAPH MODEL IM, V53, P213, DOI 10.1016/1049-9652(91)90043-J
   Kyrki V, 2000, REAL-TIME IMAGING, V6, P79, DOI 10.1006/rtim.1999.0183
   LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041
   McLaughlin RA, 1998, PATTERN RECOGN LETT, V19, P299, DOI 10.1016/S0167-8655(98)00010-5
   Mount DM, 2001, COMP GEOM-THEOR APPL, V19, P1, DOI 10.1016/S0925-7721(01)00009-8
   Nair PS, 1996, PATTERN RECOGN LETT, V17, P777, DOI 10.1016/0167-8655(96)00014-1
   PEI SC, 1995, PATTERN RECOGN LETT, V16, P615, DOI 10.1016/0167-8655(95)00010-E
   PRINCEN J, 1990, CVGI, V52, P52
   SANZ J., 1988, SPRINGER SER INFORM, V16
   *U GRAN COMP VIS G, IM DAT
   *U S CA, USC SIPI IM DAT
   Wright M, 1996, IMAGE VISION COMPUT, V14, P627, DOI 10.1016/0262-8856(96)01100-6
   XU L, 1993, CVGIP-IMAG UNDERSTAN, V57, P131, DOI 10.1006/ciun.1993.1009
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
NR 30
TC 22
Z9 29
U1 2
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2009
VL 20
IS 4
BP 242
EP 253
DI 10.1016/j.jvcir.2009.01.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 447EV
UT WOS:000266175300002
DA 2024-07-18
ER

PT J
AU Li, HL
   Ngan, KN
AF Li, Hongliang
   Ngan, King N.
TI Saliency model-based face segmentation and tracking in head-and-shoulder
   video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video segmentation; facial saliency map; boundary saliency map;
   video-conferencing; face tracking; skin tone; facial feature extraction;
   visual attention; face segmentation; head-and-shoulder video
ID COLOR; RECOGNITION; CLASSIFICATION; FEATURES; REGIONS; OBJECTS; SPACE
AB In this paper, a novel face segmentation algorithm is proposed based on facial saliency map (FSM) for head-and-shoulder type video application. This method consists of three stages. The first stage is to generate the saliency map of input video image by our proposed facial attention model. In the second stage, a geometric model and an eye-map built from chrominance components are employed to localize the face region according to the saliency map. The third stage involves the adaptive boundary correction and the final face contour extraction. Based on the segmented result, an effective boundary saliency map (BSM) is then constructed, and applied for the tracking based segmentation of the successive frames. Experimental evaluation on test sequences shows that the proposed method is capable of segmenting the face area quite effectively. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Li, Hongliang; Ngan, King N.] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Li, HL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM hlli@ee.cuhk.edu.hk; knngan@ee.cuhk.edu.hk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
CR [Anonymous], P SIGGRAPH
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], CVL FACE DATABASE
   Caetano TS, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P275, DOI 10.1109/SIBGRA.2002.1167155
   Caetano TS, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P279, DOI 10.1109/ICIAP.2001.957022
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P575, DOI 10.1109/TCSVT.2005.844447
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chen C, 1997, IEE P-VIS IMAGE SIGN, V144, P384, DOI 10.1049/ip-vis:19971414
   Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015
   Criminisi A., 2006, Proc. of CVPR
   Fritsch J, 2002, IEEE ROMAN 2002, PROCEEDINGS, P337, DOI 10.1109/ROMAN.2002.1045645
   FROBA B, 2004, P CVPR, P65
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Greenspan H, 2001, PATTERN RECOGN LETT, V22, P1525, DOI 10.1016/S0167-8655(01)00086-1
   Habili N, 2004, IEEE T CIRC SYST VID, V14, P1086, DOI 10.1109/TCSVT.2004.831970
   HAN J, 2004, UNSUPERVISED ATTENTI, V2, P941
   Hsia SC, 2005, IEEE T CIRC SYST VID, V15, P1026, DOI 10.1109/TCSVT.2005.852413
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   KAWATO S, 2000, P INT C SIGN PROC, V2, P1415
   Lam KM, 1998, IEEE T PATTERN ANAL, V20, P673, DOI 10.1109/34.689299
   Levner I, 2007, IEEE T IMAGE PROCESS, V16, P1437, DOI 10.1109/TIP.2007.894239
   Li JL, 2007, PROCEEDINGS OF UK-CHINA SPORTS ENGINEERING WORKSHOP, P1
   Li SZ, 2005, IEEE T IMAGE PROCESS, V14, P705, DOI 10.1109/TIP.2005.847295
   Liévin M, 2004, IEEE T IMAGE PROCESS, V13, P63, DOI 10.1109/TIP.2003.818013
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Luo HT, 2003, IEEE T MULTIMEDIA, V5, P379, DOI 10.1109/TMM.2003.813285
   MA YF, 2002, MODEL MOTION ATTENTI, V1, P129
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martinkauppi B, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P652, DOI 10.1109/ICIAP.2003.1234124
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P1190, DOI 10.1109/76.809155
   Menser B, 2000, PROC SPIE, V4067, P731, DOI 10.1117/12.386675
   PARK J, 2000, P IEEE INT C MULT EX, V1, P133
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Phung SL, 2001, ANZIIS 2001: PROCEEDINGS OF THE SEVENTH AUSTRALIAN AND NEW ZEALAND INTELLIGENT INFORMATION SYSTEMS CONFERENCE, P171
   Rajagopalan AN, 2005, IEEE T IMAGE PROCESS, V14, P832, DOI 10.1109/TIP.2005.847288
   SCOTT VD, 2007, P CVPR
   SOBOTTKA K, 1997, P IAPR INT C AUD VID, P77
   Terrillon JC, 1998, INT C PATT RECOG, P1350, DOI 10.1109/ICPR.1998.711952
   Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HL, 1997, IEEE T CIRC SYST VID, V7, P615, DOI 10.1109/76.611173
   Yan SC, 2004, IEEE T CIRC SYST VID, V14, P102, DOI 10.1109/TCSVT.2003.818359
   Yang JF, 2004, INT C PATT RECOG, P632
   YANG MH, 1998, IEEE ICIP, V98, P127
   Yin P., 2007, P CVPR
NR 51
TC 73
Z9 76
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2008
VL 19
IS 5
BP 320
EP 333
DI 10.1016/j.jvcir.2008.04.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 318LO
UT WOS:000257093400004
DA 2024-07-18
ER

PT J
AU Li, XG
   Lam, KM
   Shen, LS
AF Li, Xiaoguang
   Lam, Kin Man
   Shen, Lansun
TI An adaptive algorithm for the display of high-dynamic range images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE high-dynamic range image; tone mapping; tone reproduction
ID TONE REPRODUCTION
AB A novel algorithm based on spatial and statistical information is proposed for the display of high-dynamic range (HDR) images. In our proposed algorithm, an image is first decomposed into a base layer and a detailed layer, which represent its smoothed and fine details, respectively. The problem of overall impression preservation is regarded as a global issue in our algorithm. Statistical-based histogram adjustment is employed to deal with the base layer. The reproduction of visual details is regarded as a local issue. The detailed layer obtained using a spatial filter is adaptively enhanced according to the mapping function used for the base layer. The main contributions of our algorithm are that: (1) an adaptive detail-enhancement method is proposed and (2) a gain map is defined to combine the local and global issues. Experimental results show the superior performance of our approach in terms of visual quality. (C) 2007 Published by Elsevier Inc.
C1 Hong Kong Polytech Univ, Dept Ingn Elect & Informat, Ctr Multimedia Signal Proc, Hong Kong, Hong Kong, Peoples R China.
   Beijing Univ Technol, Signal & Informat Proc Lab, Beijing 100022, Peoples R China.
C3 Hong Kong Polytechnic University; Beijing University of Technology
RP Lam, KM (corresponding author), Hong Kong Polytech Univ, Dept Ingn Elect & Informat, Ctr Multimedia Signal Proc, Hong Kong, Hong Kong, Peoples R China.
EM enkmlam@polyu.cdu.hk
RI Kan, Kin-Man/A-9352-2014
OI Kan, Kin-Man/0000-0002-0422-8454
CR [Anonymous], P 2 S APPL PERC GRAP
   [Anonymous], 13 SPRING C COMP GRA
   ASHIKHMIN M, 2002, 13 EUR WORKSH REND E, V10, P145
   Chiu K., 1993, Proceedings Graphics Interface '93, P245
   DiCarlo JM, 2000, PROC SPIE, V3965, P392, DOI 10.1117/12.385456
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   FAIRCHILD MD, 2004, ACM P 1 S APPL PERC
   FATTAL R, 2002, SIGGRAPH 02, P249
   IMPOCO G, 2005, P 8 COST 276 WORKSH
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Ledda P., 2004, Proceedings of the 3rd international conference on Com- puter graphics, virtual reality, visualisation and interaction in Africa, P151
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Mantiuk R, 2005, PROC SPIE, V5666, P204, DOI 10.1117/12.586757
   Mantiuk R, 2004, IEEE SYS MAN CYBERN, P2763
   Qiu GP, 2005, IEEE INT SYMP CIRC S, P6276
   Qiu GP, 2006, INT C PATT RECOG, P996
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   Tumblin J, 1999, COMP GRAPH, P83, DOI 10.1145/311535.311544
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
   YOSHIDA A, 2006, EUROGRAPHICS, V25
NR 22
TC 22
Z9 25
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 397
EP 405
DI 10.1016/j.jvcir.2007.06.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000006
DA 2024-07-18
ER

PT J
AU Chen, CM
   Lin, CW
   Wei, HC
   Chen, YC
AF Chen, Chih-Ming
   Lin, Chia-Wen
   Wei, Hsiao-Cheng
   Chen, Yung-Chang
TI Robust video streaming over wireless LANs using multiple description
   transcoding and prioritized retransmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE wireless video; video streaming; error resilience transcoding; automatic
   retransmission
ID ERROR CONTROL; TRANSMISSION; TRANSPORT
AB Video transport over wireless Local Area Networks (LANs) usually suffers from signal fading, noise interference, and network congestion, leading to time-varying packet loss rate and fluctuating effective bandwidth. We propose in this paper an adaptive error control scheme to adaptively insert error-resilience features into a compressed video in the media gateway which serves roaming clients. Our scheme divides the error control operation into the single description (SD) and multiple-description (MD) modes according to channel condition estimation. In the SD mode, a content-based prioritized retransmission method is proposed to mitigate the error propagation due to packet loss in video transport over wireless LANs. The proposed prioritized retransmission scheme determines the retransmission schedule of a lost packet according to the packet's loss impact that is obtained in a front-end encoding process. In the MD mode, we propose a channel-aware MD transcoding method to take advantage of MD coding and path diversity so as to further mitigate the error propagation due to packet loss caused by transient channel switching while roaming in wireless LANs. Experimental results show that the proposed scheme effectively mitigates the error propagation due to packet loss, while maintaining low extra computational complexity and low overhead cost. The proposed method is suitable for realtime streaming of prestored videos. (c) 2007 Elsevier Inc. All rights reserved.
C1 Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 300, Taiwan.
   Chunghwa Telecom Co Ltd, Telecommun Labs, Tao Yuan 326, Taiwan.
   Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Tsing Hua University; Chunghwa Telecom; National Chung Cheng
   University
RP Lin, CW (corresponding author), Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 300, Taiwan.
EM cmchen2@cht.com.tw; cwlin@ee.nthu.edu.tw; scwei@msl.url.com.tw;
   ycchen@ee.nthu.edu.tw
RI Lin, Chia-Wen/ABH-6075-2020; Chen, Chih-Ming/I-2464-2015; Lin,
   Chia-Wen/M-4571-2013
OI Lin, Chia-Wen/0000-0002-9097-2318
CR [Anonymous], 14496 ISOIEC
   Apostolopoulos J. G., 2000, Proceedings of the SPIE - The International Society for Optical Engineering, V4310, P392, DOI 10.1117/12.411817
   Aramvith S, 2002, IEEE T CIRC SYST VID, V12, P558, DOI 10.1109/TCSVT.2002.800326
   Boulgouris NV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P105, DOI 10.1109/MMSP.2001.962719
   Cen S, 2003, IEEE ACM T NETWORK, V11, P703, DOI 10.1109/TNET.2003.818187
   Chakareski J, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P9
   Chiou HJ, 2005, J VIS COMMUN IMAGE R, V16, P563, DOI 10.1016/j.jvcir.2004.11.009
   CORMON TH, 2001, INTRO ALGORITHMS
   Gogate N, 2002, IEEE T CIRC SYST VID, V12, P777, DOI 10.1109/TCSVT.2002.803229
   Goyal VK, 1998, IEEE DATA COMPR CONF, P388, DOI 10.1109/DCC.1998.672173
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Hasegewa T, 1996, 1996 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P32, DOI 10.1109/ICNP.1996.564893
   *IEEE, 1997, P80211 IEEE
   KANG SH, 2002, P WORKSH PACK VID
   Kim CS, 2001, IEEE T CIRC SYST VID, V11, P1011, DOI 10.1109/76.946518
   LAM WM, 1993, P INT C AC SPEECH SI, pV417
   Lu MH, 2007, WIREL COMMUN MOB COM, V7, P187, DOI 10.1002/wcm.473
   LU MH, 2005, P IEEE INT C MULT EX
   Mao SW, 2003, IEEE J SEL AREA COMM, V21, P1721, DOI 10.1109/JSAC.2003.815965
   Miu A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P441
   Reibman AR, 2002, IEEE T CIRC SYST VID, V12, P193, DOI 10.1109/76.993440
   Stuber G. L., 2001, PRINCIPLES MOBILE CO
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Tan K, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P836
   TAN W, 2001, P PACK VID WORKSH
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Zorzi M, 1997, IEEE T VEH TECHNOL, V46, P445, DOI 10.1109/25.580783
NR 32
TC 10
Z9 13
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 191
EP 206
DI 10.1016/j.jvcir.2007.02.001
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300001
DA 2024-07-18
ER

PT J
AU Fang, Y
   Wu, CK
   Yu, L
AF Fang, Yong
   Wu, Cheng-ke
   Yu, Lu
TI Video transmission using advanced partial backward decodable bit stream
   (APBDBS)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilience; PBDBS; APBDBS; resynchronization; video transmission
ID CONCEALMENT
AB An analysis on the error robustness of partial backward decodable bit stream (PBDBS) presented by Gao and Tu shows that bits at both ends of video packets are safer than those in the middle when the PBDBS is used. According to this, a new structure of video packet called advanced partial backward decodable bit stream (APBDBS) is proposed in this paper. First, different types of syntax elements in video packets are reordered according to their syntactical importance. The more important (such as motion vectors) are placed at both ends of video packets, while the less important in the middle. Second, MBs in video packets are reordered according to their spatial importance. MBs near to the centers of images are placed close to both ends of video packets while marginal MBs are placed in the middle. The simulation shows that with the APBDBS used, up to 2 dB luminance peak signal noise ratio (PSNR) improvement can be found compared with the PBDBS. (C) 2006 Elsevier Inc. All rights reserved.
C1 Xidian Univ, Natl Key Lab ISN, Xian, Peoples R China.
   Zhejiang Univ, Inst Informat & Commun Engn, Hangzhou 310027, Peoples R China.
C3 Xidian University; Zhejiang University
RP Fang, Y (corresponding author), Xidian Univ, Natl Key Lab ISN, Xian, Peoples R China.
EM yfang79@gmail.com
RI WU, CHENGKE/AGN-8305-2022
OI Yu, Lu/0000-0002-0550-7754
CR Gao SS, 2003, IEEE T CIRC SYST VID, V13, P182, DOI 10.1109/TCSVT.2002.808434
   KIEU LH, 1994, IEEE T IMAGE PROCESS, V3, P666, DOI 10.1109/83.334978
   KWOK W, 1993, IEEE T CONSUM ELECTR, V39, P455, DOI 10.1109/30.234620
   LAM WM, 1992, P IEEE INT C AC SPEE, V3, P477
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   SUN HF, 1995, IEEE T IMAGE PROCESS, V4, P470, DOI 10.1109/83.370675
   TAKISHIMA Y, 1995, IEEE T COMMUN, V43, P58
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WENGER S, 1998, Q15E50 ITUT
NR 12
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 186
EP 190
DI 10.1016/j.jvcir.2006.10.003
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700009
OA Bronze
DA 2024-07-18
ER

PT J
AU Zang, D
   Sommer, G
AF Zang, Di
   Sommer, Gerald
TI Signal modeling for two-dimensional image structures
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE monogenic curvature tenser; generalized monogenic curvature signal;
   phase; signal modeling
ID MONOGENIC SCALE-SPACE; PHASE
AB This paper presents a novel approach towards two-dimensional (2D) image structures modeling. To obtain more degrees of freedom, a 2D image signal is embedded into a certain geometric algebra. Coupling methods of differential geometry, tensor algebra, monogenic signal and quadrature filter, a general model for 2D image structures can be obtained as the monogenic extension of a curvature tensor. Based on this model, local representations for the intrinsically one-dimensional (i1D) and intrinsically two-dimensional (i2D) image structures are derived as the monogenic signal and the generalized monogenic curvature signal. From the local representation, independent features of local amplitude, phase and orientation are simultaneously extracted. Compared with the other related work, the remarkable advantage of our approach lies in the rotationally invariant phase evaluation of 2D structures, which delivers access to phase-based processing in many computer vision tasks. (c) 2006 Elsevier Inc. All rights reserved.
C1 Univ Kiel, Dept Comp Sci, Cognit Syst Grp, D-24118 Kiel, Germany.
C3 University of Kiel
RP Zang, D (corresponding author), Univ Kiel, Dept Comp Sci, Cognit Syst Grp, Olshaussenstr 40, D-24118 Kiel, Germany.
EM zd@ks.informatik.uni-kiel.de; gs@ks.informatik.uni-kiel.de
CR Ablamowicz R., 1996, CLIFFORD ALGEBRAS NU
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 2012, Clifford algebra to geometric calculus: a unified language for mathematics and physics
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   Bracewell R., 2003, FOURIER ANAL IMAGING
   BRACKX F, 2005, ICNAAM 2005 C RHOD G
   BRACKX F, 2006, IN J MATH MATH SCI
   Bülow T, 2001, IEEE T SIGNAL PROCES, V49, P2844, DOI 10.1109/78.960432
   BULOW T, 1999, 903 CHRIST ALBR U KI
   Carmo Do., 1976, DIFFERENTIAL GEOMETR
   Danielsson PE, 2001, J VIS COMMUN IMAGE R, V12, P255, DOI 10.1006/jvci.2000.0472
   Davenport CM., 1996, A Commutative Hypercomplex Algebra with Associated Function Theory Clifford Algebras with Numeric and Symbolic Computations, P213
   Felsberg M, 2001, GEOMETRIC COMPUTING WITH CLIFFORD ALGEBRAS, P209
   Felsberg M, 2005, LECT NOTES COMPUT SC, V3663, P493
   Felsberg M, 2005, LECT NOTES COMPUT SC, V3459, P192
   Felsberg M, 2004, J MATH IMAGING VIS, V21, P5, DOI 10.1023/B:JMIV.0000026554.79537.35
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   FELSBERG M, 2002, 2016 I INF PRAKT MAT
   Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793
   Florack L.M.J., 1997, COMPUTATIONAL IMAGIN, V10
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Hahn SL, 1996, HILBERT TRANSFORMS S, V2
   Hestenes D, 2001, GEOMETRIC ALGEBRA WITH APPLICATIONS IN SCIENCE AND ENGINEERING, P3
   KOENDERINK JJ, 1994, PATTERN RECOGN LETT, V15, P439, DOI 10.1016/0167-8655(94)90134-1
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Köthe U, 2005, LECT NOTES COMPUT SC, V3459, P179
   Köthe U, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P424
   Krause M, 2005, P SOC PHOTO-OPT INS, V5960, P1295, DOI 10.1117/12.632667
   Krieger G, 1996, IEEE T IMAGE PROCESS, V5, P1026, DOI 10.1109/83.503917
   KRUGER N, 2003, BRIT MACH VIS C, P260
   Lounesto P., 1997, Clifford Algebras and Spinors
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   PAPAULIS A, 1962, FOURIER INTEGRAL ITS
   Pei SC, 2004, IEEE T SIGNAL PROCES, V52, P2012, DOI 10.1109/TSP.2004.828901
   SCHUTTE HD, 1990, P IEEE INT S CIRC SY, V2, P1557
   Sobczyk G, 2005, LECT NOTES COMPUT SC, V3519, P191
   SOMMER G, 2005, P 4 INT C WAV AN ITS
   ZETZSCHE C, 1990, VISION RES, V30, P1111, DOI 10.1016/0042-6989(90)90120-A
   ZETZSCHE C, 1990, P SOC PHOTO-OPT INS, V1249, P160, DOI 10.1117/12.19667
NR 40
TC 22
Z9 22
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 81
EP 99
DI 10.1016/j.jvcir.2006.10.002
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100007
DA 2024-07-18
ER

PT J
AU Chen, ZB
   Xu, JF
   He, Y
   Zheng, JL
AF Chen, Zhibo
   Xu, Jianfeng
   He, Yun
   Zheng, Junli
TI Fast integer-pel and fractional-pel motion estimation for H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE fast motion estimation; UMHexagonS; CBFP; early termination; H.264/AVC;
   video coding
ID SEARCH ALGORITHM
AB This paper gives out a fast motion estimation algorithm for H.264/AVC, which has almost the same quality performance as that of the Full Search scheme and also provides a strategy to balance the quality performance and the search speed. Integer-pel search is the most time consuming module for motion estimation. In this paper a hybrid Unsymmetrical-cross Multihexagon-grid Search (UMHexagonS) algorithm is introduced, which well solves the false motion vector estimation problem because of the local-minimum. As results, it saves more than 90% on search time whereas the averaging PSNR loss is less than 0.056 dB for all tested sequences with different motion extent compared with the Fast Full Search scheme. Fractional-pel fast search is not negligible when the integer motion estimation has been extensively speeded up. By utilizing the property of uni-modal error surface inside the fractional-pel search window, a novel Center Biased Fractional-pel Search (CBFPS) algorithm is proposed in this paper, which can save 30-50% computation compared with the Full Fractional-pel Search scheme. Early termination is another problem discussed in this paper, to construct a complete motion estimation method, giving a uniform method which can cover a wide range of applications, terminating the program at early and right stage is certainly required. A model based on the Normative SAD Difference (NSD) is given to assist the termination decisionmaking, and a tradeoff between the search speed and the reconstructed quality can be achieved by changing a modulation factor. (c) 2005 Elsevier Inc. All rights reserved.
C1 Tsing Hua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP He, Y (corresponding author), Tsing Hua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM chenzb@ieee.org; hey@tsinghua.edu.cn
RI he, yun/JMB-6362-2023; feng, chen/JLM-8296-2023; Chen, Zhibo/T-5349-2019
OI Chen, Zhibo/0000-0002-8525-5066
CR [Anonymous], P 1997 INT C INF COM
   BIERLING M, 1986, SIGNAL PROCESS, V11, P387, DOI 10.1016/0165-1684(86)90079-4
   BJONTEGAARD G, 2001, VCEGM33 ITU SG16 DOC
   Chen SM, 2002, CHINESE J PHYSIOL, V45, P9
   CHEN Z, 2002, 3 M FAIRF VIRG US, P6
   CHEN Z, 2002, P IEEE ISCAS, V3
   CHEN Z, 2003, 7 M PATT 2 THAIL, P7
   CHEN Z, 2003, P PICT COD S SAINT M, P17
   CHEN Z, 2003, 8 M GEN SWITZ, P23
   Chen Z.B., 2002, 6 M AW JP, P5
   CHEN ZB, 2002, 4 M KLAG AUSTR 22 26
   CHEN ZB, 2003, THESIS TSINGHUA U
   Chung YY, 2000, P SOC PHOTO-OPT INS, V4067, P913, DOI 10.1117/12.386693
   Du C, 2003, IEEE T CIRC SYST VID, V13, P514, DOI 10.1109/TCSVT.2003.813416
   DU C, 2000, THESIS TSINGHUA U
   FENG XJ, 2004, THESIS TSINGHUA U
   GONG D, 2000, THESIS TSINGHUA U
   GONG DN, 2001, P PCS2001 SEOUL APR, P362
   *ISO IEC MPEG ITU, 2002, 6 M AW ISL JP, P5
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   KAPPAGANTULA S, 1983, P SOC PHOTO-OPT INST, V432, P64
   Koga B.T., 1981, P NAT TEL C
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   SULLIVAN G, 2001, VCEGN81 ITU SG16
   TOURAPIS AM, 2001, P 2001 IEEE INT S CI, V5, P183
   TOURAPIS HYC, 2002, 5 M GEN SWITZ 09 17
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   XU JF, 2003, 10 M WAIK HI USA, P7
   XU JF, 2003, P PCM SING
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
NR 33
TC 127
Z9 168
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 264
EP 290
DI 10.1016/j.jvcir.2004.12.002
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000005
DA 2024-07-18
ER

PT J
AU Liu, TQ
   Huang, H
   Lei, ZJ
   Fang, RG
   Wu, DP
AF Liu, Tianqi
   Huang, Hong
   Lei, Zhijun
   Fang, Ruogu
   Wu, Dapeng
TI Texture and motion aware perception in-loop filter for AV1
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE AV1; In-loop filter; Lightweight model; Texture and motion aware;
   Receptive field; Perceptual loss
ID CNN; ALGORITHM
AB Lossy compression introduces artifacts, and many conventional in-loop filters have been adopted in the AV1 standard to reduce these artifacts. Researchers have explored deep learning-based filters to remove artifacts in the compression loop. However, the high computational complexity of CNN-based filters remains a challenge. In this paper, a Texture-and Motion-Aware Perception (TMAP) in-loop filter is proposed to addresses this issue by selectively applying CNNs to texture-rich and high-motion regions, while utilizing non-learning methods to detect these regions. The proposed method introduces a new CNN structure, the Dense-Dual-Field Network (DDFN), which leverages a larger receptive field to enhance the quality of reconstructed frames by incorporating more contextual information. Furthermore, to improve perceptual quality, a novel loss function integrating wavelet-based perceptual information is presented. Experimental results demonstrate the superiority of our proposed models over other lightweight CNN models, and the effectiveness of the perceptual loss function is validated using the VMAF metric.
C1 [Liu, Tianqi; Huang, Hong] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
   [Lei, Zhijun] Meta, Menlo Pk, CA 94025 USA.
   [Fang, Ruogu] Univ Florida, J Crayton Pruitt Family Dept Biomed Engn, Gainesville, FL 32611 USA.
   [Wu, Dapeng] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida; City University of
   Hong Kong
RP Liu, TQ (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM tianqi.liu1@ufl.edu
RI Fang, Ruogu/AAY-8923-2020
OI Fang, Ruogu/0000-0003-3980-3532; Liu, Tianqi/0000-0002-8617-5236
CR aomedia, AV2 Common Test Conditions v2.0
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Cai J, 2020, IEEE COMPUT SOC CONF, P1852, DOI 10.1109/CVPRW50498.2020.00235
   Chen GY, 2019, IEEE IMAGE PROC, P1725, DOI 10.1109/icip.2019.8803127
   Chen WG, 2020, IEEE ACCESS, V8, P162479, DOI 10.1109/ACCESS.2020.3020388
   Chen Y, 2018, PICT COD SYMP, P41, DOI 10.1109/PCS.2018.8456249
   Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3
   Ding DD, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954565
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Fu CM, 2011, IEEE INT WORKSH MULT
   gitlab, AVM research 3.1
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Han JN, 2021, P IEEE, V109, P1435, DOI 10.1109/JPROC.2021.3058584
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ZJ, 2021, IEEE T IMAGE PROCESS, V30, P5439, DOI 10.1109/TIP.2021.3084345
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia CM, 2019, IEEE T IMAGE PROCESS, V28, P3343, DOI 10.1109/TIP.2019.2896489
   Joshi U, 2022, IEEE IMAGE PROC, P1946, DOI 10.1109/ICIP46576.2022.9897763
   Karczewicz M, 2021, IEEE T CIRC SYST VID, V31, P3907, DOI 10.1109/TCSVT.2021.3072297
   Kong LY, 2020, IEEE IMAGE PROC, P3379, DOI [10.1109/icip40778.2020.9190807, 10.1109/ICIP40778.2020.9190807]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2921877
   Li X, 2020, IEEE COMPUT SOC CONF, P615, DOI 10.1109/CVPRW50498.2020.00087
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Lu G, 2018, LECT NOTES COMPUT SC, V11218, P591, DOI 10.1007/978-3-030-01264-9_35
   Ma D, 2020, Arxiv, DOI arXiv:2011.09190
   Ma D, 2021, IEEE J-STSP, V15, P378, DOI 10.1109/JSTSP.2020.3043064
   Meng XD, 2020, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2020), P320, DOI 10.1109/MIPR49039.2020.00072
   Mercat A, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P297, DOI 10.1145/3339825.3394937
   Midtskogen S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1193, DOI 10.1109/ICASSP.2018.8462021
   Montgomery Chris, 1994, Xiph. org video test media (derf's collection), the xiph open source community
   Mukherjee D, 2017, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2017.8296284
   Nasiri F, 2021, IEEE OPEN J SIGNAL P, V2, P466, DOI 10.1109/OJSP.2021.3092598
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Shao T, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103615
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V, 2014, Integr. Circ. Syst. Algor. Archit, V39, P40
   Tsai CY, 2013, IEEE J-STSP, V7, P934, DOI 10.1109/JSTSP.2013.2271974
   Umer RM, 2020, IEEE COMPUT SOC CONF, P1769, DOI 10.1109/CVPRW50498.2020.00227
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang J., 2020, P EUR C COMP VIS ECC, P405
   Wang JJ, 2022, IEEE IMAGE PROC, P3331, DOI 10.1109/ICIP46576.2022.9897898
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welch G., 1995, An introduction to the kalman filter
   Xia JY, 2020, IEEE IMAGE PROC, P1291, DOI 10.1109/ICIP40778.2020.9190743
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697
   Yu Y., 2019, 2019 IEEE VISUAL COM, P1
   Zhang HY, 2012, INT SYM COMPUT INTEL, P148, DOI 10.1109/ISCID.2012.45
   Zhang SP, 2022, Arxiv, DOI arXiv:2206.07893
   Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3827, DOI 10.1109/TIP.2018.2815841
   Zhao HW, 2020, IEEE ACCESS, V8, P920, DOI 10.1109/ACCESS.2019.2961760
NR 57
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104025
DI 10.1016/j.jvcir.2023.104025
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FP8O6
UT WOS:001147144700001
DA 2024-07-18
ER

PT J
AU Kanimozhi, M
   Sudhakar, MS
AF Kanimozhi, M.
   Sudhakar, M. S.
TI Octagonal lattice-based triangulated shape descriptor engaging
   second-order derivatives supplementing image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Affine invariance; Bulls -Eye Retrieval (BER); Classification accuracy;
   Second -order derivatives; Shape retrieval; Similarity matching
ID TRIANGLE-AREA REPRESENTATION; RECOGNITION; HISTOGRAM; FEATURES; SPACE;
   SCALE; BAG
AB Erstwhile shape description schemes lack primarily in establishing trade-offs with accuracy and computational load. Accordingly, a lightweight shape descriptor offering precise definition and compaction of high-frequency features is contributed in this paper using a simple geometrical shape for localization and shape characterization. Initially, the input image is octagonally tessellated and triangularly decomposed into sub-regions whose side-wise differences are evaluated and subjected to second-order differentiation to produce three high-frequency values representing triangle corners. The resultant is processed by the law of sines to yield localized shape features exhibiting congruence and is reiterated on the residual regions, followed by a novel octal encoding scheme encompassing maximal variations in the localized regions. The resulting features are globally fabricated into shape histograms in a non-overlapping manner representing the shape vector. This scheme validated on widely popular benchmark shape datasets demonstrates superior retrieval and recognition accuracies greater than 93% which is lacking in its competitors.
C1 [Kanimozhi, M.; Sudhakar, M. S.] VIT, Sch Elect Engn, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Sudhakar, MS (corresponding author), VIT, Sch Elect Engn, Vellore, India.
EM kanimozhi.m@vit.ac.in; sudhakar.ms@vit.ac.in
OI M, KANIMOZHI/0000-0003-1120-1505
CR Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Alwaely B, 2020, IEEE ACCESS, V8, P182260, DOI 10.1109/ACCESS.2020.3028696
   Atabay H.A., 2016, Atabay, V7, P332
   Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009
   Bai X, 2012, IEEE T IMAGE PROCESS, V21, P2747, DOI 10.1109/TIP.2011.2170082
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cunningham P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459665
   El Rube I, 2005, IEEE IMAGE PROC, P1053
   Elghoul S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116058
   Giveki D, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6533
   Gonzalez R.C., 2018, Digital Image Processing
   Govindaraj P, 2019, SIGNAL IMAGE VIDEO P, V13, P771, DOI 10.1007/s11760-018-1407-5
   Govindaraj P, 2018, PATTERN RECOGN LETT, V116, P157, DOI 10.1016/j.patrec.2018.10.004
   Govindaraj P, 2018, IMAGING SCI J, V66, P98, DOI 10.1080/13682199.2017.1380356
   Haesevoets S, 2004, LECT NOTES COMPUT SC, V3074, P52
   Hu DM, 2015, IET COMPUT VIS, V9, P769, DOI 10.1049/iet-cvi.2014.0409
   Hu RX, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2286330
   Johnson R.A., 2013, Advanced euclidean geometry
   Kanimozhi M, 2023, DIGIT SIGNAL PROCESS, V133, DOI 10.1016/j.dsp.2022.103893
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Kumar R, 2023, J MATH IMAGING VIS, V65, P618, DOI 10.1007/s10851-022-01130-x
   Kurnianggoro L, 2018, NEUROCOMPUTING, V300, P1, DOI 10.1016/j.neucom.2018.02.093
   Lardeux F, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108000
   Leonard I.E., 2014, Classical geometry: Euclidean, transformational, inversive, and projective
   Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Lourenço VN, 2019, SIBGRAPI, P218, DOI 10.1109/SIBGRAPI.2019.00037
   Ma L, 2023, IEEE T CIRC SYST VID, V33, P6635, DOI 10.1109/TCSVT.2023.3265751
   Ma L, 2024, IEEE T MULTIMEDIA, V26, P1306, DOI 10.1109/TMM.2023.3279990
   Ma L, 2023, APPL INTELL, V53, P12999, DOI 10.1007/s10489-022-04014-0
   Ma L, 2020, IEEE SIGNAL PROC LET, V27, P2129, DOI 10.1109/LSP.2020.3039755
   Ma L, 2021, NEUROCOMPUTING, V443, P85, DOI 10.1016/j.neucom.2021.02.057
   Ma L, 2020, NEUROCOMPUTING, V380, P115, DOI 10.1016/j.neucom.2019.11.009
   Ma L, 2018, NEUROCOMPUTING, V312, P49, DOI 10.1016/j.neucom.2018.05.052
   Ma L, 2017, IEEE T MULTIMEDIA, V19, P2545, DOI 10.1109/TMM.2017.2703089
   Ma L, 2017, J VIS COMMUN IMAGE R, V44, P29, DOI 10.1016/j.jvcir.2017.01.014
   Mallikarjuna K, 2021, WIRELESS PERS COMMUN, V117, P2495, DOI 10.1007/s11277-020-07991-y
   Mori G, 2001, PROC CVPR IEEE, P723
   Myles AJ, 2004, J CHEMOMETR, V18, P275, DOI 10.1002/cem.873
   Nunes JF, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P433
   Paramarthalingam A, 2021, IET IMAGE PROCESS, V15, P1093, DOI 10.1049/ipr2.12088
   Patel V, 2019, IEEE WINT CONF APPL, P1223, DOI 10.1109/WACV.2019.00135
   Priyanka S, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119260
   Priyanka S, 2018, DIGIT SIGNAL PROCESS, V79, P125, DOI 10.1016/j.dsp.2018.04.012
   Reddy PVN, 2022, WIRELESS PERS COMMUN, V123, P2923, DOI 10.1007/s11277-021-09269-3
   Sharma P, 2017, OPTIK, V145, P346, DOI 10.1016/j.ijleo.2017.04.102
   Shekar BH, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P218, DOI 10.1109/ICSIP.2014.41
   Shen W, 2016, PATTERN RECOGN LETT, V83, P321, DOI 10.1016/j.patrec.2016.02.002
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Tabia H, 2017, NEUROCOMPUTING, V253, P24, DOI 10.1016/j.neucom.2017.01.101
   Tavakolian M, 2013, IEEE IMAGE PROC, P4210, DOI 10.1109/ICIP.2013.6738867
   Temlyakov A, 2010, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2010.5539912
   García-Ordás MT, 2013, LECT NOTES COMPUT SC, V8199, P141, DOI 10.1007/978-3-642-41062-8_14
   Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294
   Vonikakis V, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/7/074024
   Wang B, 2014, IEEE T IMAGE PROCESS, V23, P4101, DOI 10.1109/TIP.2014.2343457
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Wang ZZ, 2010, IEEE SIGNAL PROC LET, V17, P803, DOI 10.1109/LSP.2010.2057506
   Wei H, 2017, J VIS COMMUN IMAGE R, V48, P292, DOI 10.1016/j.jvcir.2017.07.003
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Yang CZ, 2023, IEEE ACM T COMPUT BI, V20, P39, DOI 10.1109/TCBB.2022.3148463
   Yang CZ, 2021, APPL MATH COMPUT, V403, DOI 10.1016/j.amc.2021.126096
   Yang CZ, 2019, SIGNAL PROCESS-IMAGE, V71, P110, DOI 10.1016/j.image.2018.11.004
   Yang CZ, 2018, NEUROCOMPUTING, V275, P1160, DOI 10.1016/j.neucom.2017.09.067
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Yang L., 2021, Image Commun., V96, DOI [10.1016/j.image.2021.116297, DOI 10.1016/J.IMAGE.2021.116297]
   Yang LJ, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103240
   Zhang CY, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13030499
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2003, J VIS COMMUN IMAGE R, V14, P41, DOI 10.1016/S1047-3203(03)00003-8
   Zhang N, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116229
   Zheng Y, 2019, IEEE T IMAGE PROCESS, V28, P5366, DOI 10.1109/TIP.2019.2919195
NR 77
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104005
DI 10.1016/j.jvcir.2023.104005
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DT0I9
UT WOS:001134203100001
DA 2024-07-18
ER

PT J
AU Ke, JW
   Watras, AJ
   Kim, JJ
   Liu, HW
   Jiang, HR
   Hu, YH
AF Ke, Jianwei
   Watras, Alex J.
   Kim, Jae-Jun
   Liu, Hewei
   Jiang, Hongrui
   Hu, Yu Hen
TI Efficient online real-time video stabilization with a novel least
   squares formulation and parallel AC-RANSAC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Online real-time video stabilization; Least squares smoothing; Parallel
   AC-RANSAC
ID KALMAN; IMAGES
AB A novel online real-time video stabilization algorithm (LSstab) that suppresses unwanted motion jitters based on cinematography principles is presented. LSstab features a parallel realization of the a-contrario RANSAC (AC-RANSAC) algorithm to estimate the inter-frame camera motion parameters. A novel least squares based smoothing cost function is then proposed to mitigate undesirable camera jitters according to cinematography principles. A recursive least square solver is derived to minimize the smoothing cost function with a linear computation complexity. LSstab is evaluated using a suite of publicly available videos against state-of-the-art video stabilization methods. Results show that LSstab achieves comparable or better performance, which attains real-time processing speed when a GPU is used.
C1 [Ke, Jianwei; Watras, Alex J.; Kim, Jae-Jun; Liu, Hewei; Jiang, Hongrui; Hu, Yu Hen] UW Madison, Dept Elect & Comp Engn, 1415 Engn Dr, Madison, WI 53706 USA.
C3 University of Wisconsin System; University of Wisconsin Madison
RP Ke, JW (corresponding author), UW Madison, Dept Elect & Comp Engn, 1415 Engn Dr, Madison, WI 53706 USA.
EM jke9@wisc.edu
RI Ke, Jianwei/KIL-2445-2024
OI HU, YU HEN/0000-0003-3427-0677; Watras, Alex/0000-0003-0861-1781; Ke,
   Jianwei/0000-0002-4086-9312; Kim, Jae-Jun/0000-0003-0722-3402
FU National Institute of Biomedical Imaging and Bioengineering (NIBIB) of
   the US National Institutes of Health (NIH) [R01EB019460]
FX <B>Acknowledgments</B> This work was supported by the National Institute
   of Biomedical Imaging and Bioengineering (NIBIB) of the US National
   Institutes of Health (NIH) under award number R01EB019460.
CR Aguilar WG, 2016, NEURAL PROCESS LETT, V43, P459, DOI 10.1007/s11063-015-9439-0
   [Anonymous], 2007, Optimizing parallel reductions in CUDA
   Battiato S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P825, DOI 10.1109/ICIAP.2007.4362878
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bell S, 2014, LECT NOTES COMPUT SC, V8692, P294, DOI 10.1007/978-3-319-10593-2_20
   Bouttefroy PLM, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/839412
   Chang HC, 2006, J VIS COMMUN IMAGE R, V17, P659, DOI 10.1016/j.jvcir.2005.10.004
   Chen JG, 2022, IEEE SENSOR, DOI 10.1109/SENSORS52175.2022.9967079
   Choi J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3363550
   Davis Timothy A., 2006, arXiv, DOI [DOI 10.1137/1.9780898717938, 10.1137/1.9780898718881, DOI 10.1137/1.9780898718881]
   Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236
   Dong J, 2017, IEEE T CIRC SYST VID, V27, P716, DOI 10.1109/TCSVT.2016.2589860
   Ertürk S, 2002, REAL-TIME IMAGING, V8, P317, DOI 10.1006/rtim.2001.0278
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goldstein A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231824
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Guilluy W., 2021, Image Commun., V90
   Ke JW, 2022, J SIGNAL PROCESS SYS, V94, P329, DOI 10.1007/s11265-021-01729-0
   Ke JW, 2020, INT CONF ACOUST SPEE, P1638, DOI [10.1109/ICASSP40776.2020.9054391, 10.1109/icassp40776.2020.9054391]
   Kejriwal L, 2016, PROCEDIA COMPUT SCI, V93, P359, DOI 10.1016/j.procs.2016.07.221
   Litvin A, 2003, PROC SPIE, V5022, P663, DOI 10.1117/12.476436
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu SC, 2016, LECT NOTES COMPUT SC, V9910, P800, DOI 10.1007/978-3-319-46466-4_48
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Liu SC, 2012, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2012.6247662
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54
   Moisan L, 2012, IMAGE PROCESS ON LIN, V2, P56, DOI 10.5201/ipol.2012.mmm-oh
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Noble FK, 2016, I C MECH MACH VIS PR, P179
   NVIDIA, 2020, Programming guide:: CUDA toolkit documentation
   Ovrén H, 2015, IEEE INT CONF ROBOT, P2090, DOI 10.1109/ICRA.2015.7139474
   Ratakonda K., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P69, DOI 10.1109/ISCAS.1998.698760
   Sánchez J, 2017, IMAGE PROCESS ON LIN, V7, P309, DOI 10.5201/ipol.2017.209
   Shi ZM, 2022, IEEE WINT CONF APPL, P865, DOI 10.1109/WACV51458.2022.00094
   Smith BM, 2009, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2009.5459270
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   Wang M, 2019, IEEE T IMAGE PROCESS, V28, P2283, DOI 10.1109/TIP.2018.2884280
   Wang Y., 2011, Proceedings of the 12th IAPR Conference on Machine Vision Applications, MVA 2011, P336
   Watras AJ, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11050488
   Xu SZ, 2018, COMPUT GRAPH FORUM, V37, P267, DOI 10.1111/cgf.13566
   Yu Jiyang, 2020, P IEEE CVF C COMP VI
   Zhang Q., 2000, IFAC P, V33, P763, DOI DOI 10.1016/S1474-6670(17)39844-0
   Zhao MD, 2020, IEEE T IMAGE PROCESS, V29, P3582, DOI 10.1109/TIP.2019.2963380
NR 46
TC 0
Z9 0
U1 9
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103922
DI 10.1016/j.jvcir.2023.103922
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S8LW5
UT WOS:001073638700001
PM 37719135
DA 2024-07-18
ER

PT J
AU Fang, HX
   Long, YW
   Hu, XY
   Ou, YT
   Huang, YJ
   Hu, HJ
AF Fang, Hangxiang
   Long, Yongwen
   Hu, Xinyi
   Ou, Yangtao
   Huang, Yuanjia
   Hu, Haoji
TI Dual cross knowledge distillation for image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super resolution; Knowledge distillation; Convolutional neural networks
AB The huge computational requirements and memory footprint limit the practical deployment of super resolution (SR) models. Knowledge distillation (KD) allows student networks to obtain performance improvement by learning from over-parameterized teacher networks. Previous work has attempted to solve SR distillation problem by using feature-based distillation, which ignores the supervisory role of the teacher module itself. In this paper, we introduce a cross knowledge distillation framework to compress and accelerate SR models. Specifically, we propose to obtain supervision by cascading the student into the teacher network for directly utilizing teacher's well-trained parameters. This not only reduces the difficulty of optimization for students but also avoids designing alignment with obscure feature textures between two networks. To the best of our knowledge, we are the first work to explore the cross distillation paradigm on the SR tasks. Experiments on typical SR networks have shown the superiority of our method in generated images, PSNR and SSIM.
C1 [Fang, Hangxiang; Hu, Xinyi; Hu, Haoji] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
   [Long, Yongwen; Ou, Yangtao; Huang, Yuanjia] Foshan Shunde Midea Elect Heating Appliances Mfg C, Foshan, Peoples R China.
   [Hu, Haoji] Zhejiang Prov Key Lab Informat Proc Commun & Netwo, Hangzhou 310007, Peoples R China.
C3 Zhejiang University
RP Hu, HJ (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.; Hu, HJ (corresponding author), Zhejiang Prov Key Lab Informat Proc Commun & Netwo, Hangzhou 310007, Peoples R China.
EM fhx@zju.edu.cn; longyw@midea.com; xinyih@zju.edu.cn;
   ouyangtao4@midea.com; yuanjia.huang@midea.com; haoji_hu@zju.edu.cn
OI Hu, Haoji/0000-0001-6048-6549
FU National Natural Science Foundation of China [U21B2004]; Zhejiang
   Provincial key RD Program of China [2021C01119]; Core Technology
   Research Project of Foshan, Guangdong Province, China [1920001000498]
FX This work is supported by the National Natural Science Foundation of
   China (U21B2004) , the Zhejiang Provincial key RD Program of China
   (2021C01119) , and the Core Technology Research Project of Foshan,
   Guangdong Province, China (1920001000498) .
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bai HL, 2020, AAAI CONF ARTIF INTE, V34, P3203
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen GB, 2017, ADV NEUR IN, V30
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Freeman William T., 1999, ICCV
   Gao QQ, 2019, LECT NOTES COMPUT SC, V11362, P527, DOI 10.1007/978-3-030-20890-5_34
   Gu JJ, 2021, PROC CVPR IEEE, P9195, DOI 10.1109/CVPR46437.2021.00908
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZB, 2020, IEEE IMAGE PROC, P518, DOI [10.1109/icip40778.2020.9190917, 10.1109/ICIP40778.2020.9190917]
   Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201
   Heo B, 2019, AAAI CONF ARTIF INTE, P3779
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang Q, 2021, IEEE IMAGE PROC, P1814, DOI 10.1109/ICIP42928.2021.9506517
   Huang ZH, 2017, Arxiv, DOI arXiv:1707.01219
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jie Liu, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P41, DOI 10.1007/978-3-030-67070-2_2
   Jin Qing, 2021, P IEEE C COMP VIS PA, P13600
   Jing YC, 2022, LECT NOTES COMPUT SC, V13667, P111, DOI 10.1007/978-3-031-20071-7_7
   Jing YC, 2021, PROC CVPR IEEE, P7768, DOI 10.1109/CVPR46437.2021.00768
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kornblith S, 2019, PR MACH LEARN RES, V97
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu S., 2022, arXiv
   Liu SH, 2022, LECT NOTES COMPUT SC, V13676, P72, DOI 10.1007/978-3-031-19787-1_5
   Lu T, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131588
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Murugesan Balamurali, 2020, MED IMAGING DEEP LEA, P515
   Nie Y, 2021, Arxiv, DOI arXiv:2101.08525
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Peng BY, 2019, IEEE I CONF COMP VIS, P5006, DOI 10.1109/ICCV.2019.00511
   Romero A, 2015, Arxiv, DOI arXiv:1412.6550
   Shen CC, 2020, Arxiv, DOI arXiv:2012.04915
   Siang Chen, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P119, DOI 10.1007/978-3-030-67070-2_7
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   Wang H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2769
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang Y., 2021, arXiv
   Wonkyung Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P465, DOI 10.1007/978-3-030-58586-0_28
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu ZQJ, 2024, Arxiv, DOI arXiv:1901.06523
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang XY, 2022, Arxiv, DOI arXiv:2210.17409
   Yang ZD, 2022, Arxiv, DOI arXiv:2205.01529
   Ye JW, 2022, LECT NOTES COMPUT SC, V13671, P87, DOI 10.1007/978-3-031-20083-0_6
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 67
TC 1
Z9 1
U1 4
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103858
DI 10.1016/j.jvcir.2023.103858
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7SC0
UT WOS:001011572500001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Yin, XH
   Yue, GH
   Zheng, Z
   Jiang, JH
   He, QG
   Li, XZ
AF Liu, Yun
   Yin, Xiaohua
   Yue, Guanghui
   Zheng, Zhi
   Jiang, Jinhe
   He, Quangui
   Li, Xinzhuang
TI Blind omnidirectional image quality assessment with representative
   features and viewport oriented statistical features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Omnidirectional images; Quality assessment; Cross-channel color feature;
   Natural scene statistics
AB With the development of information technologies, various types of streaming images are generated, such as videos, graphics, Virtual Reality (VR)/omnidirectional images (OIs), etc. Among them, the OIs usually have a broader view and a higher resolution, which provides human an immersive visual experience in a head -mounted display. However, the current image quality assessment works cannot achieve good performance without considering representative human visual features and visual viewing characteristics of OIs, which limited OIs' further development. Motivated by the above problem, this work proposes a blind omnidirectional image quality assessment (BOIQA) model based on representative features and viewport oriented statistical features. Specifically, we apply the local binary pattern operator to encoder the cross-channel color information, and apply the weighted LBP to extract the structural features. Then the local natural scene statistics (NSS) features are extracted by using the viewport sampling to boost the performance. Finally, we apply support vector regression to predict the OIs' quality score, and experimental results on CVIQD2018 and OIQA2018 Databases prove that the proposed model achieves better performance than state-of-the-art OIQA models.
C1 [Liu, Yun; Yin, Xiaohua; He, Quangui] Liaoning Univ, Shenyang, Peoples R China.
   [Yue, Guanghui] Shenzhen Univ, Shenzhen, Peoples R China.
   [Zheng, Zhi] Beijing Jiaotong Univ, Beijing, Peoples R China.
   [Jiang, Jinhe] China Tower Corp Ltd, Liaoning Branch, Shenyang, Peoples R China.
   [Li, Xinzhuang] JD Logist, Dept Technol & Data Intelligence, Beijing, Peoples R China.
C3 Liaoning University; Shenzhen University; Beijing Jiaotong University
RP Yin, XH (corresponding author), Liaoning Univ, Shenyang, Peoples R China.; Yue, GH (corresponding author), Shenzhen Univ, Shenzhen, Peoples R China.; Jiang, JH (corresponding author), China Tower Corp Ltd, Liaoning Branch, Shenyang, Peoples R China.
EM yunliu@tju.edu.cn; yinxhhhh@163.com; yueguanghui@szu.edu.cn;
   jiangjh@chinatowercom.cn
FU National Natural Science Founda-tion of China [61901205, 62001302];
   Guangdong Basic and Applied Basic Research Foundation [2019A151511-1205]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under 61901205 and 62001302, and the Guangdong
   Basic and Applied Basic Research Foundation under Grant
   2019A151511-1205. The authors would like to thank Prof. Huiyu Duan for
   providing the OIQA database and Prof. Wei Sun for providing the
   CVIQD2018 database.
CR Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Fang YM, 2021, IEEE T MULTIMEDIA, V23, P955, DOI 10.1109/TMM.2020.2991528
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Jiang H, 2022, IEEE T CIRC SYST VID, V32, P4211, DOI 10.1109/TCSVT.2021.3128014
   Jiang H, 2021, IEEE T IMAGE PROCESS, V30, P2364, DOI 10.1109/TIP.2021.3052073
   Kim HG, 2020, IEEE T CIRC SYST VID, V30, P917, DOI 10.1109/TCSVT.2019.2898732
   Kusuno Y, 2019, IEEE/SICE I S SYS IN, P325, DOI [10.1109/SII.2019.8700393, 10.1109/sii.2019.8700393]
   Li C, 2019, PROC CVPR IEEE, P10169, DOI 10.1109/CVPR.2019.01042
   Ling SY, 2018, IEEE INT CON MULTI
   Liu LX, 2018, NEUROCOMPUTING, V275, P1823, DOI 10.1016/j.neucom.2017.10.017
   Liu Y.X., 2021, ACM INT C MULT ACMMM
   Liu Y, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3124057
   Liu Y, 2020, NEUROCOMPUTING, V405, P126, DOI 10.1016/j.neucom.2020.04.049
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pelli DG, 2008, NAT NEUROSCI, V11, P1129, DOI 10.1038/nn.2187
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shi ZF, 2018, SIGNAL PROCESS, V145, P99, DOI 10.1016/j.sigpro.2017.11.015
   Sui XJ, 2022, IEEE T VIS COMPUT GR, V28, P3022, DOI 10.1109/TVCG.2021.3050888
   Sun W, 2018, IEEE INT WORKSH MULT
   Sun W, 2019, IEEE T SYST MAN CY-S, V49, P2201, DOI 10.1109/TSMC.2018.2870642
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie XM, 2017, NEUROCOMPUTING, V266, P176, DOI 10.1016/j.neucom.2017.05.034
   Xu JH, 2021, IEEE T CIRC SYST VID, V31, P1724, DOI 10.1109/TCSVT.2020.3015186
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Jiang XH, 2020, NEUROCOMPUTING, V386, P30, DOI 10.1016/j.neucom.2019.12.027
   Yang W., 2021, ACM INT C MULT ACMMM
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zheng XL, 2020, IEEE ACCESS, V8, P31647, DOI 10.1109/ACCESS.2020.2972158
   Zhou WZ, 2019, INT J POLYM SCI, V2019, DOI 10.1155/2019/9209210
   Zhou Y, 2022, IEEE T CIRC SYST VID, V32, P1767, DOI 10.1109/TCSVT.2021.3081162
   Zhou Y, 2019, IEEE T IMAGE PROCESS, V28, P4566, DOI 10.1109/TIP.2019.2912463
   Zhou YF, 2018, INT CONF SIGN PROCES, P54, DOI 10.1109/ICSP.2018.8652269
NR 37
TC 2
Z9 2
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103770
DI 10.1016/j.jvcir.2023.103770
EA FEB 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9W2OI
UT WOS:000948918500001
DA 2024-07-18
ER

PT J
AU Xu, G
   Zhou, WJ
   Qian, XH
   Ye, L
   Lei, JS
   Yu, L
AF Xu, Gao
   Zhou, Wujie
   Qian, Xiaohong
   Ye, Lv
   Lei, Jingsheng
   Yu, Lu
TI CCFNet: Cross-Complementary fusion network for RGB-D scene parsing of
   clothing images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D; Cross-complementary fusion; Cross-feature enhancement module;
   Scene parsing; Cross-modal fusion module
ID SEMANTIC SEGMENTATION
AB Schemes to complement context relationships by cross-scale feature fusion have appeared in many RGB-D scene parsing algorithms; however, most of these works conduct multi-scale information interaction after multi-modal feature fusion, which ignores the information loss of the two modes in the original coding. Therefore, a cross -complementary fusion network (CCFNet) is designed in this paper to calibrate the multi-modal information before feature fusion, so as to improve the feature quality of each mode and the information complementarity ability of RGB and the depth map. First, we divided the features into low, middle, and high levels, among which the low-level features contain the global details of the image and the main learning features include texture, edge, and other features. The middle layer features contain not only some global detail features but also some local semantic features. Additionally, the high-level features contain rich local semantic features. Then, the feature information lost in the coding process of low and middle level features is supplemented and extracted through the designed cross feature enhancement module, and the high-level features are extracted through the feature enhancement module. In addition, the cross-modal fusion module is designed to integrate multi-modal features of different levels. The experimental results verify that the proposed CCFNet achieves excellent per-formance on the RGB-D scene parsing dataset containing clothing images, and the generalization ability of the model is verified by the dataset NYU Depth V2.
C1 [Xu, Gao; Zhou, Wujie; Qian, Xiaohong; Ye, Lv; Lei, Jingsheng] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Peoples R China.
   [Zhou, Wujie; Yu, Lu] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.
C3 Zhejiang University of Science & Technology; Zhejiang University
RP Zhou, WJ (corresponding author), Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Peoples R China.; Zhou, WJ (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.
EM wujiezhou@163.com
FU National Natural Science Foundation of China; Zhejiang Provincial
   Nat-ural Science Foundation of China; Zhejiang Key R D Program; 
   [61502429];  [61672337];  [61972357];  [LY18F020012];  [LY17F020011]; 
   [2019C03135]
FX Acknowledgements This work was supported by National Natural Science
   Foundation of China (61502429, 61672337, 61972357) ; the Zhejiang
   Provincial Nat-ural Science Foundation of China (LY18F020012,
   LY17F020011) ; and Zhejiang Key R & D Program (2019C03135) .
CR Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fayyaz M, 2017, LECT NOTES COMPUT SC, V10116, P493, DOI 10.1007/978-3-319-54407-6_33
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gong TT, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105510
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang NI, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108359
   Huang NAC, 2022, IEEE T MULTIMEDIA, V24, P1651, DOI 10.1109/TMM.2021.3069297
   Huang NAC, 2021, IEEE T MULTIMEDIA, V23, P2428, DOI 10.1109/TMM.2020.3011327
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang JD, 2018, Arxiv, DOI arXiv:1806.01054
   Joukovsky B, 2020, ELECTRON LETT, V56, P432, DOI 10.1049/el.2019.4150
   Li G, 2019, P BRIT MACHINE VISIO, P1
   Li XL, 2022, IEEE T CYBERNETICS, V52, P9352, DOI 10.1109/TCYB.2021.3050558
   Lin D, 2020, IEEE T CYBERNETICS, V50, P1120, DOI 10.1109/TCYB.2018.2885062
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Luo WJ, 2017, Arxiv, DOI [arXiv:1701.04128, DOI 10.48550/ARXIV.1701.04128]
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O., 2015, Int. J. Comput. Vis., V115, P211, DOI DOI 10.1007/S11263-015-0816-Y
   Seichter D, 2021, IEEE INT CONF ROBOT, P13525, DOI 10.1109/ICRA48506.2021.9561675
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song MK, 2022, IEEE T IMAGE PROCESS, V31, P6124, DOI 10.1109/TIP.2022.3205747
   Sun P, 2021, PROC CVPR IEEE, P1407, DOI 10.1109/CVPR46437.2021.00146
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XH, 2021, IEEE T IMAGE PROCESS, V30, P458, DOI 10.1109/TIP.2020.3037470
   Wang Y., 2022, P IEEE CVF C COMP VI, P12186
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J., 2023, Digit. Signal Process., V133
   Wu Y, 2021, IEEE ACCESS, V9, P47230, DOI 10.1109/ACCESS.2021.3068293
   Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33
   Xiong ZT, 2020, PROC CVPR IEEE, P3991, DOI 10.1109/CVPR42600.2020.00405
   Yan HT, 2023, Arxiv, DOI arXiv:2201.01615
   Yan Weiqing, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P3403, DOI 10.1145/3503161.3548144
   Yan WQ, 2020, INFORM SCIENCES, V511, P58, DOI 10.1016/j.ins.2019.09.051
   Yang EQ, 2022, IEEE SIGNAL PROC LET, V29, P2567, DOI 10.1109/LSP.2022.3229594
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yao CL, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104351
   Yuan JZ, 2019, IEEE ACCESS, V7, P169350, DOI 10.1109/ACCESS.2019.2955101
   Yue YC, 2021, IEEE SIGNAL PROC LET, V28, P1115, DOI 10.1109/LSP.2021.3084855
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhou F, 2022, NEUROCOMPUTING, V492, P464, DOI 10.1016/j.neucom.2022.04.025
   Zhou WJ, 2023, IEEE T COGN DEV SYST, V15, P476, DOI 10.1109/TCDS.2021.3051010
   Zhou WJ, 2023, IEEE T INTELL VEHICL, V8, P48, DOI 10.1109/TIV.2022.3164899
   Zhou WJ, 2022, IEEE T INTELL TRANSP, V23, P24540, DOI 10.1109/TITS.2022.3203385
   Zhou WJ, 2022, IEEE J-STSP, V16, P677, DOI 10.1109/JSTSP.2022.3174338
   Zhou WJ, 2022, IEEE J-STSP, V16, P666, DOI 10.1109/JSTSP.2022.3159032
   Zhou WJ, 2023, IEEE T MULTIMEDIA, V25, P3483, DOI 10.1109/TMM.2022.3161852
   Zhou WJ, 2022, NEUROCOMPUTING, V490, P347, DOI 10.1016/j.neucom.2021.11.100
   Zhou WJ, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3337-9
   Zhou WJ, 2021, IEEE T IMAGE PROCESS, V30, P7790, DOI 10.1109/TIP.2021.3109518
   Zhou WJ, 2022, IEEE T MULTIMEDIA, V24, P2526, DOI 10.1109/TMM.2021.3086618
   Zhou WJ, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3105484
   Zhou WJ, 2022, IEEE T CIRC SYST VID, V32, P1224, DOI 10.1109/TCSVT.2021.3077058
   Zhou WJ, 2022, IEEE T MULTIMEDIA, V24, P2192, DOI 10.1109/TMM.2021.3077767
   Zhou WJ, 2021, IEEE T MULTIMEDIA, V23, P3388, DOI 10.1109/TMM.2020.3025166
   Zhou WJ, 2021, IEEE INTELL SYST, V36, P73, DOI 10.1109/MIS.2020.2999462
   Zhou WJ, 2021, IEEE T SYST MAN CY-S, V51, P3641, DOI 10.1109/TSMC.2019.2957386
   Zhou WJ, 2018, IEEE T IMAGE PROCESS, V27, P2086, DOI 10.1109/TIP.2018.2794207
NR 69
TC 15
Z9 15
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103727
DI 10.1016/j.jvcir.2022.103727
EA DEC 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7S6DL
UT WOS:000910842000001
DA 2024-07-18
ER

PT J
AU Zhang, H
   Li, Y
   Yang, HQ
   He, B
   Zhang, Y
AF Zhang, Hong
   Li, Yang
   Yang, Hanqing
   He, Bin
   Zhang, Yu
TI Isomorphic model-based initialization for convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural networks; Weight initialization; Isomorphic model;
   Structural weight transformation
AB Modern deep convolutional neural networks(CNNs) are often designed to be scalable, leading to the model family concept. A model family is a large (possibly infinite) collection of related neural network architectures. The isomorphism of a model family refers to the fact that the models within it share the same high-level structure. Meanwhile, the models within the model family are called isomorphic models for each other. Existing weight initialization methods for CNNs use random initialization or data-driven initialization. Even though these methods can perform satisfactory initialization, the isomorphism of model families is rarely explored. This work proposes an isomorphic model-based initialization method (IM Init) for CNNs. It can initialize any network with another well-trained isomorphic model in the same model family. We first formulate the widely used general network structure of CNNs. Then a structural weight transformation is presented to transform the weight between two isomorphic models. Finally, we apply our IM Init to the model down-sampling and up-sampling scenarios and confirm its effectiveness in improving accuracy and convergence speed through experiments on various image classification datasets. In the model down-sampling scenario, IM Init initializes the smaller target model with a larger well-trained source model. It improves the accuracy of RegNet200MF by 1.59% on the CIFAR-100 dataset and 1.9% on the CUB200 dataset. Inversely, IM Init initializes the larger target model with a smaller well-trained source model in the model up-sampling scenario. It significantly speeds up the convergence of RegNet600MF and improves the accuracy by 30.10% under short training schedules. Code will be available.
C1 [Zhang, Hong; Li, Yang; Yang, Hanqing; He, Bin; Zhang, Yu] Zhejiang Univ, Coll Control Sci & Engn, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhang, Y (corresponding author), Zhejiang Univ, Coll Control Sci & Engn, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.
EM hongzhang99@zju.edu.cn; yanglivision@zju.edu; yanglivision@zju.edu.cn;
   binhe@zju.edu.cn; hongzhang99@zju.edu.cn
OI Zhang, Yu/0000-0002-0043-4904; Zhang, Hong/0000-0003-4004-617X
FU NSFC [62088101]; National Key Research and Development Program of China
   [2021ZD0201400]; Project of State Key Laboratory of Industrial Control
   Technology, Zhejiang University, China [ICT2021A10]; Open Research
   Project of the State Key Laboratory of Industrial Control Technology,
   Zhejiang University, China [ICT2022B04]
FX This work was supported by the NSFC 62088101 Autonomous Intelligent
   Unmanned Systems, the National Key Research and Development Program of
   China under Grant 2021ZD0201400, the Project of State Key Laboratory of
   Industrial Control Technology, Zhejiang University, China (No.
   ICT2021A10) , the the Open Research Project of the State Key Laboratory
   of Industrial Control Technology, Zhejiang University, China (No.
   ICT2022B04) .
CR Alberti M., 2017, P 4 INT WORKSH HIST, P95
   [Anonymous], 2017, IN P IEEE C COMPUTER
   [Anonymous], 2019, ICLR
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, INT C LEARN REPR
   Ba LJ, 2014, ADV NEUR IN, V27
   Balduzzi D, 2017, PR MACH LEARN RES, V70
   Cachi P G., 2020, Information Processing and Management of Uncertainty in Knowledge-Based Systems, P773, DOI [DOI 10.1007/978-3-030-50153-2_57, 10.1007/978-3-030-50153-2_57]
   Deng J., 2009, IEEE C COMP VIS PATT
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gan YH, 2015, Arxiv, DOI arXiv:1505.03703
   Ghazi MM, 2019, LECT NOTES COMPUT SC, V11953, P275, DOI 10.1007/978-3-030-36708-4_23
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hasegawa R, 2016, INT C PATT RECOG, P1601, DOI 10.1109/ICPR.2016.7899865
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Hinton G., 2015, COMPUT SCI, V2
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Krizhevsky A., 2009, Tech. Rep.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S., 2017, P 2017 C EMPIRICAL M, P1884, DOI [DOI 10.18653/V1/D17-1201, 10.18653/v1/D17-1201]
   Liu Z., 2022, P IEEECVF C COMPUTER
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Masden M, 2020, Arxiv, DOI arXiv:2007.12782
   Murru N, 2016, NEUROCOMPUTING, V193, P92, DOI 10.1016/j.neucom.2016.01.063
   Peng BY, 2019, IEEE I CONF COMP VIS, P5006, DOI 10.1109/ICCV.2019.00511
   Qiao JF, 2016, NEUROCOMPUTING, V207, P676, DOI 10.1016/j.neucom.2016.05.054
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Radosavovic I, 2019, IEEE I CONF COMP VIS, P1882, DOI 10.1109/ICCV.2019.00197
   Romero A., 2015, ICLR, P1, DOI DOI 10.48550/ARXIV.1412.6550
   Simonyan K., 2014, CORR
   Sun WC, 2018, NEUROCOMPUTING, V278, P34, DOI 10.1016/j.neucom.2017.05.103
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang JL, 2017, COMPUT ELECTRON AGR, V135, P63, DOI 10.1016/j.compag.2017.01.001
   Vaswani A, 2017, ADV NEUR IN, V30
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang HQ, 2022, NEUROCOMPUTING, V467, P348, DOI 10.1016/j.neucom.2021.09.061
   Yang HQ, 2021, NEUROCOMPUTING, V455, P390, DOI 10.1016/j.neucom.2021.04.116
   Yang HF, 2021, INVERSE PROBL IMAG, V15, P147, DOI 10.3934/ipi.2020045
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zhu J., 2021, P IEEECVF C COMPUTER, P9260
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 47
TC 2
Z9 2
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103677
DI 10.1016/j.jvcir.2022.103677
EA NOV 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600002
DA 2024-07-18
ER

PT J
AU Aulí-Llinàs, F
   de Cea-Dominguez, C
   Hernández-Cabronero, M
AF Auli-Llinas, Francesc
   de Cea-Dominguez, Carlos
   Hernandez-Cabronero, Miguel
TI Accelerating BPC-PaCo through Visually Lossless Techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High-throughput image coding; Visually lossless coding; JPEG2000
ID HIGH-SPEED; LOW-COST; IMAGE; ARCHITECTURE; EFFICIENT; IMPLEMENTATION;
   GPU
AB Fast image codecs are a current need in applications that deal with large amounts of images. Graphics Processing Units (GPUs) are suitable processors to speed up most kinds of algorithms, especially when they allow fine-grain parallelism. Bitplane Coding with Parallel Coefficient processing (BPC-PaCo) is a recently proposed algorithm for the core stage of wavelet-based image codecs tailored for the highly parallel architectures of GPUs. This algorithm provides complexity scalability to allow faster execution at the expense of coding efficiency. Its main drawback is that the speedup and loss in image quality is controlled only roughly, resulting in visible distortion at low and medium rates. This paper addresses this issue by integrating techniques of visually lossless coding into BPC-PaCo. The resulting method minimizes the visual distortion introduced in the compressed file, obtaining higher-quality images to a human observer. Experimental results also indicate 12% speedups with respect to BPC-PaCo.
C1 [Auli-Llinas, Francesc; de Cea-Dominguez, Carlos; Hernandez-Cabronero, Miguel] Univ Autonoma Barcelona, Dept Informat & Commun Engn, Bellaterra 08193, Spain.
C3 Autonomous University of Barcelona
RP Aulí-Llinàs, F (corresponding author), Univ Autonoma Barcelona, Dept Informat & Commun Engn, Bellaterra 08193, Spain.
EM francesc.auli@uab.cat
RI Auli-Llinas, Francesc/K-4395-2013
OI Auli-Llinas, Francesc/0000-0002-3208-9957
FU Spanish Ministry of Science, Innovation and Universities (MICIU);
   European Regional Development Fund (FEDER) [RTI2018-095287-B-I00,
   PID2021-125258OB-I00]; Catalan Government [2018-BP-00008, 2017SGR-463];
   Horizon 2020 under the Marie Sklodowska-Curie grant [801370]
FX This work has been partially supported by the Spanish Ministry of
   Science, Innovation and Universities (MICIU) and by the European
   Regional Development Fund (FEDER) under Grants RTI2018-095287-B-I00 and
   PID2021-125258OB-I00, by the Catalan Government under Grants
   2018-BP-00008 and 2017SGR-463, and by the Horizon 2020 under the Marie
   Sklodowska-Curie grant agreement #801370.
CR Al-Mulla Y, 2022, IEEE ACCESS, V10, P86782, DOI 10.1109/ACCESS.2022.3198942
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 2019, INFORM TECHNOLOGY JP
   [Anonymous], 2000, INFORM TECHNOLOGY JP
   Auli-Llinas F., 2022, BOI CODEC
   Aulí-Llinàs F, 2016, IEEE T IMAGE PROCESS, V25, P209, DOI 10.1109/TIP.2015.2484069
   Aulí-Llinàs F, 2015, IEEE T IMAGE PROCESS, V24, P57, DOI 10.1109/TIP.2014.2370937
   Aulí-Llinàs F, 2012, IEEE T IMAGE PROCESS, V21, P1920, DOI 10.1109/TIP.2011.2176953
   Aulí-Llinàs F, 2011, IEEE T IMAGE PROCESS, V20, P2153, DOI 10.1109/TIP.2011.2114892
   Chang H, 2022, IEEE ACM T NETWORK, V30, P2343, DOI 10.1109/TNET.2022.3171467
   DALY S, 1992, P SOC PHOTO-OPT INS, V1666, P2, DOI 10.1117/12.135952
   de Cea-Dominguez C., 2021, IMAGE COMMUN, V99, P1
   de Cea-Dominguez C, 2020, IEEE SIGNAL PROC LET, V27, P840, DOI 10.1109/LSP.2020.2990307
   De Cea-Dominguez C, 2020, IEEE ACCESS, V8, P68474, DOI 10.1109/ACCESS.2020.2985859
   Descampe A, 2006, IEEE T CIRC SYST VID, V16, P1397, DOI 10.1109/TCSVT.2006.884573
   Díaz M, 2019, IEEE J-STARS, V12, P2803, DOI 10.1109/JSTARS.2019.2917088
   Dyer M, 2006, IEEE T CIRCUITS-I, V53, P1203, DOI 10.1109/TCSI.2006.875171
   Dyer M, 2009, IEEE T CIRC SYST VID, V19, P215, DOI 10.1109/TCSVT.2008.2009245
   Enfedaque P, 2017, IEEE T PARALL DISTR, V28, P2272, DOI 10.1109/TPDS.2017.2657506
   Enfedaque P, 2015, IEEE T PARALL DISTR, V26, P3394, DOI 10.1109/TPDS.2014.2384047
   Fang HC, 2005, IEEE T CIRC SYST VID, V15, P1086, DOI 10.1109/TCSVT.2005.852618
   Gupta AK, 2006, IEEE T CIRC SYST VID, V16, P843, DOI 10.1109/TCSVT.2006.877400
   Jiménez-Rodríguez L, 2014, IEEE SIGNAL PROC LET, V21, P35, DOI 10.1109/LSP.2013.2290317
   Jin Y, 2012, IEEE T CIRC SYST VID, V22, P1064, DOI 10.1109/TCSVT.2012.2189793
   Kim S, 2016, IEEE T MULTIMEDIA, V18, P392, DOI 10.1109/TMM.2015.2514196
   Lee SH, 2021, IEEE ACCESS, V9, P22516, DOI 10.1109/ACCESS.2021.3056115
   Li YZ, 2019, IEEE T CIRC SYST VID, V29, P1179, DOI 10.1109/TCSVT.2018.2825022
   Li YJ, 2006, IEEE T CIRC SYST VID, V16, P1153, DOI 10.1109/TCSVT.2006.881864
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Mei KZ, 2007, IEEE T CIRC SYST VID, V17, P1065, DOI 10.1109/TCSVT.2007.903555
   Naman AA, 2019, IEEE IMAGE PROC, P1084, DOI 10.1109/ICIP.2019.8803729
   Naman AT, 2020, IEEE IMAGE PROC, P1171, DOI 10.1109/ICIP40778.2020.9190899
   Nobile MS, 2017, BRIEF BIOINFORM, V18, P870, DOI 10.1093/bib/bbw058
   Oh H, 2016, INFORMATION, V7, DOI 10.3390/info7030045
   Oh H, 2013, IEEE T IMAGE PROCESS, V22, P189, DOI 10.1109/TIP.2012.2215616
   Park JW, 2020, IEEE T VLSI SYST, V28, P101, DOI 10.1109/TVLSI.2019.2936260
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Rhu M, 2010, IEEE T CIRC SYST VID, V20, P446, DOI 10.1109/TCSVT.2009.2031401
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sarawadekar K, 2011, IEEE T CIRC SYST VID, V21, P825, DOI 10.1109/TCSVT.2011.2133450
   Song XY, 2017, IET IMAGE PROCESS, V11, P80, DOI 10.1049/iet-ipr.2016.0564
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Taubman D, 2019, IEEE IMAGE PROC, P1079, DOI [10.1109/icip.2019.8803774, 10.1109/ICIP.2019.8803774]
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   WATSON AB, 1987, J OPT SOC AM A, V4, P2401, DOI 10.1364/JOSAA.4.002401
   Xie G, 2005, IEEE T CIRC SYST VID, V15, P762, DOI 10.1109/TCSVT.2005.848311
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
NR 49
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103672
DI 10.1016/j.jvcir.2022.103672
EA NOV 2022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600003
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Ji, CF
   Liu, GZ
   Zhao, D
AF Ji, Chaofeng
   Liu, Guizhong
   Zhao, Dan
TI ETS-3D: An Efficient Two-Stage Framework for Stereo 3D Object Detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D Object Detection; Deep Learning; Stereo Matching; Autonomous Driving
AB We propose an efficient two-stage framework for stereo 3D object detection, called ETS-3D. Contrary to many recent approaches that rely on depth maps predicted using time-consuming stereo matching models, our approach utilizes the well-designed features to generate high-quality 3D proposals in stage-1, without explicitly exploiting predicted depth map. Specifically, we leverage pixel-wise correlation to produce normalized cost volumes to weight the left image features, and fuse multi-scale weighted features to obtain the weighted and fused features for 3D proposal generation. To maintain fast computation, only the filtered positive 3D proposals are fed into the stage-2 sub-network for further proposal refinement and quality prediction. Furthermore, we reconstruct the 3D proposal features in stage-2 to make use of different feature representations, achieving more accurate detection results. The experimental results on the KITTI 3D object detection benchmark demonstrate that our method achieves state-of-the-art performance, and can run at more than 10 fps.
C1 [Ji, Chaofeng; Liu, Guizhong; Zhao, Dan] Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
EM liugz@xjtu.edu.cn
FU shaanxi Key Research and Development Program;  [2018ZDCXL-GY-04-03-02]
FX Funding This work was supported by shaanxi Key Research and Development
   Program under Grant 2018ZDCXL-GY-04-03-02.
CR Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen XZ, 2015, ADV NEUR IN, V28
   Chen Y., 2020, CVPR, P10337
   Deng JJ, 2021, AAAI CONF ARTIF INTE, V35, P1201
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiaming Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10545, DOI 10.1109/CVPR42600.2020.01056
   Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   Li PX, 2020, Arxiv, DOI arXiv:2001.03343
   Li PX, 2021, AAAI CONF ARTIF INTE, V35, P1930
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu YX, 2021, IEEE INT CONF ROBOT, P13018, DOI 10.1109/ICRA48506.2021.9561423
   Pon AD, 2020, IEEE INT CONF ROBOT, P8383, DOI [10.1109/ICRA40945.2020.9196660, 10.1109/icra40945.2020.9196660]
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qian R, 2020, PROC CVPR IEEE, P5880, DOI 10.1109/CVPR42600.2020.00592
   Reading C, 2021, PROC CVPR IEEE, P8551, DOI 10.1109/CVPR46437.2021.00845
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shen ZL, 2021, PROC CVPR IEEE, P13901, DOI 10.1109/CVPR46437.2021.01369
   Simonelli A, 2019, IEEE I CONF COMP VIS, P1991, DOI 10.1109/ICCV.2019.00208
   Wang Q, 2020, IEEE INT CONF ROBOT, P101, DOI [10.1109/icra40945.2020.9197031, 10.1109/ICRA40945.2020.9197031]
   Wang Y, 2021, IEEE INT C INT ROBOT, P3383, DOI 10.1109/IROS51168.2021.9635875
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Wanli Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13012, DOI 10.1109/CVPR42600.2020.01303
   Xu ZB, 2020, AAAI CONF ARTIF INTE, V34, P12557
   Yilun Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12533, DOI 10.1109/CVPR42600.2020.01255
   You Y., 2020, Large batch optimization for deep learning: Training bert in 76 minutes
   Zhang YM, 2020, AAAI CONF ARTIF INTE, V34, P12926
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 33
TC 3
Z9 3
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103634
DI 10.1016/j.jvcir.2022.103634
EA SEP 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5K4EW
UT WOS:000869681800001
DA 2024-07-18
ER

PT J
AU Arora, A
   Garg, H
   Shivani, S
AF Arora, Akanksha
   Garg, Hitendra
   Shivani, Shivendra
TI Anti-phishing technique based on dynamic image captcha using multi
   secret sharing scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Phishing; Dynamic image CPTCHA; Visual cryptography; Multi secret
   sharing
ID VISUAL CRYPTOGRAPHY
AB With the cutting-edge improvement of web, online abuses have been increasing rapidly. Phishing is the most widely recognized abuses performed by digital crooks nowadays. It is an activity to steal private data (for example, client names, passwords and Visa data) in an electronic correspondence. It is a sort of fraud with the end goal of monetary benefit and other fake exercises. It utilizes phony websites that resemble genuine ones. Phishing messages might contain links to sites that are contaminated with malware. In this paper, "an anti-phishing approach using multi secret sharing scheme" is implemented as an answer to this problem. Here, Dynamic Image CAPTCHA based verification using multi secret sharing is performed. Image CAPTCHA is divided into two pieces called shares. Multiple secret pictures are revealed by overlapping the same set of shares at different angles. In the proposed approach, shares are of different modes i.e., user's share is imprinted on a physical transparency while server's share is in digital mode. By using the proposed approach, websites and end clients can cross confirm their identity.
C1 [Arora, Akanksha; Garg, Hitendra] GLA Univ, Dept Comp Sci & Engn, Mathura, Uttar Pradesh, India.
   [Shivani, Shivendra] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 GLA University; Thapar Institute of Engineering & Technology
RP Shivani, S (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM shivendra.shivani@thapar.edu
RI Garg, Hitendra/AAV-6756-2020; Arora, Akanksha/JXM-8599-2024; Shivani,
   Shivendra/AFN-2368-2022
OI Shivani, Shivendra/0000-0002-5931-6603; , Akanksha/0000-0002-1790-014X
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Freeda M.A.A., 2013, IMAGE CAPTCHA BASED
   Hwa-Ching Hsu, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P996
   James D., 2012, 2012 INT C POW SIGN, P1
   Klein A., 2003, ARXIVPREPRINT MATH03
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   MacPherson L, 2002, Grey level visual cryptography for general access structures
   Sahare V., 2015, INT J EMERG TECHNOL, V3
   Sander T, 2002, Proceedings of the 9th ACM conference on Computer and communications security, P161, DOI [10.1145/586110, 10.1145/586110.586133, DOI 10.1145/586110.586133]
   Sarin SK, 2009, HEPATOL INT, V3, P269, DOI 10.1007/s12072-008-9106-x
   Sharma RG, 2018, INF SECUR J, V27, P241, DOI 10.1080/19393555.2019.1567872
   Shirali-Shahreza S, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P205, DOI 10.1109/ISKE.2008.4730926
   Shivani S., 2018, Handbook of Image-based Security Techniques
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Shivani S, 2018, PATTERN ANAL APPL, V21, P139, DOI 10.1007/s10044-016-0571-x
   Shivani S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2935618
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Sukal K., 2016, INT J ENG SCI COMPUT, V6, P5247
   Syiemlieh P., 2015, IOSR J COMPUT ENG IO
   Vinodhini A., 2010, INT J COMPUT INTERNE, V2, P67
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294
   Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Yan J, 2009, IEEE SECUR PRIV, V7, P22, DOI 10.1109/MSP.2009.84
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 31
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103624
DI 10.1016/j.jvcir.2022.103624
EA SEP 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2FV
UT WOS:000859982300003
DA 2024-07-18
ER

PT J
AU Hu, JB
   Wu, LF
   Li, N
AF Hu, Junbao
   Wu, Lingfeng
   Li, Na
TI High dynamic range imaging with short- and long-exposures based on
   artificial remapping using multiscale exposure fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range imaging; Exposure fusion; Artificial remapping; Image
   processing
ID RATIO
AB High dynamic range imaging (HDRI) is an excellent high-quality image acquisition technique, which can reflect real human visual characteristics from one (or several) captured low dynamic range (LDR) image. However, the input LDR image only provides partial information of the scene. Besides, in traditional HDRI methods that require multiple captured images as input, field of view errors can be induced, which will be difficult to apply it to the emerging image acquisition systems. Here, we propose a novel HDRI method that reconstructs an HDR image from only a pair of short- and long-exposure images based on artificial remapping using multi-scale exposure fusion. Firstly, we introduce a simulated exposure model called artificial remapping to synthesize a multi-exposure image sequence from the input LDR image pairs. Then, weighting maps of the sequence for fusion can be obtained according to the evaluation factors of contrast, saturation, as well as improved exposedness. Finally, we utilize the pyramid based multiscale exposure fusion framework to integrate them into an enhanced HDR image. Comparative experiments, fully implemented on some source images, have been demonstrated that better performance can be realized compared with some competing methods in qualitative and quantitative evaluation. Note that the operation of the proposed method is simple yet effective, which is easy to popularize. The method thus can be potentially applied to the emerging image acquisition systems where two images are captured simultaneously by two image sensors or by one image sensor with a pair of short- and long-exposure setting.
C1 [Hu, Junbao] Shenzhen Univ, Inst Micronano Optoelect, Shenzhen 518060, Peoples R China.
   [Wu, Lingfeng] Guangdong Univ Sci & Technol, Coll Mech & Elect Engn, Dongguan 523083, Guangdong, Peoples R China.
   [Li, Na] Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Shanxi, Peoples R China.
C3 Shenzhen University; Guangdong University of Science & Technology; Xi'an
   University of Posts & Telecommunications
RP Wu, LF (corresponding author), Guangdong Univ Sci & Technol, Coll Mech & Elect Engn, Dongguan 523083, Guangdong, Peoples R China.
EM lfwu1822@163.com
FU National Natural Science Foundation of China [41874173]; Guangdong
   University of Science and Technology Youth Fund Project
   [GKY-2021KYQNK-1]
FX Acknowledgements This work was supported by the National Natural Science
   Foundation of China (Grant No. 41874173) ; Guangdong University of
   Science and Technology Youth Fund Project (Grant No. GKY-2021KYQNK-1) .
CR Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Goto Y, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2555582
   Gu B, 2012, J VIS COMMUN IMAGE R, V23, P604, DOI 10.1016/j.jvcir.2012.02.009
   Hessel C, 2020, IEEE WINT CONF APPL, P137, DOI 10.1109/WACV45572.2020.9093643
   Hu JB, 2022, OPTIK, V260, DOI 10.1016/j.ijleo.2022.169132
   Hu JB, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.6.063106
   Hu JB, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/ab2527
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kenry, 2018, ADV MATER, V30, DOI 10.1002/adma.201802394
   Kou F, 2017, IEEE INT CON MULTI, P1105, DOI 10.1109/ICME.2017.8019529
   Lee C, 2014, IEEE SIGNAL PROC LET, V21, P1045, DOI 10.1109/LSP.2014.2323404
   Lee S, 2018, IEEE ACCESS, V6, P49913, DOI 10.1109/ACCESS.2018.2868246
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P5805, DOI 10.1109/TIP.2020.2987133
   Li H, 2018, IEEE IMAGE PROC, P1723, DOI 10.1109/ICIP.2018.8451689
   Li JC, 2019, CHEM SOC REV, V48, P38, DOI 10.1039/c8cs00001h
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Liu ZY, 2022, Arxiv, DOI arXiv:2107.02299
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Marnerides D, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13340
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   mmspg, HDR EYE DAT HIGH DYN
   Mohamed AA, 2019, FOOD CHEM, V274, P360, DOI 10.1016/j.foodchem.2018.09.014
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   Rana A, 2020, IEEE T IMAGE PROCESS, V29, P1285, DOI 10.1109/TIP.2019.2936649
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wu F, 2020, APPL OPTICS, V59, P5785, DOI 10.1364/AO.394532
   Wu LF, 2021, RESULTS OPT, V2, DOI 10.1016/j.rio.2020.100046
   Xu H, 2020, IEEE T IMAGE PROCESS, V29, P7203, DOI 10.1109/TIP.2020.2999855
   Yang Y, 2018, IEEE SIGNAL PROC LET, V25, P1885, DOI 10.1109/LSP.2018.2877893
NR 31
TC 4
Z9 4
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103585
DI 10.1016/j.jvcir.2022.103585
EA JUL 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4Y7HL
UT WOS:000861694600002
DA 2024-07-18
ER

PT J
AU Fang, JT
   Liu, BH
   Chang, PC
AF Fang, Jiunn-Tsair
   Liu, Bang-Hao
   Chang, Pao-Chi
TI Fast coding unit partitioning algorithms for versatile video coding
   intra coding*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile video coding; Quadtree with nested multi-type tree; Coding
   unit; Intra coding; Convolutional neural network
AB Versatile video coding (VVC) is the newest video compression standard. It adopts quadtree with nested multitype tree (QT-MTT) to encode square or rectangular coding units (CUs). The QT-MTT coding structure is more flexible for encoding video texture, but it is also accompanied by many time-consuming algorithms. So, this work proposes fast algorithms to determine horizontal or vertical split for binary or ternary partition of a 32 x 32 CU in the VVC intra coding to replace the rate-distortion optimization (RDO) process, which is time-consuming. The proposed fast algorithms are actually a two-step algorithm, including feature analysis method and deep learning method. The feature analysis method is based on variances of pixels, and the deep learning method applies the convolution neural networks (CNNs) for classification. Experimental results show that the proposed method can reduce encoding time by 28.94% on average but increase Bjontegaard delta bit rate (BDBR) by about 0.83%.
C1 [Fang, Jiunn-Tsair] Ming Chuan Univ, Dept Elect Engn, 5 Deming Rd, Taoyuan 33348, Taiwan.
   [Liu, Bang-Hao; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
C3 Ming Chuan University; National Central University
RP Fang, JT (corresponding author), Ming Chuan Univ, Dept Elect Engn, 5 Deming Rd, Taoyuan 33348, Taiwan.
EM fang@mail.mcu.edu.tw
CR Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen F., 2020, 16WP3 ITUT SG
   Bossen F., 2020, JVET Q0003 V1
   Bross B, 2018, JVET L0283
   Chen J., 2018, JVET-J1002-v2, Patent No. [1803.04393, 180304393]
   Chen J., 2020, JVETT2002
   Chen J., 2019, PROC IEEE INT C IMAG
   Cui J, 2020, IEEE DATA COMPR CONF, P103, DOI 10.1109/DCC47342.2020.00018
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   De-Luxán-Hernández S, 2019, IEEE IMAGE PROC, P1203, DOI [10.1109/ICIP.2019.8803777, 10.1109/icip.2019.8803777]
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Hanhart P, 2018, JVET COMMON TEST CON
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GL, 2017, IEEE ICC
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jin ZP, 2018, IEEE ACCESS, V6, P54660, DOI 10.1109/ACCESS.2018.2872492
   Karczewicz M., 2017, JVET H0001 8 M CHIN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lei M, 2019, IEEE IMAGE PROC, P4120, DOI [10.1109/ICIP.2019.8803421, 10.1109/icip.2019.8803421]
   Li TY, 2017, IEEE INT CON MULTI, P1255, DOI 10.1109/ICME.2017.8019316
   Park SH, 2021, IEEE T MULTIMEDIA, V23, P4388, DOI 10.1109/TMM.2020.3042062
   Saldanha M, 2020, IEEE IMAGE PROC, P3119, DOI [10.1109/ICIP40778.2020.9190970, 10.1109/icip40778.2020.9190970]
   Segall A., 2018, JVET K1011 11 JVET M
   Sullivan Gary, 2020, 2020 IEEE International Conference on Visual Communications and Image Processing (VCIP), DOI 10.1109/VCIP49819.2020.9301847
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang G., 2019, IEEE VISUAL COMMUNIC
   Tissier A, 2020, IEEE IMAGE PROC, P3139, DOI [10.1109/ICIP40778.2020.9190797, 10.1109/icip40778.2020.9190797]
   vcgit, VTM REF SOFTW
   Wang Z, 2018, IEEE T IMAGE PROCESS, V27, P1475, DOI 10.1109/TIP.2017.2778564
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Zhao L, 2019, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2019.00013
NR 33
TC 0
Z9 0
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103542
DI 10.1016/j.jvcir.2022.103542
EA JUN 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H5UY
UT WOS:000814360600004
DA 2024-07-18
ER

PT J
AU Fang, S
   Duan, MX
   Li, KL
   Li, KQ
AF Fang, Sen
   Duan, Mingxing
   Li, Kenli
   Li, Keqin
TI Facial makeup transfer with GAN for different aging faces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Domain; Facial aging; GAN; Makeup
ID RECOGNITION; SIMULATION
AB Facial aging is widely used in criminal tracking and the search for lost children. If the aging face is made up, it will greatly affect the discrimination of the tracking system. Therefore, the research on the makeup of different aging faces is extremely important. Existing studies have achieved a good transition from the non-makeup domain to the makeup domain in facial makeup transfer. But few studies involve the transfer of facial makeup at different ages. In addition, existing datasets rarely contain both age and makeup attributes, which make the transfer of facial makeup for different ages full of challenges. To solve the above problems, we propose a learning framework, called AM-Net, which can realize facial makeup transfer for different ages while protecting identity information. AM-Net is composed of two sub-network modules: Aging-Net and Makeup-Net. AM-Net first learns the aging mechanism of faces through Aging-Net, and then, it feeds the learned aging mode to Makeup-Net. After that, AM-Net trains Makeup-Net to realize the mapping relationship between the non-makeup domain to the makeup domain and transfer the makeup style to the face of the non-makeup. Throughout the network, multiple losses are applied to ensure AM-Net preserve information about the identity, background, etc. Extensive experiments are conducted on different datasets with different state-of-the-art methods, which prove the effectiveness of AM-Net.
C1 [Fang, Sen; Duan, Mingxing; Li, Kenli; Li, Keqin] Hunan Univ, Sch Informat Sci & Engn, Changsha, Peoples R China.
   [Li, Keqin] SUNY Coll New Paltz, Dept Comp Sci, New Paltz, NY USA.
   [Fang, Sen; Duan, Mingxing; Li, Kenli; Li, Keqin] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.
   [Duan, Mingxing] Hunan Univ, Shenzhen Inst, Shenzhen 518063, Peoples R China.
   [Duan, Mingxing] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Li, Keqin] SUNY Coll New Paltz, Dept Comp Sci, New Paltz, NY 12561 USA.
C3 Hunan University; State University of New York (SUNY) System; SUNY New
   Paltz; Hunan University; Hunan University; Hong Kong Polytechnic
   University; State University of New York (SUNY) System; SUNY New Paltz
RP Duan, MX; Li, KL (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.; Duan, MX (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
EM sen.fang@hnu.edu.cn; duanmingxing@hnu.edu.cn; lik@hnu.edu.cn;
   lik@newpaltz.edu
FU National Key-Research and Development Program of China [2020YFB2104003];
   National Outstanding Youth Science Program of National Natural Science
   Foundation of China [61625202]; International Cooperation and Exchange
   Key Program of National Natural Science Foundation of China
   [61860206011]; Shenzhen Excellent Technological and Innovative Talent
   Training Foundation [RCBS20200714114941176]; Science and Education Joint
   Project of Natural Science Foundation of Hunan Province [2020JJ7056];
   Hong Kong Scholars Program [XJ2020032]
FX This work was supported in part by the National Key-Research and
   Development Program of China under Grant No. 2020YFB2104003, in part by
   the National Outstanding Youth Science Program of National Natural
   Science Foundation of China under Grant 61625202, in part by the
   International Cooperation and Exchange Key Program of National Natural
   Science Foundation of China under Grant 61860206011, in part by the
   Shenzhen Excellent Technological and Innovative Talent Training
   Foundation under Grant RCBS20200714114941176, in part by the Science and
   Education Joint Project of Natural Science Foundation of Hunan Province
   under Grant 2020JJ7056. This paper is funded by the Hong Kong Scholars
   Program under Grants XJ2020032.
CR Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Duan MX, 2022, IEEE T CIRC SYST VID, V32, P3012, DOI 10.1109/TCSVT.2021.3096061
   Duan MX, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3418285
   Duan MX, 2021, IEEE T CIRC SYST VID, V31, P608, DOI 10.1109/TCSVT.2020.2981117
   Duan MX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3355542
   Duong C.N., 2016, ARXIV160602254
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kemelmacher-Shlizerman I, 2014, PROC CVPR IEEE, P3334, DOI 10.1109/CVPR.2014.426
   Kim T, 2017, PR MACH LEARN RES, V70
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lanitis A, 2008, IEEE INT CONF AUTOMA, P993
   Li C, 2015, PROC CVPR IEEE, P4621, DOI 10.1109/CVPR.2015.7299093
   Li TT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P645, DOI 10.1145/3240508.3240618
   Liu S., 2018, ARXIV180200237
   Liu S., 2016, ARXIV160407102, P2568
   Liu S., 2016, MAKEUP SUPERSTAR DEE
   Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431
   M. Inc, FAC RES TOOLK
   Mingxing D., P 29 ACM INT C MULT, V2021, P264
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Panis G, 2015, LECT NOTES COMPUT SC, V8926, P737, DOI 10.1007/978-3-319-16181-5_56
   Qawaqneh Z., 2017, ARXIV E PRINTS ARXIV
   Radford A., 2015, ARXIV
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Salimans T, 2016, ADV NEUR IN, V29
   Shi CL, 2020, PATTERN RECOGN LETT, V138, P520, DOI 10.1016/j.patrec.2020.08.021
   Shu XB, 2018, IEEE T PATTERN ANAL, V40, P905, DOI 10.1109/TPAMI.2017.2705122
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Sun N., 2020, UNSUPERVISED CROSS V
   Sun YL, 2020, IEEE T INF FOREN SEC, V15, P2679, DOI 10.1109/TIFS.2020.2975921
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Tazoe Y., 2012, ACM SIGGRAPH 2012 PO, DOI [10.1145/2342896.2343002, DOI 10.1145/2342896.2343002]
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   Tong WS, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P211, DOI 10.1109/PG.2007.31
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wang YH, 2012, IEEE T SYST MAN CY B, V42, P1107, DOI 10.1109/TSMCB.2012.2187051
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Wu Y., 2002, PLASTIC VISCO ELASTI
   Yang H., 2017, CORRABS171110352
   Yang TY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1078
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, DOI [10.1109/ICCV.2017.244, DOI 10.1109/ICCV.2017.244]
NR 53
TC 3
Z9 3
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103464
DI 10.1016/j.jvcir.2022.103464
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600006
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Chandler, DM
   Mou, XQ
AF Zhang, Yi
   Chandler, Damon M.
   Mou, Xuanqin
TI Multi-domain residual encoder-decoder networks for generalized
   compression artifact reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Artifact reduction; Residual network; Compression artifact; Quality
   factor estimation
ID IMAGE QUALITY ASSESSMENT; BLOCKING ARTIFACTS; SPARSE REPRESENTATION;
   DEBLOCKING FILTER; SUPERRESOLUTION; DECOMPRESSION; FRAMEWORK; CNN
AB A fundamental requirement for designing compression artifact reduction techniques is to restore the artifact free image from its compressed version regardless of the compression level. Most existing algorithms require the prior knowledge of JPEG encoding parameters to operate effectively. Although there are works that attempt to train universal models to deal with different compression levels, some JPEG quality factors (QF) are still missing. To overcome these potential limitations, in this paper, we present a generalized JPEG-compression artifact reduction framework that relies on improved QF estimator and rectified networks to take into account all possible QF values. Our method, called a generalized compression artifact reducer (G-CAR), first predicts QF by analyzing luminance patches with high activity. Then, based on the estimated QF, images are adaptively restored by the cascaded residual encoder-decoder networks learned in multiple domains. Results tested on six benchmark datasets demonstrate the effectiveness of our proposed model.
C1 [Zhang, Yi; Mou, Xuanqin] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Chandler, Damon M.] Ritsumeikan Univ, Coll Informat Sci & Engn, Kusatsu, Shiga 5258577, Japan.
C3 Xi'an Jiaotong University; Ritsumeikan University
RP Zhang, Y (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM yi.zhang.osu@xjtu.edu.cn
FU National Natural Science Founda-tion of China (NSFC) [61901355,
   62071375]; China Postdoctoral Science Foundation [2018M640991]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China (NSFC) (Grant No. 61901355, 62071375) and the China
   Postdoctoral Science Foundation (Grant No. 2018M640991) .
CR [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2016, Journal of WSCG
   Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927
   Chang HB, 2014, IEEE T SIGNAL PROCES, V62, P718, DOI 10.1109/TSP.2013.2290508
   Chen H., 2018, IEEE COMPUT SOC CONF, P711, DOI DOI 10.1109/CVPRW.2018.00114
   Chen T, 2001, IEEE T CIRC SYST VID, V11, P594, DOI 10.1109/76.920189
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Corchs S, 2014, DIGIT SIGNAL PROCESS, V30, P86, DOI 10.1016/j.dsp.2014.04.003
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Francisco NC, 2012, SIGNAL PROCESS-IMAGE, V27, P985, DOI 10.1016/j.image.2012.05.005
   Fu XY, 2019, IEEE I CONF COMP VIS, P2501, DOI 10.1109/ICCV.2019.00259
   Galteri L, 2019, IEEE T MULTIMEDIA, V21, P2131, DOI 10.1109/TMM.2019.2895280
   Galteri L, 2017, IEEE I CONF COMP VIS, P4836, DOI 10.1109/ICCV.2017.517
   Golestaneh SA, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013018
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo J, 2017, PROC CVPR IEEE, P4867, DOI 10.1109/CVPR.2017.517
   Guo J, 2016, LECT NOTES COMPUT SC, V9905, P628, DOI 10.1007/978-3-319-46448-0_38
   Hamaguchi R, 2018, IEEE WINT CONF APPL, P1442, DOI 10.1109/WACV.2018.00162
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Jiang ZR, 2019, IEEE T MED IMAGING, V38, P2705, DOI 10.1109/TMI.2019.2912791
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jung C, 2012, SIGNAL PROCESS-IMAGE, V27, P663, DOI 10.1016/j.image.2012.03.002
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kim SD, 1999, IEEE T CIRC SYST VID, V9, P156, DOI 10.1109/76.744282
   King DB, 2015, ACS SYM SER, V1214, P1
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li JQ, 2017, IEEE IJCNN, P4052, DOI 10.1109/IJCNN.2017.7966367
   Li T, 2018, IEEE T MULTIMEDIA, V20, P1305, DOI 10.1109/TMM.2017.2766889
   Lin GM, 2018, NEUROCOMPUTING, V275, P1219, DOI 10.1016/j.neucom.2017.09.062
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P509, DOI 10.1109/TIP.2016.2627807
   Liu XM, 2016, IEEE T IMAGE PROCESS, V25, P1649, DOI 10.1109/TIP.2016.2526910
   Liu XM, 2015, PROC CVPR IEEE, P5171, DOI 10.1109/CVPR.2015.7299153
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Ma L, 2012, SIGNAL PROCESS-IMAGE, V27, P54, DOI 10.1016/j.image.2011.05.004
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P490, DOI 10.1109/76.754778
   MINAMI S, 1995, IEEE T CIRC SYST VID, V5, P74, DOI 10.1109/76.388056
   Ming Yin, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1996, DOI 10.1109/ICASSP.2014.6853948
   Mu J, 2016, IEEE INT CON MULTI
   Nosratinia A, 2001, J VLSI SIG PROCESS S, V27, P69, DOI 10.1023/A:1008167430544
   ORourke TP, 1995, IEEE T CIRC SYST VID, V5, P490, DOI 10.1109/76.475891
   Park HW, 1999, IEEE T CIRC SYST VID, V9, P161, DOI 10.1109/76.744283
   Peng YL, 2019, NEUROCOMPUTING, V345, P67, DOI 10.1016/j.neucom.2018.12.075
   Radford A., 2015, ARXIV151106434
   RAMAMURTHI B, 1986, IEEE T ACOUST SPEECH, V34, P1258, DOI 10.1109/TASSP.1986.1164961
   REEVE HC, 1984, OPT ENG, V23, P34, DOI 10.1117/12.7973248
   Ren J, 2013, IEEE DATA COMPR CONF, P516, DOI 10.1109/DCC.2013.95
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samadani R, 2004, IEEE IMAGE PROC, P1799
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shi WZ, 2017, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.2017.8296427
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Sun DQ, 2007, IEEE T IMAGE PROCESS, V16, P2743, DOI 10.1109/TIP.2007.904969
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Triantafyllidis GA, 2002, IEEE T CIRC SYST VID, V12, P877, DOI 10.1109/TCSVT.2002.804880
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang C, 2013, SIGNAL PROCESS-IMAGE, V28, P522, DOI 10.1016/j.image.2013.01.006
   Wang L., 2017, KSII Trans. Internet Inform. Syst, V11
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang TY, 2017, PROC INT C TOOLS ART, P1272, DOI 10.1109/ICTAI.2017.00192
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2016, PROC CVPR IEEE, P2764, DOI 10.1109/CVPR.2016.302
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Xinfeng Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P836, DOI 10.1109/ICME.2012.159
   Yang YY, 1997, IEEE T IMAGE PROCESS, V6, P1345, DOI 10.1109/83.624945
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Yu K., 2016, arXiv
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
   Zhang J, 2015, IEEE IMAGE PROC, P306, DOI 10.1109/ICIP.2015.7350809
   Zhang J, 2016, IEEE T IMAGE PROCESS, V25, P1246, DOI 10.1109/TIP.2016.2515985
   Zhang JM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132686
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang XS, 2018, IEEE IMAGE PROC, P390, DOI 10.1109/ICIP.2018.8451694
   Zhang XF, 2016, IEEE T IMAGE PROCESS, V25, P4158, DOI 10.1109/TIP.2016.2588326
   Zhang XF, 2013, IEEE T IMAGE PROCESS, V22, P4613, DOI 10.1109/TIP.2013.2274386
   Zhang ZD, 2019, IEEE T IMAGE PROCESS, V28, P1625, DOI 10.1109/TIP.2018.2877483
   Zhao C, 2017, IEEE T CIRC SYST VID, V27, P2057, DOI 10.1109/TCSVT.2016.2580399
   Zhao ZS, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0465-0
   Zheng BL, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043037
   Zini S, 2020, IEEE ACCESS, V8, P63283, DOI 10.1109/ACCESS.2020.2984387
NR 91
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103425
DI 10.1016/j.jvcir.2021.103425
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800004
DA 2024-07-18
ER

PT J
AU Ren, DK
   Chen, JZ
   Zhong, J
   Lu, ZM
   Jia, T
   Li, ZY
AF Ren, Dakai
   Chen, Jiazhong
   Zhong, Jian
   Lu, Zhaoming
   Jia, Tao
   Li, Zongyi
TI Gaze estimation via bilinear pooling-based attention networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gaze tracking; Deep learning; Bilinear pooling; Attention
AB Attention mechanism has been found effective for human gaze estimation, and the attention and diversity of learned features are two important aspects of attention mechanism. However, the traditional attention mechanism used in existing gaze model is more prone to utilize first-order information that is attentive but not diverse. Though the existing bilinear pooling-based attention could overcome the shortcoming of traditional attention, it is limited to extract high-order contextual information. Thus we introduce a novel bilinear poolingbased attention mechanism, which could extract the second-order contextual information by the interaction between local deep learned features. To make the gaze-related features robust for spatial misalignment, we further propose an attention-in-attention method, which consists of a global average pooling and an inner attention on the second-order features. For the purpose of gaze estimation, a new bilinear pooling-based attention networks with attention-in-attention is further proposed. Extensive evaluation shows that our method surpasses the state-of-the-art by a big margin.
C1 [Ren, Dakai; Lu, Zhaoming] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Chen, Jiazhong; Zhong, Jian; Jia, Tao; Li, Zongyi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Huazhong University of
   Science & Technology
RP Chen, JZ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM chenjz70@163.com
RI Li, Zongyi/AAY-3602-2020
OI Li, Zongyi/0000-0002-5989-9132
FU Natural Science Foundation of China [61972169]; National key research
   and development program of China [2019QY(Y)0202]; Research Programme on
   Applied Fundamentals and Frontier Technologies of Wuhan
   [2020010601012182]; Beijing Nova Program [Z201100006820123]; Beijing
   Municipal Science and Technology Commission
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61972169, in part by the National key research and
   development program of China (2019QY(Y)0202), in part by the Research
   Programme on Applied Fundamentals and Frontier Technologies of Wuhan
   (2020010601012182), in part by the Beijing Nova Program
   (Z201100006820123) from Beijing Municipal Science and Technology
   Commission.
CR [Anonymous], 2013, IMPACT HAND HELD HAN
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Bengio S, 2015, ADV NEUR IN, V28
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen ZK, 2019, IEEE INT CONF COMP V, P1088, DOI 10.1109/ICCVW.2019.00139
   Chen Zhaokang, 2018, ASIAN C COMPUTER VIS, P309
   Cheng YH, 2018, LECT NOTES COMPUT SC, V11218, P105, DOI 10.1007/978-3-030-01264-9_7
   Cheng YH, 2020, IEEE T IMAGE PROCESS, V29, P5259, DOI 10.1109/TIP.2020.2982828
   Cohen S., 2018, BMVC, P1
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   EFRON B, 1981, ANN STAT, V9, P586, DOI 10.1214/aos/1176345462
   Fang PF, 2019, IEEE I CONF COMP VIS, P8029, DOI 10.1109/ICCV.2019.00812
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jha S, 2019, INT CONF ACOUST SPEE, P3792, DOI [10.1109/ICASSP.2019.8683794, 10.1109/icassp.2019.8683794]
   Jyoti S, 2018, INT C PATT RECOG, P2474, DOI 10.1109/ICPR.2018.8545162
   Kingma D. P., 2014, arXiv
   Koniusz P, 2018, PROC CVPR IEEE, P5774, DOI 10.1109/CVPR.2018.00605
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Lemley J, 2019, IEEE T CONSUM ELECTR, V65, P179, DOI 10.1109/TCE.2019.2899869
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li JF, 2014, IEEE COMPUT SOC CONF, P606, DOI 10.1109/CVPRW.2014.93
   Lian DZ, 2019, IEEE T NEUR NET LEAR, V30, P3010, DOI 10.1109/TNNLS.2018.2865525
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin Z., 2017, PROC INT C LEARN REP
   Ling HF, 2019, IEEE ACCESS, V7, P55159, DOI 10.1109/ACCESS.2019.2913205
   Lu F, 2011, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2011.6126237
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mora K. A. F., 2014, P S EYE TRACK RES AP, P255, DOI [10.1145/2578153.2578190, 10.1145/2578153]
   Nguyen TV, 2018, INT J COMPUT VISION, V126, P86, DOI 10.1007/s11263-017-1042-6
   Park S, 2019, IEEE I CONF COMP VIS, P9367, DOI 10.1109/ICCV.2019.00946
   Park S, 2018, LECT NOTES COMPUT SC, V11217, P741, DOI 10.1007/978-3-030-01261-8_44
   Paszke A, 2017, NIPS 2017 WORKSHOP
   Pomerleau D., 1993, P AAAI FALL S MACH L, P153
   Pramono RRA, 2019, IEEE I CONF COMP VIS, P61, DOI 10.1109/ICCV.2019.00015
   Ranjan R, 2018, IEEE COMPUT SOC CONF, P2237, DOI 10.1109/CVPRW.2018.00290
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Schneider T, 2014, INT C PATT RECOG, P1167, DOI 10.1109/ICPR.2014.210
   Smith B.A., 2013, P 26 ANN ACM S USER, P271, DOI DOI 10.1145/2501988.2501994
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180
   Vaswani A, 2017, ADV NEUR IN, V30
   Vora S, 2018, IEEE T INTELL VEHICL, V3, P254, DOI 10.1109/TIV.2018.2843120
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wood E., 2014, P S EYE TRACK RES AP, P207, DOI DOI 10.1145/2578153.2578185
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Xiong YY, 2019, PROC CVPR IEEE, P7735, DOI 10.1109/CVPR.2019.00793
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Zhang HG, 2019, IEEE WINT CONF APPL, P1185, DOI 10.1109/WACV.2019.00131
   Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103
   Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhou XL, 2019, IEEE INT CON MULTI, P850, DOI 10.1109/ICME.2019.00151
NR 63
TC 2
Z9 2
U1 2
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103369
DI 10.1016/j.jvcir.2021.103369
EA NOV 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XK3OJ
UT WOS:000727378900004
DA 2024-07-18
ER

PT J
AU Wu, Y
   Fan, JX
   Tao, RS
   Wang, JK
   Qin, HT
   Liu, AS
   Liu, XL
AF Wu, Yan
   Fan, Jiaxin
   Tao, Renshuai
   Wang, Jiakai
   Qin, Haotong
   Liu, Aishan
   Liu, Xianglong
TI Sequential alignment attention model for scene text recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene text recognition; Attention-gated recurrent unit; Attention
   mechanism; Connectionist temporal classification
AB Scene text recognition has been a hot research topic in computer vision due to its various applications. The stateof-the-art solutions usually depend on the attention-based encoder-decoder framework that learns the mapping between input images and output sequences in a purely data-driven way. Unfortunately, there often exists severe misalignment between feature areas and text labels in real-world scenarios. To address this problem, this paper proposes a sequential alignment attention model to enhance the alignment between input images and output character sequences. In this model, an attention gated recurrent unit (AGRU) is first devised to distinguish the text and background regions, and further extract the localized features focusing on sequential text regions. Furthermore, CTC guided decoding strategy is integrated into the popular attention-based decoder, which not only helps to boost the convergence of the training but also enhances the well-aligned sequence recognition. Extensive experiments on various benchmarks, including the IIIT5k, SVT, and ICDAR datasets, show that our method substantially outperforms the state-of-the-art methods.
C1 [Wu, Yan; Fan, Jiaxin; Tao, Renshuai; Wang, Jiakai; Qin, Haotong; Liu, Aishan; Liu, Xianglong] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
C3 Beihang University
RP Tao, RS (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
EM rstao@buaa.edu.cn
RI Wang, Jiakai/ABB-3894-2022; Qin, Haotong/AGP-1834-2022
OI Wang, Jiakai/0000-0001-5884-3412; Qin, Haotong/0000-0001-7391-7539; Liu,
   Xianglong/0000-0002-7618-3275
CR [Anonymous], 3 INT C LEARN REPR S
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He RN, 2016, AAAI CONF ARTIF INTE, P144
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jaderberg Max, 2014, WORKSH DEEP LEARN NI
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kawakami K., 2008, THESIS
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331
   Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Liao MH, 2019, AAAI CONF ARTIF INTE, P8714
   Lin QX, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107692
   Liu W., 32 AAAI C ARTIFICIAL
   Liu ZC, 2018, AAAI CONF ARTIF INTE, P7194
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127
   Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Qin H, 2021, P ICLR, P2021
   Qin HT, 2020, PROC CVPR IEEE, P2247, DOI 10.1109/CVPR42600.2020.00232
   Qin HT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107281
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Su BL, 2017, PATTERN RECOGN, V63, P397, DOI 10.1016/j.patcog.2016.10.016
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Sutskever I, 2014, ADV NEUR IN, V27
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Xie HT, 2014, IEEE T MULTIMEDIA, V16, P1104, DOI 10.1109/TMM.2014.2305909
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Zeiler M. D., 2012, CoRR
   Zhang XG, 2021, PROC CVPR IEEE, P15653, DOI 10.1109/CVPR46437.2021.01540
   Zhi Qiao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13525, DOI 10.1109/CVPR42600.2020.01354
NR 53
TC 5
Z9 5
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103289
DI 10.1016/j.jvcir.2021.103289
EA SEP 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900011
DA 2024-07-18
ER

PT J
AU Yu, JR
   Ge, YX
   Qin, XL
   Li, ZQ
   Huang, S
   Chen, FY
AF Yu, Jiaruo
   Ge, Yongxin
   Qin, Xiaolei
   Li, Ziqiang
   Huang, Sheng
   Chen, Feiyu
TI Deep feature enhancing and selecting network for weakly supervised
   temporal action localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised; Temporal action localization; Deep learning
AB Weakly supervised temporal action localization is a challenging computer vision problem that uses only video-level labels and lacks the supervision of temporal annotations. In this task, the majority of existing methods usually identify the most discriminative snippets and ignore other relevant snippets. To address this problem, we propose a deep feature enhancing and selecting network. It generates multiple masks for both capturing more complete temporal interval of actions and keeping its high classification accuracy. After that, we further propose a novel selection strategy to balance the influence of multiple masks and improve the model performance. In the experiments, we evaluate the proposed method on the THUMOS'14 and ActivityNet datasets, and the results show the effectiveness of our approach for weakly supervised temporal action localization.
C1 [Yu, Jiaruo; Ge, Yongxin; Qin, Xiaolei; Li, Ziqiang; Huang, Sheng] Chongqing Univ, Sch Big Data & Software Engn, Chongqing, Peoples R China.
   [Chen, Feiyu] Natl Ctr Appl Math Chongqing, Chongqing, Peoples R China.
C3 Chongqing University
RP Ge, YX (corresponding author), Chongqing Univ, Sch Big Data & Software Engn, Chongqing, Peoples R China.
EM yongxinge@cqu.edu.cn
RI qin, xiaolei/AAZ-8130-2020
FU National Natural Science Foundation of China [62176031]; Graduate
   Research and Innovation Foundation of Chongqing, China [CYS20074];
   Fundamental Research Funds for the Central Universities [2021CDJQY-018]
FX The work described in this paper was partially supported by the National
   Natural Science Foundation of China (Grant no. 62176031), Graduate
   Research and Innovation Foundation of Chongqing, China (Grant no.
   CYS20074) and the Fundamental Research Funds for the Central
   Universities(Grant no. 2021CDJQY-018).
CR Buch S., 2017, P BRIT MACH VIS C BM
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Hou QB, 2018, ADV NEUR IN, V31
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   King DB, 2015, ACS SYM SER, V1214, P1
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Paul S., 2018, P EUR C COMP VIS, P563
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Yu T, 2019, IEEE I CONF COMP VIS, P5521, DOI 10.1109/ICCV.2019.00562
   Yuan ZH, 2017, PROC CVPR IEEE, P3215, DOI 10.1109/CVPR.2017.342
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhong JX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P35, DOI 10.1145/3240508.3240511
   Zhu Y., 2017, ARXIV
NR 30
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103276
DI 10.1016/j.jvcir.2021.103276
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600004
DA 2024-07-18
ER

PT J
AU Lu, JX
   Fang, ZJ
   Gao, YB
   Chen, JY
AF Lu, Junxin
   Fang, Zhijun
   Gao, Yongbin
   Chen, Jieyu
TI Line-based visual odometry using local gradient fitting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual odometry; Line; Gradient; Texture-less; RGB-D
AB Visual odometry aims to estimate the relative pose between frames, which is a fundamental task for visual SLAM. In this paper, we present a novel line-based visual odometry (VO) algorithm that fully utilizes the characteristic of line to estimate the projected line of adjacent frame by minimizing the local gradient fitness evaluation. In contrast to the current feature-based or line-based visual odometry, we don ' t need to explicitly match points or lines of two frames, which is non-trivial and inaccurate in challenging scenarios such as texture-less scenes. In our method, the projected line is calculated simultaneously with the local gradient fitting function of pose estimation based on the constraint that the orientation of the projected line should be perpendicular to the gradient orientation of pixels of its local regions. The proposed method is more robust and reliable than other line-based VO since it fully uses the pixel orientations in the local regions to estimate the projected line and relative pose. We evaluate our method on the real-world RGB-D dataset and synthetic benchmark dataset. Experimental results show that our method achieves the state-of-the-art algorithms in indoors scenes, especially in texture-less scenes.
C1 [Lu, Junxin; Fang, Zhijun; Gao, Yongbin; Chen, Jieyu] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
C3 Shanghai University of Engineering Science
RP Fang, ZJ (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
EM zjfang@sues.edu.cn
OI lu, junxin/0000-0003-3653-0858
FU National Natural Science Foundation of China [61772328, 61831018,
   61802253, U2033218]; National Key Research and Development Project of
   Ministry of Science and Technology of China [2020AAA0109302,
   2020AAA0109300]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772328, 61831018, 61802253, U2033218,
   in part by the National Key Research and Development Project of Ministry
   of Science and Technology of China under Grant 2020AAA0109302,
   2020AAA0109300.
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Christensen Kevin, 2019, ARXIV COMPUTER VISIO
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Fraundorfer Friedrich, 2017, BMVC
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Gomez-Ojeda R, 2019, IEEE T ROBOT, V35, P734, DOI 10.1109/TRO.2019.2899783
   Gomez-Ojeda R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4211, DOI 10.1109/IROS.2016.7759620
   Gomez-Ojeda R, 2016, IEEE INT CONF ROBOT, P2521, DOI 10.1109/ICRA.2016.7487406
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Kim C, 2018, IEEE INT C INT ROBOT, P6887, DOI 10.1109/IROS.2018.8593594
   Kim P, 2018, LECT NOTES COMPUT SC, V11208, P350, DOI 10.1007/978-3-030-01225-0_21
   Kim P, 2018, IEEE INT CONF ROBOT, P7247
   Klein George, 2007, P1
   Li Renju, 2016, BRIT MACH VIS C
   Li S, 2020, MECH ADV MATER STRUC, V27, P1213, DOI 10.1080/15376494.2018.1504361
   Li XL, 2018, INT CONF CLOUD COMPU, P390, DOI [10.1109/CCIS.2018.8691213, 10.1109/ICITBS.2018.00105]
   Lu XH, 2015, IEEE IMAGE PROC, P507, DOI 10.1109/ICIP.2015.7350850
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nistér D, 2004, PROC CVPR IEEE, P652
   Nister David, 2006, CVPR
   Pumarola Albert, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4503, DOI 10.1109/ICRA.2017.7989522
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233
   Schenk F, 2019, IEEE INT CONF ROBOT, P154, DOI [10.1109/icra.2019.8794462, 10.1109/ICRA.2019.8794462]
   Schenk F, 2017, IEEE INT C INT ROBOT, P1297, DOI 10.1109/IROS.2017.8202305
   Seonwook Park, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4523, DOI 10.1109/ICRA.2017.7989525
   Steinbrücker F, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Triggs Bill, 2000, ICCV 99 P INT WORKSH, P7
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wasenmüller O, 2016, IEEE WINT CONF APPL
   Yang SA, 2019, INT CONF MACH LEARN, P1, DOI 10.1109/icmlc48188.2019.8949230
   Yijun Zhou, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P900, DOI 10.1109/ICMA.2018.8484479
   Zhang ZS, 2008, I C MECH MACH VIS PR, P1, DOI 10.1109/MMVIP.2008.4749497
   Zhou HZ, 2015, IEEE T VEH TECHNOL, V64, P1364, DOI 10.1109/TVT.2015.2388780
   Zhou Y, 2019, IEEE T ROBOT, V35, P184, DOI 10.1109/TRO.2018.2875382
NR 42
TC 4
Z9 4
U1 3
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103071
DI 10.1016/j.jvcir.2021.103071
EA MAR 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SF9SQ
UT WOS:000653087000001
DA 2024-07-18
ER

PT J
AU Salas, RR
   Dokládal, P
   Dokladalova, E
AF Salas, Rosemberg Rodriguez
   Dokladal, Petr
   Dokladalova, Eva
TI A minimal model for classification of rotated objects with prediction of
   the angle of rotation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image Classification; Convolutional neural network; Rotation invariance;
   Prediction of angle of rotation; Steerable filters
AB In classification tasks, the robustness against various image transformations remains a crucial property of CNN models. When acquired using the data augmentation it comes at the price of a considerable increase in training time and the risk of overfitting. Consequently, researching other ways to endow CNNs with invariance to various transformations is an intensive field of study.
   This paper presents a new reduced, rotation-invariant, classification model composed of two parts: a feature representation mapping and a classifier. We provide an insight into the principle and we show that the proposed model is trainable. The model we obtain is smaller and has angular prediction capabilities.
   We illustrate the results on the MNIST-rot and CIFAR-10 datasets. We achieve the state-of-the-art classification score on MNIST-rot, and improve by 20% the state of the art score on rotated CIFAR-10. In all cases, we can predict the rotation angle.
C1 [Salas, Rosemberg Rodriguez; Dokladalova, Eva] Univ Gustave Eiffel, ESIEE Paris, CNRS, LIGM, F-77454 Marne La Vallee, France.
   [Dokladal, Petr] PSL Res Univ, Ctr Math Morphol, MINES Paris, 35 Rue St Honore, F-77305 Fontainebleau, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Gustave-Eiffel; ESIEE Paris; Ecole des Ponts ParisTech; Universite PSL;
   MINES ParisTech
RP Salas, RR (corresponding author), Univ Gustave Eiffel, ESIEE Paris, CNRS, LIGM, F-77454 Marne La Vallee, France.
EM r.rodriguez@esiee.fr
OI Dokladal, Petr/0000-0002-6502-7461; Dokladalova, Eva/0000-0003-1765-7394
CR Aquino N.R., 2017, Braz. Soc. Comput. Intell
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chen Z., 2020, PROC EUR C COMPUT VI, P195, DOI DOI 10.1007/978-3-030-58558-7_12
   Chen Z, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010139
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cohen T.S., 2018, PROC INT C LEARN REP, P1
   Cohen TS, 2019, PR MACH LEARN RES, V97
   Dieleman S., 2016, ABS160202660 CORR
   Esteves Carlos, 2018, INT C LEARN REPR
   Follmann P, 2018, IEEE WINT CONF APPL, P784, DOI 10.1109/WACV.2018.00091
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gao LY, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P551, DOI 10.1145/3341162.3349330
   Gens R., 2014, Advances in Neural Information Processing Systems (NIPS), P2537
   Gopalakrishnan R, 2018, I C CONT AUTOMAT ROB, P1520, DOI 10.1109/ICARCV.2018.8581256
   Graham S., 2020, IEEE T MED IMAGING, DOI DOI 10.1109/TMI.2020.3013246
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jaderberg M, 2015, ADV NEUR IN, V28
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev D, 2016, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.2016.38
   Li HC, 2017, I C INTELL COMPUT TE, P390, DOI 10.1109/ICICTA.2017.93
   Li JY, 2018, NEUROCOMPUTING, V290, P26, DOI 10.1016/j.neucom.2018.02.029
   Lintott C, 2011, MON NOT R ASTRON SOC, V410, P166, DOI 10.1111/j.1365-2966.2010.17432.x
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Marcos D, 2017, IEEE I CONF COMP VIS, P5058, DOI 10.1109/ICCV.2017.540
   Marcos D, 2016, INT C PATT RECOG, P2012, DOI 10.1109/ICPR.2016.7899932
   McGuinness K., 2019, P IMVIP 2019 IR MACH, DOI [10.21427/148b-ar75, DOI 10.21427/148B-AR75, 10. 21427/148b-ar75]
   Quiroga Facundo, 2020, Modelling and Simulation in Management Sciences. Proceedings of the International Conference on Modelling and Simulation in Management Sciences (MS-18). Advances in Intelligent Systems and Computing (AISC 894), P127, DOI 10.1007/978-3-030-15413-4_10
   Rodriguez R, 2019, IEEE IMAGE PROC, P654, DOI [10.1109/ICIP.2019.8804467, 10.1109/icip.2019.8804467]
   Salas R. Rodriguez, 2019, ROTATION EQUIVARIANT
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Shin C, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P441, DOI 10.1109/IRC.2019.00090
   Shin I., 2006, FLOR C REC ADV ROB F, P1
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   van Dyk DA, 2001, J COMPUT GRAPH STAT, V10, P1, DOI 10.1198/10618600152418584
   Weiler M, 2018, PROC CVPR IEEE, P849, DOI 10.1109/CVPR.2018.00095
   Worrall D, 2018, LECT NOTES COMPUT SC, V11209, P585, DOI 10.1007/978-3-030-01228-1_35
   Worrall DE, 2017, PROC CVPR IEEE, P7168, DOI 10.1109/CVPR.2017.758
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Zhang X, 2017, IEEE INT CONF COMP V, P1210, DOI 10.1109/ICCVW.2017.146
   Zhang YC, 2019, IEEE INT CON MULTI, P1606, DOI 10.1109/ICME.2019.00277
   Zhang Y, 2019, IEEE MTT S INT MICR, P846, DOI 10.1109/mwsym.2019.8701039
   Zhong Z.W. Pan, 2019, AN C INF SCI SYST CI, P1
   Zhou YZ, 2017, PROC CVPR IEEE, P4961, DOI 10.1109/CVPR.2017.527
NR 45
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103054
DI 10.1016/j.jvcir.2021.103054
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, Y
   Choi, J
   Chen, YR
   Li, SY
   Huang, Q
   Zhang, KT
   Lee, MS
   Kuo, CCJ
AF Wang, Ye
   Choi, Jongmoo
   Chen, Yueru
   Li, Siyang
   Huang, Qin
   Zhang, Kaitai
   Lee, Ming-Sui
   Kuo, C-C Jay
TI Unsupervised video object segmentation with distractor-aware online
   adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised video object segmentation; Pseudo ground truth; Motion
   saliency; Hard negative mining; Online adaptation
AB Unsupervised video object segmentation is a crucial application in video analysis when there is no prior information about the objects. It becomes tremendously challenging when multiple objects occur and interact in a video clip. In this paper, a novel unsupervised video object segmentation approach via distractor-aware online adaptation (DOA) is proposed. DOA models spatiotemporal consistency in video sequences by capturing background dependencies from adjacent frames. Instance proposals are generated by the instance segmentation network for each frame and they are grouped by motion information as positives or hard negatives. To adopt high-quality hard negatives, the block matching algorithm is then applied to preceding frames to track the associated hard negatives. General negatives are also introduced when there are no hard negatives in the sequence. The experimental results demonstrate these two kinds of negatives are complementary. Finally, we conduct DOA using positive, negative, and hard negative masks to update the foreground and background segmentation. The proposed approach achieves state-of-the-art results on two benchmark datasets, the DAVIS 2016 and the Freiburg-Berkeley motion segmentation (FBMS)-59.
C1 [Wang, Ye; Choi, Jongmoo; Chen, Yueru; Zhang, Kaitai; Kuo, C-C Jay] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Li, Siyang] Google AI Percept, Mountain View, CA USA.
   [Huang, Qin] Facebook, Menlo Pk, CA USA.
   [Lee, Ming-Sui] Natl Taiwan Univ, Taipei, Taiwan.
C3 University of Southern California; Facebook Inc; National Taiwan
   University
RP Lee, MS (corresponding author), Natl Taiwan Univ, Taipei, Taiwan.
EM mslee@csie.ntu.edu.tw
RI Chen, Yueru/GWC-9924-2022; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2017, ARXIV170105384
   [Anonymous], 2013, PMLR
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2016, ARXIV160802236
   [Anonymous], 2016, ARXIV 1606 00915 CS
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen CW, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351436
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Faktor Alon, 2014, BMVC
   GRUNDMANN M, 2010, PROC CVPR IEEE, P2141, DOI DOI 10.1109/CVPR.2010.5539893
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu Y.-T., 2018, ARXIV180901123
   Hu Y.-T., 2018, P ECCV
   Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82
   Jin S., 2018, ARXIV180804285
   Kingma D. P., 2014, arXiv
   Koh Y.J, 2017, P IEEE C COMP VIS PA, V1, P6
   Lee SH, 2017, PROC CVPR IEEE, P5863, DOI 10.1109/CVPR.2017.621
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683
   Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2009, NANOTECHNOLOGY, V20, DOI 10.1088/0957-4484/20/6/065604
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735
   Märki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   Maninis Kevis-Kokitsi, 2017, PAMI
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F., 2017, Computer Vision and Pattern Recognition
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Song H, 2018, JOINT INT CONF SOFT, P718, DOI 10.1109/SCIS-ISIS.2018.00119
   Tang Kevin, 2012, P INT C NEUR INF PRO, P647
   Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055
   Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480
   Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Voigtlaender P., 2017, BMVC, P1000
   Waleed A, 2017, GITHUB REPOSITORY
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu Zifeng, 2016, CoRR
   Xiao HX, 2018, PROC CVPR IEEE, P1140, DOI 10.1109/CVPR.2018.00125
   Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45
   Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680
   Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
NR 60
TC 4
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102953
DI 10.1016/j.jvcir.2020.102953
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I2ON
UT WOS:000779264200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, HE
   Su, H
   Chang, ZG
   Yu, MY
   Gao, JL
   Li, XZ
   Zheng, SB
AF Huang, Hong'en
   Su, Hang
   Chang, Zhigang
   Yu, Mingyang
   Gao, Jialin
   Li, Xinzhe
   Zheng, Shibao
TI Convolutional neural network with adaptive inferential framework for
   skeleton-based action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skeleton-based action recognition; Pseudo image; Adaptive inferential
   framework; Different prior information
AB In the task of skeleton-based action recognition, CNN-based methods represent the skeleton data as a pseudo image for processing. However, it still remains as a critical issue of how to construct the pseudo image to model the spatial dependencies of the skeletal data. To address this issue, we propose a novel convolutional neural network with adaptive inferential framework (AIF-CNN) to exploit the dependencies among the skeleton joints. We particularly investigate several initialization strategies to make the AIF effective with each strategy introducing the different prior knowledge. Extensive experiments on the dataset of NTU RGB+D and Kinetics-Skeleton demonstrate that the performance is improved significantly by integrating the different prior information.
C1 [Huang, Hong'en; Chang, Zhigang; Yu, Mingyang; Gao, Jialin; Li, Xinzhe; Zheng, Shibao] Shanghai Jiao Tong Univ, Dept Elect Engn, SEIEE, Shanghai, Peoples R China.
   [Su, Hang] Tsinghua Univ, Inst AI, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Shanghai Jiao Tong University; Tsinghua University
RP Zheng, SB (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, SEIEE, Shanghai, Peoples R China.
EM sbzh@sjtu.edu.cn
RI Gao, Jialin/AGY-7711-2022
OI Gao, Jialin/0000-0002-8554-7827; Chang, Zhigang/0000-0002-8565-3857
FU National Natural Science Foundation of China (NSFC) [61671289,
   61771303]; STCSM, China [18DZ2270700]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) (Grant No. 61671289, 61771303), STCSM, China (18DZ2270700).
CR [Anonymous], 2007, 2007 IEEE C COMPUTER
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Liu AA, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P821
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wen YH, 2019, AAAI CONF ARTIF INTE, P8989
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang B., 2017, KINETICS HUMAN ACTIO
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2116, DOI 10.1109/ICCV.2017.231
   Zhao R, 2019, IEEE I CONF COMP VIS, P6881, DOI 10.1109/ICCV.2019.00698
NR 29
TC 9
Z9 10
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102925
DI 10.1016/j.jvcir.2020.102925
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200008
DA 2024-07-18
ER

PT J
AU Nie, L
   Lin, CY
   Liao, K
   Liu, MQ
   Zhao, Y
AF Nie, Lang
   Lin, Chunyu
   Liao, Kang
   Liu, Meiqin
   Zhao, Yao
TI A view-free image stitching network based on global homography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 41A05; 41A10; 65D05; 65D17
AB Image stitching is a traditional but challenging computer vision task, aiming to obtain a seamless panoramic image. Recently, researchers begin to study the image stitching task using deep learning. However, the existing learning methods assume a relatively fixed view during the image capturing, thus show a poor generalization ability to flexible view cases. To address the above problem, we present a cascaded view-free image stitching network based on a global homography. This novel image stitching network does not have any restriction on the view of images and it can be implemented in three stages. In particular, we first estimate a global homography between two input images from different views. And then we propose a structure stitching layer to obtain the coarse stitching result using the global homography. In the last stage, we design a content revision network to eliminate ghosting effects and refine the content of the stitching result. To enable efficient learning on various views, we also present a method to generate synthetic datasets for network training. Experimental results demonstrate that our method can achieve almost 100% elimination of artifacts in overlapping areas at the cost of acceptable slight distortions in non-overlapping areas, compared with traditional methods. In addition, the proposed method is view-free and more robust especially in a scene where feature points are difficult to detect.
C1 [Nie, Lang; Lin, Chunyu; Liao, Kang; Liu, Meiqin; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Lin, CY (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
EM cylin@bjtu.edu.cn
RI Lin, Chunyu/AAI-5185-2021; Liao, Kang/ADB-6353-2022
OI Lin, Chunyu/0000-0003-2847-0349; 
FU Fundamental Research Funds for the Central Universities [2018JBM011];
   National Natural Science Foundation of China [61772066, 61972028]
FX This work was supported by Fundamental Research Funds for the Central
   Universities (2018JBM011) and National Natural Science Foundation of
   China (No.61772066, No.61972028).
CR Alzohairy TA., 2016, INT J COMPUT APPL, V975, P8887
   Anderson R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980257
   Canwei Shen, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P192, DOI 10.1109/RCAR47638.2019.9044010
   Chang CH, 2014, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2014.422
   Chang CH, 2012, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2012.6247786
   Chen YS, 2016, LECT NOTES COMPUT SC, V9909, P186, DOI 10.1007/978-3-319-46454-1_12
   DeTone Daniel, 2016, ARXIV160603798
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eden A., 2006, P 2006 IEEE COMP SOC, VVolume 2, P2498
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gaddam VR, 2016, IEEE T MULTIMEDIA, V18, P1819, DOI 10.1109/TMM.2016.2586304
   Gao J., 2013, Eurographics (Short Papers), P45, DOI DOI 10.2312/CONF/EG2013/SHORT/045-048
   Gao JH, 2011, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2011.5995433
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jaderberg M, 2015, ADV NEUR IN, V28
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   King DB, 2015, ACS SYM SER, V1214, P1
   Lai W.-S., 2019, P BRIT MACHINE VISIO, P1
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li J., 2019, IEEE J-STSP, V14, P209, DOI [10.1109/JSTSP.2019.2953950, DOI 10.1109/JSTSP.2019.2953950]
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin KM, 2016, LECT NOTES COMPUT SC, V9907, P370, DOI 10.1007/978-3-319-46487-9_23
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi ZF, 2020, J SIGNAL PROCESS SYS, V92, P435, DOI 10.1007/s11265-019-01477-2
   Simonyan K., 2014, CORR
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Timofte R., 2019, ARXIV PREPRINT ARXIV
   Nguyen T, 2018, IEEE ROBOT AUTOM LET, V3, P2346, DOI 10.1109/LRA.2018.2809549
   Hoang VD, 2020, LECT NOTES ARTIF INT, V12034, P141, DOI 10.1007/978-3-030-42058-1_12
   Wang L, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P694, DOI [10.1109/ITNEC48623.2020.9084886, 10.1109/itnec48623.2020.9084886]
   Yan M, 2016, IEEE IJCNN, P4162, DOI 10.1109/IJCNN.2016.7727742
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang, 2019, ARXIV PREPRINT ARXIV
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
   Zhu ZG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P345, DOI 10.1109/ICCV.2001.937539
NR 41
TC 53
Z9 57
U1 12
U2 63
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102950
DI 10.1016/j.jvcir.2020.102950
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QO
UT WOS:000598558100002
DA 2024-07-18
ER

PT J
AU Cardenas, EJE
   Chavez, GC
AF Escobedo Cardenas, Edwin Jonathan
   Chavez, Guillermo Camara
TI Multimodal hand gesture recognition combining temporal and pose
   information based on CNN descriptors and histogram of cumulative
   magnitudes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand gesture recognition; Spherical coordinates; Keyframe extraction;
   Pose and motion information; Convolucional neuronal networks; Histogram
   of cumulative magnitudes; Fusion schemes
AB In this paper, we present a new approach for dynamic hand gesture recognition. Our goal is to integrate spatiotemporal features extracted from multimodal data captured by the Kinect sensor. In case the skeleton data is not provided, we apply a novel skeleton estimation method to compute temporal features. Furthermore, we introduce an effective method to extract a fixed number of keyframes to reduce the processing time. To extract pose features from RGB-D data, we take advantage of two different approaches: (1) Convolutional Neural Networks and (2) Histogram of Cumulative Magnitudes. We test different integration methods to fuse the extracted spatiotemporal features to boost recognition performance in a linear SVM classifier. Extensive experiments prove the effectiveness and feasibility of the proposed framework for hand gesture recognition. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Escobedo Cardenas, Edwin Jonathan; Chavez, Guillermo Camara] Univ Fed Ouro Preto, Dept Comp DECOM, Ouro Preto, MG, Brazil.
C3 Universidade Federal de Ouro Preto
RP Cardenas, EJE (corresponding author), Univ Fed Ouro Preto, Dept Comp DECOM, Ouro Preto, MG, Brazil.
EM edu.escobedo88@gmail.com; gcamarac@gmail.com
OI Escobedo Cardenas, Edwin/0000-0003-2034-513X
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]; Postgraduate Program in Computer Science (PPGCC) at the
   Federal University of Ouro Preto (UFOP); FAPEMIG (Fundacao de Amparo a
   Pesquisa do Estado de Minas Gerais) [APQ 01517-17]; Brazilian agency
   CNPq
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001, the
   Postgraduate Program in Computer Science (PPGCC) at the Federal
   University of Ouro Preto (UFOP), the FAPEMIG (Fundacao de Amparo a
   Pesquisa do Estado de Minas Gerais, research project APQ 01517-17) and
   the funding Brazilian agency CNPq.
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], ROBUST COLLABORATIVE
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Ben Mahjoub A, 2016, INT DES TEST SYMP, P83, DOI 10.1109/IDT.2016.7843019
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Blunsom P., 2004, Lecture notes, P48
   Budiman A, 2014, 2014 INTERNATIONAL CONFERENCE ON INDUSTRIAL AUTOMATION, INFORMATION AND COMMUNICATIONS TECHNOLOGY (IAICT), P39, DOI 10.1109/IAICT.2014.6922113
   Cao Z, 2017, DESTECH TRANS SOC, P25
   Cardenas E.E., 2017, IB C PATT REC, P212
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui R, 2019, IEEE ACCESS, V7, P8245, DOI 10.1109/ACCESS.2018.2889797
   Ding RW, 2019, IEEE ACCESS, V7, P5597, DOI 10.1109/ACCESS.2018.2886362
   Duan J., 2018, ACM T MULTIM COMPUT, V14, P1, DOI DOI 10.1145/3131343
   Escobedo E, 2016, SIBGRAPI, P209, DOI [10.1109/SIBGRAPI.2016.35, 10.1109/SIBGRAPI.2016.037]
   Escobedo E, 2015, SIBGRAPI, P173, DOI 10.1109/SIBGRAPI.2015.49
   Escobedo-Cardenas E, 2015, IEEE IMAGE PROC, P1240, DOI 10.1109/ICIP.2015.7350998
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Geng LB, 2014, IEEE INT CONF CON AU, P1393, DOI 10.1109/ICCA.2014.6871127
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Hayat M, 2016, NEUROCOMPUTING, V171, P889, DOI 10.1016/j.neucom.2015.07.027
   Hernandez-Vela A., 2013, PATTERN RECOGN LETT
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hou Yonghong., 2016, IEEE Transactions on Circuits and Systems for Video Technology
   Lan XY, 2020, PATTERN RECOGN LETT, V130, P12, DOI 10.1016/j.patrec.2018.10.002
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li B.L. Wanhua, 2017, LEARNING BOTH DYNAMI
   Li YN, 2016, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2016.7899602
   Liu K., 2018, T C3D TEMPORAL CONVO
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lostoy Y. Li, 2017, SIMPLE TRICK MASKED
   Miao QG, 2017, IEEE INT CONF COMP V, P3047, DOI 10.1109/ICCVW.2017.360
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Otiniano Rodriguez K., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P1, DOI 10.1109/SIBGRAPI.2013.10
   Otiniano-Rodríguez K, 2015, SIBGRAPI, P72, DOI 10.1109/SIBGRAPI.2015.50
   Pan TY, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P64, DOI 10.1109/BigMM.2016.44
   Pigou Lionel, 2015, INT J COMPUT VISION, P1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shao ZP, 2013, IEEE INT CONF ROBOT, P4749, DOI 10.1109/ICRA.2013.6631253
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Takimoto Hironori, 2013, INT J MACHINE LEARNI, V3, P245, DOI DOI 10.7763/IJM1C.2013.V3.312
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang HG, 2017, IEEE INT CONF COMP V, P3129, DOI 10.1109/ICCVW.2017.370
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao Y, 2016, IEEE ANN INT CONF CY, P392, DOI 10.1109/CYBER.2016.7574856
NR 56
TC 24
Z9 25
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102772
DI 10.1016/j.jvcir.2020.102772
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900017
DA 2024-07-18
ER

PT J
AU Zhao, JF
   Zhang, J
AF Zhao, Jingfeng
   Zhang, Jing
TI Application of multimedia technology in water conservancy and hydropower
   engineering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia; Water conservancy and cydro-power; Demonstration system;
   Information technology
ID 3-DIMENSIONAL PRINTING TECHNOLOGY
AB Multimedia covers a wide range. In general, digital audio production, animation video production, web site production, and even game development can all be attributed to multimedia. The definition of multimedia narrowly defined, that is, the project with interactive program development as the main object of this paper, such as interactive CD production, touch screen presentation production, etc. Of course, there will still be a lot of content related to graphic design, animation, video processing, audio production and so on. The application of multimedia technology in water conservancy and hydro-power engineering is characterized by a variety of media means to represent the design, construction process and post-construction scene of water conservancy and hydro-power projects and to simulate the phenomenon in the project, such as the performance of water conservancy and hydro-power projects. Hub layout, structure of main buildings, dam flood discharge, rubber dam dam overflow, sluice dispatching process, ship lock crossing process, etc. In the water conservancy and hydro-power project, computer multimedia technology has been widely used from the general design proposal to the entire pivot project demonstration system. This paper mainly introduces the design and development of the multimedia demonstration system for water conservancy and hydro-power projects. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Zhao, Jingfeng; Zhang, Jing] North China Univ Water Resources & Elect Power, Sch Management & Econ, Zhengzhou, Henan, Peoples R China.
C3 North China University of Water Resources & Electric Power
RP Zhang, J (corresponding author), North China Univ Water Resources & Elect Power, Sch Management & Econ, Zhengzhou, Henan, Peoples R China.
EM zhaojingfeng@nwu.edu.cn; shamommm@126.com
RI Zhao, Xujun/IRZ-4119-2023
CR Chen A, 2016, WATER SCI ENG, V9, P312, DOI 10.1016/j.wse.2017.01.008
   Cheung CL, 2014, J SURG EDUC, V71, P762, DOI 10.1016/j.jsurg.2014.03.001
   Choi JW, 2015, ARCH PLAST SURG-APS, V42, P267, DOI 10.5999/aps.2015.42.3.267
   Dulinska JM, 2013, APPL MECH MATER, V405-408, P2015, DOI 10.4028/www.scientific.net/AMM.405-408.2015
   Fang H.M., 2016, KEY ENG MATER, V693, P1886
   Fonseca D., 2015, UNIVERSAL ACCESS INF, V14, P1
   Guo M.Z., 2014, APPL MECH MAT, V722, P308
   He W., 2015, INT AS C IND ENG MAN, V01, P56
   Huang G.B., 2018, J YANGTZE RIVER SCI, V34, P113
   Laurent G, 2016, MATH GEOSCI, V48, P811, DOI 10.1007/s11004-016-9637-y
   McMenamin PG, 2014, ANAT SCI EDUC, V7, P479, DOI 10.1002/ase.1475
   Michalski A, 2016, MED SCI MONITOR, V22, P3994, DOI 10.12659/MSM.894147
   Ngoc TDT, 2014, ENVIRON EARTH SCI, V72, P119, DOI 10.1007/s12665-013-2941-7
   Rajendra I.M., 2018, INFLUENCE INTERACTIV
   Rao K., 2014, J ED MULTIMEDIA HYPE, V24, P121
   Santos I, 2018, GEOHERITAGE, V10, P143, DOI 10.1007/s12371-018-0305-0
   Shuquan X.U., 2014, WATER RESOUR HYDRO P, V23, P224
   Tang X.Q., 2014, WUHAN U J NAT SCI, V14, P537
   Taratoukhina J., 2014, U J ED RES, V2, P200
   Wang L, 2016, ADV FUNCT MATER, V26, P10, DOI 10.1002/adfm.201502071
   Wu LB, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717700899
   Xi C., 2019, MULTIMEDIA TOOLS APP, V2
   Xiaoyu X.U., 2015, J NAT DISASTERS, V32, P21
   Yin W., 2016, INT C ADV MAT COMP S, V27, P120
   Zhang W., 2014, WATER RESOUR HYDROPO, V45, P11
   Zhou Yi, 2015, J GEOTECH ENG, V37, P1232, DOI DOI 10.11779/CJGE201507009
NR 26
TC 1
Z9 1
U1 10
U2 92
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102707
DI 10.1016/j.jvcir.2019.102707
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900011
DA 2024-07-18
ER

PT J
AU Jiang, XH
   Shen, LQ
   Ding, Q
   Zheng, LR
   An, P
AF Jiang, Xuhao
   Shen, Liquan
   Ding, Qing
   Zheng, Linru
   An, Ping
TI Screen content image quality assessment based on convolutional neural
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Screen content image; No-reference;
   Convolutional neural network
ID SIMILARITY
AB Screen content image (SCI) is a composite image including textual and pictorial regions resulting in many difficulties in image quality assessment (IQA). Large SCIs are divided into image patches to increase training samples for CNN training of IQA model, and this brings two problems: (1) local quality of each image patch is not equal to subjective differential mean opinion score (DMOS) of an entire image; (2) importance of different image patches is not same for quality assessment. In this paper, we propose a novel no-reference (NR) IQA model based on the convolutional neural network (CNN) for assessing the perceptual quality of SCIs. Our model conducts two designs solving problems which benefits from two strategies. For the first strategy, to imitate full-reference (FR) CNN-based model behavior, a CNN-based model is designed for both FR and NR IQA, and performance of NR-IQA part improves when the image patch scores predicted by FR-IQA part are adopted as the ground-truth to train NR-IQA part. For the second strategy, image patch qualities of one entire SCI are fused to obtain the SCI quality with an adaptive weighting method taking account the effect of the different image patch contents. Experimental results verify that our model outperforms all test NR IQA methods and most FR IQA methods on the screen content image quality assessment database (SIQAD). On the cross-database evaluation, the proposed method outperforms the existing NR IQA method in terms of at least 2.4 percent in PLCC and 2.8 percent in SRCC, which shows high generalization ability and high effectiveness of our model, (C) 2019 Elsevier Inc. All rights reserved.
C1 [Jiang, Xuhao; Ding, Qing; Zheng, Linru; An, Ping] Shanghai Univ, Sch Commun & Informat Engn, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai, Peoples R China.
   [Shen, Liquan] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University
RP Shen, LQ (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
EM jxuhao@shu.edu.cn; jsslq@163.com; dingqing@shu.edu.cn; anping@shu.edu.cn
RI Shen, Liquan/D-4832-2012
OI Shen, Liquan/0000-0002-2148-6279
FU National Natural Science Foundation of China [61671282, 61931022];
   Shanghai Pujiang Program [15pjd015]; Shanghai Science and Technology
   Innovation Plan [18010500200]; Shanghai Shuguang Program [17SG37]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant Nos. 61671282 and 61931022, through the
   Shanghai Pujiang Program under Grant 15pjd015, Shanghai Science and
   Technology Innovation Plan under Grant 18010500200, and Shanghai
   Shuguang Program under Grant 17SG37.
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], P INT C MACH LEARN L
   Bare B, 2017, IEEE INT CON MULTI, P1356, DOI 10.1109/ICME.2017.8019508
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen JN, 2018, IEEE SIGNAL PROC LET, V25, P1685, DOI 10.1109/LSP.2018.2871250
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P2016, DOI 10.1109/TIP.2017.2669840
   Fu Y, 2018, IEEE T CIRC SYST VID, V28, P2428, DOI 10.1109/TCSVT.2018.2854176
   Gu K, 2018, IEEE T VIS COMPUT GR, V24, P2689, DOI 10.1109/TVCG.2017.2771284
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu Y, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P1, DOI 10.1109/DASC.2014.10
   Ji WP, 2019, J VIS COMMUN IMAGE R, V58, P195, DOI 10.1016/j.jvcir.2018.11.038
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2019, IEEE T NEUR NET LEAR, V30, P11, DOI 10.1109/TNNLS.2018.2829819
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   King DB, 2015, ACS SYM SER, V1214, P1
   Li YZ, 2017, AIP ADV, V7, DOI 10.1063/1.5010804
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2018, IEEE T SYST MAN CY-S, V48, P1521, DOI 10.1109/TSMC.2017.2676180
   Temel D, 2016, IEEE SIGNAL PROC LET, V23, P1414, DOI 10.1109/LSP.2016.2601119
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2019, J VIS COMMUN IMAGE R, V58, P353, DOI 10.1016/j.jvcir.2018.12.005
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Zhang L, 2014, IEEE MULTIMEDIA, V21, P67, DOI 10.1109/MMUL.2014.50
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5113, DOI 10.1109/TIP.2018.2851390
   Zhou WJ, 2019, J VIS COMMUN IMAGE R, V60, P305, DOI 10.1016/j.jvcir.2019.03.001
   Zuo LX, 2016, IEEE IMAGE PROC, P2082, DOI 10.1109/ICIP.2016.7532725
NR 41
TC 12
Z9 12
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102745
DI 10.1016/j.jvcir.2019.102745
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800012
DA 2024-07-18
ER

PT J
AU Hou, WJ
   Feng, GY
   Cheng, YT
AF Hou, Wenjun
   Feng, Guangyu
   Cheng, Yiting
TI A fuzzy interaction scheme of mid-air gesture elicitation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Natural interaction; Gesture elicitation; Fuzzy match; Guessibility
ID RECOGNITION; DESIGN; SYSTEM; DEEP
AB In a virtual assembly scenario, a semantic model of mid-air gesture interaction is established through a user-defined elicitation experiment. Considering the spatial-temporal continuity of the gesture movement, a fuzzy interaction scheme of gesture segments is proposed based on Trie Tree and Levenshtein distance. The experiment result proves that this design can effectively alleviate the effect of missing input sequences and recognition errors. Moreover, it helps relieve the memory load for users by establishing a close correlation of input actions. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hou, Wenjun; Cheng, Yiting] Beijing Univ Posts & Telecommun, Sch Digital Media & Design, Beijing 100876, Peoples R China.
   [Feng, Guangyu] Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.
   [Hou, Wenjun; Feng, Guangyu; Cheng, Yiting] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications; Beijing University of Posts &
   Telecommunications
RP Feng, GY (corresponding author), Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.
EM kinsney@bupt.edu.cn
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   Atta R, 2010, IEEE T CONSUM ELECTR, V56, P1542, DOI 10.1109/TCE.2010.5606295
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Basari, 2010, IEEE T VEH TECHNOL, V59, P4248, DOI 10.1109/TVT.2010.2066997
   BenAbdennour A, 1996, IEEE T ENERGY CONVER, V11, P394, DOI 10.1109/60.507651
   Bouënard A, 2011, COMPUT MUSIC J, V35, P57, DOI 10.1162/COMJ_a_00069
   Essabbah M, 2014, VIRTUAL REAL-LONDON, V18, P219, DOI 10.1007/s10055-014-0247-z
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Ibraheem N.A., 2012, INT J COMPUTER APPL, V50, P38
   Lea R, 2000, COMPUTER, V33, P35, DOI 10.1109/2.868695
   Lee WP, 2014, KNOWL-BASED SYST, V56, P167, DOI 10.1016/j.knosys.2013.11.007
   MATSUDA Y, 1995, ELECTROPHORESIS, V16, P261, DOI 10.1002/elps.1150160142
   Paradiso JA, 2003, COMMUN ACM, V46, P62, DOI 10.1145/792704.792731
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Takahashi T., 2010, SYST COMPUT JPN, V23, P38
   Wachs JP, 2008, J AM MED INFORM ASSN, V15, P321, DOI 10.1197/jamia.M241
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu Mingliang, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/298017910.1145/2980179.2982425
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang M., 2018, J VISUAL COMMUN IMAG, V53
   Zhou W, 2018, INT J NEXT-GENER COM, V9, P1
NR 25
TC 6
Z9 6
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102637
DI 10.1016/j.jvcir.2019.102637
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600030
DA 2024-07-18
ER

PT J
AU Ij, ZJ
   Feng, K
   Qian, YH
AF Ij, Zhangjian
   Feng, Kai
   Qian, Yuhua
TI Part-based visual tracking via structural support correlation filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Support vector machines; Correlation filter; Structural
   learning; Temporal consistency; Scale estimation
ID ROBUST
AB To better deal with the partial occlusion issue and improve their efficiency of part-based and support vector machines (SVM) based trackers, we propose a novel part-based structural support correlation filter tracking method, which absorbs the strong discriminative ability from SVM and the excellent property of part-based tracking methods which is less sensitive to partial occlusion. Then, our proposed model can learn the support correlation filter of each part jointly by a star structure model, which preserves the spatial layout structure among parts and tolerates outliers of parts. In addition, our model introduces inter-frame consistencies of local parts to mitigate the drift problem. Finally, our model can accurately estimate the scale changes of object by the relative distance change among reliable parts. The extensive empirical evaluations on three benchmark datasets: OTB2015, TempleColor128 and VOT2015 demonstrate that the proposed method achieves comparable performance against several state-of-the-art trackers and runs in real time. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ij, Zhangjian; Feng, Kai; Qian, Yuhua] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Shanxi, Peoples R China.
   [Ij, Zhangjian; Feng, Kai; Qian, Yuhua] Shanxi Univ, Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan, Shanxi, Peoples R China.
   [Ij, Zhangjian; Qian, Yuhua] Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan, Shanxi, Peoples R China.
C3 Shanxi University; Shanxi University; Shanxi University
RP Ij, ZJ (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Shanxi, Peoples R China.; Ij, ZJ (corresponding author), Shanxi Univ, Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan, Shanxi, Peoples R China.; Ij, ZJ (corresponding author), Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan, Shanxi, Peoples R China.
EM jizhangjian@sxu.edu.cn
RI Ji, Zhangjian/C-7757-2015
OI Ji, Zhangjian/0000-0002-8022-0518; Ji, Zhangjian/0000-0002-9407-2878
FU National Natural Science Foundation of China [61602288, 61703252];
   Shanxi Provincial Natural Science Foundation of China [201701D221102]
FX This work is supported by the National Natural Science Foundation of
   China Under Grant No. 61602288, 61703252 and Shanxi Provincial Natural
   Science Foundation of China Under Grant No. 201701D221102. The authors
   also would like to thank the anonymous reviewers for their valuable
   suggestions.
CR Akin O, 2016, J VIS COMMUN IMAGE R, V38, P763, DOI 10.1016/j.jvcir.2016.04.018
   [Anonymous], 2010, IEEE INT C COMP VIS
   [Anonymous], 2014, ECCV WORKSH
   [Anonymous], 2016, ARXIV160106032
   [Anonymous], 2005, BMVC
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cheng WC, 2012, IEEE INFOCOM SER, P864, DOI 10.1109/INFCOM.2012.6195835
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276
   Danelljan M., 2014, IEEE INT C COMP VIS
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Galoogahi H.K., 2015, IEEE INT C COMP VIS
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2013, IEEE I CONF COMP VIS, P2760, DOI 10.1109/ICCV.2013.343
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Ji Z, 2014, IEEE INT C MULT EXP, P1
   Ji Z., 2014, IEEE INT C IM PROC
   Ji ZJ, 2015, J VIS COMMUN IMAGE R, V28, P44, DOI 10.1016/j.jvcir.2015.01.008
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Lee CP, 2013, NEURAL COMPUT, V25, P1302, DOI 10.1162/NECO_a_00434
   Li C.-L., 2018, ARXIV PREPRINT ARXIV
   Li C, 2018, BDIOT 2018: PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON BIG DATA AND INTERNET OF THINGS, P80, DOI 10.1145/3289430.3289464
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lukezic A, 2018, IEEE T CYBERNETICS, V48, P1849, DOI 10.1109/TCYB.2017.2716101
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2011, PROC CVPR IEEE, P1257
   Montero AS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P587, DOI 10.1109/ICCVW.2015.80
   Nebehay G, 2015, PROC CVPR IEEE, P2784, DOI 10.1109/CVPR.2015.7298895
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151
   Sun X, 2017, IEEE I CONF COMP VIS, P5496, DOI 10.1109/ICCV.2017.586
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang K., 2014, ECCV
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
NR 52
TC 4
Z9 4
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102602
DI 10.1016/j.jvcir.2019.102602
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ko, KM
   Ko, PC
   Lin, SY
   Hong, Z
AF Ko, Kuo-Min
   Ko, Po-Chang
   Lin, Shih-Yang
   Hong, Zhen
TI Quality-guided image classification toward information management
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Convolutional neural network; Image retrieval; Image
   quality assessment
ID FRACTAL MODEL; FLUID-FLOW
AB Image information management (IIM) is a key technique to improve the performance of large-scale image retrieval. However, IIM is still a big challenge due to the large sum of image datasets and traditional algorithms cannot cope with this problem. In order to solve these disadvantages, we propose a novel image classification algorithm based on image quality assessment (IQA) for image information management. Specifically, we first incorporate both low-level, high-level features as well as quality scores for image representation, where we leverage convolution neural network for deep feature extraction. Then, deep feature vector can be generated by column-wise stacking. Thus, each image can be represented by a feature vector. We leverage GMM to learn the distribution of obtained feature vectors. Similar image categories have similar probability distributions, we leverage the learned GMM model to calculate the posterior probability and image can be classified into corresponding category. Experimental results demonstrate the performance of our proposed method, and image information management is easier to implement. (C) 2019 Published by Elsevier Inc.
C1 [Ko, Kuo-Min; Hong, Zhen] Yango Univ, Fuzhou 350015, Fujian, Peoples R China.
   [Ko, Po-Chang] Natl Kaohsiung Univ Sci & Technol, Dept Informat Management, Kaohsiung 807, Taiwan.
   [Lin, Shih-Yang] Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 807, Taiwan.
C3 National Kaohsiung University of Science & Technology; National
   Kaohsiung University of Science & Technology
RP Lin, SY (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 807, Taiwan.
EM kuomin@nkust.edu.tw; cobol@nkust.edu.tw; Lsy.msn@hotmail.com
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], ACTA PHARM SIN
   [Anonymous], SCI TECHNOL INNOV
   [Anonymous], ELECT TEST Z
   [Anonymous], COMPUT APPL
   [Anonymous], 2019, SCI TECHNOLOGY INNOV
   [Anonymous], SCI TECHNOL PHILOS
   [Anonymous], INF COMPUT THEOR EDI
   [Anonymous], J LIB SCI
   [Anonymous], HIGH TEACH J
   [Anonymous], COMPUT APPL RES
   [Anonymous], ACTA OPT SINICA
   [Anonymous], 2018, DIGITAL COMMUNICATIO
   [Anonymous], HEILONGJIANG SCI
   [Anonymous], MODERN ELECT TECHNOL
   [Anonymous], ELECT QUAL
   [Anonymous], MODERN ELECT TECHN
   [Anonymous], CHINA SCI TECHNOL IN
   [Anonymous], COMMAND CONTROL SIMU
   [Anonymous], ART EVALUAT
   [Anonymous], J MECH ENG
   [Anonymous], RES APPL DIGITAL COM
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Chang J, 2019, J VIS COMMUN IMAGE R, V58, P316, DOI 10.1016/j.jvcir.2018.11.047
   Ding SF, 2013, ARTIF INTELL REV, V39, P251, DOI 10.1007/s10462-011-9270-6
   Du YY, 2011, ENTERP INF SYST-UK, V5, P449, DOI 10.1080/17517575.2010.541943
   Du YY, 2009, INFORM SCIENCES, V179, P995, DOI 10.1016/j.ins.2008.11.025
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Liu RC, 2016, COMPUT GEOTECH, V75, P57, DOI 10.1016/j.compgeo.2016.01.025
   Liu RC, 2015, COMPUT GEOTECH, V65, P45, DOI 10.1016/j.compgeo.2014.11.004
   Liu W, 2012, ENTERP INF SYST-UK, V6, P95, DOI 10.1080/17517575.2011.617472
   Liu Yueming, 2019, ACTA OCEANOL SIN, V04, P119, DOI DOI 10.3969/j..0253-4193.2019.04.011
   Liu Z, 2016, IEEE T CYBERNETICS, V46, P524, DOI 10.1109/TCYB.2015.2405616
   Lu W, 2018, JCO PRECIS ONCOL, V2, P1, DOI 10.1200/PO.17.00168
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Tian Junfeng, 2019, CHINESE J COMPUT, P1
   Wang F, 2018, IEEE T CYBERNETICS, V48, P1839, DOI 10.1109/TCYB.2017.2715980
   Wang F, 2017, IEEE T CYBERNETICS, V47, P1795, DOI 10.1109/TCYB.2016.2623898
   Wang Z, 2012, NEUROCOMPUTING, V83, P83, DOI 10.1016/j.neucom.2011.11.018
   [王中任 Wang Zhongren], 2019, [激光与红外, Laser and Infrared], V49, P246
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Zhang LX, 2017, IEEE T CYBERNETICS, V47, P1028, DOI 10.1109/TCYB.2016.2536748
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang WH, 2008, INT J INNOV COMPUT I, V4, P689
   Zhang ZY, 2014, IEEE T NEUR NET LEAR, V25, P1704, DOI 10.1109/TNNLS.2013.2288943
   Zou L, 2017, IEEE T NEUR NET LEAR, V28, P1139, DOI 10.1109/TNNLS.2016.2524621
NR 47
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102594
DI 10.1016/j.jvcir.2019.102594
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200025
DA 2024-07-18
ER

PT J
AU Shakeel, MS
   Lam, KM
   Lai, SC
AF Shakeel, M. Saad
   Lam, Kin-Man
   Lai, Shun-Cheung
TI Learning sparse discriminant low-rank features for low-resolution face
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Feature fusion; Local features; Low rank
   approximation; Linear regression; Sparse coding
ID IMAGE SUPERRESOLUTION; REPRESENTATION; CLASSIFICATION; DECOMPOSITION;
   HALLUCINATION; EIGENFACES; SCALE
AB In this paper, we propose a novel approach for low-resolution face recognition, under uncontrolled settings. Our approach first decomposes a multiple of extracted local features into a set of representative basis (low-rank matrix) and sparse error matrix, and then learns a projection matrix based on our proposed sparse-coding-based algorithm, which preserves the sparse structure of the learned low-rank features, in a low-dimensional feature subspace. Then, a coefficient vector, based on linear regression, is computed to determine the similarity between the projected gallery and query image's features. Furthermore, a new morphological pre-processing approach is proposed to improve the visual quality of images. Our experiments were conducted on five available face-recognition datasets, which contain images with variations in pose, facial expressions and illumination conditions. Experiment results show that our method outperforms other state-of-the-art low-resolution face recognition methods in terms of recognition accuracy. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Shakeel, M. Saad] Guangdong Univ Petrochem Technol, Sch Automat, Maoming, Peoples R China.
   [Shakeel, M. Saad; Lam, Kin-Man; Lai, Shun-Cheung] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Hong Kong, Peoples R China.
C3 Guangdong University of Petrochemical Technology; Hong Kong Polytechnic
   University
RP Shakeel, MS (corresponding author), Guangdong Univ Petrochem Technol, Sch Automat, Maoming, Peoples R China.; Shakeel, MS (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Hong Kong, Peoples R China.
EM 15902620r@connect.polyu.hk; enkmlam@polyu.edu.hk;
   shun-cheung.lai@connect.polyu.hk
FU GRF Grant of the Hong Kong SAR Government [PolyU 152765/16E, B-Q55J]
FX The work described in this paper was supported by the GRF Grant PolyU
   152765/16E (project code: B-Q55J) of the Hong Kong SAR Government.
CR [Anonymous], 2007, 0749 U MASS
   [Anonymous], P INT C PATT REC
   [Anonymous], 2016, PROC 10 EUR C ANTENN
   [Anonymous], 2014, 14117923 ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bereta M, 2013, J VIS COMMUN IMAGE R, V24, P1213, DOI 10.1016/j.jvcir.2013.08.004
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Chellappa R, 2012, PATTERN RECOGN LETT, V33, P1849, DOI 10.1016/j.patrec.2011.11.020
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Chen J, 2017, IMAGE VISION COMPUT, V64, P34, DOI 10.1016/j.imavis.2017.05.006
   Chu YJ, 2017, SIGNAL PROCESS, V141, P144, DOI 10.1016/j.sigpro.2017.05.012
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hennings-Yeomans P. H., 2008, IEEE INT C COMPUTER, P1
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Hu Y, 2011, IEEE T IMAGE PROCESS, V20, P433, DOI 10.1109/TIP.2010.2063437
   Huang H, 2011, IEEE T NEURAL NETWOR, V22, P121, DOI 10.1109/TNN.2010.2089470
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Lin Z., 2009, UIUC TECHNICAL REPOR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Okajima K, 1998, NEURAL NETWORKS, V11, P441, DOI 10.1016/S0893-6080(98)00007-0
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pong KH, 2014, PATTERN RECOGN, V47, P556, DOI 10.1016/j.patcog.2013.08.023
   Qiu GP, 2000, J VIS COMMUN IMAGE R, V11, P360, DOI [10.1006/jvci.2000.0451, 10.1006/jvci.1999.0451]
   Qiu GP, 1999, IEEE T IMAGE PROCESS, V8, P109, DOI 10.1109/83.736699
   Ren CX, 2012, IEEE T IMAGE PROCESS, V21, P3770, DOI 10.1109/TIP.2012.2192285
   Shi JG, 2015, IEEE SIGNAL PROC LET, V22, P554, DOI 10.1109/LSP.2014.2364262
   Siena S, 2012, LECT NOTES COMPUT SC, V7584, P240, DOI 10.1007/978-3-642-33868-7_24
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Y, 2011, EVID-BASED COMPL ALT, V2011, P1, DOI 10.1093/ecam/nen087
   Wang ZY, 2015, NEURAL COMPUT APPL, V26, P1645, DOI 10.1007/s00521-015-1834-y
   Wei CP, 2014, IEEE T IMAGE PROCESS, V23, P3294, DOI 10.1109/TIP.2014.2329451
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xing XL, 2016, SIGNAL PROCESS, V125, P329, DOI 10.1016/j.sigpro.2016.02.009
   Yang FW, 2018, IEEE SIGNAL PROC LET, V25, P388, DOI 10.1109/LSP.2017.2746658
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yoo CH, 2017, J VIS COMMUN IMAGE R, V45, P11, DOI 10.1016/j.jvcir.2017.02.009
   Zhang JQ, 2016, LECT NOTES COMPUT SC, V9810, P661, DOI 10.1007/978-3-319-42911-3_55
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang LH, 2012, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2012.6466948
   Zhang SQ, 2014, J VIS COMMUN IMAGE R, V25, P1878, DOI 10.1016/j.jvcir.2014.09.011
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 68
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102590
DI 10.1016/j.jvcir.2019.102590
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200022
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yang, YK
   Jiao, SJ
   Wang, WF
AF Yang, Yikun
   Jiao, Shengjie
   Wang, Wenfa
TI Cooperative media control parameter optimization of the integrated
   mixing and paving machine based on the fuzzy cuckoo search algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Integrated mixing and paving machine; Cooperative control; Cuckoo
   search; Fuzzy logic
AB First, this paper studies the MOH material mixing and paving equipment technology, and quantifies the correlations between each variable through the data fitting based on massive experimental data. Then, with the operation speed as the design variable and yielding the maximum mixing efficiency, minimum slip ratio and highest measuring accuracy as the three performance optimization objectives, an operation speed optimization model for the integrated mixer and paver has been built. Moreover, the principles and workflows of the cuckoo search are investigated, the population diversity and convergence rate of the cuckoo search are improved by using the fuzzy logic, and subsequently the operation speed optimization model is solved using the modified cuckoo search. At last, a simulation test based on MATLAB is carried out for validation. Research results show that the optimization results based on the modified cuckoo search algorithm excels those of frequently-used optimization algorithms such as the conventional cuckoo search and genetic algorithm. Also, the comparison between the cases of the optimized and standard operation speeds show that the mixing efficiency of the integrated mixing and paving machine can grow by 15.3%; the slip ratio drops by 54.2%; the measuring accuracy rises by 18.2%. (C) 2019 Published by Elsevier Inc.
C1 [Yang, Yikun; Jiao, Shengjie] Changan Univ, Natl Engn Lab Highway Maintenance Equipment, Xian 710064, Shaanxi, Peoples R China.
   [Yang, Yikun; Wang, Wenfa] Yanan Univ, Sch Math & Comp Sci, Yanan 716000, Shanxi, Peoples R China.
C3 Chang'an University; Yanan University
RP Yang, YK (corresponding author), Changan Univ, Natl Engn Lab Highway Maintenance Equipment, Xian 710064, Shaanxi, Peoples R China.
EM yangyikun_edu@sina.com
FU National Natural Science Foundation of China [51805041]; Fundamental
   Research Funds for the Central Universities of Chang'an University
   [300102259204]
FX We appreciate the supports from the National Natural Science Foundation
   of China (No. 51805041) and the Fundamental Research Funds for the
   Central Universities of Chang'an University (No. 300102259204).
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Chang J, 2019, J VIS COMMUN IMAGE R, V58, P316, DOI 10.1016/j.jvcir.2018.11.047
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Feng Zhongxu, 2006, J CHINESE HIGHWAY, P19
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Hu Xin-xin, 2013, Computer Engineering and Design, V34, P3639
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Li Wen, 2007, RES EMBEDDED CONTROL
   [李煜 Li Yu], 2012, [系统工程, Systems Engineering], V30, P64
   Lu Ren, 2016, FUZZY CUCKOO SEARCH
   Na Li, 2014, J BASIC SCI TEXTILE, V27, P374
   Shan Gen-li, 2014, Advanced Materials Research, V971-973, P1125, DOI 10.4028/www.scientific.net/AMR.971-973.1125
   Shen D. H., 2004, INT IEEE C INT TRANS
   Vickers Jr Thomas M., 2005, RESEARCH, V25, P1882
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu Shilin, 2017, ROAD CONSTR MACH CON, V03, P34
   Zhang D, 2018, WATER RESOUR MANAG, V32, P2079, DOI 10.1007/s11269-018-1919-3
NR 22
TC 1
Z9 1
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102591
DI 10.1016/j.jvcir.2019.102591
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200029
DA 2024-07-18
ER

PT J
AU Jin, LH
   Zhang, WH
   Ma, GZ
   Song, EM
AF Jin, Lianghai
   Zhang, Wenhua
   Ma, Guangzhi
   Song, Enmin
TI Learning deep CNNs for impulse noise removal in images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image; Impulse noise; Convolution neural network; Denoising
ID MEDIAN FILTER; SPARSE; REPRESENTATION; DECOMPOSITION; DIFFUSION;
   DETECTOR; MATRIX
AB Deep learning has been widely applied in image processing and computer vision due to its powerful learning capability. Although some learning models have been proposed to suppress noise in images, most of them are developed for Gaussian noise and few are for impulse noise. This paper proposes an image recovery method based on deep convolutional neural networks for impulse noise removal. The proposed framework falls into two components: a classifier network which divides image pixels into noisy and noise-free, and a regression network which is trained for image reconstruction. In the regression network, the noise-free pixels identified by the classifier network together with the original noisy image are used for recovery of the noisy image. Furthermore, batch normalization is embedded to the network to improve denoising performance. Experimental results show that the proposed method can excellently remove impulse noise, providing clear performance improvements over other state-of-theart denoising methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Jin, Lianghai; Zhang, Wenhua; Ma, Guangzhi; Song, Enmin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Ma, GZ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM guangzhima.hust@gmail.com
FU National Natural Science Foundation of China [61370181]
FX The authors would like to thank Dr. Kyong Hwan Jin for providing the
   program for the algorithm ALOHA [29]. This work is supported by the
   National Natural Science Foundation of China under Grant No. 61370181.
CR Ananthi VP, 2016, SIGNAL PROCESS, V121, P81, DOI 10.1016/j.sigpro.2015.10.030
   Arashloo SR, 2017, J VIS COMMUN IMAGE R, V43, P89, DOI 10.1016/j.jvcir.2016.12.015
   Burger H., 2012, CVPR
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fathi A, 2012, IEEE T IMAGE PROCESS, V21, P3981, DOI 10.1109/TIP.2012.2200491
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Greenberg S, 2006, PATTERN RECOGN LETT, V27, P59, DOI 10.1016/j.patrec.2005.07.001
   Hosseini H, 2015, IEEE SIGNAL PROC LET, V22, P1050, DOI 10.1109/LSP.2014.2381649
   Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jin KH, 2018, IEEE T IMAGE PROCESS, V27, P1448, DOI 10.1109/TIP.2017.2771471
   Jin LH, 2017, J VIS COMMUN IMAGE R, V48, P54, DOI 10.1016/j.jvcir.2017.05.012
   Kaliraj G, 2010, IMAGE VISION COMPUT, V28, P458, DOI 10.1016/j.imavis.2009.07.007
   Kingma D. P., 2014, arXiv
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Liang SF, 2008, IEEE T FUZZY SYST, V16, P863, DOI 10.1109/TFUZZ.2008.917297
   Lin TC, 2012, NEURAL COMPUT APPL, V21, P695, DOI 10.1007/s00521-011-0648-9
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nair MS, 2013, SIGNAL IMAGE VIDEO P, V7, P1041, DOI 10.1007/s11760-012-0310-8
   Nair V., 2010, P 27 INT C MACHINE L, P807
   NIEMINEN A, 1987, IEEE T PATTERN ANAL, V9, P74, DOI 10.1109/TPAMI.1987.4767873
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Remenyi N, 2014, IEEE T IMAGE PROCESS, V23, P5165, DOI 10.1109/TIP.2014.2362058
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Shi KH, 2016, NEUROCOMPUTING, V173, P659, DOI 10.1016/j.neucom.2015.08.012
   Turkmen I, 2016, J VIS COMMUN IMAGE R, V34, P28, DOI 10.1016/j.jvcir.2015.10.011
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang HY, 2017, IEEE T MULTIMEDIA, V19, P969, DOI 10.1109/TMM.2016.2638624
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P2428, DOI 10.1109/TIP.2011.2131664
   Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5
   Zhang JJ, 2018, J VIS COMMUN IMAGE R, V55, P640, DOI 10.1016/j.jvcir.2018.07.011
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 48
TC 33
Z9 36
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 193
EP 205
DI 10.1016/j.jvcir.2019.05.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600018
DA 2024-07-18
ER

PT J
AU Wang, XY
   Zhang, SY
   Wang, L
   Yang, HY
   Niu, PP
AF Wang Xiang-yang
   Zhang Si-yu
   Wang Li
   Yang Hong-ying
   Niu Pan-pan
TI Locally optimum image watermark decoder by modeling NSCT domain
   difference coefficients with vector based Cauchy distribution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking; NSCT difference coefficient; Vector based Cauchy
   distribution; Second-kind statistics; Locally most powerful test
ID HIDDEN MARKOV MODEL; CONTOURLET TRANSFORM; DETECTOR
AB Improving the ability of imperceptibility, watermark capacity, and robustness at the same time still remains a challenge within the digital image watermarking community. By modeling the robust nonsub-sampled Contourlet transform (NSCT) difference coefficients with vector based Cauchy distribution and employing locally most powerful (LMP) test, we propose a locally optimum image watermark decoder in NSCT domain. We first compute the difference coefficients according to the inter-scale dependency between NSCT coefficients, and investigate the robustness of the NSCT difference coefficients by subjective visual error and objective mean squared error (MSE) terms. We then embed the digital watermark into the significant NSCT difference subband with highest energy by modifying the robust NSCT difference coefficients. At the receiver, by combining the vector based Cauchy probability distribution and LMP test, we propose a locally optimum blind watermark decoder in the NSCT domain. Here, robust NSCT difference coefficients are firstly modeled by employing the vector based Cauchy probability density function (PDF), where the Cauchy marginal statistics and various strong dependencies of NSCT coefficients are incorporated. Then the statistical model parameters of vector based Cauchy PDF are estimated using second-kind statistics approach. And finally a blind image watermark decoder is developed using vector based Cauchy PDF and LMP decision rule. We conduct extensive experiments to evaluate the performance of the proposed blind watermark decoder, in which encouraging results validate the effectiveness of the proposed technique, in comparison with the state-of-the-art approaches recently proposed in the literature. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang Xiang-yang; Zhang Si-yu; Wang Li; Yang Hong-ying; Niu Pan-pan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Niu Pan-pan] Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Niu Pan-pan] Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Niu, PP (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; niupanpan3333@163.com
RI Niu, Panpan/Q-9953-2017; Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863; Zhang, siyu/0000-0002-0001-0204
FU National Natural Science Foundation of China [61701212, 61472171]; China
   Postdoctoral Science Foundation [2017M621135, 2018T110220]; High-level
   Innovation Talents Foundation of Dalian [2017RQ055]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61701212 & 61472171), China Postdoctoral
   Science Foundation (No. 2017M621135, 2018T110220), and High-level
   Innovation Talents Foundation of Dalian (No. 2017RQ055).
CR Achim A, 2006, IEEE T IMAGE PROCESS, V15, P2686, DOI 10.1109/TIP.2006.877362
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Bian Y, 2013, IET IMAGE PROCESS, V7, P281, DOI 10.1049/iet-ipr.2012.0345
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Briassouli A, 2004, IEEE T IMAGE PROCESS, V13, P1604, DOI 10.1109/TIP.2004.837516
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Erfani Y, 2017, IEEE T INF FOREN SEC, V12, P840, DOI 10.1109/TIFS.2016.2636094
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   FISHER NI, 1985, BIOMETRIKA, V72, P253
   Hill P.R., 2016, 2016 IEEE INT C IM P
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Khawne A, 2015, IEEJ T ELECTR ELECTR, V10, P149, DOI 10.1002/tee.22047
   Kwitt R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P33, DOI 10.1145/1411328.1411337
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Reath J, 2018, COMPUTATION STAT, V33, P339, DOI 10.1007/s00180-017-0738-y
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Tsihrintzis GA, 1996, IEEE T SIGNAL PROCES, V44, P1492, DOI 10.1109/78.506614
   Valizadeh A, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-88
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 37
TC 27
Z9 27
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 309
EP 329
DI 10.1016/j.jvcir.2019.05.012
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600030
DA 2024-07-18
ER

PT J
AU Chang, WY
AF Chang, Wu-Yeh
TI Research on sports video image based on fuzzy algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fuzzy clustering algorithm; Image segmentation; Membership; Motion video
ID FEATURE-EXTRACTION; ZERNIKE MOMENTS; SELECTION; OBJECTS; DEEP;
   RECONSTRUCTION; INVARIANT; RANGE
AB With the rapid development of network and multimedia technology, a large number of sports and national fitness information are stored in various fitness guidance systems in the form of video and pictures. In order to better promote public fitness and facilitate learning and viewing, sports video has a variety of needs of editing, segmentation and integration. Aiming at the shortcomings of current sports video image segmentation methods, such as rough segmentation results and high spatial distortion rate, a sports video image segmentation method based on fuzzy clustering algorithm is proposed. This paper introduces the basic theory of fuzzy clustering algorithm, establishes second-order fuzzy attributes with normal distribution and gray value by means of time-domain difference images, assigns the fuzzy attribute S membership function, then performs fuzzy clustering on time-domain difference images, and obtains the segmentation results of moving video images by edge detection. The experimental results show that the method has high spatial accuracy, good noise iteration performance and low spatial distortion rate, and can accurately segment complex moving video images to obtain high-definition images. (C) 2019 Published by Elsevier Inc.
C1 [Chang, Wu-Yeh] Univ Taipei, Dept Ball Sports, 101,Sec 2,Zhongcheng Rd, Taipei 111, Taiwan.
C3 University of Taipei
RP Chang, WY (corresponding author), Univ Taipei, Dept Ball Sports, 101,Sec 2,Zhongcheng Rd, Taipei 111, Taiwan.
EM soccer@utaipei.edu.tw
CR Ai L, 2018, OPT COMMUN, V410, P871, DOI 10.1016/j.optcom.2017.11.032
   Amoon M, 2014, J INDIAN SOC REMOTE, V42, P483, DOI 10.1007/s12524-013-0344-6
   Cecil J., 2017, SYST C
   Chandy DA, 2017, MED BIOL ENG COMPUT, V55, P493, DOI 10.1007/s11517-016-1513-x
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   De-Deus G, 2014, J ENDODONT, V40, P271, DOI 10.1016/j.joen.2013.07.025
   Fujimoto R., 2014, IIAI INT C ADV APPL
   Han DR, 2014, MATH COMPUT, V83, P2263, DOI 10.1090/S0025-5718-2014-02829-9
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han Junwei, 2014, IEEE T GEOSCI REMOTE, V53, P1515
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Han LH, 2014, IEEE T MED IMAGING, V33, P682, DOI 10.1109/TMI.2013.2294539
   Hegarty J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601174
   Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661260
   Köhler T, 2015, MED IMAGE ANAL, V24, P220, DOI 10.1016/j.media.2015.06.011
   Liang JZ, 2014, IET IMAGE PROCESS, V8, P528, DOI 10.1049/iet-ipr.2013.0006
   Liu D, 2014, FOOD BIOPROCESS TECH, V7, P307, DOI 10.1007/s11947-013-1193-6
   Liu L, 2014, OPTIK, V125, P5327, DOI 10.1016/j.ijleo.2014.06.062
   Milan S., 2014, J ELECTRON IMAGING, Vxix, P685
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI [10.1145/2775054.2694364, 10.1145/2694344.2694364]
   Naito T, 2017, J NEUROSCI METH, V291, P141, DOI 10.1016/j.jneumeth.2017.08.014
   Russ J.C., 2017, COMPUT PHYS, V8, P177
   Schlüter S, 2014, WATER RESOUR RES, V50, P3615, DOI 10.1002/2014WR015256
   Wang Cheng, 2014, Journal of Chinese Computer Systems, V35, P1662
   Yang WY, 2015, IET RADAR SONAR NAV, V9, P783, DOI 10.1049/iet-rsn.2014.0281
   Yao Qin, 2014, J AUTOMAT, V40, P1184
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Zaher A, 2017, J PHYS CONF SER, V783, DOI 10.1088/1742-6596/783/1/012058
   Zeng YL, 2014, OPTIK, V125, P3733, DOI 10.1016/j.ijleo.2014.01.135
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhanwu Peng, 2014, Advanced Materials Research, V1044-1045, P1366, DOI 10.4028/www.scientific.net/AMR.1044-1045.1366
   2014, APPL MECH MAT, V474, P173, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.474.173
   2014, IEEE T FUZZY SYST, V22, P1515, DOI DOI 10.1109/TFUZZ.2013.2297159
NR 43
TC 5
Z9 5
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 105
EP 111
DI 10.1016/j.jvcir.2019.02.033
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100011
DA 2024-07-18
ER

PT J
AU Nguyen, DV
   Tran, HTT
   Thang, TC
AF Nguyen, D. V.
   Tran, Huyen T. T.
   Truong Cong Thang
TI A client-based adaptation framework for 360-degree video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Virtual reality; 360-degree videos; Framework; Adaptive streaming
ID HTTP
AB 360-degree video is one of the key components of Virtual Reality (VR) applications. 360-degree videos viewed on Head Mounted Displays can offer impressive viewing experiences to users. Yet, streaming of 360-degree videos over the Internet is a very challenging task since it requires extremely high bandwidth. To reduce the bandwidth requirement while still providing good experiences, viewport adaptive streaming has been introduced. In this paper, we propose a client-based adaptation framework for view port adaptive streaming of 360 videos, which can support different application scenarios. The key components and important issues are presented with a general problem formulation for tile version selection. Especially, we introduce for the first time the use of bitrate and quality estimation in viewport adaptive streaming of 360 videos. Experiments show that the proposed framework can significantly improve video quality for users. In addition, the impacts of buffering delay and projection formats in VR context are investigated. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Nguyen, D. V.; Tran, Huyen T. T.; Truong Cong Thang] Univ Aizu, Aizu Wakamatsu, Fukushima 9658580, Japan.
C3 University of Aizu
RP Nguyen, DV (corresponding author), Univ Aizu, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM nvduc712@gmail.com; thang@u-aizu.ac.jp
RI Nguyen, Duc/AAD-8017-2022
OI Nguyen, Duc/0000-0003-1122-0650; Huyen, Tran Thi
   Thanh/0000-0002-8620-1844
CR Ahmadi H, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P170, DOI 10.1145/3126686.3126743
   Alface PR, 2012, BELL LABS TECH J, V16, P135, DOI 10.1002/bltj.20538
   [Anonymous], 2016, JOINT VID EXPL TEAM
   [Anonymous], OPENTRACK HEAD TRACK
   [Anonymous], F DEV
   [Anonymous], 2017, P 27 NOSSDAV, DOI DOI 10.1145/3083165.3083180
   [Anonymous], JT VID EXPL TEAM ITU
   [Anonymous], 2017, P 2017 9 INT C QUAL
   Bae TM, 2006, ETRI J, V28, P239, DOI 10.4218/etrij.06.0205.0126
   Corbillon X., 2017, ARXIV160908042, P1, DOI [10.1145/2557642.2557652, DOI 10.1145/2557642.2557652]
   Graf M, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P261, DOI 10.1145/3083187.3084016
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.45, 10.1109/ISM.2016.0028]
   Huang Chun-Ying, 2013, P 4 ACM MULT SYST C, P36, DOI DOI 10.1145/2483977.2483981
   JVET, 2016, 360Lib
   Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P583, DOI [10.1109/ISM.2016.0126, 10.1109/ISM.2016.143]
   Le HT, 2017, IEICE T COMMUN, VE100B, P901, DOI 10.1587/transcom.2016EBP3250
   Le HT, 2017, IEICE T INF SYST, VE100D, P379, DOI 10.1587/transinf.2016EDL8172
   Nguyen DV, 2017, IEEE INT SYM MULTIM, P38, DOI 10.1109/ISM.2017.16
   Nguyen DV, 2016, IEICE COMMUN EXPRESS, V5, P69, DOI 10.1587/comex.2015XBL0177
   Nguyen DV, 2016, INT CONF UBIQ FUTUR, P972, DOI 10.1109/ICUFN.2016.7536942
   Niamut OA, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P46, DOI 10.1145/2910017.2910606
   Qian F., 2016, Proceedings of the 5th Workshop on All Things Cellular: Operations, Applications and Challenges, P1, DOI DOI 10.1145/2980055.2980056
   Rizzo Luigi., 1997, ACM COMPUTER COMMUNI, V27, P31, DOI DOI 10.1145/251007.251012
   Skupin R, 2016, IEEE INT SYM MULTIM, P399, DOI [10.1109/ISM.2016.0089, 10.1109/ISM.2016.137]
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tran H.T., 2017, IEEE INT WORKSH MULT, P1
   Tran HTT, 2018, IEICE T INF SYST, VE101D, P28, DOI 10.1587/transinf.2017MUP0011
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Thang TC, 2013, J COMMUN NETW-S KOR, V15, P635, DOI 10.1109/JCN.2013.000112
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zare A., 2016, P 24 ACM INT C MULT, P601, DOI DOI 10.1145/2964284.2967292
NR 33
TC 12
Z9 13
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 231
EP 243
DI 10.1016/j.jvcir.2019.01.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600024
DA 2024-07-18
ER

PT J
AU Mun, J
   Jang, Y
   Nam, Y
   Kim, J
AF Mun, Junwon
   Jang, Yuneseok
   Nam, Yoojun
   Kim, Jaeseok
TI Edge-enhancing bi-histogram equalisation using guided image filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Histogram equalisation; Contrast enhancement; Brightness preservation;
   Edge enhancement; Guided image filter
ID ENHANCEMENT
AB Histogram equalisation (HE) is a simple and effective contrast enhancement method. However, it has certain drawbacks, namely, brightness inconsistency, over-enhancement, and noise amplification. In addition, there is structure information loss while processing HE. To overcome those drawbacks simultaneously, we propose a novel edge enhancing bi-histogram equalisation method using guided image filter. In the proposed algorithm, a new adaptive plateau limit and a new edge-enhancing transformation function are proposed. The adaptive plateau limit makes the method robust to various histogram distributions, and the edge-enhancing transformation enhances edges while suppressing noise amplification in the flat region. The performance of the various HE algorithms are evaluated both quantitatively and qualitatively. The qualitative assessment shows that the proposed algorithm avoids over-enhancement and noise amplification, effectively. In addition, the quantitative metrics show that the proposed algorithm outperforms the existing HE algorithms in terms of local contrast, discrete entropy, and perceptual sharpening index. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Mun, Junwon; Jang, Yuneseok; Nam, Yoojun; Kim, Jaeseok] Yonsei Univ, Dept Elect & Elect Engn, 50 Yonsei Ro, Seoul, South Korea.
C3 Yonsei University
RP Kim, J (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, 50 Yonsei Ro, Seoul, South Korea.
EM jaekim@yosnei.ac.kr
FU Ministry of Trade, Industry & Energy (MOTIE, Korea) under Industrial
   Technology Innovation Program [10080619]
FX This material is based upon work supported by the Ministry of Trade,
   Industry & Energy (MOTIE, Korea) under Industrial Technology Innovation
   Program (10080619).
CR Agarwal M, 2018, PROCEDIA COMPUT SCI, V125, P149, DOI 10.1016/j.procs.2017.12.021
   [Anonymous], 2018, DIGITAL IMAGE PROCES
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Feichtenhofer C, 2013, IEEE SIGNAL PROC LET, V20, P379, DOI 10.1109/LSP.2013.2248711
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lamberti F, 2006, IEEE T CONSUM ELECTR, V52, P966, DOI 10.1109/TCE.2006.1706495
   Lim SH, 2015, SIGNAL IMAGE VIDEO P, V9, P675, DOI 10.1007/s11760-013-0500-z
   Liu YF, 2017, IEEE T CIRC SYST VID, V27, P1171, DOI 10.1109/TCSVT.2016.2527338
   Liu YF, 2016, INFORM SCIENCES, V370, P323, DOI 10.1016/j.ins.2016.07.032
   Ma JX, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540186
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Parihar AS, 2017, IEEE T IMAGE PROCESS, V26, P1810, DOI 10.1109/TIP.2017.2665975
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Shin J, 2015, IEEE SIGNAL PROC LET, V22, P1293, DOI 10.1109/LSP.2015.2399612
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Yang Y, 2010, ELECTRON LETT, V46, P120, DOI 10.1049/el.2010.2063
   [No title captured]
NR 28
TC 23
Z9 25
U1 3
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 688
EP 700
DI 10.1016/j.jvcir.2018.12.037
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100065
DA 2024-07-18
ER

PT J
AU Yu, ST
   Jung, C
AF Yu, Shengtao
   Jung, Cheolkon
TI Adaptive perceptual quantizer for high dynamic range video compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Adaptive transfer function; High dynamic range; Perceptual
   quantizer; Perceptual uniformity
AB Although high dynamic range (HDR) videos are a very fascinating way to represent real-world scenes, they need a huge amount of memory to store and transmit due to the high bit-depth. Thus, it is a major challenge for HDR video coding to efficiently compress them without sacrificing perceptual quality. Perceptual Quantizer (PQ) transfer function provides a solution to this problem, which is adopted as the HEVC Main 10 Profile-based Anchor. However, PQ is not adaptive to HDR contents, thus reducing the coding efficiency. In this paper, we propose adaptive transfer function based on PQ for HDR video compression, called adaptive PQ. Different from PQ which uses a fixed mapping curve from luminance to luma, the proposed transfer function adaptively maps luminance to luma according to HDR contents. Thus, adaptive PQ is able to efficiently utilize possible luma values. Moreover, adaptive PQ achieves better perceptual uniformity in the luminance range than PQ. Experimental results demonstrate that adaptive PQ achieves a significant performance improvement in HDR video coding over PQ in terms of visual quality and bitrate. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yu, Shengtao; Jung, Cheolkon] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Jung, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM zhengzk@xidian.edu.cn
RI Yu, Shengtao/K-3600-2015
FU National Natural Science Foundation of China [61271298, 61872280];
   International S&T Cooperation Program of China [2014DFG12780]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61271298 and 61872280) and the International S&T Cooperation
   Program of China (No. 2014DFG12780).
CR Andersson K., 2015, 113 MPEG M GEN OCT
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 114 MPEG M SAN DIEG
   Association of Radio Industries and Businesses, 2015, B67 ARIB
   Aydin T. O., 2008, P SOC PHOTO-OPT INS
   Aydin TO, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866187
   Azimi M., 2014, INT C MULT SIGN PROC, P801
   Banitalebi-Dehkordi A, 2014, 2014 10TH INTERNATIONAL CONFERENCE ON HETEROGENEOUS NETWORKING FOR QUALITY, RELIABILITY, SECURITY AND ROBUSTNESS (QSHINE), P8, DOI [10.4108/icst.qshine.2014.256318, 10.1109/QSHINE.2014.6928652]
   Barten PGJ, 2004, P SOC PHOTO-OPT INS, V5294, P231, DOI 10.1117/12.537476
   Baylon D., 2015, 112 MPEG M WARS JUN
   Bjeintegaard G., 2010, P 13 VCEG M ITU T Q
   Boitard R., 2015, P SOC PHOTO-OPT INS, V9394
   Borer T., 2014, NONLINEAR OPTOELECTR
   Fogg C., 2016, 114 MPEG M SAN DIEG
   Francois E., 2015, 112 MPEG M WARS JUN
   François E, 2016, IEEE T CIRC SYST VID, V26, P63, DOI 10.1109/TCSVT.2015.2461911
   Garbas JU, 2011, INT CONF ACOUST SPEE, P829
   Gu Z., 2016, 114 MPEG M SAN DIEG
   Hanhart P., 2016, 114 MPEG M SAN DIEG
   ITU Telecommunication Standardization, 2016, HIGH EFF VID COD TEL
   Kains F., 2003, P ACM SIGGRAPH SKETC
   Kim J., 2016, 114 MPEG M SAN DIEG
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Larson GregW., 1992, GRAPHICS GEMS 2, P80, DOI [10.1016/B978-0-08-050754-5.50025-6, DOI 10.1016/B978-0-08-050754-5.50025-6]
   Le Pendu M, 2014, EUR SIGNAL PR CONF, P1612
   Liu Y, 2017, IEEE INT C INTELL TR
   Lu T., 2016, 114 MPEG M SAN DIEG
   Luthra A., 2015, 111 MPEG M GEN FEBR
   Mai ZC, 2011, IEEE T IMAGE PROCESS, V20, P1558, DOI 10.1109/TIP.2010.2095866
   Mantiuk R, 2004, ACM T GRAPHIC, V23, P733, DOI 10.1145/1015706.1015794
   MANTIUK R, 2006, P SOC PHOTO-OPT INS, V6057, P311
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Miller S., 2013, SMPTE Motion Imaging Journal, V122, P52
   Motra A, 2010, IEEE IMAGE PROC, P2061, DOI 10.1109/ICIP.2010.5654069
   Myszkowski K., 2008, HIGH DYNAMIC RANGE V
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Oh H. M., 2016, 114 MPEG M SAN DIEG
   Ozcinar C, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P43, DOI 10.1109/DMIAF.2016.7574900
   Poynton C, 2014, COLOR RES APPL, V39, P6, DOI 10.1002/col.21768
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rusanovskyy D., 2016, 114 MPEG M SAN DIEG
   Segall A., 2016, 114 MPEG M SAN DIEG
   Segall A, 2007, IEEE IMAGE PROC, P1
   Society of Motion Picture and Television Engineers, 2014, 2084 FCD ST
   StrOm J., 2015, 112 MPEG M WARS JUN
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Topiwala P, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P17, DOI 10.1109/DMIAF.2016.7574893
   Tourapis A. M., 2015, 112 MPEG M WARS JUN
   Yin P., 2015, 111 MPEG M SWITZ FEB
   Yin P., 2015, 112 MPEG M WARS JUN
   Yu S., 2016, P IEEE VCIP
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhang Y, 2011, IEEE IMAGE PROC, P1321, DOI 10.1109/ICIP.2011.6115679
   Zhao J., 2015, 113 MPEG M GEN OCT
NR 56
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 25
EP 36
DI 10.1016/j.jvcir.2018.11.016
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100003
DA 2024-07-18
ER

PT J
AU Zhi, H
   Liu, SY
AF Zhi, Hui
   Liu, Sanyang
TI Face recognition based on genetic algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Genetic algorithm; Principal component analysis;
   Support vector machine
ID IDENTIFICATION
AB The development of computer technology has led to the development of face recognition technology. Nowadays, face recognition technology has been successfully applied in many fields with the help of computer technology and network technology. This paper establishes an effective face recognition model based on principal component analysis, genetic algorithm and support vector machine, in which principal component analysis is used to reduce feature dimension, genetic algorithm is used to optimize search strategy, and support vector machine is used to realize classification. Through the simulation experiment on the face database of the Institute of Technology of Chinese Academy of Sciences in 2003, the results show that the model can achieve face recognition with high efficiency, and the highest accuracy rate is 99%. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhi, Hui; Liu, Sanyang] Xidian Univ, Sch Math & Stat, Xian 710126, Shaanxi, Peoples R China.
   [Zhi, Hui] Sch Huaqing, Xian 710055, Shaanxi, Peoples R China.
   [Zhi, Hui] Xian Univ Architecture & Technol, Xian 710055, Shaanxi, Peoples R China.
C3 Xidian University; Xi'an University of Architecture & Technology
RP Zhi, H (corresponding author), Xidian Univ, Sch Math & Stat, Xian 710126, Shaanxi, Peoples R China.; Zhi, H (corresponding author), Sch Huaqing, Xian 710055, Shaanxi, Peoples R China.; Zhi, H (corresponding author), Xian Univ Architecture & Technol, Xian 710055, Shaanxi, Peoples R China.
EM xzzhihui@163.com
FU National Natural Science Foundation of China [61877046]; Natural Science
   Foundation of Shaanxi Province [2018JQ1004]; Natural Science Special
   Plan of school of Huaqing and Xi'an University of Architecture and
   Technology [17KY01]
FX This work was supported by the National Natural Science Foundation of
   China (61877046), the Natural Science Foundation of Shaanxi Province
   (2018JQ1004) and Natural Science Special Plan of school of Huaqing and
   Xi'an University of Architecture and Technology (17KY01).
CR Ali M. M. H., 2016, IEEE INT C ADV COMP
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Du MJ, 2016, KNOWL-BASED SYST, V99, P135, DOI 10.1016/j.knosys.2016.02.001
   Galton F., 1998, J ANTHR I GREAT BRIT, V18, P177
   Goljan M., 2016, Electronic Imaging, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.8.MWSF-086, DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-086]
   Gonzalez MA, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007483
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Kim SK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P661, DOI 10.1109/ICIP.1996.560964
   MACFARLANE PW, 1971, CARDIOVASC RES, V5, P141, DOI 10.1093/cvr/5.1.141
   Micheva Ilina, 2011, CLIN EXP METASTAS, V28, P413
   Ming-Yuan Shieh, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1610
   Nicholl Paul, 2008, EL DES TEST APPL 200
   Rahmani Mohammad-Reza, 2018, Soft Computing, V22, P8097, DOI 10.1007/s00500-017-2749-6
   Samanta B, 2003, ENG APPL ARTIF INTEL, V16, P657, DOI 10.1016/j.engappai.2003.09.006
   Waghmare L.M., 2011, Int. J. Sci. Eng. Res, V2, P37
   Wang Hong, 2007, INT C COMP INT SEC W
   Wang M, 2000, CHEM RES TOXICOL, V13, P1149, DOI 10.1021/tx000118t
   Yao HB, 2003, IEEE T GEOSCI REMOTE, V41, P1469, DOI 10.1109/TGRS.2003.811691
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   [张同珍 ZHANG Tongzhen], 2006, [计算机仿真, Computer Simulation], V23, P198
   Zhao ZD, 2013, SENSORS-BASEL, V13, P6832, DOI 10.3390/s130506832
NR 22
TC 65
Z9 68
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 495
EP 502
DI 10.1016/j.jvcir.2018.12.012
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100048
DA 2024-07-18
ER

PT J
AU Gao, Z
   Wang, DY
   Xue, YB
   Xu, GP
   Zhang, H
   Wang, YL
AF Gao, Z.
   Wang, D. Y.
   Xue, Y. B.
   Xu, G. P.
   Zhang, H.
   Wang, Y. L.
TI 3D object recognition based on pairwise Multi-view Convolutional Neural
   Networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D object recognition; CNN; Multi-view; PMV-CNN; Pairwise; End-to-end
ID RETRIEVAL
AB With the development of 3D sensors, it will be much easier for us to obtain 3D models, which is prevailing in our future daily life, but up to now, although many 3D object recognition algorithms have been proposed, there are some limitations, including the lack of training samples, hand-crafted feature representation, feature extraction and recognition separately. In this work, we propose a novel pairwise Multi-View Convolutional Neural Network for 3D Object Recognition (PMV-CNN for short), where automatic feature extraction and object recognition are put into a unify CNN architecture. Moreover, since the pairwise network architecture is utilized in PMV-CNN, thus, the requirement of the number of training samples in the original dataset is not severe. In addition, the latent complementary relationships from different views can be highly explored by view pooling. Large scale experiments demonstrate that the pairwise architecture is very useful when the number of labeled training samples is very small. Moreover, it also makes more robust feature extraction. Furthermore, since the end-to-end network architecture is employed in PMV-CNN, thus, the extracted feature is very suitable for 3D object recognition, whose performance is much better than that of hand-crafted features. In a word, the performance of our proposed method outperforms state-of-the-art methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Gao, Z.; Wang, Y. L.] Qilu Univ Technol, Shandong Acad Sci, Shandong Artificial Intelligence Inst, Jinan 250014, Shandong, Peoples R China.
   [Gao, Z.; Wang, Y. L.] Natl Supercomp Ctr Jinan, Shandong Comp Sci Ctr, Jinan 250014, Shandong, Peoples R China.
   [Wang, D. Y.; Xue, Y. B.; Xu, G. P.; Zhang, H.] Tianjin Univ Technol, Minist Educ, Key Lab Comp Vis & Syst, Tianjin 300384, Peoples R China.
   [Wang, D. Y.; Xue, Y. B.; Xu, G. P.; Zhang, H.] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
C3 Qilu University of Technology; Qilu University of Technology; Tianjin
   University of Technology; Tianjin University of Technology
RP Gao, Z (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Shandong Artificial Intelligence Inst, Jinan 250014, Shandong, Peoples R China.; Gao, Z (corresponding author), Natl Supercomp Ctr Jinan, Shandong Comp Sci Ctr, Jinan 250014, Shandong, Peoples R China.
EM gaoz@sdas.org
OI Xu, Guangping/0000-0001-5221-0331
FU National Natural Science Foundation of China [61872270, 61572357]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61872270, No. 61572357).
CR [Anonymous], P S GEOM PROC
   [Anonymous], 2009, NIPS
   [Anonymous], NEUROCOMPUTING
   [Anonymous], P IEEE ICCV WORKSH S
   [Anonymous], 2016, 3D OBJECT RECOGNITIO
   [Anonymous], DEEPVISION WORKSH
   [Anonymous], GROUP PAIR CONVOLUTI
   [Anonymous], P ICCV
   [Anonymous], SIMILARITY BASED ASP
   [Anonymous], ACM T GRAPH
   [Anonymous], 2010, EUROPEAN C COMPUTER
   [Anonymous], P CVPR
   [Anonymous], ACM T GRAPH
   [Anonymous], ACM T GRAPH
   [Anonymous], P SAMT WORKSH SEM 3
   [Anonymous], 2000, P KDD WORKSHOP TEXT
   [Anonymous], ACM T GRAPH
   [Anonymous], 2016, P COMP VIS PATT REC
   [Anonymous], P CVPR
   [Anonymous], VISUAL LEARNING RECO
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Chaudhuri S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866205
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J., 2009, PECKHAMIA, P1
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Jing P., IEEE T CIRCUITS SYST
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595
   Krizhevsky A., 2012, NIPS, V1, P4
   Leibe B, 2003, PROC CVPR IEEE, P409
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Macrini D, 2002, INT C PATT RECOG, P24, DOI 10.1109/ICPR.2002.1047786
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Perron F., 2010, Potentiel energetique et gains environnementaux generes par la biomethanisation des matieres organiques residuelles au Quebec, P1
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Socher R., 2012, NIPS, V3, P8
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tabia H, 2017, PATTERN RECOGN LETT, V95, P78, DOI 10.1016/j.patrec.2017.06.007
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Zhongyu Wu, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286115
NR 49
TC 26
Z9 27
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 305
EP 315
DI 10.1016/j.jvcir.2018.10.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500030
DA 2024-07-18
ER

PT J
AU Kanso, A
   Ghebleh, M
AF Kanso, A.
   Ghebleh, M.
TI An efficient lossless secret sharing scheme for medical images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret sharing; Secret image sharing; (t, n)-threshold scheme; Chaos
ID AUTHENTICATION; STEGANOGRAPHY; QUALITY
AB Medical doctors use diagnostic imaging techniques such as X-rays, CT scans and MRI, for detecting diseases or narrowing down possible causes of pain. This often require sharing and transmitting medical images over public channels. In this work we adapt Shamir's secret sharing paradigm to propose a novel lossless scheme for secure sharing of medical images. The proposed scheme takes advantage of the redundancy in typical medical images to reduce share sizes, and hence facilitate storing and sharing. To this end, we employ a customized run-length encoding method to compress the medical image. We conduct an extensive performance analysis on the proposed scheme, including a comparison with some existing Shamir-type secret image sharing schemes. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Kanso, A.; Ghebleh, M.] Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
C3 Kuwait University
RP Kanso, A (corresponding author), Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
EM akanso@sci.kuniv.edu.kw; mamad@sci.kuniv.edu.kw
RI Kanso, Ali/GVT-1076-2022; Ghebleh, Mohammad/I-1040-2014
OI Kanso, Ali/0000-0002-4366-841X; Ghebleh, Mohammad/0000-0003-2291-0892
CR Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen CC, 2018, J VIS COMMUN IMAGE R, V52, P143, DOI 10.1016/j.jvcir.2018.02.006
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Dworkin M.J, 2015, Federal Information Processing Standards, DOI [DOI 10.6028/NIST.FIPS.202, 10.6028/NIST.FIPS.202]
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xie D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168674
   Yan XH, 2018, J VIS COMMUN IMAGE R, V50, P135, DOI 10.1016/j.jvcir.2017.11.012
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Yang CN, 2009, PATTERN RECOGN, V42, P1615, DOI 10.1016/j.patcog.2009.01.024
NR 31
TC 21
Z9 21
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 245
EP 255
DI 10.1016/j.jvcir.2018.09.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500024
DA 2024-07-18
ER

PT J
AU Panda, DK
   Meher, S
AF Panda, Deepak Kumar
   Meher, Sukadev
TI A new Wronskian change detection model based codebook background
   subtraction for visual surveillance applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual surveillance; Moving object detection; Background subtraction;
   Dynamic backgrounds; Wronskian change detection model; Codebook model
ID GAUSSIAN MIXTURE MODEL; HIERARCHICAL METHOD; TEXTURE FEATURES;
   SEGMENTATION; HISTOGRAM; COLOR
AB Background subtraction (BS) is a popular approach for detecting moving objects in video sequences for visual surveillance applications. In this paper, a new multi-channel and multi-resolution Wronskian change detection model (MCMRWM) based codebook background subtraction is proposed for moving object detection in the presence of dynamic background conditio ns. In the prooed MCMRWM, the multi-channel information helps to reduce the false negative of the foreground object; and the multi-resolution data suppresses the background noise resulting in reduced false positives. The proposed algorithm considers the ratio between feature vectors of current frame to the background model or its reciprocal in an adaptive manner, depending on the l(2) norm of the feature vector, which helps to detect the foreground object completely without any false negatives. Extensive experiments are carried out with challenging video sequences to show the efficacy of the proposed algorithm against state-of-the-art BS techniques. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Panda, Deepak Kumar; Meher, Sukadev] Natl Inst Technol Rourkela, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Panda, DK (corresponding author), Natl Inst Technol Rourkela, Rourkela 769008, Odisha, India.
EM deepakkumar.panda@gmail.com
RI Meher, Sukadev/AAW-2774-2020; PANDA, DEEPAK/N-5580-2016; Meher,
   Sukadev/O-4489-2017
OI PANDA, DEEPAK/0000-0001-8835-3908; Meher, Sukadev/0000-0003-4397-3139
CR [Anonymous], 2008, PROC 5 INT ICST C MO
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], P IEEE C COMPUTER VI
   Baf FE, 2008, IEEE IMAGE PROC, P2648, DOI 10.1109/ICIP.2008.4712338
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans Thierry, 2009, Recent Patents on Computer Science, V2, P223, DOI 10.2174/1874479610902030223
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Chen YT, 2007, PATTERN RECOGN, V40, P2706, DOI 10.1016/j.patcog.2006.11.023
   Chiranjeevi P, 2012, J VIS COMMUN IMAGE R, V23, P948, DOI 10.1016/j.jvcir.2012.06.004
   Chiranjeevi P, 2012, IEEE SIGNAL PROC LET, V19, P603, DOI 10.1109/LSP.2012.2205380
   Chiranjeevi P, 2014, IEEE T CYBERNETICS, V44, P870, DOI 10.1109/TCYB.2013.2274330
   Chiranjeevi P, 2014, IEEE T IMAGE PROCESS, V23, P645, DOI 10.1109/TIP.2013.2285598
   Chiranjeevi P, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3662910
   Durucan E, 2001, P IEEE, V89, P1368, DOI 10.1109/5.959336
   El Baf F, 2008, IEEE INT CONF FUZZY, P1731
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Guo JM, 2011, IEEE T CIRC SYST VID, V21, P804, DOI 10.1109/TCSVT.2011.2133270
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hati KK, 2013, IEEE SIGNAL PROC LET, V20, P759, DOI 10.1109/LSP.2013.2263800
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hongxun Z, 2006, LECT NOTES COMPUT SC, V4223, P887
   Jacques JCS, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P189
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Manzanera A, 2007, PATTERN RECOGN LETT, V28, P320, DOI 10.1016/j.patrec.2006.04.007
   Marie R., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2369, DOI 10.1109/ICIP.2011.6116117
   Mason M, 2001, 30TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P154, DOI 10.1109/AIPR.2001.991219
   Mittal A., 2004, P 2004 IEEE COMP SOC, V2, pII
   Mukherjee D, 2014, IEEE T IND INFORM, V10, P1086, DOI 10.1109/TII.2013.2294134
   Mukherjee D, 2013, IEEE T IMAGE PROCESS, V22, P5022, DOI 10.1109/TIP.2013.2281423
   Panda DK, 2016, IEEE SIGNAL PROC LET, V23, P45, DOI 10.1109/LSP.2015.2498839
   Panda DK, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P219, DOI 10.1109/ICSPCom.2013.6719786
   Pojala C., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P255, DOI 10.1109/ICSIPA.2011.6144098
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subudhi BN, 2013, MACH VISION APPL, V24, P795, DOI 10.1007/s00138-012-0475-8
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhang SP, 2009, INT J PATTERN RECOGN, V23, P1397, DOI 10.1142/S0218001409007569
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 45
TC 14
Z9 15
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 52
EP 72
DI 10.1016/j.jvcir.2018.07.014
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500005
DA 2024-07-18
ER

PT J
AU Mi, QC
   Xue, DL
AF Mi, Qunchao
   Xue, Dali
TI A sound-based video clipping framework toward sports scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sonogram; Deep representation; Convolutional neural network
ID SUPERVISED IMAGE SEGMENTATION; CATEGORIZATION; FUSION
AB Video clipping system is very important in many intelligent applications. In order to shorten the time of video and extract the framework of the video, many methods have been proposed. But these methods just considered videos without taking sound into account. As we know, sound is also an important information for image processing. For example, many sport match videos include rich sound of audience and commentator such as NBA. In addition, human pay more attention to some video clips of interest (VCOI) such as scoring time instead of pause. So in this paper, we propose a sound-based video clipping framework toward specific sports scenes. First, we convert sound of sport videos to sonogram. For some aesthetically-pleasing images (APIM) such as slam dunk or jump shot, a set of object patches are selected using BING feature. Then, these object patches are ordered by our active object patches ranking algorithm. After that, ordered object patches and sonogram are fed into CNN respectively to obtain patch-level deep feature. In order to obtain image-level deep representation, deep feature extracted from ordered object patches are aggregated statistically into a deep representation. Finally, probabilistic model is used to select VCOI and APIM. Experiments on some NBA basketball matches have shown the effectiveness of our video clipping framework.
C1 [Mi, Qunchao; Xue, Dali] State Grid Wenzhou Power Supply Co, Regulat & Control Ctr, Wenzhou, Peoples R China.
RP Mi, QC (corresponding author), State Grid Wenzhou Power Supply Co, Regulat & Control Ctr, Wenzhou, Peoples R China.
EM 1963561164@qq.com
CR [Anonymous], 2016, ARXIV161001708
   [Anonymous], 2007, MM
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Rehan M., 2007, 2007 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, P573, DOI 10.1109/PACRIM.2007.4313301
   Sun X, 2018, INFORM SCIENCES, V429, P37, DOI 10.1016/j.ins.2017.10.051
   Xia YJ, 2017, IEEE T MULTIMEDIA, V19, P1811, DOI 10.1109/TMM.2017.2679900
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P40, DOI 10.1109/TMM.2014.2370257
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
NR 27
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 648
EP 653
DI 10.1016/j.jvcir.2018.07.008
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100055
DA 2024-07-18
ER

PT J
AU Perrot, R
   Bourdon, P
   Helbert, D
AF Perrot, Romuald
   Bourdon, Pascal
   Helbert, David
TI Sampling strategies for performance improvement in cascaded face
   regression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face landmarking; Regression; Sampling; Data augmentation
AB Automatic face landmarking has received a lot of attention in the past decades. It is now mature enough to be implemented in fully autonomous video systems. As cascade-of-regression based algorithms have become state of the art in such systems, two major (and still relevant) sources of interest have slowly faded away: the need for semantic-driven learning beyond ground truth annotation, and full video chain performance Le. tracking efficiency, which in the case of said methods strongly relates to their robustness towards shape initialization before fitting. In this paper, we investigate how data sampling using face priors can affect their performance in terms of convergence and robustness. We propose new strategies based on said priors to overcome inconsistencies observed during cascade-of-regression learning on purely random sampling-based stages. We will show that simple choices can be easily integrated within regression-based face tracking systems to increase accuracy and robustness.
C1 [Perrot, Romuald; Bourdon, Pascal; Helbert, David] Univ Poitiers, XLIM ASALI, UMR CNRS, F-7252 Poitiers, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Poitiers
RP Perrot, R (corresponding author), Univ Poitiers, XLIM ASALI, UMR CNRS, F-7252 Poitiers, France.
EM romuald.perrot@univ-poitiers.fr; pascal.bourdon@univ-poitiers.fr;
   david.helbert@univ-poitiers.fr
OI Helbert, David/0000-0001-6518-1509
CR [Anonymous], 2017, SPACE
   [Anonymous], CORRABS160804188
   [Anonymous], CORRABS160908764
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2002, TORCH MODULAR MACHIN
   [Anonymous], DATASET AUGMENTATION
   [Anonymous], 2017, INT C COMP VIS
   [Anonymous], 2006, BMVC
   [Anonymous], 2013 IEEE C COMP VIS
   [Anonymous], CORRABS14101037
   [Anonymous], CORRABS151105049
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Breiman L., 2001, Mach. Learn., V45, P5
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao X., 2012, CVPR
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Haoqiang Fan, 2016, Image and Vision Computing, V47, P27, DOI 10.1016/j.imavis.2015.11.004
   Hasan MK, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P362, DOI 10.1109/ICCVW.2013.55
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Liu H., IEEE T PATTERN ANAL
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P1666, DOI 10.1109/TIP.2017.2657118
   Milborrow S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P378, DOI 10.1109/ICCVW.2013.57
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Saragih J, 2009, PATTERN RECOGN, V42, P2628, DOI 10.1016/j.patcog.2009.04.014
   Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 49
TC 1
Z9 1
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 841
EP 852
DI 10.1016/j.jvcir.2018.07.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100074
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wazarkar, S
   Keshavamurthy, BN
AF Wazarkar, Seema
   Keshavamurthy, Bettahally N.
TI A survey on image data analysis through clustering techniques for real
   world applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image clustering; Feature extraction; Real world applications
ID LOCAL BINARY PATTERN; FEATURE-EXTRACTION; TEXTURE ANALYSIS; AFFINITY
   AGGREGATION; COMPONENT ANALYSIS; FOURIER-TRANSFORM; COLOR HISTOGRAM;
   MEAN SHIFT; ALGORITHM; RETRIEVAL
AB A huge amount of image data is being collected in real world sectors. Image data analytics provides information about important facts and issues of a particular domain. But, it is challenging to handle voluminous, unstructured and unlabeled image collection. Clustering provides groups of homogeneous unlabeled data. Therefore, it is used quite often to access the interesting data easily and quickly. Image clustering is a process of partitioning image data into clusters on the basis of similarities. Whereas, features extracted from images are used for the computation of similarities among them. In this paper, significant feature extraction approaches and clustering methods applied on the image data from nine important applicative areas are reviewed. Medical, 3D imaging, oceanography, industrial automation, remote sensing, mobile phones, security and traffic control are considered applicative areas. Characteristics of images, suitable clustering approaches for each domain, challenges and future research directions for image clustering are discussed.
C1 [Wazarkar, Seema; Keshavamurthy, Bettahally N.] Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda 403401, Goa, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa
RP Wazarkar, S (corresponding author), Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda 403401, Goa, India.
EM wazarkarseema@nitgoa.ac.in
RI Wazarkar, Seema/Y-3371-2019; Wazarkar, Seema/G-8541-2018
OI Bettahally nanjaiah, Keshavamurthy/0000-0002-6680-8462
CR Abonyi J, 2002, IEEE T SYST MAN CY B, V32, P612, DOI 10.1109/TSMCB.2002.1033180
   Addison Paul S, 2017, The illustrated wavelet transform handbook: introductory theory and applications in science, engineering, medicine and finance
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ai TH, 2013, COMPUT ENVIRON URBAN, V41, P219, DOI 10.1016/j.compenvurbsys.2013.07.002
   Alamdar F, 2011, PROCEDIA ENVIRON SCI, V10, P777, DOI 10.1016/j.proenv.2011.09.126
   Amit Kumar, 2016, Image processing in diabetic related causes, P5
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], 1996, SIGMOD REC ACM SPEC, DOI DOI 10.1145/235968.233324
   [Anonymous], 2016, Joint European Conference on Machine Learning and Knowledge Discovery in Databases
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], 1998, AUTOMATIC SUBSPACE C
   [Anonymous], 2017, Data mining with R: Learning with case studies
   Assfalg J, 2007, IEEE T MULTIMEDIA, V9, P589, DOI 10.1109/TMM.2006.886271
   Aydav Prem Shankar Singh, 2014, P IEEE INT C DAT MIN, P1
   Azar AA, 2011, IEEE ENG MED BIO, P8098, DOI 10.1109/IEMBS.2011.6091997
   Azimi R, 2017, EXPERT SYST APPL, V76, P59, DOI 10.1016/j.eswa.2017.01.024
   Baek S, 2005, LECT NOTES COMPUT SC, V3480, P37
   Banu M.S., 2010, IEEE INT C COMPUTATI, P1
   Barla A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P513
   Barla Sathya, 2010, NAT C COMM NCC, P1
   Basset Boukerroui, 1997, P IEEE ULTR S, V2, P1389
   Batool N, 2015, PATTERN RECOGN, V48, P642, DOI 10.1016/j.patcog.2014.08.003
   Berthold MR, 2008, STUD CLASS DATA ANAL, P319, DOI 10.1145/1656274.1656280
   Bo Li, 2010, 2010 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC), P380, DOI 10.1109/CyberC.2010.75
   Boyle, 2014, CENGAGE LEARNING
   Burget R, 2010, TSP 2010: 33RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING, P114
   Chang HL, 2015, NEUROCOMPUTING, V151, P632, DOI 10.1016/j.neucom.2014.05.092
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866, DOI 10.1109/69.553155
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng SS, 2009, IEEE T NEURAL NETWOR, V20, P805, DOI 10.1109/TNN.2009.2013708
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cheung W, 2009, IEEE T IMAGE PROCESS, V18, P2012, DOI 10.1109/TIP.2009.2024578
   Chu XiaoLi, 2010, 2010 International Conference on Intelligent Computing and Integrated Systems (ICISS 2010), P254, DOI 10.1109/ICISS.2010.5657199
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dave Parth, 2015, P 2015 IEEE INT C EL, P1, DOI DOI 10.1109/ICECCT.2015.7226070
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Dongxiang Chi, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1333, DOI 10.1109/CISP.2010.5648009
   Santos ED, 2005, P ANN INT IEEE EMBS, P3471
   Ebling J, 2005, IEEE T VIS COMPUT GR, V11, P469, DOI 10.1109/TVCG.2005.54
   El Bakrawy L. M., 2011, 2011 Federated Conference on Computer Science and Information Systems (FedCSIS), P19
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Elleuch M, 2015, LECT NOTES COMPUT SC, V9257, P371, DOI 10.1007/978-3-319-23117-4_32
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fan JC, 2009, PATTERN RECOGN, V42, P2527, DOI 10.1016/j.patcog.2009.04.013
   Fathabadi H, 2016, INT J ELEC POWER, V78, P96, DOI 10.1016/j.ijepes.2015.11.077
   Fierro-Radilla AN, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE), P233, DOI 10.1109/ICEEE.2013.6676028
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Friedman A, 2011, IEEE INT C INT ROBOT, P1533, DOI 10.1109/IROS.2011.6048779
   Fustes D, 2014, FUTURE GENER COMP SY, V34, P155, DOI 10.1016/j.future.2013.09.020
   Gallo I, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P73, DOI 10.1109/SIBGRAPI.2014.35
   Ghaffarian S, 2014, ISPRS J PHOTOGRAMM, V97, P46, DOI 10.1016/j.isprsjprs.2014.08.006
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gil M., 1999, 1999 7th IEEE International Conference on Emerging Technologies and Factory Automation. Proceedings ETFA '99 (Cat. No.99TH8467), P465, DOI 10.1109/ETFA.1999.815392
   Gil-García RJ, 2006, INT C PATT RECOG, P569
   Gomathy, 2015, 2015 IEEE INT C INNO, P1
   Gómez-Chova L, 2012, IEEE GEOSCI REMOTE S, V9, P312, DOI 10.1109/LGRS.2011.2167212
   Gonzalez Rafael, 2002, DIGITAL IMAGE PROCES, P116
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Guo LQ, 2014, INFORM SCIENCES, V273, P132, DOI 10.1016/j.ins.2014.03.037
   Gustafson D. E., 1979, Proceedings of the 1978 IEEE Conference on Decision and Control Including the 17th Symposium on Adaptive Processes, P761
   Haiwei Pan, 2006, P 27 IEEE ANN INT C, P3308
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hamed Mohsen, 2012, P 4 IEEE INT C COMP, P222
   Hamouda K, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P245, DOI 10.1109/ICCES.2014.7030967
   Han J, 2012, MOR KAUF D, P1
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   He Yuejiao, 2014, URBAN CONSTRUCTION T, P1
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Heechan Park, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P49
   Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446
   Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P357, DOI 10.1109/ANZIIS.1994.396988
   Hong BW, 2015, IEEE T PATTERN ANAL, V37, P151, DOI 10.1109/TPAMI.2014.2342215
   Hong Zhang, 2010, P 2010 INT C COMP AP, V14, pV14
   Huang HC, 2012, PROC CVPR IEEE, P773, DOI 10.1109/CVPR.2012.6247748
   Huang QH, 2012, ULTRASONICS, V52, P266, DOI 10.1016/j.ultras.2011.08.011
   Ito T, 2013, KOR-JPN JT WORKS FR, P22, DOI 10.1109/FCV.2013.6485453
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jia S, 2016, IEEE T GEOSCI REMOTE, V54, P88, DOI 10.1109/TGRS.2015.2450759
   Jiang CF, 1998, P ANN INT IEEE EMBS, V20, P850, DOI 10.1109/IEMBS.1998.745570
   Jin-Hua Yu, 2007, 2007 1st International Conference on Bioinformatics and Biomedical Engineering, P599
   Jovic A, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1112, DOI 10.1109/MIPRO.2014.6859735
   Kaneko T, 2016, NEUROCOMPUTING, V172, P143, DOI 10.1016/j.neucom.2015.02.081
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kaufman Leonard., Wiley Series in Probability and Statistics, P68, DOI DOI 10.1093/aje/kwu209
   Kersten PR, 2005, IEEE T GEOSCI REMOTE, V43, P519, DOI 10.1109/TGRS.2004.842108
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Kim SY, 2015, 2015 IEEE/ACIS 14TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), P209, DOI 10.1109/ICIS.2015.7166595
   Kissi A, 2004, P ANN INT IEEE EMBS, V26, P1613
   Kohonen Teuvo, 2001, NJ, P43
   Kong FH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2228, DOI 10.1109/ICMLC.2009.5212186
   Kou L, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040402
   Kriegel HP, 2003, EIGHTH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PROCEEDINGS, P27, DOI 10.1109/DASFAA.2003.1192365
   Krishnapuram R, 1999, IEEE T FUZZY SYST, V7, P453, DOI 10.1109/91.784208
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kroger Peer, 2011, WILEY INTERDISCIPLIN, V1, P231
   Kruthiventi Srinivas S. S., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P63, DOI 10.1109/CVPRW.2015.7301285
   Kurtz C, 2012, PATTERN RECOGN, V45, P685, DOI 10.1016/j.patcog.2011.07.017
   Laganiere R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P280, DOI 10.1109/ICCV.1998.710731
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lee S, 2010, BIOMICROFLUIDICS, V4, DOI 10.1063/1.3463716
   Li B, 2015, IEEE T VEH TECHNOL, V64, P1435, DOI 10.1109/TVT.2014.2331314
   Li Hao, 2015, J APPL SOFT COMPUTIN, V10, P10
   Li J, 2012, 2012 8TH INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORKING TECHNOLOGY (ICCNT, INC, ICCIS AND ICMIC), P153
   Li JY, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2923, DOI 10.1109/WCICA.2014.7053193
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Li YG, 2012, CHIN CONTR CONF, P4006
   Li ZR, 2013, 2013 5TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY (IC-BNMT), P1, DOI 10.1109/ICBNMT.2013.6823903
   Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu HL, 2017, IEEE T INTELL TRANSP, V18, P2477, DOI 10.1109/TITS.2017.2649541
   Liu Hongfu, P 22 ACM SIGKDD INT, P1745
   Liu HC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P801
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2013, OPTIK, V124, P2577, DOI 10.1016/j.ijleo.2012.07.010
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Liu Rongjie, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P403, DOI 10.1109/CSSE.2008.1017
   Liu XY, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4155
   Liu XF, 2007, INT GEOSCI REMOTE SE, P2010, DOI 10.1109/IGARSS.2007.4423224
   Lu YS, 2005, LECT NOTES ARTIF INT, V3584, P824
   Lu Z, 2017, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2017.7952478
   Lu Z, 2008, 2008 IEEE CONFERENCE ON ROBOTICS, AUTOMATION, AND MECHATRONICS, VOLS 1 AND 2, P644
   Malegori C, 2016, J FOOD ENG, V185, P48, DOI 10.1016/j.jfoodeng.2016.04.001
   Masi G, 2015, INT GEOSCI REMOTE SE, P1028, DOI 10.1109/IGARSS.2015.7325944
   Meng XR, 2016, J MACH LEARN RES, V17
   Mennesson J, 2014, PATTERN RECOGN LETT, V40, P27, DOI 10.1016/j.patrec.2013.12.014
   Messing DS, 2001, IEEE IMAGE PROC, P670, DOI 10.1109/ICIP.2001.959134
   Mikut R, 2011, WIRES DATA MIN KNOWL, V1, P431, DOI 10.1002/widm.24
   Mitra D, 2015, I S BIOMED IMAGING, P1344, DOI 10.1109/ISBI.2015.7164124
   Mitrea D, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P633, DOI 10.1109/TSP.2013.6614013
   Moldovanu S, 2010, 2010 3RD INTERNATIONAL SYMPOSIUM ON ELECTRICAL AND ELECTRONICS ENGINEERING (ISEEE), P197, DOI 10.1109/ISEEE.2010.5628516
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Murugan Vel, 2014, P IEEE INT C INF COM, P1
   Nagpal A, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P298
   Nascimento S, 2015, COMPUT GEOSCI-UK, V85, P74, DOI 10.1016/j.cageo.2015.06.002
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   Nguyen T.N. D., 2010, Proceedings of the International Conference on Software Maintenance, P1, DOI DOI 10.1109/ICSM.2010.5609560
   Otto C, 2018, IEEE T PATTERN ANAL, V40, P289, DOI 10.1109/TPAMI.2017.2679100
   Padmavathi Muthukumar, 2010, P 3 IEEE INT C ADV C, V2, pV2
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pandey S, 2016, COMPUT ELECTR ENG, V54, P506, DOI 10.1016/j.compeleceng.2016.04.003
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Patel RC, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P577, DOI 10.1109/OCEANS.1998.725812
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pedrosa GV, 2013, NEUROCOMPUTING, V120, P156, DOI 10.1016/j.neucom.2012.07.055
   Petrovai A, 2014, INT C INTELL COMP CO, P141, DOI 10.1109/ICCP.2014.6936966
   Pham DL, 2001, COMPUT VIS IMAGE UND, V84, P285, DOI 10.1006/cviu.2001.0951
   Pigeau A, 2004, INT C PATT RECOG, P878, DOI 10.1109/ICPR.2004.1334668
   Pratt William K., 2013, INTRO DIGITAL IMAGE
   Pun D, 2009, IN C IND ENG ENG MAN, P698, DOI 10.1109/IEEM.2009.5373234
   Qi ZHao, 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P263
   Qu JY, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P289
   Riddell C, 1999, IEEE T NUCL SCI, V46, P713, DOI 10.1109/23.775604
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Ryu J, 2015, IEEE T IMAGE PROCESS, V24, P2254, DOI 10.1109/TIP.2015.2419081
   Saha Sriparna, 2017, APPLIED COMPUTATIONA, P105
   Salvi G, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 1, P131, DOI 10.1109/CSCI.2014.29
   Sanchez-Ortiz GI, 2002, IEEE T MED IMAGING, V21, P1069, DOI 10.1109/TMI.2002.804434
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shajahan, 2014, P 2 INT C DEV CIRC S, P1
   Shao M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3798
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi Y, 2017, NEURAL COMPUT APPL, V28, pS29, DOI 10.1007/s00521-016-2300-1
   Shi-long Wang, 2010, PROCEEDINGS OF THE I, V1, pV1
   Shukui Bo, 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P327, DOI 10.1109/CICN.2012.128
   Sohail Abu Sayeed Md, 2011, P 24 IEEE CAN C EL C
   Srinivas M, 2015, NEUROCOMPUTING, V168, P880, DOI 10.1016/j.neucom.2015.05.036
   Tabakov M, 2006, 2006 INTERNATIONAL SYMPOSIUM ON EVOLVING FUZZY SYSTEMS, PROCEEDINGS, P118, DOI 10.1109/ISEFS.2006.251140
   Tagawa N, 2003, ULTRASON, P1829
   Tan M, 2016, IEEE T INTELL TRANSP, V17, P1415, DOI 10.1109/TITS.2015.2506182
   Tang H, 2011, PROCED EARTH PLAN SC, V2, P358, DOI 10.1016/j.proeps.2011.09.056
   [唐杰 Tang Jie], 2015, [科学通报, Chinese Science Bulletin], V60, P509
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Tasdemir K, 2015, IEEE J-STARS, V8, P1996, DOI 10.1109/JSTARS.2015.2424292
   Tasdemir K, 2013, INT GEOSCI REMOTE SE, P3136, DOI 10.1109/IGARSS.2013.6723491
   Tasoulis SK, 2013, PATTERN RECOGN LETT, V34, P131, DOI 10.1016/j.patrec.2012.09.008
   Tian CH, 2009, PROCEEDINGS OF 2009 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATION, LOGISTICS AND INFORMATICS, P1, DOI 10.1109/SOLI.2009.5203894
   Tian F, 2014, AAAI CONF ARTIF INTE, P1293
   Tian L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1039, DOI 10.1109/ICDSP.2015.7252036
   Ting Yun, 2011, 2011 International Conference on Electrical and Control Engineering (ICECE), P920
   Turcsany D, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1140, DOI 10.1109/ICIT.2013.6505833
   Uijlings J.R., 2009, Proceedings of the ACM international Conference on Image and Video Retrieval, P6
   van de Weijer J, 2005, IEEE T PATTERN ANAL, V27, P625, DOI 10.1109/TPAMI.2005.75
   van der Meer F, 2006, INT J APPL EARTH OBS, V8, P3, DOI 10.1016/j.jag.2005.06.001
   Verma Nishchal K., 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P156, DOI 10.1109/ITNG.2010.219
   Verma NK, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1307, DOI 10.1109/ITNG.2009.238
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Vinushree N, 2014, 2014 WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT 2014), P179, DOI 10.1109/WCCCT.2014.61
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P2537, DOI 10.1109/TVCG.2015.2501813
   Vozna N, 2015, PROCEEDINGS OF XIIITH INTERNATIONAL CONFERENCE - EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS CADSM 2015, P295, DOI 10.1109/CADSM.2015.7230861
   Wang Shi-long, 2011, 2011 30 URSI GEN ASS, P1
   Wang W, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P186
   Wang W, 2016, VLDB J, V25, P79, DOI 10.1007/s00778-015-0391-4
   Wang XC, 2008, I C COMP AID DES CON, P250, DOI 10.1109/CAIDCD.2008.4730564
   Wang ZF, 2014, INT GEOSCI REMOTE SE, P1737, DOI 10.1109/IGARSS.2014.6946787
   Wazarkar S, 2018, INT J WEB SERV RES, V15, P89, DOI 10.4018/IJWSR.2018040105
   Wazarkar S, 2018, SMART INNOV SYST TEC, V77, P669, DOI 10.1007/978-981-10-5544-7_66
   Wilson HG, 2002, INT GEOSCI REMOTE SE, P1624, DOI 10.1109/IGARSS.2002.1026201
   WONG SH, 1993, TENCON '93: 1993 IEEE REGION 10 CONFERENCE ON COMPUTER, COMMUNICATION, CONTROL AND POWER ENGINEERING, VOL 2, P910, DOI 10.1109/TENCON.1993.320160
   Wu KL, 2002, PATTERN RECOGN, V35, P2267, DOI 10.1016/S0031-3203(01)00197-2
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Wu ZZ, 2013, COMPUT GRAPH-UK, V37, P628, DOI 10.1016/j.cag.2013.05.015
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Yan Xu, 2009, Proceedings of the 2009 IEEE Symposium on Industrial Electronics & Applications (ISIEA 2009), P6, DOI 10.1109/ISIEA.2009.5356492
   YANG HH, 2012, PLOS ONE
   Yang HY, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (5TH), VOL III, P47
   Yang J, 2006, IEEE INT C NETW SENS, P1001
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yi WB, 2011, IEEE GEOSCI REMOTE S, V8, P522, DOI 10.1109/LGRS.2010.2090034
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yu Jeongmin, 2011, P 13 ANN C COMPANION, P217
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, PATTERN RECOGN, V47, P3512, DOI 10.1016/j.patcog.2014.05.002
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yuan X, 2005, IEEE INT SYMP CIRC S, P3211
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang G, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P71, DOI 10.1109/IIH-MSP.2008.16
   Zhang LY, 2016, IEEE T IMAGE PROCESS, V25, P4504, DOI 10.1109/TIP.2016.2592703
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhang Y, 2009, IEEE INT VEH SYM, P168, DOI 10.1109/IVS.2009.5164272
   Zhao J, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418500039
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zheng LF, 2012, CHIN CONTR CONF, P4001
   Zhengmao Ye, 2007, 16th IEEE International Conference on Control Applications. Part of IEEE Multi-conference on Systems and Control, P313
   Zhou B, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING ICISCE 2015, P412, DOI 10.1109/ICISCE.2015.97
   Zhu CM, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P418, DOI 10.1109/KAMW.2008.4810513
NR 242
TC 29
Z9 30
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 596
EP 626
DI 10.1016/j.jvcir.2018.07.009
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100052
DA 2024-07-18
ER

PT J
AU Firouznia, M
   Faez, K
   Amindavar, H
   Koupaei, JA
AF Firouznia, Marjan
   Faez, Karim
   Amindavar, Hamidreza
   Koupaei, Javad Alikhani
TI Chaotic particle filter for visual object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Chaos theory; Particle filter; Global motion
   estimation; Occlusion; Fast motion
ID MEAN SHIFT; ALGORITHM; OPTIMIZATION; MAPS
AB In this paper, a chaotic particle filter method is introduced to improve the performance of particle filter based on chaos theory. The methodology of the algorithm includes two steps. First, the global motion estimation is used to predict target position using dynamical information of object movement over frames. Then, the color-based particle filter method is employed in the local region obtained from global motion estimation to localize the target. The algorithm significantly reduces the number of particles, search space, and the filter divergence because of high-order estimation. To verify the efficiency of the tracker, the proposed method is applied to two datasets, consisting of particle filter-based methods under the Bonn Benchmark on Tracking (BoBoT), the large Tracking Benchmark (TB), and Visual Object Tracking (VOT2014). The results demonstrate that the chaotic particle filter method outperforms other state-of-the-art methods on the abrupt motion, occlusion, and out of view. The precision of the proposed method is about 10% higher than that of other particle filter algorithms with low computational cost.
C1 [Firouznia, Marjan; Faez, Karim; Amindavar, Hamidreza] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Koupaei, Javad Alikhani] Payamenoor Univ, Dept Math, POB 19395-3697, Tehran, Iran.
C3 Amirkabir University of Technology
RP Firouznia, M (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
EM Marjan.abdechiri@aut.ac.ir
RI Firouznia, Marjan/AAW-8217-2020; faez, karim/K-5117-2019; Hamidreza,
   Hamidreza/ABC-1981-2021
OI Firouznia, Marjan/0000-0001-6491-2955; faez, karim/0000-0002-1159-4866;
   Hamidreza, Hamidreza/0000-0002-0954-0674
CR Abd-Elhady M. A., 2010, P INT S SIGN SYST EL, V1, P1, DOI DOI 10.1109/IWISA.2010.5473247
   Abdechiri M, 2018, MULTIDIM SYST SIGN P, V29, P1643, DOI 10.1007/s11045-017-0521-9
   Abdechiri M, 2017, SIGNAL PROCESS-IMAGE, V54, P23, DOI 10.1016/j.image.2017.02.004
   Abdechiri M, 2017, NEUROCOMPUTING, V247, P16, DOI 10.1016/j.neucom.2017.03.032
   Abdechiri M, 2017, NONLINEAR DYNAM, V87, P2597, DOI 10.1007/s11071-016-3213-3
   Abdechiri M, 2013, APPL SOFT COMPUT, V13, P2932, DOI 10.1016/j.asoc.2012.03.068
   Abdel-Hadi A, 2010, ICCES'2010: THE 2010 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS, P337, DOI 10.1109/ICCES.2010.5674880
   Ait Abdelali H., 2016, MOD SIMUL ENG, V2016, P1
   Abdelali HA, 2016, J VIS COMMUN IMAGE R, V34, P219, DOI 10.1016/j.jvcir.2015.11.010
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], BOBOT BONN BENCHMARK
   Bahrami H, 2010, 2010 12TH INTERNATIONAL CONFERENCE ON COMPUTER MODELLING AND SIMULATION (UKSIM), P98, DOI 10.1109/UKSIM.2010.26
   Chiranjeevi P, 2016, IEEE T FUZZY SYST, V24, P695, DOI 10.1109/TFUZZ.2015.2471811
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dabby DS, 1996, CHAOS, V6, P95, DOI 10.1063/1.166171
   Dou JF, 2014, NEUROCOMPUTING, V135, P118, DOI 10.1016/j.neucom.2013.12.049
   Du H., 2014, RISING CHAOTIC LIKEL
   Du HL, 2014, J ATMOS SCI, V71, P483, DOI 10.1175/JAS-D-13-033.1
   Du HL, 2014, J ATMOS SCI, V71, P469, DOI 10.1175/JAS-D-13-032.1
   Fan ZH, 2015, SIGNAL PROCESS-IMAGE, V36, P140, DOI 10.1016/j.image.2015.07.001
   Farmer Michael E., 2007, J MULTIMED, V2, P53
   Firouznia M, 2017, DIGIT SIGNAL PROCESS, V70, P94, DOI 10.1016/j.dsp.2017.07.024
   Gordon Neil., 2004, Beyond the kalman filter: Particle filters for tracking applications
   Karami AH, 2015, ENG APPL ARTIF INTEL, V37, P307, DOI 10.1016/j.engappai.2014.09.018
   Koupaei JA, 2016, ENG APPL ARTIF INTEL, V50, P201, DOI 10.1016/j.engappai.2016.01.034
   Koupaei JA, 2015, CHAOS SOLITON FRACT, V81, P233, DOI 10.1016/j.chaos.2015.09.027
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Lee SH, 2013, IEEE T SIGNAL PROCES, V61, P801, DOI 10.1109/TSP.2012.2231075
   Maggio E, 2005, INT CONF ACOUST SPEE, P221
   Maggio E, 2007, IEEE T CIRC SYST VID, V17, P1348, DOI 10.1109/TCSVT.2007.903781
   Mazinan AH, 2012, ISA T, V51, P485, DOI 10.1016/j.isatra.2012.02.002
   Mekonnen AA, 2013, COMPUT VIS IMAGE UND, V117, P1229, DOI 10.1016/j.cviu.2012.12.004
   Murangira A., 2012, 2012 15th International Conference on Information Fusion (FUSION 2012), P794
   Pan P, 2011, IEEE SIGNAL PROC LET, V18, P51, DOI 10.1109/LSP.2010.2091406
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   [齐玉娟 Qi Yujuan], 2012, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V25, P810
   Shan C, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P669
   Sun X, 2014, SIGNAL IMAGE VIDEO P, V8, pS95, DOI 10.1007/s11760-014-0674-z
   Tian C, 2015, IEEE T IMAGE PROCESS, V24, P5236, DOI 10.1109/TIP.2015.2479409
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao JJ, 2016, IEEE SENS J, V16, P2639, DOI 10.1109/JSEN.2016.2514704
   Xu BL, 2014, ENG APPL ARTIF INTEL, V30, P155, DOI 10.1016/j.engappai.2013.11.010
   Yi SY, 2015, SIGNAL PROCESS, V110, P178, DOI 10.1016/j.sigpro.2014.09.020
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zeng DL, 2012, IEEE T IMAGE PROCESS, V21, P946, DOI 10.1109/TIP.2011.2168408
   Zhou ZY, 2016, OPTIK, V127, P613, DOI 10.1016/j.ijleo.2015.10.038
NR 48
TC 14
Z9 17
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 1
EP 12
DI 10.1016/j.jvcir.2018.02.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800001
DA 2024-07-18
ER

PT J
AU Qu, JH
   Li, YS
   Dong, WQ
AF Qu, Jiahui
   Li, Yunsong
   Dong, Wenqian
TI Fusion of hyperspectral and panchromatic images using an average filter
   and a guided filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral (HS) image; Panchromatic (PAN) image; Guided filter;
   Average filter; Component substitution (CS)
ID MULTIBAND IMAGES; RESOLUTION; CONTRAST; MS
AB The fusion of hyperspectral and panchromatic images aims to generate a fused image with high spatial and high spectral resolutions. This paper proposes a novel hyperspectral pansharpening method using an average filter and a guided filter. Based on the traditional component substitution methods, we propose a new and simple method to extract the spatial information of the HS image by average filtering at first. Then to solve the significant spectral distortion, a guided filter is utilized to obtain more detailed spatial information from the PAN image which has been sharpened. The appropriate injection gains matrix is generated by selecting the optimal value of the tradeoff coefficient. The spatial detail is finally injected into each band of the interpolated HS image to achieve the fused image. Experimental results demonstrate that the proposed method can obtain more spatial information and preserve more spectral information in both subjective and objective evaluations.
C1 [Qu, Jiahui; Li, Yunsong; Dong, Wenqian] Xidian Univ, State Key Lab Integrated Serv Networks, Sch Telecommun Engn, 2 South Taibai St, Xian 710071, Shaanxi, Peoples R China.
   [Qu, Jiahui; Li, Yunsong] Xidian Univ, Joint Lab High Speed Multisource Image Coding & P, Sch Telecommun Engn, 2 South Taibai St, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Xidian University
RP Li, YS (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Sch Telecommun Engn, 2 South Taibai St, Xian 710071, Shaanxi, Peoples R China.
EM ysli@mail.xidian.edu.cn
FU National Science Foundation of China [61222101, 61272120, 61301287,
   61301291, 61350110239]
FX The authors would like to thank the editors, and the anonymous reviewers
   for their insightful comments and suggestions which have greatly
   improved this paper. This work was supported by the National Science
   Foundation of China under Grants 61222101, 61272120, 61301287, 61301291
   and 61350110239.
CR Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Aiazzi B., 2011, Signal and Image Processing for Remote Sensing, P533
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L., 2015, Remote Sensing Image Fusion
   [Anonymous], 2002, DATA FUSION DEFINITI
   Baronti S, 2011, IEEE J-STSP, V5, P446, DOI 10.1109/JSTSP.2011.2104938
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Laben C. A., 2000, US Patent, Patent No. 6,011,875
   Liao WZ, 2015, IEEE J-STARS, V8, P2984, DOI 10.1109/JSTARS.2015.2420582
   Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499
   Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mastic T., 2003, ELEMENTS STAT LEARNI
   Mookambiga A, 2016, MULTIDIM SYST SIGN P, V27, P863, DOI 10.1007/s11045-016-0415-2
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Pohl C, 2015, INT J IMAGE DATA FUS, V6, P3, DOI 10.1080/19479832.2014.998727
   Rahmani S, 2010, IEEE GEOSCI REMOTE S, V7, P746, DOI 10.1109/LGRS.2010.2046715
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Simoes M, 2015, IEEE T GEOSCI REMOTE, V53, P3373, DOI 10.1109/TGRS.2014.2375320
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Vivone G, 2014, IEEE GEOSCI REMOTE S, V11, P930, DOI 10.1109/LGRS.2013.2281996
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wei Q, 2015, IEEE T IMAGE PROCESS, V24, P4109, DOI 10.1109/TIP.2015.2458572
   Wei Q, 2015, IEEE J-STSP, V9, P1117, DOI 10.1109/JSTSP.2015.2407855
   Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Yuhas R., 1992, SUMMARIES 4 ANN JPL, P147
   Zhang JL, 2010, APPL ANAL, V89, P293, DOI 10.1080/00036810903517555
NR 32
TC 9
Z9 9
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 151
EP 158
DI 10.1016/j.jvcir.2018.01.006
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300015
OA Bronze
DA 2024-07-18
ER

PT J
AU Venkata, US
   Naskar, R
AF Venkata, Udaya Sameer
   Naskar, Ruchira
TI Eliminating the effects of illumination condition in feature based
   camera model identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Camera model identification; Classification; Digital forensics; Image
   features; Illumination dependency; Overfitting; Scene content
ID FEATURE-SELECTION; STEGANALYSIS
AB State-of-the-art techniques for Camera Model Identification operate by extracting different features from the training image set and incorporating those features to predict the source of test images using machine learning. Though the existing approaches perform efficiently for images captured in natural daylight or bright illumination conditions, the state-of-the-art lacks sufficient experiments and results to evaluate efficiency of such schemes for images captured in dark illumination conditions. In this paper, we present a set of experiments to assess the impact of illumination conditions, on image source classification problem, and also propose an image filtering based technique to eliminate the adverse effects of scene illumination on source classification accuracy. Our experimental results prove that the performance efficiency of existing feature based source classification techniques, is indeed dependent on the illumination conditions. The proposed strategy enables our source classification model to achieve high efficiency as compared to the state-of-the-art, under all illumination conditions.
C1 [Venkata, Udaya Sameer; Naskar, Ruchira] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Rourkela, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Venkata, US (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Rourkela, India.
EM 515cs1003@nitrkl.ac.in; naskarr@nitrkl.ac.in
FU Media Asia Lab, Ministry of Electronics and Information Technology
   (MeitY), Govt. of India [PhD-MLA/4(13)/2015-16]
FX This work is funded by Media Asia Lab, Ministry of Electronics and
   Information Technology (MeitY), Govt. of India, Grant No.
   PhD-MLA/4(13)/2015-16, dated: 24/07/2015.
CR Akshatha K., 2016, DIGITAL CAMERA IDENT
   Amerini I, 2014, SIGNAL PROCESS-IMAGE, V29, P831, DOI 10.1016/j.image.2014.07.003
   [Anonymous], 2000, CS229 Lecture notes
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Bayram S., 2005, IEEE INT C IM PROC, V3, P111
   Bayram S, 2015, IEEE T INF FOREN SEC, V10, P597, DOI 10.1109/TIFS.2014.2385634
   Çeliktutan O, 2008, IEEE T INF FOREN SEC, V3, P553, DOI 10.1109/TIFS.2008.926993
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Dirik AE, 2008, IEEE T INF FOREN SEC, V3, P539, DOI 10.1109/TIFS.2008.926987
   Dirik AE, 2014, IEEE T INF FOREN SEC, V9, P2277, DOI 10.1109/TIFS.2014.2361200
   Foi Alessandro., 2008, IEEE transactions on image processing, V17
   Gloe Thomas, 2012, Transactions on Data Hiding and Multimedia Security VIII. Pattern Recognition for IT Security, P42, DOI 10.1007/978-3-642-31971-6_3
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Gloe T, 2009, LECT NOTES COMPUT SC, V5806, P262, DOI 10.1007/978-3-642-04431-1_19
   Goljan M., 2009, IS T SPIE ELECT IMAG
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Huang YG, 2015, IEEE T INF FOREN SEC, V10, P2692, DOI 10.1109/TIFS.2015.2474836
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Karaküçük A, 2015, DIGIT INVEST, V12, P66, DOI 10.1016/j.diin.2015.01.017
   Kharrazi M., 2004, 2004 INT C 1 IM PROC
   Li C.f., 2011, WDFIA, P149
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Marra F, 2015, LECT NOTES COMPUT SC, V9281, P11, DOI 10.1007/978-3-319-23222-5_2
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sencar H. T., 2013, Digital Image Forensics
   Tesic J, 2005, IEEE MULTIMEDIA, V12, P86, DOI 10.1109/MMUL.2005.50
   Thai TH, 2016, DIGIT SIGNAL PROCESS, V48, P285, DOI 10.1016/j.dsp.2015.10.002
   Thai TH, 2015, DIGIT SIGNAL PROCESS, V40, P88, DOI 10.1016/j.dsp.2015.01.002
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P1980, DOI 10.1109/TIP.2014.2310126
   Tsai MJ, 2008, IEEE INT SYMP CIRC S, P412, DOI 10.1109/ISCAS.2008.4541442
   Tsai MJ, 2012, COMPUT STAND INTER, V34, P292, DOI 10.1016/j.csi.2011.10.006
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang GC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110991
   Xu B., 2016, NEUROCOMPUTING
   Zeng H., 2017, IEEE T CYBERNET
   Zeng H, 2016, MULTIMED TOOLS APPL, V75, P13871, DOI 10.1007/s11042-015-3072-9
NR 42
TC 7
Z9 7
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 24
EP 32
DI 10.1016/j.jvcir.2018.01.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300003
DA 2024-07-18
ER

PT J
AU Hu, KC
   Tsai, CW
   Chiang, MC
AF Hu, Kai-Cheng
   Tsai, Chun-Wei
   Chiang, Ming-Chao
TI A highly efficient method for improving the performance of GLA-based
   algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Generalized Lloyd algorithm; Reduction method; Multiple stage vector
   quantization
ID VECTOR QUANTIZATION; CODEBOOK GENERATION; PARALLEL FRAMEWORK; SEARCH
   ALGORITHM; IMAGE
AB Motivated by the observation that most methods for accelerating the generalized Lloyd algorithm (GLA) normally lack the capability to improve the quality of its end result and that most methods for improving the quality of the end result of GLA usually lack the capability to speed it up, an efficient and effective method is presented in this paper to enhance the performance of GLA and its variants, in terms of both the computation time and the quality of the end result, by leveraging the strengths of several reduction methods and the multiple stage mechanism. Simulation results show that the proposed method can efficiently and effectively reduce the computation time of GLA by up to about 93% while at the same time improving its quality by up to about 1 dB in terms of the peak-signal-to-noise-ratio in most cases.
C1 [Hu, Kai-Cheng; Chiang, Ming-Chao] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
   [Tsai, Chun-Wei] Natl Chung lising Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
C3 National Sun Yat Sen University
RP Chiang, MC (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
EM mcchiang@cse.nsysu.edu.tw
RI Tsai, Chun-Wei/R-6389-2019
FU Ministry of Science and Technology of Taiwan, R.O.C.
   [MOST105-2221-E-005-091, MOST105-2221-E-110-067, MOST106-2221-E-005-094,
   MOST106-2221-E-110-023]
FX The authors would like to thank the editor and anonymous reviewers for
   their valuable comments and suggestions on the paper. This work was
   supported in part by the Ministry of Science and Technology of Taiwan,
   R.O.C., under Contracts MOST105-2221-E-005-091, MOST105-2221-E-110-067,
   MOST106-2221-E-005-094, and MOST106-2221-E-110-023.
CR Biing-Hwang Juang, 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P597
   BUZO A, 1980, IEEE T ACOUST SPEECH, V28, P562, DOI 10.1109/TASSP.1980.1163445
   Carreira-Perpinan M.A., 1997, Tech. Rep. CS- 96-09, V9, P1
   Chang CC, 1997, J VIS COMMUN IMAGE R, V8, P27, DOI 10.1006/jvci.1997.0327
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   David G., 2015, CLUSTERING BASED PRO, P147
   Dimitriadis S, 2016, IEEE T NEUR SYS REH, V24, P1017, DOI 10.1109/TNSRE.2016.2516107
   Flanagan J. K., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1759, DOI 10.1109/ICASSP.1989.266790
   Fodor I. K, 2002, SURVEY DIMENSION RED
   Franti P, 1998, PATTERN RECOGN, V31, P1139, DOI 10.1016/S0031-3203(97)00127-1
   Gersho A., 1992, Vector quantization and signal compression
   Horng MH, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P319, DOI 10.1109/ICBNMT.2011.6155949
   Horng MH, 2012, EXPERT SYST APPL, V39, P1078, DOI 10.1016/j.eswa.2011.07.108
   Hossan MA, 2013, INT J SPEECH TECHNOL, V16, P103, DOI 10.1007/s10772-012-9166-0
   Hsieh CH, 2000, IEEE T IMAGE PROCESS, V9, P321, DOI 10.1109/83.826771
   Hsieh CH, 2000, J VIS COMMUN IMAGE R, V11, P374, DOI 10.1006/jvci.2000.0452
   HUANG SH, 1990, ELECTRON LETT, V26, P1618, DOI 10.1049/el:19901037
   Jain BJ, 2011, COMPUT VIS IMAGE UND, V115, P946, DOI 10.1016/j.cviu.2011.03.004
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Jun S, 2014, EXPERT SYST APPL, V41, P3204, DOI 10.1016/j.eswa.2013.11.018
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844
   Kaukoranta T, 2000, IEEE T IMAGE PROCESS, V9, P1337, DOI 10.1109/83.855429
   Krishna K, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P1585, DOI 10.1109/ICICS.1997.652261
   Krishnamoorthy R, 2014, MULTIMED TOOLS APPL, V70, P2293, DOI 10.1007/s11042-012-1244-4
   Lai JZC, 2008, PATTERN RECOGN, V41, P315, DOI 10.1016/j.patcog.2007.04.015
   Lai JZC, 2009, PATTERN RECOGN, V42, P2551, DOI 10.1016/j.patcog.2009.02.014
   Li JJ, 2012, ADV INTEL SOFT COMPU, V139, P447
   LI WH, 1995, IEEE T CIRC SYST VID, V5, P119, DOI 10.1109/76.388060
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu T.C., 2010, J. Inf. Hiding Multim. Signal Process., V1, P190
   Ma XX, 2015, IET IMAGE PROCESS, V9, P986, DOI 10.1049/iet-ipr.2015.0048
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mohammed AA, 2010, INTEGR COMPUT-AID E, V17, P29, DOI 10.3233/ICA-2010-0327
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Patané G, 2001, NEURAL NETWORKS, V14, P1219, DOI 10.1016/S0893-6080(01)00104-6
   RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335
   RIZVI SA, 1995, IEEE T CIRC SYST VID, V5, P370, DOI 10.1109/76.465093
   Sharma A, 2016, PATTERN RECOGN LETT, V84, P22, DOI 10.1016/j.patrec.2016.07.015
   Sharma A, 2007, PATTERN RECOGN LETT, V28, P1151, DOI 10.1016/j.patrec.2007.01.012
   Smith L.I., 2002, TUTORIAL PRINCIPAL C
   Soman S.J., 2014, 2014 International Conference on Recent Trends in Information Technology, P1
   Tsai CW, 2013, APPL SOFT COMPUT, V13, P3008, DOI 10.1016/j.asoc.2013.01.017
   Tsai CW, 2009, PATTERN RECOGN LETT, V30, P653, DOI 10.1016/j.patrec.2009.02.003
   Tsai JT, 2015, INT J ELECTRON, V102, P1831, DOI 10.1080/00207217.2014.996785
   Vaisey J., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1176, DOI 10.1109/ICASSP.1988.196808
   Xie YF, 2016, IEEE T IMAGE PROCESS, V25, P5806, DOI 10.1109/TIP.2016.2615292
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 51
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 290
EP 302
DI 10.1016/j.jvcir.2017.12.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700029
DA 2024-07-18
ER

PT J
AU Dang, K
   Yuan, JS
AF Dang, Kang
   Yuan, Junsong
TI Learning location constrained pixel classifiers for image parsing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pedestrian parsing; Street-view scene parsing; Local learning; Spatial
   layout
ID ENERGY MINIMIZATION
AB When parsing images with regular spatial layout, the location of a pixel (x,y) can provide important prior for its semantic label. This paper proposes a technique to leverage both location and appearance information for pixel labeling. The proposed method utilizes the spatial layout of the image by building local pixel classifiers that are location constrained, i.e., trained with pixels from a local neighborhood region only. Our proposed local learning works well in different challenging image parsing problems, such as pedestrian parsing, street-view scene parsing and object segmentation, and outperforms existing results that rely on one unified pixel classifier. To better understand the behavior of our local classifier, we perform bias-variance analysis, and demonstrate that the proposed local classifier essentially performs spatial smoothness over the target estimator that uses appearance information and location, which explains why the local classifier is more discriminative but can still handle mis-alignment. Meanwhile, our theoretical and experimental studies suggest the importance of selecting an appropriate neighborhood size to perform location constrained learning, which can significantly influence the parsing results. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Dang, Kang; Yuan, Junsong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Dang, K (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM kangdang@gmail.com
RI Yuan, Junsong/A-5171-2011; Dang, Kang/O-7627-2019
OI Yuan, Junsong/0000-0002-7901-8793
FU Singapore MoE Tier-1 Grant [M4011272.040]
FX This work is supported in part by Singapore MoE Tier-1 Grant
   M4011272.040. We wish to thank Dr. Yihang Bo for providing us with
   Penn-Fudan dataset and annotations of HumanEva dataset. We wish to thank
   Dr. Ping Luo and Dr. Xiaogang Wang for providing us with PPSS dataset.
CR Achanta R., 2010, SLIC Superpixels
   Akbari Hamed, 2012, SPIE MED IMAGING
   AKSELRODBALLIN A, 2006, MICCAI
   [Anonymous], 2002, ECCV
   [Anonymous], 2012, CVPR
   [Anonymous], 2015, ARXIV151100561
   [Anonymous], 2009, ICCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2008, ECCV
   [Anonymous], 2015, ICLR
   [Anonymous], 2013, CVPR
   [Anonymous], 2006, ECCV
   [Anonymous], 2014, ARXIV14115752
   [Anonymous], 2014, CVPR
   [Anonymous], 2012, ECCV
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], ICCV
   [Anonymous], 2008, P WORKSHOP CAUSATION
   [Anonymous], 2014, CVPR
   [Anonymous], 2004, CVPR
   [Anonymous], 2015, CVPR
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Bo Y., 2011, CVPR
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Bubo Samuel Rota, 2014, CVPR
   Cover T.M., 1994, SIAM REV, V36, P509, DOI DOI 10.1137/1036124
   Cuingnet Remi, 2012, MICCAI
   Dang K., 2014, BMVC
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Freiman M., 2010, MICCAI
   Gong Minglun, 2011, CVPR
   Hinton Geoffrey E., 1999, INT C ART NEUR NETW
   Huang Q., 2011, CVPR
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kuettel D., 2012, CVPR
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu Buyu., 2016, ECCV
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu FY, 2015, PATTERN RECOGN, V48, P2983, DOI 10.1016/j.patcog.2015.04.019
   Liu Siqi, 2016, P IEEE C COMP VIS PA
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo P., 2013, ICCV
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Roth P.M., 2009, CVPR
   Seyedhosseini M., 2014, ARXIV14020595
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Stern Darko, 2016, MICCAI
   Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Tu Zhuowen, 2007, MICCAI
   Wang LL, 2015, J VIS COMMUN IMAGE R, V28, P83, DOI 10.1016/j.jvcir.2015.01.014
   Yang J., 2014, CVPR
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zeng K, 2017, IEEE T CYBERNETICS, V47, P27, DOI 10.1109/TCYB.2015.2501373
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
NR 57
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 1
EP 13
DI 10.1016/j.jvcir.2017.07.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800001
DA 2024-07-18
ER

PT J
AU Fezza, SA
   Chetouani, A
   Larabi, MC
AF Fezza, Sid Ahmed
   Chetouani, Aladine
   Larabi, Mohamed-Chaker
TI Using distortion and asymmetry determination for blind stereoscopic
   image quality assessment strategy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind/NR image quality assessment; Stereoscopic images; Distortion
   classification; Asymmetric distortion; Weighting strategy
ID BINOCULAR COMBINATION; VIDEO; COMPRESSION; PERCEPTION; PREDICTION
AB Predicting the perceived quality of stereoscopic 3D images is a challenging task, especially when the stereo-pair is asymmetrically distorted. Despite the considerable efforts to fix this issue, there is no commonly accepted metric. Most of the attempts consisted in developing full reference quality metrics, while very few efforts have been dedicated to blind/no-reference (NR) quality assessment of stereoscopic images. In this paper, we propose a blind/NR quality assessment strategy for stereoscopic images based on the identification of the distortion type in order to select the most efficient impairment measure in addition to the determination of whether a stereo-pair is symmetrically or asymmetrically distorted to account for the binocular fusion properties. Finally, the last step combines the two key information derived from previous steps and estimates the 3D image quality appropriately using different binocular combination strategies. Experimental results on four publicly available 3D image quality assessment databases showed that the proposed strategy reaches significant prediction consistency and accuracy when compared to state-of-the-art metrics. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Fezza, Sid Ahmed] Natl Inst Telecommun & ICT, Oran, Algeria.
   [Chetouani, Aladine] Univ Orleans, PRISME Lab, Orleans, France.
   [Larabi, Mohamed-Chaker] Univ Poitiers, XLIM Lab, Poitiers, France.
C3 Universite de Orleans; Universite de Poitiers
RP Larabi, MC (corresponding author), Univ Poitiers, XLIM Lab, Poitiers, France.
EM sfezza@ito.dz; aladine.chetouani@univ-orleans.fr;
   chaker.larabi@univ-poitiers.fr
RI Fezza, Sid Ahmed/AAN-6217-2020; chetouani, aladine/AAB-3086-2020; Fezza,
   Sid Ahmed/JJF-6642-2023; FEZZA, Sid Ahmed/G-5337-2010
OI Fezza, Sid Ahmed/0000-0001-6453-8588; chetouani,
   aladine/0000-0002-2066-4707; Fezza, Sid Ahmed/0000-0001-6453-8588; 
CR [Anonymous], THESIS
   Anstis S, 1998, VISION RES, V38, P523, DOI 10.1016/S0042-6989(97)00167-3
   Appina B, 2016, SIGNAL PROCESS-IMAGE, V43, P1, DOI 10.1016/j.image.2016.02.001
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bensalma R, 2013, MULTIDIM SYST SIGN P, V24, P281, DOI 10.1007/s11045-012-0178-3
   BLAKE R, 1980, PERCEPTION, V9, P223, DOI 10.1068/p090223
   Bovik A.C., 2001, IEEE INT C AC SPEECH
   BUCKLEY MJ, 1994, BIOMETRIKA, V81, P247, DOI 10.2307/2336955
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Campisi P., 2007, P EUR SIGN PROC C EU
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Chetouani A, 2012, SIGNAL PROCESS-IMAGE, V27, P948, DOI 10.1016/j.image.2012.06.001
   Chetouani A, 2009, IEEE INT SYMP SIGNAL, P155, DOI 10.1109/ISSPIT.2009.5407502
   De Silva V., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P184, DOI 10.1109/PV.2012.6229734
   De Silva V, 2013, IEEE T IMAGE PROCESS, V22, P3392, DOI 10.1109/TIP.2013.2268422
   FAHLE M, 1982, VISION RES, V22, P787, DOI 10.1016/0042-6989(82)90010-4
   Falk TH, 2007, CONFERENCE RECORD OF THE FORTY-FIRST ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1-5, P503
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Geng XQ, 2017, SIGNAL PROCESS-IMAGE, V52, P54, DOI 10.1016/j.image.2016.12.004
   Gorley P., 2008, P SPIE STER DISPL AP, VXIX
   Gu K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/436031
   Hewage CTER, 2008, ELECTRON LETT, V44, P963, DOI 10.1049/el:20081562
   Jiang GY, 2017, J VIS COMMUN IMAGE R, V46, P269, DOI 10.1016/j.jvcir.2017.04.010
   Julesz B., 1971, Foundation of Cyclopean Perception
   Lambooij M, 2011, IEEE T BROADCAST, V57, P432, DOI 10.1109/TBC.2011.2134590
   Li, 2011, INT C INT SCI INT DA, P644
   Lin YC, 2017, IEEE J-STSP, V11, P89, DOI 10.1109/JSTSP.2016.2632422
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maalouf A, 2011, INT CONF ACOUST SPEE, P1161
   Marichal X., 1999, INT C IMAG PROC ICIP
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Meegan DV, 2001, J EXP PSYCHOL-APPL, V7, P143, DOI 10.1037//1076-898X.7.2.143
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nauge M., 2012, P SPIE C HUM VIS EL, VXVII
   Pourazad MT, 2011, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2011.6116729
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Ryu S, 2012, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2012.6466933
   Sazzad ZMP, 2012, ADV MULTIMED, V2012, DOI 10.1155/2012/256130
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Seuntiëns P, 2003, PROC SPIE, V5006, P215, DOI 10.1117/12.474122
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Shao F, 2015, IEEE T BROADCAST, V61, P154, DOI 10.1109/TBC.2015.2402491
   Shao F, 2015, IEEE SIGNAL PROC LET, V22, P1548, DOI 10.1109/LSP.2015.2413946
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shen L., 2017, MSR-Net: Low-Light Image Enhancement Using Deep Convolutional Network, P1, DOI [10.48550/arXiv.1711.02488, DOI 10.48550/ARXIV.1711.02488]
   Steinman SB., 2000, Foundations of Binocular Vision
   Stelmach LB, 2000, IEEE IMAGE PROC, P5, DOI 10.1109/ICIP.2000.900878
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Wang J, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P29, DOI 10.1109/ICCSS.2014.6961811
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2002, INT C IMAG PROC ICIP
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yang JC, 2015, J VIS COMMUN IMAGE R, V31, P138, DOI 10.1016/j.jvcir.2015.06.002
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   You J., 2010, P INT WORK VPQM SCOT
   Zhang X, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P307, DOI 10.1109/PCS.2015.7170096
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P3810, DOI 10.1109/TIP.2015.2456414
   Zhou WJ, 2017, NEUROCOMPUTING, V224, P128, DOI 10.1016/j.neucom.2016.10.046
NR 64
TC 12
Z9 13
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 115
EP 128
DI 10.1016/j.jvcir.2017.08.009
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800010
DA 2024-07-18
ER

PT J
AU Xiao, Y
   Wang, LM
   Jiang, B
   Tu, ZZ
   Tang, J
AF Xiao, Yun
   Wang, Liangmin
   Jiang, Bo
   Tu, Zhengzheng
   Tang, Jin
TI A global and local consistent ranking model for image saliency
   computation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Markov chain; Graph ranking
ID OBJECT DETECTION; VISUAL-ATTENTION
AB Image saliency detection is an important issue in computer vision and has been widely used in many applications. In this paper, we propose a new global and local consistent ranking (GLR) model for image saliency computation. Firstly, we propose to use an absorbed Markov chain model to obtain a kind of global ranking for image superpixels, in which the absorbing nodes represent the virtual boundary superpixels and the transient nodes denote the general superpixels of image. Then, the absorbed time from each transient node to boundary absorbing nodes are computed. This absorbing time of transient node measures its global similarity with all absorbing nodes and thus provides a kind of global ranking for each transient node w.r.t. absorbing nodes. At last, we further exploit the local manifold structure and incorporate the local manifold smooth information into ranking process and thus propose a general global and local consistent ranking for saliency detection. Experimental results on several large benchmark databases show the effectiveness of the proposed GLR method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Xiao, Yun; Jiang, Bo; Tu, Zhengzheng; Tang, Jin] Anhui Univ, Hefei, Peoples R China.
   [Wang, Liangmin] Jiangsu Univ, Zhenjiang, Peoples R China.
C3 Anhui University; Jiangsu University
RP Tang, J (corresponding author), Anhui Univ, Hefei, Peoples R China.
EM ahu_tj@163.com
RI Xiao, Yun/AAB-6938-2022
OI Xiao, Yun/0000-0002-5285-8565
FU National Natural Science Foundation of China [61472002, 61602001,
   61602006]; Natural Science Foundation of Anhui Higher Education
   Institution of China [KJ2015A110]; Co-Innovation Center for Information
   Supply & Assurance Technology, Anhui University
FX This work was sponsored by the National Natural Science Foundation of
   China (Nos. 61472002, 61602001, 61602006), the Natural Science
   Foundation of Anhui Higher Education Institution of China (KJ2015A110)
   and by Co-Innovation Center for Information Supply & Assurance
   Technology, Anhui University.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Alpert S, 2007, PROC CVPR IEEE, P359
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], 2010, Technical Report
   [Anonymous], 2002, P 10 ACM INT C MULT
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Frintrop S, 2005, LECT NOTES COMPUT SC, V3663, P117
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Han B., INT C MULT 2011 SCOT, P1117
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li S., 2014, LOW RANK SPARSE DICT
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 46
TC 6
Z9 7
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 199
EP 207
DI 10.1016/j.jvcir.2017.04.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500018
DA 2024-07-18
ER

PT J
AU Cao, XW
   Wei, XX
   Guo, R
   Wang, CC
AF Cao, Xingwu
   Wei, Xingxing
   Guo, Rui
   Wang, Changchun
TI No embedding: A novel image cryptosystem for meaningful encryption
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image encryption; Privacy protection; Compressive sensing; Coupled
   dictionary learning; Image cryptosystem
ID WATERMARKING; DCT; SUPERRESOLUTION; SYSTEM
AB In this paper, we propose a novel image cryptosystem, which enables to encrypt the secret images with a smaller-size cover image. Compared with the existing meaningful encryption methods, our cryptosystem has three advantages: (1) non-embedding encryption, i.e., there isn't any data embedding into the cover image during the encryption process. (2) Our cryptosystem can simultaneously encrypt multiple secret images with one cover image, which greatly improves the security of secret images. (3) Our cryptosystem can accomplish not only the meaningful encryption, but also the meaningless encryption. Thus, people don't switch encryption methods when meeting different encryption requirements. Our scheme leverages the popular coupled dictionary learning and compressive sensing techniques to accomplish the whole task. Specifically, we use the coupled dictionaries to build connection between the cover image and the secret image, and apply the compressive sensing to decrypt the secret image. To demonstrate the effectiveness of the proposed cryptosystem, a series of experiments are conducted. Experimental results on gray images and colorful RGB images verify its superiority. (C) 2016 Published by Elsevier Inc.
C1 [Cao, Xingwu] Beihang Univ, Sch Elect Informat Engn, Beijing 100191, Peoples R China.
   [Wei, Xingxing] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Guo, Rui] Southeast Univ, Natl Engn Res Ctr Turbo Generator Vibrat, Nanjing, Jiangsu, Peoples R China.
   [Guo, Rui] Southeast Univ, Sch Energy & Environm, Nanjing, Jiangsu, Peoples R China.
   [Wang, Changchun] Air Force Equipment Acad, Beijing, Peoples R China.
C3 Beihang University; Tianjin University; Southeast University - China;
   Southeast University - China
RP Wei, XX (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
EM caoxingwu@ee.buaa.edu.cn; xwei@tju.edu.cn; gr@seu.edu.cn;
   china.wcc198324@163.com
FU National Natural Science Foundation of China [61758226, 51206025,
   71401175]; Ministry of Education of China [20120092120013]
FX This work was supported by National Natural Science Foundation of China
   (Nos. 61758226, 51206025 and 71401175) and Ph. D Programs Foundation of
   Ministry of Education of China (20120092120013).
CR [Anonymous], 1997, PRIMAL DUAL INTERIOR
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Barchiesi D, 2013, IEEE T SIGNAL PROCES, V61, P2055, DOI 10.1109/TSP.2013.2245663
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candès EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Cherian A., 2014, P ICML, P214
   Cox I.J., 2002, DIGITAL WATERMARKING, V53
   Denemark T, 2014, PROC SPIE, V9028, DOI 10.1117/12.2044803
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Lee KH, 2014, IEEE T IMAGE PROCESS, V23, P4336, DOI 10.1109/TIP.2014.2346026
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang XP, 2012, IEEE T IMAGE PROCESS, V21, P3108, DOI 10.1109/TIP.2012.2187671
   Zhao HD, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4077
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 37
TC 10
Z9 10
U1 0
U2 60
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 236
EP 249
DI 10.1016/j.jvcir.2016.08.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600021
DA 2024-07-18
ER

PT J
AU Tian, DP
   Shi, ZZ
AF Tian, Dongping
   Shi, Zhongzhi
TI Automatic image annotation based on Gaussian mixture model considering
   cross-modal correlations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Automatic image annotation; Gaussian mixture model; RPEM; Semantic
   correlation; Max-bisection; Image retrieval
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; EFFICIENT; SIMILARITY
AB Automatic image annotation has been an active topic of research in the field of computer vision and pattern recognition for decades. In this paper, we present a new method for automatic image annotation based on Gaussian mixture model (GMM) considering cross-modal correlations. To be specific, we first employ GMM fitted by the rival penalized expectation-maximization (RPEM) algorithm to estimate the posterior probabilities of each annotation keyword. Next, a label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity by seamlessly integrating the information from both image low level visual features and high level semantic concepts together, which can effectively avoid the phenomenon that different images with the same candidate annotations would obtain the same refinement results. Followed by the rank-two relaxation heuristics over the built label similarity graph is applied to further mine the correlation of the candidate annotations so as to capture the refining annotation results, which plays a crucial role in the semantic based image retrieval. The main contributions of this work can be summarized as follows: (1) Exploiting GMM that is trained by the RPEM algorithm to capture the initial semantic annotations of images. (2) The label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity of images associated with the corresponding labels. (3) Refining the candidate set of annotations generated by the GMM through solving the max-bisection based on the rank-two relaxation algorithm over the weighted label graph. Compared to the current competitive model SGMM-RW, we can achieve significant improvements of 4% and 5% in precision, 6% and 9% in recall on the Corel5k and Mirflickr25k, respectively. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Tian, Dongping] Baoji Univ Arts & Sci, Inst Comp Software, No 44,Baoguang Rd, Baoji 721007, Shaanxi, Peoples R China.
   [Shi, Zhongzhi] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, PR, Peoples R China.
C3 Baoji University of Arts & Sciences; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Tian, DP (corresponding author), Baoji Univ Arts & Sci, Inst Comp Software, No 44,Baoguang Rd, Baoji 721007, Shaanxi, Peoples R China.
EM tdp211@l63.com
RI yang, qing/JBR-8440-2023
FU National Program on Key Basic Research Project (973 Program)
   [2013CB329502]; National Natural Science Foundation of China [61035003,
   61202212]; Special Research Project of the Educational Department of
   Shaanxi Province of China [15JK1038]; Key Research Project of Baoji
   University of Arts and Sciences [ZK16047]
FX The authors would like to sincerely thank the editor and six anonymous
   reviewers for their valuable comments and insightful suggestions that
   have helped us to improve the paper. In addition, this work is partially
   supported by the National Program on Key Basic Research Project (973
   Program) (No. 2013CB329502), the National Natural Science Foundation of
   China (No. 61035003, No. 61202212), Special Research Project of the
   Educational Department of Shaanxi Province of China (No. 15JK1038) and
   the Key Research Project of Baoji University of Arts and Sciences (No.
   ZK16047).
CR [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2003, P 11 ACM INT C MULT
   [Anonymous], 2010, PROG ANATOMIC SCI, DOI DOI 10.1111/J.1472--4642.2010.00682.X
   Beecks C, 2011, IEEE I CONF COMP VIS, P1754, DOI 10.1109/ICCV.2011.6126440
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Burer S, 2001, SIAM J OPTIMIZ, V12, P503, DOI 10.1137/S1052623400382467
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Celik T, 2010, J VIS COMMUN IMAGE R, V21, P965, DOI 10.1016/j.jvcir.2010.09.005
   Cheung YM, 2005, IEEE T KNOWL DATA EN, V17, P750, DOI 10.1109/TKDE.2005.97
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Dixit M, 2011, PROC CVPR IEEE, P937, DOI 10.1109/CVPR.2011.5995674
   Dong YS, 2015, IEEE T CYBERNETICS, V45, P358, DOI 10.1109/TCYB.2014.2326059
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   El Sayad I, 2012, MULTIMED TOOLS APPL, V60, P455, DOI 10.1007/s11042-010-0596-x
   Fellbaum C, 2010, THEORY AND APPLICATIONS OF ONTOLOGY: COMPUTER APPLICATIONS, P231, DOI 10.1007/978-90-481-8847-5_10
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng ZY, 2013, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2013.203
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Hou YQ, 2015, LECT NOTES COMPUT SC, V9474, P71, DOI 10.1007/978-3-319-27857-5_7
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Inoue N, 2012, IEEE T MULTIMEDIA, V14, P1196, DOI 10.1109/TMM.2012.2191395
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jin YH, 2010, J SIGNAL PROCESS SYS, V58, P387, DOI 10.1007/s11265-009-0391-y
   Lavrenko V., 2003, NIPS
   Lee S, 2010, PATTERN RECOGN LETT, V31, P976, DOI 10.1016/j.patrec.2009.12.024
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li ZX, 2010, J VIS COMMUN IMAGE R, V21, P798, DOI 10.1016/j.jvcir.2010.06.004
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380
   [刘峥 Liu Zheng], 2011, [计算机研究与发展, Journal of Computer Research and Development], V48, P1246
   Luo X., 2013, P 2 INT C INF TECHN, P503
   Luszczkiewicz M, 2009, IEEE IMAGE PROC, P77, DOI 10.1109/ICIP.2009.5414097
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Raju L., 2012, INT J COMPUT SCI INF, V3, P5326
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Sahbi H, 2008, SOFT COMPUT, V12, P667, DOI 10.1007/s00500-007-0247-y
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tian D., 2015, HIGH TECHNOL LETT, V21, P78
   Tian DP, 2013, IEEE IMAGE PROC, P3996, DOI 10.1109/ICIP.2013.6738823
   Tian DP, 2014, KNOWL-BASED SYST, V72, P72, DOI 10.1016/j.knosys.2014.08.023
   Tian DP, 2014, INTELL AUTOM SOFT CO, V20, P335, DOI 10.1080/10798587.2013.878529
   Valipour Mohammad, 2014, International Journal of Hydrology Science and Technology, V4, P192, DOI 10.1504/IJHST.2014.067733
   Valipour M., 2012, Journal of Agricultural Science (Toronto), V4, P125
   Valipour M., 2012, Journal of Agricultural Science (Toronto), V4, P68
   Valipour M, 2015, METEOROL APPL, V22, P385, DOI 10.1002/met.1465
   Valipour M, 2013, J HYDROL, V476, P433, DOI 10.1016/j.jhydrol.2012.11.017
   Wan YC, 2012, LECT NOTES COMPUT SC, V7664, P210, DOI 10.1007/978-3-642-34481-7_26
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Wang ZY, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P384, DOI 10.1109/ICIG.2009.174
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang FF, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P506, DOI 10.1109/ICICISYS.2009.5358125
   Yohan Jin, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563044
   Zhang R., 2011, ACM Multimedia, P1513
   Zhu Guangyu., 2010, Proceedings of the International Conference on Multimedia, MM '10, P461
NR 68
TC 12
Z9 14
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 50
EP 60
DI 10.1016/j.jvcir.2017.01.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600005
DA 2024-07-18
ER

PT J
AU Zhou, ML
   Zhang, YF
   Li, B
   Hu, HM
AF Zhou, Mingliang
   Zhang, Yongfei
   Li, Bo
   Hu, Hai-Miao
TI Complexity-based intra frame rate control by jointing inter-frame
   correlation for high efficiency video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE HEVC; Complexity; Intra-frame; R-lambda model; Region-based; Quality
   smoothness
ID RATE-QUANTIZATION MODEL; MOTION ESTIMATION; RATE-DISTORTION; ALLOCATION
AB Rate control is of great significance for the High Efficiency Video Coding (HEVC). Due to the high efficiency and low complexity, the R-lambda model has been applied to the HEVC as the default rate control algorithm. However, the video content complexity, which can help improve the code efficiency and rate control performance, is not fully considered in the R-lambda model. To address this problem, an intra-frame rate control algorithm, which aims to provide improved and smooth video quality, is developed in this paper by jointly taking into consideration the frame-level content complexity between the encoded intra frames and the encoded inter frame, as well as the CTU-level complexity among different CTUs in texture-different regions for intra-frame. Firstly, in order to improve the rate control efficiency, this paper introduces a new prediction measure of content complexity for CTUs of intra-frame by jointly considering the inter-frame correlations between encoding intra frame and previous encoded inter frames as well as correlations between encoding intra frame and previous encoded intra frame. Secondly, a frame-level complexity-based bit-allocation-balancing method, by jointly considering the inter-frame correlation between intra frame and previous encoded inter frame, is brought up so that the smoothness of the visual quality can be improved between adjacent inter- and intra-frames. Thirdly, a new region-division and complexity-based CTU-level bit allocation method is developed to improve the objective quality and to reduce PSNR fluctuation among CTUs in intra-frame. In the end, related model parameters are updated during the encoding process to increase rate control accuracy. As a result, as can be seen from the extensive experimental results that compared with the state-of-the-art schemes, the video quality can be significantly improved. More specifically, up to 10.5% and on average 5.2% BD-Rate reduction was achieved compared to HM16.0 and up to 2.7% and an average of 2.0% BD-Rate reduction was achieved compared to state-of-the-art algorithm. Besides, a superior performance in enhancing the smoothness of quality can be achieved, which outperforms the state-of-the-art algorithms in term of flicker measurement, frame and CTU-wise PSNR, as well as buffer fullness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhou, Mingliang; Zhang, Yongfei; Li, Bo; Hu, Hai-Miao] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhang, Yongfei; Li, Bo; Hu, Hai-Miao] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, YF (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM zhangyf.ac@gmail.com
RI Zhou, Mingliang/HPC-0298-2023; Li, Bo/AAA-8968-2020; Li,
   bo/IWL-9318-2023; Zhang, Yongfei/A-1505-2010
OI Li, Bo/0000-0002-7294-6888; Zhang, Yongfei/0000-0002-5080-1733
FU National Key Research and Development Plan [2016YFC0801001]; National
   Natural Science Foundation of China [61272502]; State Key Program of
   National Natural Science Foundation of China [61632001]
FX This work was partially supported by the National Key Research and
   Development Plan (Grant No.2016YFC0801001) and the National Natural
   Science Foundation of China (No. 61272502) and the State Key Program of
   National Natural Science Foundation of China (No. 61632001).
CR [Anonymous], 2012, 2012 VISUAL COMMUNIC
   [Anonymous], 2013, PROC VIS COMMUN IMAG
   [Anonymous], 2013, Technical Report JCTVC-L1100
   Bossen F., 2011, G1200 JCTVC
   Chien MC, 2012, IEEE T BROADCAST, V58, P200, DOI 10.1109/TBC.2011.2182550
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Fan X., 2002, JOINT VID TEAM ISO I
   Hosking B, 2016, INT CONF ACOUST SPEE, P1486, DOI 10.1109/ICASSP.2016.7471924
   Hu H. M., J VIS COMMUN IMAGE R, V22
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Hu SD, 2012, IEEE T IMAGE PROCESS, V21, P1911, DOI 10.1109/TIP.2011.2176347
   Jing X, 2008, IEEE SIGNAL PROC LET, V15, P373, DOI 10.1109/LSP.2008.920010
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Li B., JCTVCK0103
   Li B., JCTVCM0036
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li Z. G., J VISUAL COMMUN IMAG, V17
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Lin WY, 2011, IEEE T CIRC SYST VID, V21, P237, DOI 10.1109/TCSVT.2011.2106290
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1533, DOI 10.1109/TCSVT.2010.2077773
   Lin WY, 2008, IEEE T CIRC SYST VID, V18, P1128, DOI 10.1109/TCSVT.2008.927111
   Liu JY, 2010, IEEE T CIRC SYST VID, V20, P967, DOI 10.1109/TCSVT.2010.2045924
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu YW, 2011, IEEE T BROADCAST, V57, P562, DOI 10.1109/TBC.2011.2105652
   Ma SW, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P793
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang MH, 2016, IEEE T IMAGE PROCESS, V25, P2943, DOI 10.1109/TIP.2016.2552646
   Wang MH, 2015, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2015.7168682
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang MH, 2009, IEEE SIGNAL PROC LET, V16, P679, DOI 10.1109/LSP.2009.2022147
   Wang X., JCTVCM0257
   Xiong HK, 2005, IEEE T BROADCAST, V51, P122, DOI 10.1109/TBC.2004.841757
   Yan B, 2009, IEEE SIGNAL PROC LET, V16, P145, DOI 10.1109/LSP.2008.2010813
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yimin Zhou, 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P648, DOI 10.1109/ICCNC.2013.6504163
   Zhou ML, 2016, J VIS COMMUN IMAGE R, V34, P204, DOI 10.1016/j.jvcir.2015.11.011
NR 38
TC 11
Z9 12
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 46
EP 64
DI 10.1016/j.jvcir.2016.11.013
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200005
DA 2024-07-18
ER

PT J
AU Su, SZ
   Ge, HW
   Yuan, YH
AF Su, Shuzhi
   Ge, Hongwei
   Yuan, Yun-Hao
TI Multi-patch embedding canonical correlation analysis for multi-view
   feature learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view feature learning; Canonical correlation analysis;
   Multi-locality preserving; Image recognition
ID EFFICIENT PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION;
   DISCRIMINANT-ANALYSIS; DEBLOCKING FILTER; FUSION; CCA
AB Locality-based feature learning for multi-view data has received intensive attention recently. As a result of only considering single-category local neighbor relationships, most of such the learning methods are difficult to well reveal intrinsic geometric structure information of raw high-dimensional data. To solve the problem, we propose a novel supervised multi-view correlation feature learning algorithm based on multi-category local neighbor relationships, called multi-patch embedding canonical correlation analysis (MPECCA). Our algorithm not only employs multiple local patches of each raw data to better capture the intrinsic geometric structure information, but also makes intraclass correlation features as close as possible by minimizing intraclass scatter of each view. Extensive experimental results on several real-world image datasets have demonstrated the effectiveness of our algorithm. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Su, Shuzhi; Ge, Hongwei; Yuan, Yun-Hao] Jiangnan Univ, Sch Internet Things Engn, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Ge, HW (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
EM sushuzhi@foxmail.com; ghw8601@163.com; yyhzbh@163.com
FU Graduate Innovation Project of Jiangsu Province [KYLX15_1169]; 111
   Project [B12018]; PAPD of Jiangsu Higher Education Institutions
FX This work is supported by the Graduate Innovation Project of Jiangsu
   Province under Grant no. KYLX15_1169, the 111 Project under Grant No.
   B12018, and PAPD of Jiangsu Higher Education Institutions.
CR [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], IEEE OTCBVS WS SERIE
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jones S, 2014, PROC CVPR IEEE, P820, DOI 10.1109/CVPR.2014.110
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Larson NB, 2014, EUR J HUM GENET, V22, P126, DOI 10.1038/ejhg.2013.69
   Lee K. J., 2014, GEN ASS C VIENN AUST
   Lin GF, 2016, PATTERN RECOGN, V53, P1, DOI 10.1016/j.patcog.2015.10.013
   Nazarpour A, 2015, PATTERN RECOGN, V48, P1854, DOI 10.1016/j.patcog.2014.12.001
   Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16
   Özuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633
   Peng Y, 2010, NEURAL PROCESS LETT, V31, P1, DOI 10.1007/s11063-009-9123-3
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun T.K., 2008, P IEEE INT C DAT MIN, P1043, DOI DOI 10.1109/ICDM.2008.28
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang FS, 2013, NEURAL PROCESS LETT, V37, P135, DOI 10.1007/s11063-012-9238-9
   Wang ZQ, 2013, SIGNAL PROCESS, V93, P1496, DOI 10.1016/j.sigpro.2012.06.023
   Wilks DS, 2014, INT J CLIMATOL, V34, P1405, DOI 10.1002/joc.3771
   Xing XL, 2016, SIGNAL PROCESS, V125, P329, DOI 10.1016/j.sigpro.2016.02.009
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P530, DOI 10.1109/DCC.2013.109
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yger F., 2012, Proceedings of the 29th International Conference on Machine Learning ICML 2012, P1071
   Yuan YH, 2014, PATTERN RECOGN, V47, P3907, DOI 10.1016/j.patcog.2014.06.016
   Yuan YH, 2014, PATTERN RECOGN, V47, P1411, DOI 10.1016/j.patcog.2013.09.009
NR 35
TC 6
Z9 7
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 47
EP 57
DI 10.1016/j.jvcir.2016.09.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000005
DA 2024-07-18
ER

PT J
AU Wang, CP
   Wang, XY
   Xia, ZQ
   Zhang, C
   Chen, XJ
AF Wang Chun-peng
   Wang Xing-yuan
   Xia Zhi-qiu
   Zhang Chuan
   Chen Xing-jun
TI Geometrically resilient color image zero-watermarking algorithm based on
   quaternion Exponent moments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image; Geometric attacks; Quaternion Exponent moments;
   Zero-watermarking
ID SCHEME
AB Although research on zero-watermarking has made great progress in recent years, most of it has been focused on grayscale images rather than color ones, and cannot resist geometric attacks efficiently. In this paper, we discuss properties of quaternion Exponent moments (QEMs) in detail and propose a robust color image zero-watermarking algorithm which is robust to geometric attacks. We first compute and select robust QEMs of the original color image, and then a binary feature image is constructed using the magnitude of the selected moments. Eventually, a bitwise exclusive-or is applied on the binary feature image and a scrambled binary logo to generate the zero-watermark image. Experimental results show that the proposed zero-watermarking algorithm is robust to both geometric attacks and common image processing attacks effectively. Compared to similar zero-watermarking algorithms and traditional watermarking algorithms based on QEMs, the proposed zero-watermarking algorithm has better performance. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang Chun-peng; Wang Xing-yuan; Xia Zhi-qiu; Zhang Chuan] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116023, Peoples R China.
   [Chen Xing-jun] Dalian Navy Acad, Operat Software & Simulat Inst, Dalian 116018, Peoples R China.
C3 Dalian University of Technology; Dalian Naval Academy
RP Wang, XY (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, 2 Linggong Rd, Dalian 116023, Peoples R China.
EM mpeng1122@163.com; wangxy@dlut.edu.cn
RI Zhang, Chuan/A-6503-2018; Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61672124, 61370145,
   61173183]; Program for Liaoning Excellent Talents in University
   [LR2012003]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61672124, 61370145 and 61173183), Program for Liaoning
   Excellent Talents in University (No: LR2012003).
CR Angulo J, 2010, J VIS COMMUN IMAGE R, V21, P33, DOI 10.1016/j.jvcir.2009.10.002
   [Anonymous], TIEN TZU HSUEH PAO
   [Anonymous], APPL MATH INF SCI
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Col MAJD, 2001, THEOR COMPUT SCI, V259, P245
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Kantor I.L, 1989, Hypercomplex Numbers: An Ele-mentary Introduction to Algebras
   Li YN, 2013, IEEE SIGNAL PROC LET, V20, P803, DOI 10.1109/LSP.2013.2267775
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Ping ZL, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064619
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   [王向阳 Wang Xiangyang], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P651
   Wójtowicz W, 2016, J VIS COMMUN IMAGE R, V38, P1, DOI 10.1016/j.jvcir.2016.02.006
   Xue JH, 2011, IEEE T IMAGE PROCESS, V20, P2392, DOI 10.1109/TIP.2011.2114358
NR 22
TC 67
Z9 70
U1 3
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 247
EP 259
DI 10.1016/j.jvcir.2016.10.004
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000022
DA 2024-07-18
ER

PT J
AU Adu, JH
   Xie, SH
   Gan, JH
AF Adu, Jianhua
   Xie, Shenghua
   Gan, Jianhong
TI Image fusion based on visual salient features and the cross-contrast
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Nonsubsampled contourlet transform; Visual salient
   features; The cross-contrast
ID PARALLEL FRAMEWORK; TRANSFORM; ATTENTION
AB To extract and combine the features of the original images, a novel algorithm based on visual salient features and the cross-contrast is proposed in this paper. Original images were decomposed into low frequency subband coefficients and bandpass direction subband coefficients by using the nonsubsampled contourlet transform. Three maps of visual salient features are constructed based on visual salient features the local energy, the contrast and the gradient respectively, and low-frequency subband coefficients are got by utilizing these visual saliency maps. The cross-contrast is obtained by computing the ratio between the local gray mean of bandpass direction subband coefficients and the local gray mean of fused low-frequency subband coefficients. Bandpass direction subband coefficients is goted by the cross contrast. Comparison experiments have been performed on different image sets, and experimental results demonstrate that the proposed method performs better in both subjective and objective qualities. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Adu, Jianhua; Gan, Jianhong] Chengdu Univ Informat Technol, Software Dept, Chengdu 610225, Peoples R China.
   [Xie, Shenghua] Sichuan Acad Med Sci, Chengdu 610072, Peoples R China.
   [Xie, Shenghua] Sichuan Prov Peoples Hosp, Sichuan Prov Key Laborary Ultrasound Cardiac Elec, Chengdu 610072, Peoples R China.
C3 Chengdu University of Information Technology; Sichuan Provincial
   People's Hospital; Sichuan Provincial People's Hospital
RP Xie, SH (corresponding author), Sichuan Acad Med Sci, Chengdu 610072, Peoples R China.; Xie, SH (corresponding author), Sichuan Prov Peoples Hosp, Sichuan Prov Key Laborary Ultrasound Cardiac Elec, Chengdu 610072, Peoples R China.
EM adjh_work@163.com
FU Scientific Research Foundation of CUIT [KYTZ201322]
FX We sincerely thank the reviewers and editors for their carefully
   checking our manuscript and providing constructive suggestions. Project
   (KYTZ201322) Supported by the Scientific Research Foundation of CUIT. We
   have benefited from the images supplied by TNO Human Factors Research
   Institute in the Netherlands.
CR Adu JH, 2012, J MOD OPTIC, V59, P1355, DOI 10.1080/09500340.2012.714802
   Aiazzi B., 1999, IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293), P1183, DOI 10.1109/IGARSS.1999.774572
   Al-Azawi M, 2014, MULTIMED TOOLS APPL, P1
   [Anonymous], 2010, 2010 13 INT C INF FU, DOI DOI 10.1109/ICIF.2010.5712006
   Bai XZ, 2012, APPL OPTICS, V51, P7566, DOI 10.1364/AO.51.007566
   Beaulieu M, 2003, INT GEOSCI REMOTE SE, P4032
   Bhatnagar G., 2015, SIVIP, V9, P1
   Chai Y, 2010, OPT COMMUN, V283, P3591, DOI 10.1016/j.optcom.2010.04.100
   Chai Y, 2011, OPT COMMUN, V284, P4376, DOI 10.1016/j.optcom.2011.05.046
   Chen T., 1987, APPL OPTICS, V26, P5204
   Choi M, 2005, IEEE GEOSCI REMOTE S, V2, P136, DOI 10.1109/LGRS.2005.845313
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Du J., 2016, NEUROCOMPUTING
   Fang Y., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1049
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Ganasala P, 2014, BIOMED ENG LETT, V4, P414, DOI 10.1007/s13534-014-0161-z
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   García JA, 2010, PATTERN RECOGN, V43, P1618, DOI 10.1016/j.patcog.2009.09.027
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Hoelscher-Hoebing U, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P571, DOI 10.1109/OCEANS.1998.725811
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang Y, 2014, INFORM FUSION, V18, P107, DOI 10.1016/j.inffus.2013.06.001
   KUMARESAN SS, 1994, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.1994.413855
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Li S., 2011, INT J WAVELETS MULTI, V6, P37
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Pu T, 2000, OPT ENG, V39, P2075, DOI 10.1117/1.1303728
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   SOLBERG AHS, 1994, IEEE T GEOSCI REMOTE, V32, P768, DOI 10.1109/36.298006
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wang J., 2013, J ELECTRON IMAGING, V22, P6931
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351
   Xue ZY, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P622
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   YONGJIAN H, 2003, COMP SCI DIG WAT 2 I, P86
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
NR 49
TC 15
Z9 15
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 218
EP 224
DI 10.1016/j.jvcir.2016.06.026
PN A
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500020
DA 2024-07-18
ER

PT J
AU Benseddik, HE
   Hadj-Abdelkader, H
   Cherki, B
   Bouchafa, S
AF Benseddik, Houssem-Eddine
   Hadj-Abdelkader, Hicham
   Cherki, Brahim
   Bouchafa, Samia
TI Direct method for rotation estimation from spherical images using 3D
   mesh surfaces with SPHARM representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rotation estimation; 3D mesh surfaces; Spherical images; Spherical
   harmonic functions; Spherical parameterization; 3D mesh generation
ID HARMONICS; RETRIEVAL
AB Since a large field of view obviously bears important advantages, the use of spherical images is becoming increasingly important in various computer vision and image processing applications. This paper presents a novel rotation estimation approach for spherical images based on 3D mesh representation of gray level intensity. Once the 3D meshes of the underlying spherical images are obtained, the 3D rotation can be estimated directly and efficiently, without feature extraction and matching process. Subsequently, we propose a direct method for 3D object rotation estimation using spherical harmonics representation with SVD decomposition and ICP algorithm for estimation refinement. Experimental results validate our approach and prove its suitability and robustness for rotation estimation. Moreover, it performs well against noisy images, brightness changes, image compression and occlusions. A comparative study of our proposed approach with four similar methods for 3D rotation estimation between spherical images, is realized to prove its effectiveness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Benseddik, Houssem-Eddine; Hadj-Abdelkader, Hicham; Bouchafa, Samia] Univ Evry, Lab IBISC, Evry, France.
   [Benseddik, Houssem-Eddine; Cherki, Brahim] Univ Tlemcen, Lab Automat, Tilimsen, Algeria.
   [Benseddik, Houssem-Eddine] Ctr Dev Technol Avancees, Algiers, Algeria.
C3 Universite Paris Saclay; Universite Abou Bekr Belkaid
RP Benseddik, HE (corresponding author), Univ Evry, Lab IBISC, Evry, France.
EM houssem.eln@gmail.com; hicham.hadj-abdelkader@ibisc.univ-evry.fr;
   brahim.cherki@gmail.com; samia.bouchafa@ibisc.univ-evry.fr
RI CHERKI, Brahim/P-8180-2016
OI Bouchafa, Samia/0000-0002-2860-8128
CR Abdelkader H. H., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3572
   Althloothi S, 2013, IEEE T IMAGE PROCESS, V22, P2306, DOI 10.1109/TIP.2013.2249083
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brechbuhler C., 1995, COMPUT VIS IMAGE UND, V61
   Burel G, 1995, GRAPH MODEL IM PROC, V57, P400, DOI 10.1006/gmip.1995.1034
   DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966
   Fang QQ, 2009, I S BIOMED IMAGING, P1142, DOI 10.1109/ISBI.2009.5193259
   Fermuller C, 1998, INT J COMPUT VISION, V28, P137, DOI 10.1023/A:1008063000586
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   García MA, 2000, LECT NOTES COMPUT SC, V1842, P844
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Heng HA, 2007, IEEE T INF TECHNOL B, V11, P474, DOI [10.1109/TITB.2006.897577, 10.1109/TITB.2007.897577]
   Hoover RC, 2009, IEEE T IMAGE PROCESS, V18, P2562, DOI 10.1109/TIP.2009.2026622
   Kazhdan M, 2007, IEEE T PATTERN ANAL, V29, P1221, DOI 10.1109/TPAMI.2007.1032
   Kostelec PJ, 2008, J FOURIER ANAL APPL, V14, P145, DOI 10.1007/s00041-008-9013-5
   Lu GY, 2016, INT CONF ACOUST SPEE, P932, DOI 10.1109/ICASSP.2016.7471812
   Lu GY, 2015, IEEE I CONF COMP VIS, P2434, DOI 10.1109/ICCV.2015.280
   Lu GY, 2015, MULTIMED TOOLS APPL, V74, P479, DOI 10.1007/s11042-014-1977-3
   Makadia A, 2006, IEEE T PATTERN ANAL, V28, P1170, DOI 10.1109/TPAMI.2006.150
   Makadia A, 2004, INT C PATT RECOG, P590, DOI 10.1109/ICPR.2004.1334598
   Massey W., 1991, BASIC COURSE ALGEBRA, V127
   Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084
   Osteen PR, 2012, IEEE INT CONF ROBOT, P1679, DOI 10.1109/ICRA.2012.6225098
   Pu JT, 2006, COMPUT AIDED DESIGN, V38, P249, DOI 10.1016/j.cad.2005.10.009
   Sajjanhar A, 2009, LECT NOTES COMPUT SC, V5788, P309, DOI 10.1007/978-3-642-04394-9_38
   Shen L, 2006, IMAGE VISION COMPUT, V24, P743, DOI 10.1016/j.imavis.2006.01.011
NR 27
TC 5
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 708
EP 720
DI 10.1016/j.jvcir.2016.08.010
PN B
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600025
DA 2024-07-18
ER

PT J
AU Chang, YJ
   Ho, YS
AF Chang, Yong-Jun
   Ho, Yo-Sung
TI Disparity map enhancement in pixel based stereo matching method using
   distance transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Disparity map; Distance transform; Disparity error
   detection; Disparity error correction
ID COST AGGREGATION
AB With the great success in three-dimensional (3D) movies, a lot of 3D content have been generated. Depth information is one of the important elements in 3D content generation. Stereo matching methods obtain depth information using the characteristic of binocular disparity. These methods find corresponding points between two images which have different viewpoints to calculate the disparity value. However, these methods have difficulties computing accurate disparity values in the textureless region. Smeared pixels near the edge region also make difficult for the stereo matching. In this paper, we propose a pixel based cost computation for the cross-scale stereo matching using the distance transform to improve these problems. In addition, the disparity error detection and correction methods are also proposed as a post-processing step. As a result, we obtain the enhanced disparity map which is robust to the textureless region and the edge region. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chang, Yong-Jun; Ho, Yo-Sung] Gwangju Inst Sci & Technol, 123 Cheomdan Gwagiro, Gwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Ho, YS (corresponding author), Gwangju Inst Sci & Technol, 123 Cheomdan Gwagiro, Gwangju 500712, South Korea.
EM yjchang@gist.ac.kr; hoyo@gist.ac.kr
FU 'Cross-Ministry Giga KOREA Project' of the Ministry of Science, ICT and
   Future Planning, Republic of Korea (ROK) [Development of Interactive and
   Realistic Massive Giga-Content Technology] [GK16C0100]
FX This research was supported by the 'Cross-Ministry Giga KOREA Project'
   of the Ministry of Science, ICT and Future Planning, Republic of Korea
   (ROK). [GK16C0100, Development of Interactive and Realistic Massive
   Giga-Content Technology].
CR [Anonymous], IEEE INT WORKSH MULT
   [Anonymous], TECHNICAL REPORT
   [Anonymous], KOR I SMART MED FALL
   Bleyer M, 2007, SIGNAL PROCESS-IMAGE, V22, P127, DOI 10.1016/j.image.2006.11.012
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang YL, 2016, EURASIP J WIREL COMM, P1, DOI 10.1186/s13638-016-0721-2
   Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Heo Y., 2008, Proceedings of the International Conference on Computer Vision and Pattern Recognition, P1, DOI 10.1109/CVPR.2008.4587697
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Jang WS, 2014, J VIS COMMUN IMAGE R, V25, P1595, DOI 10.1016/j.jvcir.2014.07.005
   Kang YS, 2011, IEEE T CONSUM ELECTR, V57, P1041, DOI 10.1109/TCE.2011.6018853
   Kim SY, 2010, IEEE T CONSUM ELECTR, V56, P1730, DOI 10.1109/TCE.2010.5606319
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Martens J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144998
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Menz MD, 2003, NAT NEUROSCI, V6, P59, DOI 10.1038/nn986
   Min D, 2010, IEEE IMAGE PROC, P1777, DOI 10.1109/ICIP.2010.5653792
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein Daniel., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang L, 2014, J REAL-TIME IMAGE PR, V9, P447, DOI 10.1007/s11554-012-0275-4
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang K, 2014, PROC CVPR IEEE, P1590, DOI 10.1109/CVPR.2014.206
NR 28
TC 14
Z9 14
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 118
EP 127
DI 10.1016/j.jvcir.2016.06.017
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500013
DA 2024-07-18
ER

PT J
AU Cheng, H
   Zhang, XP
   Yu, J
   Zhang, Y
AF Cheng, Hang
   Zhang, Xinpeng
   Yu, Jiang
   Zhang, Yuan
TI Encrypted JPEG image retrieval using block-wise feature comparison
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Image encryption; JPEG image; Feature descriptor
ID SEARCH
AB This paper proposes a novel scheme for encrypted JPEG image retrieval, which includes image encryption and retrieval phases. Using the scheme, the content owner encrypts JPEG images by jointly applying permutation cipher and stream cipher to their corresponding bit-streams, and then transmits encrypted versions to a database server. With an encrypted query image, although the server learns nothing about the plaintext content, it may extract local statistical feature of intra-block AC coefficients using a new feature descriptor. Subsequently, exploiting block-wise feature comparison, the server can measure the similarity between encrypted query image and database image. After that, the encrypted images with plaintext content similar to the query image are returned to the authorized user. Experimental results show that the proposed scheme can ensure both format compliance and file size preservation while providing effective retrieval service in encrypted domain. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Cheng, Hang; Zhang, Xinpeng; Yu, Jiang; Zhang, Yuan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Cheng, Hang] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Peoples R China.
   [Zhang, Xinpeng] Shanghai Univ, Key Lab Specialty Fiber Opt & Opt Access, Shanghai 200444, Peoples R China.
   [Zhang, Yuan] Huzhou Univ, Coll Informat Engn, Huzhou 313000, Peoples R China.
C3 Shanghai University; Fuzhou University; Shanghai University; Huzhou
   University
RP Cheng, H (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM hcheng@fzu.edu.cn; xzhang@shu.edu.cn; sxyj1981@shu.edu.cn;
   zhangyuan@hutc.zj.cn
FU National Natural Science Foundation of China [61472235, 61525203];
   Program of Shanghai Dawn Scholar [14SG36]; Shanghai Academic Research
   Leader [16XD1401200]; Natural Science Foundation of Shanghai
   [16ZR1413100]; Excellent University Young Teachers Training Program of
   Shanghai Municipal Education Commission [ZZsdl15105]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61472235 and 61525203, the Program of Shanghai Dawn
   Scholar under Grant 14SG36, Shanghai Academic Research Leader under
   Grant 16XD1401200, the Natural Science Foundation of Shanghai under
   Grant 16ZR1413100, and the Excellent University Young Teachers Training
   Program of Shanghai Municipal Education Commission under Grant
   ZZsdl15105.
CR [Anonymous], 2013, INT C FIN CRYPT DAT
   [Anonymous], 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587388
   [Anonymous], IS T SPIE ELECT IMAG
   Barni M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P231
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Cash D, 2013, LECT NOTES COMPUT SC, V8042, P353, DOI 10.1007/978-3-642-40041-4_20
   Cheng H, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0028-6
   Chou Jia-Kai, 2015, MULTIMED TOOLS APPL, P1
   Curtmola Reza, 2006, P 13 ACM C COMP COMM, DOI DOI 10.1145/1180405.1180417
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Evans David, 2011, P NETW DISTR SYST SE
   Fanti G, 2013, IEEE SIGNAL PROC MAG, V30, P53, DOI 10.1109/MSP.2012.2229783
   Ferreira B, 2015, SYM REL DIST SYST, P11, DOI 10.1109/SRDS.2015.27
   Goh E.-J., 2003, Rep. 2003/216
   Khan MF, 2010, STUD ISLAM FINANC AC, P1, DOI 10.1109/CEC.2010.5586547
   Kuroiwa K., 2006, 2006 International Symposium on Intelligent Signal Processing and Communications (IEEE Cat. No.06EX1444), P821, DOI 10.1109/ISPACS.2006.364771
   Lian SG, 2004, IEEE INFOR VIS, P217, DOI 10.1109/IV.2004.1320147
   Lu WJ, 2014, IEEE ACCESS, V2, P125, DOI 10.1109/ACCESS.2014.2307057
   Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888
   Minemura K, 2012, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2012.6466845
   Munadi K, 2015, 2015 ASIA PACIFIC CONFERENCE ON MULTIMEDIA AND BROADCASTING, P1, DOI 10.1109/APMediaCast.2015.7210285
   Munadi K, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1052-1
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Shreyamsha Kumar BK, 2010, SIGNAL IMAGE VIDEO P, V4, P419, DOI 10.1007/s11760-009-0131-6
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Tang L., 1997, P 4 ACM INT C MULT, P219
   Torrubia A, 2003, ICCE: 2003 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P58, DOI 10.1109/ICCE.2003.1218805
   Wang C, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.34
   Wang C, 2012, IEEE INFOCOM SER, P451, DOI 10.1109/INFCOM.2012.6195784
   Yang B., 2009, PROC 16 INT C DIGITA, P1, DOI [10.1109/ICDSP.2009.5201075, DOI 10.1109/ICDSP.2009.5201075]
   Zhang XP, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P446, DOI 10.1109/ChinaSIP.2014.6889282
NR 32
TC 40
Z9 40
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 111
EP 117
DI 10.1016/j.jvcir.2016.06.016
PN A
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500012
DA 2024-07-18
ER

PT J
AU Ghosh, D
   Kaabouch, N
   Hu, WC
AF Ghosh, Debabrata
   Kaabouch, Naima
   Hu, Wen-Chen
TI A robust iterative super-resolution mosaicking algorithm using an
   adaptive and directional Huber-Markov regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mosaicking; Super-resolution; Scale invariant feature transform (SIFT);
   Homography; Steepest descent optimization; Huber-Markov regularization
ID IMAGE QUALITY ASSESSMENT; RESOLUTION
AB A robust spatial-domain based super-resolution mosaicking algorithm is proposed. This technique incorporates a mosaicking algorithm, and a super-resolution reconstruction algorithm. The main contribution of this paper is the development of a super-resolution algorithm using a Huber Norm-based maximum likelihood (ML) estimation in combination with an adaptive directional Huber-Markov regularization. Another contribution is the development of a no-reference performance metric based on reciprocal singular value curve for quantitative evaluation of the proposed algorithm. Along with the above-mentioned metric, five other performance measurement metrics are used to assess the efficiency of the algorithm. The performance of this algorithm is compared with the performances of two different algorithms: the Tikhonov regularization-based and the total variation (TV)-based super-resolution mosaicking algorithms. Results show that the proposed algorithm outperforms the other two techniques in terms of lowest amount of blur and noise in the output. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ghosh, Debabrata; Kaabouch, Naima] Univ North Dakota, Dept Elect Engn, Grand Forks, ND 58202 USA.
   [Hu, Wen-Chen] Univ North Dakota, Dept Comp Sci, Grand Forks, ND 58202 USA.
C3 University of North Dakota Grand Forks; University of North Dakota Grand
   Forks
RP Ghosh, D (corresponding author), Univ North Dakota, Dept Elect Engn, Grand Forks, ND 58202 USA.
EM debabrata.ghosh@ndus.edu
OI Ghosh, Debabrata/0000-0002-4603-1238
CR Ait-Aoudia S., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P652, DOI 10.1109/IV.2012.113
   [Anonymous], 2012, P 42 AIAA FLUID DYNA
   [Anonymous], P MED IM INF AUG
   Ben-Ezra A, 2009, I S BIOMED IMAGING, P254, DOI 10.1109/ISBI.2009.5193032
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Chen HH, 2014, ELECTRON LETT, V50, P1834, DOI 10.1049/el.2014.1429
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Farsiu S., 2006, ELECT IMAG
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   GAO G, 2007, 2 INT C INN COMP INF, P471
   Ghosh D., 2014, COMPUT INFORM SCI, V7, P68, DOI [10.5539/cis.v7n2p68, DOI 10.5539/cis.v7n2p68]
   He H, 2006, IEEE T IMAGE PROCESS, V15, P592, DOI 10.1109/TIP.2005.860599
   Hou YQ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P123, DOI 10.1109/ICMA.2009.5246042
   Kim Y.J., 2011, SPIE IMAGE QUAL SYST, V7867
   Laflen J.B., 2009, IEEE APPL IM PATT RE, P1
   Lee ES, 2003, IEEE T IMAGE PROCESS, V12, P826, DOI 10.1109/TIP.2003.811488
   Lei Yang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P846, DOI 10.1109/CISP.2011.6100279
   Li Tian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P493, DOI 10.1109/ICPR.2010.127
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miao Ligang, 2011, Proceedings of the 2011 2nd International Conference on Intelligent Control and Information Processing (ICICIP), P1094, DOI 10.1109/ICICIP.2011.6008422
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Nelson K, 2012, INT SYM QUAL ELECT, P1, DOI 10.1109/ISQED.2012.6187466
   Ng MK, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/74585
   Okumura KI, 2013, IEEE INT C INT ROBOT, P2665, DOI 10.1109/IROS.2013.6696732
   Panagiotopoulou A, 2009, OPT ENG, V48, DOI 10.1117/1.3265543
   Pandey A., 2013, India Conference (INDICON), 2013 Annual IEEE, P1
   Park S., 2012, AIAA INFOTECH AEROSP
   Park S., 2012, IS T SPIE ELECT IMAG
   Patanavijit V., 2006, 2006 International Symposium on Intelligent Signal Processing and Communications (IEEE Cat. No.06EX1444), P13, DOI 10.1109/ISPACS.2006.364825
   Peng Kang, 2011, 2011 International Conference on Multimedia Technology, P155
   Pickering M., 2008, J PHYS C SER
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Qureshi, 2012, P 6 ACM IEEE INT C D, P1
   Rajan D, 2003, IEEE SIGNAL PROC MAG, V20, P49, DOI 10.1109/MSP.2003.1203209
   Rong W, 2009, 2009 24TH INTERNATIONAL CONFERENCE IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2009), P271, DOI 10.1109/IVCNZ.2009.5378399
   Sang QB, 2014, SIGNAL PROCESS-IMAGE, V29, P1149, DOI 10.1016/j.image.2014.09.005
   Shi Wenzhong, 2006, Wuhan University Journal of Natural Sciences, V11, P399, DOI 10.1007/BF02832131
   Su H, 2012, IEEE T IMAGE PROCESS, V21, P1782, DOI 10.1109/TIP.2011.2173204
   Wang J, 2011, APPL MECH MATER, V80-81, P207, DOI 10.4028/www.scientific.net/AMM.80-81.207
   Wang Q, 2009, IEEE IMAGE PROC, P1537, DOI 10.1109/ICIP.2009.5414518
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan QQ, 2013, IEEE T IMAGE PROCESS, V22, P2327, DOI 10.1109/TIP.2013.2251648
   Yuan QQ, 2012, IEEE T CIRC SYST VID, V22, P379, DOI 10.1109/TCSVT.2011.2163447
   Zhang J., 2007, 2 INT C INN COMP INF, P576
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zomet A, 2001, SPRING INT SER ENG C, V632, P195
NR 46
TC 10
Z9 10
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 98
EP 110
DI 10.1016/j.jvcir.2016.06.008
PN A
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500011
DA 2024-07-18
ER

PT J
AU Wu, HT
   Cheung, YM
   Huang, JW
AF Wu, Hao-Tian
   Cheung, Yiu-ming
   Huang, Jiwu
TI Reversible data hiding in Paillier cryptosystem
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Paillier cryptosystem; Value expansion; Self-blinding; Reversible data
   hiding; Homomorphic encryption
ID FULLY HOMOMORPHIC ENCRYPTION; IMAGES; DIFFERENCE; EXPANSION; DOMAIN;
   ERROR
AB In this paper, reversible image data hiding in the Paillier cryptosystem is investigated. To transmit additional data in homomorphic encryption domain, two algorithms are proposed for different application scenarios. By exploiting the additive homomorphism, high-capacity data hiding can be accomplished with the first algorithm by conducting value expansion on the encrypted pixel values. But the hidden data can only be extracted after image decryption (i.e., in plain-text domain). With the second algorithm, both of data embedding and extraction can be performed in the encryption domain by exploiting the self blinding property, while the corresponding plain-text values are unchanged. Compared with the reversible data hiding algorithms designed for encryption with a cipher stream, the proposed ones are more applicable in cloud computing without degrading the security level. Thus the additional data can be loss-lessly transmitted in the different applications of Paillier cryptosystem. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wu, Hao-Tian] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Cheung, Yiu-ming] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Huang, Jiwu] Shenzhen Univ, Coll Informat Engn, Shenzhen, Peoples R China.
   [Huang, Jiwu] Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.
C3 South China University of Technology; Hong Kong Baptist University;
   Shenzhen University
RP Wu, HT (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM htwu1981@gmail.com; ymc@comp.hkbu.edu.hk; jwhuang@szu.edu.cn
RI Cheung, Yiu-ming/E-2050-2015; huang, jw/KVY-9917-2024; Wu,
   Hao-Tian/S-5360-2019
OI Cheung, Yiu-ming/0000-0001-7629-4648; Wu, Hao-Tian/0000-0001-6462-7193
FU National Natural Science Foundation of China [61100169, 61672444,
   61272366]; Shenzhen RD Program [JCYJ20160328144421330,
   GJHZ20140418191518323]; Natural Science Foundation of Jiangsu Province
   of China [BK20151131]
FX This work was supported by National Natural Science Foundation of China
   (Nos. 61100169, 61672444, 61272366), Shenzhen R&D Program
   (JCYJ20160328144421330, GJHZ20140418191518323) and Natural Science
   Foundation of Jiangsu Province of China (BK20151131).
CR [Anonymous], 1978, FDN SEC COMPUT
   [Anonymous], 2011, P 19 ACM INT C MULTI
   Barni M, 2013, IEEE SIGNAL PROC MAG, V30, P16, DOI 10.1109/MSP.2012.2229069
   Barni M, 2011, IEEE T INF FOREN SEC, V6, P452, DOI 10.1109/TIFS.2011.2108650
   Bianchi T, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/716357
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Brakerski Z, 2014, SIAM J COMPUT, V43, P831, DOI 10.1137/120868669
   Brakerski Z, 2013, LECT NOTES COMPUT SC, V7778, P1, DOI 10.1007/978-3-642-36362-7_1
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Cheung YM, 2007, IEEE T CIRC SYST VID, V17, P1007, DOI 10.1109/TCSVT.2007.903553
   Cramer R, 1997, EUR T TELECOMMUN, V8, P481, DOI 10.1002/ett.4460080506
   Gentry C, 2012, LECT NOTES COMPUT SC, V7237, P465, DOI 10.1007/978-3-642-29011-4_28
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Tari Z, 2015, IEEE CLOUD COMPUT, V2, P30, DOI 10.1109/MCC.2015.45
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang J., IEEE T CYBE IN PRESS
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2010, IEEE T INSTRUM MEAS, V59, P221, DOI 10.1109/TIM.2009.2022453
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Zhang X., IEEE T CIRC IN PRESS
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng PJ, 2013, IEEE T IMAGE PROCESS, V22, P2455, DOI 10.1109/TIP.2013.2253474
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 37
TC 50
Z9 53
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 765
EP 771
DI 10.1016/j.jvcir.2016.08.021
PN B
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600030
DA 2024-07-18
ER

PT J
AU Wang, XY
   Liu, YN
   Han, MM
   Yang, HY
AF Wang, Xiang-yang
   Liu, Yu-nan
   Han, Meng-meng
   Yang, Hong-ying
TI Local quaternion PHT based robust color image watermarking algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image watermarking; Desynchronization attacks; SIFER detector;
   Color invariance model; Algebra of quaternions; Polar harmonic transform
ID SPREAD-SPECTRUM WATERMARKING; TRANSFORM; RESILIENT; EXTRACTION; MOMENTS;
   SCHEME
AB It is a challenging work to design a robust localized color image watermarking scheme against desynchronization attacks. There are two main drawbacks indwelled in current localized color image watermarking: firstly, the pure gray-based feature points detectors were utilized, in which the important color information is ignored. Secondly, the watermarking algorithms were designed mainly to mark the image luminance component only, in which the significant color channels correlation are neglected. In this paper, we propose a robust color image watermarking algorithm using local quaternion PHT (Polar Harmonic Transform), which is invariant to various noises, local geometric transformations, and color variations. Firstly, the stable color image feature points are extracted by using new color image feature point detector, in which the SIFER (Scale-Invariant Feature detector with Error Resilience) detector and color invariance model are incorporated. Then, the affine invariant local regions are built adaptively according to local image content variation. Finally, the digital watermark is embedded into the local regions by modulating the invariant quaternion PHT modulus coefficients. Experiments are carried out on a color image set collected from Internet, and the extensive experimental works have shown that the proposed color image watermarking is not only invisible and robust against common image processing operations such as median filtering, noise adding, and JPEG compression, but also has conquered those challenging desynchronization attacks. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Xiang-yang; Liu, Yu-nan; Han, Meng-meng; Yang, Hong-ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Liu, Yunan/GXH-9776-2022; Yang, Jing/JFK-4046-2023; Liu,
   Yunan/JGM-3801-2023
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61272416];
   Liaoning Research Project for Institutions of Higher Education of China
   [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61472171 & 61272416, and Liaoning Research
   Project for Institutions of Higher Education of China under Grant No.
   L2013407.
CR Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   Ahmed T, 2014, ADV INTELLIGENT SYST, VII, P281, DOI DOI 10.1007/978-3-319-03095-/1_31
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Behloul A., 2014, P 6 ACM INT C MAN EM, P139
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Bollimpalli P, 2014, IEEE IMAGE PROC, P5507, DOI 10.1109/ICIP.2014.7026114
   Botta M, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2568224
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen CH, 2014, OPTIK, V125, P1134, DOI 10.1016/j.ijleo.2013.07.126
   Deng Cheng, 2010, Acta Automatica Sinica, V36, P221, DOI 10.3724/SP.J.1004.2010.00221
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Ji F, 2013, NEUROCOMPUTING, V106, P42, DOI 10.1016/j.neucom.2012.09.032
   Keskinarkaus A, 2012, J VIS COMMUN IMAGE R, V23, P507, DOI 10.1016/j.jvcir.2012.01.010
   Kuribayashi M, 2014, IEEE T INF FOREN SEC, V9, P610, DOI 10.1109/TIFS.2014.2305799
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Li M, 2013, IEEE T INF FOREN SEC, V8, P1201, DOI 10.1109/TIFS.2013.2264462
   Liu S, 2015, SIGNAL PROCESS, V109, P345, DOI 10.1016/j.sigpro.2014.06.024
   Mainali P, 2013, INT J COMPUT VISION, V104, P172, DOI 10.1007/s11263-013-0622-3
   Mathon B, 2014, IEEE T IMAGE PROCESS, V23, P1694, DOI 10.1109/TIP.2014.2305873
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Singh C, 2014, IET IMAGE PROCESS, V8, P373, DOI 10.1049/iet-ipr.2013.0382
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tian HW, 2013, IEEE T CYBERNETICS, V43, P2190, DOI 10.1109/TCYB.2013.2245415
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang XY, 2015, APPL MATH COMPUT, V256, P951, DOI 10.1016/j.amc.2015.01.075
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Yang HY, 2013, ENG APPL ARTIF INTEL, V26, P2058, DOI 10.1016/j.engappai.2013.04.014
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang XQ, 2014, SIGNAL PROCESS-IMAGE, V29, P1171, DOI 10.1016/j.image.2014.09.003
   Zhao Y, 2012, SCI CHINA INFORM SCI, V55, P650, DOI 10.1007/s11432-011-4470-x
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 39
TC 18
Z9 20
U1 3
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 678
EP 694
DI 10.1016/j.jvcir.2016.04.011
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100057
DA 2024-07-18
ER

PT J
AU Xu, LL
   Wu, X
   Chen, KW
   Yao, L
AF Xu, Lele
   Wu, Xia
   Chen, Kewei
   Yao, Li
TI Supervised within-class-similar discriminative dictionary learning for
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discriminative dictionary learning; Face recognition; Linear
   classification error; Within-class scatter
ID SPARSE REPRESENTATION; K-SVD; ALGORITHM
AB The current study puts forward a supervised within-class-similar discriminative dictionary learning (SCDDL) algorithm for face recognition. Some popular discriminative dictionary learning schemes for recognition tasks always incorporate the linear classification error term into the objective function or make some discriminative restrictions on representation coefficients. In the presented SCDDL algorithm, we propose to directly restrict the representation coefficients to be similar within the same class and simultaneously include the linear classification error term in the supervised dictionary learning scheme to derive a more discriminative dictionary for face recognition. The experimental results on three large well-known face databases suggest that our approach can enhance the fisher ratio of representation coefficients when compared with several dictionary learning algorithms that incorporate linear classifiers. In addition, the learned discriminative dictionary, the large fisher ratio of representation coefficients and the simultaneously learned classifier can improve the recognition rate compared with some state-of-the-art dictionary learning algorithms. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xu, Lele; Wu, Xia; Yao, Li] Beijing Normal Univ, Coll Informat Sci & Technol, 19 Xin Jie Kou Wai Da Jie, Beijing 100875, Peoples R China.
   [Wu, Xia; Yao, Li] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
   [Wu, Xia; Yao, Li] Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing 100875, Peoples R China.
   [Chen, Kewei] Banner Alzheimers Inst, Phoenix, AZ USA.
   [Chen, Kewei] Banner Good Samaritan PET Ctr, Phoenix, AZ USA.
C3 Beijing Normal University; Beijing Normal University; Beijing Normal
   University; Banner Research; Banner Health; Banner Alzheimer's
   Institute; Banner Research; Banner Health
RP Wu, X; Yao, L (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, 19 Xin Jie Kou Wai Da Jie, Beijing 100875, Peoples R China.
EM wuxia@bnu.edu.cn; yaoli@bnu.edu.cn
RI Xu, Le/HDN-9623-2022; Kewei, Chen/CAA-1584-2022
FU 863 Program [2015AA020912]; Funds for International Cooperation and
   Exchange of the National Natural Science Foundation of China [61210001];
   General Program of National Natural Science Foundation of China
   [61571047]; Fundamental Research Funds for the Central Universities
FX This work is supported by the 863 Program (2015AA020912), the Funds for
   International Cooperation and Exchange of the National Natural Science
   Foundation of China (61210001), the General Program of National Natural
   Science Foundation of China (61571047) and the Fundamental Research
   Funds for the Central Universities.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2009, COMPUTATION
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   [Anonymous], 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2008.4587408
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Candes E., 2005, 11 MAGIE RECOVERY SP, V4, P14
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Engan K, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P1, DOI 10.1109/ISCAS.1999.779928
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hale E. T., 2007, TR0707 CAAM RIC U
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Khan HU, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P1, DOI 10.1109/ICE2T.2014.7006207
   Koh K., 2007, LI IS MATLAB SOLVER
   Kong S., 2013, FG, P1
   Li Lingjun., 2013, NDSS, V56, P57, DOI DOI 10.1109/NSSMIC.2013.6829098
   Liu HD, 2014, PATTERN RECOGN, V47, P1835, DOI 10.1016/j.patcog.2013.11.007
   Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Mairal J., 2010, SPAMS SPARSE MODELIN
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Martinez A., 1998, AR FACE DATABASE
   Mohimani G.H., 2007, FAST SPARSE REPRESEN, P389
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Wang DH, 2013, IMAGE VISION COMPUT, V31, P895, DOI 10.1016/j.imavis.2013.10.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522
   Yang M., 2014, INT J COMPUT VISION, P1
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 43
TC 13
Z9 14
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 561
EP 572
DI 10.1016/j.jvcir.2016.04.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100048
DA 2024-07-18
ER

PT J
AU Florea, L
   Florea, C
   Vertan, C
AF Florea, Laura
   Florea, Corneliu
   Vertan, Constantin
TI Recognition of the gaze direction: Anchoring with the eyebrows
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eye and eyebrow landmarks; Gaze recognition; Vision processing; Eyebrow
   influence on gaze; Shape processing; Face analysis; Real time;
   Multistage fusion landmark localization
ID PERCEPTION; ATTENTION
AB In this paper we investigate the accuracy of estimating a person's direction of gaze from remote imaging. The problem is addressed by a person independent, multistage fusion approach for eye landmark localization, followed by eye region analysis for actual gaze recognition. We test the proposed landmark localization system on three databases, showing superior accuracy than state of the art solutions. Finally, we show that, inspired by human perception, by incorporating the location of eyebrows, superior performance is achievable when estimating the gaze direction. Given the found results, we argue that computer vision systems for gaze recognition should mimic the human perception and incorporate the eyebrows. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Florea, Laura; Florea, Corneliu; Vertan, Constantin] Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, 313 Splaiul Independetei, Bucharest, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest
RP Florea, L (corresponding author), Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, 313 Splaiul Independetei, Bucharest, Romania.
EM laura.florea@upb.ro; corneliu.florea@upb.ro; constantin.vertan@upb.ro
RI Vertan, Constantin/F-4459-2015; Florea, Corneliu/B-5540-2012; Florea,
   Laura Maria/I-6823-2013
OI Florea, Corneliu/0000-0001-9754-6795; Florea, Laura
   Maria/0000-0001-6095-9692
FU Romanian Sectoral Operational Programme Human Resources Development
   through the European Social Fund [POSDRU/159/1.5/S/134398]; Romanian
   National Agency for Scientific Research [PNCDI2 PN-II-RU-TE 253/2015]
FX This work was supported by the Romanian Sectoral Operational Programme
   Human Resources Development 2007-2013 through the European Social Fund
   Financial Agreements POSDRU/159/1.5/S/134398 and Romanian National
   Agency for Scientific Research under the PNCDI2 PN-II-RU-TE 253/2015
   (PANDORA) research grant.
CR Adams RB, 2005, EMOTION, V5, P3, DOI 10.1037/1528-3542.5.1.3
   Ando S, 2002, PERCEPTION, V31, P657, DOI 10.1068/p3332
   [Anonymous], 2008, HONEST SIGNALS, DOI DOI 10.7551/MITPRESS/8022.001.0001
   [Anonymous], 2009, P IEEE INT WORKSH SA
   Asteriadis S., 2009, Proceedings of the International Workshop on A ective-Aware Virtual Agents and Social Robots - AFFINE '09, P1
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cootes T., 2012, ECCV
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dakin SC, 2009, J VISION, V9, DOI [10.1167/9.11.28, 10.1167/9.4.2]
   Duchowski A. T., 2017, EYE TRACKING METHODO, DOI [10.1007/978-3-319-57883-5, DOI 10.1007/978-3-319-57883-5]
   Everingham M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P441
   Fan B, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY WORKSHOPS (WI-IAT WORKSHOPS 2012), VOL 3, P39, DOI 10.1109/WI-IAT.2012.164
   Feng GC, 1998, PATTERN RECOGN LETT, V19, P899, DOI 10.1016/S0167-8655(98)00065-8
   Florea L., 2015, ROBUST EYE CTR LOCAL
   Florea L, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.60
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Jesorskya O., 2000, AUDIO VIDEO BASED PE, P90
   Kasinski A., 2008, Image Processing and Communications, V13, P59
   Kobayashi H, 1997, NATURE, V387, P767, DOI 10.1038/42842
   Laeng B, 2002, COGNITIVE SCI, V26, P207, DOI 10.1016/S0364-0213(01)00065-9
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   LEUNG TK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P637, DOI 10.1109/ICCV.1995.466878
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nummenmaa L, 2009, TRENDS COGN SCI, V13, P135, DOI 10.1016/j.tics.2008.12.006
   Rayner K, 2001, PSYCHOL SCI, P31, DOI 10.1111/1529-1006.00004
   Sadr J, 2003, PERCEPTION, V32, P285, DOI 10.1068/p5027
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Song FY, 2014, PATTERN RECOGN, V47, P2825, DOI 10.1016/j.patcog.2014.03.024
   Sun L, 2015, INFORM SCIENCES, V320, P346, DOI 10.1016/j.ins.2015.02.004
   Sun L, 2014, IEEE MULTIMEDIA, V21, P28, DOI 10.1109/MMUL.2014.54
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Tuisku O, 2012, INTERACT COMPUT, V24, P1, DOI 10.1016/j.intcom.2011.10.002
   Turkan M., 2004, OPTICAL ENG, V47
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vranceanu Ruxandra, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P225, DOI 10.1007/978-3-642-40246-3_28
   Vrânceanu R, 2015, MACH VISION APPL, V26, P267, DOI 10.1007/s00138-014-0656-8
   Wang P., 2005, 2005 IEEE COMP SOC C, P164
   Watt R, 2007, Q J EXP PSYCHOL, V60, P1169, DOI 10.1080/17470210701396798
   Weidenbacher U., 2007, 3rd IET International Conference on Intelligent Environments, P455
   Wolf L, 2010, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2010.5540133
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhang YH, 2014, J VIS COMMUN IMAGE R, V25, P916, DOI 10.1016/j.jvcir.2014.02.010
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 55
TC 2
Z9 3
U1 2
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 67
EP 77
DI 10.1016/j.jvcir.2015.12.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA DD4GD
UT WOS:000369879600006
DA 2024-07-18
ER

PT J
AU Kang, M
   Kang, M
   Jung, M
AF Kang, Myeongmin
   Kang, Myungjoo
   Jung, Miyoun
TI Nonconvex higher-order regularization based Rician noise removal with
   spatially adaptive parameters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rician noise removal; Image denoising-deblurring; Variational
   minimization model; Nonconvex higher-order regularization; Nonconvex
   hybrid TV regularizer; Spatially adaptive parameter; Iteratively
   reweighted l(1) algorithm; Alternating direction method of multipliers
ID IMAGE-RESTORATION; MINIMIZATION; RECOVERY
AB In this article, we introduce a class of variational models for the restoration of images that are polluted by Rician noise and/or blurring. The novel energy functional consists of a convex fidelity term and a nonconvex higher-order regularization term. The regularization term enables us to efficiently denoise piecewise smooth images, by alleviating the staircasing effects that appear in total variation based models, and to preserve details and edges. Furthermore, we incorporate our nonconvex higher-order model with spatially adaptive regularization parameters; this further improves restoration results by sufficiently smoothing homogeneous regions while conserving edge parts. To handle the nonconvexity and nonsmoothness of our models, we adopt the iteratively reweighted l(1) algorithm, and the alternating direction method of multipliers. This results in fast and efficient algorithms for solving our proposed models. Numerical experiments demonstrate the superiority of our models over the state-of-the-art methods, as well as the effectiveness of our algorithms. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kang, Myeongmin; Kang, Myungjoo] Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
   [Jung, Miyoun] Hankuk Univ Foreign Studies, Dept Math, Yongin, South Korea.
C3 Seoul National University (SNU); Hankuk University Foreign Studies
RP Jung, M (corresponding author), Hankuk Univ Foreign Studies, Dept Math, Yongin, South Korea.
EM wjdjr1@snu.ac.kr; mkang@snu.ac.kr; mjung@hufs.ac.kr
OI Jung, Miyoun/0000-0001-7370-6651; Kang, Myeongmin/0000-0003-1693-1582
FU BK21 PLUS SNU Mathematical Sciences Division; NRF of Korea - Ministry of
   Science, ICT and Future Planning [2014R1A2A1A10050531, 2015R1A5A1009350,
   2013R1A1A3010416]; Hankuk University of Foreign Studies Research Fund
FX Myeongmin Kang was supported by BK21 PLUS SNU Mathematical Sciences
   Division. Myungjoo Kang was supported by Basic Sciences Research Program
   through the NRF of Korea funded by the Ministry of Science, ICT and
   Future Planning (2014R1A2A1A10050531 and 2015R1A5A1009350). Miyoun Jung
   was supported in part by Hankuk University of Foreign Studies Research
   Fund and by Basic Science Research Program through the NRF of Korea
   funded by the Ministry of Science, ICT and Future Planning
   (2013R1A1A3010416).
CR Aja-Fernandez Santiago, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4815
   [Anonymous], LNCS
   [Anonymous], 2006, MATH PROBLEMS IMAGE
   [Anonymous], 9756 UCLA CAM
   Basu S, 2006, LECT NOTES COMPUT SC, V4190, P117
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chen DQ, 2012, IEEE T IMAGE PROCESS, V21, P1650, DOI 10.1109/TIP.2011.2172801
   Chen LY, 2015, J MATH IMAGING VIS, V53, P92, DOI 10.1007/s10851-014-0551-y
   Dong YQ, 2011, J MATH IMAGING VIS, V40, P82, DOI 10.1007/s10851-010-0248-9
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2281, DOI 10.1109/TIP.2006.875247
   Grasmair M, 2009, LECT NOTES COMPUT SC, V5567, P331, DOI 10.1007/978-3-642-02256-2_28
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Li F, 2010, SIAM J IMAGING SCI, V3, P1, DOI 10.1137/090748421
   Liu RW, 2014, MAGN RESON IMAGING, V32, P702, DOI 10.1016/j.mri.2014.03.004
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Nesterov Y., 2004, INTRO LECT CONVEX OP, V87
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Ochs P, 2015, SIAM J IMAGING SCI, V8, P331, DOI 10.1137/140971518
   Oh S, 2013, J VIS COMMUN IMAGE R, V24, P332, DOI 10.1016/j.jvcir.2013.01.010
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   Papoulis A., 1965, PROBABILITY RANDOM V
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Robini MC, 2007, IEEE T IMAGE PROCESS, V16, P2576, DOI 10.1109/TIP.2007.904975
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 33
TC 15
Z9 15
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 180
EP 193
DI 10.1016/j.jvcir.2015.08.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300015
DA 2024-07-18
ER

PT J
AU Chen, T
   Lu, SJ
   Fan, JY
AF Chen, Tao
   Lu, Shijian
   Fan, Jiayuan
TI Context-aware vocabulary tree for mobile landmark recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Codeword discrimination learning; Location and direction; Inverted file
   structure; Vocabulary tree; GPS; Direction; Image scoring; Mobile
   landmark recognition
AB This paper presents an effective approach that incorporates contextual information into vocabulary tree learning for mobile landmark recognition. For most existing mobile landmark recognition works, the context information (GPS or direction) is mainly used to reduce the search space in a heuristic and insufficient manner. Some recent work uses the context information for codebook learning but only the GPS information is explored. We propose an effective mobile landmark recognition approach which exploits both context (direction and location) and content information for vocabulary tree learning and image recognition. The proposed approach has two major contributions: (i) it proposes an information gain-based codeword discrimination learning method to evaluate the discriminative capability of each direction-aware codeword, as generated by a context-aware vocabulary tree, and (ii) it develops a context-aware image scoring technique based on an inverted file structure that speeds up the image matching process greatly. Experimental results on the NTU and San Francisco database show that the proposed method can achieve good recognition performance with fast speed. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Tao; Lu, Shijian; Fan, Jiayuan] Agcy Sci Technol & Res, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis South Tower, Singapore 138632, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Chen, T (corresponding author), Agcy Sci Technol & Res, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis South Tower, Singapore 138632, Singapore.
EM chent@i2r.a-star.edu.sg; slu@i2r.a-star.edu.sg; fanj@i2r.a-star.edu.sg
RI Lu, Shijian/AAU-4831-2021
OI Lu, Shijian/0000-0002-6766-2506
CR [Anonymous], ACM INT C MULT
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chandrasekhar Vijay, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2504, DOI 10.1109/CVPRW.2009.5206733
   Chandrasekhar V, 2012, INT J COMPUT VISION, V96, P384, DOI 10.1007/s11263-011-0453-z
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chen DM, 2008, IEEE DATA COMPR CONF, P143, DOI 10.1109/DCC.2009.33
   Chen T, 2013, IEEE T CIRC SYST VID, V23, P1611, DOI 10.1109/TCSVT.2013.2254978
   Chen T, 2011, IEEE T CIRC SYST VID, V21, P1476, DOI 10.1109/TCSVT.2011.2161413
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Girod B, 2011, IEEE SIGNAL PROC MAG, V28, P61, DOI 10.1109/MSP.2011.940881
   Guan T, 2014, IEEE MULTIMEDIA, V21, P32, DOI 10.1109/MMUL.2013.31
   Guan T, 2013, IEEE T MULTIMEDIA, V15, P1688, DOI 10.1109/TMM.2013.2265674
   Hays J, 2008, PROC CVPR IEEE, P3436
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Ji R. -R., 2011, Int. J. Comput. Vision, V96, P1
   Kalogerakis E, 2009, IEEE I CONF COMP VIS, P253, DOI 10.1109/ICCV.2009.5459259
   Kreyszig E., 2009, Advanced engineering mathematics
   Lee JA, 2008, LECT NOTES COMPUT SC, V5359, P346, DOI 10.1007/978-3-540-89646-3_34
   Li Y., 2008, 4 INT C WIRELESS COM, P1
   Liu H., 2012, Proceedings_of_the_20th_ACM_ International_Conference_on_Multimedia, MM'12, P9
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister David, 2006, CVPR
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Schindler G., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Yap KH, 2010, IEEE INTELL SYST, V25, P48, DOI 10.1109/MIS.2010.12
   Yu N, 2012, J VIS COMMUN IMAGE R, V23, P237, DOI 10.1016/j.jvcir.2011.10.004
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
   Zhou WG, 2011, PATTERN RECOGN, V44, P2263, DOI 10.1016/j.patcog.2010.08.016
NR 35
TC 1
Z9 5
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 289
EP 298
DI 10.1016/j.jvcir.2015.05.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900026
DA 2024-07-18
ER

PT J
AU Jiang, WF
   Cui, HB
   Zhang, F
   Rong, YC
   Chen, ZB
AF Jiang, Wenfei
   Cui, Hengbin
   Zhang, Fan
   Rong, Yaocheng
   Chen, Zhibo
TI Oriented total variation <i>l</i>1/2 regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total variation; l1/2 regularization; Restoration; Decomposition;
   Denoising; Compression; Anisotropic regularization; Structure preserving
   smoothing
ID IMAGE-RESTORATION; NOISE REMOVAL; ALGORITHM; SPARSE; DECOMPOSITION;
   MINIMIZATION
AB Total Variation (TV) is a widely used image restoration/decomposition model. It is observed that the classical TV l1 and TV l2 regularization, on the one hand, do not favor higher-gradient structures over lower-gradient details as expected for structure preserving image processing, and on the other hand, tend to reduce the horizontal and vertical gradients, and thus inevitably blur the oblique edges in images. In this paper, we address these two problems by defining Oriented Total Variation l1/2 (OTV l1/2). It is theoretically and experimentally demonstrated that applying l1/2 regularization to the directional derivatives of images leads to superior structure preservation. OW l1/2 regularization can be applied to image denoising and video compression, and the experimental results verify that OW l1/2 outperforms other similar models. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jiang, Wenfei] Alibaba Com, Video Tech Dept, Shanghai 200336, Peoples R China.
   [Cui, Hengbin] Baidu Com, Beijing, Peoples R China.
   [Zhang, Fan] Lenovo Res, Hong Kong, Hong Kong, Peoples R China.
   [Rong, Yaocheng] Tsinghua Univ, Beijing 100084, Peoples R China.
   [Chen, Zhibo] Univ Sci & Technol China, Beijing, Peoples R China.
C3 Alibaba Group; Baidu; Legend Holdings; Lenovo; Tsinghua University;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Jiang, WF (corresponding author), Alibaba Com, Video Tech Dept, E10,10th Floor,2299 West Yanan Rd, Shanghai 200336, Peoples R China.
EM wenfei.jwf@alibaba-inc.com; cuihengbin@baidu.com; zhangfanhk@lenovo.com;
   yaocheng.rong@gmail.com; chenzb@ieee.org
RI Chen, Zhibo/T-5349-2019
OI Chen, Zhibo/0000-0002-8525-5066
CR Aliney S., 1994, IEEE T SIGNAL PROCES, V45, P913
   [Anonymous], P 2010 INT C POW SYS
   [Anonymous], 2003, P VLSM
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   AUJOL JF, 2004, 0466 UCLA CAM
   Bayram I, 2012, IEEE SIGNAL PROC LET, V19, P781, DOI 10.1109/LSP.2012.2220349
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Bjontegaard G., 2001, Document VCEG-M33
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Cao W., 2012, J VIS COMMUN IMAGE R
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan T. F., 1996, ICAOS'96. 12th International Conference on Analysis and Optimization of Systems. Images, Wavelets and PDEs, P241
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0
   Do TT, 2010, IEEE IMAGE PROC, P3377, DOI 10.1109/ICIP.2010.5652726
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045
   Fu JJ, 2010, IEEE INT SYMP CIRC S, P3040, DOI 10.1109/ISCAS.2010.5537991
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   Gilboa G., 2009, MULTISCALE MODEL SIM, V7
   JM Software, JM 12 4 H 264 AVC SO
   Karahanoglu FI, 2011, IEEE T SIGNAL PROCES, V59, P5265, DOI 10.1109/TSP.2011.2164399
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Li Y., 1994, Tech Repost 12/94, Center for theory and simulation in science and engineering, Cornell University, P24
   Ma J, 2007, IEEE T IMAGE PROCESS, V16, P2198, DOI 10.1109/TIP.2007.902333
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   RUDIN LI, 1994, IEEE IMAGE PROC, P31
   SONNEVELD P, 1989, SIAM J SCI STAT COMP, V10, P36, DOI 10.1137/0910004
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   VOGEL CR, 1995, PROGR SYSTEMS CONTRO, V20
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wright J., 2009, ADV NEURAL INF PROCE, V22, P1
   Xu L., ACM T GRAPH, V30
   Yin W, 2007, MULTISCALE MODEL SIM, V6, P190, DOI 10.1137/060663027
   Yuan QQ, 2012, IEEE T CIRC SYST VID, V22, P379, DOI 10.1109/TCSVT.2011.2163447
   Zeng JS, 2014, IEEE T SIGNAL PROCES, V62, P2317, DOI 10.1109/TSP.2014.2309076
   Zhang J., 2012, P IEEE INT C IM PROC
   Zhang YF, 2008, INT CONF ACOUST SPEE, P1361
NR 45
TC 7
Z9 8
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 125
EP 137
DI 10.1016/j.jvcir.2015.02.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100012
DA 2024-07-18
ER

PT J
AU Zhang, N
   Mei, T
   Hua, XS
   Guan, L
   Li, S
AF Zhang, Ning
   Mei, Tao
   Hua, Xian-Sheng
   Guan, Ling
   Li, Shipeng
TI TapTell: Interactive visual search for mobile task recommendation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual intent; Mobile visual search; Interactive visual search; Image
   retrieval; Mobile recommendation; Natural user interface; Mobile user
   intention; Visual vocabulary
AB Mobile devices are becoming ubiquitous. People use them as personal concierge to search information and make decisions. Therefore, understanding user intent and subsequently provide meaningful and personalized suggestions is important. While existing efforts have predominantly focused on understanding the intent expressed by a textual or a voice query, this paper presents a new and alternative perspective which understands user intent visually, i.e., via visual signal captured by the built-in camera. We call this kind of intent "visual intent" as it can be naturally expressed through a visual form. To accomplish the discovery of visual intent on the phone, we develop TapTell, an exemplary real application on Windows Phone seven, by taking advantages of user interaction and rich context to enable interactive visual searches and contextual recommendations. Through the TapTell system, a mobile user can take a photo and indicate an object-of-interest within the photo via different drawing patterns. Then, the system performs a search-based recognition using a proposed large-scale context-embedded vocabulary tree. Finally, contextually relevant entities (i.e., local businesses) are recommended to the user for completing mobile tasks (those tasks which are natural to be raised and subsequently executed when the user utilizes mobile devices). We evaluated TapTell in a variety of scenarios with millions of images, and compared our results to state-of-the-art algorithms for image retrieval. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Ning; Guan, Ling] Ryerson Univ, Ryerson Multimedia Res Lab, Toronto, ON M5B 2K3, Canada.
   [Mei, Tao; Li, Shipeng] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Hua, Xian-Sheng] Microsoft Res, Redmond, WA 98052 USA.
C3 Toronto Metropolitan University; Microsoft Research Asia; Microsoft;
   Microsoft
RP Zhang, N (corresponding author), Ryerson Univ, Ryerson Multimedia Res Lab, 350 Victoria St, Toronto, ON M5B 2K3, Canada.
EM ning.zhang@ryerson.ca; tmei@microsoft.com; xshua@microsoft.com;
   lguan@ee.ryerson.ca; spli@microsoft.com
RI Li, Shipeng/AAA-3374-2020; Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Li, Shipeng/0000-0001-5368-4256; Zhang,
   Ning/0000-0003-0497-1966
CR [Anonymous], 2009, P 5 INT C MOB MULT C
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   Chandrasekhar Vijay, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2504, DOI 10.1109/CVPRW.2009.5206733
   Chen Dongdong, 2010, Proceedings 2010 International Conference on Optoelectronics and Image Processing (ICOIP 2010), P651, DOI 10.1109/ICOIP.2010.66
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Church K., 2009, WORKSH VIS INT SOC S
   Church K., 2009, IUI09, P247, DOI DOI 10.1145/1502650.1502686
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Dix A., 2004, Human-computer interaction
   Duan L.-Y., 2011, 2 WORKSH MOB VIS SEA
   Girod B, 2011, IEEE SIGNAL PROC MAG, V28, P61, DOI 10.1109/MSP.2011.940881
   Guy Ido., 2010, Proceedings of the fourth ACM conference on Recommender systems (RecSys '10), P7
   Jain R., 2010, INT C MULTIMEDIA, P1259, DOI DOI 10.1145/1873951.1874199
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Polifroni J, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1515
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Rose D.E., 2004, P 13 INT C WORLD WID, P13, DOI [DOI 10.1145/988672.988675, 10.1145/988672.988675]
   Schroth G, 2011, IEEE SIGNAL PROC MAG, V28, P77, DOI 10.1109/MSP.2011.940882
   Smith J., 2010, IEEE MultiMedia, V17, P2
   Takacs G., 2008, MIR 08, P427, DOI DOI 10.1145/1460096.1460165
   Yang LJ, 2011, IEEE T MULTIMEDIA, V13, P1295, DOI 10.1109/TMM.2011.2162399
   Yin Xiaoxin, 2010, P 19 INT C WORLD WID, P1001, DOI DOI 10.1145/1772690.1772792
   Zhuang JF, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P153
NR 25
TC 3
Z9 6
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 114
EP 124
DI 10.1016/j.jvcir.2015.02.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100011
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Dong, SF
   Wang, RG
   Wang, WM
   Gao, W
AF Wang, Zhenyu
   Dong, Shengfu
   Wang, Ronggang
   Wang, Wenmin
   Gao, Wen
TI Dynamic macroblock wavefront parallelism for parallel video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video encoding; Wavefront parallelism; Parallel scheduling; Parallel
   video coding; Synchronization delay; AVS; H.264/AVC; HEVC
ID DESIGN; IMPLEMENTATION; FRAMEWORK; ALGORITHM; DECISION
AB Wavefront parallelism is effective for parallel video encoding thanks to its merits of low latency, no quality loss and high degree of parallelism. In traditional video encoders, macroblock row wavefront (MRW) parallelism was widely adopted. However the performance of MRW is limited by workload unbalance and computing resource unbalance among multiple work threads. This paper proposes a new dynamic macroblock wavefront (DMW) parallelism to alleviate the limitations of MRW. In DMW, the available macroblocks (MBs) are scheduled to work threads MB by MB other than MB row by MB row; and after one MB is encoded by a work thread, the MB on its right (if available) has the highest priority to be scheduled to avoid synchronization delay. Experimental results demonstrate that video encoder with traditional MRW can be accelerated by more than 10% with our proposed DMW. When hyper-threading is used, the advantage of DMW is more prominent. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Zhenyu; Dong, Shengfu; Wang, Ronggang; Wang, Wenmin; Gao, Wen] Peking Univ, Shenzhen Grad Sch, Shenzhen, Guangdong, Peoples R China.
C3 Peking University
RP Wang, RG (corresponding author), Peking Univ, Shenzhen Grad Sch, Shenzhen, Guangdong, Peoples R China.
EM wangzhenyu@pkusz.edu.cn; dongsf@pkusz.edu.cn; rgwang@pkusz.edu.cn;
   wangwm@pkusz.edu.cn; wgao@pku.edu.cn
RI Wang, Wenmin/W-3511-2019; 王, 振宇/E-2109-2015
OI Wang, Wenmin/0000-0003-2664-4413; 
FU National Natural Science Foundation of China [61370115]; China
   High-Technique Research Project (863) [2015AA011605]; Shenzhen Peacock
   Plan
FX This work was partly supported by the grant of National Natural Science
   Foundation of China 61370115, China High-Technique Research Project
   (863) of 2015AA011605, and Shenzhen Peacock Plan.
CR Azevedo A., 2009, P 4 INT C HIGH PERF
   Bovet DanielP., 2000, Understanding the Linux Kernel
   Chen TC, 2006, IEEE T CIRC SYST VID, V16, P673, DOI 10.1109/TCSVT.2006.873163
   CHEN YK, 2004, P 18 INT PAR DISTR P, P63
   Chi C., 2012, IEEE T CIRC SYST VID, V15, P1
   Chi Ching Chi, 2010, 24th ACM International Conference on Supercomputing 2010, P105
   Dong S.F., 2012, INT C SIGN PROC COMM
   Farrell J., 1996, PTHREADS PROGRAMMING
   Fernández JC, 2002, LECT NOTES COMPUT SC, V2400, P830
   Gao W, 2010, STUD COMPUT INTELL, V280, P125
   Li P, 2005, IEEE T CIRC SYST VID, V15, P1098, DOI 10.1109/TCSVT.2005.852627
   Meenderinck C, 2009, J SIGNAL PROCESS SYS, V57, P173, DOI 10.1007/s11265-008-0256-9
   Reinders J., 2005, Vtune performance analyzer essentials
   Sachdeva R., 2011, INT C CONS EL ICCE
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun SW, 2007, LECT NOTES COMPUT SC, V4782, P577
   Wang ZY, 2011, J SIGNAL PROCESS SYS, V65, P129, DOI 10.1007/s11265-010-0543-0
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhao Z., 2006, IEEE International Conference on Acoustics, Speech and Signal Processing, V5, P489
   Zhao Z, 2006, IEEE INT SYMP CIRC S, P2669
   Zhu C, 2013, IEEE T MULTIMEDIA, V15, P1815, DOI 10.1109/TMM.2013.2280446
NR 22
TC 4
Z9 4
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 36
EP 43
DI 10.1016/j.jvcir.2015.01.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000005
DA 2024-07-18
ER

PT J
AU Jayasree, S
   Bodduna, K
   Pattnaik, PK
   Siddavatam, R
AF Jayasree, Syamala
   Bodduna, Kireeti
   Pattnaik, Prasant Kumar
   Siddavatam, Rajesh
TI An expeditious cum efficient algorithm for salt-and-pepper noise removal
   and edge-detail preservation using cardinal spline interpolation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edge-preserving regularization; Salt-and-pepper impulse noise; Cardinal
   splines; Expeditious algorithm; Image de-noising; Cardinal spline
   interpolation; Edge preservation; Two-phase noise removal
ID SWITCHING MEDIAN FILTERS; HIGHLY CORRUPTED IMAGES; IMPULSE NOISE
AB This work proposes a faster and an efficient way to remove salt-and-pepper impulse noise and edge-preserving regularization of the henceforth obtained image. In this paper, we propose a two phase mechanism where the noisy pixels are identified and removed in the first phase. The detected noisy pixels in the first phase are involved in cardinal spline edge regularization process in the second phase. Promising results were found even for Noise levels as high as 95% with the proposed algorithm. The results were found to be much better than the previously proposed nonlinear filters or regularization methods both in terms of noise removal as well as edge regularization. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Jayasree, Syamala; Pattnaik, Prasant Kumar; Siddavatam, Rajesh] KIIT Univ, Sch Comp Engn, Bhubaneswar, Orissa, India.
   [Bodduna, Kireeti] Indian Inst Sci Educ & Res, Dept Phys Sci, Kolkata, India.
C3 Kalinga Institute of Industrial Technology (KIIT); Indian Institute of
   Science Education & Research (IISER) - Kolkata
RP Siddavatam, R (corresponding author), KIIT Univ, Sch Comp Engn, Bhubaneswar, Orissa, India.
EM srajesh@ieee.org
RI Pattnaik, Prasant Kumar/AAH-2440-2020; Bodduna, Kireeti/AAE-3148-2019;
   Siddavatam, Prof Rajesh/GPG-3124-2022
OI Bodduna, Kireeti/0000-0002-6752-850X; Siddavatam, Prof
   Rajesh/0000-0003-0454-5377; Pattnaik, Prasant Kumar/0000-0002-4566-8077
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   Aizenberg I, 2005, IEEE SIGNAL PROC LET, V12, P63, DOI 10.1109/LSP.2004.838198
   Alajlan N, 2004, SIGNAL PROCESS-IMAGE, V19, P993, DOI 10.1016/j.image.2004.08.003
   Besdok E., 2005, INT J ELECT COMMUN, V59, P105
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chan Raymond H., 2005, IEEE T IMAGE PROCESS, V14
   CHAN TF, 1995, P SOC PHOTO-OPT INS, V2563, P314, DOI 10.1117/12.211408
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chen T, 2001, IEEE T CIRCUITS-II, V48, P784, DOI 10.1109/82.959870
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hashimoto Y, 2002, ELECTRON COMM JPN 3, V85, P22, DOI 10.1002/ecjc.1076
   Hearn Donal, 2009, COMPUTER GRAPHICS OP
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jaiswal T, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P667, DOI 10.1109/ARTCom.2009.61
   LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   Meijering E, 2003, IEEE T IMAGE PROCESS, V12, P477, DOI 10.1109/TIP.2003.811493
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   Prasad L., 1997, WAVELET ANAL APPL IM
   Russo F, 2004, MEASUREMENT, V36, P205, DOI 10.1016/j.measurement.2004.09.002
   Sree PSJ, 2013, SIGNAL IMAGE VIDEO P, V7, P111, DOI 10.1007/s11760-011-0210-3
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Vogel CR, 1998, IEEE T IMAGE PROCESS, V7, P813, DOI 10.1109/83.679423
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Windyga PS, 2001, IEEE T IMAGE PROCESS, V10, P173, DOI 10.1109/83.892455
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 33
TC 7
Z9 7
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1349
EP 1365
DI 10.1016/j.jvcir.2014.05.004
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100006
DA 2024-07-18
ER

PT J
AU Kang, SH
   March, R
AF Kang, Sung Ha
   March, Riccardo
TI Multiphase image segmentation via equally distanced multiple well
   potential
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Multiphase; Vectorial well-potential; Equial
   distance; True length; Total Variation; Modica-Mortola;
   Gamma-convergence; Calculus of variations
ID LEVEL SET METHOD; PHASE-TRANSITIONS; MUMFORD; MODEL; APPROXIMATION;
   FUNCTIONALS; ALGORITHMS
AB Variational models for image segmentation, e.g. Mumford-Shah variational model [47] and Chan-Vese model [21,59], generally involve a regularization term that penalizes the length of the boundaries of the segmentation. In practice often the length term is replaced by a weighted length, i.e., some portions of the set of boundaries are penalized more than other portions, thus unbalancing the geometric term of the segmentation functional.
   In the present paper we consider a class of variational models in the framework of T-convergence theory. We propose a family of functionals defined on vector valued functions that involve a multiple well potential of the type arising in diffuse-interface models of phase transitions. A potential with equally distanced wells makes it possible to retrieve the penalization of the true (i.e., not weighted) length of the boundaries as the T-convergence parameter tends to zero. We explore the differences and the similarities of behavior of models in the proposed class, followed by some numerical experiments. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Kang, Sung Ha] Georgia Inst Technol, Sch Math, Atlanta, GA 30332 USA.
   [March, Riccardo] CNR, Ist Applicaz Calcolo, I-00185 Rome, Italy.
C3 University System of Georgia; Georgia Institute of Technology; Consiglio
   Nazionale delle Ricerche (CNR)
RP Kang, SH (corresponding author), Georgia Inst Technol, Sch Math, 686 Cherry St NW, Atlanta, GA 30332 USA.
EM kang@math.gatech.edu; r.march@iac.cnr.it
OI March, Riccardo/0000-0003-3144-7537; Kang, Sung Ha/0000-0002-0312-6595
CR AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805
   AMBROSIO L, 1992, B UNIONE MAT ITAL, V6B, P105
   Ambrosio L., 2000, Functions of Bounded Variation and Free Discontinuity Problems
   Amstutz S., 2012, HAL00614818
   [Anonymous], 2004, Int. J. Numer. Anal. Model
   Aubert G, 2004, SIAM J NUMER ANAL, V42, P1128, DOI 10.1137/S0036142902412336
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Bae E, 2009, LECT NOTES COMPUT SC, V5681, P28, DOI 10.1007/978-3-642-03641-5_3
   Bae E, 2009, LECT NOTES COMPUT SC, V5567, P1, DOI 10.1007/978-3-642-02256-2_1
   BALDO S, 1990, ANN I H POINCARE-AN, V7, P67
   Barone P, 2009, J MATH IMAGING VIS, V34, P152, DOI 10.1007/s10851-009-0139-0
   Bellettini G., 1990, CALCOLO, V27, P251
   Bellettini Giovanni., 1990, ATTI ACCAD NAZ LIN, V1, P317
   Bertozzi A., 2006, SIAM J MULTISCALE MO, V6
   Borzi A, 2005, INT J COMPUT VISION, V64, P203, DOI 10.1007/s11263-005-1844-9
   Brown E. S., 2010, 1043 CAM
   Brown ES, 2012, INT J COMPUT VISION, V98, P103, DOI 10.1007/s11263-011-0499-y
   Burger M., 2009, SIAM J IMAG SCI, V3
   Candela VF, 2008, J SCI COMPUT, V35, P99, DOI 10.1007/s10915-007-9148-6
   Chambolle A, 2012, SIAM J IMAGING SCI, V5, P1113, DOI 10.1137/110856733
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chung J.T., 2003, 0353 UCLA CAM
   Dal Maso G., 1993, An introduction to T-convergence, DOI 10.1007/978-1-4612-0327-8
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   Esedoglu S., 2003, J MATH IMAG VIS, V18
   Gao S, 2005, IEEE T IMAGE PROCESS, V14, P1537, DOI 10.1109/TIP.2005.852200
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GIUSTI E, 1984, MONOGRAPHS MATH, V80
   Grossauer H, 2003, LECT NOTES COMPUT SC, V2695, P225
   Gu Y, IEEE T IMAGE PROCESS, V21
   Hauser S., 2012, INT J COMPUT MATH
   He Y., 2012, PATTERN RECOGN, V45, P3436, DOI DOI 10.1016/J.PATC0G.2012.03.009
   Jung YM, 2007, SIAM J APPL MATH, V67, P1213, DOI 10.1137/060662708
   Lellmann J, 2011, SIAM J IMAGING SCI, V4, P1049, DOI 10.1137/100805844
   Lellmann J, 2009, IEEE I CONF COMP VIS, P646, DOI 10.1109/ICCV.2009.5459176
   Lellmann J, 2009, LECT NOTES COMPUT SC, V5567, P150, DOI 10.1007/978-3-642-02256-2_13
   Li F, 2010, SIAM J IMAGING SCI, V3, P277, DOI 10.1137/080736752
   Li F, 2010, SIAM J APPL MATH, V70, P2750, DOI 10.1137/090753887
   Li HW, 2007, INT J NUMER ANAL MOD, V4, P291
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Lie J, 2006, MATH COMPUT, V75, P1155, DOI 10.1090/S0025-5718-06-01835-7
   March R, 1997, IMAGE VISION COMPUT, V15, P705, DOI 10.1016/S0262-8856(97)00002-4
   MARCH R, 1992, IMAGE VISION COMPUT, V10, P30, DOI 10.1016/0262-8856(92)90081-D
   MODICA L, 1987, ARCH RATION MECH AN, V98, P123, DOI 10.1007/BF00251230
   Modica L., 1977, Boll. Un. Mat. Ital. B, V14, P285
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nitzberg M., 1993, Filtering, segmentation and depth, V662
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003
   Shafei B., 2012, J VIS COMMUN IMAGE R
   Shen JH, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/92329
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958
   [No title captured]
NR 60
TC 3
Z9 3
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1446
EP 1459
DI 10.1016/j.jvcir.2014.04.008
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100014
DA 2024-07-18
ER

PT J
AU Liu, HW
   Philipose, M
   Pettersson, M
   Sun, MT
AF Liu, Haowei
   Philipose, Matthai
   Pettersson, Martin
   Sun, Ming-Ting
TI Recognizing object manipulation activities using depth and visual cues
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Activity recognition; Action recognition; Joint object and action
   recognition; HMM; Depth camera; Temporal action recognition; Temporal
   smoothing; Boost
AB We propose a framework, consisting of several algorithms to recognize human activities that involve manipulating objects. Our proposed algorithm identifies objects being manipulated and models high-level tasks being performed accordingly. Realistic settings for such tasks pose several problems for computer vision, including sporadic occlusion by subjects, non-frontal poses, and objects with few local features. We show how size and segmentation information derived from depth data can address these challenges using simple and fast techniques. In particular, we show how to robustly and without super-vision find the manipulating hand, properly detect/recognize objects and properly use the temporal information to fill in the gaps between sporadically detected objects, all through careful inclusion of depth cues. We evaluate our approach on a challenging dataset of 12 kitchen tasks that involve 24 objects performed by 2 subjects. The entire framework yields 82%/84% precision (74%/83%recall) for task/object recognition. Our techniques outperform the state-of-the-art significantly in activity/object recognition. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Liu, Haowei; Pettersson, Martin; Sun, Ming-Ting] Univ Washington, Seattle, WA 98195 USA.
   [Philipose, Matthai] Intel Labs Seattle, Seattle, WA USA.
C3 University of Washington; University of Washington Seattle; Intel
   Corporation
RP Liu, HW (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM hwliu@uw.edu; matthai.philipose@gmail.com; marpett@uw.edu; mts@uw.edu
CR Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], IEEE INT C COMP VIS
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gupta Abhinav, 2007, IEEE INT C COMP VIS
   Gupta Abhinav, 2008, IEEE INT C COMP VIS
   Kjellstrom Hedvig, 2008, IEEE EUR C COMP VIS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Micilotta AS, 2006, LECT NOTES COMPUT SC, V3953, P139, DOI 10.1007/11744078_11
   Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang SK, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2237
   Wu JX, 2007, IEEE I CONF COMP VIS, P290, DOI 10.1109/ICCV.2007.4408865
NR 15
TC 3
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 719
EP 726
DI 10.1016/j.jvcir.2013.03.015
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500012
DA 2024-07-18
ER

PT J
AU Wang, LF
   Pan, ZB
   Ma, XX
   Hu, S
AF Wang, Lingfei
   Pan, Zhibin
   Ma, Xiaoxiao
   Hu, Sen
TI A novel high-performance reversible data hiding scheme using SMVQ and
   improved locally adaptive coding method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Image compression; Vector quantization (VQ); Side-match
   vector quantization (SMVQ); Reversible data hiding; Locally adaptive
   coding scheme (LAC); High embedding rate; Steganography; Threshold list
ID WATERMARKING ALGORITHM; VECTOR QUANTIZATION; VQ; IMAGES
AB Reversible data hiding is a method that not only embeds secret data but also reconstructs the original cover image without distortion after the confidential data are extracted. In this paper, we propose novel reversible data hiding scheme that can embed high capacity of secret bits and recover image after data extraction. Our proposed scheme depends on the locally adaptive coding scheme (LAC) as Chang&Nguyen's scheme and SMVQ scheme. Experimental results show that the compression rate of our proposed scheme is 0.33 bpp on average. To embed secret bits we propose the normal-hiding scheme and the over-hiding scheme which have an average embedding rate of 2.01 bpi and 3.01 bpi, more than that of Chang&Nguyen's scheme (1.36 bpi). The normal-hiding scheme and the over-hiding scheme also has high embedding efficiency of 0.28 and 0.36 on average, which are better than that of Chang&Kieu's scherrie (0.12), Chang&Nguyen's scheme (0.18) and Chang&Nguyen's scheme (0.16). (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Lingfei; Pan, Zhibin; Ma, Xiaoxiao; Hu, Sen] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM leonardo22@sohu.com; zbpan@mail.xjtu.edu.cn; xiao.77@stu.xjtu.edu.cn;
   husen123456@163.com
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20100201110030]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Science and Technology Program of Xian Municipality
   [CX1251-3]; State Key Lab of SKL, Nanjing University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20100201110030), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30), Science and Technology Program of Xian
   Municipality (Grant No. CX1251-3), and Open Project Program of the State
   Key Lab of SKL (Grant No. KFKT2013B05), Nanjing University.
CR Alghoniemy M., 1999, P S CONT SEC DAT HID
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang HC, 2002, IEICE T FUND ELECTR, VE85A, P1719
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lin Chih Yang, 2006, J COMPUT, V17, P3
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   Pan JS, 2004, IEICE T FUND ELECTR, VE87A, P1839
   SWANSON MD, 1996, P IEEE DIG SIGN PROC, P37
   Trappe W., 2001, INTRO CRYPTOGRAPHY C
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 19
TC 22
Z9 24
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 454
EP 465
DI 10.1016/j.jvcir.2013.12.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300021
DA 2024-07-18
ER

PT J
AU Chen, HT
   Ma, KL
   Chuang, JH
   Lin, HH
AF Chen, Hua-Tsung
   Ma, Kuo-Lian
   Chuang, Jen-Hui
   Lin, Horng-Horng
TI Recognizing jump patterns with physics-based validation in human moving
   trajectory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sports video analysis; Camera calibration; Content-based multimedia
   analysis; 3D trajectory approximation; Object tracking; Pattern
   recognition; Volleyball video; Trajectory analysis
ID SPORTS VIDEO; FRAMEWORK; TRACKING; MOTION
AB This paper presents an approach to recognize jump patterns in human moving trajectory, differentiating jump tracks from planar moving tracks. Since human moving trajectory is one of the most informative representations for content understanding and event detection, trajectory-based video analysis has been gaining popularity. However, a jump action typically leads to violent change in human moving trajectory, since the person suddenly leaves the original plane on which he/she has been moving. The abnormal tracks of the trajectory would influence the performance of trajectory-based video analysis. Hence, differentiating jump tracks from planar moving tracks is of vital importance, not to mention that jump actions typically imply significant events, especially in sports games. In this paper, volleyball videos are used as case study to demonstrate the effectiveness of our proposed jump pattern recognition approach. We derive player trajectory by head tracking, analyze the movement of each player, and recognize potential jump tracks in player trajectories based on two important characteristics: (1) jumps cause pulse-like tracks in the trajectory and (2) the extensions of such tracks go through the vanishing point of vertical lines in the scenes. Finally, the jump positions/heights are estimated, in addition to the planar moving trajectory of each player on the court ground. The experiments show that satisfactory results can be obtained with the proposed recognition scheme. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Hua-Tsung] Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
   [Ma, Kuo-Lian; Chuang, Jen-Hui] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Lin, Horng-Horng] Southern Taiwan Univ, Dept Comp Sci & Informat Engn, Tainan 710, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University; Southern Taiwan University of Science & Technology
RP Chen, HT (corresponding author), Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
EM huatsung@cs.nctu.edu.tw
RI Lin, Horng-Horng/GQI-1661-2022
FU [ICTL-102-Q707];  [ATU-102-W958];  [NSC-98-2221-E-009-124-MY2]; 
   [NSC-102-2221-E-009-031]
FX This research is supported in part by projects ICTL-102-Q707,
   ATU-102-W958, NSC-98-2221-E-009-124-MY2, and NSC-102-2221-E-009-031.
   Thanks to the members of the school volleyball team of National Chiao
   Tung University, Taiwan, especially Mr. Chen-Hsing Chang, who is a
   physical education teacher and is also a professional volleyball coach.
CR [Anonymous], 2007, P 15 ACM INT C MULTI
   Bashir F.I., IEEE T MULTIMEDIA, V9
   Chang SF, 2002, IEEE MULTIMEDIA, V9, P6, DOI 10.1109/93.998041
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Chen HT, 2012, MULTIMED TOOLS APPL, V60, P641, DOI 10.1007/s11042-011-0833-y
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Duan L.Y., 2003, Proc. ACM Int. Conf. Multimedia, P33
   Farin D, 2004, PROC SPIE, V5307, P80
   Han JG, 2008, IEEE T CIRC SYST VID, V18, P1628, DOI 10.1109/TCSVT.2008.2005611
   Han JG, 2011, IEEE MULTIMEDIA, V18, P72, DOI 10.1109/MMUL.2010.24
   Hsieh J.-W., IEEE T CIRCUITS SYST, V16
   Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Lee JS, 2011, J VIS COMMUN IMAGE R, V22, P704, DOI 10.1016/j.jvcir.2010.11.002
   Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001
   Mauthner T., 2007, INT J COMPUTER SCI S, V6, P21
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Piciarelli C, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P40
   Preda RO, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3558734
   Preda RO, 2011, INT J ELECTRON, V98, P393, DOI 10.1080/00207217.2010.547810
   Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
   Zhu G., 2007, P 14 ACM INT C MULT, P431
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 26
TC 4
Z9 4
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1191
EP 1203
DI 10.1016/j.jvcir.2013.08.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700042
DA 2024-07-18
ER

PT J
AU Dehkordi, MG
   Daliri, MR
   Ayatollahi, A
   Ayatollahi, F
AF Dehkordi, Masoud Ghaderi
   Daliri, Mohammad Reza
   Ayatollahi, Ahmad
   Ayatollahi, Fazael
TI RETRACTED: Pose invariant face recognition using biological inspired
   features based on ensemble of classifiers (Retracted article. See vol.
   25, pg. 1287, 2014)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE View-independent face recognition; Visual ventral stream; HMAX; C1
   features; Ensemble of classifiers; Bootstrapping; Scale and translation
   invariant features; Diversity; CMU-PIE database; FERET face database
ID MONKEY STRIATE CORTEX; FUNCTIONAL ARCHITECTURE; OBJECT RECOGNITION;
   RECEPTIVE-FIELDS; EXPERTS; MIXTURE; MODEL; IMAGE; IDENTIFICATION;
   EIGENSPACES
AB This paper introduces a new method for view-independent face recognition by means of features inspired by the human's visual ventral stream and ensemble of classifiers. Several sets of scale and translation invariant features are first extracted. The feature vectors are then given to a new method of ensemble of classifiers. Diversity is a crucial condition for obtaining accurate ensembles. Diversity in our method is obtained by using bootstrapped replicas of the training vectors. Different training vectors are randomly drawn from the training vectors and are connected together to form diverse training sets. Experiments were performed to validate the method on the CMU-PIE and FERET face databases. Comparison with some of the most related methods indicates that the proposed method yields better recognition rate in view independent face recognition. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Dehkordi, Masoud Ghaderi; Daliri, Mohammad Reza; Ayatollahi, Ahmad] Iran Univ Sci & Technol, Fac Elect Engn, Tehran 1684613114, Iran.
   [Ayatollahi, Fazael] Amirkabir Univ Technol, Fac Elect Engn, Tehran, Iran.
C3 Iran University Science & Technology; Amirkabir University of Technology
RP Daliri, MR (corresponding author), Iran Univ Sci & Technol, Fac Elect Engn, Tehran 1684613114, Iran.
EM daliri@iust.ac.ir
RI Ayatollahi, Ahmad/S-5984-2018; Daliri, Mohammad Reza/AAF-4609-2021
OI Daliri, Mohammad Reza/0000-0001-9241-8751; Ayatollahi,
   Ahmad/0000-0003-1005-9009
CR [Anonymous], 2005, Information Fusion, DOI https://doi.org/10.1016/j.inffus.2004.04.009
   [Anonymous], THESIS MIT CAMBRIDGE
   [Anonymous], TECHNICAL REPORT
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BLASDEL GG, 1992, J NEUROSCI, V12, P3139, DOI 10.1523/JNEUROSCI.12-08-03139.1992
   Borji A, 2008, NEURAL PROCESS LETT, V28, P97, DOI 10.1007/s11063-008-9084-y
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   Du S, 2006, J FRANKLIN I, V343, P596, DOI 10.1016/j.jfranklin.2006.08.006
   Ebrahimpour R., 2010, INT J COMPUT ELECT E, V2, P1793
   Ebrahimpour R, 2008, COMPUT VIS IMAGE UND, V111, P195, DOI 10.1016/j.cviu.2007.10.003
   Ebrahimpour R, 2008, J FRANKLIN I, V345, P87, DOI 10.1016/j.jfranklin.2007.06.004
   Ebrahimpour R, 2008, NEUROCOMPUTING, V71, P1103, DOI 10.1016/j.neucom.2007.08.021
   Ebrahimpour R, 2011, MACH VISION APPL, V22, P421, DOI 10.1007/s00138-009-0232-9
   El Aroussi M, 2011, SIGNAL PROCESS, V91, P38, DOI 10.1016/j.sigpro.2010.06.005
   FRANC V, 2005, THESIS CZECH TU
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gao XB, 2009, NEUROCOMPUTING, V72, P3742, DOI 10.1016/j.neucom.2009.06.001
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Hajiany A, 2009, INT CONF INTELL SYST, P1425, DOI 10.1109/ISDA.2009.57
   He L.M., 2007, P 6 INT C MACH LEARN, P19
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Kim TK, 2006, IEEE T CIRC SYST VID, V16, P1096, DOI 10.1109/TCSVT.2006.881197
   Kim TK, 2004, LECT NOTES COMPUT SC, V3138, P565
   Kirby M., IEEE T PATTERN ANAL, V12
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629
   Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Mu Y, 2010, NEUROCOMPUTING, V73, P895, DOI 10.1016/j.neucom.2009.09.017
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Song D., 2009, C1 UNITS SCENE CLASS, P1
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 47
TC 2
Z9 2
U1 1
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 968
EP 976
DI 10.1016/j.jvcir.2013.06.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700021
OA Bronze
DA 2024-07-18
ER

PT J
AU Tarnoi, S
   Kumwilaisak, W
   Ji, YS
   Kuo, CCJ
AF Tarnoi, Saran
   Kumwilaisak, Wuttipong
   Ji, Yusheng
   Kuo, C. -C. Jay
TI Robust scalable video multi-cast with multiple sources and inter-source
   network decoding in lossy networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable video coding; Inter-source network decoding;
   Quality-of-Service; Source diversity; Integer linear optimization;
   Multi-cast transmission; Lossy network; Network coding
AB This paper presents a robust scalable video multi-cast scheme with source diversity and inter-source network decoding in lossy networks. The source diversity technique gives path diversity, providing a better quality of layered video transmission under hostile environments. For each source, an optimization formulation is set up to find the best transmission route of each transmitting video layer. The objectives of the formulation are to maximize the total information values of video layers reflecting the end-to-end video quality and transmission reliability. The source providing the best overall achievable data rate, which is the data rate destination can expect to receive from the transmission, is selected to be the primary source, while the rest will be secondary sources. When the Quality-of-Service (QoS) guarantees of some transmitting video layers cannot be fulfilled by the primary source, the secondary source with the best QoS parameters is selected to transmit the layers to destinations. The number of secondary sources used for transmissions is increased until the QoS guarantees of all transmitting video layers are satisfied or all network resources are utilized. Network coding is deployed to multi-cast video layers from the same source for efficient resource usage. Network coded data from different sources can be used to decode the transmitting video data. In other words, at each destination, it needs only a sufficient number of video packets from different sources to recover all transmitting video data. Simulations with different network topologies show the improvement in both objective and subjective qualities of layered video multi-cast under lossy environments. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Tarnoi, Saran; Ji, Yusheng] Natl Inst Informat, Tokyo, Japan.
   [Kumwilaisak, Wuttipong] King Mongkuts Univ Technol, Dept Elect & Telecommun Engn, Bangkok, Thailand.
   [Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA USA.
C3 Research Organization of Information & Systems (ROIS); National
   Institute of Informatics (NII) - Japan; King Mongkuts University of
   Technology Thonburi; King Mongkuts University of Technology North
   Bangkok; University of Southern California
RP Kumwilaisak, W (corresponding author), King Mongkuts Univ Technol, Dept Elect & Telecommun Engn, Bangkok, Thailand.
EM saran@nii.ac.jp; wuttipong.kum@kmutt.ac.th; kei@nii.ac.jp;
   cckuo@sipi.usc.edu
RI Ji, Yusheng/AAF-1537-2020; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035; Ji, Yusheng/0000-0003-4364-8491
FU Telecommunications Research and Industrial Development Institute
   (TRIDI), National Telecommunication Commission Fund [003/2553]; National
   Research University Project of Thailand's Office of the Higher Education
   Commission; Grants-in-Aid for Scientific Research [23240011] Funding
   Source: KAKEN
FX This research is partly supported by the Telecommunications Research and
   Industrial Development Institute (TRIDI), National Telecommunication
   Commission Fund (Grant No. 003/2553) and partly supported by the
   National Research University Project of Thailand's Office of the Higher
   Education Commission.
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   Ahn CW, 2002, IEEE T EVOLUT COMPUT, V6, P566, DOI 10.1109/TEVC.2002.804323
   [Anonymous], 2010, 2010 P IEEE INFOCOM, DOI DOI 10.1109/GLOCOM.2010.5684107
   [Anonymous], 2006, INT SER OPER RES MAN
   Basso S., P ACM SIGCOMM WORKSH, P7
   DING Y, 2011, P IEEE INFOCOM, P2051
   Han TS, 2011, IEEE T INFORM THEORY, V57, P4, DOI 10.1109/TIT.2010.2090223
   Hasslinger G., 2008, The Gilbert-Elliott Model for Packet Loss in Real Time Services on the Internet, P1
   HO T, 2004, P C INF SCI SYST, P1
   Ho T, 2006, IEEE T INFORM THEORY, V52, P4413, DOI 10.1109/TIT.2006.881746
   Ke CH, 2012, KSII T INTERNET INF, V6, P379, DOI 10.3837/tiis.2012.01.021
   Lee KD, 2006, IEEE J SEL AREA COMM, V24, P2051, DOI 10.1109/JSAC.2006.881628
   Li DJ, 2005, J COMMUN NETW-S KOR, V7, P144, DOI 10.1109/JCN.2005.6387862
   Nguyen UT, 2007, IEEE COMMUN MAG, V45, P72, DOI 10.1109/MCOM.2007.4378324
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Ramzan N, 2011, IEEE COMMUN MAG, V49, P128, DOI 10.1109/MCOM.2011.5723810
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Selvam R. P., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P115, DOI 10.1109/ICPRIME.2012.6208297
   Sundaram N., 2005, P 43 ANN ALL C COMM, P1
   Supittayapornpong S, 2010, COMPUT COMMUN, V33, P1651, DOI 10.1016/j.comcom.2010.04.010
   Tarnoi S, 2012, IEICE T COMMUN, VE95B, P3120, DOI 10.1587/transcom.E95.B.3120
   Trullols-Cruces O, 2011, IEEE COMMUN LETT, V15, P67, DOI 10.1109/LCOMM.2010.110310.101480
   Tuncel E, 2003, IEEE T INFORM THEORY, V49, P1983, DOI 10.1109/TIT.2003.814934
   Wang YA, 2009, LECT NOTES COMPUT SC, V5448, P57, DOI 10.1007/978-3-642-00975-4_6
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu C., 2007, P IEEE INT C PERF CO, P323
   Xu XF, 2004, IEEE IMAGE PROC, P1759
   Zhao J, 2006, IEEE T MULTIMEDIA, V8, P1021, DOI 10.1109/TMM.2006.879847
   Zhao XB, 2012, IEEE COMMUN LETT, V16, P720, DOI 10.1109/LCOMM.2012.041112.112564
   Zhu Y, 2004, IEEE J SEL AREA COMM, V22, P107, DOI 10.1109/JSAC.2003.818801
NR 30
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 602
EP 614
DI 10.1016/j.jvcir.2013.04.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900009
DA 2024-07-18
ER

PT J
AU Chen, LK
   Lu, W
   Ni, JQ
   Sun, W
   Huang, JW
AF Chen, Likai
   Lu, Wei
   Ni, Jiangqun
   Sun, Wei
   Huang, Jiwu
TI Region duplication detection based on Harris corner points and step
   sector statistics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image forensics; Region duplication detection; Harris corner
   detector; Step sector statistics; Best-bin-first
ID FORGERY
AB Region duplication is a simple and effective operation for digital image forgeries. The detection of region duplication is very important in digital image forensics. Most existing detection methods for region duplication are based on exhaustive block-matching of image pixels or transform coefficients. They may not be effective when the duplicate regions have gone through some geometrical transformations. In this paper, a novel region duplication detection method that is robust to general geometrical transformations is proposed. Firstly, the Harris corner interest points in an image are detected. Then, an image region description method based on step sector statistics is developed to represent the small circle image region around each Harris point with a feature vector. Finally, the small circle image regions are matched using the best-bin-first algorithm to reveal duplicate regions. Experimental results show that the proposed method can work effectively on the forged images from two image databases, and it is also robust to several geometrical transformations and image degradations. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Likai; Lu, Wei; Ni, Jiangqun; Huang, Jiwu] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM xiayu007clk@yahoo.com.cn; luwei3@mail.sysu.edu.cn;
   issjqni@mail.sysu.edu.cn; sunwei@mail.sysu.edu.cn;
   isshjw@mail.sysu.edu.cn
RI huang, jw/KVY-9917-2024
FU National Natural Science Foundation of China (NSFC) [60803136, 60970145]
FX This work is supported by National Natural Science Foundation of China
   (NSFC No. 60803136 and No. 60970145). The authors thank the anonymous
   reviewers for their comments that greatly improve the manuscript.
   Credits for the use of the CASIA Image Tempering Detection Evaluation
   Database (CAISA TIDE) V2.0 are given to the National Laboratory of
   Pattern Recognition, Institute of Automation, Chinese Academy of
   Science, Corel Image Database and the photographers.
   http://forensics.idealtest.org
CR Amerini I, 2010, INT CONF ACOUST SPEE, P1702, DOI 10.1109/ICASSP.2010.5495485
   [Anonymous], 2010, IEEE T INF FOREN SEC, DOI DOI 10.1109/TIFS.2010.2078506
   [Anonymous], 2003, PROC DIGIT FORENSIC, DOI DOI 10.1109/PACIIA.2008.240
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S., 2009, SURVEY COPY MOVE FOR
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Chen LK, 2012, INT J DIGIT CRIME FO, V4, P49, DOI 10.4018/jdcf.2012010104
   Farid H, 2009, ADV COMPUT, V77, P1, DOI 10.1016/S0065-2458(09)01201-7
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Katzenbeisser S., 2000, INFORM TECHNIQUES ST, V685
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Moravec H.P., 1980, Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rove
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
NR 24
TC 74
Z9 85
U1 0
U2 54
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 244
EP 254
DI 10.1016/j.jvcir.2013.01.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200004
DA 2024-07-18
ER

PT J
AU Kwon, OC
   Song, H
AF Kwon, Oh Chan
   Song, Hwangjun
TI Adaptive tree-based P2P video streaming multicast system under high
   peer-churn rate
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE P2P network; Multicast tree; Peer stability; Link delay; Quality of
   service; Peer churn; Peer behavior; Video streaming
ID ALGORITHMS
AB This paper presents an adaptive tree-based P2P video streaming multicast system under high peer-churn rate. Because peers typically display dynamic and unstable behavior during the session, a P2P video streaming multicast tree must take into account both the link delay and peer stability in order to provide a seamless video streaming multicast service with low delay. Hence, we need to adaptively update the multicast tree according to its time-varying environments in order to obtain an effective tradeoff between the delay of the tree and the relative peer stability over multicast tree. Finally, simulation results are provided to demonstrate the performance of the proposed system. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Kwon, Oh Chan] POSTECH Pohang Univ Sci & Technol, Dept Comp Sci & Engn, Pohang 790784, South Korea.
   [Song, Hwangjun] POSTECH Pohang Univ Sci & Technol, Div IT Convergence Engn, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Pohang University
   of Science & Technology (POSTECH)
RP Song, H (corresponding author), POSTECH Pohang Univ Sci & Technol, Div IT Convergence Engn, Pohang 790784, South Korea.
EM ochanism@postech.ac.kr; hwangjun@postech.ac.kr
FU MKE (The Ministry of Knowledge Economy), Korea, under the "IT
   Consilience Creative Program"; NIPA (National IT Industry Promotion
   Agency) [C1515-1121-0003]; World Class University program; Ministry of
   Education, Science and Technology through the National Research
   Foundation of Korea [R31-10100]
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the "IT Consilience Creative Program" support
   program supervised by the NIPA (National IT Industry Promotion Agency)
   (C1515-1121-0003) and World Class University program funded by the
   Ministry of Education, Science and Technology through the National
   Research Foundation of Korea (R31-10100).
CR [Anonymous], INTERNET STUDY 2008
   Bishop M., 2006, IEEE C COMP COMM INF
   Chen Y., 2011, IEEE INT C COMM ICC
   Cohen B., 2003, WORKSH EC P2P SYST
   Deering S, 1989, 1112 IETF RFC
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   Fischlin M, 2003, LECT NOTES COMPUT SC, V2567, P116
   Francis P., 1999, YOID EXTENDING MULTI
   Haghighat AT, 2004, COMPUT COMMUN, V27, P111, DOI 10.1016/S0140-3664(03)00185-3
   He Q., 2003, P IEEE ACM INT S MOD
   Joo H., 2007, IEICE T COMMUNICAT B, VE90-B
   Kamvar Sepandar D., 2003, P 12 INT C WORLD WID, P261, DOI DOI 10.1145/775152.775190
   Klinberg Tor, 2002, GNUTELLA PROTOCOL SP
   Kostic D., 2003, ACM S OP SYST PRINC
   LaFortune R., 2009, P 42 HAW INT C SYST
   Lim H., 2003, ACM SPEC INT GROUP D
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Lua EK, 2005, IEEE COMMUN SURV TUT, V7, P72, DOI 10.1109/COMST.2005.1610546
   McCanne S., NETWORK SIMULATOR NS
   OECD, 2012, OECD BROADB PORT
   PAI V, 2005, INT WORKSH PEER TO P
   Pendarakis D, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 3RD USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P49
   PIAS M, 2003, 2 INT WORKSH PEER TO
   Song HJ, 2006, COMPUT COMMUN, V29, P1480, DOI 10.1016/j.comcom.2005.09.015
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
   Stutzbach R., 2006, ACM SIGCOMM C INT ME, P189, DOI [10.1145/1177080.1177105, DOI 10.1145/1177080.1177105]
   Tian Y, 2008, J SYST ARCHITECT, V54, P305, DOI 10.1016/j.sysarc.2007.07.002
   Ullah I, 2010, LECT NOTES COMPUT SC, V6155, P2, DOI 10.1007/978-3-642-13986-4_2
   Wang B, 2000, IEEE NETWORK, V14, P22, DOI 10.1109/65.819168
   Wang F., 2007, P 27 IEEE INT C DIST
   Wang F, 2011, IEEE SYST J, V5, P440, DOI 10.1109/JSYST.2011.2165189
   Wang ZY, 2001, COMPUT COMMUN, V24, P685, DOI 10.1016/S0140-3664(00)00273-5
   Xiong L, 2004, IEEE T KNOWL DATA EN, V16, P843, DOI 10.1109/TKDE.2004.1318566
   Zegura EW, 1997, IEEE ACM T NETWORK, V5, P770, DOI 10.1109/90.650138
   Zhang BC, 2002, IEEE INFOCOM SER, P1366, DOI 10.1109/INFCOM.2002.1019387
   Zhang QF, 1999, IEEE T EVOLUT COMPUT, V3, P53, DOI 10.1109/4235.752920
   ZHANG X, 2005, P IEEE C COMP COMM I
NR 37
TC 6
Z9 6
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 203
EP 216
DI 10.1016/j.jvcir.2012.11.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200001
DA 2024-07-18
ER

PT J
AU Lin, HC
   Yang, CN
   Laih, CS
   Lin, HT
AF Lin, Hsiao-Ching
   Yang, Ching-Nung
   Laih, Chi-Sung
   Lin, Hui-Tang
TI Natural language letter based visual cryptography scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deterministic VCS; Letter-based; Natural language; Probabilistic VCS;
   Secret sharing; Subpixel; Visual cryptography scheme; Visual secret
   sharing
ID MULTIPLE SECRETS; AUTHENTICATION; IMAGES
AB Naor and Shamir proposed the notion of a (k, n) visual cryptography scheme (VCS), which allows k or more stacked transparent share images to reveal a secret image. It can be used without prerequisite knowledge of cryptography or complex computations. In these schemes, no information about the secret can be obtained from fewer than k shares. Previous VCSs use black and white subpixels to create share images. In this paper, we present a letter-based VCS (LVCS) where pixels are replaced by letters for the share images. Shares can now be constructed using meaningful data as subterfuge all while carrying secret data in plain sight, and an adversary will not recognize them as containing secrets. We prove that the proposed (k, n)-LVCS satisfies contrast and security conditions and secret information may be reconstructed by any k shares but with less than k shares reveal nothing. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Lin, Hsiao-Ching] Natl Cheng Kung Univ, Inst Comp & Commun Engn, Tainan 70101, Taiwan.
   [Laih, Chi-Sung; Lin, Hui-Tang] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University
RP Lin, HT (corresponding author), 1 Univ Rd, Tainan 701, Taiwan.
EM gookey22@gmail.com; cnyang@mail.ndhu.edu.tw; htlin100@gmail.com
RI Yang, Ching-Nung/HKV-1639-2023; Lin, Hui-Tang/AAE-6097-2019
OI Lin, Hui-Tang/0000-0002-3183-5727; Yang, Ching-Nung/0000-0002-3881-7329
CR Alharthi S, 2010, IEEE INT CON MULTI, P1661, DOI 10.1109/ICME.2010.5583180
   Cachin C., 1997, THESIS SWISS FEDERAL
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S., 2011, DIGITAL IMAGING COMP
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Guo T., 2012, INFORM SECURITY PRAC, V7232, P217
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Kuwakado H, 2004, IEICE T FUND ELECTR, VE87A, P1193
   Lee KH, 2011, OPT COMMUN, V284, P2730, DOI 10.1016/j.optcom.2011.01.077
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Liu F, 2009, DESIGN CODE CRYPTOGR, V50, P215, DOI 10.1007/s10623-008-9225-3
   McCune JM, 2005, P IEEE S SECUR PRIV, P110, DOI 10.1109/SP.2005.19
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Takizawa O., 2005, Journal of the National Institute of Information and Communications Technology, V52, P173
   Takizawa O., 2001, IPSJ COMP SEC S, P343
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Wang DS, 2011, INFORM SCIENCES, V181, P2189, DOI 10.1016/j.ins.2011.01.019
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Yang CN, 2008, CRYPTOLOGIA, V32, P131, DOI 10.1080/01611190701869669
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2010, OPT COMMUN, V283, P4949, DOI 10.1016/j.optcom.2010.07.051
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2009, SIGNAL PROCESS, V89, P1602, DOI 10.1016/j.sigpro.2009.02.014
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 30
TC 12
Z9 12
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 318
EP 331
DI 10.1016/j.jvcir.2013.01.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200010
DA 2024-07-18
ER

PT J
AU Chiranjeevi, P
   Sengupta, S
AF Chiranjeevi, P.
   Sengupta, S.
TI Spatially correlated background subtraction, based on adaptive
   background maintenance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving object detection; Background subtraction; Dynamic backgrounds; Hu
   moment; Improved Hu moment; Covariance matrix; Spatial correlation;
   Adaptive model updating rates
ID IMAGE; SEGMENTATION; TRACKING
AB Moving object detection in dynamic backgrounds remains a challenging problem. Our earlier work established that the background subtraction using the covariance matrix descriptor is robust for dynamic backgrounds. The work proposed herein extends this approach further, using just two features-Hu moment and intensity. An improved local Hu moment is proposed, where the moment calculation of a pixel, involving neighboring pixels, are used in a weighted manner to reduce the effects of background moving pixels and the accurate shape localization of moving objects simultaneously. To further counter the erratic labeling of dynamic pixels, the fact that the neighboring pixels are spatially correlated is exploited for model construction and foreground detection. An adaptive model updating rate is calculated as a function of model distance. The proposed approach models each pixel with a covariance matrix and a mean feature vector and is dynamically updated. Extensive studies are made with the proposed technique to demonstrate its effectiveness. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Chiranjeevi, P.; Sengupta, S.] Indian Inst Technol Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Chiranjeevi, P (corresponding author), Indian Inst Technol Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
EM chiru.pojala@gmail.com; ssg@ece.iitkgp.erne-t.in
RI Kolekar, Maheshkumar/ABF-8942-2020
OI Kolekar, Maheshkumar/0000-0002-4272-3528
CR [Anonymous], 200137540 IST
   Bineng Zhong, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P152
   Chen YT, 2007, PATTERN RECOGN, V40, P2706, DOI 10.1016/j.patcog.2006.11.023
   Chiranjeevi P, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3662910
   El Baf F, 2008, IEEE INT CONF FUZZY, P1731
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Forstner W., 1999, METRIC COVARIANCE MA
   Greiffenhagen M, 2001, PROC CVPR IEEE, P704
   HEIKKILA M., 2004, British Machine Vision Conference, P187, DOI DOI 10.5244/C.18.21
   Herrero S, 2009, LECT NOTES COMPUT SC, V5807, P33
   Hongxun Z, 2006, LECT NOTES COMPUT SC, V4223, P887
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jodoin PM, 2007, IEEE T CIRC SYST VID, V17, P1758, DOI 10.1109/TCSVT.2007.906935
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lin HH, 2011, IEEE T IMAGE PROCESS, V20, P822, DOI 10.1109/TIP.2010.2075938
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Messelodi S, 2005, LECT NOTES COMPUT SC, V3617, P163, DOI 10.1007/11553595_20
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Seki M, 2003, PROC CVPR IEEE, P65
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhang S., IEEE ICIP 08, P1556
   Zhang S., IEEE ICPR 08, P1
   Zhang SP, 2009, IEEE INT CON MULTI, P518, DOI 10.1109/ICME.2009.5202547
   Zhang SP, 2009, INT J PATTERN RECOGN, V23, P1397, DOI 10.1142/S0218001409007569
   Zheng JY, 2006, TRANSPORT RES REC, P82
NR 30
TC 16
Z9 17
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 948
EP 957
DI 10.1016/j.jvcir.2012.06.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900011
DA 2024-07-18
ER

PT J
AU Song, CL
   Sudirman, S
   Merabti, M
AF Song, Chunlin
   Sudirman, Sud
   Merabti, Madjid
TI A robust region-adaptive dual image watermarking technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robust watermarking system; Region-adaptive watermarking system; DWT-SVD
   domain; Dual watermark images; Watermark attack analysis; Fourier
   spectrum; Histogram; Stirmark
ID ATTACKS
AB Despite the progress in digital image watermarking technology, the main objectives of the majority of research in this area remain to be the improvement in robustness to attack. In this paper, a novel watermarking technique is proposed using a region-adaptive approach to further improve upon criteria. Watermark data is embedded on different regions of the host image using a combination of Discrete Wavelet Transform and Singular Value Decomposition techniques. The technique is derived from an earlier hypothesis that the robustness of a watermarking process can be improved by using watermark data which frequency spectrum not dissimilar to that of the host data. To facilitate this, the technique utilises dual watermarking technologies and embed parts of the watermark images into selected regions in the host image. Our experiment shows our technique has improved the robustness of the watermark data to image processing attacks and geometric attacks, thus validating the earlier hypothesis. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Song, Chunlin; Sudirman, Sud; Merabti, Madjid] Liverpool John Moores Univ, Sch Comp & Math, Liverpool L3 3AF, Merseyside, England.
C3 Liverpool John Moores University
RP Song, CL (corresponding author), Liverpool John Moores Univ, Sch Comp & Math, Liverpool L3 3AF, Merseyside, England.
EM C.L.Song@2004.ljmu.ac.uk; s.sudirman@ljmu.ac.uk; m.merabti@ljmu.ac.uk
RI Sudirman, Sud/AAF-6901-2020
OI Sudirman, Sud/0000-0003-4083-0810
CR [Anonymous], 2000, Computational Geometry Algorithms and Applications
   Bhatnagar G., 2008, APPL DIG INF WEB TEC, P526
   Chad C., 1999, LECT NOTES COMPUTER, V1614
   Erdogan C., 2001, IEEE T NEURAL NETWOR, P12394
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Ingemar J.C., 2008, DIGITAL WATERMARKING, V2nd
   Jagadeesh B, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P120, DOI 10.1109/ICSAP.2010.71
   Jain A.K., 1990, SYSTEMS MAN CYBERNET, P14
   Lai C. C., 2010, IEEE T INSTRUMENTATI, V59
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Moustafa K.A., 2007, FGCN P FUT GEN COMM, V156-161
   Nikolaidis A, 2001, IEEE T IMAGE PROCESS, V10, P1726, DOI 10.1109/83.967400
   PETITCOLAS F, 1998, INF HID 2 INT WORKSH
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Riaz S, 2008, 2008 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES, PROCEEDINGS, P211, DOI 10.1109/ICET.2008.4777502
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Song C., 2009, PROC 10 POSTGRADUATE, P283
   Tao P.N., 2004, INT MULT MAN SYST C, P5601133
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Ying-Hua L., 2007, WAV AN PATT REC 2007, P1865
   Zain J., 2005, SETIT 2005 3 INT C S
NR 22
TC 58
Z9 64
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 549
EP 568
DI 10.1016/j.jvcir.2012.01.017
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800013
DA 2024-07-18
ER

PT J
AU Hu, WC
   Chen, CH
   Huang, DY
   Ye, YT
AF Hu, Wu-Chih
   Chen, Chao-Ho
   Huang, Deng-Yuan
   Ye, Yan-Ting
TI Video object segmentation in rainy situations based on difference scheme
   with object structure and color analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video object segmentation; Background subtraction; Frame difference;
   Object structure; Color analysis; Rainy situation; Change detection;
   Diamond window mask
ID TRACKING
AB A scheme based on a difference scheme using object structures and color analysis is proposed for video object segmentation in rainy situations. Since shadows and color reflections on the wet ground pose problems for conventional video object segmentation, the proposed method combines the background construction-based video object segmentation and the foreground extraction-based video object segmentation where pixels in both the foreground and background from a video sequence are separated using histogram-based change detection from which the background can be constructed and detection of the initial moving object masks based on a frame difference mask and a background subtraction mask can be further used to obtain coarse object regions. Shadow regions and color-reflection regions on the wet ground are removed from the initial moving object masks via a diamond window mask and color analysis of the moving object. Finally, the boundary of the moving object is refined using connected component labeling and morphological operations. Experimental results show that the proposed method performs well for video object segmentation in rainy situations. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Makung 880, Penghu, Taiwan.
   [Chen, Chao-Ho; Ye, Yan-Ting] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.
   [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, Changhua 515, Taiwan.
C3 National Penghu University of Science & Technology; National Kaohsiung
   University of Science & Technology; Da Yeh University
RP Hu, WC (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Makung 880, Penghu, Taiwan.
EM wchu@npu.edu.tw; thouho@cc.kuas.edu.tw; kevin@mail.dyu.edu.tw;
   1094320134@cc.kuas.edu.tw
CR Carmona EJ, 2008, PATTERN RECOGN LETT, V29, P272, DOI 10.1016/j.patrec.2007.10.007
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Chen TH, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P257
   Chen TY, 2009, INT J INNOV COMPUT I, V5, P1797
   Chen W, 2010, DIGIT SIGNAL PROCESS, V20, P1637, DOI 10.1016/j.dsp.2010.02.005
   Gupta A, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P336, DOI 10.1109/ICCSIT.2009.5234624
   Hu W.-C., 2010, ICIC EXPRESS LETT B, V1, P45
   HU W-C., 2011, Journal of Information Hiding and Multimedia Signal Processing, V2, P123
   Hu WC, 2011, J VIS COMMUN IMAGE R, V22, P543, DOI 10.1016/j.jvcir.2011.03.009
   Hu WC, 2011, INT J INNOV COMPUT I, V7, P1845
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Leng B., 2007, P PICT COD S 2007
   Liao HYM, 2006, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2006.1692634
   Sugandi B, 2009, INT J INNOV COMPUT I, V5, P1179
   Wang L, 2010, IEEE T INTELL TRANSP, V11, P40, DOI 10.1109/TITS.2009.2026674
   Wang Y, 2005, IEEE T IMAGE PROCESS, V14, P937, DOI 10.1109/TIP.2005.849330
   WOLLBORN M, 1998, M3448 ISOIEC JTC1SC2
   Zhang GY, 2006, INT C COMMUN CIRCUIT, P437, DOI 10.1109/ICCCAS.2006.284671
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
   ZHU S, 2008, INT J COMPUTER SCI E, V2, P157
NR 20
TC 9
Z9 10
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 303
EP 312
DI 10.1016/j.jvcir.2011.10.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900008
DA 2024-07-18
ER

PT J
AU Li, BP
   Meng, MQH
AF Li, Baopu
   Meng, Max Q. -H.
TI Wireless capsule endoscopy images enhancement via adaptive contrast
   diffusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Wireless capsule endoscopy image; Enhancement; Contrast; Diffusion; GI
   tract; Local analysis; Hessian matrix; Computer aided detection
ID ANISOTROPIC DIFFUSION
AB Wireless capsule endoscopy (WCE) has been widely applied to diagnose diseases in human digestive tract due to its advantage that it can directly view the entire small intestine for the first time. However, many WCE images are rather dark, which challenge to analysis and diagnosis exerted by a clinician. To overcome this shortcoming so as to assist physicians, especially computer aided detection, we propose an adaptive contrast diffusion to enhance WCE images. Based on local analysis of WCE images, we put forward a new idea of contrast diffusion. Then, we employ contrast diffusion to enhance WCE images with an adaptive choice of the conductance parameter, which plays an important role in diffusion. Extensive experiments demonstrate that this new method exhibits promising performance of enhancement for WCE images, leading into a better visualization as well as an improved classification performance of WCE images using computerized methods. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Li, Baopu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Li, Baopu; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese University of Hong Kong
RP Li, BP (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM greenfigo2008@gmail.com
RI Meng, Max Q.-H./C-8078-2009; Meng, Q./GSI-6185-2022; meng,
   meng/GWZ-7461-2022
FU Hong Kong Research Grants Council (RGC) [415709]; Innovation and
   Technology Support Programme in Hong Kong [ITS/430/09]
FX This work is supported by the Hong Kong Research Grants Council (RGC)
   General Research Fund (415709) and Innovation and Technology Support
   Programme (ITS/430/09) in Hong Kong, both awarded to Max Meng.
   Meanwhile, we should also show our sincere thanks to James Lau, a
   professor in Prince of Wales Hospital in Hong Kong, for providing us WCE
   image data. Last but not least, we would like to express our gratitude
   to the anonymous reviewers for their constructive comments that lead to
   this manuscript's improvements in quality and representation.
CR [Anonymous], 2003, Hosp Physician
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P97
   Carmona RA, 1998, IEEE T IMAGE PROCESS, V7, P353, DOI 10.1109/83.661185
   Ge ZZ, 2004, WORLD J GASTROENTERO, V10, P1349
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   HARA AK, 2003, RADIOLOGY, P260
   *HONG KONG REG HOS, 2007, CANC STAT
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Lee D. W. H., 2004, Hong Kong Medical Journal, V10, P419
   LI B, 2010, ENHANCEMENT CAPSULE
   LI XP, 1994, PATTERN RECOGN, V27, P1029, DOI 10.1016/0031-3203(94)90142-2
   LITWILLER D, 2005, PHOTONICS SPECTRA
   Lorenz C, 1997, LECT NOTES COMPUT SC, V1205, P233, DOI 10.1007/BFb0029242
   MENG MQH, 2004, P 5 WORLD C INT CONT, P5561
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Sato Y, 1998, Med Image Anal, V2, P143, DOI 10.1016/S1361-8415(98)80009-1
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sun QL, 2004, COMPUT MED IMAG GRAP, V28, P461, DOI 10.1016/j.compmedimag.2004.08.001
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Tsai DM, 2005, IMAGE VISION COMPUT, V23, P325, DOI 10.1016/j.imavis.2004.09.003
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   WONG RF, 2006, CLIN GASTROENTEROLOG, V4, P998
   Xiang X, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2194032
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 30
TC 38
Z9 41
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 222
EP 228
DI 10.1016/j.jvcir.2011.10.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100021
DA 2024-07-18
ER

PT J
AU Zhang, BC
   Zhong, BN
   Cao, Y
AF Zhang, Baochang
   Zhong, Bineng
   Cao, Yao
TI Complex background modeling based on Texture Pattern Flow with adaptive
   threshold propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion detection; Adaptive threshold propagation; GMM; Background
   modeling; Background subtraction; Texture Pattern Flow; Binary pattern;
   Integral histogram
ID LOCAL BINARY PATTERNS; FACE
AB This paper proposes a high-order Texture Pattern Flow (TPF) for complex background modeling and motion detection. The pattern flow is proposed to encode the binary pattern changes among the neighborhoods in the space-time domain. To model the distribution of the TPF pattern flow, the TPF integral histograms are used to extract the discriminative features to represent the input video. The Gaussian Mixture Model (GMM) is exploited to calculate an adaptive threshold in propagation way for the histogram similarity measure to decide which part/pixel is background or moving object. Experimental results on the public databases testify the effectiveness of the proposed method in comparison to LBP and GMM based background modeling methods. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Zhang, Baochang; Cao, Yao] Beihang Univ, Sch Automat Sci & Elect Engn, Sci & Technol Aircraft Control Lab, Beijing 100191, Peoples R China.
   [Zhong, Bineng] Huaqiao Univ, Dept Comp Sci & Technol, Xiamen 361021, Peoples R China.
C3 Beihang University; Huaqiao University
RP Zhang, BC (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Sci & Technol Aircraft Control Lab, Beijing 100191, Peoples R China.
EM bczhang@buaa.edu.cn; bnzhong@vilab.hit.edu.cn; caoyao@buaa.edu.cn
FU Natural Science Foundation of China [60903065, 61039003]; Ph.D. Programs
   Foundation of Ministry of Education of China [20091102120001];
   Fundamental Research Funds for the Central Universities
FX This work was supported in part by the Natural Science Foundation of
   China, under Contracts 60903065 and 61039003, in part by the Ph.D.
   Programs Foundation of Ministry of Education of China, under Grant
   20091102120001, and in part by the Fundamental Research Funds for the
   Central Universities.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HJ, 2005, LECT NOTES COMPUT SC, V3687, P334
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 13
TC 5
Z9 6
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 516
EP 521
DI 10.1016/j.jvcir.2011.05.001
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000006
DA 2024-07-18
ER

PT J
AU Bustamante, AL
   Lopez, JMM
   Patricio, MA
AF Luis Bustamante, Alvaro
   Molina Lopez, Jose M.
   Patricio, Miguel A.
TI MIJ2K: Enhanced video transmission based on conditional replenishment of
   JPEG2000 tiles with motion compensation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE JPEG2000; Streaming; rtp; Real-time; Motion; Tile; Interframe;
   Compensation
AB A video compressed as a sequence of JPEG2000 images can achieve the scalability, flexibility, and accessibility that is lacking in current predictive motion-compensated video coding standards. However, streaming JPEG2000-based sequences would consume considerably more bandwidth. With the aim of solving this problem, this paper describes a new patent pending method, called MIJ2K. MIJ2K reduces the inter-frame redundancy present in common JPEG2000 sequences (also called MJP2). We apply a real-time motion detection system to perform conditional tile replenishment. This will significantly reduce the bit rate necessary to transmit JPEG2000 video sequences, also improving their quality.
   The MIJ2K technique can be used both to improve JPEG2000-based real-time video streaming services or as a new codec for video storage. MIJ2K relies on a fast motion compensation technique, especially designed for real-time video streaming purposes. In particular, we propose transmitting only the tiles that change in each JPEG2000 frame. This paper describes and evaluates the method proposed for real-time tile change detection, as well as the overall MIJ2K architecture.
   We compare MIJ2K against other intra-frame codecs, like standard Motion JPEG2000, Motion JPEG, and the latest H.264-Intra, comparing performance in terms of compression ratio and video quality, measured by standard peak signal-to-noise ratio, structural similarity and visual quality metric metrics. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Luis Bustamante, Alvaro; Molina Lopez, Jose M.; Patricio, Miguel A.] Univ Carlos III Madrid, Madrid 28270, Spain.
C3 Universidad Carlos III de Madrid
RP Bustamante, AL (corresponding author), Univ Carlos III Madrid, Avda Univ Carlos III 22, Madrid 28270, Spain.
EM aluis@inf.uc3m.es; molina@ia.uc3m.es; mpatrici@inf.uc3m.es
RI Lopez, Jose/HZL-8909-2023; López, José/B-5579-2015; Patricio, Miguel
   A./AAZ-4876-2020; Molina, Jose/B-1956-2008; Lopez, Jose/KHD-0318-2024
OI Patricio, Miguel A./0000-0002-9304-826X; Molina,
   Jose/0000-0002-7484-7357; 
FU CICYT [TIN2008-06742-C02-02/TSI, TEC2008-06732-C02-02/TEC]; SINPROB; CAM
   MADRINET [S-0505/TIC/0255];  [DPS2008-07029-C02-02]
FX This work was supported in part by Projects CICYT
   TIN2008-06742-C02-02/TSI, CICYT TEC2008-06732-C02-02/TEC, SINPROB, CAM
   MADRINET S-0505/TIC/0255 and DPS2008-07029-C02-02.
CR ADAMS M, 2001, 2001 IEEE PAC RIM C, V1
   [Anonymous], 2000, DCT BASED VIDEO QUAL
   [Anonymous], WHATS WRONG MEAN SQU
   BUSTAMANTE AL, 2009, P 11 ANN C GEN EV CO, P1835
   BUSTAMANTE AL, 2008, INT S DISTR COMP ART, P574
   CHARRIER M, 1999, IEEE INT C MULT COMP, V1
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   DEVAUX F, IEEE INT C AC SPEECH
   Fössel S, 2003, IEEE T CONSUM ELECTR, V49, P787, DOI 10.1109/TCE.2003.1261156
   FUKUHARA T, 2000, IM PROC 2000 P 2000, V2
   FUTEMMA S, 2008, RTP PAYLOAD FORMAT J
   *ISO IEC, 2007, 1544432007 ISO IEC
   *ISO IEC, 1544412000 ISO IEC
   Karlsson G, 1996, IEEE COMMUN MAG, V34, P118, DOI 10.1109/35.533930
   *L DIG CIN IN, 2008, DIG CIN SYST SPEC VE
   LORA M, 1994, TEST MEDIA
   Marpe D, 2003, PROC SPIE, V5266, P129
   MEESSEN J, 2005, IEEE INT C IM PROC 2, V1
   NAMAN A, 2007, IEEE INT C IM PROC 2, V5
   NAMAN A, 2007, P INT WORKSH MOB VID, P43
   Netravali A. N, 1996, Digital video: an introduction to MPEG-2
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Pereira F., 2002, IMSC Press multimedia series
   Santa-Cruz D, 2000, P SOC PHOTO-OPT INS, V4115, P446, DOI 10.1117/12.411564
   SANTACRUZ D, 2000, IM PROC 2000 P 2000, V2
   Shi Y.Q., 2000, IMAGE PROC SER
   Shirai D, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1855
   Skodras AN, 2001, PATTERN RECOGN LETT, V22, P1337, DOI 10.1016/S0167-8655(01)00079-4
   VanDroogenbroeck M, 1996, PATTERN RECOGN LETT, V17, P1451, DOI 10.1016/S0167-8655(96)00113-4
   Varma K, 2004, IEEE SIGNAL PROC MAG, V21, P70, DOI 10.1109/MSP.2004.1359144
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Watson AB, 1998, P SOC PHOTO-OPT INS, V3299, P139, DOI 10.1117/12.320105
NR 34
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2011
VL 22
IS 4
BP 332
EP 344
DI 10.1016/j.jvcir.2011.02.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 751AG
UT WOS:000289589100004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, RQ
   Ouyang, WL
   Cham, WK
AF Zhang, Renqi
   Ouyang, Wanli
   Cham, Wai-Kuen
TI Image postprocessing by Non-local Kuan's filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blocking artifacts; Low bit rates; Postprocessing; MMSE; Two
   assumptions; Non-local Kuan's filter; DNLK filter; OCDNLK filter
ID ARTIFACT REDUCTION; BLOCKING ARTIFACTS; CONSTRAINT SET; DCT; DEBLOCKING;
   PROJECTION; COEFFICIENTS; NOISE
AB Blocking artifacts exist in images and video sequences compressed to low bit rates using block-based discrete cosine transform (DCT) compression standards. In order to reduce blocking artifacts, two image postprocessing techniques, DNLK filter and OCDNLK filter, are presented in this paper. A more accurate DCT domain Kuan's filter based on Non-local parameter estimation was proposed from the linear minimum mean-square-error (MMSE) criterion. We analyze the required two assumptions for the filter theoretically. Then the DCT domain Kuan's filter for low frequency coefficients and Non-local mean filter for high frequency AC coefficients constitute the proposed Non-local Kuan's (NLK) filter. After that, we propose the Dual Non-local Kuan's (DNLK) filter by applying the proposed filter in dual layer. The DNLK filter is extended to form the Overcomplete Dual Non-local Kuan's (OCDNLK) filter by applying to the overcomplete DCT coefficients. Experimental results on coded images using test quantization tables and JPEG coded images show the effectiveness of the two methods. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Zhang, Renqi; Ouyang, Wanli; Cham, Wai-Kuen] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Zhang, RQ (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM rqzhang@ee.cuhk.edu.hk; wlouyang@ee.cuhk.edu.hk; wkcham@ee.cuhk.edu.hk
RI Zhang, Renqi/AHE-3861-2022; Ouyang, Wanli/I-7135-2018
OI Ouyang, Wanli/0000-0002-9163-2761
CR [Anonymous], 2009, IJSP IMAGE PROCESS P
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CHANG SF, 1995, IEEE J SEL AREA COMM, V13, P1, DOI 10.1109/49.363151
   Chen T, 2001, IEEE T CIRC SYST VID, V11, P594, DOI 10.1109/76.920189
   CHOY SSO, 1997, IEEE SIGNAL PROCESS, V4
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Gan XC, 2005, IMAGE VISION COMPUT, V23, P731, DOI 10.1016/j.imavis.2005.05.001
   GREGORY S, 1997, 30 AS C SIGN SYST CO, V1, P601
   Guleryuz OG, 2007, IEEE T IMAGE PROCESS, V16, P3020, DOI 10.1109/TIP.2007.908078
   Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184
   Hsung TC, 1998, IEEE T IMAGE PROCESS, V7, P1488, DOI 10.1109/83.718489
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1583, DOI 10.1109/TCSVT.2005.858613
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   Luo JB, 1996, IEEE T IMAGE PROCESS, V5, P1363, DOI 10.1109/83.535848
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P490, DOI 10.1109/76.754778
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Park SH, 1999, IEEE T IMAGE PROCESS, V8, P1361, DOI 10.1109/83.791962
   RAMAMURTHI B, 1986, IEEE T ACOUST SPEECH, V34, P1258, DOI 10.1109/TASSP.1986.1164961
   REEVE HC, 1984, OPT ENG, V23, P34, DOI 10.1117/12.7973248
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Sage A., 1971, ESTIMATION THEORY AP
   SRIPAD AB, 1977, IEEE T ACOUST SPEECH, V25, P442, DOI 10.1109/TASSP.1977.1162977
   SUN D, 2007, IEEE INT C AC SPEECH, V1, P705
   Sun DQ, 2007, IEEE T IMAGE PROCESS, V16, P2743, DOI 10.1109/TIP.2007.904969
   Xiong ZX, 1999, IEEE T CIRC SYST VID, V9, P692, DOI 10.1109/76.780358
   YANG YY, 1995, IEEE T IMAGE PROCESS, V4, P896, DOI 10.1109/83.392332
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   2001, MPEG4 VERIFICATION M, P271
NR 33
TC 9
Z9 10
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 251
EP 262
DI 10.1016/j.jvcir.2010.12.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300005
DA 2024-07-18
ER

PT J
AU Viswanath, K
   Mukherjee, J
   Biswas, PK
AF Viswanath, K.
   Mukherjee, Jayanta
   Biswas, P. K.
TI Image filtering in the block DCT domain using symmetric convolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discrete cosine transform; Transform domain processing; Symmetric
   convolution; Image filtering; Block DCT domain filtering; Composition
   and decomposition; Speedup factor; Blocking artifacts; Image sharpening
ID COMPRESSED DOMAIN; TRANSFORMS
AB Processing of images in the transform domain saves computation by avoiding inverse and re-transform operations. In this paper, we present a technique for filtering of images in the transform domain using symmetric convolution in the block DCT space. Due to the application of convolution-multiplication property in the DCT domain, the filtering operation requires significantly less computation than its equivalent in the original signal/image space. To take care of discontinuities along boundaries of blocks, filtering is performed on a larger DCT block composed from adjacent blocks. Subsequently, the filtered DCT block is obtained by decomposing it. The proposed filtering technique achieves the same results of linear convolution in the spatial domain with reduced cost. With the proposed filtering, it is possible to significantly speedup the operation by ignoring some elements in the filtering matrices whose magnitudes are smaller than a threshold value. Typical sparseness of DCT domain input blocks is also considered for further reduction of computational cost. The proposed method uses simple linear operations such as matrix multiplication, which is appropriate for efficient hardware implementations. We also demonstrate its applications in image sharpening and removal of blocking artifacts directly in the compressed domain. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Viswanath, K.] SIT Tumkur, Dept Telecommun Engn, Tumkur, India.
   [Mukherjee, Jayanta] IIT Kharagpur, Dept Comp Sci & Engn, Kharagpur, W Bengal, India.
   [Biswas, P. K.] IIT Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
C3 Siddaganga Institute of Technology; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Kharagpur;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Viswanath, K (corresponding author), SIT Tumkur, Dept Telecommun Engn, Tumkur, India.
EM kviitkgp@gmail.com; jay@cse.iitkgp.ernet.in; pkb@ece.iitkgp.ernet.in
RI Biswas, Prabir Kumar/AAV-4935-2021; Biswas, Prabir Kumar/AAY-5904-2021
OI Kapinaiah, Viswanath/0000-0001-8563-5379
FU Siddaganga Institute of Technology-Tumkur, INDIA; All India Council for
   Technical Education (AICTE), Government of India
FX The first author acknowledges the financial support provided by
   Siddaganga Institute of Technology-Tumkur, INDIA and All India Council
   for Technical Education (AICTE), Government of India.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Chan RC, 2000, COMPUT CARDIOL, V27, P37, DOI 10.1109/CIC.2000.898449
   DATTA BN, 2010, SIAM
   Drori I, 2003, IEEE T VIS COMPUT GR, V9, P395, DOI 10.1109/TVCG.2003.1207446
   Foltz TM, 2000, IEEE T SIGNAL PROCES, V48, P2691, DOI 10.1109/78.863086
   Foltz TM, 1998, J OPT SOC AM A, V15, P2827, DOI 10.1364/JOSAA.15.002827
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Kresch R, 1999, IEEE T IMAGE PROCESS, V8, P821, DOI 10.1109/83.766859
   MARTUCCI SA, 1994, IEEE T SIGNAL PROCES, V42, P1038, DOI 10.1109/78.295213
   MARTUCCI SA, 1993, P IEEE INT C AC SPEE, V5, P65
   MERHAV N, 1996, HPL9556
   Mukherjee J, 2005, IEE P-VIS IMAGE SIGN, V152, P155, DOI 10.1049/ip-vis:20040843
   Mukherjee J, 2006, LECT NOTES COMPUT SC, V4338, P194
   Shen B, 1998, IEEE T CIRC SYST VID, V8, P947, DOI 10.1109/76.736723
   Wu BF, 1999, J CHIN INST ENG, V22, P179, DOI 10.1080/02533839.1999.9670455
   Yim CH, 2004, IEEE T CIRC SYST VID, V14, P517, DOI 10.1109/TCSVT.2004.825558
NR 16
TC 5
Z9 6
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 141
EP 152
DI 10.1016/j.jvcir.2010.11.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600004
DA 2024-07-18
ER

PT J
AU He, L
   Zheng, SF
   Wang, L
AF He, Lei
   Zheng, Songfeng
   Wang, Li
TI Integrating local distribution information with level set for boundary
   extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Implicit active contour; Gaussian mixture model;
   Hueckel edge operator; Zernike moments; Local distribution fitting;
   Level set without initial contour; Piecewise smooth image
ID IMAGE SEGMENTATION; MINIMIZATION; EVOLUTION; TEXTURE; COLOR
AB This paper presents a general object boundary extraction model for piecewise smooth images, which incorporates local intensity distribution information into an edge-based implicit active contour. Unlike traditional edge-based active contours that use gradient to detect edges, our model derives the neighborhood distribution and edge information with two different region-based operators: a Gaussian mixture model (GMM)-based intensity distribution estimator and the Hueckel operator. We propose the local distribution fitting model for more accurate segmentation, which incorporates the operator outcomes into the recent local binary fitting (LBF) model. The GMM and the Hueckel model parameters are estimated before contour evolution, which enables the use of the proposed model without the need for initial contour selection, i.e., the level set function is initialized with a random constant instead of a distance map. Thus our model essentially alleviates the initialization sensitivity problem of most active contours. Experiments on synthetic and real images show the improved performance of our approach over the LBF model. (C) 2010 Elsevier Inc. All rights reserved.
C1 [He, Lei] Armstrong Atlantic State Univ, Coll Sci & Technol, Dept Informat Comp & Engn, Savannah, GA 31419 USA.
   [Zheng, Songfeng] Missouri State Univ, Dept Math, Springfield, MO 65897 USA.
   [Wang, Li] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.
C3 University System of Georgia; Armstrong Atlantic State University;
   Missouri State University; Nanjing University of Science & Technology
RP He, L (corresponding author), Armstrong Atlantic State Univ, Coll Sci & Technol, Dept Informat Comp & Engn, 11935 Abercorn St, Savannah, GA 31419 USA.
EM Lei.He@armstrong.edu
RI Wang, Li/O-1425-2015; wang, li/O-1425-2015
OI Wang, Li/0000-0003-2165-0080; wang, li/0000-0001-8927-6772
CR AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805
   AMBROSIO L, 1992, B UNIONE MAT ITAL, V6B, P105
   [Anonymous], 0906 UCLA CAM
   [Anonymous], 1977, MAXIMUM LIKELIHOOD I
   [Anonymous], 2009, P INT C COMP VIS
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P203
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439
   GRADY L, IEEE T IMAG IN PRESS
   He L, 2008, IMAGE VISION COMPUT, V26, P141, DOI 10.1016/j.imavis.2007.07.010
   HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   LI C, IEEE T IMAG IN PRESS
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MARKUS U, 2008, P BRIT MACH VIS C
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   MORY B, 2007, P IEEE INT C COMP VI
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   SFIKAS G, 2008, P IEEE C COMP VIS PA
   Sum KW, 2008, IEEE T BIO-MED ENG, V55, P358, DOI 10.1109/TBME.2007.896587
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang X, 2004, INT J COMPUT VISION, V59, P87, DOI 10.1023/B:VISI.0000020672.14006.ad
   Weber M, 2004, LECT NOTES COMPUT SC, V3022, P391
   Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 39
TC 28
Z9 31
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 343
EP 354
DI 10.1016/j.jvcir.2010.02.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800007
DA 2024-07-18
ER

PT J
AU Narasimha, R
   Dihidar, S
   Ji, CY
   McLaughlin, SW
AF Narasimha, Rajesh
   Dihidar, Souvik
   Ji, Chuanyi
   McLaughlin, Steven W.
TI Scalable diagnosis in IP networks using path-based measurement and
   inference: A learning framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia networks; Scalable diagnosis; Machine learning; Variational
   inference; Bayesian belief networks; Low density parity check codes;
   Inference; Congestion; Link failure; Measurements
AB In this paper, we investigate scalability and performance of measurement-based network monitoring, focusing on failure and congestion diagnosis in IP networks for network-based multimedia applications. Path-based measurements using unicast probe-packets are obtained at end-hosts, and diagnosis is performed by exploiting the spatial dependence among those measurements. We formulate network monitoring in a machine learning framework using probabilistic graphical models which perform inference of the network states (on/off) using unicast measurements. We provide fundamental limits on the relationship between the number of probe packets, the size of a network and the ability to diagnose either failed links or congested network components. Specifically, the diagnosis problem is dealt in a two-fold manner. Initially for fault diagnosis, we construct a graphical model using a Bayesian belief network for path-based measurements. We then provide a lower bound on the average number of probes per edge for link failure diagnosis using variational inference under "noisy" probe measurements. Variational inference provides a feasible approximation to address the number of spatially dependent measurements needed for diagnosis in large networks. We then develop an entropy lower (EL) bound by drawing similarities between coding over a binary symmetric channel (BSC) and link failure diagnosis. Both bounds show that the number of measurements needed for diagnosis grows linearly with respect to the number of links. The analytical results are validated by simulation. On the other hand, for congestion diagnosis, we propose a solution based on decoding of linear error control codes on a BSC. In this scenario, we consider path-based probing experiments under both noiseless and "noisy" measurements and compare its performance against the fundamental limits. To identify the congested nodes we construct a factor graph, and congestion is inferred using belief-propagation algorithm. Simulation results demonstrate the ability of our approach to perfectly localize congested nodes using a scalable number of measurements and a computationally efficient algorithm. We believe that this study can ease the problem arising due to lack of QoS support and provide good-quality broadband multimedia services. (C) 2010 Published by Elsevier Inc.
C1 [Narasimha, Rajesh; Dihidar, Souvik; Ji, Chuanyi; McLaughlin, Steven W.] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Narasimha, R (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM rajesh@ece.gatech.edu; dihidar@ece.gatech.edu; jic@ece.gatech.edu;
   swm@ece.gatech.edu
FU NSF [ECS-0300605, ECS-9908578]
FX This work is supported in part by NSF grants ECS-0300605 and
   ECS-9908578. Parts of this paper have been presented at IEEE
   Communication Conference (ICC) 2006 and 2007.
CR Akella Aditya, 2003, ACM SIGCOMM C INTERN
   [Anonymous], 2004, APPROXIMATION ALGORI
   BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996
   BOUTREMANS C, 2002, P ACM NOSSDAV
   Breitbart Y., 2000, P IEEE INFOCOM
   BRODIE M, 2002, IBM SYSTEMS J, V41
   Burshtein D, 2002, IEEE T INFORM THEORY, V48, P2437, DOI 10.1109/TIT.2002.801408
   CASTRO R, 2003, INTERNET TOMOGRAPHY
   CHEN Y, 2004, ALGEBRAIC APPROACH P
   CHUA D, 2005, ACM SIGMETRICS PERFO, V33, P390
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DAVIE B, 1997, EXPLICIT ROUTE SUPPO
   Floyd S., 1994, Computer Communication Review, V24, P8, DOI 10.1145/205511.205512
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Gallager R. G., 1968, INFORM THEORY RELIAB
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Geman S, 2001, IEEE T INFORM THEORY, V47, P549, DOI 10.1109/18.910574
   Habib A, 2004, COMPUT NETW, V44, P211, DOI 10.1016/j.comnet.2003.08.002
   Hu N., 2004, Locating Internet Bottlenecks: Algorithms, Measurements, and Implications
   Iyer S., 2003, An approach to alleviate link overload as observed on an ip backbone
   Ji CY, 2002, IEEE J SEL AREA COMM, V20, P714, DOI 10.1109/JSAC.2002.1003038
   Jordan M.I, 1998, Learning in Graphical Models
   Kandula S., 2005, MINENET WORKSH SIGCO
   KATABI D, 2001, IEEE INT C COMP COMM
   KATZELA I, 1995, IEEE T NETWORKING, V3
   Kliger S., 1995, Integrated Network Management IV, P266
   Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536
   Labovitz C, 1998, IEEE ACM T NETWORK, V6, P515, DOI 10.1109/90.731185
   Mao YY, 2005, IEEE J SEL AREA COMM, V23, P820, DOI 10.1109/JSAC.2005.843557
   Markopoulou A, 2004, IEEE INFOCOM SER, P2307
   Medina A., 2001, BUCSTR2001003
   Paxson V, 1997, IEEE ACM T NETWORK, V5, P601, DOI 10.1109/90.649563
   Paxson V, 1999, IEEE ACM T NETWORK, V7, P277, DOI 10.1109/90.779192
   Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P599, DOI 10.1109/18.910577
   Rish I, 2005, IEEE T NEURAL NETWOR, V16, P1088, DOI 10.1109/TNN.2005.853423
   RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936
   RUBENSTEIN D, 2000, P ACM SIGMETRICS 00
   Seetharaman S, 2006, IEEE INFOCOM SER, P2800
   Steinder M, 2004, IEEE ACM T NETWORK, V12, P809, DOI 10.1109/TNET.2004.836121
   Tachibana A, 2005, 2005 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P342, DOI 10.1109/SAINT.2005.26
   Tang C., 2004, MSUCSE0442
   Vardi Y, 1996, J AM STAT ASSOC, V91, P365, DOI 10.2307/2291416
   Wen Y., 2005, IEEE OSA J LIGHT OCT
NR 43
TC 1
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 175
EP 191
DI 10.1016/j.jvcir.2009.07.007
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800011
DA 2024-07-18
ER

PT J
AU Duan, Q
   Angelini, ED
   Laine, AF
AF Duan, Qi
   Angelini, Elsa D.
   Laine, Andrew F.
TI Surface Function Actives
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Surface Function Actives; Image segmentation; Deformable model;
   Real-time segmentation; Variational approach; Interface representation
ID CONTOUR MODEL; SEGMENTATION; QUANTIFICATION; ULTRASOUND; TRACKING; MR;
   IMAGES
AB Deformable models have been widely used in image segmentation since the introduction of the snakes. Later the introduction of level set frameworks to solve the energy minimization problem associated with the deformable model overcame some limitations of the parametric active contours with respect to topological changes by embedding surface representations into higher dimensional functions. However, this may also bring in more computational load so that recent advances in spatio-temporal resolutions of 3D/4D imaging raised some challenges for real-time segmentation, especially for interventional imaging. In this context, a novel segmentation framework, Surface Function Actives (SFA), is proposed for real-time segmentation purpose. SFA has great advantages in terms of potential efficiency, based on its dimensionality reduction for the surface representation. Utilizing implicit representations with variational framework also provides flexibility and benefits currently shared by level set frameworks. An application for minimally-invasive intervention is shown to illustrate the potential applications of this framework. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Duan, Qi] NYU, Sch Med, Ctr Biomed Imaging, New York, NY 10016 USA.
   [Duan, Qi; Laine, Andrew F.] Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA.
   [Angelini, Elsa D.] Ecole Natl Super Telecommun Bretagne, LTCI, Dept Image & Signal Proc, CNRS,UMR 5141, Paris, France.
C3 New York University; Columbia University; IMT - Institut Mines-Telecom;
   IMT Atlantique; Centre National de la Recherche Scientifique (CNRS)
RP Duan, Q (corresponding author), NYU, Sch Med, Ctr Biomed Imaging, 660 1st Ave,FL1, New York, NY 10016 USA.
EM Qi.Duan@nyumc.org
RI Angelini, Elsa D/A-7363-2009; Duan, Qi/J-7916-2016
OI Duan, Qi/0000-0002-2407-6611; Angelini, Elsa/0000-0002-1602-300X
CR Angelini ED, 2005, ULTRASOUND MED BIOL, V31, P1143, DOI 10.1016/j.ultrasmedbio.2005.03.016
   Angelini ED, 2001, IEEE T MED IMAGING, V20, P457, DOI 10.1109/42.929612
   ANGELINI ED, 2004, SPIE INT S MED IM 20, P526
   [Anonymous], 1999, LEVEL SET METHODS FA
   Bosch JG, 2002, PROC SPIE, V4684, P452, DOI 10.1117/12.467187
   Boukerroui D, 1999, LECT NOTES COMPUT SC, V1679, P516
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chalana V, 1996, IEEE T MED IMAGING, V15, P290, DOI 10.1109/42.500138
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Christie G. R., 2002, Computing and Visualization in Science, V4, P227, DOI 10.1007/s00791-002-0079-3
   Chung J, 2006, J AM COLL CARDIOL, V47, P384, DOI 10.1016/j.jacc.2005.08.061
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   DREZEK R, 1997, 25 AIPR WORKSH EM AP, P26
   DUAN Q, 2005, 3 INT C FUNCT IM MOD, P434
   DUAN Q, 2004, SPIE INT S MED IM SA, P331
   Fedkiw SOR., 2002, APPL MATH SCI, V44, P77, DOI [10.1007/ b98879, 10.1007/b98879]
   HAN X, 2001, COMPUTER VISION PATT, P765
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Hellier P, 2003, IEEE T MED IMAGING, V22, P1120, DOI 10.1109/TMI.2003.816961
   Herz SL, 2005, ANN BIOMED ENG, V33, P912, DOI 10.1007/s10439-005-3312-7
   Hillenbrand CM, 2004, MAGN RESON MED, V51, P668, DOI 10.1002/mrm.20050
   JIN Y, 2003, P 6 INT C MED IM COM, P635
   Jongbloed MRM, 2005, RADIOLOGY, V234, P702, DOI 10.1148/radiol.2343031047
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Mikic I, 1998, IEEE T MED IMAGING, V17, P274, DOI 10.1109/42.700739
   Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425
   Mulet-Parada M, 1998, LECT NOTES COMPUT SC, V1496, P806, DOI 10.1007/BFb0056268
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   NIELSEN PMF, 1991, AM J PHYSIOL, V260, pH1365, DOI 10.1152/ajpheart.1991.260.4.H1365
   O'Donnell T, 2000, PROC CVPR IEEE, P790, DOI 10.1109/CVPR.2000.854960
   Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785
   RAMM OTV, 1990, J DIGIT IMAGING, V3, P261
   Schoenhagen P, 2004, INT J CARDIOVAS IMAG, V20, P531, DOI 10.1007/s10554-004-3106-2
   Sethian J., 1999, LEVEL SET METHODS FA
   SONG T, 2004, ANN INT C IEEE ENG M, P1671
   Tao Z, 2005, PROC SPIE, V5747, P475, DOI 10.1117/12.595611
   THOMAS JG, 1991, IEEE T MED IMAGING, V10, P180, DOI 10.1109/42.79476
   Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750
   Valdés-Cristerna R, 2004, IEEE T BIO-MED ENG, V51, P459, DOI 10.1109/TBME.2003.820377
   VALLET B, 2006, SPIE MED IM C SAN DI
   VALLET B, 2006, MED IMAGING 2006 IMA, P1370
   WANG T, 2007, EUSIPCO, P307
   Wink AM, 2004, IEEE T MED IMAGING, V23, P374, DOI 10.1109/TMI.2004.824234
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
   ZHANG H, 2003, INT C IM PROC
NR 48
TC 14
Z9 17
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2009
VL 20
IS 7
BP 478
EP 490
DI 10.1016/j.jvcir.2009.06.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 559DJ
UT WOS:000274800800004
DA 2024-07-18
ER

PT J
AU Li, F
   Shen, CM
   Shen, CL
   Zhang, GX
AF Li, Fang
   Shen, Chaomin
   Shen, Chunli
   Zhang, Guixu
TI Variational denoising of partly textured images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Variational denoising; Total variation; Texture detecting function;
   Local feature
ID TOTAL VARIATION MINIMIZATION; RESTORATION; DECOMPOSITION; SPACE
AB The Rudin-Osher-Fatemi model is a widely used variational denoising algorithm which favors piecewise constant solutions. Although edge sharpness and location are well preserved, some local features such as textures and small details are often diminished with noise simultaneously. This paper aims to better preserve these local features using a similar variational framework. We introduce a texture detecting function according to the derivatives of the noisy textured image. Then this function is used to construct a spatially adaptive fidelity term, which adjusts the denoising extent in terms of the local features. Numerical results show that our method is superior to the Rudin-Osher-Fatemi model in both signal-to-noise ratio and visual quality. Moreover, part of our results are also compared with other state-of-the-art methods including a variational method and a non local means filter. The comparison shows that our method is competitive with these two methods in restoration quality but is much faster. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Shen, Chaomin; Zhang, Guixu] E China Normal Univ, Dept Comp Sci, Shanghai 200241, Peoples R China.
   [Li, Fang; Shen, Chunli] E China Normal Univ, Dept Math, Shanghai 200241, Peoples R China.
C3 East China Normal University; East China Normal University
RP Zhang, GX (corresponding author), E China Normal Univ, Dept Comp Sci, Shanghai 200241, Peoples R China.
EM gxzhang@cs.ecnu.edu.cn
RI Li, Chun/KBC-9591-2024
FU National Basic Research Program [2006CB708305]; National Science
   Foundation of China [60773119, 10671066]; ECNU [20080037]; Shanghai
   Rising-Star Program [07QH14005]; Research Fund for the Doctoral Program
   of Higher Education [200802691037]
FX Fang Li thanks G. Gilboa for his open source code for [14] and A. Buades
   for his open source code for NL-means filter. This work is supported by
   the National Basic Research Program (973 Program, No. 2006CB708305),
   National Science Foundation of China (Nos. 60773119 and 10671066), Ph.D.
   Program Scholarship Fund of ECNU 2008 (No. 20080037), Shanghai
   Rising-Star Program (07QH14005) and The Research Fund for the Doctoral
   Program of Higher Education (200802691037).
CR Almansa A, 2008, J SCI COMPUT, V34, P209, DOI 10.1007/s10915-007-9160-x
   [Anonymous], 2003, P VLSM
   AUBERT G, 2006, APPL MATH SCI, V14
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   Bertalmio M, 2003, J SCI COMPUT, V19, P95, DOI 10.1023/A:1025391506181
   BROX T, 2002, LECT NOTES COMPUTER, V2449, P446
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chen YM, 2003, SIAM J MATH ANAL, V34, P1084, DOI 10.1137/S0036141002404577
   Chen YM, 2006, SIAM J APPL MATH, V66, P1383, DOI 10.1137/050624522
   Erdem E, 2007, LECT NOTES COMPUT SC, V4485, P545
   Gilboa G, 2007, MULTISCALE MODEL SIM, V6, P595, DOI 10.1137/060669358
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2281, DOI 10.1109/TIP.2006.875247
   Hu J., 2004, T ENG COMPUT TECHNOL, V2, P245
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Meyer Y., 2001, U LECT SERIES AMS, V22
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rousson M, 2003, PROC CVPR IEEE, P699
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   STRONG DM, 0502 UCLA CAM
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
NR 28
TC 12
Z9 13
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2009
VL 20
IS 4
BP 293
EP 300
DI 10.1016/j.jvcir.2009.01.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 447EV
UT WOS:000266175300006
DA 2024-07-18
ER

PT J
AU Chiang, CC
   Hung, YP
   Yang, H
   Lee, GC
AF Chiang, Cheng-Chieh
   Hung, Yi-Ping
   Yang, Hsuan
   Lee, Greg C.
TI Region-based image retrieval using color-size features of watershed
   regions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Region-based image retrieval; Visual
   feature; Color-size feature; Region filtering; Earth mover's distance
ID ALGORITHM
AB This paper presents a region-based image retrieval system that provides a user interface for helping to specify the watershed regions of interest within a query image. We first propose a new type of visual features, called color-size feature, which includes color-size histogram and moments, to integrate color and region-size information of watershed regions. Next, we design a scheme of region filtering that is based on color-size histogram to fast screen out some of most irrelevant regions and images for the preprocessing of the image retrieval. Our region-based image retrieval system applies the Earth Mover's Distance in the design of the similarity measure for image ranking and matching. Finally, we present some experiments for the color-size feature, region filtering, and retrieval results that demonstrate the efficiency of our proposed system. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Chiang, Cheng-Chieh] Takming Univ Sci & Technol, Dept Informat Technol, Taipei, Taiwan.
   [Hung, Yi-Ping] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10764, Taiwan.
   [Yang, Hsuan] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
   [Lee, Greg C.] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 Takming University Science & Technology; National Taiwan University;
   National Taiwan University; National Taiwan Normal University
RP Chiang, CC (corresponding author), Takming Univ Sci & Technol, Dept Informat Technol, Taipei, Taiwan.
EM kevin@csie.ntnu.edu.tw; hung@csie.ntu.edu.tw; edmond.td@gmail.com;
   leeg@csie.ntnu.edu.tw
RI cai, bo/G-1491-2010
FU National Science Council, Taiwan [NSC 97-2218-E-147-002]; Ministry of
   Economic Affairs, Taiwan [97-EC-17-A-02-S1-032]
FX This work was in part supported by National Science Council, Taiwan,
   under Grant No. NSC 97-2218-E-147-002 and by Ministry of Economic
   Affairs, Taiwan, under Grant No. 97-EC-17-A-02-S1-032.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2005, P INT C COMP VIS
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   BARNARD K, 2003, INTERNET IMAGING, V9
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Chiang CC, 2005, LECT NOTES COMPUT SC, V3568, P487
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Datta R., 2005, P ACM SIGMM INT WORK
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FERGUS R, 2005, P INT C COMP VIS
   HOWARTH P, 2004, P INT C IM VID RETR
   JEON J., 2003, P INT ACM SIGIR C RE
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MAREE R, 2005, P IEEE C COMP VIS PA
   Mehrotra S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P632, DOI 10.1109/MMCS.1997.609791
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Smith J.P., 1999, COMPENDIOUS SYRIAC D, P165
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2420, P381
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   VU K, 2001, P SPIE C STOR RETR M, P1
   Wang DM, 1997, PATTERN RECOGN, V30, P2043, DOI 10.1016/S0031-3203(97)00015-0
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WEBER R, 2003, P ACM INT C INF KNOW
NR 31
TC 13
Z9 15
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2009
VL 20
IS 3
BP 167
EP 177
DI 10.1016/j.jvcir.2009.01.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 424VD
UT WOS:000264595500001
OA Green Published
DA 2024-07-18
ER

PT J
AU Chang, CC
   Kieu, TD
   Chou, YC
AF Chang, Chin-Chen
   Kieu, The Duc
   Chou, Yung-Chen
TI Reversible information hiding for VQ indices based on locally adaptive
   coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Image compression; Locally adaptive coding; Steganography;
   VQ compression
ID WATERMARKING ALGORITHM; DIGITAL WATERMARKING; SCHEME
AB Steganography is one of protective methods for secret communications over public networks such as the Internet. This paper proposes a novel reversible information hiding method for vector quantization (VQ) compressed images based on locally adaptive coding method. The proposed stegamographic method embeds a secret message into VQ indices in an index table during the process of compressing the index table in the block-by-block manner. The experimental results show that, in average, the proposed method achieves the best visual quality of reconstructed images and the best embedding rate compared to two related works. In terms of compression rate and encoding execution time, in average, Yang et al.'s method is the best, followed by our proposed method, and then Lin and Chang's method. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Chang, Chin-Chen; Kieu, The Duc] Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
   [Chang, Chin-Chen; Chou, Yung-Chen] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 62102, Taiwan.
C3 Feng Chia University; National Chung Cheng University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Comp Sci & Informat Engn, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM ccc@cs.ccu.edu.tw; ktduc0323@yahoo.com.au; jackjow@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 1997, J VIS COMMUN IMAGE R, V8, P27, DOI 10.1006/jvci.1997.0327
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Cox IJ., 2007, DIGITAL WATERMARKING
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang HC, 2002, IEICE T FUND ELECTR, VE85A, P1719
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Lin Chih Yang, 2006, J COMPUT, V17, P3
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pan JS, 2004, IEICE T FUND ELECTR, VE87A, P1839
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Wu YT, 2007, PATTERN RECOGN, V40, P3753, DOI 10.1016/j.patcog.2007.04.013
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 17
TC 60
Z9 63
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 57
EP 64
DI 10.1016/j.jvcir.2008.08.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700006
DA 2024-07-18
ER

PT J
AU Ouyang, JQ
   Li, JT
   Tang, HR
AF Jian-quan Ouyang
   Li Jin-tao
   Huanrong Tang
TI Interactive key frame selection model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE key frame selection; interactive key frame selection; interactive
   computing; coinduction
ID VIDEO; EXTRACTION; MOTION
AB Video summarization can provide a fine representation of the content of video stream and reduce a large amount of data involved in video indexing, browsing, and retrieval. Moreover, Key frame selection is an important step in the research of content-based video analysis and retrieval. Although there exist a variety of methods for key frame selection, they are heuristic and closed systems, which cannot dynamically generate video summary with user's preference. In this paper, an M-estimator and epipolar line distance constraint camera motion estimation algorithm is introduced as camera parameters is an important motion feature for key frame selection, and Broyden-Fletcher-Goldfarb-Shanno (BFGS) method is applied to optimize estimated parameters. Moreover, since Interactive Computing is a novel-computing model that represents the transition of algorithm to interaction, an interactive model of key frame selection (IKFS) is presented as a result of improving the model of key frame selection (KFS). The model of KFS and lKFS are proved to satisfy the criterion of induction and coinduction, respectively. Experimental results show that the processing scheme generates flexible and desirable summarizations whose distortion rate is lower than current method. Above all, IKFS is an extension to KFS. (C) 2006 Elsevier Inc. All rights reserved.
C1 Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
   Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
C3 Xiangtan University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS
RP Ouyang, JQ (corresponding author), Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
EM oyjq@ict.ac.cn
RI ouyang, jianquan/HTN-9999-2023; ouyang, jian-quan/A-2159-2011
OI ouyang, jianquan/0000-0002-7518-5156; 
CR FENG H, 2005, P 7 ACM SIGMM INT WO, P121
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064
   Ho YH, 2004, IEEE IMAGE PROC, P613
   Lee HC, 2003, SIGNAL PROCESS-IMAGE, V18, P1, DOI 10.1016/S0923-5965(02)00089-9
   LEE S, 2004, P IEEE INT C AC SPEE, V5, P905
   Li Z, 2004, IEEE IMAGE PROC, P617
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Porter SV, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P460, DOI 10.1109/ICIAP.2003.1234093
   Rutten RGM, 2001, ASTR SOC P, V249, P3
   SMOLIC A, 2000, IEEE INT C IM PROC V, P1247
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   Wegner P, 1999, MONIST, V82, P58, DOI 10.5840/monist19998216
   WEGNER P, 1999, MATH MODELS INTERACT, P99
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 15
TC 7
Z9 7
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1145
EP 1163
DI 10.1016/j.jvcir.2006.03.003
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200002
DA 2024-07-18
ER

PT J
AU Huang, PW
   Dai, SK
   Lin, PL
AF Huang, P. W.
   Dai, S. K.
   Lin, P. L.
TI Texture image retrieval and image segmentation using composite sub-band
   gradient vectors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE texture descriptor; CSG vector; image retrieval; image segmentation;
   wavelet decomposition
AB A new texture descriptor, called CSG vector, is proposed for image retrieval and image segmentation in this paper. The descriptor can be generated by composing the gradient vectors obtained from the sub-images through a wavelet decomposition of a texture image. By exercising a database containing 2400 images which were cropped from a set of 150 types of textures selected from the Brodatz Album, we demonstrated that 93% efficacy can be achieved in image retrieval. Moreover, using CSG vectors as the texture descriptor for image segmentation can generate very successful results for both synthesized and natural scene images. (c) 2006 Elsevier Inc. All rights reserved.
C1 Natl Chung Hsing Univ, Dept Comp Sci, Taichung 40227, Taiwan.
   Providence Univ, Dept Comp Sci & Informat Management, Shalu, Taiwan.
C3 National Chung Hsing University; Providence University - Taiwan
RP Huang, PW (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci, Taichung 40227, Taiwan.
EM powhei.huang@msa.hinet.net; lan@pu.edu.tw
CR [Anonymous], PURE APPL MATH
   Ballard D.H., 1982, Computer Vision
   BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3
   BOVIK AC, 1991, IEEE T SIGNAL PROCES, V39, P2025, DOI 10.1109/78.134435
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Fountain SR, 1998, PATTERN RECOGN, V31, P1725, DOI 10.1016/S0031-3203(98)00015-6
   GORKANI M, 1994, TEXTURE ORIENTATION, P459
   Haralick R. M., 1992, COMPUTER ROBOT VISIO, V1
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P195, DOI 10.1109/34.481543
   Kankanhalli MS, 1996, PATTERN RECOGN, V29, P701, DOI 10.1016/0031-3203(95)00097-6
   Manian V, 1998, PATTERN RECOGN, V31, P1937, DOI 10.1016/S0031-3203(98)00053-3
   Stephane G. M., 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466
   Van de Wouwer G, 1999, PATTERN RECOGN, V32, P443, DOI 10.1016/S0031-3203(98)00035-1
NR 15
TC 35
Z9 39
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 947
EP 957
DI 10.1016/j.jvcir.2005.08.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700001
DA 2024-07-18
ER

PT J
AU Chang, HC
   Lai, SH
   Lu, KR
AF Chang, Hung-Chang
   Lai, Shang-Hong
   Lu, Kuang-Rong
TI A robust real-time video stabilization algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video stabilization; optical flow computation; camera motion estimation;
   robust estimation; motion smoothing
ID SEQUENCE STABILIZATION; MOTION
AB The acquisition of digital video usually suffers from undesirable camera jitters due to unstable camera motions. In this paper, we propose a robust real-time video stabilization algorithm that alleviates the undesirable jitter motions from the unstable video to produce a stabilized video. In the proposed algorithm, we first compute the sparse optical flow vectors between successive frames, followed by estimating the camera motion by fitting the computed optical flow vectors to a simplified affine motion model with a robust trimmed least squares method. Then the computed camera motion parameters are smoothed temporally to reduce the motion fluctuations by using a regularization method. Finally, we transform all frames in the video sequence based on the original and smoothed camera motions to obtain a stabilized video. Experimental results are given to demonstrate the stabilization performance and the efficiency of the proposed algorithm. (C) 2005 Elsevier Inc. All rights reserved.
C1 Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30043, Taiwan.
   Ulead Syst Inc, Taipei, Taiwan.
C3 National Tsing Hua University
RP Lai, SH (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30043, Taiwan.
EM lai@cs.nthu.edu.tw
RI Lai, Shang-Hong/AAS-4002-2020
OI Lai, Shang-Hong/0000-0002-5092-993X
CR BOUTHEMY P, 1999, IEEE T CIRCUITS SYST, V9
   Chang JY, 2002, IEEE T CONSUM ELECTR, V48, P108, DOI 10.1109/TCE.2002.1010098
   Duric Z, 1996, REAL-TIME IMAGING, V2, P271, DOI 10.1006/rtim.1996.0029
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Etrurk S., 2002, REAL-TIME IMAGING, V8, P317
   Hansen M., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P54, DOI 10.1109/ACV.1994.341288
   Jin JS, 2001, REAL-TIME IMAGING, V7, P357, DOI 10.1006/rtim.2000.0243
   Kuo JH, 2002, PROC SPIE, V4676, P168
   Lai SH, 2002, PROC SPIE, V4676, P148
   LITVIN A, 2003, IS T SPIE S EL IM IM, P20
   Lucas B. D., 1981, P IJCAI, P674
   Morimoto C, 1996, REAL-TIME IMAGING, V2, P285, DOI 10.1006/rtim.1996.0030
   Nomura A, 2000, IMAGE VISION COMPUT, V18, P939, DOI 10.1016/S0262-8856(99)00081-5
   RATAKONDA K, 1998, P IEEE INT S CIRC SY, V4, P69
NR 14
TC 49
Z9 59
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 659
EP 673
DI 10.1016/j.jvcir.2005.10.004
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300011
DA 2024-07-18
ER

PT J
AU Oh, HR
   Song, H
AF Oh, Hyung Rai
   Song, Hwangjun
TI Scalable proxy caching algorithm minimizing client's buffer size and
   channel bandwidth
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE proxy server; scalable caching; client's buffer size; channel bandwidth
ID VIDEO
AB This paper presents a scalable caching algorithm of proxy server with the finite storage size minimizing client's buffer size and constant-bit-rate channel bandwidth. Under the general video traffic condition, it is observed that the amount of decreased client's buffer size and channel bandwidth after caching a video frame depends on the relative frame position in the time axis as well as the frame size. Based on this fact, we propose an effective caching algorithm to select the cached frames by using the normalized buffer size. Finally, experimental results are provided to show the superior performance of the proposed algorithm. (c) 2005 Elsevier Inc. All rights reserved.
C1 POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Song, H (corresponding author), POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
EM hwangjun@postech.ac.kr
CR Dan A, 1996, P SOC PHOTO-OPT INS, V2667, P344, DOI 10.1117/12.235887
   *ISO IEC, 2001, JTC1SC29WG11 ISOIEC
   *ISO IEC, 1994, 13818 ISOIEC
   *ITU T, 1993, H261 ITUT
   *ITU T, 1998, H263 ITUT
   *JOINT VID TEAM IS, 2003, 1449610 H264ISOIEC I
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   Rizzo L, 2000, IEEE ACM T NETWORK, V8, P158, DOI 10.1109/90.842139
   SEN S, 1999, P IEEE INF 99 NY US
   Shim J, 1999, IEEE T KNOWL DATA EN, V11, P549, DOI 10.1109/69.790804
   Yu F, 2003, IEEE T CIRC SYST VID, V13, P257, DOI 10.1109/TCSVT.2003.809829
   Zhang ZL, 1997, IEEE J SEL AREA COMM, V15, P1148, DOI 10.1109/49.611165
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
NR 13
TC 6
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 57
EP 71
DI 10.1016/j.jvcir.2005.01.003
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900004
DA 2024-07-18
ER

PT J
AU Sandberg, B
   Chan, TF
AF Sandberg, B
   Chan, TF
TI A logic framework for active contours on multi-channel images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE multi-channel; segmentation; logic operations; active contours
AB We propose a mathematical framework for object detection using logic operations as a structure for defining multi-channel segmentation. The model combines object information from the different channels into any logic combination. We consider active contour methods which use one initial contour that would evolve from the information given in each channel simultaneously. Specific models are derived based on the single-channel region based "active contours without edges" [IEEE Trans. Image Process. 10 (2) (2001) 266] model. Numerical experiments show that the method is able to find general intersections, unions, and complements of the regions of objects of both synthetic and realistic images. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA.
C3 University of California System; University of California Los Angeles
RP Univ Calif Los Angeles, Dept Math, 405 Hilgard Ave, Los Angeles, CA 90095 USA.
EM bsand@math.ucla.edu; chan@math.ucla.edu
RI Chan, Tony/IQW-1869-2023; Chan, Tony F/A-4166-2013
OI Chan, Tony F/0000-0001-6196-2068
CR [Anonymous], 2002, SURFACES
   Aubert G., 2001, MATH PROBLEMS IMAGE
   CHAN T, 2002, 0228 CAM
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   DIBOS F, 1997, ACT 16 C GRETSI, P367
   Guichard F, 1998, IEEE T IMAGE PROCESS, V7, P444, DOI 10.1109/83.661194
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PARAGIOS N, 1999, P 7 INT C COMP VIS, P100
   Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Sapiro G., 2001, Geometric Partial Differential Equations and Image Analysis
   TU Z, 2003, P ICCV
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 19
TC 21
Z9 24
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 333
EP 358
DI 10.1016/j.jvcir.2004.08.005
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500006
DA 2024-07-18
ER

PT J
AU Petkovic, M
   Jonker, W
AF Petkovic, M
   Jonker, W
TI Integrated use of different content derivation techniques within a
   multimedia database management system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE content-based video retrieval; multimedia databases; video indexing;
   spatio-temporal event recognition; hidden Markov models; dynamic
   Bayesian networks
AB As amounts of publicly available video data grow, the need to automatically infer semantics from raw video data becomes significant. In this paper, we address the use of three different techniques that support that task, namely, spatio-temporal rule-based method, hidden Markov models, and dynamic Bayesian networks. First, the application of these techniques for detection and recognition of diverse events is briefly described using two case studies (Tennis and Formula 1). We explain the relationships and differences of the three approaches, as well as benefits of their integrated use. Then the focus is moved to the main point of the paper, which is the integration of the aforementioned techniques within a database management system, which provides efficient, flexible, scalable, and domain independent content-based video retrieval. We identify and consider the most important issues when extending a traditional database management system with content-based video retrieval functionality, namely issues concerning video data models, dynamic feature extraction, and extensions of different layers of database architecture. The advantages of the integrated system are demonstrated on examples from our two case studies. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Twente, NL-7500 AE Enschede, Netherlands.
   Philips Res Labs, NL-5656 AA Eindhoven, Netherlands.
C3 University of Twente; Philips; Philips Research
RP Petkovic, M (corresponding author), Univ Twente, POB 217, NL-7500 AE Enschede, Netherlands.
EM milan.petkovic@philips.com; wjonker@cs.utwente.nl
CR Al-Khatib W, 1999, IEEE T KNOWL DATA EN, V11, P64, DOI 10.1109/69.755616
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   *ALT VIS, 2004, ALT VIS VID SEARCH
   [Anonymous], 1995, P IEEE INT C MULT CO
   Boncz P, 1998, PROC INT CONF DATA, P568, DOI 10.1109/ICDE.1998.655820
   BONCZ P, 1995, MONET IMPRESSIONIST
   BOYEN X, 1999, DISCOVERING HIDDEN S, P91
   CHANG HJ, 1996, MULTIMEDIA INFORMATI, P373
   CHRISTIE J, 1996, COMPLETION TNO ABBOT
   DELBIMBO A, 1999, VISUAL INFORMATION R
   EGENHOFER M, 1991, LNCS
   EGENHOFER MJ, 1991, INT J GEOGR INF SYST, V5, P161, DOI 10.1080/02693799108927841
   FORSYTH DA, 1996, P EUR C COMP VIS ECC
   Grosky WI, 1997, COMMUN ACM, V40, P72, DOI 10.1145/265563.265574
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   INTILLE S, 1994, 294 MIT
   JASINSCHI RS, 2001, P IEEE INT C IM PROC
   Koenen Rob., 1999, Overview of the MPEG-4 Standard
   LIU T, 1999, P INT C COMP VIS, P456
   *LYC, 2003, CARN MELL U MUTLR SE
   MICHAELSON S, 1990, HIDDEN MARKOV MODELS
   MIHAJLOVIC V, 2001, TRCTIT0141
   *MPEG REQ GROUP, 2000, JTCISC29WG11 ISOIEC
   *MPEG REQ GROUP, 2000, JTCISC29WG11 ISO IEC
   Mufit Ferman A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P91, DOI 10.1109/ICIP.1999.822861
   NAPHADE M, 2000, P IEEE INT C MULT EX, V1, P475
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   PERTKOVIC M, 2003, THESIS CTR TELEMATES
   PEUQUET DJ, 1987, PATTERN RECOGN, V20, P65, DOI 10.1016/0031-3203(87)90018-5
   PINGALI G, 2000, P IEEE INT C MULT EX, V3, P1433
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   SHAH M., 1997, MOTION BASED RECOGNI
   Sudhir G, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P81, DOI 10.1109/CAIVD.1998.646036
   Syeda-Mahmood T., 2000, Proceedings ACM Multimedia 2000, P85, DOI 10.1145/354384.354433
   VASCONCELOS N, 1998, P IEEE INT C IM PROC, V2, P550
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
NR 36
TC 2
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 303
EP 329
DI 10.1016/j.jvcir.2004.04.001
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100004
OA Green Published
DA 2024-07-18
ER

PT J
AU Gan, XC
   Liew, AWC
   Yan, H
AF Gan, XC
   Liew, AWC
   Yan, H
TI Blocking artifact reduction in compressed images based on edge-adaptive
   quadrangle meshes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image postprocessing; adaptive mesh; projections onto convex sets;
   blocking artifacts; smoothness; constraint set; quantization constraint
   set
ID CODED IMAGES; PROJECTION; RESTORATION; SET
AB During image deblocking, the preservation of visually significant edges in the image is important. Based on the observation that blocking artifact along edge direction is difficult for human perception, a number of existing techniques have proposed to filter the edge pixels with low weight or bypass them altogether to avoid blurring. However, the un-processed artifacts that are anti-parallel to the edge direction often fragment the edges and seriously degrade visual quality. In this paper, by considering the behavior of intensity evolution along and across edges, we propose a new POCS-based algorithm using a new smoothness constraint set. The new constraint set is realized indirectly by limiting the distance between the coded image and the image simulated using edge-adaptive quadrangle meshes. Experimental results indicated that our method compares favorably with several existing techniques. (C) 2003 Elsevier Inc. All rights reserved.
C1 City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
   Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
C3 City University of Hong Kong; University of Sydney
RP Gan, XC (corresponding author), City Univ Hong Kong, Dept Comp Engn & Informat Technol, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
RI Liew, Alan Wee-Chung/F-6988-2011
OI Liew, Alan Wee-Chung/0000-0001-6718-7584; YAN, Hong/0000-0001-9661-3095
CR [Anonymous], VECTOR SPACE PROJECT
   CHEN T, 2000, IEEE T CIRCUIT SYST, V10, P617
   CHITPRASERT B, 1990, IEEE T COMMUN, V38, P1040, DOI 10.1109/26.57501
   Jeong Y, 2000, IEEE T CIRC SYST VID, V10, P617, DOI 10.1109/76.845007
   KIM DS, 1991, IEEE T COMMUN
   Kim SD, 1999, IEEE T CIRC SYST VID, V9, P156, DOI 10.1109/76.744282
   NGAN KN, 1989, IEEE T ACOUST SPEECH, V37, P1743, DOI 10.1109/29.46556
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Park HW, 1999, IEEE T CIRC SYST VID, V9, P161, DOI 10.1109/76.744283
   Park SH, 1999, IEEE T IMAGE PROCESS, V8, P1361, DOI 10.1109/83.791962
   RAMAMURTHI R, 1986, IEEE T COMMUN
   ROSENBERG K, 1992, IFIP TRANS C, V2, P91
   SEZAN MI, 1990, IEEE T ACOUST SPEECH, V38, P181, DOI 10.1109/29.45570
   SEZAN MI, 1991, IEEE T SIGNAL PROCES, V39, P2275, DOI 10.1109/78.91183
   YANG Y, 1993, IEEE T CIRCUITS SYST, V3, P431
   YANG YY, 1995, IEEE T IMAGE PROCESS, V4, P896, DOI 10.1109/83.392332
   Yang YY, 1997, IEEE T IMAGE PROCESS, V6, P1345, DOI 10.1109/83.624945
   ZOU JJ, IN PRESS OPTICAL ENG
NR 18
TC 11
Z9 14
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 492
EP 507
DI 10.1016/S1047-3203(03)00044-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800007
DA 2024-07-18
ER

PT J
AU El-Qawasmeh, E
AF El-Qawasmeh, E
TI A quadtree-based representation technique for indexing and retrieval of
   image databases
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image database; image search; image retrieval; quadtrees; segmentation
AB Currently, several approaches for image indexing based on the quadtrees exist. In this paper, we propose a new organization for image databases combined with the corresponding algorithm for image search by example. The suggested organization uses the quadtrees to splits the database into multi-subsets by adding some extra fields to facilitate the image search. We suggest a centroid partial match algorithm to process the search query. The algorithm selects random points from an image in a circular uniform movement to check for image match. The proposed organization searches a subset of the image database rather than the whole database. It is flexible since the number of subsets in the database is variable. The centroid image algorithm permits the search regardless of the image size. Both the database organization and the centroid algorithm guarantee that the precision and the recall maximum values are achievable. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Jordan Univ Sci & Technol, Dept Informat Syst & Comp Sci, Irbid, Jordan.
C3 Jordan University of Science & Technology
RP El-Qawasmeh, E (corresponding author), Jordan Univ Sci & Technol, Dept Informat Syst & Comp Sci, POB 3030, Irbid, Jordan.
EM eyas@just.edu.jo
CR Aslandogan YA, 1999, IEEE T KNOWL DATA EN, V11, P56, DOI 10.1109/69.755615
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519, DOI 10.1109/TSE.1980.230801
   CHANG SK, 1988, IEEE T SOFTWARE ENG, V14, P681, DOI 10.1109/32.6147
   CHANG SK, 1981, COMPUTER, V14, P13, DOI [10.1109/C-M.1981.220241, 10.1109/C-M.1981.220243]
   Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Goodchild M.F., 1990, NCGIA CORE CURRICULU
   Mahmoud HA, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P213, DOI 10.1109/ICME.2000.869581
   MOSTAFA J, 1996, P 59 ANN C AM SOC IN, P52
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   SCHWEITZER H, 1999, SPECIAL ISSUE CONTEN, V17, P531
   SMITH J, 1977, IEEE WORKSH MULT SIG, P545
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   SRIHARI RK, 1995, COMPUTER, V28, P49, DOI 10.1109/2.410153
   TZOURAMANIS T, 2001, P 8 IEEE INT C IM PR, V2, P733
   WANG Y, 2001, DISTR COMP SYST WORK, P396
NR 19
TC 3
Z9 3
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 340
EP 357
DI 10.1016/S1047-3203(03)00034-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200007
DA 2024-07-18
ER

PT J
AU Balaji, P
   Prusty, MR
AF Balaji, Pranav
   Prusty, Manas Ranjan
TI Multimodal fusion hierarchical self-attention network for dynamic hand
   gesture recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic hand gesture recognition; Multimodal fusion; Cross -attention;
   Transformer; SHREC '17 track dataset
AB Recent improvements in dynamic hand gesture recognition have seen a shift from traditional convolutional architectures to attention-based networks. These attention networks have been proven to outclass CNN + LSTM architectures, showing higher accuracy as well as reduced model parameters. Especially, skeleton-based attention networks have been shown to outperform visual-based networks due to the rich information from skeletonbased hand features. However, there is an opportunity to introduce complementary features from other modalities like RGB, depth, and optical flow images to enhance the recognition capability of skeleton-based networks. This paper aims to explore the addition of a multimodal fusion network to a skeleton-based Hierarchical Self-Attention Network (MF-HAN) and test for increased model effectiveness. Unlike traditional fusion techniques, this fusion network uses features derived from other sources of multimodal data in a reduced feature space using a cross-attention layer. The model outperforms its root model and other state-of-the-art models on the SHREC'17 track dataset, especially in the 28 gestures setting by more than 1 % in gesture classification accuracy. The experimentation was tested on the DHG dataset as well.
C1 [Balaji, Pranav] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
   [Prusty, Manas Ranjan] Vellore Inst Technol, Ctr Cyber Phys Syst, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Prusty, MR (corresponding author), Vellore Inst Technol, Ctr Cyber Phys Syst, Chennai, India.
EM manas.iter144@gmail.com
RI Prusty, Manas Ranjan/O-5706-2017
OI Prusty, Manas Ranjan/0000-0003-2704-505X
FU Vellore Institute of Technol- ogy, Chennai, India
FX I would like to sincerely acknowledge Vellore Institute of Technol- ogy,
   Chennai, India for their amazing support and infrastructure during the
   course of this work. I would also like to thank the School of Com- puter
   Science and Engineering for their support.
CR Abavisani M, 2019, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2019.00126
   Cao ZJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042041
   Chen XH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020239
   Chen Y., 2019, BRIT MACH VISION C
   Chung HY, 2019, IEEE INT CONF INDUST, P853, DOI 10.1109/ICIT.2019.8755038
   D'Eusanio A, 2020, INT CONF 3D VISION, P623, DOI 10.1109/3DV50981.2020.00072
   De Smedt Q., 2017, 3DOR 10 EUR WORKSH 3, P1, DOI DOI 10.2312/3DOR.20171049
   De Smedt Q, 2016, IEEE COMPUT SOC CONF, P1206, DOI 10.1109/CVPRW.2016.153
   Hakim NL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245429
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Hu QH, 2022, LECT NOTES ARTIF INT, V13455, P24, DOI 10.1007/978-3-031-13844-7_3
   Huang JH, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106855
   Huu P.N., 2020, Vietnam J. Sci. Technol., V58, P514
   Jain R, 2022, VISUAL COMPUT, V38, P1957, DOI 10.1007/s00371-021-02259-3
   Li XF, 2023, COMPUT ELECTR ENG, V110, DOI 10.1016/j.compeleceng.2023.108846
   Li Y, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0476-x
   Liu JB, 2021, Arxiv, DOI arXiv:2106.13391
   Liu JB, 2020, PROC CVPR IEEE, P5750, DOI 10.1109/CVPR42600.2020.00579
   Ma Y, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22165959
   Mahmud H, 2021, Arxiv, DOI [arXiv:2107.02543, 10.48550/arXiv.2107.02543, DOI 10.48550/ARXIV.2107.02543]
   Munasinghe MINP, 2018, 2018 3RD INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT)
   Rehman MU, 2022, CMC-COMPUT MATER CON, V70, P4675, DOI 10.32604/cmc.2022.019586
   Roy SK, 2023, IEEE Transactions on Geoscience and Remote Sensing, V61
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma B, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103554
   Verma B, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293421
   Wang K., 2023, Neurocomputing, V560
   Xia Y, 2024, ENG APPL ARTIF INTEL, V127, DOI 10.1016/j.engappai.2023.107210
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   [颜成钢 Yan Chenggang], 2022, [信号处理, Journal of Signal Processing], V38, P1111
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang K, 2018, IEEE IMAGE PROC, P3104, DOI 10.1109/ICIP.2018.8451700
NR 36
TC 2
Z9 2
U1 6
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104019
DI 10.1016/j.jvcir.2023.104019
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EL4E9
UT WOS:001139060600001
DA 2024-07-18
ER

PT J
AU Yang, CX
   He, YN
   Sun, C
   Chen, BK
   Cao, J
   Wang, YT
   Hao, Q
AF Yang, Chenxuan
   He, Yunan
   Sun, Ce
   Chen, Bingkun
   Cao, Jie
   Wang, Yongtian
   Hao, Qun
TI Multi-scale convolutional neural networks and saliency weight maps for
   infrared and visible image fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Infrared and visible images; Image fusion; CNN; Guided filter; Saliency;
   Weight assignment
AB Image fusion is the fusion of multiple images from the same scene to produce a more informative image, and infrared and visible image fusion is an important branch of image fusion. To tackle the issues of diminished luminosity in the infrared target, inconspicuous target features, and blurred texture of the fused image after the fusion of infrared and visible images. This paper introduces a novel effective fusion framework that merges multiscale Convolutional Neural Networks (CNN) with saliency weight maps. First, the method measures the source image features to estimate the initial saliency weight map. Then, the initial weight map is segmented and optimized using a guided filter before being further processed by CNN. Next, a trained Siamese convolutional network is used to solve the two key problems of activity measure and weight assignment. Meanwhile, a multilayer fusion strategy is designed to effectively retain the luminance of the infrared target and the texture information in the visible background. Finally, adaptive adjustment of the fusion coefficients is achieved by employing saliency. The experimental results show that the method outperforms the state-of-the-art algorithms in terms of both subjective visual quality and objective evaluation effects.
C1 [Yang, Chenxuan; Chen, Bingkun; Cao, Jie; Wang, Yongtian; Hao, Qun] Beijing Inst Technol, Sch Opt & Photon, Beijing 100081, Peoples R China.
   [He, Yunan] Beijing Inst Technol, Sch Mechatron Engn, Beijing 100081, Peoples R China.
   [Sun, Ce] Chinese Acad Sci, Xi An Inst Opt & Precis Mech, Xian 710119, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology;
   Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS
RP Cao, J; Wang, YT (corresponding author), Beijing Inst Technol, Sch Opt & Photon, Beijing 100081, Peoples R China.
EM ajieanyyn@163.com; wyt@bit.edu.cn
OI Yang, Chenxuan/0000-0001-8695-1322
CR Aghamaleki JA, 2023, VISUAL COMPUT, V39, P1181, DOI 10.1007/s00371-021-02396-9
   An L, 2021, NEUROCOMPUTING, V437, P274, DOI 10.1016/j.neucom.2021.01.047
   Bhatnagar G, 2019, IEEE-CAA J AUTOMATIC, V6, P220, DOI 10.1109/JAS.2018.7511102
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   Hu JW, 2012, INFORM FUSION, V13, P196, DOI 10.1016/j.inffus.2011.01.002
   Li GF, 2021, INFORM FUSION, V71, P109, DOI 10.1016/j.inffus.2021.02.008
   Li HF, 2016, INFORM SCIENCES, V349, P25, DOI 10.1016/j.ins.2016.02.030
   Liu CH, 2017, INFRARED PHYS TECHN, V83, P94, DOI 10.1016/j.infrared.2017.04.018
   Liu LL, 2021, NEUROCOMPUTING, V460, P50, DOI 10.1016/j.neucom.2021.05.034
   Liu YC, 2021, INFRARED PHYS TECHN, V118, DOI 10.1016/j.infrared.2021.103916
   Liu YC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204556
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Lu T, 2024, IEEE T NEUR NET LEAR, V35, P3938, DOI 10.1109/TNNLS.2022.3201448
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Mo Y, 2021, INFORM FUSION, V75, P41, DOI 10.1016/j.inffus.2021.04.005
   Mustafa HT, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165409
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qi B, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020283
   Sappa AD, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060861
   Selvaraj A, 2020, IET IMAGE PROCESS, V14, P4210, DOI 10.1049/iet-ipr.2020.0781
   Toet A, 2017, DATA BRIEF, V15, P249, DOI 10.1016/j.dib.2017.09.038
   Wang JM, 2024, INFORM FUSION, V101, DOI 10.1016/j.inffus.2023.101980
   Wang JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090585
   Xing CD, 2020, NEUROCOMPUTING, V402, P437, DOI 10.1016/j.neucom.2020.04.002
   Yan H, 2020, ISA T, V107, P160, DOI 10.1016/j.isatra.2020.07.040
   Yan L, 2020, IEEE ACCESS, V8, P59976, DOI 10.1109/ACCESS.2020.2982712
   Yin WX, 2022, INFRARED PHYS TECHN, V121, DOI 10.1016/j.infrared.2022.104041
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Yuan YH, 2011, OPT ENG, V50, DOI 10.1117/1.3549928
   Zhang Q, 2012, SIGNAL PROCESS, V92, P912, DOI 10.1016/j.sigpro.2011.10.004
   Zhang XC, 2020, INFORM FUSION, V63, P166, DOI 10.1016/j.inffus.2020.05.002
   Zhao C, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.102976
   Zhao F, 2021, INFORM FUSION, V76, P189, DOI 10.1016/j.inffus.2021.06.002
   Zhou T, 2020, IEEE T MED IMAGING, V39, P2772, DOI 10.1109/TMI.2020.2975344
NR 35
TC 2
Z9 2
U1 12
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104015
DI 10.1016/j.jvcir.2023.104015
EA DEC 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IC4O5
UT WOS:001164113200001
DA 2024-07-18
ER

PT J
AU Hettiarachchi, D
   Tian, Y
   Yu, H
   Kamijo, S
AF Hettiarachchi, Dulmini
   Tian, Ye
   Yu, Han
   Kamijo, Shunsuke
TI Depth as attention to learn image representations for visual
   localization, using monocular images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Visual localization; Image representation; Depth
   attention; Global descriptors
AB Image retrieval algorithms are widely used in visual localization tasks. In visual localization, we can benefit from retrieving the images depicting same landmark taken from a pose similar to the query. However, state-of-the-art image retrieval algorithms are optimized mainly for landmark retrieval, and do not take camera pose into account. To address this limitation, we propose novel Depth Attention Network (DeAttNet). DeAttNet leverages both visual and depth information in learning a global image representation. Depth varies for similar features captured from different camera poses. Based on this insight, we employ depth within an attention mechanism to discern and emphasize the salient regions. In our method, we utilize monocular depth estimation algorithms to render depth maps. Compared to RGB only image descriptors, significant improvements are obtained with the proposed method on Mapillary Street Level Sequences, Pittsburgh and Cambridge Landmark datasets.
C1 [Hettiarachchi, Dulmini; Tian, Ye] Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Tokyo 1130033, Japan.
   [Yu, Han] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1130033, Japan.
   [Kamijo, Shunsuke] Univ Tokyo, Inst Ind Sci IIS, Tokyo 1538505, Japan.
C3 University of Tokyo; University of Tokyo; University of Tokyo
RP Hettiarachchi, D (corresponding author), Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Tokyo 1130033, Japan.
EM dulmini@kmj.iis.u-tokyo.ac.jp
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Ayesha S, 2020, INFORM FUSION, V59, P44, DOI 10.1016/j.inffus.2020.01.005
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Balntas V., 2016, Bmvc, DOI DOI 10.5244/C.30.119
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhat SF, 2023, Arxiv, DOI [arXiv:2302.12288, 10.48550/arXiv.2302.12288]
   Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Bingyi Cao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P726, DOI 10.1007/978-3-030-58565-5_43
   Chen YX, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3255302
   Cinaroglu I, 2022, ENG SCI TECHNOL, V35, DOI 10.1016/j.jestch.2022.101098
   Couturier A, 2021, ROBOT AUTON SYST, V135, DOI 10.1016/j.robot.2020.103666
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Du M, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P2822, DOI 10.1145/3534678.3539071
   Ge Yixiao, 2020, EUR C COMP VIS
   Germain H, 2019, Arxiv, DOI arXiv:1812.03707
   Germain H, 2019, INT CONF 3D VISION, P513, DOI 10.1109/3DV.2019.00063
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Hausler S, 2021, PROC CVPR IEEE, P14136, DOI 10.1109/CVPR46437.2021.01392
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Humenberger M, 2022, INT J COMPUT VISION, V130, P1811, DOI 10.1007/s11263-022-01615-7
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Liu L, 2019, IEEE I CONF COMP VIS, P2570, DOI 10.1109/ICCV.2019.00266
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Ming Y, 2021, NEUROCOMPUTING, V438, P14, DOI 10.1016/j.neucom.2020.12.089
   Ning H., 2021, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V60, P1, DOI [DOI 10.1109/TGRS.2021.3060705, 10.1109/TGRS.2021.3060705]
   Ning HL, 2022, IEEE T MULTIMEDIA, V24, P1763, DOI 10.1109/TMM.2021.3071243
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Paszke A, 2019, ADV NEUR IN, V32
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Piasco N., 2019, BRIT MACH VIS C BMVC
   Piasco N, 2019, IEEE IMAGE PROC, P2561, DOI [10.1109/icip.2019.8803014, 10.1109/ICIP.2019.8803014]
   Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013
   Pion N, 2020, INT CONF 3D VISION, P483, DOI 10.1109/3DV50981.2020.00058
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300
   Seymour Z, 2019, Arxiv, DOI arXiv:1812.03402
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752
   Toft C, 2022, IEEE T PATTERN ANAL, V44, P2074, DOI 10.1109/TPAMI.2020.3032010
   Torii A, 2021, IEEE T PATTERN ANAL, V43, P814, DOI 10.1109/TPAMI.2019.2941876
   Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119
   Uppal H, 2021, INT C PATT RECOG, P10120, DOI 10.1109/ICPR48806.2021.9412514
   Uppal H, 2021, IEEE T INF FOREN SEC, V16, P2461, DOI 10.1109/TIFS.2021.3053458
   Warburg F, 2020, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR42600.2020.00270
   Yu X, 2018, IEEE INT C INT ROBOT, P3196, DOI 10.1109/IROS.2018.8594358
   Zheng XT, 2022, IEEE T IMAGE PROCESS, V31, P6951, DOI 10.1109/TIP.2022.3217697
NR 52
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104012
DI 10.1016/j.jvcir.2023.104012
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DW7N9
UT WOS:001135186400001
DA 2024-07-18
ER

PT J
AU Pang, XY
   Tian, X
   Nie, XS
   Yin, YL
   Jiang, GW
AF Pang, Xiyu
   Tian, Xin
   Nie, Xiushan
   Yin, Yilong
   Jiang, Gangwu
TI Vehicle re-identification based on grouping aggregation attention and
   cross-part interaction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vehicle re-identification; Grouping aggregation attention; Cross-part
   interaction
AB Vehicle re-identification (Re-ID) plays an important role in intelligent transportation systems. To solve the key problem of small inter-class difference, we propose a vehicle Re-ID network based on grouping aggregation attention and cross-part interaction (GACP), which uses a channel context local interaction attention block (CCLI) and a cross-part interaction module (CPIM) to extract global and local discriminative features, respectively. The CCLI constructs the context information of each channel and performs local interaction to realize the communication of local and long-range information, thus effectively infer the weights of channels. In addition, the CCLI further reduces the number of parameters and improves the attention effect through a grouping aggregation module and an attention enhancement constraint. The CPIM enhances the correlation between vehicle parts obtained by rigid segmentation on feature maps to mine robust local information. Extensive experiments on two popular datasets VeRi776 and VehicleID demonstrate the effectiveness of the proposed method.
C1 [Pang, Xiyu; Yin, Yilong] Shandong Univ, Sch Software, 1500 Shunhua Rd, Jinan 250101, Shan Dong, Peoples R China.
   [Pang, Xiyu; Tian, Xin; Jiang, Gangwu] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, 5001 Haitang Rd, Jinan 250357, Peoples R China.
   [Nie, Xiushan] Shandong Jianzhu Univ, Sch Comp Sci & Technol, 1000 Fengming Rd, Jinan 250101, Shan Dong, Peoples R China.
C3 Shandong University; Shandong Jiaotong University; Shandong Jianzhu
   University
RP Yin, YL (corresponding author), Shandong Univ, Sch Software, 1500 Shunhua Rd, Jinan 250101, Shan Dong, Peoples R China.
EM xiyupang@126.com; tianxin_5076@163.com; niexsh@hotmail.com;
   ylyin@sdu.edu.cn; wuge2693080@126.com
RI jiang, gang/KII-8233-2024; pang, xiyu/JRX-8219-2023
OI pang, xiyu/0000-0001-7987-6782
FU National Natural Science Foundation of China [62176139, 61876098]; Major
   Basic Research Project of the Natural Science Foundation of Shandong
   Province, China [ZR2021ZD15]
FX <B>Acknowledgements</B> This work is jointly supported by the National
   Natural Science Foundation of China (62176139 and 61876098) , and by the
   Major Basic Research Project of the Natural Science Foundation of
   Shandong Province, China (ZR2021ZD15) .
CR Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen M, 2020, PR MACH LEARN RES, V119
   Chen X, 2021, IEEE T INTELL TRANSP, V22, P1276, DOI 10.1109/TITS.2020.2968517
   Chen YB, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103432
   Dai J., 2021, ICLR
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fu XP, 2022, ENG APPL ARTIF INTEL, V107, DOI 10.1016/j.engappai.2021.104540
   Gao CY, 2020, IEEE COMPUT SOC CONF, P2520, DOI 10.1109/CVPRW50498.2020.00303
   Guo HY, 2019, IEEE T IMAGE PROCESS, V28, P4328, DOI 10.1109/TIP.2019.2910408
   He B, 2019, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2019.00412
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hu H, 2019, IEEE I CONF COMP VIS, P3463, DOI 10.1109/ICCV.2019.00356
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Jain V, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010052
   Jing YC, 2022, LECT NOTES COMPUT SC, V13667, P111, DOI 10.1007/978-3-031-20071-7_7
   Jing YC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5281, DOI 10.1109/ICCV48922.2021.00525
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing Yongcheng, 2023, CoRR abs/2304.14593
   Khorramshahi Pirazh, 2019, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SY, 2021, ACTA OTO-LARYNGOL, V141, P495, DOI 10.1080/00016489.2021.1880632
   Li HD, 2023, APPL INTELL, V53, P186, DOI 10.1007/s10489-022-03420-8
   Li K, 2022, IEEE T NEUR NET LEAR, V33, P826, DOI 10.1109/TNNLS.2020.3029299
   Li YD, 2022, IEEE T INTELL TRANSP, V23, P1381, DOI 10.1109/TITS.2020.3025387
   Lian JW, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071016
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu K, 2020, IEEE COMPUT SOC CONF, P2494, DOI 10.1109/CVPRW50498.2020.00300
   Liu Songhua, 2022, NEURIPS
   Liu W, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1618, DOI 10.1145/3123266.3123422
   Liu XB, 2018, IEEE INT CON MULTI
   Liu XC, 2016, IEEE INT CON MULTI
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Lou YH, 2019, IEEE T IMAGE PROCESS, V28, P3794, DOI 10.1109/TIP.2019.2902112
   Meng DC, 2020, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR42600.2020.00713
   Peng JJ, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103207
   Qian W, 2022, LECT NOTES COMPUT SC, V13674, P336, DOI 10.1007/978-3-031-19781-9_20
   Qian W, 2022, NEUROCOMPUTING, V480, P89, DOI 10.1016/j.neucom.2022.01.043
   Ramachandran P, 2019, Arxiv, DOI arXiv:1906.05909
   Saghafi M. A., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P404, DOI 10.1109/CSPA.2012.6194758
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen F, 2023, IEEE T IMAGE PROCESS, V32, P1039, DOI 10.1109/TIP.2023.3238642
   Spanhel J, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Sun Z., 2020, Rethinking Transformer-based Set Prediction for Object Detection
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsai-Shien Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P330, DOI 10.1007/978-3-030-58536-5_20
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang HB, 2021, NEUROCOMPUTING, V438, P55, DOI 10.1016/j.neucom.2020.06.148
   Wang HY, 2021, PROC CVPR IEEE, P5459, DOI 10.1109/CVPR46437.2021.00542
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang Xingyi, 2022, NeurIPS
   Yuan L, 2021, Arxiv, DOI arXiv:2101.11986
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhu K, 2024, Arxiv, DOI arXiv:2104.00921
NR 64
TC 1
Z9 1
U1 7
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103937
DI 10.1016/j.jvcir.2023.103937
EA SEP 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA U3VA1
UT WOS:001084094600001
DA 2024-07-18
ER

PT J
AU Singh, D
   Mathew, J
   Agarwal, M
   Govind, M
AF Singh, Divya
   Mathew, Jimson
   Agarwal, Mayank
   Govind, Mahesh
TI Indoor dataset for Person Re-Identification: Exploring the impact of
   backpacks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person Re-Identification; WB; WoB; Dataset; PRid dataset; Bag; Knapsack
AB Person Re-Identification (PR-Id) encounters misclassification issues when re-identifying persons with different backpacks. These bags manifest as large and distinct regions in the images surpassing other finer details of a person. As a result, a CNN model swiftly detects and prioritizes these image regions for re-identification. However, the bags are subject to alterations or may be similar among multiple persons, resulting in misclassification. To ensure that a CNN model does not consider bags as unique features of specific persons and prioritize them for re-identification, images of persons with diverse backpacks are crucial in the training dataset. Moreover, these images enhance the model's focus on other unique regions of a person. Although the current datasets show potential, incorporating such images could enhance their effectiveness. Therefore, in this paper, we propose an indoor PR-Id dataset named "With Bag/Without Bag-ReID"(WB/WoB-ReID). The set "with_bag"in WB/WoB-ReID dataset includes identities with different backpacks for the first time. We also incorporate identities without bags and with varying numbers of image counts in three other sets, namely "without_bag", "both_small,"and "both_large". We assess WB/WoB-ReID and three other PR-Id datasets: Market1501, CUHK03, and DukeMTMC-reID on various existing approaches. The highest mAP achieved on the"with_bag"is 74%, "without_bag"is 96.7% and other datasets are 97.78%, 95.20% and 92.4%. The results show that incorporating identities with diverse bags reduces the mAP, highlighting the misclassifications that arise specifically in the presence of bags.
C1 [Singh, Divya; Mathew, Jimson; Agarwal, Mayank] IITP, Bihta Campus, Patna 801103, India.
   [Govind, Mahesh] Digiledge, Bangalore 560102, Karnataka, India.
RP Singh, D (corresponding author), IITP, Bihta Campus, Patna 801103, India.
EM divya_1921cs21@iitp.ac.in; jimson@iitp.ac.in; mayank265@iitp.ac.in
FU CII-SERB Prime Minister's Fellowship for Doctoral Research
FX This work is supported by CII-SERB Prime Minister's Fellowship for
   Doctoral Research.
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   Li HF, 2021, IEEE T INF FOREN SEC, V16, P1480, DOI 10.1109/TIFS.2020.3036800
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao SC, 2014, Arxiv, DOI arXiv:1408.0872
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mansouri N, 2021, NEURAL COMPUT APPL, V33, P12827, DOI 10.1007/s00521-021-05936-5
   Peng J., 2023, IEEE Trans. Circuits Syst. Video Technol.
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma C, 2021, Arxiv, DOI arXiv:2106.03720
   Wang HB, 2020, IEEE MULTIMEDIA, V27, P112, DOI 10.1109/MMUL.2020.2999464
   Wieczorek M., 2021, INT C NEUR INF PROC, P212
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
NR 20
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103931
DI 10.1016/j.jvcir.2023.103931
EA AUG 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S8VL6
UT WOS:001073889700001
DA 2024-07-18
ER

PT J
AU Muhammed, A
   Pais, AR
AF Muhammed, Ajnas
   Pais, Alwyn Roshan
TI A secure fingerprint template generation mechanism using visual secret
   sharing with inverse halftoning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fingerprint template protection; Visual secret sharing; Minutiae;
   Security; Super-resolution; Inverse halftoning
ID CANCELABLE BIOMETRICS; IMAGE; CRYPTOGRAPHY; DESIGN
AB Fingerprints are the most popular and widely practiced biometric trait for human recognition and au-thentication. Due to the wide approval, reliable fingerprint template generation and secure saving of the generated templates are highly vital. Since fingers are permanently connected to the human body, loss of fingerprint data is irreversible. Cancelable fingerprint templates are used to overcome this problem. This paper introduces a novel cancelable fingerprint template generation mechanism using Visual Secret Sharing (VSS), data embedding, inverse halftoning, and super-resolution. During the fingerprint template generation, VSS shares with some hidden information are formulated as the secure cancelable template. Before authentication, the secret fingerprint image is reconstructed back from the VSS shares. The experimental results show that the proposed cancelable templates are simple, secure, and fulfill all the properties of the ideal cancelable templates, such as security, accuracy, non-invertibility, diversity, and revocability. The experimental analysis shows that the reconstructed fingerprint images are similar to the original fingerprints in terms of visual parameters and matching error rates.
C1 [Muhammed, Ajnas; Pais, Alwyn Roshan] Natl Inst Technol Karnataka Surathkal, Informat Secur Res Lab, Mangaluru, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Muhammed, A (corresponding author), Natl Inst Technol Karnataka Surathkal, Informat Secur Res Lab, Mangaluru, Karnataka, India.
EM ajnas.177co001@nitk.edu.in; alwyn@nitk.edu.in
RI Muhammed, Ajnas/KJM-6673-2024
OI Muhammed, Ajnas/0000-0003-0068-6885
CR Abou Elazm LA, 2020, MULTIMED TOOLS APPL, V79, P14053, DOI 10.1007/s11042-019-08462-8
   Ahmad T., 2015, 2015 7 INT C SOFT CO, P84
   Ahmad T, 2011, IEEE IND ELEC
   Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   Ali SS, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104004
   [Anonymous], 2012, 2 INT C CONVERGENCE
   [Anonymous], 2012, INT J EMERG TECHNOL
   [Anonymous], 2013, 2013 INT C INFORMATI
   Bhatega A, 2014, 2014 6th IEEE Power India International Conference (PIICON)
   Cappelli R., 2007, Biom. Technol. Today, V15, P7, DOI DOI 10.1016/S0969-4765(07)70140-6
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chandra E., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P15, DOI 10.1109/ICECTECH.2011.5941948
   Chen T.-H., 2016, IMAGE COMMUN, V44, P101
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chin CS, 2006, COMPUT VIS IMAGE UND, V102, P169, DOI 10.1016/j.cviu.2006.01.002
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   Dwivedi R, 2018, Arxiv, DOI arXiv:1805.10853
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Gayathri M, 2021, PATTERN RECOGN LETT, V152, P1, DOI 10.1016/j.patrec.2021.09.016
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Jain A.K., 2013, Security and Privacy in Biometrics, P187
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Kim J, 2018, INT C PATT RECOG, P3108, DOI 10.1109/ICPR.2018.8545565
   Lee CH, 2007, IEEE T SYST MAN CY B, V37, P980, DOI 10.1109/TSMCB.2007.896999
   Lee C, 2010, J NETW COMPUT APPL, V33, P236, DOI 10.1016/j.jnca.2009.12.011
   Liu E, 2011, ELECTRON LETT, V47, P98, DOI 10.1049/el.2010.2964
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Mohan J, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103355
   Monoth T, 2010, PROCEDIA COMPUT SCI, V2, P143, DOI 10.1016/j.procs.2010.11.018
   Moon D, 2014, SECUR COMMUN NETW, V7, P1543, DOI 10.1002/sec.788
   Muhammed A, 2021, MULTIMED TOOLS APPL, V80, P10255, DOI 10.1007/s11042-020-10095-1
   Mukesh R., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P16
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Rachapalli D.R., 2017, 2017 2 INT C ELECT C, P1
   Raja KB, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2098, DOI 10.23919/ICIF.2018.8455809
   Ram Mamatha, 2020, 2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS), P214, DOI 10.1109/ICIIS51140.2020.9342740
   Rao YV Subba., 2008, TENCON 2008-2008 IEEE Region 10 Conference, P1
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ren L., ADV MULTIMED, V2022
   Ren LJ, 2022, MICROPROCESS MICROSY, V91, DOI 10.1016/j.micpro.2022.104540
   Revenkar PS, 2010, Arxiv, DOI arXiv:1004.1748
   Rivandi Pranoko, 2019, E3S Web of Conferences, V130, DOI 10.1051/e3sconf/201913001022
   Ross A., 2010, BIOMETRIC TECHNOLOGY, V7667
   Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018
   Sandhya M, 2018, PATTERN ANAL APPL, V21, P397, DOI 10.1007/s10044-016-0584-5
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Sandhya M, 2015, INT CONF BIOMETR, P386, DOI 10.1109/ICB.2015.7139100
   Sarkar A., 2018, 2018 4 INT C REC ADV, P1
   Shahzad M, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107735
   Shivani S, 2018, PATTERN ANAL APPL, V21, P139, DOI 10.1007/s10044-016-0571-x
   Son CH, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107591
   Tee C., 2009, TENCON 2009 2009 IEE, P1
   Tran Q.N., 2021, IEEE T INF FORENSICS
   VeriFinger S., 2010, NEURO TECHNOLOGY
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang S, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1682, DOI 10.1109/CISP.2013.6743947
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Wang S, 2012, PATTERN RECOGN, V45, P4129, DOI 10.1016/j.patcog.2012.05.004
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wong WJ, 2013, J CENT SOUTH UNIV, V20, P1292, DOI 10.1007/s11771-013-1614-8
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yang W., 2013, CYBERSPACE SAFETY SE, P81, DOI DOI 10.1007/978-3-319-03584-0_7
   Yang WC, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102704
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zhang N., 2013, BIOMETRICS THEORY AP, P1
NR 75
TC 3
Z9 3
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103854
DI 10.1016/j.jvcir.2023.103854
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K3JN2
UT WOS:001015434900001
DA 2024-07-18
ER

PT J
AU Dai, Y
   Song, WW
   Gao, Z
   Fang, LY
AF Dai, Yong
   Song, Weiwei
   Gao, Zhi
   Fang, Leyuan
TI Global-guided weakly-supervised learning for multi-label image
   classification*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Global correlation Feature disentanglement Label-related regions
   Weakly-supervised learning Multi-label classification
AB Multi-label classification with region-free labels is attracting increasing attention compared to that with region-based labels due to the time-consuming manual region-labeling process. Existing methods usually employ attention-based technology to discover the conspicuous label-related regions in a weakly-supervised manner with only image-level region-free labels, while the region covering is not precise without exploring global clues of multi-level features. To address this issue, a novel Global-guided Weakly-Supervised Learning (GWSL) method for multi-label classification is proposed. The GWSL first extracts the multi-level features to estimate their global correlation map which is further utilized to guide feature disentanglement in the proposed Feature Disentanglement and Localization (FDL) networks. Specifically, the FDL networks then adaptively combine the different correlated features and localize the fine-grained features for identifying multiple labels. The proposed method is optimized in an end-to-end manner under weakly supervision with only image-level labels. Experimental results demonstrate that the proposed method outperforms the state-of-the-arts for multi-label learning problems on several publicly available image datasets. To facilitate similar researches in the future, the codes are directly available online at https://github.com/Yong-DAI/GWSL.
C1 [Dai, Yong; Song, Weiwei; Fang, Leyuan] Peng Cheng Lab, Shenzhen 518000, Peoples R China.
   [Gao, Zhi] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Fang, Leyuan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
C3 Peng Cheng Laboratory; Wuhan University; Hunan University
RP Song, WW (corresponding author), Peng Cheng Lab, Shenzhen 518000, Peoples R China.
EM chd-dy@foxmail.com; weiweisong415@gmail.com; gaozhinus@whu.edu.cn;
   fangleyuan@gmail.com
RI Song, Weiwei/X-6247-2019; Fang, Leyuan/G-1468-2011
OI Song, Weiwei/0000-0001-5089-4127
CR Cheng WW, 2009, MACH LEARN, V76, P211, DOI 10.1007/s10994-009-5127-5
   Dai Y, 2022, NEUROCOMPUTING, V511, P353, DOI 10.1016/j.neucom.2022.09.007
   Dai Y, 2021, NEUROCOMPUTING, V447, P307, DOI 10.1016/j.neucom.2021.03.067
   Dai Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.007
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gibaja E, 2014, WIRES DATA MIN KNOWL, V4, P411, DOI 10.1002/widm.1139
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hassanin M, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103448
   Hu HX, 2016, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2016.323
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jie Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13052, DOI 10.1109/CVPR42600.2020.01307
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Li DW, 2018, IEEE INT CON MULTI
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41
   Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199
   Liu PZ, 2018, Arxiv, DOI arXiv:1808.09102
   Liu WW, 2015, AAAI CONF ARTIF INTE, P2800
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu XH, 2021, Arxiv, DOI arXiv:2103.04337
   Luaces O, 2012, PROG ARTIF INTELL, V1, P303, DOI 10.1007/s13748-012-0030-x
   Madjarov G, 2012, PATTERN RECOGN, V45, P3084, DOI 10.1016/j.patcog.2012.03.004
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Ren Z, 2015, Arxiv, DOI arXiv:1512.06963
   Rokach L, 2014, EXPERT SYST APPL, V41, P7507, DOI 10.1016/j.eswa.2014.06.015
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarafianos N, 2018, LECT NOTES COMPUT SC, V11215, P708, DOI 10.1007/978-3-030-01252-6_42
   Sarfraz M.S., 2017, P BRIT MACH VIS C BM, P1
   Song WW, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3143571
   Song WW, 2021, IEEE T GEOSCI REMOTE, V59, P9661, DOI 10.1109/TGRS.2020.3035676
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Tang CF, 2019, IEEE I CONF COMP VIS, P4996, DOI 10.1109/ICCV.2019.00510
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Tsoumakas G, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P667, DOI 10.1007/978-0-387-09823-4_34
   Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang JL, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9178-8
   Wang X., 2017, IMAGE VISION COMPUT
   Wang X, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P464
   Wei YC, 2014, Arxiv, DOI arXiv:1406.5726
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Yang H, 2016, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2016.37
   Yeh CK, 2017, AAAI CONF ARTIF INTE, P2838
   Zhang JJ, 2015, NEUROCOMPUTING, V154, P305, DOI 10.1016/j.neucom.2014.11.062
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhao X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3177
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
NR 54
TC 3
Z9 3
U1 5
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103823
DI 10.1016/j.jvcir.2023.103823
EA APR 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F6DG3
UT WOS:000983223600001
DA 2024-07-18
ER

PT J
AU Hao, LB
   Yang, XF
   Xu, K
   Yi, WT
   Shen, Y
   Wang, HM
AF Hao, Linbo
   Yang, Xuefeng
   Xu, Ke
   Yi, Wentao
   Shen, Ying
   Wang, Huaming
TI Rotational Voxels Statistics Histogram for both real-valued and binary
   feature representations of 3D local shape
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D local feature descriptor; Point cloud; 3D multi-pose processing
   mechanism; Binary extension
ID OBJECT RECOGNITION; DESCRIPTOR; EFFICIENT
AB 3D Local feature description is an active and fundamental task in 3D computer vision. However, most of the existing descriptors fail to simultaneously achieve satisfactory performance among descriptiveness, robustness, efficiency, and compactness. To address these limitations, we first propose a real-valued descriptor named Rotational Voxels Statistics Histogram (RoVo), which exploits the novel 3D multi-pose processing mechanism proposed in this paper to calculate the 3D voxel density distribution in different 3D poses. Moreover, through well-designed binary encoding algorithms, we conduct the seamless extension of the real-valued RoVo descriptor to three binary representations that have different performance characteristics. Extensive evaluation experiments validate the superiority of the real-valued and three binary RoVo descriptors concerning descriptiveness, robustness, and efficiency. Furthermore, the three binary RoVo descriptors extend the performance of high compactness. Lastly, we perform the experiments of 3D scene registration and 3D object recognition to intuitively present the effectiveness of the four proposed RoVo descriptors.
C1 [Hao, Linbo; Yang, Xuefeng; Xu, Ke; Yi, Wentao; Shen, Ying; Wang, Huaming] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing, Peoples R China.
   [Wang, Huaming] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics
RP Wang, HM (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China.
EM lb_hao@nuaa.edu.cn; yangxuefeng0309@nuaa.edu.cn;
   xuke_zhejiang@nuaa.edu.cn; WentaoYI@nuaa.edu.cn; shenying@nuaa.edu.cn;
   hmwang@nuaa.edu.cn
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Aldoma A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P585, DOI 10.1109/ICCVW.2011.6130296
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Domenech JF, 2020, IEEE ACCESS, V8, P161958, DOI 10.1109/ACCESS.2020.3021455
   Dong Z, 2017, ISPRS J PHOTOGRAMM, V130, P431, DOI 10.1016/j.isprsjprs.2017.06.012
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Han XF, 2021, MULTIMED TOOLS APPL, V80, P26121, DOI 10.1007/s11042-021-10794-3
   Hao L., 2021, IMAGE VISION COMPUT
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Petrelli A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P403, DOI 10.1109/3DIMPVT.2012.51
   Petrelli A, 2011, IEEE I CONF COMP VIS, P2244, DOI 10.1109/ICCV.2011.6126503
   Prakhya SM, 2017, AUTON ROBOT, V41, P1501, DOI 10.1007/s10514-016-9612-y
   Quan SW, 2020, IEEE T GEOSCI REMOTE, V58, P7380, DOI 10.1109/TGRS.2020.2982221
   Quan SW, 2018, INFORM SCIENCES, V444, P153, DOI 10.1016/j.ins.2018.02.070
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Lima JPSD, 2016, SIBGRAPI, P56, DOI [10.1109/SIBGRAPI.2016.017, 10.1109/SIBGRAPI.2016.16]
   Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sun TC, 2020, INFORM SCIENCES, V520, P209, DOI 10.1016/j.ins.2020.02.004
   Tao WY, 2021, IEEE T GEOSCI REMOTE, V59, P801, DOI 10.1109/TGRS.2020.2998683
   Tombari Federico, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P349, DOI 10.1109/PSIVT.2010.65
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   van Blokland BI, 2021, COMPUT GRAPH-UK, V100, P32, DOI 10.1016/j.cag.2021.07.018
   van Blokland BI, 2020, COMPUT GRAPH-UK, V92, P55, DOI 10.1016/j.cag.2020.09.001
   Yang J., 2021, IEEE Transactions on Geoscience and Remote Sensing, V60, P1
   Yang J., 2022, Vis. Comput, P1
   Yang JQ, 2017, COMPUT VIS IMAGE UND, V160, P133, DOI 10.1016/j.cviu.2017.02.004
   Yang JQ, 2017, PATTERN RECOGN, V65, P175, DOI 10.1016/j.patcog.2016.11.019
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Yue XF, 2022, APPL INTELL, V52, P12569, DOI 10.1007/s10489-022-03201-3
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang YH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107691
   Zou Y, 2018, PATTERN RECOGN, V76, P522, DOI 10.1016/j.patcog.2017.11.029
NR 45
TC 3
Z9 3
U1 5
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103817
DI 10.1016/j.jvcir.2023.103817
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M0MT8
UT WOS:001027150100001
DA 2024-07-18
ER

PT J
AU Li, RW
   Mai, ZD
   Zhang, ZB
   Jang, J
   Sanner, S
AF Li, Ruiwen
   Mai, Zheda
   Zhang, Zhibo
   Jang, Jongseong
   Sanner, Scott
TI TransCAM: Transformer attention-based CAM refinement for Weakly
   supervised semantic segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised learning; Semantic segmentation; Vision transformer
AB Weakly supervised semantic segmentation (WSSS) with only image-level supervision is a challenging task. Most existing methods exploit Class Activation Maps (CAM) to generate pixel-level pseudo labels for supervised training. However, due to the local receptive field of Convolution Neural Networks (CNN), CAM applied to CNNs often suffers from partial activation - highlighting the most discriminative part instead of the entire object area. In order to capture both local features and global representations, the Conformer has been proposed to combine a visual transformer branch with a CNN branch. In this paper, we propose TransCAM, a Conformer-based solution to WSSS that explicitly leverages the attention weights from the transformer branch of the Conformer to refine the CAM generated from the CNN branch. TransCAM is motivated by our observation that attention weights from shallow transformer blocks are able to capture low-level spatial feature similarities while attention weights from deep transformer blocks capture high-level semantic context. Despite its simplicity, TransCAM achieves competitive performance of 69.3% and 69.6% on the respective PASCAL VOC 2012 validation and test sets, showing the effectiveness of transformer attention-based refinement of CAM for WSSS.
C1 [Li, Ruiwen; Zhang, Zhibo; Sanner, Scott] Univ Toronto, Dept Mech & Ind Engn, 5 Kings Coll Rd, Toronto, ON M5S 3G8, Canada.
   [Mai, Zheda] Ohio State Univ, 281 W Lane Ave, Columbus, OH USA.
   [Jang, Jongseong] LG AI Res, 30 Magokjungang 10 Ro, Seoul, South Korea.
C3 University of Toronto; University System of Ohio; Ohio State University
RP Li, RW (corresponding author), Univ Toronto, Dept Mech & Ind Engn, 5 Kings Coll Rd, Toronto, ON M5S 3G8, Canada.
EM ruiwen.li@mail.utoronto.ca; mai.145@osu.edu; zhibozhang@cs.toronto.edu;
   j.jang@lgresearch.ai; ssanner@mie.utoronto.ca
RI Zhang, Zhibo/HPE-5550-2023; Mai, Zheda/JQH-8756-2023
CR Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231
   Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Chang YT, 2020, Arxiv, DOI arXiv:2008.01201
   Chen L., 2020, P 16 EUR C COMP VIS, P347
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y., 2021, arXiv
   Chen ZW, 2021, Arxiv, DOI arXiv:2112.05291
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Dai Z., 2021, J NEUROSCI RURAL PRA, V34
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan JS, 2020, AAAI CONF ARTIF INTE, V34, P10762
   Fan JS, 2020, PROC CVPR IEEE, P4282, DOI 10.1109/CVPR42600.2020.00434
   Gao W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2866, DOI 10.1109/ICCV48922.2021.00288
   Guolei Sun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P347, DOI 10.1007/978-3-030-58536-5_21
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2018, ADV NEUR IN, V31
   Ismail A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165413
   Jo S, 2021, IEEE IMAGE PROC, P639, DOI 10.1109/ICIP42928.2021.9506058
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Koltun V., 2011, Adv. Neural Inf. Process. Syst, DOI 10.48550/arXiv.1210.5644
   Lee J., 2021, IEEE CVF C COMP VIS, P4071
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Ru L., 2022, P IEEECVF C COMPUTER, P16846
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sangheum Hwang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P239, DOI 10.1007/978-3-319-46723-8_28
   Shimoda W, 2019, IEEE I CONF COMP VIS, P5207, DOI 10.1109/ICCV.2019.00531
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Wu T, 2021, PROC CVPR IEEE, P16760, DOI 10.1109/CVPR46437.2021.01649
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xu Leiyang, 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968781
   Xu L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6964, DOI 10.1109/ICCV48922.2021.00690
   Xu Y., 2021, Adv. Neural Inf. Process. Syst., V34
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yao YZ, 2021, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR46437.2021.00265
   Yu-Ting Chang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8988, DOI 10.1109/CVPR42600.2020.00901
   Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229
   Yunchao Wei, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P6488, DOI 10.1109/CVPR.2017.687
   ZHANG D, 2020, ADV NEURAL INFORM PR, V33, P655, DOI DOI 10.5555/3495724.3495780
   Zhang Fei, 2021, P IEEECVF INT C COMP, P7242
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 55
TC 11
Z9 12
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103800
DI 10.1016/j.jvcir.2023.103800
EA MAR 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0A3SW
UT WOS:000951746800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, LZ
   Tian, QH
   Ruan, QL
   Shi, ZX
AF Zhang, Lizao
   Tian, Qiuhong
   Ruan, Qionglu
   Shi, Zhixiang
TI A simple and effective static gesture recognition method based on
   attention mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sign language recognition; Deep learning; Attention mechanism
AB To solve the problem of low sign language recognition rate under the condition of small samples, a simple and effective static gesture recognition method based on an attention mechanism is proposed. The method proposed in this paper can enhance the features of both the details and the subject of the gesture image. The input of the proposed method depends on the intermediate feature map generated by the original network. Also, the proposed convolutional model is a lightweight general module, which can be seamlessly integrated into any CNN(Convolutional Neural Network) architecture and achieve significant performance gains with minimal overhead. Experiments on two different datasets show that the proposed method is effective and can improve the accuracy of sign language recognition of the benchmark model, making its performance better than the existing methods.
C1 [Zhang, Lizao; Tian, Qiuhong; Ruan, Qionglu; Shi, Zhixiang] Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Zhejiang Sci-Tech University
RP Tian, QH (corresponding author), Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Peoples R China.
EM tianqiuhong@zstu.edu.cn
RI chen, qiang/JXY-6982-2024; luo, yuan/JLS-6416-2023; YAN,
   LING/JXY-6904-2024; chen, yan/JRY-4645-2023; Wang,
   Minghao/JMD-0670-2023; Zhang, Wenbin/JXX-8070-2024
FU National Natural Science Foundation of China [51405448]; Zhejiang
   Sci-Tech University, China [18032117-Y]; Zhejiang University Student
   Science and Technology Achievement Promotion Project, China
   [14530031661961]; Zhejiang Sci-Tech University 2021 National University
   Students Innovation and Entrepreneurship Training Program, China
   [11120032382104]
FX This work was supported by the National Natural Science Foun-dation of
   China (51405448) . Qiuhong Tian acknowledges financial support from the
   doctoral research start-up funding of Zhe-jiang Sci-Tech University,
   China (18032117-Y) . This work was also supported by Zhejiang University
   Student Science and Technology Achievement Pro-motion Project, China
   (14530031661961) and Zhejiang Sci-Tech Uni-versity 2021 National
   University Students Innovation and Entrepreneur-ship Training Program,
   China (11120032382104) .
CR Ahuja R, 2019, INT J AMBIENT COMPUT, V10, P60, DOI 10.4018/IJACI.2019070104
   Bird JJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185151
   Arun C, 2020, IET IMAGE PROCESS, V14, P2101, DOI 10.1049/iet-ipr.2019.0195
   Chong TW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103554
   Hasan MM, 2020, INT CONF COMPUT INFO, DOI 10.1109/ICCIT51783.2020.9392703
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, PREPRINT
   Hu J., 2017, IEEE T PATTERN ANAL, VPP, P1
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jain Vanita, 2021, International Journal of Information Technology, V13, P1193, DOI 10.1007/s41870-021-00617-x
   Kolivand H, 2021, NEURAL COMPUT APPL, V33, P13885, DOI 10.1007/s00521-021-06025-3
   Lahamy H, 2012, SENSORS-BASEL, V12, P14416, DOI 10.3390/s121114416
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514, DOI 10.48550/ARXIV.1807.06514]
   Rafi A.M., 2019, IMAGE BASED BENGALI, DOI [10.1109/GHTC46095.2019.9033031, DOI 10.1109/GHTC46095.2019.9033031]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarawate N., 2015, TURK J ELECTR ENG CO
   Stewart J.A, 2011, AUTOMATED EMPLOYMENT
   Tamiru NK, 2022, VISUAL COMPUT, V38, P1703, DOI 10.1007/s00371-021-02099-1
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tian QH, 2021, TECHNOL HEALTH CARE, V29, P527, DOI 10.3233/THC-192000
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XL, 2018, Arxiv, DOI arXiv:1711.07971
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 26
TC 4
Z9 4
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103783
DI 10.1016/j.jvcir.2023.103783
EA FEB 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9P7AH
UT WOS:000944433100001
DA 2024-07-18
ER

PT J
AU Singh, K
   Parihar, AS
AF Singh, Kavinder
   Parihar, Anil Singh
TI DSE-Net: Deep simultaneous estimation network for low-light image
   enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning-based network; Simultaneous estimation; Illumination;
   Reflectance; Low-light (LOL) image enhancement (LLIE); Convolutional
   neural networks
ID QUALITY ASSESSMENT; ILLUMINATION; DIFFERENCE; RETINEX
AB This paper presents a novel approach for low-light image enhancement. We propose a deep simultaneous estimation network (DSE-Net), which simultaneously estimates the reflectance and illumination for low-light image enhancement. The proposed network contains three modules: image decomposition, illumination adjustment, and image refinement module. The DSE-Net uses a novel branched encoder-decoder based image decomposition module for simultaneous estimation. The proposed decomposition module uses a separate decoder to estimate illumination and reflectance. DSE-Net improves the estimated illumination using the illumination adjustment module and feeds it to the proposed refinement module. The image refinement module aims to produce sharp and natural-looking output. Extensive experiments conducted on a range of low-light images demonstrate the efficacy of the proposed model and show its supremacy over various state-of-the-art alternatives.
C1 [Singh, Kavinder; Parihar, Anil Singh] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
C3 Delhi Technological University
RP Singh, K; Parihar, AS (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
EM kavinder85@gmail.com; parihar.anil@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671
CR Bhowmik A, 2021, MULTIMED TOOLS APPL, V80, P28015, DOI 10.1007/s11042-021-10964-3
   Bhowmik A, 2019, COMM COM INF SC, V1000, P104, DOI 10.1007/978-3-030-20257-6_9
   Chaitanya BSNV, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103014
   Chen YY, 2019, J VIS COMMUN IMAGE R, V61, P284, DOI 10.1016/j.jvcir.2019.04.008
   Chiu YS, 2011, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2011.6084119
   Dhamija A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103393
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Gautam S, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102993
   Guo BY, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102851
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355
   Jain G, 2022, IEEE T COGN DEV SYST, V14, P136, DOI 10.1109/TCDS.2020.3023055
   Jiang Yifan, 2019, arXiv, DOI DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khaire P, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103531
   Kim W, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103364
   Kumar A, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103376
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2012, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2012.6467022
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Lind D., 2014, Statistical techniques in business economics, V16th
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Mun J, 2019, J VIS COMMUN IMAGE R, V58, P688, DOI 10.1016/j.jvcir.2018.12.037
   Parihar A.S., 2020, 2020 5 INT C COMM EL, P766
   Parihar AS, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103722
   Parihar AS, 2021, IET IMAGE PROCESS, V15, P1410, DOI 10.1049/ipr2.12114
   Parihar AS, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P823, DOI [10.1109/ICICCS48265.2020.9120999, 10.1109/iciccs48265.2020.9120999]
   Parihar AS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P619, DOI 10.1109/ICISC.2018.8398874
   Parihar AS, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P625, DOI 10.1109/ISS1.2017.8389246
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Parihar AS, 2022, 2022 2 INT C INTELLI, P1, DOI [10.1109/CONIT55038.2022.9847710, DOI 10.1109/CONIT55038.2022.9847710]
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Sethi Angad, 2022, 2022 6th International Conference on Computing Methodologies and Communication (ICCMC), P749, DOI 10.1109/ICCMC53470.2022.9753760
   Shao ZP, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103529
   Shen L, 2017, Arxiv, DOI arXiv:1711.02488
   Singh K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103241
   Singh S., 2020, 2020 11 INT C COMPUT, P1, DOI DOI 10.1109/ICCCNT49239.2020.9225687
   Tsai HC, 2015, J VIS COMMUN IMAGE R, V33, P165, DOI 10.1016/j.jvcir.2015.09.012
   Vaidwan N., 2021, 2021 INT C INT TECHN, P1, DOI [10.1109/CONIT51480.2021.9498550, DOI 10.1109/C0NIT51480.2021.9498550]
   Vishwakarma DK, 2019, VISUAL COMPUT, V35, P1595, DOI 10.1007/s00371-018-1560-4
   Wang L, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103545
   Wang Q, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103260
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118
   Wang X., 2021, IEEE T CYBERNETICS, V99, P1, DOI 10.1109/tcyb.2020.3041212
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 60
TC 4
Z9 4
U1 4
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103780
DI 10.1016/j.jvcir.2023.103780
EA FEB 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9S9RJ
UT WOS:000946672300001
DA 2024-07-18
ER

PT J
AU Lin, J
   Mu, ZK
   Zhao, TQ
   Zhang, HL
   Yang, XY
   Zhao, P
AF Lin, Jie
   Mu, Zekun
   Zhao, Tianqing
   Zhang, Hanlin
   Yang, Xinyu
   Zhao, Peng
TI Action density based frame sampling for human action recognition in
   videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Frame sampling; Action density; Neural network
AB In the action recognition, a proper frame sampling method can not only reduce redundant video information, but also improve the accuracy of action recognition. In this paper, an action density based non-isometric frame sampling method, namely NFS, is proposed to discard the redundant video information and sample the rational frames in videos for neural networks to achieve great accuracy on human action recognition, in which action density is introduced in our method to indicate the intensity of actions in videos. Particularly, the action density determination mechanism, focused-clips division mechanism, and reinforcement learning based frame sampling (RLFS) mechanism are proposed in NFS method. Via the evaluations with various neural networks and datasets, our results show that the proposed NFS method can achieve great effectiveness in frame sampling and can assist in achieving better accuracy on action recognition in comparison with existing methods.
C1 [Lin, Jie; Mu, Zekun; Yang, Xinyu; Zhao, Peng] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
   [Zhao, Tianqing] Northwest Inst Nucl Technol, Xian, Peoples R China.
   [Zhang, Hanlin] Qingdao Univ, Qingdao, Peoples R China.
C3 Xi'an Jiaotong University; Northwest Institute of Nuclear Technology -
   China; Qingdao University
RP Yang, XY (corresponding author), Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
EM jielin@mail.xjtu.edu.cn; 811398487@qq.com; zhaotianqing@nint.ac.cn;
   hanlin@qdu.edu.cn; yxyphd@mail.xjtu.edu.cn; zhaotianqing@nint.ac.cn
FU K. C. Wong Education Founda-tion; Fundamental Research Funds for the
   Central Universities [xzy012021082]; Natural Science Basic Research Plan
   in Shaanxi Province of China [2020JQ-070]
FX This work was partly supported by K. C. Wong Education Founda-tion, by
   the Fundamental Research Funds for the Central Universities under Grant
   xzy012021082, by Natural Science Basic Research Plan in Shaanxi Province
   of China 2020JQ-070. Any opinions, findings and conclusions or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of the agencies.
CR [Anonymous], 2018, ADV NEUR IN
   [Anonymous], 2012, CoRR
   Asghari-Esfeden S, 2020, IEEE WINT CONF APPL, P546, DOI 10.1109/WACV45572.2020.9093500
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22
   Dong WK, 2019, AAAI CONF ARTIF INTE, P8247
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gowda S. N., 2020, arXiv, DOI DOI 10.48550/ARXIV.2012.10671
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Huang DA, 2018, PROC CVPR IEEE, P7366, DOI 10.1109/CVPR.2018.00769
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Korbar B, 2019, IEEE I CONF COMP VIS, P6241, DOI 10.1109/ICCV.2019.00633
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Setitra I, 2014, INT C PATT RECOG, P2436, DOI 10.1109/ICPR.2014.421
   Sevilla-Lara Laura, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P281, DOI 10.1007/978-3-030-12939-2_20
   Simonyan K, 2014, ADV NEUR IN, V27
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Qiang, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P1143
   Wu ZX, 2019, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2019.00137
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang SW, 2020, AAAI CONF ARTIF INTE, V34, P12862
   Zheng YD, 2020, IEEE T IMAGE PROCESS, V29, P7970, DOI 10.1109/TIP.2020.3007826
NR 43
TC 0
Z9 0
U1 5
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103740
DI 10.1016/j.jvcir.2022.103740
EA JAN 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8P7CM
UT WOS:000926678400001
DA 2024-07-18
ER

PT J
AU Zhou, L
   Chen, ZZ
AF Zhou, Lin
   Chen, Zhenzhong
TI Illumination-aware window transformer for RGBT modality fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multispectral image; Multi-modal learning; Transformers
ID ATTENTION NETWORK
AB Combination of RGB and thermal sensors has been proven to be useful for many vision applications. However, how to effectively fuse the information of two modalities remains a challenging problem. In this paper, we propose an Illumination-Aware Window Transformer (IAWT) fusion module to handle the RGB and thermal multi-modality fusion. Specifically, the IAWT fusion module adopts a window-based multi-modality attention combined with additional estimated illumination information. The window-based multi-modality attention infers dependency cross modalities within a local window, thus implicitly alleviate the problem caused by weakly spatial misalignment of the RGB and thermal image pairs within specific dataset. The introduction of estimated illumination feature enables the fusion module to adaptively merge the two modalities according to illumination conditions so as to make full use of the complementary characteristics of RGB and thermal images under different environments. Besides, our proposed fusion module is task-agnostic and data-specific, which means it can be used for different tasks with RGBT inputs. To evaluate the advances of the proposed fusion method, we embed the IAWT fusion module into different networks and conduct the experiments on various RGBT tasks, including pedestrian detection, semantic segmentation and crowd counting. Extensive results demonstrate the superior performance of our method.
C1 [Zhou, Lin; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Chen, Zhenzhong] Hubei Luojia Lab, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM ramsey@whu.edu.cn; zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015
FU National Natural Science Foundation of China; Special Fund of Hubei
   Luojia Laboratory;  [62036005]
FX This work was supported in part by the National Natural Science
   Foundation of China] under Grant 62036005 and the Special Fund of Hubei
   Luojia Laboratory.
CR Bao YQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103306
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Deng FQ, 2021, IEEE INT C INT ROBOT, P4467, DOI 10.1109/IROS51168.2021.9636084
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757
   Hu RH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1419, DOI 10.1109/ICCV48922.2021.00147
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Jiang CX, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103192
   Kailai Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P787, DOI 10.1007/978-3-030-58523-5_46
   Kingma D. P., 2014, arXiv
   Koenig D, 2017, IEEE COMPUT SOC CONF, P243, DOI 10.1109/CVPRW.2017.36
   Li C., 2018, PROC BRIT MACH VIS C, P225
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J., 2016, ARXIV161102644, P1, DOI DOI 10.5244/C.30.73
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu Z., 2021, arXiv
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu JS, 2019, ADV NEUR IN, V32
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Peng T., 2020, P AS C COMP VIS ACCV, DOI DOI 10.1007/978-3-030-69544-6_30
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strudel R., 2021, arXiv
   Sun YX, 2019, IEEE ROBOT AUTOM LET, V4, P2576, DOI 10.1109/LRA.2019.2904733
   Vaswani A, 2017, ADV NEUR IN, V30
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zhai YJ, 2021, IEEE T IMAGE PROCESS, V30, P8727, DOI 10.1109/TIP.2021.3116793
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang LY, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3085978
   Zhang L, 2019, IEEE I CONF COMP VIS, P5126, DOI 10.1109/ICCV.2019.00523
   Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015
   Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou W., 2022, IEEE T INTELL VEH, P1
   Zhou WJ, 2022, IEEE J-STSP, V16, P677, DOI 10.1109/JSTSP.2022.3174338
   Zhou WJ, 2022, NEUROCOMPUTING, V490, P347, DOI 10.1016/j.neucom.2021.11.100
   Zhou WJ, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3337-9
   Zhou WJ, 2022, IEEE T EM TOP COMP I, V6, P957, DOI 10.1109/TETCI.2021.3118043
   Zhou WJ, 2021, IEEE T IMAGE PROCESS, V30, P7790, DOI 10.1109/TIP.2021.3109518
   Zhou WJ, 2022, IEEE T MULTIMEDIA, V24, P2526, DOI 10.1109/TMM.2021.3086618
   Zhou WJ, 2022, IEEE T CIRC SYST VID, V32, P1224, DOI 10.1109/TCSVT.2021.3077058
   Zhu PF, 2022, IEEE T PATTERN ANAL, V44, P7380, DOI 10.1109/TPAMI.2021.3119563
   Zhu X., 2021, P INT C LEARNING REP
NR 55
TC 3
Z9 3
U1 8
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103725
DI 10.1016/j.jvcir.2022.103725
EA DEC 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M6ZU
UT WOS:000906804000001
DA 2024-07-18
ER

PT J
AU Liu, JX
   Li, YC
   Han, G
   Sun, N
AF Liu, Jixin
   Li, Yicong
   Han, Guang
   Sun, Ning
TI Visual video evaluation association modeling based on chaotic
   pseudo-random multi-layer compressed sensing for visual
   privacy-protected keyframe extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi -layer VPP coding; Visual evaluation algorithm; Keyframe
   extraction; Keyframe extraction performance evaluation; index;
   Association model
ID QUALITY
AB In current society, artificial intelligence processing technology offers convenient video monitoring, but also raises the risk of privacy leakage. Theoretically, the data used in intelligent video processing methods may directly convey visual information containing private content. For the above problem, this paper uses a multi-layer visual privacy-protected (VPP) coding method to blur private content in the video at the visual level, while avoiding the loss of important visual features contained in the video as much as possible. And this provides a guarantee of the quality of the subsequent keyframe extraction step. Then a visual evaluation algorithm is proposed for assessing the quality of VPP-encoded video privacy protection. And the experiment shows that the results are consistent with those of subjective evaluation. In addition, for VPP-encoded video, we propose an unsupervised two-layer clustering keyframe extraction method with corresponding performance evaluation index. Finally, an association model is established to balance the privacy protection quality and the keyframe extraction performance.
C1 [Liu, Jixin; Li, Yicong; Han, Guang; Sun, Ning] Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Liu, JX (corresponding author), Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
EM liujixin@njupt.edu.cn
RI Sun, Ning/HLX-6289-2023; LIU, Jixin/AHC-0596-2022
FU Provincial Natural Sci- ence Foundation of the Science and Technology
   Bureau of Jiangsu Province; China Postdoctoral Science Foundation;
   Postgraduate Research & Practice Innovation Program of Jiangsu Province;
   Natural Science Foundation of China;  [BK20180088];  [2019M651916]; 
   [SJCX21_0269];  [61871445]
FX This work was supported by funds from the Provincial Natural Sci- ence
   Foundation of the Science and Technology Bureau of Jiangsu Province
   (Grant No. BK20180088) , the China Postdoctoral Science Foundation
   (Grant No. 2019M651916) , the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (Grant No. SJCX21_0269) , and the
   Natural Science Foundation of China (Grant No. 61871445) .
CR Azizi E, 2020, IEEE T CONSUM ELECTR, V66, P233, DOI 10.1109/TCE.2020.3008261
   Bao G, 2020, Journal of Physics: Conference Series, V1646
   Basak Debasish, 2007, Support vector regression
   BEDNAR JB, 1984, IEEE T ACOUST SPEECH, V32, P145, DOI 10.1109/TASSP.1984.1164279
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Cui MS, 2015, IEEE T GEOSCI REMOTE, V53, P2683, DOI 10.1109/TGRS.2014.2363582
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du L, 2019, J VIS COMMUN IMAGE R, V59, P347, DOI 10.1016/j.jvcir.2019.01.027
   Harrou F, 2016, IEEE INTL CONF IND I, P332, DOI 10.1109/INDIN.2016.7819182
   Huayong Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1238, DOI 10.1109/FSKD.2012.6233777
   Kannappan Sivapriyaa, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P33, DOI 10.1007/978-3-319-50832-0_4
   Karim S., 2020, WIREL COMMUN MOB COM, V32, P1
   Lamboi U., 2017, INT J SCI TECHNOL RE, V6, P14
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li Q, 2016, MATEC WEB CONF, V44, DOI 10.1051/matecconf/20164401002
   Liu JX, 2017, IET SIGNAL PROCESS, V11, P115, DOI 10.1049/iet-spr.2016.0026
   Liu JX, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103321
   Liu JX, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115996
   Long YH, 2019, 2019 15TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2019), P211, DOI 10.1109/CIS.2019.00052
   Maswadi K, 2020, IEEE ACCESS, V8, P92244, DOI 10.1109/ACCESS.2020.2992727
   Mrvelj S, 2020, PROMET-ZAGREB, V32, P409
   Oukili S, 2015, INT C MICROELECTRON, P126, DOI 10.1109/ICM.2015.7438004
   Panetta K, 2013, IEEE T CONSUM ELECTR, V59, P643, DOI 10.1109/TCE.2013.6626251
   PARK J, 1993, NEURAL COMPUT, V5, P305, DOI 10.1162/neco.1993.5.2.305
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Pozueco L, 2017, NEW REV HYPERMEDIA M, V23, P1, DOI 10.1080/13614568.2016.1152310
   Rigaki M, 2023, Arxiv, DOI arXiv:2007.07646
   Sheikh H.R., Live Image Quality Assessment Database
   Sheikhpour S, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103740
   Shi M., ARTIF INTELL, P63
   Tillmann Andreas M., 2014, IEEE Transactions on Information Theory, V60, P1248, DOI 10.1109/TIT.2013.2290112
   Ulfarsson MO, 2011, IEEE T SIGNAL PROCES, V59, P1949, DOI 10.1109/TSP.2011.2112653
   Vuppala Akshitha, 2020, Procedia Computer Science, V171, P1054, DOI 10.1016/j.procs.2020.04.113
   Yan XS, 2011, OPT ENG, V50, DOI 10.1117/1.3530070
   Yang JC, 2020, IEEE T CIRC SYST VID, V30, P3608, DOI 10.1109/TCSVT.2019.2948383
   Zeng XL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1285, DOI 10.1109/ICME.2008.4607677
NR 37
TC 1
Z9 1
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103691
DI 10.1016/j.jvcir.2022.103691
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200002
DA 2024-07-18
ER

PT J
AU Liu, XH
   Cao, GT
   Lin, QB
   Cao, WM
AF Liu, Xinghua
   Cao, Guitao
   Lin, Qiubin
   Cao, Wenming
TI Adaptive weight multi-channel center similar deep hashing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-channel; Center similar; Multimodal retrieval; Deep cross-modal
   hashing
ID REPRESENTATION
AB To increase the richness of the extracted text modality feature information and deeply explore the semantic similarity between the modalities. In this paper, we propose a novel method, named adaptive weight multi-channel center similar deep hashing (AMCDH). The algorithm first utilizes three channels with different configurations to extract feature information from the text modality; and then adds them according to the learned weight ratio to increase the richness of the information. We also introduce the Jaccard coefficient to measure the semantic similarity level between modalities from 0 to 1, and utilize it as the penalty coefficient of the cross-entropy loss function to increase its role in backpropagation. Besides, we propose a method of constructing center similarity, which makes the hash codes of similar data pairs close to the same center point, and dissimilar data pairs are scattered at different center points to generate high-quality hash codes. Extensive experimental evaluations on four benchmark datasets show that the performance of our proposed model AMCDH is significantly better than other competing baselines. The code can be obtained from https://github.com/DaveLiu6/AMCDH.git.
C1 [Liu, Xinghua; Lin, Qiubin; Cao, Wenming] Shenzhen Univ, Guangdong Prov Multimedia Informat Serv Engn Techn, Shenzhen, Peoples R China.
   [Cao, Guitao] East China Normal Univ, Res Ctr Software Hardware Codesign Engn, MOE, Shanghai 200062, Peoples R China.
   [Cao, Wenming] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai, Peoples R China.
   [Cao, Wenming] Shenzhen Univ, Guangdong Prov Multimedia Informat Serv Engn Techn, Shenzhen, Peoples R China.
C3 Shenzhen University; East China Normal University; East China Normal
   University; Shenzhen University
RP Cao, WM (corresponding author), Shenzhen Univ, Guangdong Prov Multimedia Informat Serv Engn Techn, Shenzhen, Peoples R China.; Cao, WM (corresponding author), Shenzhen Univ, Guangdong Prov Multimedia Informat Serv Engn Techn, Shenzhen, Peoples R China.
EM liuxinghua2019@email.szu.edu.cn; gtcao@sei.ecnu.edu.cn;
   2170269126@email.szu.edu.cn; gtcao@sei.ecnu.edu.cn
RI cao, wenming/Y-5293-2019
OI Lin, Qiubin/0000-0003-0221-2464; cao, wenming/0000-0002-8174-6167
FU National Natural Science Foundation of China; Fundamental Research
   Foundation of Shenzhen;  [61771322];  [61871186]; 
   [JCYJ20190808160815125]
FX ** This work was supported by the National Natural Science Foundation of
   China (No. 61771322 and No. 61871186) and the Fundamental Research
   Foundation of Shenzhen (No. JCYJ20190808160815125) .
CR Akaho S., 2006, PREPRINT
   Andrew G., 2013, ICML, P1247
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao WM, 2019, NEUROCOMPUTING, V345, P45, DOI 10.1016/j.neucom.2018.10.082
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Deng C, 2019, IEEE T IMAGE PROCESS, V28, P4032, DOI 10.1109/TIP.2019.2903661
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jia Y., 2010, Adv. Neural Inf. Process. Syst., P982
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Li K, 2017, IEEE T PATTERN ANAL, V39, P1825, DOI 10.1109/TPAMI.2016.2610969
   Lin QB, 2021, IEEE T MULTIMEDIA, V23, P550, DOI 10.1109/TMM.2020.2984081
   Lin QB, 2020, NEUROCOMPUTING, V396, P113, DOI 10.1016/j.neucom.2020.02.043
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Ma XH, 2020, IEEE T MULTIMEDIA, V22, P3101, DOI 10.1109/TMM.2020.2969792
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1392, DOI 10.1109/TNNLS.2014.2357794
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang XZ, 2020, NEUROCOMPUTING, V400, P255, DOI 10.1016/j.neucom.2020.03.019
   Yan C, 2019, NEUROCOMPUTING, V337, P58, DOI 10.1016/j.neucom.2019.01.040
   Yang E, 2018, IEEE T NEUR NET LEAR, V29, P5292, DOI 10.1109/TNNLS.2018.2793863
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yuan L, 2020, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR42600.2020.00315
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhai Xiaohua, 2013, P AAAI C ART INT
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang X, 2018, LECT NOTES COMPUT SC, V11219, P614, DOI 10.1007/978-3-030-01267-0_36
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhu F., 2014, P 23 ACM INT C INF K, P1479, DOI DOI 10.1145/2661829.2661926
   Zhuang Y., 2013, P 27 AAAI C ART INT, P1070
   Zou X., 2021, IMAGE COMMUN, V93
   Zou XT, 2022, NEUROCOMPUTING, V467, P138, DOI 10.1016/j.neucom.2021.09.053
NR 42
TC 0
Z9 0
U1 6
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103642
DI 10.1016/j.jvcir.2022.103642
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300007
DA 2024-07-18
ER

PT J
AU Li, ZX
   Lu, SH
   Lan, LQ
   Liu, QY
AF Li, Zhaoxin
   Lu, Shuhua
   Lan, Lingqiang
   Liu, Qiyuan
TI Crowd counting in complex scenes based on an attention aware CNN network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Density estimation; Attentive maps
ID CONVOLUTIONAL NEURAL-NETWORK
AB Crowd counting with density estimation has been an active research community due to its significant applica-tions in the fields of public security, video surveillance, traffic monitoring. However, Crowd counting for con-gested scenes often suffers from some obstacles including severe occlusions, large scale variations, noise interference, etc. In this paper, using the first ten layers of a modified VGG16 and dilated convolution layers as the framework, we have proposed a CNN based crowd counting and density estimation model improved by the attention aware modules with residual connections. To tackle the problem of noise interference, convolutional block attention modules have been introduced into the deep network to segment the foreground and background to focus on interest information, refining deeper features of the input image. To improve information trans-mission and reuse, residual connections are utilized to link 3 attention blocks. Meanwhile, dilated convolution layers keep larger reception fields and obtain high-resolution density maps. The proposed method has been evaluated on three public benchmarks, i.e. Shanghai Tech A & B, UCF-QNRF and MALL, achieving the mean absolute errors of 64.6 & 8.3, 113.8 and 1.68, respectively. The results outperform some existing excellent ap-proaches. This indicates that the proposed model has high accuracy and better robustness, which is suitable for crowd counting and density estimation in various congested scenes.
C1 [Li, Zhaoxin; Lu, Shuhua; Lan, Lingqiang; Liu, Qiyuan] Peoples Publ Secur Univ China, Coll Informat & Cyber Secur, Beijing 102600, Peoples R China.
C3 People's Public Security University of China
RP Lu, SH (corresponding author), Peoples Publ Secur Univ China, Coll Informat & Cyber Secur, Beijing 102600, Peoples R China.
EM lushuhua@ppsuc.edu.cn
RI chen, qiang/JXY-6982-2024; luo, yuan/JLS-6416-2023; Wang,
   Minghao/JMD-0670-2023; YAN, LING/JXY-6904-2024
FU Fundamental Research Funds for the Central Universities [2019JKF225];
   Project for strengthening the police with science and technology
   [2021JC03]
FX Acknowledgements This work is partly supported by Fundamental Research
   Funds for the Central Universities (2019JKF225) and Project for
   strengthening the police with science and technology (2021JC03) .
CR Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Delussu R, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108484
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Fan ZZ, 2022, NEUROCOMPUTING, V472, P224, DOI 10.1016/j.neucom.2021.02.103
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang S., 2019, IEEE T CIRC SYST VID
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Leibe B, 2005, PROC CVPR IEEE, P878
   Li X., 2019, IEEE T CIRC SYST VID
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Ma JJ, 2019, NEUROCOMPUTING, V350, P91, DOI 10.1016/j.neucom.2019.03.065
   Miao YQ, 2019, PATTERN RECOGN LETT, V125, P113, DOI 10.1016/j.patrec.2019.04.012
   Varior RR, 2019, Arxiv, DOI arXiv:1901.06026
   Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Wang MJ, 2021, NEUROCOMPUTING, V441, P128, DOI 10.1016/j.neucom.2021.01.112
   Wang SZ, 2020, NEUROCOMPUTING, V404, P227, DOI 10.1016/j.neucom.2020.04.139
   Wang YJ, 2020, NEUROCOMPUTING, V411, P1, DOI 10.1016/j.neucom.2020.06.034
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang SH, 2022, ENG APPL ARTIF INTEL, V108, DOI 10.1016/j.engappai.2021.104563
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302
   Zhu AC, 2022, IEEE T INTELL TRANSP, V23, P8090, DOI 10.1109/TITS.2021.3075859
   Zhu FS, 2021, NEUROCOMPUTING, V423, P46, DOI 10.1016/j.neucom.2020.09.059
   Zhu M, 2020, PATTERN RECOGN LETT, V135, P279, DOI 10.1016/j.patrec.2020.05.009
NR 38
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103591
DI 10.1016/j.jvcir.2022.103591
EA JUL 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4Y7HL
UT WOS:000861694600001
DA 2024-07-18
ER

PT J
AU Liu, L
   Wang, SH
   Wan, LL
   Yu, HB
AF Liu, Lu
   Wang, Shenghui
   Wan, Lili
   Yu, Haibo
TI Multimodal face aging framework via learning disentangled representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face aging; Disentangled representation; Variational auto-encoder; KL
   divergence; Generative adversarial network
ID AGE ESTIMATION; PERCEPTION; IMAGE; RECOGNITION; TEXTURES
AB Existing face aging (FA) approaches usually concentrate on a universal aging pattern, and produce restricted aging faces from one-to-one mapping. However, the diversity of living environments impact individuals differently in their oldness. To simulate various aging effects, we propose a multimodal FA framework based on face disentanglement technique of age-specific and age-irrelevant information. A Variational Autoencoder (VAE)-based encoder is designed to represent the distribution of the age-specific attributes. To capture the age-irrelevant features, a cycle-consistency loss of unpaired faces is utilized among various age spans. The extensive experimental results demonstrate that the sampled age-specific codes along with an age-irrelevant feature make the multimodal FA diverse and realistic.
C1 [Liu, Lu] Inspur Beijing Elect Informat Ind Co Ltd, Beijing 100085, Peoples R China.
   [Liu, Lu; Wang, Shenghui; Wan, Lili; Yu, Haibo] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Wang, Shenghui; Wan, Lili; Yu, Haibo] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Inspur; Beijing Jiaotong University; Beijing Jiaotong University
RP Wang, SH; Wan, LL (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM shwang@bjtu.edu.cn; llwan@bjtu.edu.cn
RI Liu, Lu/GYA-0257-2022
OI Liu, Lu/0000-0002-1303-9196
FU National Natural Science Foundation of China [61572064]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61572064.
CR Ai M., 2013, ACM SIGGRAPH
   [Anonymous], 2012, PROC ACM SIGGRAPH PO, DOI 10.1145/2342896.2343002
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bereta M, 2013, PATTERN RECOGN, V46, P2634, DOI 10.1016/j.patcog.2013.03.010
   Berg AC, 2006, INFORMATION VISUALIZATION-BOOK, P791
   Cao K, 2018, ARXIV PREPRINT ARXIV
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Despois J., 2020, COMPUTER VISION ECCV
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Duong CN, 2016, PROC CVPR IEEE, P5772, DOI 10.1109/CVPR.2016.622
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Gandhi M.R., 2004, THESIS
   Goodfellow I., 2016, NIPS 2016 TUTORIAL G
   Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huang ZZ, 2021, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR46437.2021.00720
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kawalec C, 1998, DEV COMMUNITY COMMUN
   Kemelmacher-Shlizerman I, 2014, PROC CVPR IEEE, P3334, DOI 10.1109/CVPR.2014.426
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, ARXIV13126114
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Li PC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2909
   Liu LQ, 2016, IEEE T MULTIMEDIA, V18, P64, DOI 10.1109/TMM.2015.2500730
   Liu MY, 2017, ADV NEUR IN, V30
   Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431
   Liu Y, 2018, INT C LEARN REPR
   MARK LS, 1981, J EXP PSYCHOL HUMAN, V7, P855, DOI 10.1037/0096-1523.7.4.855
   Ni BB, 2011, IEEE T MULTIMEDIA, V13, P1217, DOI 10.1109/TMM.2011.2167317
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   Or-El Roy, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P739, DOI 10.1007/978-3-030-58539-6_44
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Patterson E., 2007, BTAS, P1, DOI 10.1109/BTAS.2007.4401953
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ramanathan N, 2008, IEEE INT CONF AUTOMA, P1006
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Schroeder G., 2007, W NY IM PROC WORKSH
   Shu XB, 2016, PATTERN RECOGN, V59, P156, DOI 10.1016/j.patcog.2015.12.015
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   TODD JT, 1980, SCI AM, V242, P132, DOI 10.1038/scientificamerican0280-132
   Ulyanov Dmitry, 2016, arXiv
   Wang W, 2019, IEEE T PATTERN ANAL, V41, P654, DOI 10.1109/TPAMI.2018.2803166
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wu T, 2012, IEEE T INF FOREN SEC, V7, P1780, DOI 10.1109/TIFS.2012.2213812
   WU Y, 1995, J VISUAL COMP ANIMAT, V6, P195, DOI 10.1002/vis.4340060403
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011
   Yang HY, 2016, IEEE T IMAGE PROCESS, V25, P2493, DOI 10.1109/TIP.2016.2547587
   Yin Wu, 1994, Proceedings of the Second Pacific Conference on Computer Graphics and Applications, Pacific Graphics '94. Fundamentals of Computer Graphics, P201
   Yixiong Liang, 2011, Transactions on Edutainment VI, P182, DOI 10.1007/978-3-642-22639-7_18
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao J, 2019, AAAI CONF ARTIF INTE, P9251
   Zhou S., 2017, PERSONALIZED OCCUPAT
   Zhu H., 2022, J VIS COMMUN IMAGE R, V83
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 73
TC 5
Z9 5
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103452
DI 10.1016/j.jvcir.2022.103452
EA FEB 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6OC
UT WOS:000819856800003
DA 2024-07-18
ER

PT J
AU Xing, FC
   Wang, YG
   Wang, HP
   He, JF
   Yuan, JC
AF Xing, Fengchuang
   Wang, Yuan-Gen
   Wang, Hanpin
   He, Jiefeng
   Yuan, Jinchun
TI DVL2021: An ultra high definition video dataset for perceptual quality
   study
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE UHD video dataset; Video quality assessment; Authentic distortion;
   Synthetic distortion
AB This paper describes an ultra high definition (UHD) video dataset named DVL2021 for the perceptual study of video quality assessment (VQA). To our knowledge, DVL2021 is the first authentically distorted 4K (3840 x 2160) UHD video quality dataset. The dataset contains 206 versatile 4K UHD video sequences, which are all collected in in-the-wild scenarios. Each sequence is captured at 50 frames per second (fps), stored in raw 10-bit 4:2:0 YUV format, and has a duration of 10 s. Following the subjective evaluation method of TV image quality granted by ITU-R BT.500-13, 32 unique participants take part in the manual annotation process, whose ages are from teenage to sixties (32.7 years old on average). DVL2021 has the following merits: (1) enormous variety of video contents, (2) captured by different types of cameras, (3) complex types and multiple levels of authentic distortion, (4) broadly distributed temporal/spatial information, and (5) a wide spectrum of mean opinion scores (MOS) distribution. Furthermore, we conduct a benchmark experiment by evaluating several mainstream VQA methods on DVL2021. The baseline results are higher than 0.75 in Spearman's rank order correlation coefficient (SROCC) metric. Our study provides a basis for the UHD VQA problem. DVL2021 is publicly available at https://github.com/GZHU-DVL/DVL2021.
C1 [Xing, Fengchuang; Wang, Yuan-Gen; Wang, Hanpin] Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Peoples R China.
   [He, Jiefeng; Yuan, Jinchun] Guangzhou Broadcasting Network, Guangzhou 510000, Peoples R China.
   [Xing, Fengchuang] Guangdong Univ Educ, Sch Phys & Informat Engn, Guangzhou 510303, Peoples R China.
C3 Guangzhou University
RP Wang, YG (corresponding author), Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Peoples R China.
EM wangyg@gzhu.edu.cn
FU National Natural Science Foundation of China [61872099]; Scientific
   Research Project of Guangzhou University [YJ2021004]
FX Acknowledgments The authors would like to thank anonymous reviewers for
   their help in improving the quality of this paper. This work is
   supported in part by the National Natural Science Foundation of China
   under Grant 61872099 and in part by the Scientific Research Project of
   Guangzhou University under Grant YJ2021004.
CR [Anonymous], 2012, SID S DIGEST TECHNIC, DOI DOI 10.1002/J.2168-0159.2012.TB05822.X
   [Anonymous], 2015, 2015 7 INT WORKSHOP, DOI DOI 10.1109/QOMEX.2015.7148114
   Banitalebi-Dehkordi M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2020.103011
   Chen PF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P834, DOI 10.1145/3394171.3413717
   Cheon M, 2018, IEEE T CIRC SYST VID, V28, P1467, DOI 10.1109/TCSVT.2017.2683504
   Cisco, 2018, White Paper
   Ghadiyaram D, 2018, IEEE T CIRC SYST VID, V28, P2061, DOI 10.1109/TCSVT.2017.2707479
   Hanhart P, 2012, PROC SPIE, V8499, DOI 10.1117/12.946036
   Hosu Vlad, 2017, Int. Conf. Quality of Multimedia Experience, P1
   ITU-R, 2020, BT22458 ITUR
   ITU-R, 2012, BT50013 ITU
   ITU-R, 2015, BT20202 ITUR
   Korhonen J., 2020, P 28 ACM INT C MULTI, P3311, DOI DOI 10.1145/3394171.3413845
   Korhonen J, 2019, IEEE T IMAGE PROCESS, V28, P5923, DOI 10.1109/TIP.2019.2923051
   Li DQ, 2021, INT J COMPUT VISION, V129, P1238, DOI 10.1007/s11263-020-01408-w
   Li DQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2351, DOI 10.1145/3343031.3351028
   Mercat A, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P297, DOI 10.1145/3339825.3394937
   Nuutinen M, 2016, IEEE T IMAGE PROCESS, V25, P3073, DOI 10.1109/TIP.2016.2562513
   Peng ZJ, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.06.011
   Rao RRR, 2019, IEEE INT SYM MULTIM, P17, DOI [10.1109/ism46123.2019.00012, 10.1109/ISM46123.2019.00012]
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sinno Z, 2019, IEEE T IMAGE PROCESS, V28, P612, DOI 10.1109/TIP.2018.2869673
   Sotelo R, 2017, IEEE INT SYM BROADB, P501
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tu Z., 2021, IEEE OPEN J SIGNAL P, DOI DOI 10.1109/OJSP.2021.3090333
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P4449, DOI 10.1109/TIP.2021.3072221
   Van Wallendael G, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Vu PV, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013016
   Wang Y, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN SOCIETY (ICSE-SEIS 2019), P1, DOI 10.1109/ICSE-SEIS.2019.00009
   Ying ZQ, 2021, PROC CVPR IEEE, P14014, DOI 10.1109/CVPR46437.2021.01380
   Yuan Y, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102629
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang Y, 2019, IEEE T CIRC SYST VID, V29, P2244, DOI 10.1109/TCSVT.2018.2868063
NR 34
TC 3
Z9 4
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103374
DI 10.1016/j.jvcir.2021.103374
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0SO
UT WOS:000783933400001
DA 2024-07-18
ER

PT J
AU Fang, YZ
   Zhang, HX
   Liu, L
AF Fang, Yuzhi
   Zhang, Huaxiang
   Liu, Li
TI Label projection online hashing for balanced similarity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Online hashing; Label semantic; Image retrieval; Balanced similarity
ID TAG COMPLETION
AB Since online hashing has the advantages of low storage and fast calculation ,it attracts the attention of many scholars. However, the learning of new data streams separates the similarity between new data and existing data in many online hashing methods, which leads to poor retrieval performance. In addition, the similarity measure ignores the expression of different similarity. In this paper, we propose a novel supervised method, namely Label Projection Online Hashing for Balanced Similarity (LPOH). Compared with existing online hashing methods, LPOH aims to solve the problem of the effective establishment of the projection between the label vector and the binary code, and the successful realization of description of different similarity between the same labeled data. Specifically, LPOH overcomes the problem of similarity deviation caused by data imbalance via establishing a mapping matrix to derive a relationship between the data label vector and the binary code. Furthermore, the error between the binary code and the hash function concerning data streams is described. Extensive experiments on widely-used three benchmark datasets demonstrate that LPOH outperforms the state-of-the-art online hashing methods.
C1 [Fang, Yuzhi; Zhang, Huaxiang; Liu, Li] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Fang, Yuzhi] Shandong Management Univ, Coll Informat Engn, Jinan 250357, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Management University; Shandong
   Jiaotong University
RP Zhang, HX; Liu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@hotmail.com; liuli_790209@163.com
RI fang, yu/KCK-2014-2024
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2009, NEURIPS
   [Anonymous], 2009, NEURIPS
   Cakir F, 2017, IEEE I CONF COMP VIS, P437, DOI 10.1109/ICCV.2017.55
   Cakir F, 2017, COMPUT VIS IMAGE UND, V156, P162, DOI 10.1016/j.cviu.2016.10.009
   Cakir F, 2015, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2015.125
   Chen XX, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017)
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Cui H, 2020, IEEE T IMAGE PROCESS, V29, P1271, DOI 10.1109/TIP.2019.2940693
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475
   Huang Long-Kai., 2013, IJCAI, P1422
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kulis B., IEEE T PATTERN ANAL, V34, P1090
   Kumar S., 22 INT JOINT C ART I, P1360
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leng C, 2015, PROC CVPR IEEE, P2503, DOI 10.1109/CVPR.2015.7298865
   Lin MB, 2020, IEEE T IMAGE PROCESS, V29, P5289, DOI 10.1109/TIP.2020.2981879
   Lin MB, 2019, AAAI CONF ARTIF INTE, P8722
   Lin MB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1635, DOI 10.1145/3240508.3240519
   Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lu X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1129, DOI 10.1145/3343031.3350999
   Lu X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P715, DOI 10.1145/3331184.3331217
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Satuluri V., 2011, ARXIV PREPRINT ARXIV
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Sun CC, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P725, DOI 10.1145/3331184.3331229
   Wang D, 2019, IEEE T PATTERN ANAL, V41, P2466, DOI 10.1109/TPAMI.2018.2861000
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang Y., 2020, 28 ACM INT C MULT
   Weng ZY, 2020, AAAI CONF ARTIF INTE, V34, P12354
   Wu YL, 2020, IEEE T MULTIMEDIA, V22, P1310, DOI 10.1109/TMM.2019.2942494
   Wu Y, 2017, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2017.424
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xia ZQ, 2015, NEUROCOMPUTING, V147, P500, DOI 10.1016/j.neucom.2014.06.028
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Yang Yang, 2015, IEEE Transactions on Big Data, V1, P162, DOI 10.1109/TBDATA.2016.2516024
   Yao T, 2019, PATTERN RECOGN, V89, P1, DOI 10.1016/j.patcog.2018.12.012
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 51
TC 0
Z9 0
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103314
DI 10.1016/j.jvcir.2021.103314
EA SEP 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7DP
UT WOS:000709884500003
DA 2024-07-18
ER

PT J
AU Li, JW
   Hu, QR
   Guo, TX
   Wang, SQ
   Shen, YF
AF Li, Jianwei
   Hu, Qingrui
   Guo, Tianxiao
   Wang, Siqi
   Shen, Yanfei
TI What and how well you exercised? An efficient analysis framework for
   fitness actions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Action assessment; Image processing; Action
   recognition; Intelligent sports; Performance analysis
ID ACTION RECOGNITION
AB Human action analysis has been an active research area in computer vision, and has many useful applications such as human computer interaction. Most of the state-of-the-art approaches of human action analysis are data driven and focus on general action recognition. In this paper, we aim to analyze fitness actions with skeleton sequences and propose an efficient and robust fitness action analysis framework. Firstly, fitness actions from 15 subjects are captured and built to a fitness action dataset (Fitness-28). Secondly, skeleton information is extracted and made alignment with a simplified human skeleton model. Thirdly, the aligned skeleton information is transformed to an uniform human center coordinate system with the proposed spatial-temporal skeleton encoding method. Finally, the action classifier and local-global geometrical registration strategy are constructed to analyze the fitness actions. Experimental results demonstrate that our method can effectively assess fitness action, and have a good performance on artificial intelligence fitness system.
C1 [Li, Jianwei; Guo, Tianxiao; Wang, Siqi; Shen, Yanfei] Beijing Sports Univ, Sch Sports Engn, Beijing 100084, Peoples R China.
   [Hu, Qingrui] Beijing One Sports Ind Dev Co Ltd, Beijing 100020, Peoples R China.
C3 Beijing Sport University
RP Shen, YF (corresponding author), Beijing Sports Univ, Sch Sports Engn, Beijing 100084, Peoples R China.
EM syf@bsu.edu.cn
RI Liu, Jing/IQX-0664-2023; LI, Jing/HNB-5575-2023; li, jy/HTT-1535-2023;
   li, jian/GSE-0245-2022; Li, Jing/GYU-5036-2022; LI, JIAN/GRY-2197-2022;
   Shen, Yanfei/S-6525-2016; li, jian/IAQ-2794-2023; Zhang,
   Jun/JPK-7723-2023; LI, JIAN/JAX-3092-2023
OI Shen, Yanfei/0000-0002-6752-2829; 
FU National Key R&D Program of China [2018YFC2000600]; Open Projects
   Program of Na-tional Laboratory of Pattern Recognition [202100009];
   National Natural Science Foundation of China [72071018]; Fundamental
   Research Funds for Central Uni-versities [2021TD006]
FX This work is supported by the National Key R&D Program of China under
   Grant No.2018YFC2000600, the Open Projects Program of Na-tional
   Laboratory of Pattern Recognition under Grant No.202100009, the National
   Natural Science Foundation of China under Grant No.72071018, and the
   Fundamental Research Funds for Central Uni-versities No.2021TD006.
CR [Anonymous], 2019, IEEE T PATTERN ANAL
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Coskun H, 2018, LECT NOTES COMPUT SC, V11218, P693, DOI 10.1007/978-3-030-01264-9_41
   de Souza LS, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P77, DOI 10.23919/MVA.2017.7986794
   Doughty H., 2017, CORR ABS17030, P6057
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Gao J., 2020, ASYMMETRIC MODELING
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hausberger P, 2016, IEEE IND ELEC, P5182, DOI 10.1109/IECON.2016.7793510
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Huang ZW, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102700
   Jiang M, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102846
   Jibin Gao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P222, DOI 10.1007/978-3-030-58577-8_14
   Kay W., 2017, CORR ABS170506950
   Li L.-J., 2007, 2007 IEEE 11 INT C C, P1
   Li YW, 2018, LECT NOTES COMPUT SC, V11210, P520, DOI 10.1007/978-3-030-01231-1_32
   Liao YL, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103687
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Örücü S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020611
   Parmar P., 2016, IEEE INT C COMP VIS
   Pirsiavash H, 2014, LECT NOTES COMPUT SC, V8694, P556, DOI 10.1007/978-3-319-10599-4_36
   Plizzari C., 2020, ARXIV PREPRINT ARXIV
   Qi J, 2019, IEEE INTERNET THINGS, V6, P1384, DOI 10.1109/JIOT.2018.2846359
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scott J, 2017, IEEE INT CONF COMP V, P795, DOI 10.1109/ICCVW.2017.99
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shen Y, 2020, 2020 IEEE INT C MULT, P1
   Shi L., 2019, SKELETON BASED ACTIO, P3247
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Soomro K., 2014, Action recognition in realistic sports videos
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Thurau C, 2007, LECT NOTES COMPUT SC, V4814, P299
   Ting H.Y., 2014, AUTOMATIC BADMINTON
   Verma Manisha, 2020, ARXIV200410362, P1038
   Vyas Shruti, 2020, P EUR C COMP VIS
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Zhou F., 2009, P 22 INT C NEUR INF, P2286
   Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812
NR 49
TC 4
Z9 4
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103304
DI 10.1016/j.jvcir.2021.103304
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900006
DA 2024-07-18
ER

PT J
AU Shao, ZF
   Wang, JM
   Lu, T
   Zhang, RQ
   Huang, X
   Lv, XW
AF Shao, Zhenfeng
   Wang, Jiaming
   Lu, Tao
   Zhang, Ruiqian
   Huang, Xiao
   Lv, Xianwei
TI Internal and external spatial-temporal constraints for person
   reidentification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person reidentification; Convolution neural network; Attention
   mechanism; Spatial-temporal constraint
ID TRANSFER GAN; NETWORK; FUSION
AB Spatial-temporal information is easy to achieve in a practical surveillance scene, but it is often neglected in most current person reidentification (ReID) methods. Employing spatial-temporal information as a constrain has been verified as beneficial for ReID. However, there is no effective modeling according to the pedestrian movement law. In this paper, we present a ReID framework with internal and external spatial-temporal constraints, termed as IESC-ReID. A novel residual spatial attention module is proposed to build a spatial- temporal constraint and increase the robustness to partial occlusions or camera viewpoint changes. A Laplace-based spatial-temporal constraint is also introduced to eliminate irrelevant gallery images, which are gathered by the internal learning network. IESC-ReID constrains the attention within the functioning range of the channel space, and utilizes additional spatial-temporal constrains to further constrain results. Intensive experiments show that these constraints consistently improve the performance. Extensive experimental results on numerous publicly available datasets show that the proposed method outperforms several state-of-the-art ReID algorithms. Our code is publicly available at https://github.com/jiaming-wang/IESC.
C1 [Shao, Zhenfeng; Wang, Jiaming; Lv, Xianwei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Lu, Tao] Wuhan Inst Technol, Sch Comp Sci & Engn, Wuhan 430205, Peoples R China.
   [Zhang, Ruiqian] Chinese Acad Surveying & Mapping, Beijing 100036, Peoples R China.
   [Huang, Xiao] Univ Arkansas, Dept Geosci, Fayetteville, AR 72701 USA.
C3 Wuhan University; Wuhan Institute of Technology; Chinese Academy of
   Surveying & Mapping; University of Arkansas System; University of
   Arkansas Fayetteville
RP Wang, JM (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM wjmecho@whu.edu.cn
RI Huang, Xiao/AAS-4608-2020; Zhang, Ruiqian/AAA-4638-2022; Wang,
   Jiaming/V-8621-2019
OI Huang, Xiao/0000-0002-4323-382X; Zhang, Ruiqian/0000-0002-6080-9771; 
FU National Key R&D Program of China [2018YFB0505401]; National Natural
   Science Foundation of China [41890820, 41771452, 41771454, 62072350];
   Key R&D Program of Yunnan Province in China [2018IB023]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018YFB0505401; in part by the National Natural Science
   Foundation of China under Grants 41890820, 41771452, 41771454, and
   62072350; in part by the Key R&D Program of Yunnan Province in China
   under Grant 2018IB023.
CR [Anonymous], 2017, ARXIV
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cho YJ, 2019, COMPUT VIS IMAGE UND, V180, P34, DOI 10.1016/j.cviu.2019.01.003
   Cho YJ, 2017, IEEE INT CONF COMP V, P2601, DOI 10.1109/ICCVW.2017.305
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Fang PF, 2019, IEEE I CONF COMP VIS, P8029, DOI 10.1109/ICCV.2019.00812
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Ge YX, 2018, ADV NEUR IN, V31
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Huang H, 2018, ARXIV181211369
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kim T, 2017, PR MACH LEARN RES, V70
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu Y, 2018, INT C PATT RECOG, P2777, DOI 10.1109/ICPR.2018.8545760
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Lu T, 2020, NEUROCOMPUTING, V387, P309, DOI 10.1016/j.neucom.2020.01.015
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   MacCartney B., 2005, NLP LUNCH TUTORIAL S
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan X., 2019, P IEEE C COMP VIS PA, P275
   Tu ZG, 2019, IEEE T CIRC SYST VID, V29, P1423, DOI 10.1109/TCSVT.2018.2830102
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang H., 2018, IEEE CVPR
   Wang JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090585
   Wang JM, 2021, NEUROCOMPUTING, V451, P265, DOI 10.1016/j.neucom.2021.04.071
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Wenxin Huang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P174, DOI 10.1007/978-3-319-27671-7_15
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Xu H, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3954
   Xu ML, 2019, PATTERN RECOGN LETT, V119, P222, DOI 10.1016/j.patrec.2017.09.040
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P2655, DOI 10.1109/TIFS.2020.2970590
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou SR, 2019, J VIS COMMUN IMAGE R, V59, P393, DOI 10.1016/j.jvcir.2019.01.029
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 81
TC 3
Z9 3
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103302
DI 10.1016/j.jvcir.2021.103302
EA SEP 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900005
DA 2024-07-18
ER

PT J
AU Sasibhooshan, R
   Kumaraswamy, S
   Sasidharan, S
AF Sasibhooshan, Reshmi
   Kumaraswamy, Suresh
   Sasidharan, Santhoshkumar
TI WavNet - Visual saliency detection using Discrete Wavelet Convolutional
   Neural Network*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual saliency detection; Discrete wavelet convolutional neural
   network; Edge structural similarity loss
ID OBJECT DETECTION; IMAGE; MODEL
AB In the recent advancements in image and video analysis, the detection of salient regions in the image becomes the initial step. This plays a crucial role in deciding the performance of such algorithms. In this work, a Multi Resolution Feature Extraction (MRFE) technique that makes use of Discrete Wavelet Convolutional Neural Network (DWCNN) for generating features is employed. An Enhanced Feature Extraction (EFE) module extracts additional features from the high level features of the DWCNN, which are used to frame both channel as well as spatial attention models for yielding contextual attention maps. A new hybrid loss function is also proposed, which is a combination of Balanced Cross Entropy (BCE) loss and Edge based Structural Similarity (ESSIM) loss that effectively identifies and segments the salient regions with clear boundaries. The method is tested exhaustively with five different benchmark datasets and is proved superior to the existing state-of-the-art methods with a minimum Mean Absolute error (MAE) of 0.03 and F-measure of 0.956.
C1 [Sasibhooshan, Reshmi; Sasidharan, Santhoshkumar] Coll Engn Trivandrum, Thiruvananthapuram 695016, Kerala, India.
   [Kumaraswamy, Suresh] Govt Engn Coll, Barton Hill, Thiruvananthapuram 695035, Kerala, India.
C3 College of Engineering, Trivandrum
RP Sasibhooshan, R (corresponding author), Coll Engn Trivandrum, Thiruvananthapuram 695016, Kerala, India.
EM reshmibhooshan@cet.ac.in; sureshk@ieee.org; santhoshs@cet.ac.in
RI K, Suresh/AAX-6448-2021
OI SASIBHOOSHAN, RESHMI/0000-0002-9866-183X; Kumaraswamy,
   Suresh/0000-0002-4358-7732
CR Ahmad J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181707
   Akgül T, 2011, IEEE SIGNAL PROC MAG, V28, P160, DOI 10.1109/MSP.2010.938777
   [Anonymous], 2010, P 13 INT C ART INT S
   Bai XF, 2014, NEUROCOMPUTING, V136, P243, DOI 10.1016/j.neucom.2014.01.008
   Burruss G. W., 2005, ENCY SOCIAL MEASUREM, P455, DOI [10.1016/B0-12-369398-5/00060-8, DOI 10.1016/B0-12-369398-5/00060-8]
   Chen G.H., 2006, P INT C ACOUSTICS SP, V2, pII
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cholakkal H, 2018, IEEE T IMAGE PROCESS, V27, P6064, DOI 10.1109/TIP.2018.2864891
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng T, 2016, IEEE T INTELL TRANSP, V17, P2051, DOI 10.1109/TITS.2016.2535402
   Du SZ, 2014, IEEE SIGNAL PROC LET, V21, P51, DOI 10.1109/LSP.2013.2290547
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fernández-Sanjurjo M, 2019, ENG APPL ARTIF INTEL, V85, P410, DOI 10.1016/j.engappai.2019.07.005
   Gao ZG, 2018, IEEE ACCESS, V6, P71422, DOI 10.1109/ACCESS.2018.2882014
   Gupta R, 2013, SIGNAL PROCESS-IMAGE, V28, P1006, DOI 10.1016/j.image.2013.07.003
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Ji YZ, 2018, NEUROCOMPUTING, V316, P357, DOI 10.1016/j.neucom.2018.08.013
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kingma D, 2014, ICLR P, V2014, P1
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li TP, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107372
   Li TP, 2020, NEUROCOMPUTING, V389, P170, DOI 10.1016/j.neucom.2019.12.109
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu ZY, 2020, NEUROCOMPUTING, V372, P55, DOI 10.1016/j.neucom.2019.09.018
   Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Muddamsetty SM, 2014, INT C PATT RECOG, P2353, DOI 10.1109/ICPR.2014.408
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Rai Y., 2018, ACAD PRESS LIB SIGNA, V6, P113, DOI [10.1016/B978-0-12-811889-4.00003-8, DOI 10.1016/B978-0-12-811889-4.00003-8]
   Ramanishka V, 2017, PROC CVPR IEEE, P3135, DOI 10.1109/CVPR.2017.334
   Russell AF, 2014, VISION RES, V94, P1, DOI 10.1016/j.visres.2013.10.005
   Scharfenberger C, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P75, DOI 10.1109/CRV.2013.25
   Shao ZF, 2020, IEEE T CIRC SYST VID, V30, P781, DOI 10.1109/TCSVT.2019.2897980
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tang YB, 2016, LECT NOTES COMPUT SC, V9912, P809, DOI 10.1007/978-3-319-46484-8_49
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vaidyanathan P. P., 1993, MULTIRATE SYSTEMS FI
   Wang KZ, 2015, IEEE T IMAGE PROCESS, V24, P3019, DOI 10.1109/TIP.2015.2432712
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102761
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yan XH, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01172-y
   Yang B, 2016, IEEE T BROADCAST, V62, P842, DOI 10.1109/TBC.2016.2617291
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang Q, 2019, J VIS COMMUN IMAGE R, V59, P415, DOI 10.1016/j.jvcir.2019.01.034
   Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22
NR 67
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103236
DI 10.1016/j.jvcir.2021.103236
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800009
DA 2024-07-18
ER

PT J
AU Guermazi, R
   Ben Abdallah, T
   Hammami, M
AF Guermazi, Radhouane
   Ben Abdallah, Taoufik
   Hammami, Mohamed
TI Facial micro-expression recognition based on accordion spatio-temporal
   representation and random forests
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial micro-expressions; Pyramid levels' combination; Accordion
   representation; Low-dimensional feature space; Random Forests; Proximity
   measure
ID OPTICAL-FLOW; CLASSIFICATION; INTELLIGENCE; DESCRIPTORS; EXTRACTION; TOP
AB Micro-expressions are very brief involuntary facial expressions which appear on the face of humans when they unconsciously conceal an emotion. Creating a solution allowing an automatic recognition of the facial microexpressions from video sequences has garnered increasing attention from experts across such different disciplines as computer science, security, and psychology. This paper offered a solution to facial micro-expressions recognition, based on accordion spatio-temporal representation and Random Forests. The proposed feature space, called "Uniform Local Binary Patterns on an Accordion 2D representation of sub-regions presented by a Pyramid of levels (LBPAccP(u2))", exploits the effectiveness of uniform LBP patterns applied on an accordion representation of sub-regions at different sizes. Random Forests were used to select the most discriminating features and reduce the classification ambiguity of similar micro-expressions through a new proximity measure. The main objective of our paper was to demonstrate that the use of few features could be more efficient to produce a strong micro-expression recognition classifier that outperforms the approaches that rely on high dimensional features space. The experimental results across six micro-expression datasets show the effectiveness of the proposed solution with an accuracy rate that can reach 81.38% on Casmell dataset. Compared to some famous competitive state-of-the-art approaches, the proposed solution proved its performance thanks to its accuracy rate as well as the number of features it uses.
C1 [Guermazi, Radhouane] Saudi Elect Univ, Riyadh, Saudi Arabia.
   [Ben Abdallah, Taoufik] Fac Econ & Management Sfax, MIR CL Lab, Sfax, Tunisia.
   [Hammami, Mohamed] Fac Sci Sfax, MIR CL Lab, Sfax, Tunisia.
C3 Saudi Electronic University; Universite de Sfax; Universite de Sfax;
   Faculty of Sciences Sfax
RP Guermazi, R (corresponding author), Saudi Elect Univ, Riyadh, Saudi Arabia.
EM r.guermazi@seu.edu.sa
CR Abdallah T.B., 2019, INT C INT SYST DES A, P629
   [Anonymous], 2009, Protecting Airline Passengers in the Age of Terrorism, DOI DOI 10.5040/9798216002246.CH-005
   [Anonymous], 2013, 2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG), DOI [DOI 10.1109/FG.2013.6553799, DOI 10.1109/FG.2013.6553799.IEEE]
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Ben Abdallah T, 2018, MULTIMED TOOLS APPL, V77, P19455, DOI 10.1007/s11042-017-5354-x
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   Breiman L., 2001, Mach. Learn., V45, P5
   Chaabane I., 2019, Advances in Data Analysis and Classification, P1
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Datta B.N, 2004, NUMERICAL METHODS LI, P19
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ekman P, 1978, FACIAL ACTION CODING
   Fangbing Qu, 2018, IEEE Transactions on Affective Computing, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Goh KM, 2020, VISUAL COMPUT, V36, P445, DOI 10.1007/s00371-018-1607-6
   Guermazi R, 2018, INFORM SCIENCES, V467, P373, DOI 10.1016/j.ins.2018.07.076
   Guo YC, 2015, OPTIK, V126, P4446, DOI 10.1016/j.ijleo.2015.08.167
   HODGES JL, 1962, ANN MATH STAT, V33, P482, DOI 10.1214/aoms/1177704575
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Huang Y, 2018, J VIS COMMUN IMAGE R, V55, P677, DOI 10.1016/j.jvcir.2018.08.002
   Husak P., 2017, P 22 COMP VIS WINT W, P1
   Imotions, 2016, FAC EXPR AN COMPL PO
   Jia XT, 2018, J COMPUT SCI-NETH, V25, P289, DOI 10.1016/j.jocs.2017.03.016
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Li X., 2017, IEEE Transactions on Affective Computing
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Liong ST, 2018, J SIGNAL PROCESS SYS, V90, P601, DOI 10.1007/s11265-017-1276-0
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lu H, 2018, SIGNAL PROCESS-IMAGE, V67, P108, DOI 10.1016/j.image.2018.05.014
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   Niu ZH, 2006, INT C PATT RECOG, P1216
   O'Sullivan M, 2009, LAW HUMAN BEHAV, V33, P530, DOI 10.1007/s10979-008-9166-4
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouni T, 2009, 2009 INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P202, DOI 10.1109/ICTEL.2009.5158644
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Pool LD, 2012, LEARN INDIVID DIFFER, V22, P306, DOI 10.1016/j.lindif.2012.01.010
   Reddi S. J., 2019, ARXIV PREPRINT ARXIV
   Rodriguez-Fdez I., 2015, 2015 IEEE INT C FUZZ, P1, DOI 10.1109/FUZZ-IEEE.2015.7337889
   Russell TA, 2006, BRIT J CLIN PSYCHOL, V45, P579, DOI 10.1348/014466505X90866
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Takalkar MA, 2020, MULTIMEDIA SYST, V26, P535, DOI 10.1007/s00530-020-00663-8
   Wang CY, 2020, NEUROCOMPUTING, V410, P354, DOI 10.1016/j.neucom.2020.06.005
   Wang L, 2019, SIGNAL PROCESS-IMAGE, V78, P246, DOI 10.1016/j.image.2019.07.011
   Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yu ZB, 2018, NEUROCOMPUTING, V317, P50, DOI 10.1016/j.neucom.2018.07.028
   Zhang P, 2016, OPTIK, V127, P1395, DOI 10.1016/j.ijleo.2015.10.217
   Zhang T, 2020, IEEE T KNOWL DATA EN
   Zheng H, 2017, J PHYS CONF SER, V787, DOI 10.1088/1742-6596/787/1/012013
   Zhi RC, 2019, IEICE T INF SYST, VE102D, P1054, DOI 10.1587/transinf.2018EDP7153
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 61
TC 9
Z9 9
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103183
DI 10.1016/j.jvcir.2021.103183
EA JUL 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA UF3QM
UT WOS:000688491100014
DA 2024-07-18
ER

PT J
AU Li, AQ
   Chen, ZZ
AF Li, Aoqi
   Chen, Zhenzhong
TI Semantic meaning modulates object importance in human fixation
   prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention; Image saliency; Semantic attributes; Object importance
ID VISUAL-ATTENTION; NATURAL SCENES; EYE-MOVEMENTS; SALIENCY; SEARCH;
   CATEGORY; GUIDANCE; COLOR; MEMORY; ROLES
AB Humans tend to allocate attention to semantic entities. Objects are important in fixation selection, but not all the objects are equally attractive. In this paper, we introduce the concept of attribute bias to characterize the influence of semantic attributes compared with low-level saliency on fixation distribution. Two different ways are adopted to get two sets of semantic attributes. In both cases, most semantic attributes have a positive influence on drawing attention and contribute more than low-level saliency in object areas. We also find that attribute bias is robust to low-level saliency and can consistently reflect the relative attractiveness of objects with different semantic attributes. It is demonstrated that such bias helps make better fixation predictions by distinguishing the importance of objects, although low-level saliency models with better performance are less dramatically improved by attribute bias. These findings indicate the role of conceptual meaning as opposed to features in visual attention.
C1 [Li, Aoqi; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015
FU National Natural Science Founda-tion of China [61771348]
FX This work was supported by the National Natural Science Founda-tion of
   China under Grant No. 61771348.
CR Baddeley RJ, 2006, VISION RES, V46, P2824, DOI 10.1016/j.visres.2006.02.024
   Baier D, 2019, VISION RES, V160, P43, DOI 10.1016/j.visres.2019.02.016
   Beauchamp MS, 2003, J COGNITIVE NEUROSCI, V15, P991, DOI 10.1162/089892903770007380
   Beck DM, 2009, VISION RES, V49, P1154, DOI 10.1016/j.visres.2008.07.012
   Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cerf M., 2007, P NEUR INF PROC SYST
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Çukur T, 2013, NAT NEUROSCI, V16, P763, DOI 10.1038/nn.3381
   Daffron JL, 2015, J VISION, V15, DOI 10.1167/15.15.16
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.14.18
   Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3
   Engmann S, 2009, ATTEN PERCEPT PSYCHO, V71, P1337, DOI 10.3758/APP.71.6.1337
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Ernst D, 2020, VISION RES, V168, P42, DOI 10.1016/j.visres.2020.01.004
   Ernst D, 2018, VIS COGN, V26, P366, DOI 10.1080/13506285.2018.1459997
   Evans KK, 2018, COGNITION, V180, P24, DOI 10.1016/j.cognition.2018.06.022
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Faivre N., 2013, J VISUAL-JAPAN, V13, P962, DOI [10.1167/13.9.962, DOI 10.1167/13.9.962]
   Foulsham T, 2013, Q J EXP PSYCHOL, V66, P1707, DOI 10.1080/17470218.2012.762798
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hemström J, 2019, VISION RES, V162, P8, DOI 10.1016/j.visres.2019.06.007
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hwang AD, 2011, VISION RES, V51, P1192, DOI 10.1016/j.visres.2011.03.010
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JONIDES J, 1972, PERCEPT PSYCHOPHYS, V12, P457, DOI 10.3758/BF03210934
   Jost T, 2005, COMPUT VIS IMAGE UND, V100, P107, DOI 10.1016/j.cviu.2004.10.009
   Kayser C, 2006, VISION RES, V46, P2535, DOI 10.1016/j.visres.2006.02.003
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Le Meur O, 2016, VISION RES, V121, P72, DOI 10.1016/j.visres.2016.01.005
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu HY, 2016, IEEE T NEUR NET LEAR, V27, P1201, DOI 10.1109/TNNLS.2016.2553579
   Ma XL, 2015, J VIS COMMUN IMAGE R, V32, P95, DOI 10.1016/j.jvcir.2015.08.003
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   Makovski T, 2018, MEM COGNITION, V46, P58, DOI 10.3758/s13421-017-0745-9
   Nako R, 2016, J EXP PSYCHOL HUMAN, V42, P1571, DOI 10.1037/xhp0000244
   Nuthmann A, 2010, J VISION, V10, DOI 10.1167/10.8.20
   Onat S, 2007, J VISION, V7, DOI 10.1167/7.10.11
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Pelphrey KA, 2004, PSYCHOL SCI, V15, P598, DOI 10.1111/j.0956-7976.2004.00726.x
   Ramey MM, 2019, COGNITION, V185, P71, DOI 10.1016/j.cognition.2019.01.007
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell AF, 2014, VISION RES, V94, P1, DOI 10.1016/j.visres.2013.10.005
   Schirmer A, 2011, SOC NEUROSCI-UK, V6, P219, DOI 10.1080/17470919.2010.507958
   Schomaker J, 2017, VISION RES, V133, P161, DOI 10.1016/j.visres.2017.02.003
   Stoll J, 2015, VISION RES, V107, P36, DOI 10.1016/j.visres.2014.11.006
   Sun XS, 2013, J VIS COMMUN IMAGE R, V24, P171, DOI 10.1016/j.jvcir.2012.01.014
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wang HX, 2012, J COMPUT INF SCI ENG, V12, DOI [10.1115/1.3617441, 10.1167/12.1.16, 10.1167/12.6.26]
   Wolfe J. M., 2007, INTEGRATED MODELS CO, P99, DOI [10.1093/acprof:oso/9780195189193.003.0008, DOI 10.1093/ACPROF:OSO/9780195189193.003.0008]
   Wu CC, 2014, VISION RES, V105, P10, DOI 10.1016/j.visres.2014.08.019
   Wu CC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00054
   Wu X, 2017, ATTEN PERCEPT PSYCHO, V79, P1968, DOI 10.3758/s13414-017-1363-0
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Yanulevskaya V, 2013, J VISION, V13, DOI 10.1167/13.13.27
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
NR 62
TC 1
Z9 1
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103206
DI 10.1016/j.jvcir.2021.103206
EA JUL 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA UF2LR
UT WOS:000688410900003
DA 2024-07-18
ER

PT J
AU Li, YJ
   Liang, QK
   Li, ZW
   Lei, YC
   Sun, W
   Wang, YN
   Zhang, D
AF Li, Yijie
   Liang, Qiaokang
   Li, Zhengwei
   Lei, Youcheng
   Sun, Wei
   Wang, Yaonan
   Zhang, Dan
TI EdgeGAN: One-way mapping generative adversarial network based on the
   edge information for unpaired training set
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lightweight generative adversarial network; Image conversion;
   Image-to-image translation; Unpaired image-to-image translation
AB Image conversion has attracted mounting attention due to its practical applications. This paper proposes a lightweight network structure that can implement unpaired training sets to complete one-way image mapping, based on the generative adversarial network (GAN) and a fixed-parameter edge detection convolution kernel. Compared with the cycle consistent adversarial network (CycleGAN), the proposed network features simpler structure, fewer parameters (only 37.48% of the parameters in CycleGAN), and less training cost (only 35.47% of the GPU memory usage and 17.67% of the single iteration time in CycleGAN). Remarkably, the cyclic consistency becomes not mandatory for ensuring the consistency of the content before and after image mapping. This network has achieved significant processing effects in some image translation tasks, and its effectiveness and validity have been well demonstrated through typical experiments. In the quantitative classification evaluation based on VGG-16, the algorithm proposed in this paper has achieved superior performance.
C1 [Li, Yijie; Liang, Qiaokang; Lei, Youcheng; Sun, Wei; Wang, Yaonan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Yijie; Liang, Qiaokang; Lei, Youcheng; Sun, Wei; Wang, Yaonan] Hunan Univ, Natl Engn Lab Robot Vis Percept & Control, Hunan Key Lab Intelligent Robot Technol Elect Mfg, Changsha 410082, Hunan, Peoples R China.
   [Li, Zhengwei] Univ Alberta, Dept Mech Engn, Edmonton, AB T6G 2E1, Canada.
   [Zhang, Dan] York Univ, Dept Mech Engn, Toronto, ON M3J 1P3, Canada.
C3 Hunan University; Hunan University; University of Alberta; York
   University - Canada
RP Liang, QK (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.; Liang, QK (corresponding author), Hunan Univ, Natl Engn Lab Robot Vis Percept & Control, Hunan Key Lab Intelligent Robot Technol Elect Mfg, Changsha 410082, Hunan, Peoples R China.
EM qiaokang@mail.ustc.edu.cn
RI Liang, Qiaokang/D-5406-2012; LI, yi/HKO-0480-2023; yijie,
   li/JRY-8316-2023; Zhang, Dan/AFA-2608-2022
OI Zhang, Dan/0000-0002-7295-4837; Liang, qiaokang/0000-0002-5504-9966
FU National Natural Science Foundation of China [NSFC 62073129];
   Chang-Zhu-Tan National Indigenous Innovation Demonstration Zone Project
   [2017XK2102]; Nature Science Research Project of Anhui Province
   [1808085QF195]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC 62073129), the Chang-Zhu-Tan National
   Indigenous Innovation Demonstration Zone Project (2017XK2102), and the
   Nature Science Research Project of Anhui Province (1808085QF195).
CR [Anonymous], 2016, ARXIV E PRINTS
   [Anonymous], P IEEE C COMP VIS PA
   Anoosheh Asha, 2018, P IEEE C COMP VIS PA
   Cheng MM, 2020, IEEE T IMAGE PROCESS, V29, P909, DOI 10.1109/TIP.2019.2936746
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fang FM, 2020, IEEE T VIS COMPUT GR, V26, P2931, DOI 10.1109/TVCG.2019.2908363
   Gatys L., 2015, NIPS
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Jing Yongcheng, 2020, P AAAI C ART INT
   Kingma D. P., 2014, arXiv
   Liu Ming-Yu, 2017, ARXIV PREPRINT ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Yi Ran, 2020, P IEEE CVF C COMP VI
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang Pan, 2020, P IEEE CVF C COMP VI
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 26
TC 0
Z9 0
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103187
DI 10.1016/j.jvcir.2021.103187
EA JUN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1MD
UT WOS:000674618200001
DA 2024-07-18
ER

PT J
AU Tsai, TH
   Hsieh, JW
   Chang, CW
   Lay, CR
   Fan, KC
AF Tsai, Tsung-Hsien
   Hsieh, Jun-Wei
   Chang, Chuan-Wang
   Lay, Chin-Rong
   Fan, Kuo-Chin
TI Air-writing recognition using reverse time ordered stroke context
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Air writing recognition; Backward time-order stroke representation;
   3D-sensor; Gesture-based interaction
ID GESTURE RECOGNITION; SYSTEM
AB Air-writing is a new human and smart device communication approach, permits users to write inputs in a natural and relentless way. This touch-less way can prevent users from virus infection such as COVID-19. Compared with other methods, air writing is more challenging due to its unique characteristics such as redundant lifting strokes, multiplicity (different writing styles from various users), and confusion (different character types written in air are similar). Without the need of any starting trigger, a novel reverse time-ordered algorithm is proposed in this paper to efficiently filter out unnecessary lifting strokes, and thus simplifies the matching procedure. As to the second and third issues, a tiered arrangement structure is proposed by sampling the air-writing results with various sampling rates to solve the multiplicity and confusion problems. Analyzed with other recently proposed air writing algorithms, the proposed approach reaches satisfactory recognition accuracy (above 94%) without any starting triggers.
C1 [Tsai, Tsung-Hsien; Hsieh, Jun-Wei] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Beining Rd, Keelung 202, Taiwan.
   [Hsieh, Jun-Wei] Natl Yang Ming Chiao Tung Univ, Inst Computat Intelligence, 1001 Univ Rd, Hsinchu, Taiwan.
   [Chang, Chuan-Wang] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, 57,Sec 2,Zhongshan Rd, Taichung, Taiwan.
   [Lay, Chin-Rong; Fan, Kuo-Chin] Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Zhongda Rd, Taoyuan, Taiwan.
C3 National Taiwan Ocean University; National Yang Ming Chiao Tung
   University; National Chin-Yi University of Technology; National Central
   University
RP Hsieh, JW (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Beining Rd, Keelung 202, Taiwan.; Hsieh, JW (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Computat Intelligence, 1001 Univ Rd, Hsinchu, Taiwan.
RI Fan, K/GXH-3734-2022
CR Akazawa N., 2013, Consumer Electronics(GCCE),2013 IEEE 2nd Global Conference on, P253
   Beg S., 2013, J INFORM DISPLAY, V14, DOI [10.1080/15980316.2013.860928, DOI 10.1080/15980316.2013.860928]
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Chiang CC, 2017, PATTERN RECOGN, V61, P15, DOI 10.1016/j.patcog.2016.07.018
   Chu TT, 2012, I S INTELL SIG PROC
   Gupta L, 2001, IEEE T SYST MAN CY C, V31, P114, DOI 10.1109/5326.923274
   Huang FA, 2013, I S INTELL SIG PROC, P694, DOI 10.1109/ISPACS.2013.6704638
   Infantino I, 2007, IEEE T SYST MAN CY C, V37, P1034, DOI 10.1109/TSMCC.2007.900624
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Lee-Wen Chiu, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P260, DOI 10.1007/978-3-030-04375-9_22
   Li T.-H. S., 2016, IEEE T SYSTEMS MAN C, V46
   Lim KM, 2016, J VIS COMMUN IMAGE R, V40, P538, DOI 10.1016/j.jvcir.2016.07.020
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Murata T, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/278460
   Qu C., 2015, Journal of Information Computational Science, V12, P413, DOI 10.12733/jics20105578
   Schick A, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P217
   Su CY, 2014, IEEE SYS MAN CYBERN, P2127, DOI 10.1109/SMC.2014.6974236
   Sun ZW, 2016, SECUR COMMUN NETW, V9, P1359, DOI 10.1002/sec.1422
   Suryanarayan Poonam, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3105, DOI 10.1109/ICPR.2010.760
   Takeuchi A, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P103, DOI 10.1109/ICAwST.2013.6765417
   Tian J., 2013, P 20 ANN NETW DISTR
   Tsai T.-H., 2017 10 INT C UB COM 2017 10 INT C UB COM
   Tsuchida K, 2015, COMM COM INF SC, V528, P534, DOI 10.1007/978-3-319-21380-4_91
   Xiao G, 2016, 2016 4TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS), P112, DOI 10.1109/ISDFS.2016.7473528
   Yang JY, 2016, J VIS COMMUN IMAGE R, V38, P627, DOI 10.1016/j.jvcir.2016.04.010
   Zhang X, 2013, IEEE MULTIMEDIA, V20, P85, DOI 10.1109/MMUL.2013.50
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
NR 28
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103065
DI 10.1016/j.jvcir.2021.103065
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200010
DA 2024-07-18
ER

PT J
AU Puteaux, P
   Ong, S
   Wong, KK
   Puech, W
AF Puteaux, Pauline
   Ong, SimYing
   Wong, KokSheik
   Puech, William
TI A survey of reversible data hiding in encrypted images-The first 12
   years
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia security; Image encryption; Data hiding; Signal processing in
   the encrypted domain
ID PROGRESSIVE QUALITY DEGRADATION; SCHEME; AUTHENTICATION; DOMAIN
AB In the last few years, with the increasing popularity of cloud computing and the availability of mobile smart devices as well as ubiquitous network connections, more and more users are uploading their personal data to remote servers. However, this can lead to significant security breaches, where confidentiality, integrity and authentication are constantly threatened. To overcome these multiple problems, multimedia data must be secured, for example by means of encryption before transmission and storage. In this survey, we look into the issues involved in handling encrypted multimedia data, and more specifically we focus on reversible data hiding in encrypted images (RDHEI). The aim of this survey is to present the birth and evolution of RDHEI methods over the last 12 years. We first highlight different classes and characteristics of RDHEI, then describe representative RDHEI methods. A comparison table is presented to summarize the key features and achievements of each representative RDHEI method considered in this survey. Finally, we share the future outlook of emerging applications and open research topics relevant to RDHEI for the next 12 years and beyond.
C1 [Puteaux, Pauline; Puech, William] Univ Montpellier, CNRS, LIRMM, 860 Rue St Priest, F-34095 Montpellier 5, France.
   [Ong, SimYing] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Wong, KokSheik] Monash Univ Malaysia, Sch Informat Technol, Subang Jaya, Malaysia.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de
   Montpellier; Universiti Malaya; Monash University; Monash University
   Malaysia
RP Puech, W (corresponding author), Univ Montpellier, CNRS, LIRMM, 860 Rue St Priest, F-34095 Montpellier 5, France.
EM pauline.puteaux@lirmm.fr; simying.ong@um.edu.my;
   wong.koksheik@monash.edu; william.puech@lirmm.fr
RI Ong, SimYing/A-7559-2011; Wong, KokSheik/B-9796-2011
OI Ong, SimYing/0000-0002-6876-3050; Puech, William/0000-0001-9383-2401;
   Wong, KokSheik/0000-0002-4893-2291
CR [Anonymous], 2016, INT WORKSH DIG WAT I
   Aslam S., 2020, Facebook by the numbers: Stats, demographics fun facts
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen B, 2019, SIGNAL PROCESS, V164, P48, DOI 10.1016/j.sigpro.2019.05.036
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Coppersmith D, 1996, IBM J RES DEV, V40, P253, DOI 10.1147/rd.402.0253
   Cox IJ., 2007, DIGITAL WATERMARKING
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Dragoi IC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2102, DOI 10.1109/ICASSP.2018.8461362
   Dragoi IC, 2017, EUR SIGNAL PR CONF, P2186, DOI 10.23919/EUSIPCO.2017.8081597
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Guo SW, 2020, IEEE T INF FOREN SEC, V15, P1151, DOI 10.1109/TIFS.2019.2935415
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   Hey T., 2009, Microsoft Research
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Jiang CL, 2020, MULTIMED TOOLS APPL, V79, P693, DOI 10.1007/s11042-019-07874-w
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Karim MSA, 2015, SIGNAL PROCESS, V108, P56, DOI 10.1016/j.sigpro.2014.08.037
   Karim MSA, 2014, SIGNAL PROCESS, V94, P174, DOI 10.1016/j.sigpro.2013.06.014
   Ke Y, 2018, J VIS COMMUN IMAGE R, V54, P133, DOI 10.1016/j.jvcir.2018.05.002
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Le Philippe N, 2017, IEEE IMAGE PROC, P4347, DOI 10.1109/ICIP.2017.8297103
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Long M, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107703
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Minemura K, 2017, IEEE T CIRC SYST VID, V27, P2309, DOI 10.1109/TCSVT.2016.2589742
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Ong S, 2015, THESIS U MALAYA
   Ong S, 2013, IEEE IMAGE PROC, P4574, DOI 10.1109/ICIP.2013.6738942
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Ong SY, 2014, SIGNAL PROCESS-IMAGE, V29, P135, DOI 10.1016/j.image.2013.09.001
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Peng F, 2020, IEEE T CIRC SYST VID, V30, P2391, DOI 10.1109/TCSVT.2020.2986782
   POH GS, 2009, INT WORKSH DIG WAT I, P00433
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Puech, 2018, 2018 IEEE INT WORKSH, P1
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Puyang Y, 2018, IEEE INT WORKS INFOR
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Ren HL, 2019, SIGNAL PROCESS, V165, P268, DOI 10.1016/j.sigpro.2019.07.020
   Richter T, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.49
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Shah M, 2018, ARAB J SCI ENG, V43, P8145, DOI 10.1007/s13369-018-3354-4
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sohn H, 2011, IEEE T CIRC SYST VID, V21, P170, DOI 10.1109/TCSVT.2011.2106250
   Tew Y, 2018, MULTIMED TOOLS APPL, V77, P24165, DOI 10.1007/s11042-018-5611-7
   Tew YQ, 2016, J VIS COMMUN IMAGE R, V40, P502, DOI 10.1016/j.jvcir.2016.07.017
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wang, SEPARABLE REVERSIBLE
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong K, 2014, IEEE REGION 10 SYMP, P527, DOI 10.1109/TENCONSpring.2014.6863090
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Xiong LZ, 2018, IEEE ACCESS, V6, P60635, DOI 10.1109/ACCESS.2018.2876036
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Xu DW, 2014, LECT NOTES COMPUT SC, V8389, P141, DOI 10.1007/978-3-662-43886-2_10
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2022, IEEE T DEPEND SECURE, V19, P992, DOI 10.1109/TDSC.2020.3019490
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng SH, 2019, INT CONF WIRE COMMUN, DOI 10.1109/wcsp.2019.8927961
NR 88
TC 34
Z9 37
U1 6
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103085
DI 10.1016/j.jvcir.2021.103085
EA APR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400006
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chtourou, I
   Fendri, E
   Hammami, M
AF Chtourou, Imen
   Fendri, Emna
   Hammami, Mohamed
TI Person re-identification based on gait via Part View Transformation
   Model under variable covariate conditions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Re-identification; Gait; Part View Transformation Model (PVTM); View
   angle variation; Covariate factors
ID RECOGNITION; PROJECTIONS
AB Human gait represents an attractive biometric modality to re-identify a person as it requires non contact and it is perceivable at a distance. However, the view angle variation and the presence of covariate factors cause significant difficulties for recognizing gaits. In order to deal with such constraints, this paper presents a Part View Transformation Model (PVTM) for gait based applications. Compared with previous methods, the PVTM is applied on selected relevant parts chosen through a semantic classification step. Conducted on the CASIA-B gait database, experimental results show that the proposed method outperforms well known multi-view methods even under covariate factors (i.e. carrying bag, clothing).
C1 [Chtourou, Imen] Univ Sfax, ENIS, MIRACL Lab, Rd Sokra Km 4,BP 1173, Sfax 3038, Tunisia.
   [Fendri, Emna; Hammami, Mohamed] Univ Sfax, FSS, MIRACL Lab, Rd Sokra Km 4,BP 802, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Multimedia, InfoRmation Systems &
   Advancing Computing Laboratory (MIRACL)
RP Chtourou, I (corresponding author), Univ Sfax, ENIS, MIRACL Lab, Rd Sokra Km 4,BP 1173, Sfax 3038, Tunisia.
EM imene.chtourou@gmail.com
OI Emna, Fendri/0000-0002-2328-2616
CR Alotaibi M, 2017, SIGNAL IMAGE VIDEO P, V11, P1131, DOI 10.1007/s11760-017-1067-x
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bedagkar-Gala A., 2014, Asian Conference on Computer Vision, P633
   Binsaadoon Amer G., 2016, ICAART 2016. 8th International Conference on Agents and Artificial Intelligence. Proceedings, P314
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Bouchrika I., 2018, SURVEILLANCE ACTION, P3
   Chtourou I., 2017, INT C INT SYST DES A, P508
   Chtourou I, 2018, PROCEDIA COMPUT SCI, V126, P759, DOI 10.1016/j.procs.2018.08.010
   Connie T, 2017, IEEE T CYBERNETICS, V47, P1395, DOI 10.1109/TCYB.2016.2545693
   Fendri E, 2019, PATTERN ANAL APPL, V22, P1629, DOI 10.1007/s10044-019-00793-4
   Ghebleh A, 2018, MULTIMED TOOLS APPL, P1
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Imad R., 2017, Ph.D. thesis
   Iwashita Yumi, 2010, Proceedings of the 2010 International Conference on Emerging Security Technologies (EST 2010), P30, DOI 10.1109/EST.2010.19
   Jean F, 2009, IMAGE VISION COMPUT, V27, P1272, DOI 10.1016/j.imavis.2008.11.009
   Kumar JS, 2014, 2014 INTERNATIONAL CONFERENCE ON COMMUNICATION AND NETWORK TECHNOLOGIES (ICCNT), P1, DOI 10.1109/CNT.2014.7062712
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lee CP, 2015, J VIS COMMUN IMAGE R, V33, P69, DOI 10.1016/j.jvcir.2015.09.006
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Li W, 2018, NEUROCOMPUTING, V275, P1932, DOI 10.1016/j.neucom.2017.10.049
   Liang YL, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0126-5
   Lishani AO, 2017, SIGNAL IMAGE VIDEO P, V11, P1123, DOI 10.1007/s11760-017-1066-y
   Liu NN, 2013, J VIS COMMUN IMAGE R, V24, P439, DOI 10.1016/j.jvcir.2013.02.002
   López-Fernández D, 2016, J VIS COMMUN IMAGE R, V38, P396, DOI 10.1016/j.jvcir.2016.03.020
   López-Fernández D, 2016, IMAGE VISION COMPUT, V48-49, P1, DOI 10.1016/j.imavis.2016.01.003
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wei L, 2015, AAAI CONF ARTIF INTE, P1882
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Xu WJ, 2018, PATTERN RECOGN LETT, V107, P75, DOI 10.1016/j.patrec.2017.10.033
   Xu WJ, 2017, NEUROCOMPUTING, V224, P37, DOI 10.1016/j.neucom.2016.10.054
   Xu ZP, 2019, J VIS COMMUN IMAGE R, V59, P159, DOI 10.1016/j.jvcir.2019.01.023
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 43
TC 4
Z9 4
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
DI 10.1016/j.jvcir.2021.103093
EA MAR 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700003
DA 2024-07-18
ER

PT J
AU Chen, CC
   Chang, CC
   Chen, KM
AF Chen, Chih-Cheng
   Chang, Chin-Chen
   Chen, Kaimeng
TI High-capacity reversible data hiding in encrypted image based on Huffman
   coding and differences of high nibbles of pixels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; Huffman coding; High nibble
AB In this paper, we propose a new reversible data hiding method in encrypted images. Due to spatial correlation, there is a large probability that the adjacent pixels of the image have small differences, which is especially obvious on the high four most significant bits (high nibbles) of the pixels. If the high nibble of each pixel is regarded as a 4-bit value, the differences between the high nibbles of the adjacent pixels are mostly concentrated in a small range. Based on this fact, Huffman coding was used to encode all the differences between the high nibbles of the adjacent pixels in order to compress the four most significant bit (MSB) planes efficiently and create a large-capacity room. After creating room, a stream cipher is used to encrypt the image, and the room is reserved in the encrypted image for data hiding without losing information. The experimental results showed that the proposed method can achieve a larger embedding rate and better visual quality of the marked decrypted image than other related methods.
C1 [Chen, Kaimeng] Jimei Univ, Comp Engn Coll, Yinjiang Rd 185, Xiamen 361021, Peoples R China.
   [Chen, Chih-Cheng] Feng Chia Univ, Dept Automat Control Engn, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Chen, Chih-Cheng] Chaoyang Univ Technol, Dept Aeronaut Engn, Taichung 413310, Taiwan.
C3 Jimei University; Feng Chia University; Feng Chia University; Hangzhou
   Dianzi University; Chaoyang University of Technology
RP Chen, KM (corresponding author), Jimei Univ, Comp Engn Coll, Yinjiang Rd 185, Xiamen 361021, Peoples R China.
EM chenkaimeng@jmu.edu.cn
RI 陳, 志成/HSG-3635-2023; Chang, Ching-Chun/JAN-6210-2023; Zhao,
   Xuan/JMR-2135-2023
OI 陳, 志成/0000-0001-8723-6152; 
FU National Natural Science Foundation of China [U1936114]; Natural Science
   Foundation of Fujian Province, China [2020J01698]
FX Funding: This paper is supported by the National Natural Science
   Foundation of China (grant number U1936114) , and the Natural Science
   Foundation of Fujian Province, China (grant number 2020J01698) .
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Computer Vision Group, TEST IM DAT
   Crandall R., 1998, POSTED STEGANOGRAPHY
   Dragoi IC, 2017, EUR SIGNAL PR CONF, P2186, DOI 10.23919/EUSIPCO.2017.8081597
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2016, J VIS COMMUN IMAGE R, V40, P732, DOI 10.1016/j.jvcir.2016.08.020
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Nguyen TS, 2015, J VIS COMMUN IMAGE R, V33, P389, DOI 10.1016/j.jvcir.2015.10.008
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang YM, 2021, IEEE T MULTIMEDIA, V23, P1466, DOI 10.1109/TMM.2020.2999187
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 37
TC 11
Z9 12
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103060
DI 10.1016/j.jvcir.2021.103060
EA MAR 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700003
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, XC
   Li, ZQ
   Zhou, DK
AF Yang, Xin
   Li, Xiaochuan
   Li, Zhiqiang
   Zhou, Dake
TI Image super -resolution based on deep neural network of multiple
   attention mechanism *
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; CNN; Attention mechanism; Channel attention; Spatial
   attention
ID SUPERRESOLUTION
AB At present, the main super-resolution (SR) method based on convolutional neural network (CNN) is to increase the layer number of the network by skip connection so as to improve the nonlinear expression ability of the model. However, the network also becomes difficult to be trained and converge. In order to train a smaller but better performance SR model, this paper constructs a novel image SR network of multiple attention mechanism (MAMSR), which includes channel attention mechanism and spatial attention mechanism. By learning the relationship between the channels of the feature map and the relationship between the pixels in each position of the feature map, the network can enhance the ability of feature expression and make the reconstructed image more close to the real image. Experiments on public datasets show that our network surpasses some current state -of-the-art algorithms in PSNR, SSIM, and visual effects.
C1 [Yang, Xin; Li, Xiaochuan; Li, Zhiqiang; Zhou, Dake] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Yang, X (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
EM yangxin@nuaa.edu.cn; 1182784700@qq.com; zq.lee@nuaa.edu.cn;
   dkzhou@nuaa.edu.cn
FU National Natural Science Foundation of China [61573182]; Fundamental
   Research Funds for the Central Universities [NS2020025]
FX This research was supported by the National Natural Science Foundation
   of China (61573182) , and by the Fundamental Research Funds for the
   Central Universities (NS2020025) .
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cheng X, 2018, INT C PATT RECOG, P147, DOI 10.1109/ICPR.2018.8546130
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, INT C PATT RECOG, P2670, DOI 10.1109/ICPR.2018.8545648
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lehtinen J., 2017, ARXIV PREPRINT ARXIV
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   Liu Z., 2017, ARXIV PREPRINT ARXIV
   Lu Y, 2018, 2018 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2018.8489612
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Yu J., 2018, ARXIV PREPRINT ARXIV
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
   Zuo W., 2018, IEEE CONF COMPUT
NR 41
TC 19
Z9 20
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103019
DI 10.1016/j.jvcir.2021.103019
EA JAN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT8KH
UT WOS:000626836800001
DA 2024-07-18
ER

PT J
AU Li, CY
   Kong, LY
   Zhou, ZP
AF Li, Chunye
   Kong, Liya
   Zhou, Zhiping
TI Improved-StoryGAN for sequential images visualization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Story visualization; Weighted Activation Degree (WAD); Dilated
   Convolution; Gated Convolution
AB Story visualization is a novel and challenging topic that intersects computer vision and natural language processing, which needs to generate sequential images based on a story. It is related to text-to-image generation and video generation. Apart from ensuring the quality of the results, the synthesized images of story visualization are supposed to be consistent with each other and reflect the input story. In order to improve the performance of generated sequential images, we have developed the baseline model StoryGAN. Firstly, we use Dilated Convolution in the discriminators to expand the receptive field of the convolution kernel in the feature maps, thus enhancing the quality of the generated sequential images. In addition, Weighted Activation Degree (WAD) is introduced in the discriminators to provide a robust evaluation in view of similarity between the generated images and the target story, which results in enhancement on the consistency between the generated images and the target story. Last but not least, Bi-GRU stores the historical and future information of each sentence to effectively extract the textual features. What's more, in order to make full use of the features of the long story features, Gated Convolution is used to replace the original MLP in the Initial State Encoder to improve the consistence between the generated sequential images. Experimental results and visual sequential images demonstrate the outperformance of the model we develop, compared with the other models.
C1 [Li, Chunye; Kong, Liya; Zhou, Zhiping] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214100, Jiangsu, Peoples R China.
   [Zhou, Zhiping] Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214100, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Zhou, ZP (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214100, Jiangsu, Peoples R China.; Zhou, ZP (corresponding author), Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214100, Jiangsu, Peoples R China.
EM zzp@jiangnan.edu.cn
CR [Anonymous], 2016, ICLR
   [Anonymous], P 2018 C EMP METH NA
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Dinh L., 2015, P 3 INT C LEARN REPR
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Goodfellow I., P ADV NEUR INF PROC, P2672
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Kim KM, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2016
   Kingma Diederik P, 2018, P ADV NEUR INF PROC, P10236
   Kingma DP., 2014, C TRACK P
   Li Y., 2018, ARXIV181202784 CORR
   Li YT, 2018, AAAI CONF ARTIF INTE, P7065
   Marwah T, 2017, IEEE I CONF COMP VIS, P1435, DOI 10.1109/ICCV.2017.159
   Mathews A, 2018, PROC CVPR IEEE, P8591, DOI 10.1109/CVPR.2018.00896
   Mei S., P INT S INT SIGN PRO, P491, DOI [10. 1109/ISPACS.2017.8266528, DOI 10.1109/ISPACS.2017.8266528]
   Pan J., 2019, ARXIV190304480 CORR
   Reed S. E., 2016, ADV NEURAL INFORM PR, V29, P217
   Reed S, 2016, PR MACH LEARN RES, V48
   Su YH, 2019, NEUROCOMPUTING, V356, P151, DOI 10.1016/j.neucom.2019.04.044
   Vondrick C., 2016, ADV NEURAL INFORM PR, P613, DOI DOI 10.13016/M26GIH-TNYZ
   Wen ZT, 2019, APPL SOFT COMPUT, V76, P251, DOI 10.1016/j.asoc.2018.12.019
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Zeng G, 2019, CSAI 2019, P155
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
NR 27
TC 9
Z9 9
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102956
DI 10.1016/j.jvcir.2020.102956
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QO
UT WOS:000598558100004
DA 2024-07-18
ER

PT J
AU Zhang, HY
   Hou, YH
   Wang, PC
   Guo, ZH
   Li, WQ
AF Zhang, Haoyuan
   Hou, Yonghong
   Wang, Pichao
   Guo, Zihui
   Li, Wanqing
TI SAR-NAS: Skeleton-based action recognition via neural architecture
   searching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neural architecture search; Action recognition; Skeleton
AB This paper presents a study of automatic design of neural network architectures for skeleton-based action recognition. Specifically, we encode a skeleton-based action instance into a tensor and carefully define a set of operations to build two types of network cells: normal cells and reduction cells. The recently developed DARTS (Differentiable Architecture Search) is adopted to search for an effective network architecture that is built upon the two types of cells. All operations are 2D based in order to reduce the overall computation and search space. Experiments on the challenging NTU RGB+D and Kinectics datasets have verified that most of the networks developed to date for skeleton-based action recognition are likely not compact and efficient. The proposed method provides an approach to search for such a compact network that is able to achieve comparative or even better performance than the state-of-the-art methods.
C1 [Zhang, Haoyuan; Hou, Yonghong; Guo, Zihui] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Wang, Pichao] Alibaba Grp US Inc, DAMO Acad, Bellevue, WA 98004 USA.
   [Li, Wanqing] Univ Wollongong, Adv Multimedia Res Lab, Wollongong, NSW, Australia.
C3 Tianjin University; University of Wollongong
RP Wang, PC (corresponding author), Alibaba Grp US Inc, DAMO Acad, Bellevue, WA 98004 USA.
EM zhy0860@tju.edu.cn; houroy@tju.edu.cn; pw212@uowmail.edu.au;
   gzihui@tju.edu.cn; wanqing@uow.edu.au
RI hou, yonghong/N-9255-2013; Li, Wanqing/ABG-2620-2020
OI Li, Wanqing/0000-0002-4427-2687
FU National Natural Science Foundation of China [61571325]
FX This paper was supported by National Natural Science Foundation of China
   (No. 61571325).
CR Berretti S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3182179
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li CK, 2017, IEEE INT CONF MULTI
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu MY, 2018, IEEE T CIRC SYST VID, V28, P1824, DOI 10.1109/TCSVT.2017.2655521
   Pham H, 2018, PR MACH LEARN RES, V80
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang PF, 2018, AAAI CONF ARTIF INTE, P2005
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xiao RY, 2019, IEEE INT CON MULTI, P1060, DOI 10.1109/ICME.2019.00186
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Yan S., 2018, AAAI, P1
   Zhang B., 2017, KINETICS HUMAN ACTIO
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 43
TC 14
Z9 14
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102942
DI 10.1016/j.jvcir.2020.102942
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bai, C
   Chen, J
   Ma, Q
   Hao, PY
   Chen, SY
AF Bai, Cong
   Chen, Jian
   Ma, Qing
   Hao, Pengyi
   Chen, Shengyong
TI Cross-domain representation learning by domain-migration generative
   adversarial network for sketch based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sketch based image retrieval; Cross-domain learning; Generative
   adversarial learning; Similarity learning
ID CONVOLUTIONAL NEURAL-NETWORK
AB Sketch based image retrieval (SBIR), which uses free-hand sketches to search the images containing similar objects/scenes, is attracting more and more attentions as sketches could be got more easily with the development of touch devices. However, this task is difficult as the huge differences between sketches and images. In this paper, we propose a cross-domain representation learning framework to reduce these differences for SBIR. This framework aims to transfer sketches to images with the information learned both in the sketch domain and image domain by the proposed domain migration generative adversarial network (DMGAN). Furthermore, to reduce the representation gap between the generated images and natural images, a similarity learning network (SLN) is also proposed with the new designed loss function incorporating semantic information. Extensive experiments have been done from different aspects, including comparison with state-of-the-art methods. The results show that the proposed DMGAN and SLN really work for SBIR. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Bai, Cong; Chen, Jian; Ma, Qing; Hao, Pengyi] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
   [Ma, Qing] Zhejiang Univ Technol, Coll Sci, Hangzhou 310023, Peoples R China.
   [Chen, Shengyong] Tianjin Univ Technol, Sch Comp Sci & Engn, Tianjin 300384, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University of Technology;
   Tianjin University of Technology
RP Ma, Q (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
EM maqing@zjut.edu.cn
RI Bai, Cong/T-9188-2019; Chen, S./H-3083-2011
OI Bai, Cong/0000-0002-6177-3862; Chen, S.Y./0000-0002-6705-3831
FU National Key Research and Development Program of China [2018YFB1305200];
   Natural Science Foundation of China [61976192, 61801428]; Zhejiang
   Provincial Natural Science Foundation of China [LY18F020032,
   LY18F020034]
FX This research is funded by National Key Research and Development Program
   of China under Grant No. 2018YFB1305200, Natural Science Foundation of
   China under Grant No.61976192, 61801428, and Zhejiang Provincial Natural
   Science Foundation of China under Grant No. LY18F020032, LY18F020034.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2019, WORLD WIDE WEB, DOI DOI 10.1007/s11280-018-0541-x
   Bai C, 2018, NEUROCOMPUTING, V303, P60, DOI 10.1016/j.neucom.2018.04.034
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Bui T, 2017, COMPUT VIS IMAGE UND, V164, P27, DOI 10.1016/j.cviu.2017.06.007
   Bui T., 2016, ARXIV PREPRINT ARXIV
   Bui T, 2018, COMPUT GRAPH-UK, V71, P77, DOI 10.1016/j.cag.2017.12.006
   Chen ZX, 2018, J VIS COMMUN IMAGE R, V51, P112, DOI 10.1016/j.jvcir.2017.12.010
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo LT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1267, DOI 10.1145/3123266.3127939
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang L, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P97, DOI 10.1109/MIPR.2019.00025
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   King DB, 2015, ACS SYM SER, V1214, P1
   Lei JJ, 2017, IEEE IMAGE PROC, P3685, DOI 10.1109/ICIP.2017.8296970
   Li H., 2020, MULTIMEDIA MODELING, P381
   Li HJ, 2015, NEUROCOMPUTING, V169, P77, DOI 10.1016/j.neucom.2014.12.111
   Li K, 2019, IEEE T IMAGE PROCESS, V28, P3219, DOI 10.1109/TIP.2019.2895155
   Li Y, 2018, MACH VISION APPL, V29, P1083, DOI 10.1007/s00138-018-0953-8
   Ma Q, 2019, PATTERN RECOGN, V92, P156, DOI 10.1016/j.patcog.2019.03.022
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Reddy S.K., 2018, LECT NOTES COMPUTER, V11219, P316
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Seddati O, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P189, DOI 10.1145/3078971.3078985
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wu X, 2018, APPL INTELL, V48, P4485, DOI 10.1007/s10489-018-1223-1
   Xu D, 2018, IEEE T IMAGE PROCESS, V27, P4410, DOI 10.1109/TIP.2018.2837381
   Xu P, 2018, NEUROCOMPUTING, V278, P75, DOI 10.1016/j.neucom.2017.05.099
   Xu XL, 2020, IEEE T IND INFORM, V16, P6172, DOI 10.1109/TII.2019.2959258
   Yu D, 2018, NEUROCOMPUTING, V296, P23, DOI 10.1016/j.neucom.2018.03.031
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhang JL, 2018, GEOPHYS RES LETT, V45, P8665, DOI 10.1029/2018GL077787
   Zhang XL, 2018, NEUROCOMPUTING, V322, P38, DOI 10.1016/j.neucom.2018.09.047
NR 42
TC 9
Z9 10
U1 8
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102835
DI 10.1016/j.jvcir.2020.102835
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400006
DA 2024-07-18
ER

PT J
AU Lin, TL
   Liang, KW
   Huang, JY
   Tu, YL
   Chang, PC
AF Lin, Ting-Lan
   Liang, Kai-Wen
   Huang, Jing-Ya
   Tu, Yu-Liang
   Chang, Pao-Chi
TI Intra mode prediction for H.266/FVC video coding based on convolutional
   neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.266/Future Video Coding (FVC); Convolutional Neural Network (CNN);
   Intra mode
AB The next-generation video compression standard H.266/Future Video Coding (FVC) provides high compression efficiency in terms of the cost of computing the optimal intra mode from 67 modes. We propose an intra mode prediction method based on a convolutional neural network (CNN). An input image set of 20 x 20 blocks is used to train the CNN; the CNN is used to predict the best classes of intra mode direction. The CNN architecture comprises two convolutional layers and a fully connected layer. Compared with the default fast search method in FVC, the proposed method can achieve a 0.033% decrease in Bjontegaard delta bit rate (BDBR) with only a slight increase in time. (c) 2020 Published by Elsevier Inc.
C1 [Lin, Ting-Lan] Natl Taipei Univ Technol, Dept Elect Engn, Taipei 10608, Taiwan.
   [Liang, Kai-Wen; Huang, Jing-Ya; Tu, Yu-Liang; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, Taoyuan 320, Taiwan.
C3 National Taipei University of Technology; National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, Taoyuan 320, Taiwan.
EM pcchang@ce.ncu.edu.tw
RI YANG, DAN/KCL-5217-2024
FU Ministry of Science and Technology, Taiwan [MOST-105-2221-E-033-020,
   MOST-106-2221-E-033-010]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under grant numbers MOST-105-2221-E-033-020 and
   MOST-106-2221-E-033-010. This manuscript was edited by Wallace Academic
   Editing.
CR Chen J., 2015, SG16Q6 ITUT
   Chen JY, 2017, PHYS REV APPL, V7, DOI 10.1103/PhysRevApplied.7.021001
   Cui WX, 2017, IEEE DATA COMPR CONF, P436, DOI 10.1109/DCC.2017.53
   Hu YY, 2019, IEEE T MULTIMEDIA, V21, P3024, DOI 10.1109/TMM.2019.2920603
   Hu YY, 2018, IEEE DATA COMPR CONF, P413, DOI 10.1109/DCC.2018.00066
   Jin ZP, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Li JH, 2017, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2017.8296231
   Lin P.H., 2017, JVETE0078
   Suehring K., 2017, JOINT VID EXPL TEAM
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang Z, 2017, IEEE DATA COMPR CONF, P23, DOI 10.1109/DCC.2017.70
   Yamamoto T.I. Yoshiya, 2016, JVETD0095
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
NR 13
TC 1
Z9 1
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102686
DI 10.1016/j.jvcir.2019.102686
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900025
DA 2024-07-18
ER

PT J
AU Wang, XJ
   Qi, ML
   Shao, F
   Jiang, QP
   Meng, XC
AF Wang, Xuejin
   Qi, Meiling
   Shao, Feng
   Jiang, Qiuping
   Meng, Xiangchao
TI Blind quality assessment for multiply distorted stereoscopic images
   towards IoT-based 3D capture systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Internet of things; Image quality assessment; Multiply-distorted
   stereoscopic images; High order statistics
ID SIMILARITY; PREDICTION
AB Empowered by 5G mobile communication networks, multimedia processing has been considered as a very promising application of Internet-of-Things (IoT). Stereoscopic image quality assessment (SIQA), as an important part of 3D capture system, can be embedded in the cloud or fog servers to automatically monitor the perceptual quality of the collected stereoscopic images. In this paper, a novel blind image quality assessment method towards IoT-based 3D capture systems is developed for multiply-distorted stereoscopic images (MDSIs), in which five complementary channels, including left view, right view, cyclopean map, summation map and difference map, are jointly considered in dictionary learning for characterizing the monocular receptive field (MRF) and binocular receptive field (BRF) properties of the visual cortex in response to MDSIs. Additionally, the high order statistics scheme is adopted by utilizing the statistical differences between the codebook and images to ensure the stable and robust quality prediction performance for MDSIs. The proposed method shows competitive prediction performances on four benchmark databases compared with the existing SIQA metrics.
C1 [Wang, Xuejin; Qi, Meiling; Shao, Feng; Jiang, Qiuping; Meng, Xiangchao] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM shaofeng@nbu.edu.cn
RI Jiang, Qiuping/AAL-8273-2020; Qi, Mei/JPL-3517-2023
FU Natural Science Foundation of China [R18F010008]; K.C. Wong Magna Fund
   in Ningbo University
FX This work was supported by the Natural Science Foundation of China
   (grant 61622109, 61901236, 41801252), and Natural Science Foundation of
   China (grant R18F010008). It was also sponsored by K.C. Wong Magna Fund
   in Ningbo University.
CR Aazam M, 2019, IEEE T IND INFORM, V15, P3085, DOI 10.1109/TII.2019.2902574
   Adiththan A, 2019, IEEE 17TH INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP / IEEE 17TH INT CONF ON PERVAS INTELLIGENCE AND COMP / IEEE 5TH INT CONF ON CLOUD AND BIG DATA COMP / IEEE 4TH CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P687, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00130
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Bensalma R, 2013, MULTIDIM SYST SIGN P, V24, P281, DOI 10.1007/s11045-012-0178-3
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Jiang QP, 2019, IEEE T IMAGE PROCESS, V28, P1866, DOI 10.1109/TIP.2018.2881828
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Jiang QP, 2018, PATTERN RECOGN, V76, P242, DOI 10.1016/j.patcog.2017.11.001
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Li YQ, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P123, DOI 10.1109/ICMIP.2017.61
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu LX, 2017, SIGNAL PROCESS-IMAGE, V58, P287, DOI 10.1016/j.image.2017.08.011
   Liu XG, 2020, IEEE T CLOUD COMPUT, V8, P326, DOI 10.1109/TCC.2015.2513397
   Lu YA, 2015, IEEE SIGNAL PROC LET, V22, P1811, DOI 10.1109/LSP.2015.2436908
   Lyu SW, 2008, PROC CVPR IEEE, P3721
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Read JCA, 2019, J VISION, V19, DOI 10.1167/19.6.7
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2018, IEEE T MULTIMEDIA, V20, P2605, DOI 10.1109/TMM.2018.2817072
   Shao F, 2017, IEEE T MULTIMEDIA, V19, P1821, DOI 10.1109/TMM.2017.2685240
   Shao F, 2016, IEEE T MULTIMEDIA, V18, P2104, DOI 10.1109/TMM.2016.2594142
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shi CH, 2014, ADV SOC BEHAV SCI, V6, P23, DOI 10.5729/asbs.vol6.23
   Su CC, 2015, IEEE T IMAGE PROCESS, V24, P1685, DOI 10.1109/TIP.2015.2409558
   Wang CJ, 2020, IEEE T IND INFORM, V16, P2667, DOI 10.1109/TII.2019.2945362
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   Yang J.-C., 2009, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video, P1
   Yang JC, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2791560
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
NR 52
TC 2
Z9 2
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102868
DI 10.1016/j.jvcir.2020.102868
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000004
DA 2024-07-18
ER

PT J
AU Guo, LY
   Xie, H
   Li, Y
AF Guo, Leiyong
   Xie, Hui
   Li, Yu
TI Data encryption based blockchain and privacy preserving mechanisms
   towards big data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blockchain; Data encryption; Privacy preserving; Big data
AB Blockchain is a key technique which can support Bitcoin. Blockchain is a decentralized infrastructure that uses chained data structure to verify and store data, and uses distributed node consensus mechanism to generate and update data. Blockchain has become a hot research topic since its attributes of decentralization, verifiability and anti-tampering. To stimulate the development of Blockchain, we conduct a comprehensive research on Blockchain. Specifically, we discuss various mainstream consensus mechanisms used in blockchain technology, and thoroughly analyze anonymity and privacy protection in digital currency. Aiming at data encryption mechanism, we discuss existing anonymity and privacy protection schemes. Our discussion can further promote the development of Blockchain. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Guo, Leiyong; Li, Yu] Guandong Pharmaceut Univ, Coll Med Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Xie, Hui] XiangNan Univ, Sch Software & Commun Engn, Chenzhou 423000, Hunan, Peoples R China.
C3 Guangdong Pharmaceutical University; Xiangnan University
RP Xie, H (corresponding author), XiangNan Univ, Sch Software & Commun Engn, Chenzhou 423000, Hunan, Peoples R China.
RI Xie, Hui/ACL-9395-2022
FU Research and Implementation of Internet+Chinese Medicine Standard
   Revised Cloud Service Platform [A2019486]
FX This study is supported by Research and Implementation of
   Internet+Chinese Medicine Standard Revised Cloud Service Platform (No.
   A2019486).
CR [Anonymous], 2016, PROC WORKSHOP DISTRI
   [Anonymous], 2011, IN WORLD EC FOR
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Boyd C, 2016, LECT NOTES COMPUT SC, V9722, P161, DOI 10.1007/978-3-319-40253-6_10
   Buterin V., 2014, CISC VIS NETW IND GL, V3, P1, DOI DOI 10.1145/2939672.2939785
   Cuende Luis Ivan, 2017, U.S. Patent, Patent No. [9,679,276, 9679276]
   Graham G.S., 1972, SPRING JOINT COMP C
   Herbert J., 2015, AUSTR COMP SCI C
   Lansiti M, 2017, HARVARD BUS REV, V95, P119
   Li M, 2019, IEEE T PARALL DISTR, V30, P1251, DOI 10.1109/TPDS.2018.2881735
   Liang XP, 2017, IEEE ACM INT SYMP, P468, DOI 10.1109/CCGRID.2017.8
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Narayanan Arvind, 2006, CS0610105 ARXIV
   Olnes S, 2017, GOV INFORM Q, V34, P355, DOI 10.1016/j.giq.2017.09.007
   SANDHU RS, 1993, COMPUTER, V26, P9, DOI 10.1109/2.241422
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2016, NEUROCOMPUTING, V195, P117, DOI 10.1016/j.neucom.2015.08.117
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 25
TC 18
Z9 20
U1 9
U2 66
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102741
DI 10.1016/j.jvcir.2019.102741
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900005
DA 2024-07-18
ER

PT J
AU Chen, Y
   Hu, RM
   Xiao, J
   Wang, ZY
AF Chen, Yu
   Hu, Ruimin
   Xiao, Jing
   Wang, Zhongyuan
TI Multisource surveillance video coding with synthetic reference frame
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Surveillance video coding; Global knowledge; Local information;
   Reference frame
ID HEVC; PREDICTION
AB Due to the increasing growth of surveillance data, high-efficiency surveillance video coding schemes are demanded. However, the existing conventional coding framework has difficulties in handling rotation and zooming whilst the recently proposed multisource surveillance video coding method is inflexible and prone to be affected by pose errors. To this end, we propose to combine conventional surveillance video coding and multisource surveillance video coding into one unified framework. First, global knowledge in the form of 3D model and initial textures is employed to construct a knowledge based reference frame. Meanwhile, a temporal reference frame is also generated from the reconstructed frames in decoded picture buffer. Then, they are fused to obtain the synthetic reference frame to exploit global and local information. Finally, we add the synthetic reference frame into reference picture list and rearrange the list to optimize the overall efficiency. Experimental results demonstrate the effectiveness of the proposed method over state-of-the-art anchors. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Yu; Wang, Zhongyuan] Wuhan Univ, Natl Engn Res Ctr Multimeida Software, Sch Comp, Wuhan 430072, Hubei, Peoples R China.
   [Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Hubei, Peoples R China.
   [Xiao, Jing] Wuhon Univ, Suzhou Inst, Nanjing 215123, Jiangsu, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Hubei, Peoples R China.
EM chenyu_whu@163.com; hrm@whu.edu.cn; jing@whu.edu.cn; wzy_hope@163.com
RI Wang, Zhongyuan/ABD-2189-2020
FU National Natural Science Foundation of China [61671336, 91738302];
   National Key R&D Program of China [2018YFB1201602]; Natural Science
   Foundation of Jiangsu Province [BK 20180234]; Hubei Province
   Technological Innovation Major Project [2017AAA123]
FX This work was supported by the National Natural Science Foundation of
   China (U1736206), the National Key R&D Program of China
   (2018YFB1201602), the Natural Science Foundation of Jiangsu Province (BK
   20180234), the National Natural Science Foundation of China (61671336,
   91738302) and the Hubei Province Technological Innovation Major Project
   (2017AAA123).
CR AIZAWA K, 1995, P IEEE, V83, P259, DOI 10.1109/5.364463
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2003 INT C MULT EXP
   [Anonymous], 2005, FOUND RES TECHNOL
   Asikuzzaman M, 2018, PICT COD SYMP, P228, DOI 10.1109/PCS.2018.8456287
   Babu R.V., 2006, 2006 9 INT C CONTROL, P1
   Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126
   Bjontegaard G., 2001, Document VCEG-M33
   Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366
   Chen C., 2012, P 20 ACM INT C MULT, P713, DOI DOI 10.1145/2393347.2396294
   Chen FD, 2017, IEEE T CIRC SYST VID, V27, P2639, DOI 10.1109/TCSVT.2016.2593599
   Chen Y, 2015, LECT NOTES COMPUT SC, V9314, P711, DOI 10.1007/978-3-319-24075-6_68
   Choi JA, 2015, SIGNAL IMAGE VIDEO P, V9, P1055, DOI 10.1007/s11760-013-0545-z
   Guo XQ, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON MATERIAL SCIENCE AND ENVIRONMENTAL ENGINEERING (MSEE 2013), P546
   Hakeem A., 2005, 13th Annual ACM International Conference on Multimedia, P608, DOI 10.1145/1101149.1101289
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724
   Ma CY, 2017, IEEE IMAGE PROC, P270, DOI 10.1109/ICIP.2017.8296285
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Ma MS, 2015, LECT NOTES COMPUT SC, V9314, P223, DOI 10.1007/978-3-319-24075-6_22
   Meher PK, 2014, IEEE T CIRC SYST VID, V24, P168, DOI 10.1109/TCSVT.2013.2276862
   Mofaddel M. A., 2011, Proceedings of the 2011 International Conference on Computer Engineering & Systems (ICCES 2011), P245, DOI 10.1109/ICCES.2011.6141051
   Ng KT, 2010, IEEE T CIRC SYST VID, V20, P548, DOI 10.1109/TCSVT.2010.2041820
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Qi Wang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P285, DOI 10.1007/978-3-319-48890-5_28
   Soyak E, 2011, IEEE T CIRC SYST VID, V21, P1378, DOI 10.1109/TCSVT.2011.2163448
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Taj-Eddin IATP, 2016, INT CONF DIGIT INFO, P159, DOI 10.1109/DICTAP.2016.7544020
   Tsai TH, 2012, IEEE T MULTIMEDIA, V14, P669, DOI 10.1109/TMM.2011.2180705
   Venkatraman D, 2009, INT CONF ACOUST SPEE, P3513, DOI 10.1109/ICASSP.2009.4960383
   Wang HH, 2005, IEEE T CIRC SYST VID, V15, P1113, DOI 10.1109/TCSVT.2005.852629
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao J, 2016, IEEE T MULTIMEDIA, V18, P1691, DOI 10.1109/TMM.2016.2581590
   Xiao J, 2015, IEEE DATA COMPR CONF, P33, DOI 10.1109/DCC.2015.37
   Xiao J, 2015, CLUSTER COMPUT, V18, P531, DOI 10.1007/s10586-015-0434-z
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P4511, DOI 10.1109/TIP.2014.2352036
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P769, DOI 10.1109/TIP.2013.2294549
   Zhang XG, 2013, IEEE T MULTIMEDIA, V15, P1769, DOI 10.1109/TMM.2013.2280117
NR 39
TC 4
Z9 4
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102685
DI 10.1016/j.jvcir.2019.102685
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700021
DA 2024-07-18
ER

PT J
AU Fan, XJ
   Tjahjadi, T
AF Fan, Xijian
   Tjahjadi, Tardi
TI Fusing dynamic deep learned features and handcrafted features for facial
   expression recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; Facial expression recognition; Feature
   extraction
ID FACE
AB The automated recognition of facial expressions has been actively researched due to its wide-ranging applications. The recent advances in deep learning have improved the performance facial expression recognition (FER) methods. In this paper, we propose a framework that combines discriminative features learned using convolutional neural networks and handcrafted features that include shape- and appearance-based features to further improve the robustness and accuracy of FER. In addition, texture information is extracted from facial patches to enhance the discriminative power of the extracted textures. By encoding shape, appearance, and deep dynamic information, the proposed framework provides high performance and outperforms state-of-the-art FER methods on the CK+ dataset. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Fan, Xijian] Nanjing Forestry Univ, Dept Comp Sci, Nanjing 210037, Jiangsu, Peoples R China.
   [Tjahjadi, Tardi] Univ Warwick, Sch Engn, Coventry, W Midlands, England.
C3 Nanjing Forestry University; University of Warwick
RP Fan, XJ (corresponding author), Nanjing Forestry Univ, Dept Comp Sci, Nanjing 210037, Jiangsu, Peoples R China.
EM xijian.fan@njfu.edu.cn; t.tjahjadi@warwick.ac.uk
RI Fan, Xijian/GRR-2740-2022
OI Fan, Xijian/0000-0002-7017-7667
FU National Science Foundation of China [61902187]; Jiangsu Province
   Innovative and Entrepre-neurial Talent Project; Nanjing Forestry
   University Start-up Foundation for Research
FX The work is supported by National Science Foundation of China (Grant No.
   61902187), Jiangsu Province Innovative and Entrepre-neurial Talent
   Project and Nanjing Forestry University Start-up Foundation for
   Research.
CR [Anonymous], 2015, 2015 International Joint Conference on Neural Networks (IJCNN)
   [Anonymous], 2010, CHAPTER AFFECTIVE CO
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Connie Tee, 2017, Multi-disciplinary Trends in Artificial Intelligence. 11th International Workshop, MIWAI 2017. Proceedings: LNAI 10607, P139, DOI 10.1007/978-3-319-69456-6_12
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Fan XJ, 2018, J VIS COMMUN IMAGE R, V56, P182, DOI 10.1016/j.jvcir.2018.09.011
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li JH, 2015, IEEE ASME INT C ADV, P1, DOI 10.1109/AIM.2015.7222499
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Martinez Brais, 2019, IEEE Transactions on Affective Computing, V10, P325, DOI 10.1109/TAFFC.2017.2731763
   Nguyen D, 2017, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2017.140
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sriman B, 2019, J VIS COMMUN IMAGE R, V62, P23, DOI 10.1016/j.jvcir.2019.04.007
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 36
TC 30
Z9 30
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102659
DI 10.1016/j.jvcir.2019.102659
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700013
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Su, GD
   Liu, YJ
   Chang, CC
AF Su, Guo-Dong
   Liu, Yanjun
   Chang, Chin-Chen
TI A square lattice oriented reversible information hiding scheme with
   reversibility and adaptivity for dual images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dual-image; Reversible information hiding; Embedding rate; Histogram
   shifting; Real-time
ID DIFFERENCE EXPANSION
AB This paper proposes an adaptive dual-image-based reversible information hiding scheme. First, for a pixel pair in the original image, an associated square lattice is selected to determine the maximum distortion that will be induced by hiding information. Then, an embedding rule, which combines the selected square lattice with integer rounding, is constructed. In addition, a novel histogram shifting mechanism to solve the problems of overflow and underflow is designed to decrease the distortions that are caused by the shifting of a large number of pixels. In our approach, both the original image and the secret messages can be recovered losslessly. Our experimental results show that the proposed scheme achieved performance that was superior to the state-of-the-art schemes, resulting in embedding rates up to 1.40 bpp and average PSNRs of approximately 47.60 dB. The proposed scheme also can be used in real-time systems due to the simplicity of its computations. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Su, Guo-Dong] Fujian Normal Univ, Fuqing Branch, Sch Elect & Informat Engn, Fuzhou 350300, Fujian, Peoples R China.
   [Su, Guo-Dong; Liu, Yanjun; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Su, Guo-Dong] Fujian Univ, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou, Fujian, Peoples R China.
C3 Fujian Normal University; Feng Chia University
RP Liu, YJ (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM yjliu104@gmail.com
RI 刘, 严君/GZL-5764-2022; liu, yan/HGV-1365-2022; liu, yan/HCI-5542-2022;
   Chang, Ching-Chun/JAN-6210-2023
OI Su, Guodong/0000-0002-3050-7166
FU Education-Scientific Research Project for Middle-aged and Young of
   Fujian Province [JAT160574, JT180621]; Project of Ministry of Science
   and Technology of Taiwan [MOST 106-2221-E-035-013-MY3]
FX This work was supported in part by the Education-Scientific Research
   Project for Middle-aged and Young of Fujian Province under Grant Nos.
   JAT160574 and JT180621, and the Project of Ministry of Science and
   Technology of Taiwan under Grant No. MOST 106-2221-E-035-013-MY3.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   LENNON RE, 1978, IBM SYST J, V17, P138, DOI 10.1147/sj.172.0138
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin JY, 2019, J REAL-TIME IMAGE PR, V16, P673, DOI 10.1007/s11554-019-00863-0
   Liu YJ, 2018, MULTIMED TOOLS APPL, V77, P25295, DOI 10.1007/s11042-018-5785-z
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   PACHGHARE V., 2015, Cryptography and information security, V2 edn
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Tian J., 2002, P WORKSH MULT SEC JU
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Yao H, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0281-y
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
NR 33
TC 15
Z9 15
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102618
DI 10.1016/j.jvcir.2019.102618
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600006
DA 2024-07-18
ER

PT J
AU Cao, ZC
   Zhang, LL
AF Cao Zhi-chao
   Zhang, Lingling
TI Key pose recognition toward sports scene using deeply-learned model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Image processing; Motion model; Image quality
ID UNIQUENESS; MOTION
AB Key pose recognition (KPR) is widely used in sport analysis, which provides effective tools for coaches, athletes and other professionals to conduct game analysis and auxiliary training. KPR from video stream can be divided into individual-oriented and group-oriented. The former method is based on the segmentation and tracking of each target, and the characteristics of the individual are used to study the events in the group. The latter is to process and sample the global image, obtain the overall information, and then process the collected data to classify the abnormal situation and normal situation. In this paper, we propose key pose recognition method based on deep learning. Specifically, we first train an FCN network for foreground extraction with weightlifting video frame images to remove a large amount of background interference in the weightlifting video image. Further, by fine-tuning the CNN network, a network model suitable for the weight-of-weight video classification of the region of interest is obtained. Finally, according to the classification result, the classification result selection strategy is designed to extract the key pose. In addition, our algorithm can select high image quality key pose frame, which is important for sports training. The experimental results show that the proposed method is very competitive. (C) 2019 Published by Elsevier Inc.
C1 [Cao Zhi-chao] Shanghai Univ Sports, Sch Phys Educ & Coaching, Shanghai, Peoples R China.
   [Zhang, Lingling] Shanghai Univ Finance & Econ, Phys Educ Dept, Shanghai, Peoples R China.
C3 Shanghai University of Sport; Shanghai University of Finance & Economics
RP Zhang, LL (corresponding author), Shanghai Univ Finance & Econ, Phys Educ Dept, Shanghai, Peoples R China.
EM caozhichao@sus.edu.cn; zhang.lingling@mail.shufe.edu.cn
RI zhang, lingling/HDM-2189-2022
CR Alcocer E, 2019, J REAL-TIME IMAGE PR, V16, P547, DOI 10.1007/s11554-016-0572-4
   Alioscha-Perez Mitchel, 2014, REMOTE SENS, V6, P6765
   Amara A. B., 2017, DES TEST S
   Ammar A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160305
   [Anonymous], IEEE SENS J
   Aoki Y., 2015, P SOC PHOTO-OPT INS, P9534
   Bo L, 2018, CLUSTER COMPUT, V1, P1
   CHARAYAPHAN C, 1992, J BIOMED ENG, V14, P419, DOI 10.1016/0141-5425(92)90088-3
   Chi X., 2016, INT J COMPUT VISION, V123, P1
   Crewther B. T., 2016, PEDIA EXERC SCI, V28, P1
   Durguerian A., 2017, J SPORTS SCI, P1
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Garcia RV, 2016, COMPUT APPL MATH, V35, P835, DOI 10.1007/s40314-015-0269-5
   Guo RN, 2017, APPL MATH COMPUT, V311, P100, DOI 10.1016/j.amc.2017.05.021
   He LM, 2017, J FUNCT SPACE, V2017, DOI 10.1155/2017/1465623
   Hu QY, 2018, ADV COMPUT MATH, V44, P245, DOI 10.1007/s10444-017-9542-z
   Huang J, 2015, ROBOT AUTON SYST, V73, P24, DOI 10.1016/j.robot.2014.11.013
   Kipp K., 2015, J SPORTS SCI, V33, P1
   Liu B, 2016, TAIDA J ART HIST, P1, DOI 10.6541/TJAH.2016.03.40.01
   Liu CH, 2017, ACTA MATH APPL SIN-E, V33, P771, DOI 10.1007/s10255-017-0697-7
   Liu F, 2017, ROCKY MT J MATH, V47, P1617, DOI 10.1216/RMJ-2017-47-5-1617
   Liu F, 2017, J MATH INEQUAL, V11, P1075, DOI 10.7153/jmi-2017-11-81
   Poddar S, 2016, INT J INTELL UNMANNE, V4, P23, DOI 10.1108/IJIUS-05-2015-0005
   Qiu ZB, 2018, CHINESE J AERONAUT, V31, P806, DOI 10.1016/j.cja.2018.01.023
   Rong S, 2016, ENERGIES, V9, DOI 10.3390/en9010017
   Sensakovic W. F., 2016, PEDIATR RADIOL, V46, P1
   Takahashi K., 2015, SYST COMPUT JPN, V31, P1
   Travis SK, 2018, SPORTS, V6, DOI 10.3390/sports6020046
   Wang ZD, 2014, ADV MATER RES-SWITZ, V1049, P1947, DOI 10.4028/www.scientific.net/AMR.1049-1050.1947
   Yamaguchi Y, 2016, PROCEDIA COMPUT SCI, V96, P1059, DOI 10.1016/j.procs.2016.08.128
   Yuefeng X. U., 2015, COMPUT ENG, V22, P1131
   Zhang YM, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501486
   Zhao Jianwei, 2014, Journal of Xi'an Jiaotong University, V48, P36, DOI 10.7652/xjtuxb201408007
   Zou YM, 2017, J FUNCT SPACE, V2017, DOI 10.1155/2017/4946198
   Zou YM, 2017, APPL MATH LETT, V74, P68, DOI 10.1016/j.aml.2017.05.011
NR 35
TC 8
Z9 8
U1 1
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102571
DI 10.1016/j.jvcir.2019.06.013
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200003
DA 2024-07-18
ER

PT J
AU Wei, GH
   Sheng, Z
AF Wei, Guanghui
   Sheng, Zhou
TI Image quality assessment for intelligent emergency application based on
   deep neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Entropy theory; Big data; Wisdom emergency; Quality model; Neural
   network
AB Video surveillance is widely applied in modern intelligent systems, such as access control, pedestrian re-identification. However, with the rapid development of urbanization, urban traffic situation becomes more and more complex. It is a big challenge for video surveillance to cope with such massive data. In addition, existing emergency systems are far from modern requirement. So in this paper, we propose an image quality based framework to improve the performance of video surveillance and design a new urban intelligent emergency system. Specifically, we first analyze emergency evacuation of social group security incident for data acquisition including surveillance video and labels. Then, incorporating image quality assessment and convolution neural network, the dataset can be classified into several parts, and each part demonstrates a particular situation. Afterward, we introduce entropy theory to study the application of urban intelligence emergency. The results show that the research method proposed in this paper effectively obtains the evacuation parameters of evacuation personnel in the evacuation of sudden social group events, and improves the timeliness of information transmission in the evacuation process. The results show that the research method of this paper significantly improves the pertinence, effectiveness and perfection of the emergency plan in the application of urban emergency system. (C) 2019 Published by Elsevier Inc.
C1 [Wei, Guanghui] ChongQing Coll Elect Engn, Chongqing, Peoples R China.
   [Sheng, Zhou] Wuhan Donghu Univ, Sch Management, Wuhan, Hubei, Peoples R China.
C3 Chongqing College of Electronic Engineering; Wuhan Donghu University
RP Sheng, Z (corresponding author), Wuhan Donghu Univ, Sch Management, Wuhan, Hubei, Peoples R China.
EM dafengqi32@126.com
RI zhang, ling/JXW-6931-2024
CR [Anonymous], 2016, RES CONSTR METH EFF
   [Anonymous], 2015, Patent No. [CN104484774A, 104484774A]
   [Anonymous], 2015, GEN UNC REL BLACK HO
   [Anonymous], 2017, ANAL USER CHARACTERI
   Brynielsson J, 2007, DECIS SUPPORT SYST, V43, P1454, DOI 10.1016/j.dss.2006.06.012
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cui YJ, 2016, APPL MATH LETT, V51, P48, DOI 10.1016/j.aml.2015.07.002
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   He B, 2013, J APPL MATH, DOI 10.1155/2013/183159
   Li Di, 2017, SCI TECHNOL J ELECT, V5, P127
   Liu Liyuan, 2017, LABOR SECURITY WORLD, P24
   Liu Qiang, 2015, J ZUNYI NORMAL COLL, V17, P32
   Liu Wei, 2010, J TSINGHUA U SCI TEC, V50, P165
   Ma Fei, 2017, SOFTWARE, V38, P132
   Meng XZ, 2016, J MATH ANAL APPL, V433, P227, DOI 10.1016/j.jmaa.2015.07.056
   Qu Xinhuai, 2011, COMBINED MACH TOOL A, V43, P42
   Reuter C, 2009, INT J EMERG MANAG, V6, P356, DOI 10.1504/IJEM.2009.031571
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Su GH, 2015, SPIN-SINGAPORE, V5, DOI 10.1142/S2010324715400111
   Sun Huijuan, 2007, J BEIJING UNION U NA, V21, P1
   [孙立 SUN Li], 2007, [安全与环境学报, Journal of Safety and Environment], V7, P124
   Swanson M., 2002, 80034 NIST, P800
   Wang Dongming, 2008, J NAT DISASTERS, V17
   [王飞跃 Wang Feiyue], 2010, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V7, P1
   Wang Haifeng, 2016, IND TECHNOL FORUM, V15, P20
   [王庆全 WANG Qing-quan], 2010, [运筹与管理, Operations Research and Management Science], V19, P21
   Weaver C., 2007, INFORM VISUALIZ, V2, P25
   Wen Li, 2010, J INTELLIGENCE, V29, P131
   Wenjuan Han, 2017, ENERGY ENV, V4, P32
   Xu ML, 2017, J COMPUT SCI TECH-CH, V32, P1162, DOI 10.1007/s11390-017-1791-2
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Yin C, 2016, COMPLEXITY, V21, P363, DOI 10.1002/cplx.21696
   Zheng Qibin, 2017, J COMPUT SCI, V44, P58
   Zhou Liqian, 2010, J WUXI I COMMERCE TE, V10, P109
   Zou Hai, 2007, SEEKING, V8
NR 38
TC 3
Z9 3
U1 3
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102581
DI 10.1016/j.jvcir.2019.102581
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200014
DA 2024-07-18
ER

PT J
AU Cai, W
   Wen, XD
   Tu, Q
   Guo, XJ
AF Cai, Wei
   Wen, Xiaodong
   Tu, Qiu
   Guo, Xiujuan
TI Research on image processing of intelligent building environment based
   on pattern recognition technology
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intelligent building; Image processing; Satellite imagery; Building
   contours; Edge detection
ID OBJECTS; DEEP
AB With the continuous development of urbanization, urban population, economy and other factors have a close impact on the geometry and distribution of urban buildings. Obtaining information of urban buildings from aerial images or satellite images quickly and accurately is not only conducive to updating geospatial data, but also of great significance for effective monitoring of new thematic information such as new buildings. Moreover, in recent years, the research and improvement of building recognition and contour extraction algorithms based on satellite images or aerial images are helpful to the recognition and classification of urban buildings. It is of great significance to the acquisition of GIS data, the understanding of images, large-scale mapping and many other applications of remote sensing data. With the development of artificial intelligence and computer technology, the image processing of intelligent building environment based on pattern recognition technology has become an important research direction in the field of intelligent building image recognition. Based on the concept, principle and technology analysis of pattern recognition technology, this paper studies the application of pattern recognition technology in the image processing of intelligent building environment. In this paper, based on image processing of intelligent building as the basic theoretical platform, with the pattern recognition technology as the basic research means, three problems of image processing, image extraction and image recognition in image processing of building intelligent environment are studied respectively, and corresponding reasonable solutions are put forward. (C) 2019 Published by Elsevier Inc.
C1 [Cai, Wei; Wen, Xiaodong; Tu, Qiu; Guo, Xiujuan] Ningbo Univ Technol, Sch Civil & Transportat Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University of Technology
RP Cai, W (corresponding author), Ningbo Univ Technol, Sch Civil & Transportat Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM caiwei@nbut.edu.cn; wenxiaodong@nbut.cn
FU Zhejiang Provincial Natural Science Foundation of China [LY15E080016];
   Beijing Key Lab of Heating, Gas Supply, Ventilating and Air Conditioning
   Engineering [NR2015K07]; Ningbo Natural Science Foundation [2016A610113]
FX This research was supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LY15E080016 and funded by Beijing
   Key Lab of Heating, Gas Supply, Ventilating and Air Conditioning
   Engineering (No. NR2015K07). Programs supported by Ningbo Natural
   Science Foundation (No. 2016A610113).
CR [Anonymous], 2018, MULTIATTENTION MULTI
   Cao  J., 2018, IMPLEMENTING IMPLEME
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Chikmurge  D., 2018, FEATURE EXTRACTION D
   Cieslewski  T., 2018, EFFICIENT DECENTRALI
   Ding  X., 2018, ELECT TEST
   Gaurav  K., 2018, IMAGE STEGANOGRAPHY
   Grm  K., 2018, STRENGTHS STRENGTHS, V7, P1
   Guo  W., 2018, ELECT TEST
   Hai-Chuan Y. U., 2018, SOFTWARE GUIDE
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang  Wei, 2018, TELECOM POWER TECHNO
   Juan D. U., 2018, IMAGE RECOGNITION BA
   Jun-Hua X. U., 2018, CONTROL ENG CHINA
   Konar  A., 2018, IEEE INT C FUZZ SYST, P1
   Kong X. L., 2018, HEILONGJIANG SCI
   Li HY, 2017, ACTA MATH APPL SIN-E, V33, P1043, DOI 10.1007/s10255-017-0718-6
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Liu F, 2017, ROCKY MT J MATH, V47, P1617, DOI 10.1216/RMJ-2017-47-5-1617
   Liu  H., 2018, MANAGE TECHNOL SME
   Liu Qian, 2018, INTELL BUILD SMART C
   Qiao S., 2018, DEEP COTRAINING SEMI
   Qiao  S., 2018, GRADUALLY UPDATED NE
   Shi Y. Z., 2018, ELECT DES ENG
   Tahmid Taqi, DENSITY BASED SMART
   Wang F. Y., APPL INTELLIGENT BUI
   Yang  F., 2018, CONSTRUCT DES ENG
   Yingjiu L. I., 2018, APPL INTELLIGENT BUI
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang YL, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/621264
   Zhao A. C., 2018, DESIGN HARDWARE IMPL
   Zhou DM, 2017, J POWER SOURCES, V366, P278, DOI 10.1016/j.jpowsour.2017.08.107
   Zhu JG, 2019, ADV DIFFER EQU-NY, DOI 10.1186/s13662-018-1908-0
   Zhu JG, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.022006
   2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI DOI 10.1109/TGRS.2014.2374218
NR 43
TC 12
Z9 12
U1 3
U2 63
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 141
EP 148
DI 10.1016/j.jvcir.2019.03.014
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100015
DA 2024-07-18
ER

PT J
AU Ibn Afjal, M
   Al Mamun, M
   Uddin, MP
AF Ibn Afjal, Masud
   Al Mamun, Md.
   Uddin, Md. Palash
TI Band reordering heuristics for lossless satellite image compression with
   3D-CALIC and CCSDS
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Satellite image; Lossless compression; Band reordering; CCSDS;
   Correlation exploitation; 3D-CALIC
AB Remote sensing satellite images are used widely in space imaging applications as they collect significant information of ground objects through capturing the ground surface in immense wavelength bands. The size of these images is typically enormous in quantity due to the bulky number of capturing wavelengths. The images need to transmit to the ground from the sensors for a specific application. Thus, the efficient compression techniques are required to fit the available bandwidth for reducing the transmission time. The data in the images are usually redundant spatially, spectrally and temporally which give an ample opportunity to compress the images in various domains. Most importantly, the data features have a strong correlation in the separate spectral area. As a result, the similarity-based band reordering strategy is used to increase the compression performance in comparison to the image having natural band order. However, finding the optimal band reordering is still a computationally challenging problem. In this paper, three different methods namely Band Reordering based on Consecutive Continuity Breakdown Heuristics (BRCCBH), Band Reordering based on Weighted-Correlation Heuristic (BRWCH) and Segmented BRCCBH have been proposed for the compression of multispectral, hyperspectral and hyper spectral sounder data. The presented methods are different on the number and type of heuristics used for obtaining the optimal band reordering. The performances of the proposed band reordering methods are tested using CCSDS 123 lossless predictor and lossless 3D-CALIC. The experimental results show the significant improvement on compression performance by using the proposed band ordering techniques for different types of real multispectral data (3-5% using CCSDS and 2-3% using 3D-CALIC), hyperspectral data (0.2-0.7% using CCSDS and 0.8-1% using 3D-CALIC) and hyperspectral sounder data (5.5-7% using CCSDS and 4-5% using 3D-CALIC). (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ibn Afjal, Masud; Al Mamun, Md.; Uddin, Md. Palash] Rajshahi Univ Engn & Technol, Dept Comp Sci & Engn, Rajshahi 6204, Bangladesh.
C3 Rajshahi University of Engineering & Technology (RUET)
RP Ibn Afjal, M (corresponding author), Rajshahi Univ Engn & Technol, Dept Comp Sci & Engn, Rajshahi 6204, Bangladesh.
EM masud@hstu.ac.bd
RI Afjal, Masud Ibn/JAN-6484-2023; Afjal, Masud Ibn/AAU-8983-2021; Uddin,
   Md Palash/AAS-3965-2020
OI Afjal, Masud Ibn/0000-0001-7764-0151; Uddin, Md
   Palash/0000-0002-4429-6590
CR Afjal M. I., 2018, INT C COMP COMM CHEM
   Amrani N, 2016, IEEE DATA COMPR CONF, P121, DOI 10.1109/DCC.2016.43
   [Anonymous], 2006, REMOTE SENSING DIGIT
   Baumgartner M. F., 2015, 220 BAND AVIRIS HYPE
   Conoscenti M, 2016, IEEE T GEOSCI REMOTE, V54, P7431, DOI 10.1109/TGRS.2016.2603998
   Consultative Committee for Space Data Systems (CCSDS), LOSSL MULT HYP IM CO
   Fu W., 2017, IEEE T GEOSCI REMOTE, V55, P1
   Gaucel  J.-M., 2011, SPIE P, V8157
   Hagag A., 2016, J VISUAL COMMUNICATI, V42, P14
   Hagag A, 2015, SIGNAL IMAGE VIDEO P, V9, P769, DOI 10.1007/s11760-013-0516-4
   Herrero R, 2014, SIGNAL IMAGE VIDEO P, V8, P255, DOI 10.1007/s11760-013-0541-3
   Huber-Lerner M, 2014, IEEE J-STARS, V7, P2246, DOI 10.1109/JSTARS.2014.2320754
   Jia XP, 1999, IEEE T GEOSCI REMOTE, V37, P538, DOI 10.1109/36.739109
   Lopez G., 2014, 8 IEEE INT C APPL IN
   Magli E, 2004, IEEE GEOSCI REMOTE S, V1, P21, DOI 10.1109/LGRS.2003.822312
   Mamatha  A.S., 2017, IMAG SCI J, V65
   Mamun M, 2014, IEEE GEOSCI REMOTE S, V11, P1005, DOI 10.1109/LGRS.2013.2284358
   Mamun M. A., 2010, 2 IITA INT C GEOSC R
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P157, DOI 10.1109/LSP.2005.862604
   Mielikainen J, 2008, IEEE GEOSCI REMOTE S, V5, P474, DOI 10.1109/LGRS.2008.917598
   Rajan K, 2016, INT ARAB J INF TECHN, V13, P435
   Sanchez J. E., 2011, 1 INT C DAT COMPR CO
   Santos L, 2016, IEEE J-STARS, V9, P757, DOI 10.1109/JSTARS.2015.2497163
   Shah Dharam, 2015, International Journal of Image, Graphics and Signal Processing, V7, P35, DOI 10.5815/ijigsp.2015.04.04
   Shen H., 2017, IEEE T GEOSCI REMOTE, V55, P1
   Shi Q., 2015, ACM 15 INT C INT MUL
   Tate SR, 1997, IEEE T COMPUT, V46, P477, DOI 10.1109/12.588062
   Toivanen P, 2005, IEEE GEOSCI REMOTE S, V2, P50, DOI 10.1109/LGRS.2004.838410
   Tsai F, 2007, INT J REMOTE SENS, V28, P1023, DOI 10.1080/01431160600887706
   Uddin MP, 2017, P IEEE 5 REG 10 HUM
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P994, DOI 10.1109/83.846242
NR 33
TC 37
Z9 38
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 514
EP 526
DI 10.1016/j.jvcir.2019.01.042
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600054
DA 2024-07-18
ER

EF